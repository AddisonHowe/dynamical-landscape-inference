Args:
Namespace(name='model_algphi2_1a_v_kl', outdir='out/model_training/model_algphi2_1a_v_kl', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1611409462

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 5.991806540586775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.991806540586775 | validation: 5.406918810774457]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 5.355734607137165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.355734607137165 | validation: 5.062339128304411]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 5.032069176401194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.032069176401194 | validation: 4.843004218973562]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 4.975589735819604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.975589735819604 | validation: 4.840463226875913]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 4.95164176698606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.95164176698606 | validation: 4.599877176846488]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 4.6906721991813605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6906721991813605 | validation: 4.391818503988931]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 4.5334941600426335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5334941600426335 | validation: 4.2033510813374075]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 4.25840628276727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.25840628276727 | validation: 3.7977791850913825]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 3.867851676714842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.867851676714842 | validation: 3.451115506623563]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5276164442778435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5276164442778435 | validation: 3.08920910351781]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 3.166874753896419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.166874753896419 | validation: 2.706726624936139]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7810201360166196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7810201360166196 | validation: 2.240068082212111]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 2.2775208212256315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2775208212256315 | validation: 1.8597764877287148]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 1.8841472498313023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8841472498313023 | validation: 1.6315568963440858]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 1.5993318686588385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5993318686588385 | validation: 1.3500485886884133]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2873566822981672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2873566822981672 | validation: 1.1063321875968828]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 1.0869238794672869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0869238794672869 | validation: 0.9455217535018894]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9313377970118485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9313377970118485 | validation: 0.8144790701128068]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.79150505229416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.79150505229416 | validation: 0.5774826339328902]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.654760185289296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.654760185289296 | validation: 0.46241504842316783]
	TIME [epoch: 4.17 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5280327496301769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5280327496301769 | validation: 0.37892621619603845]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.43504652224489865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43504652224489865 | validation: 0.41379698023715084]
	TIME [epoch: 4.14 sec]
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.45636267649504036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45636267649504036 | validation: 0.5001351355095798]
	TIME [epoch: 4.14 sec]
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4894304964207506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4894304964207506 | validation: 0.4614955851208006]
	TIME [epoch: 4.13 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3761856909023131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3761856909023131 | validation: 0.27902042779822805]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2831209328276228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2831209328276228 | validation: 0.29062332683805014]
	TIME [epoch: 4.16 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3262471998400433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3262471998400433 | validation: 0.34001709128022706]
	TIME [epoch: 4.14 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2872529704343926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2872529704343926 | validation: 0.2158000858199755]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.202443429875297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.202443429875297 | validation: 0.1681986136420776]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17495977725372103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17495977725372103 | validation: 0.17480394544149863]
	TIME [epoch: 4.13 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1582378329641295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1582378329641295 | validation: 0.1369430973238489]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1564194519409418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1564194519409418 | validation: 0.136436471116976]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1604399669839427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1604399669839427 | validation: 0.18519754411371597]
	TIME [epoch: 4.18 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20249003104271446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20249003104271446 | validation: 0.20106010734864238]
	TIME [epoch: 4.16 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24877724505017793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24877724505017793 | validation: 0.3046862466533051]
	TIME [epoch: 4.14 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.29486963879587674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29486963879587674 | validation: 0.25394242584584903]
	TIME [epoch: 4.14 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.254228907603884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.254228907603884 | validation: 0.2536294928603271]
	TIME [epoch: 4.15 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24211552039949535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24211552039949535 | validation: 0.20214991685064165]
	TIME [epoch: 4.14 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20008426922554068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20008426922554068 | validation: 0.17811125954856755]
	TIME [epoch: 4.14 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1872735408892734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1872735408892734 | validation: 0.1841703053613077]
	TIME [epoch: 4.14 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17816559041386484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17816559041386484 | validation: 0.15795808956932483]
	TIME [epoch: 4.18 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1660392050459837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1660392050459837 | validation: 0.16428097948955447]
	TIME [epoch: 4.16 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15091939302664237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15091939302664237 | validation: 0.1274626468143476]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12620038931874827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12620038931874827 | validation: 0.12878221711471727]
	TIME [epoch: 4.14 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12656395549337685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12656395549337685 | validation: 0.11100665372223556]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14952168949297062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14952168949297062 | validation: 0.14684494699396863]
	TIME [epoch: 4.13 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19637755421488706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19637755421488706 | validation: 0.15488307259597736]
	TIME [epoch: 4.13 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20958005034751295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20958005034751295 | validation: 0.14460445075252049]
	TIME [epoch: 4.17 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1795951608767385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1795951608767385 | validation: 0.1448416870506538]
	TIME [epoch: 4.14 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1577163106302103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1577163106302103 | validation: 0.11964115404142642]
	TIME [epoch: 4.13 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04322174996318377		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.04322174996318377 | validation: 0.04769288548719354]
	TIME [epoch: 113 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06301773323101445		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.06301773323101445 | validation: 0.027648260793161704]
	TIME [epoch: 8.13 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.036439474130380956		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.036439474130380956 | validation: 0.03537753283698261]
	TIME [epoch: 8.09 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06753681090789754		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.06753681090789754 | validation: 0.04513845871533691]
	TIME [epoch: 8.12 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.049716598782490136		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.049716598782490136 | validation: 0.011736133617595736]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008589401101053188		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.008589401101053188 | validation: -0.013416080889837487]
	TIME [epoch: 8.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010711331981206027		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.010711331981206027 | validation: 0.0019425905125989716]
	TIME [epoch: 8.07 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02198828039023275		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.02198828039023275 | validation: 0.02197189614265121]
	TIME [epoch: 8.14 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014185240790037712		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.014185240790037712 | validation: 0.006115735684561759]
	TIME [epoch: 8.1 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016081064053352995		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.016081064053352995 | validation: -0.0009762762525085834]
	TIME [epoch: 8.11 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012038424039042435		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.012038424039042435 | validation: 0.013698107175900379]
	TIME [epoch: 8.09 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013570378757679297		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.013570378757679297 | validation: -0.015722379277014448]
	TIME [epoch: 8.11 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002932786126704714		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.002932786126704714 | validation: 0.0015136407053567389]
	TIME [epoch: 8.09 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012375456093931321		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.012375456093931321 | validation: 0.018918150412038218]
	TIME [epoch: 8.04 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.051531430522338065		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.051531430522338065 | validation: 0.03923561611316699]
	TIME [epoch: 8.04 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041271992271374014		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.041271992271374014 | validation: 0.04625620515930677]
	TIME [epoch: 8.06 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04516618923962207		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.04516618923962207 | validation: 0.019880516123341636]
	TIME [epoch: 8.11 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02022317903899762		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.02022317903899762 | validation: 0.01757105161939558]
	TIME [epoch: 8.07 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017876948908669497		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.017876948908669497 | validation: -0.0016842774371075655]
	TIME [epoch: 8.05 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017768436232467422		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.017768436232467422 | validation: 0.025166841547506542]
	TIME [epoch: 8.06 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025059544986024723		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.025059544986024723 | validation: 0.009533833842115074]
	TIME [epoch: 8.11 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025196849285736633		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.025196849285736633 | validation: 0.010236344086106706]
	TIME [epoch: 8.08 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02256861077006152		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.02256861077006152 | validation: 0.011410377911321715]
	TIME [epoch: 8.05 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030968479423576147		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.030968479423576147 | validation: 0.012658943684581276]
	TIME [epoch: 8.07 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02912679952584457		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.02912679952584457 | validation: 0.017421021042712072]
	TIME [epoch: 8.13 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029013159574621673		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.029013159574621673 | validation: 0.012692653972331368]
	TIME [epoch: 8.1 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03275159254361229		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.03275159254361229 | validation: 0.0001072573090148167]
	TIME [epoch: 8.08 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012453247093263493		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.012453247093263493 | validation: -0.0179648691828627]
	TIME [epoch: 8.07 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0062240927893193404		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.0062240927893193404 | validation: -0.0003340947646209353]
	TIME [epoch: 8.08 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006232664239513701		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.006232664239513701 | validation: -0.0017076406730001433]
	TIME [epoch: 8.1 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005408473183744136		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.005408473183744136 | validation: 0.0034749185702673585]
	TIME [epoch: 8.05 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021800749235211858		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.021800749235211858 | validation: 0.0004787397736210437]
	TIME [epoch: 8.05 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027911995430323758		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.027911995430323758 | validation: 0.03599721619557647]
	TIME [epoch: 8.08 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05645490726743582		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.05645490726743582 | validation: 0.04090863069003274]
	TIME [epoch: 8.13 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04579222202642204		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.04579222202642204 | validation: 0.02339146221011678]
	TIME [epoch: 8.13 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05936192937784189		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.05936192937784189 | validation: 0.06226461968909036]
	TIME [epoch: 8.1 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.047089015621899696		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.047089015621899696 | validation: 0.028401299156053973]
	TIME [epoch: 8.12 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04408219574283543		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.04408219574283543 | validation: 0.01818773832045689]
	TIME [epoch: 8.13 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029051182408130337		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.029051182408130337 | validation: 0.01272511998000133]
	TIME [epoch: 8.16 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019062793343755925		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.019062793343755925 | validation: -0.0022032649231022244]
	TIME [epoch: 8.11 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019357096139228834		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.019357096139228834 | validation: -0.007712120036402263]
	TIME [epoch: 8.12 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0030308119293598742		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.0030308119293598742 | validation: -0.01501262966490852]
	TIME [epoch: 8.13 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000747626584848909		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: -0.000747626584848909 | validation: -0.0017820841310943554]
	TIME [epoch: 8.15 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004147330364689521		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.004147330364689521 | validation: 8.736929832356931e-05]
	TIME [epoch: 8.1 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011222239024821076		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.011222239024821076 | validation: 0.004894918171612696]
	TIME [epoch: 8.12 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007964714615657781		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.007964714615657781 | validation: -0.004314825992169955]
	TIME [epoch: 8.14 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01149163826414832		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.01149163826414832 | validation: 0.011138079061503834]
	TIME [epoch: 8.16 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02788759217200686		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.02788759217200686 | validation: 0.013917358765253053]
	TIME [epoch: 8.12 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04623677249860099		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.04623677249860099 | validation: 0.028338045848515223]
	TIME [epoch: 8.13 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04824061979384402		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.04824061979384402 | validation: 0.013873147400721837]
	TIME [epoch: 8.12 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03349228784997109		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.03349228784997109 | validation: 0.020329183904350415]
	TIME [epoch: 124 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04048200860248876		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.04048200860248876 | validation: 0.03671365850464311]
	TIME [epoch: 18.3 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04917617266769678		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.04917617266769678 | validation: 0.0376307483055903]
	TIME [epoch: 18.3 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0560045682595484		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.0560045682595484 | validation: 0.030101392893126768]
	TIME [epoch: 18.3 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0420374322180185		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.0420374322180185 | validation: 0.030546066589369206]
	TIME [epoch: 18.3 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0406152794793469		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.0406152794793469 | validation: 0.018431453833417447]
	TIME [epoch: 18.3 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04427688883771107		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.04427688883771107 | validation: 0.021152046413776174]
	TIME [epoch: 18.4 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03452502444787131		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.03452502444787131 | validation: 0.01230231086220908]
	TIME [epoch: 18.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018853882144752993		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.018853882144752993 | validation: 0.0061747331870463254]
	TIME [epoch: 18.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022394254764447858		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.022394254764447858 | validation: 0.003470016329479697]
	TIME [epoch: 18.3 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009053127049022537		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.009053127049022537 | validation: -0.0045291146752082356]
	TIME [epoch: 18.4 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005632943765243031		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.005632943765243031 | validation: -0.00034455106337449317]
	TIME [epoch: 18.3 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006063918780014376		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.006063918780014376 | validation: -0.010016060008077978]
	TIME [epoch: 18.4 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004913811394752453		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.004913811394752453 | validation: 0.001084205203594877]
	TIME [epoch: 18.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010933139838608441		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.010933139838608441 | validation: 0.009243906906147611]
	TIME [epoch: 18.4 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014140864534165347		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.014140864534165347 | validation: 0.01257922534199103]
	TIME [epoch: 18.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025955474693317843		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.025955474693317843 | validation: 0.021955698539491395]
	TIME [epoch: 18.3 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03828801813457691		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.03828801813457691 | validation: 0.033924765914507354]
	TIME [epoch: 18.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04001515097515815		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.04001515097515815 | validation: 0.024795140436805307]
	TIME [epoch: 18.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02338234903329173		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.02338234903329173 | validation: 0.007528376724383667]
	TIME [epoch: 18.3 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011201894403139843		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.011201894403139843 | validation: -0.003293753100282809]
	TIME [epoch: 18.3 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012784873674836836		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.012784873674836836 | validation: -0.008299025045297816]
	TIME [epoch: 18.3 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00844910095540187		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.00844910095540187 | validation: -0.0022255071857438255]
	TIME [epoch: 18.3 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004861667848298426		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.004861667848298426 | validation: -0.0038025677680697534]
	TIME [epoch: 18.3 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005986951070703173		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.005986951070703173 | validation: -0.0033310285730393714]
	TIME [epoch: 18.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005588253685664259		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.005588253685664259 | validation: -0.005172024502898562]
	TIME [epoch: 18.3 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005009365371045826		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.005009365371045826 | validation: -0.008272778450932956]
	TIME [epoch: 18.3 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0013420739148741901		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.0013420739148741901 | validation: -0.01011237664570767]
	TIME [epoch: 18.3 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0015475095132101474		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.0015475095132101474 | validation: -0.009329407782832085]
	TIME [epoch: 18.4 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005131041495137708		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.005131041495137708 | validation: -0.006887100616618708]
	TIME [epoch: 18.3 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003381354783117443		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.003381354783117443 | validation: -0.008175670602480426]
	TIME [epoch: 18.4 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003590442986857713		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.003590442986857713 | validation: -0.004212543664920389]
	TIME [epoch: 18.3 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004884928439745979		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.004884928439745979 | validation: -0.01780005413437572]
	TIME [epoch: 18.4 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00206774960109232		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.00206774960109232 | validation: -0.008492771469204397]
	TIME [epoch: 18.3 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00454489569041442		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: -0.00454489569041442 | validation: -0.007645420100173984]
	TIME [epoch: 18.4 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002572603091613083		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: -0.002572603091613083 | validation: -0.004908779877344237]
	TIME [epoch: 18.4 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002662129757270461		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.002662129757270461 | validation: -0.011609048276238635]
	TIME [epoch: 18.4 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005535697356799114		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.005535697356799114 | validation: -0.0046268338886863115]
	TIME [epoch: 18.3 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012090552019546423		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.012090552019546423 | validation: 0.002707493672092184]
	TIME [epoch: 18.4 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014693425098013491		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.014693425098013491 | validation: 0.0025545224827373905]
	TIME [epoch: 18.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017827742146495875		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.017827742146495875 | validation: 0.0034962838971811607]
	TIME [epoch: 18.3 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023841191740654282		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.023841191740654282 | validation: 0.0023702329211633105]
	TIME [epoch: 18.3 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026960614146337297		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.026960614146337297 | validation: 0.019993987602380973]
	TIME [epoch: 18.3 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02470799189974807		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.02470799189974807 | validation: 0.011453162984609865]
	TIME [epoch: 18.3 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023340665635792273		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.023340665635792273 | validation: -0.0002742859864471605]
	TIME [epoch: 18.3 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021585450159768038		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.021585450159768038 | validation: 0.00799383753760514]
	TIME [epoch: 18.3 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025868936583448916		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.025868936583448916 | validation: 0.014636933093610412]
	TIME [epoch: 18.3 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023422901137644767		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.023422901137644767 | validation: 0.00670167193156341]
	TIME [epoch: 18.3 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02779268004745877		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.02779268004745877 | validation: -0.0007038826997173685]
	TIME [epoch: 18.3 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021324226624295672		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.021324226624295672 | validation: 0.0019564656123443576]
	TIME [epoch: 18.4 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013391718820422614		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.013391718820422614 | validation: 0.000861531817154682]
	TIME [epoch: 18.3 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017299527444013085		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.017299527444013085 | validation: -0.0034344040677845083]
	TIME [epoch: 18.4 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01020885531763099		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.01020885531763099 | validation: -0.0015276452019140846]
	TIME [epoch: 18.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01380564898624314		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.01380564898624314 | validation: 0.002616137216159649]
	TIME [epoch: 18.4 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010238370299023412		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.010238370299023412 | validation: -0.005709816430868295]
	TIME [epoch: 18.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00030122008113496067		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.00030122008113496067 | validation: -0.008810465532088169]
	TIME [epoch: 18.4 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003966890818331308		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.003966890818331308 | validation: -0.008319402058230715]
	TIME [epoch: 18.4 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0026261479905555244		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.0026261479905555244 | validation: -0.01719285868212779]
	TIME [epoch: 18.4 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005387072205178453		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.005387072205178453 | validation: -0.010927789093788734]
	TIME [epoch: 18.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004120680360575482		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.004120680360575482 | validation: -0.004472086809707454]
	TIME [epoch: 18.4 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003733805277597057		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.003733805277597057 | validation: -0.004554843732750049]
	TIME [epoch: 18.3 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008393803762357623		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.008393803762357623 | validation: -0.008360564227106175]
	TIME [epoch: 18.4 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005878986773862915		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.005878986773862915 | validation: -0.011016948623620584]
	TIME [epoch: 18.4 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0036063003153602776		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.0036063003153602776 | validation: -0.01322422497095952]
	TIME [epoch: 18.4 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004994241037296192		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.004994241037296192 | validation: -0.011208444489433067]
	TIME [epoch: 18.4 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005047716179358794		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.005047716179358794 | validation: -0.010891108920369263]
	TIME [epoch: 18.4 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005437322170386097		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.005437322170386097 | validation: -0.023198422479958944]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_167.pth
	Model improved!!!
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00894948370262726		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.00894948370262726 | validation: -0.014478833664079586]
	TIME [epoch: 18.3 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004541441351113777		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.004541441351113777 | validation: -0.017820281813001562]
	TIME [epoch: 18.3 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00842110776853603		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.00842110776853603 | validation: -0.013019722241037663]
	TIME [epoch: 18.3 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009475410646174366		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.009475410646174366 | validation: -0.012256355417025265]
	TIME [epoch: 18.3 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011187160884608985		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.011187160884608985 | validation: -0.015062035219965414]
	TIME [epoch: 18.3 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009793278717704901		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.009793278717704901 | validation: -0.01442878702727736]
	TIME [epoch: 18.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004393388827715486		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.004393388827715486 | validation: -0.01912629568478084]
	TIME [epoch: 18.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005219447263891094		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.005219447263891094 | validation: -0.00509870095060066]
	TIME [epoch: 18.3 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005884989193412594		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.005884989193412594 | validation: -0.01789090719270973]
	TIME [epoch: 18.3 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00537347691822933		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.00537347691822933 | validation: -0.01521224221280473]
	TIME [epoch: 18.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0095256988524889		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.0095256988524889 | validation: -0.014372583261066427]
	TIME [epoch: 18.3 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009956953530224048		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.009956953530224048 | validation: -0.019026350420813787]
	TIME [epoch: 18.3 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01000644642117719		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.01000644642117719 | validation: -0.009832671184724555]
	TIME [epoch: 18.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008719745000420368		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.008719745000420368 | validation: -0.016215826350449762]
	TIME [epoch: 18.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010831130986929925		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.010831130986929925 | validation: -0.017571185427260314]
	TIME [epoch: 18.3 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01246213835970791		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.01246213835970791 | validation: -0.02109030575875799]
	TIME [epoch: 18.3 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00862434144169182		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.00862434144169182 | validation: -0.012272008631189584]
	TIME [epoch: 18.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008757156825275357		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.008757156825275357 | validation: -0.004919187688823951]
	TIME [epoch: 18.3 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007092240774445192		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.007092240774445192 | validation: -0.010067213918421095]
	TIME [epoch: 18.3 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00907253512160199		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.00907253512160199 | validation: -0.014404281869486934]
	TIME [epoch: 18.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006088747793259051		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.006088747793259051 | validation: -0.013508054555705945]
	TIME [epoch: 18.3 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008230625028974396		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.008230625028974396 | validation: 0.0009170334578615256]
	TIME [epoch: 18.3 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015053116830646578		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.0015053116830646578 | validation: -0.012148070594045358]
	TIME [epoch: 18.3 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006549115304932927		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.006549115304932927 | validation: -0.0073278396663944735]
	TIME [epoch: 18.3 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005005706172709958		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.005005706172709958 | validation: -0.01656447629032059]
	TIME [epoch: 18.3 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007889574850454717		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.007889574850454717 | validation: -0.02060449079120278]
	TIME [epoch: 18.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003613196587525129		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.003613196587525129 | validation: -0.0175112091861701]
	TIME [epoch: 18.3 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010183922935681215		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.010183922935681215 | validation: -0.02656156827983671]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_195.pth
	Model improved!!!
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007892635617049545		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.007892635617049545 | validation: -0.02649470775189197]
	TIME [epoch: 18.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005095062205292958		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.005095062205292958 | validation: -0.014238610898651298]
	TIME [epoch: 18.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01195644330152638		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.01195644330152638 | validation: -0.01852176705555434]
	TIME [epoch: 18.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006078680405572972		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.006078680405572972 | validation: -0.01139759813526155]
	TIME [epoch: 18.4 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005888778222105297		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.005888778222105297 | validation: -0.006785927480630142]
	TIME [epoch: 18.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00997773699458715		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.00997773699458715 | validation: -0.011892069393325383]
	TIME [epoch: 18.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025127023693586647		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.0025127023693586647 | validation: -0.02079675756463529]
	TIME [epoch: 18.4 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00463294488235802		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.00463294488235802 | validation: -0.01452027712238372]
	TIME [epoch: 18.4 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00729409764365278		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.00729409764365278 | validation: -0.023035497387523203]
	TIME [epoch: 18.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007537082757018679		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.007537082757018679 | validation: -0.009217872420343793]
	TIME [epoch: 18.4 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000598288961110755		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.000598288961110755 | validation: -0.012256208227604313]
	TIME [epoch: 18.3 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009637623798556185		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.0009637623798556185 | validation: -0.007432201091068725]
	TIME [epoch: 18.4 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015423589192356086		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.0015423589192356086 | validation: -0.015882180806969147]
	TIME [epoch: 18.3 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001713126080260337		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.001713126080260337 | validation: -0.005445967441439965]
	TIME [epoch: 18.4 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002077861100025037		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.002077861100025037 | validation: -0.009549946419140755]
	TIME [epoch: 18.4 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006184608565254218		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.006184608565254218 | validation: -0.014794492965173867]
	TIME [epoch: 18.4 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000537512943288971		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.000537512943288971 | validation: -0.021249675756579888]
	TIME [epoch: 18.4 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025751324933190115		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.0025751324933190115 | validation: -0.010008283724335723]
	TIME [epoch: 18.4 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005525837594808968		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.005525837594808968 | validation: -0.014142703388040311]
	TIME [epoch: 18.4 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004457173761670438		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.004457173761670438 | validation: -0.015461347545970096]
	TIME [epoch: 18.4 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0034012941070321757		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.0034012941070321757 | validation: -0.013072271962927755]
	TIME [epoch: 18.3 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024087835461798096		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.0024087835461798096 | validation: -0.010952326738401245]
	TIME [epoch: 18.4 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007187903229420566		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.007187903229420566 | validation: -0.006097627789452334]
	TIME [epoch: 18.3 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006134802908988824		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.006134802908988824 | validation: -0.021642779762287352]
	TIME [epoch: 18.4 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005131214772890666		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.005131214772890666 | validation: -0.02087400984165328]
	TIME [epoch: 18.3 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002496601198757916		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.002496601198757916 | validation: -0.022453924716335498]
	TIME [epoch: 18.4 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008311089616962827		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.008311089616962827 | validation: -0.017146655285800935]
	TIME [epoch: 18.3 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006626158216044109		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.006626158216044109 | validation: -0.012960083104086605]
	TIME [epoch: 18.4 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007183817169025364		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.007183817169025364 | validation: -0.012082773917201839]
	TIME [epoch: 18.3 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004965586377678717		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.004965586377678717 | validation: -0.005674345376141481]
	TIME [epoch: 18.4 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0042264725089709975		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.0042264725089709975 | validation: -0.00539091424356331]
	TIME [epoch: 18.3 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002919901101166635		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.002919901101166635 | validation: -0.005320112828623677]
	TIME [epoch: 18.4 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0028397040029835424		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.0028397040029835424 | validation: -0.014972480756553958]
	TIME [epoch: 18.3 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007890662438551474		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.007890662438551474 | validation: -0.023379242344151854]
	TIME [epoch: 18.3 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00497583632048788		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.00497583632048788 | validation: -0.026681217562924364]
	TIME [epoch: 18.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_230.pth
	Model improved!!!
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005634170073009484		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.005634170073009484 | validation: -0.014932026180698006]
	TIME [epoch: 18.4 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0054310233279775905		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.0054310233279775905 | validation: -0.01467024936015059]
	TIME [epoch: 18.4 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003963539255413853		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.003963539255413853 | validation: -0.010251217369907775]
	TIME [epoch: 18.4 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005604004085120248		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.005604004085120248 | validation: -0.010915928495271593]
	TIME [epoch: 18.3 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006590314006222328		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.006590314006222328 | validation: -0.012574202192416823]
	TIME [epoch: 18.4 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008143834469814388		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.008143834469814388 | validation: -0.02117107121779596]
	TIME [epoch: 18.4 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002516611068866118		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.002516611068866118 | validation: -0.010729244483661315]
	TIME [epoch: 18.4 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010799956434322019		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.010799956434322019 | validation: -0.007276941402316065]
	TIME [epoch: 18.4 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008561059975991723		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.008561059975991723 | validation: -0.02300459589386167]
	TIME [epoch: 18.4 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007245925675733758		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.007245925675733758 | validation: -0.008923489645436116]
	TIME [epoch: 18.4 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008634229976117945		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.008634229976117945 | validation: -0.007254070295002304]
	TIME [epoch: 18.3 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0068538290794319485		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.0068538290794319485 | validation: -0.005005738049373426]
	TIME [epoch: 18.3 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012360627637935663		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.012360627637935663 | validation: -0.004010563724765397]
	TIME [epoch: 18.3 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010052924463084222		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.010052924463084222 | validation: -0.012205008682565022]
	TIME [epoch: 18.4 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0071444270052993		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.0071444270052993 | validation: -0.02229885881472175]
	TIME [epoch: 18.3 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008381419045346599		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.008381419045346599 | validation: -0.0089904309030959]
	TIME [epoch: 18.4 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005827738341742186		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.005827738341742186 | validation: -0.019776871456824878]
	TIME [epoch: 18.3 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010577504814277622		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.010577504814277622 | validation: -0.016511842397526535]
	TIME [epoch: 18.4 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00692560776264734		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.00692560776264734 | validation: -0.019575117777864692]
	TIME [epoch: 18.4 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00469828483293042		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.00469828483293042 | validation: -0.01067020020413649]
	TIME [epoch: 18.3 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005366192084648901		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.005366192084648901 | validation: -0.017153584877040905]
	TIME [epoch: 147 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002665050001267183		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.002665050001267183 | validation: -0.004726464214409198]
	TIME [epoch: 40.6 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00672432663299472		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.00672432663299472 | validation: -0.021941479054355777]
	TIME [epoch: 40.4 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005577944050567392		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.005577944050567392 | validation: -0.004201337294909371]
	TIME [epoch: 40.4 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008921519010872703		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.008921519010872703 | validation: -0.02230869044692125]
	TIME [epoch: 40.4 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005904836003951362		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.005904836003951362 | validation: -0.012660560294110848]
	TIME [epoch: 40.5 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008644408164032126		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.008644408164032126 | validation: -0.010683731005003014]
	TIME [epoch: 40.4 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007360995755084001		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.007360995755084001 | validation: -0.015243083477908963]
	TIME [epoch: 40.4 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002970626585492737		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.002970626585492737 | validation: -0.015525249734415133]
	TIME [epoch: 40.5 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00740153774552114		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.00740153774552114 | validation: -0.015586972789826712]
	TIME [epoch: 40.5 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008469091688988094		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.008469091688988094 | validation: -0.029368424257496584]
	TIME [epoch: 40.5 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_261.pth
	Model improved!!!
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0054066942096249685		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.0054066942096249685 | validation: -0.00943059053291105]
	TIME [epoch: 40.6 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007921548033816145		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.007921548033816145 | validation: -0.013949212061235517]
	TIME [epoch: 40.5 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006901911125681939		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.006901911125681939 | validation: -0.026392142398672616]
	TIME [epoch: 40.5 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0038409771242016843		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.0038409771242016843 | validation: -0.009863593432365422]
	TIME [epoch: 40.5 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021847058564561784		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.0021847058564561784 | validation: -0.01914765037045573]
	TIME [epoch: 40.5 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003923093378260629		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.003923093378260629 | validation: -0.015570274128975712]
	TIME [epoch: 40.5 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005570490134557541		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.005570490134557541 | validation: -0.019448314872178536]
	TIME [epoch: 40.5 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008950686116826196		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.008950686116826196 | validation: -0.012055628201411733]
	TIME [epoch: 40.5 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007663960731149121		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.007663960731149121 | validation: -0.019445917345614544]
	TIME [epoch: 40.5 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007083351544451744		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.007083351544451744 | validation: -0.017051396798124844]
	TIME [epoch: 40.5 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005461925638656762		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.005461925638656762 | validation: -0.0201535198088615]
	TIME [epoch: 40.5 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004013813209080303		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.004013813209080303 | validation: -0.010032461029524188]
	TIME [epoch: 40.5 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009348179521822894		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.009348179521822894 | validation: -0.010551414706925569]
	TIME [epoch: 40.5 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00624081181940863		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.00624081181940863 | validation: -0.012060444530944778]
	TIME [epoch: 40.5 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0060889403754491095		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.0060889403754491095 | validation: -0.019963443315349154]
	TIME [epoch: 40.5 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01105156319584313		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.01105156319584313 | validation: -0.012484131434239518]
	TIME [epoch: 40.5 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004407998542365971		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.0004407998542365971 | validation: -0.010762042240210433]
	TIME [epoch: 40.5 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008243518458606193		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.008243518458606193 | validation: -0.010213806797162784]
	TIME [epoch: 40.5 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007270804533052856		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.007270804533052856 | validation: -0.016620370832610126]
	TIME [epoch: 40.5 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007185048067434601		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.007185048067434601 | validation: -0.024632687222592466]
	TIME [epoch: 40.5 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0105340877144085		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.0105340877144085 | validation: -0.014769107290129146]
	TIME [epoch: 40.5 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011360068568740658		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.0011360068568740658 | validation: -0.012087541884597403]
	TIME [epoch: 40.5 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008551244918737261		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.008551244918737261 | validation: -0.014475242898659136]
	TIME [epoch: 40.5 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004031021400063223		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.004031021400063223 | validation: -0.02269773197075225]
	TIME [epoch: 40.5 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005838644612910398		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.005838644612910398 | validation: -0.0017581270059823825]
	TIME [epoch: 40.5 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00727591026569035		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.00727591026569035 | validation: -0.018567002977847843]
	TIME [epoch: 40.5 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006597645197966394		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.006597645197966394 | validation: -0.021561093422612747]
	TIME [epoch: 40.6 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010163687811902697		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.010163687811902697 | validation: -0.005909483159794616]
	TIME [epoch: 40.6 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006801515712757673		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.006801515712757673 | validation: -0.014646757449710491]
	TIME [epoch: 40.5 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00891488500957502		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.00891488500957502 | validation: -0.004220979309907925]
	TIME [epoch: 40.5 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006569546720291127		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.006569546720291127 | validation: -0.01978330960373294]
	TIME [epoch: 40.5 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005046519659089584		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.005046519659089584 | validation: -0.01580581636750306]
	TIME [epoch: 40.5 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008734600093968675		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.008734600093968675 | validation: -0.007657000694498633]
	TIME [epoch: 40.5 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009770632241516305		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.009770632241516305 | validation: -0.011458366779827658]
	TIME [epoch: 40.6 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006904827153861306		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.006904827153861306 | validation: -0.02267929820494828]
	TIME [epoch: 40.6 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00874186984493616		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.00874186984493616 | validation: -0.01126059758651204]
	TIME [epoch: 40.5 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008120868669911973		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.008120868669911973 | validation: -0.023686960393486015]
	TIME [epoch: 40.5 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031194954528649295		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.0031194954528649295 | validation: -0.01868818285837922]
	TIME [epoch: 40.5 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003949371699378611		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.003949371699378611 | validation: -0.01805795210024365]
	TIME [epoch: 40.5 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007093296296324804		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.007093296296324804 | validation: -0.018941843620399353]
	TIME [epoch: 40.5 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00545983334592157		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.00545983334592157 | validation: -0.011578463072527278]
	TIME [epoch: 40.5 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004637589240690518		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.004637589240690518 | validation: -0.013660720596050394]
	TIME [epoch: 40.5 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005740813714217254		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.005740813714217254 | validation: -0.021805787748963152]
	TIME [epoch: 40.5 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006148792565664522		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.006148792565664522 | validation: -0.010942384279656187]
	TIME [epoch: 40.5 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0072758192081687585		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.0072758192081687585 | validation: -0.009227606310854591]
	TIME [epoch: 40.5 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0065170097229791555		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.0065170097229791555 | validation: -0.015949552534516794]
	TIME [epoch: 40.5 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011460282286997352		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.011460282286997352 | validation: -0.01647358201025426]
	TIME [epoch: 40.5 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008513788577872118		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.008513788577872118 | validation: -0.018253010458640556]
	TIME [epoch: 40.4 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006441204220777036		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.006441204220777036 | validation: -0.015356401787283844]
	TIME [epoch: 40.5 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005236217010810864		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.005236217010810864 | validation: -0.016492626412790704]
	TIME [epoch: 40.5 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011975349318683642		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.011975349318683642 | validation: -0.00866399999362337]
	TIME [epoch: 40.5 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004451577931433101		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.004451577931433101 | validation: -0.020764586694188493]
	TIME [epoch: 40.5 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008694565209337316		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.008694565209337316 | validation: -0.009080386541477081]
	TIME [epoch: 40.5 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0061581322757885875		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.0061581322757885875 | validation: -0.015822047236467393]
	TIME [epoch: 40.6 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010524210006326563		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.010524210006326563 | validation: -0.020227583869048164]
	TIME [epoch: 40.5 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007654010321875758		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.007654010321875758 | validation: -0.010920693009882493]
	TIME [epoch: 40.5 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009011600839115081		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.009011600839115081 | validation: -0.015647536816413808]
	TIME [epoch: 40.5 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005685834170403314		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.005685834170403314 | validation: -0.020654658166122504]
	TIME [epoch: 40.5 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009610084257775016		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.009610084257775016 | validation: -0.014113759604038854]
	TIME [epoch: 40.5 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009773916627517231		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.009773916627517231 | validation: -0.011705158494465467]
	TIME [epoch: 40.6 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008575486958174715		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.008575486958174715 | validation: -0.012702137098201458]
	TIME [epoch: 40.5 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006455746552241286		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.006455746552241286 | validation: -0.010355994459336687]
	TIME [epoch: 40.5 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008956560927791792		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.008956560927791792 | validation: -0.011633353052179895]
	TIME [epoch: 40.6 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00789278570402839		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.00789278570402839 | validation: -0.005930126257173296]
	TIME [epoch: 40.5 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012715050340235635		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.012715050340235635 | validation: -0.015346493995263864]
	TIME [epoch: 40.6 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006489496828695572		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.006489496828695572 | validation: -0.022100698969053176]
	TIME [epoch: 40.5 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009177712266153356		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.009177712266153356 | validation: -0.00961238879114274]
	TIME [epoch: 40.6 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013936874912083855		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.013936874912083855 | validation: -0.015576507390337366]
	TIME [epoch: 40.5 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00851302391145722		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.00851302391145722 | validation: -0.006668744610364339]
	TIME [epoch: 40.5 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012050266849261592		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.012050266849261592 | validation: -0.016215937356620237]
	TIME [epoch: 40.5 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008585766358938027		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.008585766358938027 | validation: -0.014813863757388296]
	TIME [epoch: 40.5 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009790795497996161		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.009790795497996161 | validation: -0.01932261234344434]
	TIME [epoch: 40.5 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009644658172354596		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.009644658172354596 | validation: -0.02352570090018974]
	TIME [epoch: 40.5 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010521938229725762		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.010521938229725762 | validation: -0.015820471004397735]
	TIME [epoch: 40.5 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006350730815466046		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.006350730815466046 | validation: -0.009832263244074215]
	TIME [epoch: 40.5 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005689848951007043		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.005689848951007043 | validation: -0.01102122909990202]
	TIME [epoch: 40.5 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003669583473225069		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.003669583473225069 | validation: -0.007890186465168994]
	TIME [epoch: 40.5 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005779249514827613		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.005779249514827613 | validation: -0.017163706676747482]
	TIME [epoch: 40.6 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007786584481313606		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.007786584481313606 | validation: -0.009494626003253197]
	TIME [epoch: 40.6 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007076276659162901		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.007076276659162901 | validation: -0.012436127016870156]
	TIME [epoch: 40.5 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00861190878577618		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.00861190878577618 | validation: -0.016840704358467642]
	TIME [epoch: 40.6 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008906032183154958		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.008906032183154958 | validation: -0.014412894794184027]
	TIME [epoch: 40.6 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0061353668880007005		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.0061353668880007005 | validation: -0.013105304589513384]
	TIME [epoch: 40.6 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011005387062105791		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.011005387062105791 | validation: -0.022552068024054683]
	TIME [epoch: 40.6 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009012024244047328		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.009012024244047328 | validation: -0.02085713763300187]
	TIME [epoch: 40.6 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010433048322578948		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.010433048322578948 | validation: -0.02319358507016982]
	TIME [epoch: 40.6 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008973284291894505		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.008973284291894505 | validation: -0.014470623818913902]
	TIME [epoch: 40.5 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010234920486696308		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.010234920486696308 | validation: -0.013611167499779956]
	TIME [epoch: 40.6 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004820680089661651		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.004820680089661651 | validation: -0.03167359808476634]
	TIME [epoch: 40.6 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_350.pth
	Model improved!!!
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009634627410438811		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.009634627410438811 | validation: -0.01092442135541819]
	TIME [epoch: 40.6 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007053714989825157		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: -0.007053714989825157 | validation: -0.01905767615669949]
	TIME [epoch: 40.6 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009218553404650484		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: -0.009218553404650484 | validation: -0.010894219767215815]
	TIME [epoch: 40.6 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008928440427214298		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: -0.008928440427214298 | validation: -0.018164765298018373]
	TIME [epoch: 40.6 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009637778149182109		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: -0.009637778149182109 | validation: -0.01826155929402948]
	TIME [epoch: 40.6 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003135890840401688		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: -0.003135890840401688 | validation: -0.018372778672421746]
	TIME [epoch: 40.6 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011932708343301587		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: -0.011932708343301587 | validation: -0.018013979511333354]
	TIME [epoch: 40.5 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008050080408612976		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: -0.008050080408612976 | validation: -0.023318973182385454]
	TIME [epoch: 40.6 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012634945440413044		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: -0.012634945440413044 | validation: -0.00870436897227632]
	TIME [epoch: 40.6 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008121585326118959		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: -0.008121585326118959 | validation: -0.009353517451927787]
	TIME [epoch: 40.6 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00978579507140746		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: -0.00978579507140746 | validation: -0.014635129695154998]
	TIME [epoch: 40.7 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011655882994809661		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: -0.011655882994809661 | validation: -0.014238997567245785]
	TIME [epoch: 40.7 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008862233925078192		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: -0.008862233925078192 | validation: -0.008464975883626841]
	TIME [epoch: 40.7 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008998096143673529		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: -0.008998096143673529 | validation: -0.0169014357868731]
	TIME [epoch: 40.6 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006605230582353522		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: -0.006605230582353522 | validation: -0.01378058720335806]
	TIME [epoch: 40.6 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009291173005350296		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: -0.009291173005350296 | validation: -0.025067061125307193]
	TIME [epoch: 40.5 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0060790333941198775		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: -0.0060790333941198775 | validation: -0.013480335940783504]
	TIME [epoch: 40.7 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008732594086869199		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: -0.008732594086869199 | validation: -0.010952592082722982]
	TIME [epoch: 40.7 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009644038845516043		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: -0.009644038845516043 | validation: -0.013287012290749028]
	TIME [epoch: 40.7 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008925948923870757		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: -0.008925948923870757 | validation: -0.008958547989055859]
	TIME [epoch: 40.6 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011290371204249892		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: -0.011290371204249892 | validation: -0.013789550947950587]
	TIME [epoch: 40.6 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008365797954103		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: -0.008365797954103 | validation: -0.016187007992479064]
	TIME [epoch: 40.7 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008735378617104973		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: -0.008735378617104973 | validation: -0.020699650442962025]
	TIME [epoch: 40.7 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007350810389508374		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: -0.007350810389508374 | validation: -0.024579531535713017]
	TIME [epoch: 40.6 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007265724153431444		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: -0.007265724153431444 | validation: -0.02288133519377543]
	TIME [epoch: 40.6 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008082811311532578		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: -0.008082811311532578 | validation: -0.016867159467873583]
	TIME [epoch: 40.6 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010400630201725412		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: -0.010400630201725412 | validation: -0.019926156167858703]
	TIME [epoch: 40.6 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007610607237523133		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: -0.007610607237523133 | validation: -0.013896824970819573]
	TIME [epoch: 40.7 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010449503016536367		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: -0.010449503016536367 | validation: -0.019424628706900884]
	TIME [epoch: 40.7 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00952294180390218		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: -0.00952294180390218 | validation: -0.013172419832987945]
	TIME [epoch: 40.6 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010100094286269201		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: -0.010100094286269201 | validation: -0.019330029308050802]
	TIME [epoch: 40.7 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009866304596687971		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: -0.009866304596687971 | validation: -0.02505244782748326]
	TIME [epoch: 40.7 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010240140788971721		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: -0.010240140788971721 | validation: -0.016315315660433753]
	TIME [epoch: 40.7 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008444573878768243		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: -0.008444573878768243 | validation: -0.014697610138684007]
	TIME [epoch: 40.6 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008964299765477302		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: -0.008964299765477302 | validation: -0.01973062141757198]
	TIME [epoch: 40.6 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009971046171768309		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: -0.009971046171768309 | validation: -0.011147203589679949]
	TIME [epoch: 40.6 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011395944617933699		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: -0.011395944617933699 | validation: -0.01804826318780482]
	TIME [epoch: 40.7 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0054226976843591915		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: -0.0054226976843591915 | validation: -0.021252323959120852]
	TIME [epoch: 40.8 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008433712676793837		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: -0.008433712676793837 | validation: -0.019624553150770763]
	TIME [epoch: 40.7 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012909679597865155		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: -0.012909679597865155 | validation: -0.017679485033741286]
	TIME [epoch: 40.6 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0077952958977411165		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: -0.0077952958977411165 | validation: -0.02069949766897651]
	TIME [epoch: 40.5 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009051760837111301		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: -0.009051760837111301 | validation: -0.019433632138833874]
	TIME [epoch: 40.6 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010846194029259836		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: -0.010846194029259836 | validation: -0.019236221215600736]
	TIME [epoch: 40.6 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006629620876798591		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: -0.006629620876798591 | validation: -0.017463032836638484]
	TIME [epoch: 40.6 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008714957100654619		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: -0.008714957100654619 | validation: -0.01613385672789696]
	TIME [epoch: 40.6 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008820650320114382		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: -0.008820650320114382 | validation: -0.01771399516792248]
	TIME [epoch: 40.6 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009104356657874362		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: -0.009104356657874362 | validation: -0.015804388460306087]
	TIME [epoch: 40.7 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004358187640758136		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: -0.004358187640758136 | validation: -0.015263073601490311]
	TIME [epoch: 40.7 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007437943154664556		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: -0.007437943154664556 | validation: -0.01665023171137436]
	TIME [epoch: 40.6 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007344544230305689		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: -0.007344544230305689 | validation: -0.00861918431474912]
	TIME [epoch: 40.6 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011069002041586598		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: -0.011069002041586598 | validation: -0.015757137730058345]
	TIME [epoch: 40.5 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005827444034457707		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: -0.005827444034457707 | validation: -0.01711751657218944]
	TIME [epoch: 40.5 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011855740934532559		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: -0.011855740934532559 | validation: -0.017207323689062252]
	TIME [epoch: 40.5 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011965533906818471		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: -0.011965533906818471 | validation: -0.022581379354590203]
	TIME [epoch: 40.5 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008558420512980697		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: -0.008558420512980697 | validation: -0.013009974193799276]
	TIME [epoch: 40.5 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007589511021455537		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: -0.007589511021455537 | validation: -0.020593091590707078]
	TIME [epoch: 40.5 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005811156045515642		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: -0.005811156045515642 | validation: -0.02013752958555045]
	TIME [epoch: 40.5 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00943188011310938		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: -0.00943188011310938 | validation: -0.022401349839897534]
	TIME [epoch: 40.5 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009427934126710013		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: -0.009427934126710013 | validation: -0.015781309511471307]
	TIME [epoch: 40.5 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010522132034192392		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: -0.010522132034192392 | validation: -0.017196440778851955]
	TIME [epoch: 40.5 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007764167804470734		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: -0.007764167804470734 | validation: -0.01357237870273394]
	TIME [epoch: 40.5 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010908131348544126		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: -0.010908131348544126 | validation: -0.02350950654863683]
	TIME [epoch: 40.5 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005048298269652618		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: -0.005048298269652618 | validation: -0.022763972530932645]
	TIME [epoch: 40.5 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00677712607315402		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: -0.00677712607315402 | validation: -0.01627101950052165]
	TIME [epoch: 40.5 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010603456830696136		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: -0.010603456830696136 | validation: -0.017525493059700976]
	TIME [epoch: 40.5 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008385888500629575		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: -0.008385888500629575 | validation: -0.009040129439697476]
	TIME [epoch: 40.5 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010283511988582288		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: -0.010283511988582288 | validation: -0.008914359103779216]
	TIME [epoch: 40.4 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007036551888727358		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: -0.007036551888727358 | validation: -0.013294760907332538]
	TIME [epoch: 40.4 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008491276598248013		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: -0.008491276598248013 | validation: -0.01925946850362016]
	TIME [epoch: 40.5 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00824244060657691		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: -0.00824244060657691 | validation: -0.015087807692760875]
	TIME [epoch: 40.6 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010564909353399564		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: -0.010564909353399564 | validation: -0.019413220191237056]
	TIME [epoch: 40.5 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009097709549055186		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: -0.009097709549055186 | validation: -0.016188401275297942]
	TIME [epoch: 40.5 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01126631773843095		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: -0.01126631773843095 | validation: -0.01578463036047444]
	TIME [epoch: 40.5 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003930491584842774		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: -0.003930491584842774 | validation: -0.010077623699928052]
	TIME [epoch: 40.5 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010342517930927102		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: -0.010342517930927102 | validation: -0.012720368578468644]
	TIME [epoch: 40.5 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011888151089925497		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: -0.011888151089925497 | validation: -0.020820693483306285]
	TIME [epoch: 40.5 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01059294236128694		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: -0.01059294236128694 | validation: -0.013287916820043346]
	TIME [epoch: 40.6 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009496485413498314		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: -0.009496485413498314 | validation: -0.01528555022892275]
	TIME [epoch: 40.5 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007291829803230163		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: -0.007291829803230163 | validation: -0.009621290535008358]
	TIME [epoch: 40.5 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008011579317868878		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: -0.008011579317868878 | validation: -0.016526186390171636]
	TIME [epoch: 40.5 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012427994571733006		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: -0.012427994571733006 | validation: -0.019763942738503626]
	TIME [epoch: 40.5 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012416638410740028		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: -0.012416638410740028 | validation: -0.01699660623810861]
	TIME [epoch: 40.6 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013708841081132944		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: -0.013708841081132944 | validation: -0.011520480187985767]
	TIME [epoch: 40.6 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011935302756374305		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: -0.011935302756374305 | validation: -0.011410916482474151]
	TIME [epoch: 40.5 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006920405152880052		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: -0.006920405152880052 | validation: -0.01814720481147219]
	TIME [epoch: 40.6 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008289636501190654		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: -0.008289636501190654 | validation: -0.029511713235212372]
	TIME [epoch: 40.5 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009727808611086602		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: -0.009727808611086602 | validation: -0.015113728265240736]
	TIME [epoch: 40.5 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009956995071940786		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: -0.009956995071940786 | validation: -0.02643251662061976]
	TIME [epoch: 40.5 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004912743620826194		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: -0.004912743620826194 | validation: -0.009257712772199791]
	TIME [epoch: 40.6 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01328989699288851		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: -0.01328989699288851 | validation: -0.012355162589940741]
	TIME [epoch: 40.5 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00796992516340709		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: -0.00796992516340709 | validation: -0.015258539631315043]
	TIME [epoch: 40.7 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008432440848328872		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: -0.008432440848328872 | validation: -0.015355425752039072]
	TIME [epoch: 40.8 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00396601025506362		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: -0.00396601025506362 | validation: -0.012189883850247739]
	TIME [epoch: 40.8 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007240953514116655		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: -0.007240953514116655 | validation: -0.013577833076478888]
	TIME [epoch: 40.8 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006484885474996101		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: -0.006484885474996101 | validation: -0.013230773271280414]
	TIME [epoch: 40.7 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011041950214604041		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: -0.011041950214604041 | validation: -0.021080430254557157]
	TIME [epoch: 40.8 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011133310415496206		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: -0.011133310415496206 | validation: -0.012752109993685657]
	TIME [epoch: 40.7 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009765376574431908		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: -0.009765376574431908 | validation: -0.02184925693707967]
	TIME [epoch: 40.8 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009157474745920168		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: -0.009157474745920168 | validation: -0.015669304324352026]
	TIME [epoch: 40.8 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007926629305488367		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: -0.007926629305488367 | validation: -0.016210374597822392]
	TIME [epoch: 40.8 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006425594583184007		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: -0.006425594583184007 | validation: -0.006182209145990762]
	TIME [epoch: 40.7 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_kl_20241015_172819/states/model_algphi2_1a_v_kl_451.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 11982.592 seconds.
