Args:
Namespace(name='model_algphi1_1a_v_kl', outdir='out/model_training/model_algphi1_1a_v_kl', training_data='data/training_data/basic/data_phi1_1a/training', validation_data='data/training_data/basic/data_phi1_1a/validation', model_type='binary_choice', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1742246824

Training model...

Saving initial model state to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 10.620251393254778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.620251393254778 | validation: 10.638231164523333]
	TIME [epoch: 105 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 10.644143029634389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.644143029634389 | validation: 10.651206570072166]
	TIME [epoch: 4.23 sec]
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 10.615760906718354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.615760906718354 | validation: 10.611831192553701]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 10.6028345101299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.6028345101299 | validation: 10.631933868028016]
	TIME [epoch: 4.18 sec]
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 10.610412996454624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.610412996454624 | validation: 10.652070181759285]
	TIME [epoch: 4.18 sec]
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 10.625921047176664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.625921047176664 | validation: 10.64442797592408]
	TIME [epoch: 4.2 sec]
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 10.61652311490138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.61652311490138 | validation: 10.616721172702935]
	TIME [epoch: 4.2 sec]
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 10.590953426062175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.590953426062175 | validation: 10.616066979700982]
	TIME [epoch: 4.19 sec]
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 10.580809412129412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.580809412129412 | validation: 10.621440254979607]
	TIME [epoch: 4.17 sec]
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 10.592039494955042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.592039494955042 | validation: 10.580032133742588]
	TIME [epoch: 4.18 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 10.552386038859021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.552386038859021 | validation: 10.562003202263044]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 10.559563254770945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.559563254770945 | validation: 10.565968209248325]
	TIME [epoch: 4.22 sec]
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 10.554078243601076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.554078243601076 | validation: 10.555148563498346]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 10.544562963122607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.544562963122607 | validation: 10.5211403428518]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 10.50122901351588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.50122901351588 | validation: 10.476972724081882]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 10.481171357023081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.481171357023081 | validation: 10.47923827667484]
	TIME [epoch: 4.21 sec]
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 10.47553714279428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.47553714279428 | validation: 10.455281942231595]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 10.461567188214609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.461567188214609 | validation: 10.443920352941966]
	TIME [epoch: 4.21 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 10.458573535103326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.458573535103326 | validation: 10.473550690583021]
	TIME [epoch: 4.23 sec]
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 10.477166481879179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.477166481879179 | validation: 10.461592137949362]
	TIME [epoch: 4.23 sec]
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 10.45639070340719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.45639070340719 | validation: 10.439453715593888]
	TIME [epoch: 4.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 10.453436254258087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.453436254258087 | validation: 10.4575257202821]
	TIME [epoch: 4.26 sec]
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 10.460985236675013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.460985236675013 | validation: 10.409899631269434]
	TIME [epoch: 4.22 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 10.453548020504096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.453548020504096 | validation: 10.467218771891915]
	TIME [epoch: 4.23 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 10.472019935128488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.472019935128488 | validation: 10.43518339603428]
	TIME [epoch: 4.23 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 10.459002254417086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.459002254417086 | validation: 10.439504700153082]
	TIME [epoch: 4.24 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 10.455201638554946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.455201638554946 | validation: 10.451514651691227]
	TIME [epoch: 4.23 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 10.449974896336341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.449974896336341 | validation: 10.433494314924268]
	TIME [epoch: 4.22 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 10.432329516131873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.432329516131873 | validation: 10.399462845378949]
	TIME [epoch: 4.24 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 10.417924519463547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.417924519463547 | validation: 10.398672393498618]
	TIME [epoch: 4.25 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 10.422086103409816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.422086103409816 | validation: 10.45057180438003]
	TIME [epoch: 4.19 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 10.428334853787774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.428334853787774 | validation: 10.435635561231338]
	TIME [epoch: 4.19 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 10.467125747212005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.467125747212005 | validation: 10.476978555412089]
	TIME [epoch: 4.16 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 10.45713731163022		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.45713731163022 | validation: 10.485835128222483]
	TIME [epoch: 4.17 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 10.482559470257247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.482559470257247 | validation: 10.519148897960644]
	TIME [epoch: 4.16 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 10.470424943969823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.470424943969823 | validation: 10.480124043137263]
	TIME [epoch: 4.17 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 10.443490859570739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.443490859570739 | validation: 10.472527149713619]
	TIME [epoch: 4.16 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 10.460225840909512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.460225840909512 | validation: 10.47885225095363]
	TIME [epoch: 4.17 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 10.465359404423296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.465359404423296 | validation: 10.440799363139698]
	TIME [epoch: 4.2 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 10.434258350134922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.434258350134922 | validation: 10.4369229034894]
	TIME [epoch: 4.16 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 10.434369641981665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.434369641981665 | validation: 10.43544048410303]
	TIME [epoch: 4.19 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 10.445990456106047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.445990456106047 | validation: 10.415031405966777]
	TIME [epoch: 4.17 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 10.43700927420316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.43700927420316 | validation: 10.43178947442353]
	TIME [epoch: 4.17 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 10.437640786961275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.437640786961275 | validation: 10.471847890645119]
	TIME [epoch: 4.16 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 10.444860425938725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.444860425938725 | validation: 10.456206321083526]
	TIME [epoch: 4.17 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 10.43081320001882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.43081320001882 | validation: 10.487092214250215]
	TIME [epoch: 4.16 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 10.444367331758839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.444367331758839 | validation: 10.459692242276414]
	TIME [epoch: 4.17 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 10.42027296029631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.42027296029631 | validation: 10.433574955156924]
	TIME [epoch: 4.2 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 10.429277304351396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.429277304351396 | validation: 10.434344165276364]
	TIME [epoch: 4.17 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 10.446415755742494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.446415755742494 | validation: 10.409868634501183]
	TIME [epoch: 4.16 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 7.2667495834646		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 7.2667495834646 | validation: 7.267158327313906]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 7.211567507127776		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 7.211567507127776 | validation: 7.258099017152714]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 7.205510155472308		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 7.205510155472308 | validation: 7.182278637770015]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 7.1478637892157595		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 7.1478637892157595 | validation: 7.156499936897801]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 7.19643584840223		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 7.19643584840223 | validation: 7.28446590323809]
	TIME [epoch: 8.23 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 7.278287621164589		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 7.278287621164589 | validation: 7.2552536752316525]
	TIME [epoch: 8.21 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 7.2375033349308735		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 7.2375033349308735 | validation: 7.242928175838643]
	TIME [epoch: 8.22 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 7.209943564137047		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 7.209943564137047 | validation: 7.167647546185279]
	TIME [epoch: 8.22 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 7.114825558172595		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 7.114825558172595 | validation: 7.142327065165436]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 7.108119067296052		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 7.108119067296052 | validation: 7.083720396182729]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 7.089290705119984		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 7.089290705119984 | validation: 6.966687388209582]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 6.930464603019268		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 6.930464603019268 | validation: 6.856770542029116]
	TIME [epoch: 8.22 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 6.823301373464163		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 6.823301373464163 | validation: 6.732220178622828]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 6.768302644073965		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 6.768302644073965 | validation: 6.679471090629603]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 6.762531898443123		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 6.762531898443123 | validation: 6.638696431486962]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 6.702198056074081		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 6.702198056074081 | validation: 6.58835081966337]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 6.682335808035015		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 6.682335808035015 | validation: 6.627445707725814]
	TIME [epoch: 8.34 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 6.675860827904781		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 6.675860827904781 | validation: 6.671743479825389]
	TIME [epoch: 8.27 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 6.62935809769591		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 6.62935809769591 | validation: 6.616431686227161]
	TIME [epoch: 8.27 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 6.610898461494563		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 6.610898461494563 | validation: 6.608636997812442]
	TIME [epoch: 8.27 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 6.553832465260832		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 6.553832465260832 | validation: 6.560458021138988]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 6.512746195642086		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 6.512746195642086 | validation: 6.481001667413766]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 6.425351722151403		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 6.425351722151403 | validation: 6.394810299983582]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 6.382920004832831		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 6.382920004832831 | validation: 6.343980468774767]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 6.323421468758713		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 6.323421468758713 | validation: 6.298584233047681]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 6.204675345890356		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 6.204675345890356 | validation: 6.105193885751172]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 6.077039514285152		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 6.077039514285152 | validation: 5.977226302921084]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 5.840397003367106		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 5.840397003367106 | validation: 5.677408829657059]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 5.533996525049844		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 5.533996525049844 | validation: 5.310038661829198]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 5.213300880591094		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 5.213300880591094 | validation: 5.082086711812709]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 4.913949294701142		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 4.913949294701142 | validation: 4.72135603189592]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_81.pth
	Model improved!!!
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 4.600621108380377		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 4.600621108380377 | validation: 4.466883320332322]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 4.252968342699614		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 4.252968342699614 | validation: 3.8775954893210423]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 3.781308283257644		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 3.781308283257644 | validation: 3.248243188677615]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_84.pth
	Model improved!!!
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 3.282616935154101		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 3.282616935154101 | validation: 2.715275916417067]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7321433997438587		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 2.7321433997438587 | validation: 2.1993407174658017]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 2.2340601073103237		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 2.2340601073103237 | validation: 1.8139821597033692]
	TIME [epoch: 8.19 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_87.pth
	Model improved!!!
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7962664109701703		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 1.7962664109701703 | validation: 1.5037889808548395]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4669141928304334		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 1.4669141928304334 | validation: 1.3127052810214663]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 1.2263743533536902		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 1.2263743533536902 | validation: 1.0820600121362385]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 1.018393072088513		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 1.018393072088513 | validation: 0.9132509965472708]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8398721862085993		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.8398721862085993 | validation: 0.7158656552465221]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6618846114317555		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.6618846114317555 | validation: 0.5611949370282674]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.513999562663992		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.513999562663992 | validation: 0.4203266766894017]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_94.pth
	Model improved!!!
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.38119491543985806		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.38119491543985806 | validation: 0.3205112305774862]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2833943432196401		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.2833943432196401 | validation: 0.263568882076085]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24117167969218517		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.24117167969218517 | validation: 0.23265472247874178]
	TIME [epoch: 8.16 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_97.pth
	Model improved!!!
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21234258223099145		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.21234258223099145 | validation: 0.1859720702000138]
	TIME [epoch: 8.14 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18400128632777452		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.18400128632777452 | validation: 0.17606305463527921]
	TIME [epoch: 8.24 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16545751827267974		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.16545751827267974 | validation: 0.1571554179249614]
	TIME [epoch: 8.23 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15008896475005307		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.15008896475005307 | validation: 0.12966970470866956]
	TIME [epoch: 121 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1232478240853528		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.1232478240853528 | validation: 0.10495146183559008]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0835664933499709		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.0835664933499709 | validation: 0.07875770452998718]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06520715541696012		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.06520715541696012 | validation: 0.05453296754892233]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04175040706249828		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.04175040706249828 | validation: 0.03582692939044726]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030189963942773686		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.030189963942773686 | validation: 0.031149422603341772]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_106.pth
	Model improved!!!
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017935273864586123		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.017935273864586123 | validation: 0.014050174406427831]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009219826230161755		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.009219826230161755 | validation: 0.01416345986570619]
	TIME [epoch: 18.9 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010204340036594092		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.010204340036594092 | validation: 0.008556594505537708]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0007284257484944832		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.0007284257484944832 | validation: 0.006005436350246099]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004070903724790556		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: -0.004070903724790556 | validation: -0.004654976359798271]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0048982376819502625		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.0048982376819502625 | validation: 0.01991789898041757]
	TIME [epoch: 18.6 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012292395768079424		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.012292395768079424 | validation: 0.01276538916964438]
	TIME [epoch: 18.7 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004333337878673794		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.004333337878673794 | validation: 0.011807127910091315]
	TIME [epoch: 18.6 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011966525160555014		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.011966525160555014 | validation: 0.007869527768880925]
	TIME [epoch: 18.7 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009361662841146031		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.009361662841146031 | validation: -0.0047286523597342344]
	TIME [epoch: 18.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_116.pth
	Model improved!!!
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0001859922169342588		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.0001859922169342588 | validation: 0.005512626371368206]
	TIME [epoch: 18.6 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008038159221177343		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: -0.008038159221177343 | validation: -0.013246294969241765]
	TIME [epoch: 18.5 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_118.pth
	Model improved!!!
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007286190388758634		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: -0.007286190388758634 | validation: 0.014323441289921609]
	TIME [epoch: 18.8 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0020717800379025457		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.0020717800379025457 | validation: -0.01023974628874067]
	TIME [epoch: 18.8 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007146405239012394		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: -0.007146405239012394 | validation: 0.007378864177148436]
	TIME [epoch: 18.8 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002057573551803297		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: -0.002057573551803297 | validation: 0.0023607995056812935]
	TIME [epoch: 18.8 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002514448754722539		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: -0.002514448754722539 | validation: -0.010682411144976409]
	TIME [epoch: 18.7 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007913729591043174		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: -0.007913729591043174 | validation: -0.00029963375488009387]
	TIME [epoch: 18.8 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007467915414740973		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: -0.007467915414740973 | validation: -0.00793015380398819]
	TIME [epoch: 18.7 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009246399910469948		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: -0.009246399910469948 | validation: -0.01564192820460106]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_126.pth
	Model improved!!!
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008577927258769347		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.008577927258769347 | validation: -0.005238324564598473]
	TIME [epoch: 18.8 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008546026915205401		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.008546026915205401 | validation: -0.006242694839355124]
	TIME [epoch: 18.9 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008290336503094301		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.008290336503094301 | validation: -0.015391323341539857]
	TIME [epoch: 18.8 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007246230198771009		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: -0.007246230198771009 | validation: -0.012096458512326803]
	TIME [epoch: 18.9 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00821007854002154		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.00821007854002154 | validation: -0.011578792196148874]
	TIME [epoch: 18.8 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008316826794500107		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.008316826794500107 | validation: -0.004172451119615564]
	TIME [epoch: 18.8 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004859034448605687		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.004859034448605687 | validation: -0.0010072176832036039]
	TIME [epoch: 18.8 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005190162518510344		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.005190162518510344 | validation: 0.0002755249354618396]
	TIME [epoch: 18.9 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008010160224259983		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: -0.008010160224259983 | validation: -0.004234052960948655]
	TIME [epoch: 18.8 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007986688173602027		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: -0.007986688173602027 | validation: -0.008394732192362355]
	TIME [epoch: 18.8 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009482441039411482		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.009482441039411482 | validation: -0.004334688100382164]
	TIME [epoch: 18.9 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011354394804085724		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: -0.011354394804085724 | validation: -0.001749453325984902]
	TIME [epoch: 18.8 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0038517068559753		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: -0.0038517068559753 | validation: -0.011958674121143303]
	TIME [epoch: 18.8 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011067560322934492		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: -0.011067560322934492 | validation: -0.008737149836607786]
	TIME [epoch: 18.7 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01050021115736896		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: -0.01050021115736896 | validation: -0.010553705618163284]
	TIME [epoch: 18.9 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010296807933702107		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: -0.010296807933702107 | validation: -0.014430259752037398]
	TIME [epoch: 18.8 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010353580531308967		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.010353580531308967 | validation: 0.009549683982300602]
	TIME [epoch: 18.8 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0029716053267678953		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.0029716053267678953 | validation: 0.004038015269793508]
	TIME [epoch: 18.7 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0023021960610736135		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.0023021960610736135 | validation: 0.008614958221913613]
	TIME [epoch: 18.8 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002957710445351168		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.002957710445351168 | validation: 0.0018286292726182067]
	TIME [epoch: 18.7 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026168668307106086		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.0026168668307106086 | validation: -0.005751326034219155]
	TIME [epoch: 18.8 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007563854646954011		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.007563854646954011 | validation: -0.005351328162900023]
	TIME [epoch: 18.7 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010235956529347636		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.010235956529347636 | validation: -0.01205718525611323]
	TIME [epoch: 18.8 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010141387508415587		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.010141387508415587 | validation: -0.011513736904952263]
	TIME [epoch: 18.8 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009992294078709303		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.009992294078709303 | validation: -0.006970733162897384]
	TIME [epoch: 18.7 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00030306699965750624		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: -0.00030306699965750624 | validation: -0.007376110837141682]
	TIME [epoch: 18.8 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004007717942218784		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.004007717942218784 | validation: -0.0030143122018620747]
	TIME [epoch: 18.7 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001975999794096581		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.001975999794096581 | validation: -0.0019686129235106558]
	TIME [epoch: 18.8 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006409895871948663		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.006409895871948663 | validation: -0.014347437268351549]
	TIME [epoch: 18.8 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005885151912541147		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.005885151912541147 | validation: -0.01121907229433514]
	TIME [epoch: 18.8 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00698947080974901		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.00698947080974901 | validation: -0.009259126101737982]
	TIME [epoch: 18.7 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0062279620613388854		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.0062279620613388854 | validation: -0.010442584137662046]
	TIME [epoch: 18.8 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010650021865089924		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.010650021865089924 | validation: -0.01036177703585644]
	TIME [epoch: 18.8 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010744835533222292		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.010744835533222292 | validation: -0.0028076138783911203]
	TIME [epoch: 18.8 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007276925875269338		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.007276925875269338 | validation: -0.006838137333754437]
	TIME [epoch: 18.7 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009869832838903272		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.009869832838903272 | validation: 0.0008832023830958186]
	TIME [epoch: 18.8 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011051670429475873		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.011051670429475873 | validation: -0.004924620138105657]
	TIME [epoch: 18.8 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005485401901021406		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.005485401901021406 | validation: -0.010164271220304999]
	TIME [epoch: 18.8 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010761739420539939		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.010761739420539939 | validation: -0.006076822435199731]
	TIME [epoch: 18.9 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008539862604467794		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.008539862604467794 | validation: -0.017750743506332885]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_166.pth
	Model improved!!!
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008482457925235661		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.008482457925235661 | validation: -0.014210012352049682]
	TIME [epoch: 18.9 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007881773864473387		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.007881773864473387 | validation: -0.00799657498054979]
	TIME [epoch: 18.8 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007827130051175859		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.007827130051175859 | validation: -0.01283944122872003]
	TIME [epoch: 18.9 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005627888861084283		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.005627888861084283 | validation: -0.012055141531319952]
	TIME [epoch: 18.8 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011955758197932593		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.011955758197932593 | validation: -0.010077955317855464]
	TIME [epoch: 18.9 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00784410718263474		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.00784410718263474 | validation: -0.01458374239985928]
	TIME [epoch: 18.8 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0056719524533826796		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.0056719524533826796 | validation: -0.009546531121484554]
	TIME [epoch: 18.9 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007289157398211863		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.007289157398211863 | validation: -0.014034251004287481]
	TIME [epoch: 18.8 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00927902495221849		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.00927902495221849 | validation: -0.007995467643468463]
	TIME [epoch: 18.9 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010235401099531551		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.010235401099531551 | validation: -0.002001691499858978]
	TIME [epoch: 18.8 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006537509333595288		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.006537509333595288 | validation: -0.00925286419929433]
	TIME [epoch: 18.9 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007307135966104279		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.007307135966104279 | validation: -0.008369126408700408]
	TIME [epoch: 18.8 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011097213258039522		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.011097213258039522 | validation: -0.010849320219746283]
	TIME [epoch: 18.8 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011498229489072986		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.011498229489072986 | validation: -0.008736243066571505]
	TIME [epoch: 18.8 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009636302500216219		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.009636302500216219 | validation: -0.0075819819274779]
	TIME [epoch: 18.8 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012383843248401808		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.012383843248401808 | validation: -0.0023807112881497573]
	TIME [epoch: 18.8 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012844189686892018		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.012844189686892018 | validation: -0.009206664830377125]
	TIME [epoch: 18.8 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008095995097301276		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.008095995097301276 | validation: 0.0025739959388820614]
	TIME [epoch: 18.8 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007190665285562116		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.007190665285562116 | validation: -0.01791967046846215]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_185.pth
	Model improved!!!
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011029563566548942		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.011029563566548942 | validation: -0.006714343098340712]
	TIME [epoch: 19 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008535336394503056		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.008535336394503056 | validation: -0.013266204930963692]
	TIME [epoch: 18.9 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013392180144076362		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.013392180144076362 | validation: -0.011352564033578712]
	TIME [epoch: 19 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008441147237633298		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.008441147237633298 | validation: 0.003422764578564533]
	TIME [epoch: 18.9 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004626585712946146		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.004626585712946146 | validation: -0.014282649412684662]
	TIME [epoch: 18.9 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008725251179954766		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.008725251179954766 | validation: -0.015932277250857364]
	TIME [epoch: 18.9 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010752375847615682		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.010752375847615682 | validation: -0.01134312330852089]
	TIME [epoch: 18.9 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01192284774853732		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.01192284774853732 | validation: -0.002887624053300235]
	TIME [epoch: 18.8 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010489788987919099		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.010489788987919099 | validation: -0.0099295484112442]
	TIME [epoch: 18.8 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01267455655651308		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.01267455655651308 | validation: -0.01564173352451449]
	TIME [epoch: 18.8 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011584162376563196		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.011584162376563196 | validation: -0.007495724722932355]
	TIME [epoch: 18.8 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009825288654792088		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.009825288654792088 | validation: -0.015204176901234684]
	TIME [epoch: 18.8 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01267441737634788		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.01267441737634788 | validation: -0.0027289020970665987]
	TIME [epoch: 18.8 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010778000634641651		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.010778000634641651 | validation: -0.00018411087031969774]
	TIME [epoch: 18.8 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00622837510013463		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.00622837510013463 | validation: -0.01820870800124025]
	TIME [epoch: 18.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_200.pth
	Model improved!!!
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010015825479274092		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.010015825479274092 | validation: -0.009124362230746343]
	TIME [epoch: 18.9 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0093544441659321		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.0093544441659321 | validation: -0.012750546791796801]
	TIME [epoch: 18.9 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010724493487054381		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.010724493487054381 | validation: -0.009176596413858356]
	TIME [epoch: 18.9 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011069766133912484		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.011069766133912484 | validation: -0.015485300220615637]
	TIME [epoch: 18.8 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012492702936606077		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.012492702936606077 | validation: -0.0007175929176668336]
	TIME [epoch: 18.9 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009301097278572423		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.009301097278572423 | validation: -0.012308879526167408]
	TIME [epoch: 18.8 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008683619887601688		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.008683619887601688 | validation: -0.008902475167784533]
	TIME [epoch: 18.9 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01157421042102524		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.01157421042102524 | validation: 7.274711890158797e-05]
	TIME [epoch: 18.8 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0038297062466434877		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.0038297062466434877 | validation: -0.015991516638343355]
	TIME [epoch: 18.8 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010549154893160387		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.010549154893160387 | validation: -0.01164370683110022]
	TIME [epoch: 18.9 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011713091628262246		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.011713091628262246 | validation: -0.010900894337194144]
	TIME [epoch: 18.8 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008618514166308868		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.008618514166308868 | validation: -0.017489524286762963]
	TIME [epoch: 18.9 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009318101506900201		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.009318101506900201 | validation: -0.015796533279047363]
	TIME [epoch: 18.9 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009620245287597638		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.009620245287597638 | validation: -0.010839345956463565]
	TIME [epoch: 18.9 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010410551873173093		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.010410551873173093 | validation: -0.00914787645117953]
	TIME [epoch: 18.9 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013024736146144552		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.013024736146144552 | validation: -0.006992490543070658]
	TIME [epoch: 18.9 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008666022752913722		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.008666022752913722 | validation: -0.00789586669242193]
	TIME [epoch: 18.9 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014552802089372695		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.014552802089372695 | validation: -0.0013584166822365549]
	TIME [epoch: 18.9 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010297541606243896		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.010297541606243896 | validation: -0.008090959111833159]
	TIME [epoch: 18.9 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005903509323731832		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.005903509323731832 | validation: -0.007657446559228776]
	TIME [epoch: 19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010379045992062616		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.010379045992062616 | validation: -0.004021938292641832]
	TIME [epoch: 18.8 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010525809358330822		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.010525809358330822 | validation: -0.006208420436924113]
	TIME [epoch: 18.9 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01295925140552626		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.01295925140552626 | validation: -0.006709596699526331]
	TIME [epoch: 18.9 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0105090744960247		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.0105090744960247 | validation: -0.006461685930969539]
	TIME [epoch: 18.9 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01189668103456384		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.01189668103456384 | validation: -0.01041389854851573]
	TIME [epoch: 18.9 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013739788371038697		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.013739788371038697 | validation: -0.011650172471363057]
	TIME [epoch: 18.9 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007980953844445337		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.007980953844445337 | validation: -0.005143897528803978]
	TIME [epoch: 18.9 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010111173095365735		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.010111173095365735 | validation: -0.011269216041339748]
	TIME [epoch: 18.8 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012965600200390639		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.012965600200390639 | validation: -0.006217482974242207]
	TIME [epoch: 18.9 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008478158312719834		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.008478158312719834 | validation: -0.009319985826426692]
	TIME [epoch: 18.8 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00966968528057217		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.00966968528057217 | validation: -0.01384288216988144]
	TIME [epoch: 18.9 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008708083104988645		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.008708083104988645 | validation: -0.017435093278976518]
	TIME [epoch: 18.8 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009151803794375198		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.009151803794375198 | validation: -0.005343906596754062]
	TIME [epoch: 18.9 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012548068373378348		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.012548068373378348 | validation: -0.011403921257048047]
	TIME [epoch: 18.8 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010324659090430758		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.010324659090430758 | validation: -0.00938405334509005]
	TIME [epoch: 18.9 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00906392703638913		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.00906392703638913 | validation: 0.0035583432063245562]
	TIME [epoch: 18.9 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008499250552398974		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.008499250552398974 | validation: -0.0010679693919955205]
	TIME [epoch: 18.9 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01069398800634937		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.01069398800634937 | validation: -0.008533117330771682]
	TIME [epoch: 18.8 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024647055194482385		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.0024647055194482385 | validation: 0.0011055702970015737]
	TIME [epoch: 18.9 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005924145857472222		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.005924145857472222 | validation: -0.007986382781742631]
	TIME [epoch: 18.8 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014045199912271248		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.014045199912271248 | validation: -0.010508377533610964]
	TIME [epoch: 18.8 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008786228239792384		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.008786228239792384 | validation: -0.015292846650804427]
	TIME [epoch: 18.9 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01055638059880828		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.01055638059880828 | validation: -0.015675735828171198]
	TIME [epoch: 18.8 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012093840991698142		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.012093840991698142 | validation: -0.006462763857411494]
	TIME [epoch: 18.9 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007072180724127308		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.007072180724127308 | validation: 0.0018818998546881608]
	TIME [epoch: 18.8 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01260060158932251		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.01260060158932251 | validation: -0.0068971439332018315]
	TIME [epoch: 18.9 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013432589368497566		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.013432589368497566 | validation: -0.01078329194687609]
	TIME [epoch: 18.8 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013030537867537634		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.013030537867537634 | validation: -0.008477538471854708]
	TIME [epoch: 18.8 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010028636417842702		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.010028636417842702 | validation: -0.015345355506224463]
	TIME [epoch: 18.8 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007691696050548588		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.007691696050548588 | validation: -0.011725639030339033]
	TIME [epoch: 18.9 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012155688686667837		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.012155688686667837 | validation: 0.0023162497533506686]
	TIME [epoch: 144 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008829137776593242		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.008829137776593242 | validation: -0.012814891787348064]
	TIME [epoch: 41.5 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01242610352374401		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.01242610352374401 | validation: -0.007925283412063264]
	TIME [epoch: 41.2 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012615140414770644		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.012615140414770644 | validation: -0.010277399332245878]
	TIME [epoch: 41.2 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010947448062101703		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.010947448062101703 | validation: 0.004800622219231407]
	TIME [epoch: 41 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010219923884603327		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.010219923884603327 | validation: -0.006317907004687773]
	TIME [epoch: 41 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009678567357844961		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.009678567357844961 | validation: -0.01273416115160628]
	TIME [epoch: 41 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0056521989960079426		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.0056521989960079426 | validation: -0.004374786852066722]
	TIME [epoch: 41 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011937545844494258		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.011937545844494258 | validation: -0.009178220250987579]
	TIME [epoch: 41 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006735855492643747		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.006735855492643747 | validation: -0.008198872823611286]
	TIME [epoch: 40.9 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011360755840735709		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.011360755840735709 | validation: -0.011938617462170236]
	TIME [epoch: 40.9 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012153596681325068		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.012153596681325068 | validation: -0.015141223648418484]
	TIME [epoch: 40.9 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008691570138036016		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.008691570138036016 | validation: -0.007132942061428913]
	TIME [epoch: 41 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010003531447973056		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.010003531447973056 | validation: -0.009661411767458147]
	TIME [epoch: 41 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01441587540570206		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.01441587540570206 | validation: -0.014204912072687651]
	TIME [epoch: 41 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01187080508548331		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.01187080508548331 | validation: -0.011652375390472054]
	TIME [epoch: 41 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015346867355887436		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.015346867355887436 | validation: -0.0032577228728874075]
	TIME [epoch: 41.1 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009218243510218379		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.009218243510218379 | validation: -0.020817780308411395]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_268.pth
	Model improved!!!
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011438916081572298		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.011438916081572298 | validation: -0.011443255774649625]
	TIME [epoch: 40.9 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009500327482182006		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.009500327482182006 | validation: -0.008390602693467445]
	TIME [epoch: 40.8 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01405518983135167		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.01405518983135167 | validation: -0.009411563632473153]
	TIME [epoch: 40.8 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013710448988313993		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.013710448988313993 | validation: -0.012615468097006095]
	TIME [epoch: 40.8 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013883829476777155		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.013883829476777155 | validation: -0.01118230904165645]
	TIME [epoch: 40.8 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008850824041263259		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.008850824041263259 | validation: -0.00996174206819845]
	TIME [epoch: 40.8 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008342464804241122		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.008342464804241122 | validation: -0.012877858996225266]
	TIME [epoch: 40.8 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009316345760661742		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.009316345760661742 | validation: -0.010939260230460983]
	TIME [epoch: 40.8 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011569408464285811		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.011569408464285811 | validation: -0.013842907116691845]
	TIME [epoch: 40.8 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011957118500441647		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.011957118500441647 | validation: -0.015335616166442259]
	TIME [epoch: 40.8 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012121722217468963		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.012121722217468963 | validation: -0.01515503524327308]
	TIME [epoch: 40.8 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013233117543052435		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.013233117543052435 | validation: -0.012470344124472855]
	TIME [epoch: 40.8 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011117516423682673		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.011117516423682673 | validation: -0.012422078271249217]
	TIME [epoch: 40.8 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011470574493395471		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.011470574493395471 | validation: -0.013105985833693707]
	TIME [epoch: 40.9 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011136569072746594		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.011136569072746594 | validation: -0.005913506403597391]
	TIME [epoch: 40.8 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013844679717707638		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.013844679717707638 | validation: -0.012551277044058503]
	TIME [epoch: 40.8 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011096034850071861		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.011096034850071861 | validation: -0.01023723779524442]
	TIME [epoch: 40.8 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011459896777762593		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.011459896777762593 | validation: -0.01522647222425485]
	TIME [epoch: 40.8 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009610177414907101		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.009610177414907101 | validation: -0.011521506969874081]
	TIME [epoch: 40.8 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01544547845248585		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.01544547845248585 | validation: -0.012413547129301792]
	TIME [epoch: 40.9 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008929807320586963		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.008929807320586963 | validation: -0.00716545611544942]
	TIME [epoch: 40.8 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01259196882830999		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.01259196882830999 | validation: -0.022760756759965344]
	TIME [epoch: 40.8 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_290.pth
	Model improved!!!
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014274387700744344		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.014274387700744344 | validation: -0.019780395454634652]
	TIME [epoch: 41.3 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01171424211410395		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.01171424211410395 | validation: -0.004421588796847121]
	TIME [epoch: 41.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007994894711329968		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.007994894711329968 | validation: -0.014699547255684559]
	TIME [epoch: 41.3 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011663239506842187		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.011663239506842187 | validation: -0.008745254436522003]
	TIME [epoch: 41.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012965179298119701		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.012965179298119701 | validation: -0.0098553886334155]
	TIME [epoch: 41.5 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012324734609784846		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: -0.012324734609784846 | validation: -0.011171346553320435]
	TIME [epoch: 41.4 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012025631516296756		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: -0.012025631516296756 | validation: -0.01404323101424746]
	TIME [epoch: 41.4 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011115507735950934		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: -0.011115507735950934 | validation: -0.0006475308223058353]
	TIME [epoch: 41.3 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01475581314666011		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: -0.01475581314666011 | validation: -0.010707991100538994]
	TIME [epoch: 41.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013296837409992279		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: -0.013296837409992279 | validation: -0.015694391464572965]
	TIME [epoch: 41.4 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012141401588052374		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: -0.012141401588052374 | validation: -0.0035974818340508466]
	TIME [epoch: 41.7 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01235518772349141		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: -0.01235518772349141 | validation: -0.013797687966572637]
	TIME [epoch: 41.6 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010195621164326225		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: -0.010195621164326225 | validation: -0.008586900409015028]
	TIME [epoch: 41.6 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012322588548660947		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: -0.012322588548660947 | validation: -0.014719085980546429]
	TIME [epoch: 41.5 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013125870236008573		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: -0.013125870236008573 | validation: -0.006796336174079752]
	TIME [epoch: 41.6 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013945398741717966		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: -0.013945398741717966 | validation: -0.009049968960033659]
	TIME [epoch: 41.6 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00931831106041482		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: -0.00931831106041482 | validation: -0.015867529480488814]
	TIME [epoch: 41.6 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011076831759978412		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: -0.011076831759978412 | validation: -3.1026106529705166e-05]
	TIME [epoch: 41.6 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012917766316480079		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: -0.012917766316480079 | validation: -0.010157988831451213]
	TIME [epoch: 41.5 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012565976018199677		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: -0.012565976018199677 | validation: -0.016819187726335283]
	TIME [epoch: 41.6 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014672832506588043		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: -0.014672832506588043 | validation: -0.0037946323590880003]
	TIME [epoch: 41.5 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01622191100782591		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: -0.01622191100782591 | validation: -0.020299111589657307]
	TIME [epoch: 41.6 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01489640868019047		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: -0.01489640868019047 | validation: -0.008472853319017011]
	TIME [epoch: 41.4 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009712507029457028		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: -0.009712507029457028 | validation: -0.013868002413461937]
	TIME [epoch: 41.5 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011618947121985634		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: -0.011618947121985634 | validation: -0.0019128627893492463]
	TIME [epoch: 41.5 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011663283657764398		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: -0.011663283657764398 | validation: -0.017066209453429352]
	TIME [epoch: 41.5 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013195662810577213		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: -0.013195662810577213 | validation: -0.005325888282847057]
	TIME [epoch: 41.6 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014735203786983581		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: -0.014735203786983581 | validation: -0.010964492939785884]
	TIME [epoch: 41.5 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012822274753213556		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: -0.012822274753213556 | validation: -0.016220616928538184]
	TIME [epoch: 41.5 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01514943707251172		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: -0.01514943707251172 | validation: -0.013122923327561303]
	TIME [epoch: 41.5 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015240221040083428		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: -0.015240221040083428 | validation: -0.018488553202195175]
	TIME [epoch: 41.5 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01539310318569995		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: -0.01539310318569995 | validation: -0.021722040818601473]
	TIME [epoch: 41.5 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011937955140948094		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: -0.011937955140948094 | validation: -0.013886913058019288]
	TIME [epoch: 41.5 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011133034680210638		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: -0.011133034680210638 | validation: -0.003773674422503607]
	TIME [epoch: 41.6 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013053699778573867		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: -0.013053699778573867 | validation: -0.01844391419380802]
	TIME [epoch: 41.5 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014309111008981688		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: -0.014309111008981688 | validation: -0.011205918338441147]
	TIME [epoch: 41.5 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01589528255978214		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: -0.01589528255978214 | validation: -0.01773511215024657]
	TIME [epoch: 41.6 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01164057255628591		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: -0.01164057255628591 | validation: -0.011647884680773057]
	TIME [epoch: 41.5 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010372734012231547		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: -0.010372734012231547 | validation: -0.006762334828463671]
	TIME [epoch: 41.6 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013342563557544717		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: -0.013342563557544717 | validation: -0.011196778447741269]
	TIME [epoch: 41.6 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01226848608492267		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: -0.01226848608492267 | validation: -0.011562870744382024]
	TIME [epoch: 41.7 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015678598015579578		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: -0.015678598015579578 | validation: -0.01484852599066473]
	TIME [epoch: 41.7 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013308910539571141		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: -0.013308910539571141 | validation: -0.005523597936258883]
	TIME [epoch: 41.7 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011590709153358011		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: -0.011590709153358011 | validation: -0.008992139964912592]
	TIME [epoch: 41.5 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013365618928012071		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: -0.013365618928012071 | validation: -0.010896285704846648]
	TIME [epoch: 41.6 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01222081907184778		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: -0.01222081907184778 | validation: -0.004072795913655941]
	TIME [epoch: 41.5 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: -0.016686357722643364		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: -0.016686357722643364 | validation: 0.003549835941652855]
	TIME [epoch: 41.7 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01323477012962678		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: -0.01323477012962678 | validation: -0.021322862108851707]
	TIME [epoch: 41.7 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013398234966631822		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: -0.013398234966631822 | validation: -0.01007498800594055]
	TIME [epoch: 41.7 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011335161915172132		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: -0.011335161915172132 | validation: -0.008792811395698551]
	TIME [epoch: 41.5 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00911684832639722		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: -0.00911684832639722 | validation: -0.00990273052954728]
	TIME [epoch: 41.7 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012225221460243341		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: -0.012225221460243341 | validation: -0.018849352890210586]
	TIME [epoch: 41.7 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007616383816929215		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: -0.007616383816929215 | validation: -0.012211945602091653]
	TIME [epoch: 41.5 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013428436931210744		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: -0.013428436931210744 | validation: -0.005169167315675653]
	TIME [epoch: 41.7 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013004030051950607		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: -0.013004030051950607 | validation: -0.01048201938369909]
	TIME [epoch: 41.7 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013353082309207003		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: -0.013353082309207003 | validation: -0.006427880973316168]
	TIME [epoch: 41.7 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012312241901517558		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: -0.012312241901517558 | validation: -0.012243358619623824]
	TIME [epoch: 41.7 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011475197543005841		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: -0.011475197543005841 | validation: -0.013253908438165261]
	TIME [epoch: 41.7 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014403306122559356		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: -0.014403306122559356 | validation: -0.008857925572548248]
	TIME [epoch: 41.7 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011421620958227966		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: -0.011421620958227966 | validation: -0.02033056686169896]
	TIME [epoch: 41.6 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013048124937026385		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: -0.013048124937026385 | validation: -0.012605037899409331]
	TIME [epoch: 41.7 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013202764321033442		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: -0.013202764321033442 | validation: -0.009227589484683645]
	TIME [epoch: 41.7 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015313333379338488		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: -0.015313333379338488 | validation: -0.017330121293511754]
	TIME [epoch: 41.8 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01192979183321823		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: -0.01192979183321823 | validation: -0.013191933927653124]
	TIME [epoch: 41.7 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01480458510392435		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: -0.01480458510392435 | validation: -0.017657934247104316]
	TIME [epoch: 41.6 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011372275562551246		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: -0.011372275562551246 | validation: -0.017968914995333454]
	TIME [epoch: 41.6 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010809979803248238		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: -0.010809979803248238 | validation: -0.00952090628374621]
	TIME [epoch: 41.7 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00976076073983548		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: -0.00976076073983548 | validation: -0.008954334052255646]
	TIME [epoch: 41.8 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008456168968155531		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: -0.008456168968155531 | validation: -0.0070138263081753836]
	TIME [epoch: 41.6 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01037954848215438		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: -0.01037954848215438 | validation: -0.010580268145951012]
	TIME [epoch: 41.6 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011961823939616752		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: -0.011961823939616752 | validation: -0.014677106208982065]
	TIME [epoch: 41.7 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011791768310861601		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: -0.011791768310861601 | validation: -0.005869142090596733]
	TIME [epoch: 41.7 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011989871427794193		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: -0.011989871427794193 | validation: -0.005147220404249142]
	TIME [epoch: 41.6 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01428293290346431		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: -0.01428293290346431 | validation: -0.011960430490802657]
	TIME [epoch: 41.8 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014969747101777578		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: -0.014969747101777578 | validation: -0.012540020387681258]
	TIME [epoch: 41.7 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013485206530906664		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: -0.013485206530906664 | validation: -0.015222035040071203]
	TIME [epoch: 41.7 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01350628045981005		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: -0.01350628045981005 | validation: -0.019662163138614096]
	TIME [epoch: 41.6 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012571878778186704		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: -0.012571878778186704 | validation: -0.0016647731835284733]
	TIME [epoch: 41.8 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012369637431016482		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: -0.012369637431016482 | validation: -0.015370757135126183]
	TIME [epoch: 41.8 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012430628364329255		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: -0.012430628364329255 | validation: -0.014590214253062148]
	TIME [epoch: 41.8 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012067235884148743		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: -0.012067235884148743 | validation: -0.008746793334798256]
	TIME [epoch: 41.6 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013412772292529558		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: -0.013412772292529558 | validation: -0.019612267869005485]
	TIME [epoch: 41.6 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: -0.015258996543878807		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: -0.015258996543878807 | validation: -0.0058435710538740655]
	TIME [epoch: 41.8 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013118054313851556		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: -0.013118054313851556 | validation: -0.010336621827037835]
	TIME [epoch: 41.6 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012974067510488366		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: -0.012974067510488366 | validation: -0.020620374500218603]
	TIME [epoch: 41.7 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012334559147913047		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: -0.012334559147913047 | validation: -0.002376167838066571]
	TIME [epoch: 41.6 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: -0.017104296477439516		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: -0.017104296477439516 | validation: -0.0027672499689460135]
	TIME [epoch: 41.7 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013861195006820499		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: -0.013861195006820499 | validation: -0.008613632517824]
	TIME [epoch: 41.6 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: -0.017127099267950054		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: -0.017127099267950054 | validation: -0.01308366080928194]
	TIME [epoch: 41.6 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014838176888310194		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: -0.014838176888310194 | validation: -0.00988206098676449]
	TIME [epoch: 41.7 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01431345185646058		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: -0.01431345185646058 | validation: 0.0018381120393686106]
	TIME [epoch: 41.6 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01197372612308939		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: -0.01197372612308939 | validation: -0.009399300710780992]
	TIME [epoch: 41.6 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01111290366931593		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: -0.01111290366931593 | validation: -0.008813591985650663]
	TIME [epoch: 41.6 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011125298663825486		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: -0.011125298663825486 | validation: -0.008921763534708973]
	TIME [epoch: 41.6 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009892931834043973		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: -0.009892931834043973 | validation: -0.007363179418085276]
	TIME [epoch: 41.8 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011198189597662328		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: -0.011198189597662328 | validation: -0.014690319365522325]
	TIME [epoch: 41.5 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: -0.014604637331681217		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: -0.014604637331681217 | validation: -0.006286358980289083]
	TIME [epoch: 41.6 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0159374876176355		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: -0.0159374876176355 | validation: -0.004921510378272506]
	TIME [epoch: 41.7 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013986419233954276		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: -0.013986419233954276 | validation: -0.008795429595518477]
	TIME [epoch: 41.7 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00951113007419824		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: -0.00951113007419824 | validation: -0.010893851134489301]
	TIME [epoch: 41.7 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013136621983719107		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: -0.013136621983719107 | validation: -0.019089726914443626]
	TIME [epoch: 41.7 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_kl_20241015_172819/states/model_algphi1_1a_v_kl_391.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 9754.900 seconds.
