Args:
Namespace(name='model_algphi2_1a_v_mmd1', outdir='out/model_training/model_algphi2_1a_v_mmd1', training_data='data/training_data/basic/data_phi2_1a/training', validation_data='data/training_data/basic/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 406097160

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 3.196703468086659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.196703468086659 | validation: 3.7175808327112456]
	TIME [epoch: 99.8 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 2.953878165998189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.953878165998189 | validation: 3.487490036787547]
	TIME [epoch: 4.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 2.75075345577316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.75075345577316 | validation: 3.3940600982173157]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 2.6904543288456244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6904543288456244 | validation: 3.3445481055371133]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 2.6397647799016735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6397647799016735 | validation: 3.3045208487566686]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 2.5882452953800126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5882452953800126 | validation: 3.2525377598524194]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 2.525316033605883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.525316033605883 | validation: 3.200733332279313]
	TIME [epoch: 4.25 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 2.460434750508732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.460434750508732 | validation: 3.1258514071464027]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 2.3875725413561733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3875725413561733 | validation: 2.948909170021114]
	TIME [epoch: 4.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 1.9547672675635892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9547672675635892 | validation: 1.9292527987403956]
	TIME [epoch: 4.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 1.3233066750746525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3233066750746525 | validation: 1.194490971179149]
	TIME [epoch: 4.36 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9549618136686837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9549618136686837 | validation: 0.9652694058923839]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7413487595707644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7413487595707644 | validation: 0.8051869211147011]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6370455525052516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6370455525052516 | validation: 0.7158730516317202]
	TIME [epoch: 4.38 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5662517902711173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5662517902711173 | validation: 0.6391411044119308]
	TIME [epoch: 4.38 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5049761231470955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049761231470955 | validation: 0.571489343382578]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.45564255742082116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45564255742082116 | validation: 0.49649411006913813]
	TIME [epoch: 4.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4021961564076407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4021961564076407 | validation: 0.41923382678305554]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3411718213578727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3411718213578727 | validation: 0.36227728734952586]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26677550915182013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26677550915182013 | validation: 0.28329040327692645]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19398390051119846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19398390051119846 | validation: 0.22834453992761594]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1407051337117607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1407051337117607 | validation: 0.0957045890434575]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0714948643523808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0714948643523808 | validation: 0.049888072159275806]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03855814022815621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03855814022815621 | validation: 0.024208032335279336]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023798202033491124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023798202033491124 | validation: 0.01786264493683363]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014913140614686514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.014913140614686514 | validation: 0.009151794982799236]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007830428504430699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007830428504430699 | validation: 0.00520024041593421]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00506740363492677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00506740363492677 | validation: 0.005994938939431064]
	TIME [epoch: 4.27 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003198400851305512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.003198400851305512 | validation: 0.0034392830949444174]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0038505984259535574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0038505984259535574 | validation: 0.021090094059754903]
	TIME [epoch: 4.28 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018483922981870172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.018483922981870172 | validation: 0.007739067306649623]
	TIME [epoch: 4.25 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005092702210857745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.005092702210857745 | validation: 0.002836172500646622]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0029622683648295525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0029622683648295525 | validation: 0.002267188790815991]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.001991877219715888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.001991877219715888 | validation: 0.0025360129731970627]
	TIME [epoch: 4.26 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0024662537018483167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0024662537018483167 | validation: 0.0018966534099957451]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0019037585872265393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0019037585872265393 | validation: 0.0022240508949050134]
	TIME [epoch: 4.28 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003164381028713695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.003164381028713695 | validation: 0.003181672908078521]
	TIME [epoch: 4.25 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0020765438482560116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0020765438482560116 | validation: 0.003268263411607867]
	TIME [epoch: 4.24 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005986698618443163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.005986698618443163 | validation: 0.005788107213249887]
	TIME [epoch: 4.24 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006549082059669655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.006549082059669655 | validation: 0.0030233877234266426]
	TIME [epoch: 4.23 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0023482237062342204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0023482237062342204 | validation: 0.0024969840006720204]
	TIME [epoch: 4.24 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002790832102602685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.002790832102602685 | validation: 0.002952091338426222]
	TIME [epoch: 4.23 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0034384167600973025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0034384167600973025 | validation: 0.005313409496368169]
	TIME [epoch: 4.23 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005862918709822243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.005862918709822243 | validation: 0.0118735671951012]
	TIME [epoch: 4.23 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01090855650297579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.01090855650297579 | validation: 0.006410892765744448]
	TIME [epoch: 4.3 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007036505013131906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.007036505013131906 | validation: 0.006988348566523619]
	TIME [epoch: 4.28 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005412558865511806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.005412558865511806 | validation: 0.0047708308765151124]
	TIME [epoch: 4.25 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004516091071699082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.004516091071699082 | validation: 0.003094467114527461]
	TIME [epoch: 4.24 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00249258103716594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00249258103716594 | validation: 0.0031388874196711554]
	TIME [epoch: 4.25 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00239627202474413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.00239627202474413 | validation: 0.002236010225642462]
	TIME [epoch: 4.26 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016489705548057149		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: -0.0016489705548057149 | validation: -0.0014618770233164524]
	TIME [epoch: 102 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0006056695779171597		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.0006056695779171597 | validation: 0.011299022848069658]
	TIME [epoch: 8.52 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010998052655376143		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.010998052655376143 | validation: -0.0011382415053737501]
	TIME [epoch: 8.42 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005797748199057615		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.005797748199057615 | validation: 0.004601539193896553]
	TIME [epoch: 8.41 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000793426937332783		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.000793426937332783 | validation: -0.0005330634675054413]
	TIME [epoch: 8.43 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017883927441574906		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: -0.0017883927441574906 | validation: -0.0013553238508170334]
	TIME [epoch: 8.43 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0014584423635362006		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.0014584423635362006 | validation: 0.00551559965423212]
	TIME [epoch: 8.49 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002435314558681536		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.002435314558681536 | validation: -0.0016612092268555592]
	TIME [epoch: 8.46 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014543023098567672		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: -0.0014543023098567672 | validation: -0.00081768833845998]
	TIME [epoch: 8.44 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016179575925736856		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: -0.0016179575925736856 | validation: -0.0016992860658830438]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: -2.770688694339226e-05		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: -2.770688694339226e-05 | validation: 0.002868198793965552]
	TIME [epoch: 8.43 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0006216781181678055		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: -0.0006216781181678055 | validation: -0.0003701541593006916]
	TIME [epoch: 8.46 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009784195264579878		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: -0.0009784195264579878 | validation: -0.0015113455457586534]
	TIME [epoch: 8.43 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001901755114699863		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: -0.001901755114699863 | validation: -0.0019280496243365727]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018039941883854242		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: -0.0018039941883854242 | validation: 0.0023509630932102197]
	TIME [epoch: 8.42 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0012173373795615252		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.0012173373795615252 | validation: -0.0008760560251499668]
	TIME [epoch: 8.45 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019473665184575994		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: -0.0019473665184575994 | validation: -0.0012148228162392957]
	TIME [epoch: 8.42 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016984272702699147		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: -0.0016984272702699147 | validation: -0.0014181912584573394]
	TIME [epoch: 8.45 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00026240950304657365		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: -0.00026240950304657365 | validation: 0.0012893864359848736]
	TIME [epoch: 8.42 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00431268804037826		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.00431268804037826 | validation: 0.0005154760288401477]
	TIME [epoch: 8.41 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00024619670067604075		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.00024619670067604075 | validation: -0.001140522875936798]
	TIME [epoch: 8.39 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015744539747673978		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: -0.0015744539747673978 | validation: 0.0007809771525775053]
	TIME [epoch: 8.43 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00599787253618601		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.00599787253618601 | validation: -0.0008664199635250362]
	TIME [epoch: 8.43 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009831617976385218		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: -0.0009831617976385218 | validation: 0.0005368770670673433]
	TIME [epoch: 8.44 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0005543569717008596		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.0005543569717008596 | validation: 0.000677893394074304]
	TIME [epoch: 8.41 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: -8.719147130036518e-05		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: -8.719147130036518e-05 | validation: -0.00027551181997698083]
	TIME [epoch: 8.41 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010015233700103857		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: -0.0010015233700103857 | validation: -0.0005389312561776829]
	TIME [epoch: 8.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015767432361177278		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: -0.0015767432361177278 | validation: -0.0013394166470910495]
	TIME [epoch: 8.44 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013281577520501534		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: -0.0013281577520501534 | validation: -0.0019655776583680966]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012151937745337516		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: -0.0012151937745337516 | validation: 0.00154536587813967]
	TIME [epoch: 8.49 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000834116497274858		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.000834116497274858 | validation: -0.0005731674602206995]
	TIME [epoch: 8.41 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012915906178525161		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: -0.0012915906178525161 | validation: -0.0017615803386483147]
	TIME [epoch: 8.42 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018509953019299893		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: -0.0018509953019299893 | validation: -0.001974539159041832]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018427379507704072		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: -0.0018427379507704072 | validation: -0.001911132785340908]
	TIME [epoch: 8.45 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001563539383172531		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: -0.001563539383172531 | validation: -0.0013748330742248639]
	TIME [epoch: 8.44 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016820966436926564		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: -0.0016820966436926564 | validation: -0.0009978267601222762]
	TIME [epoch: 8.43 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017866969687818524		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: -0.0017866969687818524 | validation: -0.0015903594734190884]
	TIME [epoch: 8.42 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017042324164035587		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: -0.0017042324164035587 | validation: 0.00039627436218914094]
	TIME [epoch: 8.42 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000659313486331384		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: -0.000659313486331384 | validation: -0.00021084480668281458]
	TIME [epoch: 8.41 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000632866092662034		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.000632866092662034 | validation: -0.0002980335076549476]
	TIME [epoch: 8.42 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013073759007312805		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: -0.0013073759007312805 | validation: -0.0011735931910508573]
	TIME [epoch: 8.44 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009366431778785209		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: -0.0009366431778785209 | validation: 5.395236114081128e-05]
	TIME [epoch: 8.44 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00020472922726421226		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: -0.00020472922726421226 | validation: -0.001411950165653582]
	TIME [epoch: 8.41 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0009425497421816731		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: -0.0009425497421816731 | validation: -0.0013405071822027055]
	TIME [epoch: 8.41 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00011502905979173985		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: -0.00011502905979173985 | validation: -0.001586271424293548]
	TIME [epoch: 8.41 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001729379067349668		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: -0.001729379067349668 | validation: -0.0018201727169374978]
	TIME [epoch: 8.38 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002076345559218895		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: -0.002076345559218895 | validation: -0.000582111276766304]
	TIME [epoch: 8.48 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001022551951634055		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: -0.001022551951634055 | validation: -0.0014050073504557044]
	TIME [epoch: 8.43 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0002401771616553619		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: -0.0002401771616553619 | validation: -0.00046840589571400717]
	TIME [epoch: 8.42 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0001737099730015561		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.0001737099730015561 | validation: -0.0003489950925978702]
	TIME [epoch: 8.42 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00012859086160678726		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: -0.00012859086160678726 | validation: -0.00130594106955123]
	TIME [epoch: 115 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013851593948962949		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: -0.0013851593948962949 | validation: -0.0008213590901140805]
	TIME [epoch: 19.2 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017011171504702637		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.0017011171504702637 | validation: -0.0018719370360592471]
	TIME [epoch: 19.1 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016422761230765366		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: -0.0016422761230765366 | validation: -0.0020912443359949735]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015474708139494077		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: -0.0015474708139494077 | validation: -0.0020858002598972193]
	TIME [epoch: 19.1 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002268052473265906		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.002268052473265906 | validation: -0.0014707430332087934]
	TIME [epoch: 19.2 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015253689478591705		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.0015253689478591705 | validation: -0.0017561389018762885]
	TIME [epoch: 19.2 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0006470450913471865		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: -0.0006470450913471865 | validation: -0.0006543168891081783]
	TIME [epoch: 19.2 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0008936852152332637		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.0008936852152332637 | validation: -0.0013964370587157414]
	TIME [epoch: 19.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013882414610229279		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: -0.0013882414610229279 | validation: -0.0004470425048032887]
	TIME [epoch: 19.2 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00011766777419215075		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: -0.00011766777419215075 | validation: -0.001307446172776475]
	TIME [epoch: 19.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018470351257075255		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: -0.0018470351257075255 | validation: -0.0016968159525601165]
	TIME [epoch: 19.3 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014899497559496943		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: -0.0014899497559496943 | validation: -0.001046140397186825]
	TIME [epoch: 19.2 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002188327847283458		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: -0.002188327847283458 | validation: -0.0022674488286423887]
	TIME [epoch: 19.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002050887116160721		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: -0.002050887116160721 | validation: -0.0013642700640329197]
	TIME [epoch: 19.2 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017569002126370942		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: -0.0017569002126370942 | validation: -0.0014997609196282353]
	TIME [epoch: 19.2 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020098347801350896		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: -0.0020098347801350896 | validation: -0.0007340780928416542]
	TIME [epoch: 19.2 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00246453681748745		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.00246453681748745 | validation: 0.0006491492234649212]
	TIME [epoch: 19.2 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: -5.8598753723512406e-05		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: -5.8598753723512406e-05 | validation: -0.0015688898976464918]
	TIME [epoch: 19.2 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0005137512675830407		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: -0.0005137512675830407 | validation: -0.0013677244803322712]
	TIME [epoch: 19.2 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010904821052336114		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: -0.0010904821052336114 | validation: -0.001794423365898687]
	TIME [epoch: 19.2 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002365554766477593		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: -0.002365554766477593 | validation: -0.00159404772125063]
	TIME [epoch: 19.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019912938468001377		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: -0.0019912938468001377 | validation: -0.001403232012077944]
	TIME [epoch: 19.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012434280762531353		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: -0.0012434280762531353 | validation: -0.001253060181890682]
	TIME [epoch: 19.2 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001767696220254008		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: -0.001767696220254008 | validation: 1.8668510377366487e-05]
	TIME [epoch: 19.1 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018767475072115432		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: -0.0018767475072115432 | validation: -0.0014613349520615575]
	TIME [epoch: 19.2 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019412358970623345		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.0019412358970623345 | validation: -0.0021168732404208434]
	TIME [epoch: 19.2 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021465382754245195		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.0021465382754245195 | validation: -0.0021938235608598665]
	TIME [epoch: 19.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020042376173556578		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.0020042376173556578 | validation: -0.0011300503872297512]
	TIME [epoch: 19.1 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017189923629833915		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: -0.0017189923629833915 | validation: -0.002139319616470028]
	TIME [epoch: 19.1 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002148310524477029		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: -0.002148310524477029 | validation: -0.002119872573290159]
	TIME [epoch: 19.2 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002249148902613285		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: -0.002249148902613285 | validation: -0.0024178130957996213]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_132.pth
	Model improved!!!
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019130191902818699		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: -0.0019130191902818699 | validation: -0.0019548644092055346]
	TIME [epoch: 19.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021583855162207017		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: -0.0021583855162207017 | validation: -0.0019437287213491714]
	TIME [epoch: 19.2 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002317935588136357		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: -0.002317935588136357 | validation: 0.0005075575023859287]
	TIME [epoch: 19.1 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00043607880329558804		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.00043607880329558804 | validation: 0.0015595255268893316]
	TIME [epoch: 19.1 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000545410171391981		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: -0.000545410171391981 | validation: -0.00022128281034743092]
	TIME [epoch: 19 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00145508479944741		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: -0.00145508479944741 | validation: -0.0020047282846628093]
	TIME [epoch: 19.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017635274584019895		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: -0.0017635274584019895 | validation: -0.0015636996736964263]
	TIME [epoch: 19.2 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015062150072391448		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: -0.0015062150072391448 | validation: -0.0005594011945515542]
	TIME [epoch: 19.1 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015228297722816699		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: -0.0015228297722816699 | validation: -0.0017937577613303447]
	TIME [epoch: 19.2 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020041883173792397		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: -0.0020041883173792397 | validation: -0.0018915980224933197]
	TIME [epoch: 19.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015231350824277822		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: -0.0015231350824277822 | validation: -0.002033686609149537]
	TIME [epoch: 19.2 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021587384523464137		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: -0.0021587384523464137 | validation: -0.0025006271398283]
	TIME [epoch: 19.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_144.pth
	Model improved!!!
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002108284740527163		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.002108284740527163 | validation: -0.000963201631997511]
	TIME [epoch: 19.2 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0028161045305400466		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.0028161045305400466 | validation: -0.002353447660518373]
	TIME [epoch: 19.2 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023241267314362034		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.0023241267314362034 | validation: -0.0008770707259468304]
	TIME [epoch: 19.2 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022660590427543595		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.0022660590427543595 | validation: -0.0018532407892911237]
	TIME [epoch: 19.2 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001618322122111401		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: -0.001618322122111401 | validation: -0.0007119730134033535]
	TIME [epoch: 19.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013430023539571577		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: -0.0013430023539571577 | validation: -0.0020218745947658905]
	TIME [epoch: 19.1 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022012965223909874		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: -0.0022012965223909874 | validation: -0.0023557226629378463]
	TIME [epoch: 19.2 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020697957160317557		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: -0.0020697957160317557 | validation: -0.0024750755884695385]
	TIME [epoch: 19.2 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002041436226214116		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.002041436226214116 | validation: -0.0015428690313724937]
	TIME [epoch: 19.2 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024862128902343058		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.0024862128902343058 | validation: -0.0005747363139247051]
	TIME [epoch: 19.2 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023549845311168047		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.0023549845311168047 | validation: -0.0014471401359363507]
	TIME [epoch: 19.1 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018254510947911607		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.0018254510947911607 | validation: -0.0019858171395198076]
	TIME [epoch: 19.2 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022280101853635816		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.0022280101853635816 | validation: -0.0021033221601242137]
	TIME [epoch: 19.2 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019113721625044623		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.0019113721625044623 | validation: -0.0021405874115640842]
	TIME [epoch: 19.2 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002223088756953773		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.002223088756953773 | validation: -0.0020741673171777875]
	TIME [epoch: 19.2 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019756727477707697		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.0019756727477707697 | validation: -0.001994715794035292]
	TIME [epoch: 19.1 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002082716015940663		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.002082716015940663 | validation: -0.00194780142417874]
	TIME [epoch: 19.1 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016044003337219157		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.0016044003337219157 | validation: -0.002530399541185702]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_162.pth
	Model improved!!!
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020589145500582535		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.0020589145500582535 | validation: -0.00217220101080029]
	TIME [epoch: 19.3 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002058634626999719		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.002058634626999719 | validation: -0.0018745798084105223]
	TIME [epoch: 19 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018750657000759594		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.0018750657000759594 | validation: -0.0020674512597618046]
	TIME [epoch: 19 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002276491179844529		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.002276491179844529 | validation: -0.0020062402778655702]
	TIME [epoch: 19 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021162613409858315		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.0021162613409858315 | validation: -0.0017367964776834198]
	TIME [epoch: 19 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021554895892923337		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.0021554895892923337 | validation: -0.0014902098769876428]
	TIME [epoch: 19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002167291287815055		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.002167291287815055 | validation: -0.001842003798060791]
	TIME [epoch: 18.9 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002031386119590228		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.002031386119590228 | validation: -0.0022565418817973833]
	TIME [epoch: 18.9 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020661272605993226		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.0020661272605993226 | validation: -0.0019921878122842545]
	TIME [epoch: 18.9 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002181016801807804		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.002181016801807804 | validation: -0.0022041735086365537]
	TIME [epoch: 18.9 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001980507159135123		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.001980507159135123 | validation: -0.0017117032113565327]
	TIME [epoch: 19 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020207590470852996		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.0020207590470852996 | validation: -0.0019659773534127373]
	TIME [epoch: 19.4 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016139362167187905		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.0016139362167187905 | validation: -0.0022701354070144156]
	TIME [epoch: 19.2 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015259866971122024		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.0015259866971122024 | validation: -0.0009744789668526214]
	TIME [epoch: 19.1 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018445021605964377		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.0018445021605964377 | validation: -0.0019090118101042354]
	TIME [epoch: 19.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019190318936148929		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.0019190318936148929 | validation: -0.0022426246090442533]
	TIME [epoch: 19.1 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015495334019550496		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.0015495334019550496 | validation: -0.001547624928623204]
	TIME [epoch: 19.2 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015054090550009613		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.0015054090550009613 | validation: -0.0015236315100701473]
	TIME [epoch: 19.2 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002077394367184		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.002077394367184 | validation: -0.0018077943286967954]
	TIME [epoch: 19.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019509079229126974		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.0019509079229126974 | validation: -0.0023065940041138693]
	TIME [epoch: 19.2 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002373787590376656		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.002373787590376656 | validation: -0.001802867048890508]
	TIME [epoch: 19.1 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021672977768596945		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.0021672977768596945 | validation: -0.0016839983906171275]
	TIME [epoch: 19.2 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00202075324437994		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.00202075324437994 | validation: -0.0025734321084616377]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0017927838603821766		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.0017927838603821766 | validation: -0.0018230596401774112]
	TIME [epoch: 19.1 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0013739778424599772		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.0013739778424599772 | validation: -0.002273678040941836]
	TIME [epoch: 19.2 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019282059657155634		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.0019282059657155634 | validation: -0.002363882035804816]
	TIME [epoch: 19.1 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020337989202649297		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.0020337989202649297 | validation: -0.0012926488389353955]
	TIME [epoch: 19.1 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020369148024097666		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.0020369148024097666 | validation: -0.002155037623673314]
	TIME [epoch: 19.1 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002008167347403544		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.002008167347403544 | validation: -0.0018431748545313762]
	TIME [epoch: 19.1 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020017118229543693		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.0020017118229543693 | validation: -0.0014370675122932029]
	TIME [epoch: 19.2 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002209906415477098		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.002209906415477098 | validation: -0.002411771002207891]
	TIME [epoch: 19.1 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019876080689860643		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.0019876080689860643 | validation: -0.0027468926921643375]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_194.pth
	Model improved!!!
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0016194753944975434		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.0016194753944975434 | validation: -0.0014618587385788716]
	TIME [epoch: 19.1 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019009635151948368		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.0019009635151948368 | validation: -0.002117338555161969]
	TIME [epoch: 19.1 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00230209151318962		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.00230209151318962 | validation: -0.001673699306997718]
	TIME [epoch: 19.2 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001988425640118603		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.001988425640118603 | validation: -0.0017230141291876878]
	TIME [epoch: 19.1 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020351557554217315		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.0020351557554217315 | validation: -0.001811639016991876]
	TIME [epoch: 19.1 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022892065624612145		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.0022892065624612145 | validation: -0.0014248299065149116]
	TIME [epoch: 19.2 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020409342415950524		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.0020409342415950524 | validation: -0.002171867364008039]
	TIME [epoch: 19.2 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001979432952699593		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.001979432952699593 | validation: -0.0016338036496598078]
	TIME [epoch: 19.2 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001985174085505251		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.001985174085505251 | validation: -0.0014598495334067403]
	TIME [epoch: 19.1 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019309172067093082		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.0019309172067093082 | validation: -0.001997518407703897]
	TIME [epoch: 19.2 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002216906958476534		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.002216906958476534 | validation: -0.0017393058886524774]
	TIME [epoch: 19.2 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001992122891134177		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.001992122891134177 | validation: -0.002032572386680436]
	TIME [epoch: 19.1 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018318885351287827		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.0018318885351287827 | validation: -0.002321912427261489]
	TIME [epoch: 19.2 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020579028028902997		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.0020579028028902997 | validation: -0.0020270122572277824]
	TIME [epoch: 19.1 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020507845176445877		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.0020507845176445877 | validation: -0.0016793087414373803]
	TIME [epoch: 19.1 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020128981375578		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.0020128981375578 | validation: -0.00185851218501381]
	TIME [epoch: 19.2 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022389781590875305		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.0022389781590875305 | validation: -0.0013300708817192385]
	TIME [epoch: 19.2 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022321366961769126		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.0022321366961769126 | validation: -0.0015694123133464396]
	TIME [epoch: 19.2 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025165802059851313		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.0025165802059851313 | validation: -0.0022030170950401145]
	TIME [epoch: 19.1 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022303158407630808		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.0022303158407630808 | validation: -0.002151572344535414]
	TIME [epoch: 19.2 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019207317438162234		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.0019207317438162234 | validation: -0.002510516930928329]
	TIME [epoch: 19.2 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023136563439000294		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.0023136563439000294 | validation: -0.002052991320762569]
	TIME [epoch: 19.2 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020720813305597978		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.0020720813305597978 | validation: -0.002360386015195008]
	TIME [epoch: 19.1 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002235181320571678		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.002235181320571678 | validation: -0.0026149599093420483]
	TIME [epoch: 19.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015031689172324348		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.0015031689172324348 | validation: -0.0024372390514228928]
	TIME [epoch: 19.2 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018153056114518177		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.0018153056114518177 | validation: -0.001966963003192474]
	TIME [epoch: 19.1 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022234546298684934		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.0022234546298684934 | validation: -0.0007045490410487605]
	TIME [epoch: 19.2 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022340681307377996		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.0022340681307377996 | validation: -0.0015655398657428773]
	TIME [epoch: 19.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024354975357263747		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.0024354975357263747 | validation: -0.002068348041691815]
	TIME [epoch: 19.1 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021474256749320166		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.0021474256749320166 | validation: -0.0021764459456829932]
	TIME [epoch: 19.2 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022416924638364423		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.0022416924638364423 | validation: -0.001959984013240494]
	TIME [epoch: 19.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023198614180588864		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.0023198614180588864 | validation: -0.0019249567995068433]
	TIME [epoch: 19.1 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002269027156538166		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.002269027156538166 | validation: -0.002137826775865038]
	TIME [epoch: 19.1 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001961302999725004		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.001961302999725004 | validation: -0.0018018329172949]
	TIME [epoch: 19 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022365554531458788		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.0022365554531458788 | validation: -0.0017353854106103264]
	TIME [epoch: 19.1 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020552212984806762		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.0020552212984806762 | validation: -0.0018959707514556753]
	TIME [epoch: 19.2 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020409579544957176		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.0020409579544957176 | validation: -0.00249113944514397]
	TIME [epoch: 19.1 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019017488986425512		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.0019017488986425512 | validation: -0.0015497406186473065]
	TIME [epoch: 19.2 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022230372559931266		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.0022230372559931266 | validation: -0.001942517320624178]
	TIME [epoch: 19.1 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002220371563267029		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.002220371563267029 | validation: -0.0021931038183426914]
	TIME [epoch: 19.1 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002164988378155542		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.002164988378155542 | validation: -0.001935858163666241]
	TIME [epoch: 19.2 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021352583778606656		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.0021352583778606656 | validation: -0.001144599171161989]
	TIME [epoch: 19.1 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020436698580086426		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.0020436698580086426 | validation: -0.0021706682290249775]
	TIME [epoch: 19.2 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001880019520539022		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.001880019520539022 | validation: -0.0022267640669612057]
	TIME [epoch: 19.1 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022135362393920395		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.0022135362393920395 | validation: -0.001800059491351761]
	TIME [epoch: 19.1 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002069260608553599		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.002069260608553599 | validation: -0.0018405864464093227]
	TIME [epoch: 19.2 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022161500921367918		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.0022161500921367918 | validation: -0.0022637268957955993]
	TIME [epoch: 19.1 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026477983816466932		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.0026477983816466932 | validation: -0.0018463252492870686]
	TIME [epoch: 19.1 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0023325940477296023		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.0023325940477296023 | validation: -0.0017426268361488714]
	TIME [epoch: 19.1 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002458409022487559		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.002458409022487559 | validation: -0.0016854707656887772]
	TIME [epoch: 19.1 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022294394277863863		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.0022294394277863863 | validation: -0.0017902774674465479]
	TIME [epoch: 19.2 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021641314897276015		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.0021641314897276015 | validation: -0.0018044137616793998]
	TIME [epoch: 19.1 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002142648127038872		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.002142648127038872 | validation: -0.0025760475886584047]
	TIME [epoch: 19.2 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020312233440692076		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.0020312233440692076 | validation: -0.0020824778635786666]
	TIME [epoch: 19.1 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001945611057850625		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.001945611057850625 | validation: -0.0015789882919343252]
	TIME [epoch: 19.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002248837602325877		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.002248837602325877 | validation: -0.0022760005969357927]
	TIME [epoch: 19.2 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018621435105143145		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.0018621435105143145 | validation: -0.0013355436149752795]
	TIME [epoch: 138 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019269829552000365		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.0019269829552000365 | validation: -0.0014868647517775307]
	TIME [epoch: 42.6 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020130969496550393		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.0020130969496550393 | validation: -0.002239668218163425]
	TIME [epoch: 42.6 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00247115009578483		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.00247115009578483 | validation: -0.0014464571723760812]
	TIME [epoch: 42.5 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002250136302448429		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.002250136302448429 | validation: -0.002055236976198049]
	TIME [epoch: 42.5 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019472621344578337		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.0019472621344578337 | validation: -0.0023860381057711493]
	TIME [epoch: 42.5 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002386887980759213		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.002386887980759213 | validation: -0.0015981745698189118]
	TIME [epoch: 42.1 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002230301930194653		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.002230301930194653 | validation: -0.002127002879442351]
	TIME [epoch: 42.1 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002004496525753408		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.002004496525753408 | validation: -0.0020553611206497084]
	TIME [epoch: 42 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019791435970224623		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.0019791435970224623 | validation: -0.001230418557479917]
	TIME [epoch: 42.2 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00246356947749489		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.00246356947749489 | validation: -0.002162100922201929]
	TIME [epoch: 42.6 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002277556697419842		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.002277556697419842 | validation: -0.001837435752139585]
	TIME [epoch: 42.6 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002179152247890112		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.002179152247890112 | validation: -0.0021806832236314394]
	TIME [epoch: 42.5 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021985109069726384		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.0021985109069726384 | validation: -0.0021085319039926935]
	TIME [epoch: 42.6 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021803009781230696		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.0021803009781230696 | validation: -0.001268762229832821]
	TIME [epoch: 42.5 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0024842066662860516		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.0024842066662860516 | validation: -0.002421537095575709]
	TIME [epoch: 42.4 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002116074123742519		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: -0.002116074123742519 | validation: -0.002045494632597588]
	TIME [epoch: 42.5 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001560459671543744		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: -0.001560459671543744 | validation: -0.0020886737949927887]
	TIME [epoch: 42.5 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002334447454171516		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.002334447454171516 | validation: -0.0021190354706639913]
	TIME [epoch: 42.4 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021971206798891176		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.0021971206798891176 | validation: -0.0021231655899183934]
	TIME [epoch: 42.6 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002030275660809513		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.002030275660809513 | validation: -0.0012881540208514585]
	TIME [epoch: 42.5 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001787299006705439		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.001787299006705439 | validation: -0.0017959855094230265]
	TIME [epoch: 42.4 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019804338184155985		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.0019804338184155985 | validation: -0.0016278041155665867]
	TIME [epoch: 42.5 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002009920282529201		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: -0.002009920282529201 | validation: -0.0018022638176964888]
	TIME [epoch: 42.5 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022859918343907768		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.0022859918343907768 | validation: -0.0022062643445776497]
	TIME [epoch: 42.5 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022050183717677255		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.0022050183717677255 | validation: -0.0015684749478327151]
	TIME [epoch: 42.5 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018993877910864249		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.0018993877910864249 | validation: -0.0022575662226403427]
	TIME [epoch: 42.5 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019523089385665385		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.0019523089385665385 | validation: -0.0020691241541586367]
	TIME [epoch: 42.3 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0020680119618206737		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.0020680119618206737 | validation: -0.002223642526033857]
	TIME [epoch: 42.4 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0015778147201737955		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.0015778147201737955 | validation: -0.001597430416195842]
	TIME [epoch: 42.6 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002024208016939624		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.002024208016939624 | validation: -0.0018514339799758424]
	TIME [epoch: 42.5 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002240076417035274		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.002240076417035274 | validation: -0.0026739890528191725]
	TIME [epoch: 42.5 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021514962606309796		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.0021514962606309796 | validation: -0.0021607084603038652]
	TIME [epoch: 42.6 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002133353211122855		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.002133353211122855 | validation: -0.0017324751322012047]
	TIME [epoch: 42.4 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021616179379666646		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: -0.0021616179379666646 | validation: -0.002085158807386461]
	TIME [epoch: 42.5 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025216825210485957		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: -0.0025216825210485957 | validation: -0.0021623203533796885]
	TIME [epoch: 42.5 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002194326791353557		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: -0.002194326791353557 | validation: -0.0017241153582635933]
	TIME [epoch: 42.6 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002223973544902761		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: -0.002223973544902761 | validation: -0.0015128005474058844]
	TIME [epoch: 42.6 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002346432223223233		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: -0.002346432223223233 | validation: -0.0011802415265683224]
	TIME [epoch: 42.6 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018625343851535582		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: -0.0018625343851535582 | validation: -0.002446337670659623]
	TIME [epoch: 42.5 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00205097665625357		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: -0.00205097665625357 | validation: -0.001816600921435999]
	TIME [epoch: 42.5 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026021799417378973		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: -0.0026021799417378973 | validation: -0.001990415695480803]
	TIME [epoch: 42.5 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0019831642208363465		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: -0.0019831642208363465 | validation: -0.0020384683730547354]
	TIME [epoch: 42.5 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022821778678992514		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: -0.0022821778678992514 | validation: -0.0019098694624890286]
	TIME [epoch: 42.6 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0022454093646193493		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: -0.0022454093646193493 | validation: -0.001663288933851272]
	TIME [epoch: 42.6 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_mmd1_20241015_173245/states/model_algphi2_1a_v_mmd1_295.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 5838.416 seconds.
