Args:
Namespace(name='model_algphi1_1a_v_klv2', outdir='out/model_training/model_algphi1_1a_v_klv2', training_data='data/training_data/basic/data_phi1_1a/training', validation_data='data/training_data/basic/data_phi1_1a/validation', model_type='binary_choice', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2486010828

Training model...

Saving initial model state to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 10.753063680712138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.753063680712138 | validation: 10.666924633151282]
	TIME [epoch: 107 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 10.72801648064637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.72801648064637 | validation: 10.652149390568393]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 10.738261153339973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.738261153339973 | validation: 10.644799060840057]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 10.707127549120809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.707127549120809 | validation: 10.631069294968938]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 10.70480919526041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.70480919526041 | validation: 10.622659057528153]
	TIME [epoch: 4.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 10.700388686392298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.700388686392298 | validation: 10.616125792579012]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 10.69976551192487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.69976551192487 | validation: 10.586398009891335]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 10.680931072549392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.680931072549392 | validation: 10.575773285900748]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 10.666014555686647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.666014555686647 | validation: 10.559976913362572]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 10.653566719542871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.653566719542871 | validation: 10.526289284882559]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 10.637537105376474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.637537105376474 | validation: 10.520715772620463]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 10.616202750041735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.616202750041735 | validation: 10.515557217866137]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 10.586544476910818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.586544476910818 | validation: 10.498604910512016]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 10.594855459348057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.594855459348057 | validation: 10.477417716374708]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 10.575725613953542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.575725613953542 | validation: 10.431609985809335]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 10.525800947178485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.525800947178485 | validation: 10.364194465359759]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 10.455543102718206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.455543102718206 | validation: 10.310993405114061]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 10.399040415446905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.399040415446905 | validation: 10.293194831515859]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 10.379075604832744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.379075604832744 | validation: 10.258424633425598]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 10.365025459274172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.365025459274172 | validation: 10.285834617362493]
	TIME [epoch: 4.34 sec]
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 10.34163778877383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.34163778877383 | validation: 10.254055446109493]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 10.343570942233262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.343570942233262 | validation: 10.205155626507853]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 10.29054290877955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.29054290877955 | validation: 10.132190085774225]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 10.235502669933558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.235502669933558 | validation: 10.099173977525663]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 10.187166317952588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.187166317952588 | validation: 10.122626872904828]
	TIME [epoch: 4.3 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 10.173700327156808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.173700327156808 | validation: 9.986232688406403]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 10.179855946042554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.179855946042554 | validation: 10.066575483048807]
	TIME [epoch: 4.31 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 10.15033374338984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.15033374338984 | validation: 9.988683280574925]
	TIME [epoch: 4.32 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 10.018021888466526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.018021888466526 | validation: 9.901934557013089]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 9.915726118936629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.915726118936629 | validation: 9.793067952897687]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 9.938152100700187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.938152100700187 | validation: 9.789105171657553]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 9.941503349542565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.941503349542565 | validation: 9.825008685762256]
	TIME [epoch: 4.3 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 9.902213059536281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.902213059536281 | validation: 9.72211139105233]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 9.811185788713104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.811185788713104 | validation: 9.602564477461753]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_34.pth
	Model improved!!!
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 9.769857638961389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.769857638961389 | validation: 9.63880064049486]
	TIME [epoch: 4.33 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 9.691045439795348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.691045439795348 | validation: 9.521339282703089]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 9.569737400869453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.569737400869453 | validation: 9.418924919092651]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 9.488953093639676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.488953093639676 | validation: 9.422797244014584]
	TIME [epoch: 4.3 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 9.45756891821804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.45756891821804 | validation: 9.378948099440134]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 9.355875129216772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.355875129216772 | validation: 9.24547079224168]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 9.310101041214235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.310101041214235 | validation: 9.24199530671481]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_41.pth
	Model improved!!!
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 9.214518184550887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.214518184550887 | validation: 9.055854789082641]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 8.997915115517069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.997915115517069 | validation: 8.994470596755217]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 8.927069119520219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.927069119520219 | validation: 8.952384628329831]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 9.013363890714963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.013363890714963 | validation: 9.039524694297038]
	TIME [epoch: 4.3 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 9.084882368020867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.084882368020867 | validation: 9.04273002483147]
	TIME [epoch: 4.3 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 9.084383867589516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.084383867589516 | validation: 9.038635241793978]
	TIME [epoch: 4.29 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 9.181991254050882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.181991254050882 | validation: 9.194454981700005]
	TIME [epoch: 4.29 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 9.31121741447762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.31121741447762 | validation: 9.284984950816384]
	TIME [epoch: 4.29 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 9.368573771886878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.368573771886878 | validation: 9.286233113892731]
	TIME [epoch: 4.29 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 7.376660428360394		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 7.376660428360394 | validation: 7.480833071731528]
	TIME [epoch: 111 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 7.288482833655424		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 7.288482833655424 | validation: 7.359932808156266]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 7.165721811407579		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 7.165721811407579 | validation: 7.209068826101395]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 7.062663265830668		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 7.062663265830668 | validation: 7.121217102685568]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 7.005882537078991		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 7.005882537078991 | validation: 7.053141059666107]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 6.944882148931386		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 6.944882148931386 | validation: 7.025640582652756]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 6.915968840137706		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 6.915968840137706 | validation: 6.9496153659072855]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_57.pth
	Model improved!!!
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 6.86620385709434		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 6.86620385709434 | validation: 6.933963806883584]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 6.84785927081212		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 6.84785927081212 | validation: 6.927788786144629]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8177167840658655		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 6.8177167840658655 | validation: 6.893978458353754]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 6.800380859473726		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 6.800380859473726 | validation: 6.8507321830863654]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 6.774905432079465		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 6.774905432079465 | validation: 6.858795636439284]
	TIME [epoch: 8.4 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 6.790619637329049		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 6.790619637329049 | validation: 6.907043181431414]
	TIME [epoch: 8.4 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 6.836986263412503		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 6.836986263412503 | validation: 6.903012980202197]
	TIME [epoch: 8.45 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 6.826853389414295		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 6.826853389414295 | validation: 6.877576938582377]
	TIME [epoch: 8.41 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 6.813724919031419		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 6.813724919031419 | validation: 6.819142662333105]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 6.742808905051086		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 6.742808905051086 | validation: 6.813441912563242]
	TIME [epoch: 8.42 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 6.731227525899164		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 6.731227525899164 | validation: 6.8180422601901824]
	TIME [epoch: 8.42 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 6.770926849290801		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 6.770926849290801 | validation: 6.7584800475799405]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 6.746792302006035		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 6.746792302006035 | validation: 6.809445313042767]
	TIME [epoch: 8.41 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 6.737150036121836		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 6.737150036121836 | validation: 6.763474790644238]
	TIME [epoch: 8.4 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 6.7380930099887415		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 6.7380930099887415 | validation: 6.755935140140485]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 6.71758832437647		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 6.71758832437647 | validation: 6.739847540197381]
	TIME [epoch: 8.46 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 6.680863094660402		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 6.680863094660402 | validation: 6.717232787626555]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 6.677917095101807		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 6.677917095101807 | validation: 6.669335289752853]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 6.642882523862384		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 6.642882523862384 | validation: 6.671830972549656]
	TIME [epoch: 8.35 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 6.62098067577745		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 6.62098067577745 | validation: 6.669463201220399]
	TIME [epoch: 8.34 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 6.6088640021521865		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 6.6088640021521865 | validation: 6.595208695297639]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 6.629370452702252		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 6.629370452702252 | validation: 6.670464696215012]
	TIME [epoch: 8.35 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 6.631613363676833		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 6.631613363676833 | validation: 6.699101725044416]
	TIME [epoch: 8.36 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 6.620594448997508		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 6.620594448997508 | validation: 6.657934768759253]
	TIME [epoch: 8.35 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 6.6288350182415225		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 6.6288350182415225 | validation: 6.654177109331988]
	TIME [epoch: 8.38 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 6.5872849626166		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 6.5872849626166 | validation: 6.561560046541702]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_83.pth
	Model improved!!!
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 6.553667145744495		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 6.553667145744495 | validation: 6.593858613594688]
	TIME [epoch: 8.43 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 6.584939635349237		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 6.584939635349237 | validation: 6.610407941678301]
	TIME [epoch: 8.4 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 6.6181066816388885		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 6.6181066816388885 | validation: 6.6212877841272215]
	TIME [epoch: 8.41 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 6.619550339879821		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 6.619550339879821 | validation: 6.602025579265197]
	TIME [epoch: 8.44 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 6.621226255885084		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 6.621226255885084 | validation: 6.638490481730048]
	TIME [epoch: 8.39 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 6.634528950641488		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 6.634528950641488 | validation: 6.6190231772991055]
	TIME [epoch: 8.39 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 6.607063079274479		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 6.607063079274479 | validation: 6.6917127800798735]
	TIME [epoch: 8.38 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 6.632927647641976		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 6.632927647641976 | validation: 6.668081014299527]
	TIME [epoch: 8.39 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 6.634062865922473		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 6.634062865922473 | validation: 6.701380239280521]
	TIME [epoch: 8.43 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 6.651080962403631		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 6.651080962403631 | validation: 6.6946798853936125]
	TIME [epoch: 8.39 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 6.634368150077287		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 6.634368150077287 | validation: 6.670861324127372]
	TIME [epoch: 8.39 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 6.594403483254421		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 6.594403483254421 | validation: 6.609410294227376]
	TIME [epoch: 8.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 6.58975072688913		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 6.58975072688913 | validation: 6.613903276787727]
	TIME [epoch: 8.42 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 6.598059296370286		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 6.598059296370286 | validation: 6.67353891601298]
	TIME [epoch: 8.42 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 6.605938262732411		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 6.605938262732411 | validation: 6.60863583879363]
	TIME [epoch: 8.4 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 6.597794264977066		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 6.597794264977066 | validation: 6.576136820073771]
	TIME [epoch: 8.4 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 6.594801434917951		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 6.594801434917951 | validation: 6.675782785973625]
	TIME [epoch: 8.41 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 6.737334205119073		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 6.737334205119073 | validation: 6.798998165836296]
	TIME [epoch: 123 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 6.7532683627565255		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 6.7532683627565255 | validation: 6.799894037790601]
	TIME [epoch: 19 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 6.741834259154301		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 6.741834259154301 | validation: 6.7469959094757685]
	TIME [epoch: 19.1 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 6.760137558498541		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 6.760137558498541 | validation: 6.771253772368051]
	TIME [epoch: 19.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 6.761679627558664		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 6.761679627558664 | validation: 6.801738207360278]
	TIME [epoch: 19 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 6.757176308952124		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 6.757176308952124 | validation: 6.8235934399113845]
	TIME [epoch: 18.9 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 6.78002032812882		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 6.78002032812882 | validation: 6.844690616756589]
	TIME [epoch: 18.9 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 6.807608454231628		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 6.807608454231628 | validation: 6.850570563032912]
	TIME [epoch: 18.9 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 6.813050907442216		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 6.813050907442216 | validation: 6.860273333627976]
	TIME [epoch: 18.9 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 6.813455441734638		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 6.813455441734638 | validation: 6.863143607759772]
	TIME [epoch: 18.9 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 6.816212381176989		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 6.816212381176989 | validation: 6.867340357977336]
	TIME [epoch: 19 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 6.841355405946603		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 6.841355405946603 | validation: 6.8146001581117694]
	TIME [epoch: 19 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8394903554736945		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 6.8394903554736945 | validation: 6.862494065500008]
	TIME [epoch: 19 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 6.834192189323101		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 6.834192189323101 | validation: 6.864965590328245]
	TIME [epoch: 19 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 6.829487816867949		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 6.829487816867949 | validation: 6.805376911298611]
	TIME [epoch: 19.1 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 6.854211628678134		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 6.854211628678134 | validation: 6.840558397986432]
	TIME [epoch: 19.1 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 6.829042765736795		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 6.829042765736795 | validation: 6.8979600205536995]
	TIME [epoch: 19.1 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 6.842645763438283		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 6.842645763438283 | validation: 6.882410571616884]
	TIME [epoch: 19.1 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 6.840517661615117		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 6.840517661615117 | validation: 6.836196916458125]
	TIME [epoch: 19.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 6.818324288748984		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 6.818324288748984 | validation: 6.824574675190866]
	TIME [epoch: 19.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 6.824115009975203		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 6.824115009975203 | validation: 6.849990447843796]
	TIME [epoch: 19.1 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8226528502056665		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 6.8226528502056665 | validation: 6.856752537774682]
	TIME [epoch: 19.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 6.806213633551044		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 6.806213633551044 | validation: 6.8406854861314095]
	TIME [epoch: 19.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 6.817931195974367		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 6.817931195974367 | validation: 6.858530628437814]
	TIME [epoch: 19.1 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 6.807389259966326		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 6.807389259966326 | validation: 6.814741102125172]
	TIME [epoch: 19.1 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8012808154664155		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 6.8012808154664155 | validation: 6.833915156403437]
	TIME [epoch: 19.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 6.783345781633393		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 6.783345781633393 | validation: 6.843434143595124]
	TIME [epoch: 19.1 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 6.795399377228153		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 6.795399377228153 | validation: 6.803372653831735]
	TIME [epoch: 19.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 6.793468587715365		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 6.793468587715365 | validation: 6.818001789790516]
	TIME [epoch: 19 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 6.806704553919659		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 6.806704553919659 | validation: 6.834403969945983]
	TIME [epoch: 19.1 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 6.82251027591073		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 6.82251027591073 | validation: 6.837985204963984]
	TIME [epoch: 19.1 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 6.811258078827641		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 6.811258078827641 | validation: 6.819920693534692]
	TIME [epoch: 19 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 6.832109196153545		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 6.832109196153545 | validation: 6.858214894722087]
	TIME [epoch: 19.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 6.829108939585018		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 6.829108939585018 | validation: 6.859093495200179]
	TIME [epoch: 19 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8242915437239136		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 6.8242915437239136 | validation: 6.858055273312429]
	TIME [epoch: 19.1 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 6.828508136203425		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 6.828508136203425 | validation: 6.87215802609677]
	TIME [epoch: 19.1 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 6.829313304643971		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 6.829313304643971 | validation: 6.851794300351763]
	TIME [epoch: 19.1 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8242175731843835		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 6.8242175731843835 | validation: 6.866518251384301]
	TIME [epoch: 19.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 6.81765539988298		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 6.81765539988298 | validation: 6.837646699511922]
	TIME [epoch: 19.1 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 6.805581635267863		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 6.805581635267863 | validation: 6.817744453499503]
	TIME [epoch: 19.1 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 6.802484687239438		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 6.802484687239438 | validation: 6.86502538470429]
	TIME [epoch: 19.2 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 6.823674975731907		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 6.823674975731907 | validation: 6.778614663033203]
	TIME [epoch: 19.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 6.800801221705659		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 6.800801221705659 | validation: 6.853562241957199]
	TIME [epoch: 19.1 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8039451076863395		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 6.8039451076863395 | validation: 6.771464290480941]
	TIME [epoch: 19.1 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 6.788956218983309		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 6.788956218983309 | validation: 6.853833197055865]
	TIME [epoch: 19.1 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 6.806587657918449		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 6.806587657918449 | validation: 6.811735636401641]
	TIME [epoch: 19.1 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 6.812512068990045		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 6.812512068990045 | validation: 6.865756610132278]
	TIME [epoch: 19.1 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 6.813043086743978		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 6.813043086743978 | validation: 6.868146052871692]
	TIME [epoch: 19.1 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8267598199866235		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 6.8267598199866235 | validation: 6.853591410199831]
	TIME [epoch: 19.1 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 6.818935209510845		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 6.818935209510845 | validation: 6.8315029278106305]
	TIME [epoch: 19.1 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 6.81839960964051		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 6.81839960964051 | validation: 6.849224051178771]
	TIME [epoch: 19.1 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8070058755831795		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 6.8070058755831795 | validation: 6.838879835026383]
	TIME [epoch: 19 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 6.834218467834744		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 6.834218467834744 | validation: 6.799082326359665]
	TIME [epoch: 19.1 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 6.816066414425343		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 6.816066414425343 | validation: 6.868351042361027]
	TIME [epoch: 19.1 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 6.82104206693516		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 6.82104206693516 | validation: 6.821145974123431]
	TIME [epoch: 19.1 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 6.811250396394484		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 6.811250396394484 | validation: 6.842994256405227]
	TIME [epoch: 19.1 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 6.824383447857505		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 6.824383447857505 | validation: 6.782350692002645]
	TIME [epoch: 19.1 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8140831112454165		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 6.8140831112454165 | validation: 6.82871152807466]
	TIME [epoch: 19.1 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 6.821840472880437		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 6.821840472880437 | validation: 6.858545702789332]
	TIME [epoch: 19.1 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 6.804292565900768		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 6.804292565900768 | validation: 6.807749601532268]
	TIME [epoch: 19.1 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 6.817797188656391		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 6.817797188656391 | validation: 6.846988155657564]
	TIME [epoch: 19.1 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 6.801770836887156		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 6.801770836887156 | validation: 6.854173427716319]
	TIME [epoch: 19.1 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 6.806474218281954		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 6.806474218281954 | validation: 6.830804410658755]
	TIME [epoch: 19.2 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 6.799940389874189		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 6.799940389874189 | validation: 6.7960088326536985]
	TIME [epoch: 19.1 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 6.790810006170118		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 6.790810006170118 | validation: 6.8047798107300554]
	TIME [epoch: 19.1 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 6.815763574683809		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 6.815763574683809 | validation: 6.813195421089921]
	TIME [epoch: 19.1 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 6.800117269467971		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 6.800117269467971 | validation: 6.829972831289619]
	TIME [epoch: 19.1 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 6.7887393298358525		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 6.7887393298358525 | validation: 6.827414765003363]
	TIME [epoch: 19.1 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 6.77324001386871		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 6.77324001386871 | validation: 6.817704972910202]
	TIME [epoch: 19.1 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 6.800695363146956		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 6.800695363146956 | validation: 6.805625050562313]
	TIME [epoch: 19.1 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 6.799344732234534		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 6.799344732234534 | validation: 6.832210674659848]
	TIME [epoch: 19.1 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 6.785615903363317		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 6.785615903363317 | validation: 6.844664657828632]
	TIME [epoch: 19.1 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 6.804796310030777		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 6.804796310030777 | validation: 6.836687151943901]
	TIME [epoch: 19.1 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 6.787754907704429		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 6.787754907704429 | validation: 6.829242528486158]
	TIME [epoch: 19.1 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 6.798511521634688		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 6.798511521634688 | validation: 6.824778904488975]
	TIME [epoch: 19.1 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 6.807210440771974		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 6.807210440771974 | validation: 6.826631027433694]
	TIME [epoch: 19.1 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 6.8118413390638235		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 6.8118413390638235 | validation: 6.843069312432819]
	TIME [epoch: 19.1 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 6.7848199254864685		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 6.7848199254864685 | validation: 6.836161569177888]
	TIME [epoch: 19.1 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 6.795210911984908		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 6.795210911984908 | validation: 6.817384760696953]
	TIME [epoch: 19.1 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 6.792917994142309		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 6.792917994142309 | validation: 6.800819215402322]
	TIME [epoch: 19.1 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 6.774266452276384		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 6.774266452276384 | validation: 6.808511557986511]
	TIME [epoch: 19.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 6.785327895983989		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 6.785327895983989 | validation: 6.8315158769222535]
	TIME [epoch: 19.1 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 6.790780685541409		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 6.790780685541409 | validation: 6.817804256343889]
	TIME [epoch: 19.1 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 6.795204182473045		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 6.795204182473045 | validation: 6.815941398560828]
	TIME [epoch: 19.2 sec]
	Saving model to: out/model_training/model_algphi1_1a_v_klv2_20241015_172819/states/model_algphi1_1a_v_klv2_184.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 2595.101 seconds.
