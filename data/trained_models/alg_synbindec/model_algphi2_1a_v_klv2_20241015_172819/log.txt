Args:
Namespace(name='model_algphi2_1a_v_klv2', outdir='out/model_training/model_algphi2_1a_v_klv2', training_data='data/training_data/data_phi2_1a/training', validation_data='data/training_data/data_phi2_1a/validation', model_type='binary_flip', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 290924636

Training model...

Saving initial model state to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 6.256457989515319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.256457989515319 | validation: 5.105757799976083]
	TIME [epoch: 109 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 5.0467098185493775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0467098185493775 | validation: 4.51449118422293]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 4.471048770663432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.471048770663432 | validation: 4.027464942932795]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 3.9677985588036466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9677985588036466 | validation: 3.5910429926440055]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 3.5046217477682715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5046217477682715 | validation: 3.2122908719184977]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 3.0833341643891066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0833341643891066 | validation: 2.880437616486201]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 2.7023416136724885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7023416136724885 | validation: 2.5561457061106623]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 2.373771772295199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.373771772295199 | validation: 2.2837696789530284]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 2.0612283364832527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0612283364832527 | validation: 1.947809306637721]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 1.7349136749600582		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7349136749600582 | validation: 1.4663366773520041]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 1.4192548195052892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4192548195052892 | validation: 1.1746279257240917]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 1.1228987320225887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1228987320225887 | validation: 1.0365917257448722]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 0.9841131984270103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9841131984270103 | validation: 0.8678629155299302]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8364982533594326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8364982533594326 | validation: 0.7330266169646864]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6983682355521357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6983682355521357 | validation: 0.6143229066501923]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5804844614658204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5804844614658204 | validation: 0.5494220532009679]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4984556977666637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4984556977666637 | validation: 0.43442964864816336]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3735471773820104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3735471773820104 | validation: 0.3172582992943116]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2942587180811389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2942587180811389 | validation: 0.27767533938555194]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2787259584929077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2787259584929077 | validation: 0.2513117009229214]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23927955459089148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23927955459089148 | validation: 0.2072036992549947]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20443543988484555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20443543988484555 | validation: 0.1923060121296059]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17943118005808611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17943118005808611 | validation: 0.16983526255419124]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18567384809889337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18567384809889337 | validation: 0.2187724654626671]
	TIME [epoch: 4.29 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2408610804346474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2408610804346474 | validation: 0.22089196626835933]
	TIME [epoch: 4.28 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1978856686866517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1978856686866517 | validation: 0.1985652175334841]
	TIME [epoch: 4.27 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17966433692665185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17966433692665185 | validation: 0.1429441246808412]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14835759736851353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14835759736851353 | validation: 0.13222425121112108]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15425298514406394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15425298514406394 | validation: 0.18297326758263724]
	TIME [epoch: 4.29 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19163816695362185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19163816695362185 | validation: 0.1717111281355504]
	TIME [epoch: 4.27 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1724596383512015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1724596383512015 | validation: 0.1422461366419035]
	TIME [epoch: 4.28 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15553959327047728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15553959327047728 | validation: 0.17358922492635798]
	TIME [epoch: 4.28 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17163959682232943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17163959682232943 | validation: 0.14940224511751649]
	TIME [epoch: 4.27 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15278360352153164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15278360352153164 | validation: 0.14882083967420964]
	TIME [epoch: 4.27 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1478840510345645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1478840510345645 | validation: 0.1491574127631886]
	TIME [epoch: 4.27 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1516345771882498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1516345771882498 | validation: 0.140590284443531]
	TIME [epoch: 4.27 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13540923499404434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13540923499404434 | validation: 0.1166917050254901]
	TIME [epoch: 4.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1311605340301727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1311605340301727 | validation: 0.1349769852739883]
	TIME [epoch: 4.26 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16525404085040354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16525404085040354 | validation: 0.16115471350251603]
	TIME [epoch: 4.26 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23382224625697995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23382224625697995 | validation: 0.19709009527257912]
	TIME [epoch: 4.26 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23387014603146516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23387014603146516 | validation: 0.13507533720153364]
	TIME [epoch: 4.26 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15237649529871072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15237649529871072 | validation: 0.11696770255530325]
	TIME [epoch: 4.27 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17595481704451815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17595481704451815 | validation: 0.1783455262551341]
	TIME [epoch: 4.26 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28264487215233286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28264487215233286 | validation: 0.20822109474620767]
	TIME [epoch: 4.26 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28355423561390397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28355423561390397 | validation: 0.1847353291488994]
	TIME [epoch: 4.27 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26663607112298693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26663607112298693 | validation: 0.2019218368638407]
	TIME [epoch: 4.28 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.26037660850069033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26037660850069033 | validation: 0.19951822899405708]
	TIME [epoch: 4.27 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2763999283085993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2763999283085993 | validation: 0.24437494930370324]
	TIME [epoch: 4.29 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2668709712955651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2668709712955651 | validation: 0.18914188614352573]
	TIME [epoch: 4.27 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23138287048638623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23138287048638623 | validation: 0.1509824180753236]
	TIME [epoch: 4.25 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.084368799172132		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.084368799172132 | validation: 0.036893996824816325]
	TIME [epoch: 113 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03892962993719617		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.03892962993719617 | validation: 0.0010293304839299631]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017146542615298965		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.017146542615298965 | validation: 0.00950120693899699]
	TIME [epoch: 8.36 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020765092449192477		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.020765092449192477 | validation: 0.024654599221692032]
	TIME [epoch: 8.27 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022040299229770164		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.022040299229770164 | validation: 0.023589602189041155]
	TIME [epoch: 8.28 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02409974559883245		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.02409974559883245 | validation: 0.022679214481960704]
	TIME [epoch: 8.31 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023925523517333413		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.023925523517333413 | validation: 0.011810482175518385]
	TIME [epoch: 8.27 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017191203446347145		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.017191203446347145 | validation: -0.0073736057747970105]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0057513992124491875		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.0057513992124491875 | validation: 0.01409617895733235]
	TIME [epoch: 8.33 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03094767533237224		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.03094767533237224 | validation: 9.03083920510148e-05]
	TIME [epoch: 8.34 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002287389778990931		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.002287389778990931 | validation: -0.004334553360459332]
	TIME [epoch: 8.34 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01605020938856855		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.01605020938856855 | validation: 0.01314485319206347]
	TIME [epoch: 8.35 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024612570008646993		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.024612570008646993 | validation: 0.01925976954492805]
	TIME [epoch: 8.33 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01691360096057047		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.01691360096057047 | validation: 0.018954070960474828]
	TIME [epoch: 8.33 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0182076649762747		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.0182076649762747 | validation: 0.03575169103632585]
	TIME [epoch: 8.33 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02180300534989639		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.02180300534989639 | validation: -0.0019137829393627726]
	TIME [epoch: 8.35 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008354316303095268		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.008354316303095268 | validation: -0.002671770415887953]
	TIME [epoch: 8.36 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014006238939407889		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.014006238939407889 | validation: -0.0004827204248713376]
	TIME [epoch: 8.33 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02554176213080315		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.02554176213080315 | validation: 0.010452142821117776]
	TIME [epoch: 8.32 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03553020605168144		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.03553020605168144 | validation: 0.003617334461725575]
	TIME [epoch: 8.34 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008281397817656409		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.008281397817656409 | validation: -0.011070866945405128]
	TIME [epoch: 8.37 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005441475926685207		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: -0.005441475926685207 | validation: -0.002369869350800538]
	TIME [epoch: 8.34 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0076844476370748925		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: -0.0076844476370748925 | validation: -0.014012926679813797]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0006487691515567212		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.0006487691515567212 | validation: 0.00633568565694434]
	TIME [epoch: 8.35 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00627449731220915		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.00627449731220915 | validation: -0.013646101361883706]
	TIME [epoch: 8.39 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005515243397587368		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: -0.005515243397587368 | validation: -0.017205678516132052]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005442681227890933		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: -0.005442681227890933 | validation: -0.026095621007844474]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0045563386774557756		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: -0.0045563386774557756 | validation: -0.010889546471233713]
	TIME [epoch: 8.34 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004024376860527149		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: -0.004024376860527149 | validation: -0.010332356319364015]
	TIME [epoch: 8.34 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0024311876994337774		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.0024311876994337774 | validation: -0.006938970267935107]
	TIME [epoch: 8.38 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018657083931696433		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.018657083931696433 | validation: 0.003752036269676762]
	TIME [epoch: 8.35 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.043251166247167495		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.043251166247167495 | validation: 0.00885284593261905]
	TIME [epoch: 8.34 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025800202894386042		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.025800202894386042 | validation: 0.010675997808558277]
	TIME [epoch: 8.34 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02009594568551682		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.02009594568551682 | validation: -0.0008768832588807159]
	TIME [epoch: 8.38 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028536738481218318		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.028536738481218318 | validation: 4.366544927858528e-05]
	TIME [epoch: 8.38 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015031624904220421		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.015031624904220421 | validation: -0.016551419563275972]
	TIME [epoch: 8.36 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006273569106823469		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: -0.006273569106823469 | validation: -0.02023229427057003]
	TIME [epoch: 8.35 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004233683776736397		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: -0.004233683776736397 | validation: -0.001407379553401923]
	TIME [epoch: 8.37 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015352337505907363		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.015352337505907363 | validation: 0.010936360042168334]
	TIME [epoch: 8.4 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03232416871998889		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.03232416871998889 | validation: 0.005424953691032773]
	TIME [epoch: 8.35 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0021788937735349135		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.0021788937735349135 | validation: -0.01448999531257868]
	TIME [epoch: 8.37 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00728286577217595		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: -0.00728286577217595 | validation: -0.00116330779142179]
	TIME [epoch: 8.36 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002658402357967736		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: -0.002658402357967736 | validation: -0.012511038786118027]
	TIME [epoch: 8.36 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010777685209916073		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.010777685209916073 | validation: 0.006867906658973832]
	TIME [epoch: 8.4 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008718380213469427		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.008718380213469427 | validation: -0.011810224699001816]
	TIME [epoch: 8.36 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008474799181403257		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: -0.008474799181403257 | validation: -0.015782237179352447]
	TIME [epoch: 8.37 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026079226950774634		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: -0.0026079226950774634 | validation: -0.006547111344056646]
	TIME [epoch: 8.36 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010086868654205956		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.010086868654205956 | validation: 0.0016350293258384934]
	TIME [epoch: 8.4 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009273504960985033		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.009273504960985033 | validation: -0.010926578589604342]
	TIME [epoch: 8.37 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000924654644729008		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.000924654644729008 | validation: -0.01055414215782434]
	TIME [epoch: 8.38 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005706092632284049		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: -0.005706092632284049 | validation: -0.01654991234984743]
	TIME [epoch: 124 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: -0.000516359791460064		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: -0.000516359791460064 | validation: -0.004262980092280988]
	TIME [epoch: 19 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0014872142291155932		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: -0.0014872142291155932 | validation: -0.011223537464938815]
	TIME [epoch: 18.9 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00427213905277935		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: -0.00427213905277935 | validation: -0.010003256170670192]
	TIME [epoch: 18.9 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006435998469915814		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: -0.006435998469915814 | validation: -0.021391419089567314]
	TIME [epoch: 18.9 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0035778519525647033		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: -0.0035778519525647033 | validation: -0.011457749891928132]
	TIME [epoch: 18.9 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0007823809512936162		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: -0.0007823809512936162 | validation: -0.008716630324933902]
	TIME [epoch: 18.9 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: -1.7420826797851597e-05		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: -1.7420826797851597e-05 | validation: -0.003048435121485892]
	TIME [epoch: 18.9 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004186726223927064		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: -0.004186726223927064 | validation: -0.006217482272926766]
	TIME [epoch: 18.8 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007256476976252613		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: -0.007256476976252613 | validation: -0.009072144993003257]
	TIME [epoch: 18.9 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00806690217338039		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: -0.00806690217338039 | validation: -0.0029001889588946665]
	TIME [epoch: 18.9 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009989763349182602		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: -0.009989763349182602 | validation: -0.007266120403031857]
	TIME [epoch: 19 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0030757761922641097		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: -0.0030757761922641097 | validation: -0.00038540751077155953]
	TIME [epoch: 19 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00041833653708253367		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.00041833653708253367 | validation: 0.002493343235301751]
	TIME [epoch: 18.9 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018842240473013964		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.018842240473013964 | validation: 0.021185458959532697]
	TIME [epoch: 18.9 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02643843186208039		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.02643843186208039 | validation: 0.011083967241940901]
	TIME [epoch: 18.9 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015977413739382967		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.015977413739382967 | validation: 0.00019919304385687979]
	TIME [epoch: 18.9 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015541358113695615		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.015541358113695615 | validation: 0.00217300455081453]
	TIME [epoch: 18.9 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009854906640022382		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.009854906640022382 | validation: 0.009681815395124924]
	TIME [epoch: 19 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016923087765958002		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.016923087765958002 | validation: 0.0032756539946350366]
	TIME [epoch: 18.9 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012804275034435127		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.012804275034435127 | validation: -0.011133573234770232]
	TIME [epoch: 18.9 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0037282960035000647		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.0037282960035000647 | validation: 0.002820994267149125]
	TIME [epoch: 19 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007745453815678162		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.007745453815678162 | validation: -0.005408134509341215]
	TIME [epoch: 18.9 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004113275294167742		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.004113275294167742 | validation: -0.003966623470726856]
	TIME [epoch: 19 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005453312624634763		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.005453312624634763 | validation: -0.0006997464892654683]
	TIME [epoch: 19 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005007076348487485		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.005007076348487485 | validation: -0.0060364443460541335]
	TIME [epoch: 19 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004367448572929423		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: -0.004367448572929423 | validation: -0.010548643840449632]
	TIME [epoch: 18.9 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004633224817421255		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: -0.004633224817421255 | validation: -0.010728431674210653]
	TIME [epoch: 19 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0004236291359523105		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: -0.0004236291359523105 | validation: -0.01543120615811859]
	TIME [epoch: 19 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0019274465627076706		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.0019274465627076706 | validation: -0.010703131686510896]
	TIME [epoch: 19 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0015096320052280544		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.0015096320052280544 | validation: 0.001997639595458186]
	TIME [epoch: 19 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0022087107299039823		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.0022087107299039823 | validation: -0.005116380734108967]
	TIME [epoch: 19 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0032504605753040754		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.0032504605753040754 | validation: -0.006613809787511709]
	TIME [epoch: 19 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007508638850751643		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.007508638850751643 | validation: -0.00023792488553477694]
	TIME [epoch: 19 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0074980236413611945		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.0074980236413611945 | validation: 0.00018380046273026315]
	TIME [epoch: 19 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009957384995126536		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.009957384995126536 | validation: 0.006164851640560716]
	TIME [epoch: 19 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006326932111769073		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.006326932111769073 | validation: -0.008380557249025363]
	TIME [epoch: 19 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005889657148888731		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.005889657148888731 | validation: 0.005045726205182533]
	TIME [epoch: 19 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014273988563396366		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.014273988563396366 | validation: -0.000560176814528736]
	TIME [epoch: 19 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006371572586739826		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.006371572586739826 | validation: -0.0014784875668977838]
	TIME [epoch: 19 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007111415489642397		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.007111415489642397 | validation: -0.007696114217418907]
	TIME [epoch: 19 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005776864755324507		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.005776864755324507 | validation: -0.0030049470336670284]
	TIME [epoch: 19 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012571759073778542		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.012571759073778542 | validation: -0.00013044511050670684]
	TIME [epoch: 19 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00957148749881937		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.00957148749881937 | validation: -0.01231118963903733]
	TIME [epoch: 19.1 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00010473779263015046		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: -0.00010473779263015046 | validation: -0.01001153070186423]
	TIME [epoch: 19 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002094058674719386		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: -0.002094058674719386 | validation: -0.015117253020740188]
	TIME [epoch: 19 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002861533394131795		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: -0.002861533394131795 | validation: -0.02276409704624733]
	TIME [epoch: 19 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0028921702119124445		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: -0.0028921702119124445 | validation: -0.004582011358021403]
	TIME [epoch: 19 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002419658121281414		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.002419658121281414 | validation: 0.0048466630129434165]
	TIME [epoch: 19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004232944863007706		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.004232944863007706 | validation: 0.0017056704525685957]
	TIME [epoch: 19 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005923889488963454		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.005923889488963454 | validation: -0.009497340684899673]
	TIME [epoch: 19 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005893218664478261		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.005893218664478261 | validation: -0.009737855375028883]
	TIME [epoch: 19 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0025321118089774524		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: -0.0025321118089774524 | validation: -0.012719006090269026]
	TIME [epoch: 19 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007152363907573778		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.007152363907573778 | validation: -0.01523795826371508]
	TIME [epoch: 19 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009507223325537972		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: -0.009507223325537972 | validation: -0.018184733859194845]
	TIME [epoch: 19 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008526993506465273		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: -0.008526993506465273 | validation: -0.017239820977023753]
	TIME [epoch: 19 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013121877197869596		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: -0.013121877197869596 | validation: -0.01521720923098343]
	TIME [epoch: 19 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009222236585487159		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.009222236585487159 | validation: -0.030851151249557344]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_158.pth
	Model improved!!!
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011552657835439234		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.011552657835439234 | validation: -0.018123743868314952]
	TIME [epoch: 18.9 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00849438340825686		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.00849438340825686 | validation: -0.017325365514130386]
	TIME [epoch: 18.9 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007304333607257018		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.007304333607257018 | validation: -0.003627576639277077]
	TIME [epoch: 18.9 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007484302462688025		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.007484302462688025 | validation: -0.01968201572895119]
	TIME [epoch: 18.9 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008339622484970208		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: -0.008339622484970208 | validation: -0.012898997494116502]
	TIME [epoch: 18.9 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006967296225362815		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.006967296225362815 | validation: -0.006881780662162778]
	TIME [epoch: 18.9 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004485018877144347		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: -0.004485018877144347 | validation: -0.008767707758765158]
	TIME [epoch: 18.9 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0070948219438391694		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: -0.0070948219438391694 | validation: -0.008129440310408456]
	TIME [epoch: 18.9 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006772954500819709		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.006772954500819709 | validation: -0.019150465865511307]
	TIME [epoch: 18.9 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005144923448238026		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: -0.005144923448238026 | validation: -0.01072258537800089]
	TIME [epoch: 19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007745872787311489		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.007745872787311489 | validation: -0.011430773074181437]
	TIME [epoch: 18.9 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00713771198753051		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: -0.00713771198753051 | validation: -0.009400505368040055]
	TIME [epoch: 19 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010994382314436854		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: -0.010994382314436854 | validation: -0.016905589617461345]
	TIME [epoch: 18.9 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009711303006555844		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: -0.009711303006555844 | validation: -0.007970188111164926]
	TIME [epoch: 18.9 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00663930111800434		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.00663930111800434 | validation: -0.013557436409751506]
	TIME [epoch: 18.9 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008430864546160271		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.008430864546160271 | validation: -0.02145438525687063]
	TIME [epoch: 18.9 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013088519411048303		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.013088519411048303 | validation: -0.008743380400257121]
	TIME [epoch: 19 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009704134135572941		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: -0.009704134135572941 | validation: -0.02208664018801028]
	TIME [epoch: 18.9 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010013078213885262		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.010013078213885262 | validation: -0.011685935440788442]
	TIME [epoch: 18.9 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0061382963063994845		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: -0.0061382963063994845 | validation: -0.01760433640248423]
	TIME [epoch: 18.9 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010122407496860374		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: -0.010122407496860374 | validation: -0.008604810324498637]
	TIME [epoch: 18.9 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009686893582680508		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: -0.009686893582680508 | validation: -0.0209010921191188]
	TIME [epoch: 18.9 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007631951728963809		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.007631951728963809 | validation: -0.024274146223189023]
	TIME [epoch: 19 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004554304250517517		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.004554304250517517 | validation: -0.008388747380481669]
	TIME [epoch: 18.9 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009301315531586796		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: -0.009301315531586796 | validation: -0.016174059916802208]
	TIME [epoch: 18.9 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006967066805611431		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.006967066805611431 | validation: -0.0033656375936265905]
	TIME [epoch: 18.9 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008124565286455927		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.008124565286455927 | validation: -0.019478794388568154]
	TIME [epoch: 18.9 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0100224670625495		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: -0.0100224670625495 | validation: -0.026814397072534035]
	TIME [epoch: 18.9 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009716990150125582		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: -0.009716990150125582 | validation: -0.01029611162286785]
	TIME [epoch: 18.9 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005330810144957628		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: -0.005330810144957628 | validation: -0.022917736566829654]
	TIME [epoch: 19 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00538360938892408		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.00538360938892408 | validation: -0.017396679170574546]
	TIME [epoch: 18.9 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007627716232744412		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.007627716232744412 | validation: -0.01396214323697014]
	TIME [epoch: 19 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004935830321878411		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.004935830321878411 | validation: -0.011202722835933222]
	TIME [epoch: 18.9 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006434554835452239		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: -0.006434554835452239 | validation: -0.007298233642699379]
	TIME [epoch: 18.9 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003516041496902063		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.003516041496902063 | validation: -0.01255331389331776]
	TIME [epoch: 18.9 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010236670217707923		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.010236670217707923 | validation: -0.013987014719184336]
	TIME [epoch: 19 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0036567872588328647		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.0036567872588328647 | validation: -0.008416163231865169]
	TIME [epoch: 18.9 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006142687857644098		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: -0.006142687857644098 | validation: -0.013533241747733692]
	TIME [epoch: 18.9 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007013182281134197		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.007013182281134197 | validation: -0.019130919583837322]
	TIME [epoch: 18.9 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004978363724033385		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: -0.004978363724033385 | validation: -0.002656745846832996]
	TIME [epoch: 18.9 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005243873239502811		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.005243873239502811 | validation: -0.01526519029709323]
	TIME [epoch: 18.9 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.001557876426150636		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.001557876426150636 | validation: -0.008232842066798873]
	TIME [epoch: 18.9 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00497198627628765		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: -0.00497198627628765 | validation: 0.004164427230914841]
	TIME [epoch: 19 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005870590658077309		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: -0.005870590658077309 | validation: -0.005550050686918117]
	TIME [epoch: 19 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00910125478245461		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.00910125478245461 | validation: -0.018832331517848085]
	TIME [epoch: 18.9 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013324492296176688		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.013324492296176688 | validation: -0.0016967130321421655]
	TIME [epoch: 19 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010332794304100388		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: -0.010332794304100388 | validation: -0.01881111717784465]
	TIME [epoch: 18.9 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008684284787229784		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.008684284787229784 | validation: -0.015069568105148966]
	TIME [epoch: 19 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008861622805371387		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.008861622805371387 | validation: -0.018427399836515486]
	TIME [epoch: 18.9 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0074877541320064805		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: -0.0074877541320064805 | validation: -0.02146187936773613]
	TIME [epoch: 19 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010088359640123546		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.010088359640123546 | validation: -0.009429097043725621]
	TIME [epoch: 18.9 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006174180343118991		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.006174180343118991 | validation: -0.021472806051711136]
	TIME [epoch: 19 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009388033949862078		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: -0.009388033949862078 | validation: -0.014076299722157015]
	TIME [epoch: 19 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010508732022003938		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: -0.010508732022003938 | validation: -0.01829187948038454]
	TIME [epoch: 19 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009588213748043757		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.009588213748043757 | validation: -0.012401273601629823]
	TIME [epoch: 19 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009229491380351021		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.009229491380351021 | validation: -0.01107016387721526]
	TIME [epoch: 19 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01215920848692476		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.01215920848692476 | validation: -0.0142515954660458]
	TIME [epoch: 19 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011873020136618777		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.011873020136618777 | validation: -0.01709382496045178]
	TIME [epoch: 19 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01482086051423427		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.01482086051423427 | validation: -0.024543875372421087]
	TIME [epoch: 19 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012451153778502755		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.012451153778502755 | validation: -0.01969389063582708]
	TIME [epoch: 19.1 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010921483501703109		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.010921483501703109 | validation: -0.023096430058472645]
	TIME [epoch: 19 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008080387877256722		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: -0.008080387877256722 | validation: -0.026928860893447686]
	TIME [epoch: 19 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00926182028174801		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.00926182028174801 | validation: -0.018961792410100924]
	TIME [epoch: 19 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006072185730118581		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.006072185730118581 | validation: -0.016328563032878968]
	TIME [epoch: 19.1 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004942425687030861		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.004942425687030861 | validation: -0.010323160761236261]
	TIME [epoch: 19 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009073741789390022		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.009073741789390022 | validation: -0.017143991062826863]
	TIME [epoch: 19.1 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007427672367976822		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.007427672367976822 | validation: -0.0209791488077034]
	TIME [epoch: 19 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0067552095743080845		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.0067552095743080845 | validation: -0.01657220987641202]
	TIME [epoch: 19.1 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008881847642012724		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.008881847642012724 | validation: -0.025408076677170252]
	TIME [epoch: 19 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010721363946799005		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.010721363946799005 | validation: -0.011138435607958592]
	TIME [epoch: 19.6 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006096092688605432		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.006096092688605432 | validation: -0.017915324471865425]
	TIME [epoch: 19 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0065106476096206635		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.0065106476096206635 | validation: -0.008273903872000433]
	TIME [epoch: 19 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006737314274282048		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.006737314274282048 | validation: -0.024305280794610373]
	TIME [epoch: 19 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003891807493459072		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.003891807493459072 | validation: -0.016473623692278234]
	TIME [epoch: 19 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013301062120688018		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.013301062120688018 | validation: -0.014830126230340865]
	TIME [epoch: 19 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005521586614669366		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.005521586614669366 | validation: -0.013352322037836574]
	TIME [epoch: 19 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01027964870865077		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.01027964870865077 | validation: -0.014195967035940515]
	TIME [epoch: 19 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005538021148567744		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.005538021148567744 | validation: -0.02841433567295534]
	TIME [epoch: 19 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007451189138028431		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.007451189138028431 | validation: -0.01546707042716736]
	TIME [epoch: 19 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01005094701634217		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.01005094701634217 | validation: -0.011385554873855312]
	TIME [epoch: 19.1 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008991085162414012		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.008991085162414012 | validation: -0.013187791179963743]
	TIME [epoch: 19 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007369774496769344		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.007369774496769344 | validation: -0.012441855093623715]
	TIME [epoch: 19 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0091748352007676		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.0091748352007676 | validation: -0.021734667272725345]
	TIME [epoch: 19 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007102045662291827		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.007102045662291827 | validation: -0.01929610163000072]
	TIME [epoch: 19 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006808814243079255		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.006808814243079255 | validation: -0.009710263107679931]
	TIME [epoch: 19 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01102537056102446		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.01102537056102446 | validation: -0.01234988718181548]
	TIME [epoch: 19 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005997673631290131		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.005997673631290131 | validation: -0.01935075031734946]
	TIME [epoch: 19.1 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008476305532498035		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.008476305532498035 | validation: -0.013862928882746164]
	TIME [epoch: 19 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008271718796457217		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.008271718796457217 | validation: -0.01926321057484262]
	TIME [epoch: 19 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003912222608642729		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.003912222608642729 | validation: -0.007605278697336088]
	TIME [epoch: 19 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010174878912201188		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.010174878912201188 | validation: -0.019135683587222327]
	TIME [epoch: 19.1 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00931216029069577		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.00931216029069577 | validation: -0.02493264555815168]
	TIME [epoch: 19 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008958059539092395		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.008958059539092395 | validation: -0.014684507148519967]
	TIME [epoch: 147 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006545704603540406		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.006545704603540406 | validation: -0.020781257848218715]
	TIME [epoch: 41.8 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009633527883329746		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.009633527883329746 | validation: -0.013598834616365817]
	TIME [epoch: 41.8 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008838881563053055		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.008838881563053055 | validation: -0.014334691263399861]
	TIME [epoch: 41.8 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01024709856048315		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.01024709856048315 | validation: -0.015539221046122875]
	TIME [epoch: 41.7 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008046365476145952		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.008046365476145952 | validation: -0.021146812578709054]
	TIME [epoch: 41.8 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011124050345339288		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.011124050345339288 | validation: -0.021588989976071782]
	TIME [epoch: 41.8 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00782478796831664		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: -0.00782478796831664 | validation: -0.02546411329721061]
	TIME [epoch: 41.6 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008739338736842786		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.008739338736842786 | validation: -0.016415482914844702]
	TIME [epoch: 41.7 sec]
	Saving model to: out/model_training/model_algphi2_1a_v_klv2_20241015_172819/states/model_algphi2_1a_v_klv2_259.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 4305.541 seconds.
