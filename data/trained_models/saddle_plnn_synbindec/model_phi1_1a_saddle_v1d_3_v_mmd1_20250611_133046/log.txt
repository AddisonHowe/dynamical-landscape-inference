Args:
Namespace(name='model_phi1_1a_saddle_v1d_3_v_mmd1', outdir='out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1', training_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1d_3/training', validation_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1d_3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05202610045671463, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 38335499

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.423140437762683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.423140437762683 | validation: 6.907923556646558]
	TIME [epoch: 374 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.116239429669441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.116239429669441 | validation: 4.8202863122113175]
	TIME [epoch: 6.23 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.723852658970126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.723852658970126 | validation: 4.524402658574233]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.905114241530047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.905114241530047 | validation: 4.765104025679703]
	TIME [epoch: 6.19 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.473037077877851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.473037077877851 | validation: 3.4654768184236886]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6733464907404993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6733464907404993 | validation: 2.972485655494944]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4130053860124163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4130053860124163 | validation: 2.573031316503033]
	TIME [epoch: 6.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9183198150487235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9183198150487235 | validation: 2.332075446166116]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7866048740334075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7866048740334075 | validation: 2.564404542716424]
	TIME [epoch: 6.19 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558476633364869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.558476633364869 | validation: 2.021948396869292]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.304673689395291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.304673689395291 | validation: 2.437239112212646]
	TIME [epoch: 6.18 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398633695371627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.398633695371627 | validation: 1.9288384804352345]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2665293837758282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2665293837758282 | validation: 2.4204420449030613]
	TIME [epoch: 6.18 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43533483338037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.43533483338037 | validation: 2.2648853904506114]
	TIME [epoch: 6.17 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293596949816833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.293596949816833 | validation: 1.9198004207566277]
	TIME [epoch: 6.17 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.23944969934419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.23944969934419 | validation: 1.9858752815136458]
	TIME [epoch: 6.18 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.140412113568968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.140412113568968 | validation: 2.0033065396799854]
	TIME [epoch: 6.18 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.124149597673207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.124149597673207 | validation: 2.1313511966688665]
	TIME [epoch: 6.17 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.177367436296737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.177367436296737 | validation: 1.8898568762971863]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1026957913114086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1026957913114086 | validation: 1.9696929012487219]
	TIME [epoch: 6.19 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.095288203245179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.095288203245179 | validation: 1.9581058339350197]
	TIME [epoch: 6.18 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.981910894252524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.981910894252524 | validation: 1.786366532237377]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0996365059666897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0996365059666897 | validation: 1.7409980910951526]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.913405681202165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.913405681202165 | validation: 2.022479259666206]
	TIME [epoch: 6.19 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0790737415222984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0790737415222984 | validation: 2.2799099807445726]
	TIME [epoch: 6.18 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.197320674481153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.197320674481153 | validation: 1.7926459662061016]
	TIME [epoch: 6.19 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2102540416598364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2102540416598364 | validation: 2.3893332809567616]
	TIME [epoch: 6.19 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.327754393595731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.327754393595731 | validation: 1.918457289507593]
	TIME [epoch: 6.18 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9962993610702986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9962993610702986 | validation: 1.823754227727303]
	TIME [epoch: 6.18 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0126092037402064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0126092037402064 | validation: 1.7936740089674554]
	TIME [epoch: 6.18 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9402576837903223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9402576837903223 | validation: 1.8028771758396922]
	TIME [epoch: 6.19 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8669054532748384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8669054532748384 | validation: 1.6421250099198463]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9028876975488398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9028876975488398 | validation: 1.7150812580235164]
	TIME [epoch: 6.18 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8717937011848984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8717937011848984 | validation: 1.8170239938993584]
	TIME [epoch: 6.17 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5841618750530482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5841618750530482 | validation: 1.3446648058272772]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5781985408670618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5781985408670618 | validation: 1.4594591151508585]
	TIME [epoch: 6.19 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2575319076592657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2575319076592657 | validation: 0.9098700828979753]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.097075873494917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.097075873494917 | validation: 1.3955462886156091]
	TIME [epoch: 6.18 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5285960229139424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5285960229139424 | validation: 1.40748078970154]
	TIME [epoch: 6.18 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2698370974086481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2698370974086481 | validation: 1.1619698157776066]
	TIME [epoch: 6.19 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.230054058307635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.230054058307635 | validation: 1.0711575674954508]
	TIME [epoch: 6.19 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2115234822633791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2115234822633791 | validation: 1.2365655872517927]
	TIME [epoch: 6.17 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2269886459257668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2269886459257668 | validation: 1.0451908711063422]
	TIME [epoch: 6.18 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0983935423180335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0983935423180335 | validation: 1.2293346716662978]
	TIME [epoch: 6.19 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.07230293336083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.07230293336083 | validation: 0.7980279987472183]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0702930312350731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0702930312350731 | validation: 0.8618830782534057]
	TIME [epoch: 6.18 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0109200021459601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0109200021459601 | validation: 0.7252960772990943]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9186052751135008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9186052751135008 | validation: 0.7263618657515297]
	TIME [epoch: 6.19 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891504755048508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9891504755048508 | validation: 0.9220027460457423]
	TIME [epoch: 6.18 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8993136017827872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8993136017827872 | validation: 0.9340259203417491]
	TIME [epoch: 6.18 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0092800081763549		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.0092800081763549 | validation: 1.0018159642174231]
	TIME [epoch: 6.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9846337436012341		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.9846337436012341 | validation: 0.9272589396843334]
	TIME [epoch: 6.19 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8508225836212119		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.8508225836212119 | validation: 0.9336118769377009]
	TIME [epoch: 6.18 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9455967489976796		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.9455967489976796 | validation: 0.6316497437819026]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8143530259809871		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.8143530259809871 | validation: 0.7477954850296302]
	TIME [epoch: 6.19 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.853993641994244		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.853993641994244 | validation: 0.6804189090360843]
	TIME [epoch: 6.18 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7616656236931568		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.7616656236931568 | validation: 0.6076889789337883]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7852135076009107		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.7852135076009107 | validation: 0.9742866215955435]
	TIME [epoch: 6.18 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9093704520763253		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.9093704520763253 | validation: 0.8393102879912299]
	TIME [epoch: 6.18 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0694285757689417		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.0694285757689417 | validation: 1.0193690892596485]
	TIME [epoch: 6.18 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9777555941144151		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.9777555941144151 | validation: 0.9587426745217658]
	TIME [epoch: 6.18 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9446269166911035		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.9446269166911035 | validation: 1.0788781326247676]
	TIME [epoch: 6.18 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9385769402658432		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9385769402658432 | validation: 0.8381086880248481]
	TIME [epoch: 6.18 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383323623048393		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7383323623048393 | validation: 0.9034359746974627]
	TIME [epoch: 6.19 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0673958951875158		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.0673958951875158 | validation: 0.6031703959232478]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828599937662525		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 0.6828599937662525 | validation: 0.9249437058565464]
	TIME [epoch: 6.18 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262974298540663		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.7262974298540663 | validation: 0.5778749579713754]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.720003045547125		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.720003045547125 | validation: 0.7960331903033646]
	TIME [epoch: 6.18 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7182157753323755		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.7182157753323755 | validation: 0.7603804111438324]
	TIME [epoch: 6.18 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7584029956842803		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.7584029956842803 | validation: 0.5971667214097797]
	TIME [epoch: 6.17 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228314332677359		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.6228314332677359 | validation: 0.7039527427341361]
	TIME [epoch: 6.17 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7709284978707569		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7709284978707569 | validation: 0.569348991780769]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073113863612818		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6073113863612818 | validation: 0.760070047756106]
	TIME [epoch: 6.19 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205942527602025		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.6205942527602025 | validation: 0.5193870853380902]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5865658866841797		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5865658866841797 | validation: 0.8981479390348053]
	TIME [epoch: 6.19 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7010242773192787		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7010242773192787 | validation: 0.7141420689253126]
	TIME [epoch: 6.17 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876795115434344		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.7876795115434344 | validation: 0.6221436196245949]
	TIME [epoch: 6.17 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968873900652613		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.6968873900652613 | validation: 0.49303598154000494]
	TIME [epoch: 6.17 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110260818092607		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.5110260818092607 | validation: 0.4722338241844197]
	TIME [epoch: 6.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739389295166381		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.739389295166381 | validation: 0.5250948469880137]
	TIME [epoch: 6.19 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7755336709978948		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.7755336709978948 | validation: 0.5771148308375886]
	TIME [epoch: 6.18 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205026911574243		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6205026911574243 | validation: 0.5840239174374022]
	TIME [epoch: 6.17 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.652307336689615		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.652307336689615 | validation: 0.44614448990161926]
	TIME [epoch: 6.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089527083719102		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.5089527083719102 | validation: 0.8692164656872792]
	TIME [epoch: 6.18 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7265559484190316		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.7265559484190316 | validation: 0.453993406919499]
	TIME [epoch: 6.18 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042458989981374		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.6042458989981374 | validation: 0.41410084206398023]
	TIME [epoch: 6.17 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47277104207449205		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.47277104207449205 | validation: 0.5537363383896895]
	TIME [epoch: 6.19 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517393660056628		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.6517393660056628 | validation: 0.47633162300682086]
	TIME [epoch: 6.18 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6245509727563019		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6245509727563019 | validation: 0.4469403253233106]
	TIME [epoch: 6.18 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753687632968508		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4753687632968508 | validation: 0.5299731181401508]
	TIME [epoch: 6.17 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6842243236213155		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6842243236213155 | validation: 0.6149327531821107]
	TIME [epoch: 6.18 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000469382387505		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5000469382387505 | validation: 0.41923601162158197]
	TIME [epoch: 6.18 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138960815126308		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6138960815126308 | validation: 0.5309729548672231]
	TIME [epoch: 6.18 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.476424398473281		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.476424398473281 | validation: 0.42122094582294456]
	TIME [epoch: 6.18 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5930454177643658		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5930454177643658 | validation: 0.515775972700971]
	TIME [epoch: 6.18 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6136772446583777		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.6136772446583777 | validation: 0.5962503309187019]
	TIME [epoch: 6.18 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674377840526731		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.4674377840526731 | validation: 0.6036217735873476]
	TIME [epoch: 6.18 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575693721741953		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.575693721741953 | validation: 0.4991986268022638]
	TIME [epoch: 6.19 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44861833035753645		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.44861833035753645 | validation: 0.6448687471208661]
	TIME [epoch: 6.18 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542153299489119		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.7542153299489119 | validation: 0.5197818237799764]
	TIME [epoch: 6.17 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49443614892374554		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.49443614892374554 | validation: 0.5905206316055226]
	TIME [epoch: 6.18 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013504064925631		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5013504064925631 | validation: 0.4382101598752479]
	TIME [epoch: 6.19 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287589380199749		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5287589380199749 | validation: 0.4856835948022801]
	TIME [epoch: 6.19 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.51399331748537		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.51399331748537 | validation: 0.5470631224690893]
	TIME [epoch: 6.18 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454115725364961		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.5454115725364961 | validation: 0.46030903281643043]
	TIME [epoch: 6.18 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678478486365343		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4678478486365343 | validation: 0.6534740442268518]
	TIME [epoch: 6.18 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.480511379764185		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.480511379764185 | validation: 0.5385262099831851]
	TIME [epoch: 6.19 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4364269872995297		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.4364269872995297 | validation: 0.3469069878734222]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095098166826114		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5095098166826114 | validation: 0.590094436713475]
	TIME [epoch: 6.17 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967875261291549		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.5967875261291549 | validation: 0.37100289890309435]
	TIME [epoch: 6.17 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781718915308915		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.4781718915308915 | validation: 0.45102932104004645]
	TIME [epoch: 6.18 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635968419227663		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4635968419227663 | validation: 0.47724939922719545]
	TIME [epoch: 6.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44941882404050737		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.44941882404050737 | validation: 0.5279474092194072]
	TIME [epoch: 6.17 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522770188796935		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.522770188796935 | validation: 0.49103268630290386]
	TIME [epoch: 6.17 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152980644604092		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.4152980644604092 | validation: 0.3280353197237639]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899736029607171		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.4899736029607171 | validation: 0.4558314913200898]
	TIME [epoch: 6.18 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690971546770813		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.4690971546770813 | validation: 0.3974276844901369]
	TIME [epoch: 6.18 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40701176453666543		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.40701176453666543 | validation: 0.4868425027832565]
	TIME [epoch: 6.17 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5121652932317722		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5121652932317722 | validation: 0.37274876854389416]
	TIME [epoch: 6.19 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47539410824351425		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.47539410824351425 | validation: 0.5731846717789487]
	TIME [epoch: 6.22 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39788242729517437		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.39788242729517437 | validation: 0.26590076376698]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191403338938786		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.4191403338938786 | validation: 0.7194528724021749]
	TIME [epoch: 6.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945880600650763		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.4945880600650763 | validation: 0.37213227546873406]
	TIME [epoch: 6.19 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37733417846970163		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.37733417846970163 | validation: 0.6872166175640029]
	TIME [epoch: 6.18 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151773195827267		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5151773195827267 | validation: 0.43937265476743564]
	TIME [epoch: 6.18 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39549659289236644		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.39549659289236644 | validation: 0.3742578615120805]
	TIME [epoch: 6.19 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.415714830172666		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.415714830172666 | validation: 0.36795653291071306]
	TIME [epoch: 6.19 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32656834753068986		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.32656834753068986 | validation: 0.4897312749318369]
	TIME [epoch: 6.18 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323410575617589		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4323410575617589 | validation: 0.2930654393634078]
	TIME [epoch: 6.18 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3669997012259128		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.3669997012259128 | validation: 0.5230202328195477]
	TIME [epoch: 6.18 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46006970137847286		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.46006970137847286 | validation: 0.267132745007736]
	TIME [epoch: 6.21 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141073012699257		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3141073012699257 | validation: 0.27074999982492404]
	TIME [epoch: 6.19 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49170261091837963		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.49170261091837963 | validation: 0.3232974434579213]
	TIME [epoch: 6.18 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37769770980839446		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.37769770980839446 | validation: 0.3380935385003253]
	TIME [epoch: 6.18 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32746766873743055		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.32746766873743055 | validation: 0.48777179911031965]
	TIME [epoch: 6.18 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764121300622497		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3764121300622497 | validation: 0.3548840426703825]
	TIME [epoch: 6.18 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30671177660956067		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.30671177660956067 | validation: 0.547931766760228]
	TIME [epoch: 6.19 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4014720839890531		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 0.4014720839890531 | validation: 0.3554713405209339]
	TIME [epoch: 6.18 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475439902765298		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3475439902765298 | validation: 0.3230972096584211]
	TIME [epoch: 6.18 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27929811483916733		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.27929811483916733 | validation: 0.2423380057570807]
	TIME [epoch: 6.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718330694414553		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3718330694414553 | validation: 0.55778209775516]
	TIME [epoch: 6.18 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41602062405576007		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.41602062405576007 | validation: 0.35362306567014573]
	TIME [epoch: 6.17 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3807271196780809		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3807271196780809 | validation: 0.2580316125262048]
	TIME [epoch: 6.18 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601177012752224		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.2601177012752224 | validation: 0.47228205500611076]
	TIME [epoch: 6.18 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3406173508290749		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3406173508290749 | validation: 0.3053538227553434]
	TIME [epoch: 6.18 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35181796492163114		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.35181796492163114 | validation: 0.20263681092722596]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26771058613668075		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.26771058613668075 | validation: 0.47169971964397917]
	TIME [epoch: 6.21 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37311204412265403		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.37311204412265403 | validation: 0.2911033645815926]
	TIME [epoch: 6.18 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3222716143629144		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3222716143629144 | validation: 0.2253327560138807]
	TIME [epoch: 6.18 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3633140159280969		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.3633140159280969 | validation: 0.25329234803302203]
	TIME [epoch: 6.19 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30553097106967986		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.30553097106967986 | validation: 0.2650020610981414]
	TIME [epoch: 6.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33028211784949635		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.33028211784949635 | validation: 0.2118994412256912]
	TIME [epoch: 6.18 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24317482923626402		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.24317482923626402 | validation: 0.2911436697622101]
	TIME [epoch: 6.17 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457214298336125		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3457214298336125 | validation: 0.2106429661768759]
	TIME [epoch: 6.17 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25023671111746193		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.25023671111746193 | validation: 0.4828286291771076]
	TIME [epoch: 6.18 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27715141788961045		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.27715141788961045 | validation: 0.28841180793929116]
	TIME [epoch: 6.19 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.343267528243647		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.343267528243647 | validation: 0.2990964262863019]
	TIME [epoch: 6.17 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25432829398597423		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.25432829398597423 | validation: 0.31248262287472967]
	TIME [epoch: 6.17 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3128351422924193		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3128351422924193 | validation: 0.2039619005511641]
	TIME [epoch: 6.17 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23323979890294697		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.23323979890294697 | validation: 0.2100147356341878]
	TIME [epoch: 6.19 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21454484114977498		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 0.21454484114977498 | validation: 0.49424306834749365]
	TIME [epoch: 6.17 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39229925195285614		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.39229925195285614 | validation: 0.38913749656092655]
	TIME [epoch: 6.17 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3169387208869885		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.3169387208869885 | validation: 0.4172409574134882]
	TIME [epoch: 6.19 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2554767075842228		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.2554767075842228 | validation: 0.19937453122773902]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666633141611076		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2666633141611076 | validation: 0.30052497741071743]
	TIME [epoch: 6.19 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3085516674697426		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.3085516674697426 | validation: 0.21281256582445918]
	TIME [epoch: 6.18 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19863288239061347		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.19863288239061347 | validation: 0.2187789248731115]
	TIME [epoch: 6.17 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2903718979552497		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.2903718979552497 | validation: 0.3559327494810002]
	TIME [epoch: 6.17 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3330182127472846		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3330182127472846 | validation: 0.2814325588184996]
	TIME [epoch: 6.19 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29855796864003525		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.29855796864003525 | validation: 0.3543728702389023]
	TIME [epoch: 6.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2169629567545906		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.2169629567545906 | validation: 0.21409236689560407]
	TIME [epoch: 6.17 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21162610243353408		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.21162610243353408 | validation: 0.2747735403667704]
	TIME [epoch: 6.18 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632535033114451		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.3632535033114451 | validation: 0.31799946358107833]
	TIME [epoch: 6.18 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2444227523070373		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2444227523070373 | validation: 0.17001789355037167]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22989016284204428		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.22989016284204428 | validation: 0.371526326883865]
	TIME [epoch: 6.19 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2381684173777921		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 0.2381684173777921 | validation: 0.27005370220912606]
	TIME [epoch: 6.18 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23048633266719926		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.23048633266719926 | validation: 0.3616421764046585]
	TIME [epoch: 6.18 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526890868152891		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.2526890868152891 | validation: 0.24937133955729057]
	TIME [epoch: 6.19 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26609245846761276		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.26609245846761276 | validation: 0.2779230237393928]
	TIME [epoch: 6.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18728579534659356		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.18728579534659356 | validation: 0.29629540283382294]
	TIME [epoch: 6.18 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21582948076823136		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.21582948076823136 | validation: 0.3659035483845395]
	TIME [epoch: 6.21 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31602017137915617		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.31602017137915617 | validation: 0.23107557544493856]
	TIME [epoch: 6.17 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17401560297631696		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.17401560297631696 | validation: 0.2157073442887345]
	TIME [epoch: 6.18 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2789939750204846		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.2789939750204846 | validation: 0.16578410515188174]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1707882298998611		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.1707882298998611 | validation: 0.21982766413510996]
	TIME [epoch: 6.19 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574500784720627		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2574500784720627 | validation: 0.19196814661039205]
	TIME [epoch: 6.18 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766603036008306		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.1766603036008306 | validation: 0.3467303938226395]
	TIME [epoch: 6.19 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2817772839074829		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2817772839074829 | validation: 0.21104861260816615]
	TIME [epoch: 6.19 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1770795991010119		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.1770795991010119 | validation: 0.2857468133954395]
	TIME [epoch: 6.19 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20513929368280198		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.20513929368280198 | validation: 0.2877810216067653]
	TIME [epoch: 6.18 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27072646194512096		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.27072646194512096 | validation: 0.1773175410018145]
	TIME [epoch: 6.18 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19465058213025216		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.19465058213025216 | validation: 0.24286810773588197]
	TIME [epoch: 6.18 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752363389901602		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.18752363389901602 | validation: 0.16849488396860401]
	TIME [epoch: 6.19 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18472249973133806		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.18472249973133806 | validation: 0.1809642089457002]
	TIME [epoch: 6.19 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2315426458766345		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2315426458766345 | validation: 0.19362099889141077]
	TIME [epoch: 6.18 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328517543748352		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.15328517543748352 | validation: 0.17954817578590632]
	TIME [epoch: 6.19 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24582010936498394		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.24582010936498394 | validation: 0.21343217992048583]
	TIME [epoch: 6.18 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15838077569605657		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.15838077569605657 | validation: 0.24521836603059968]
	TIME [epoch: 6.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22473344810848153		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.22473344810848153 | validation: 0.22595850660478312]
	TIME [epoch: 6.19 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497528485681778		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.1497528485681778 | validation: 0.13265817860005227]
	TIME [epoch: 6.19 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13426762396957628		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.13426762396957628 | validation: 0.24074816943589322]
	TIME [epoch: 397 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1604757411003919		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.1604757411003919 | validation: 0.2046031417348383]
	TIME [epoch: 12.2 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20527425431946095		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.20527425431946095 | validation: 0.2741005002235314]
	TIME [epoch: 12.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26219319421293613		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.26219319421293613 | validation: 0.19617875932036882]
	TIME [epoch: 12.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838412797866353		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.13838412797866353 | validation: 0.11974762628510319]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1982122391739888		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1982122391739888 | validation: 0.1954680603316905]
	TIME [epoch: 12.2 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502729170845832		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.1502729170845832 | validation: 0.16426647211717435]
	TIME [epoch: 12.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130525330291583		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.12130525330291583 | validation: 0.18312570193883848]
	TIME [epoch: 12.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553553650111514		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.1553553650111514 | validation: 0.1760698999486672]
	TIME [epoch: 12.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519218602540172		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.2519218602540172 | validation: 0.21744114147356075]
	TIME [epoch: 12.2 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15305172127462177		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.15305172127462177 | validation: 0.23023095716403397]
	TIME [epoch: 12.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19116868199993226		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.19116868199993226 | validation: 0.12544639581643963]
	TIME [epoch: 12.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15374144216288999		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.15374144216288999 | validation: 0.18104804184498943]
	TIME [epoch: 12.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1677931082920743		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.1677931082920743 | validation: 0.19667971412550653]
	TIME [epoch: 12.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357735446588192		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1357735446588192 | validation: 0.17187040517667396]
	TIME [epoch: 12.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19333152164807832		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.19333152164807832 | validation: 0.21060273646122202]
	TIME [epoch: 12.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18348381575225514		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.18348381575225514 | validation: 0.19210739173627245]
	TIME [epoch: 12.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.175771974785068		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.175771974785068 | validation: 0.13123731411365666]
	TIME [epoch: 12.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11312775365108099		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.11312775365108099 | validation: 0.31293917565278695]
	TIME [epoch: 12.2 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17379744878994646		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.17379744878994646 | validation: 0.17624649145815452]
	TIME [epoch: 12.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18435518853884403		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.18435518853884403 | validation: 0.14725116756254758]
	TIME [epoch: 12.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17101406152633072		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.17101406152633072 | validation: 0.17474706820139763]
	TIME [epoch: 12.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067978416412238		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.13067978416412238 | validation: 0.16354215674887224]
	TIME [epoch: 12.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16451302298470466		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.16451302298470466 | validation: 0.14837954769316664]
	TIME [epoch: 12.1 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1315216138505127		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.1315216138505127 | validation: 0.17215814643013885]
	TIME [epoch: 12.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490022780878536		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.13490022780878536 | validation: 0.18091267338386108]
	TIME [epoch: 12.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14276062863534575		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.14276062863534575 | validation: 0.2100231651532368]
	TIME [epoch: 12.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15846436305613137		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.15846436305613137 | validation: 0.2073641525124651]
	TIME [epoch: 12.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13232211050243217		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.13232211050243217 | validation: 0.12073209805293833]
	TIME [epoch: 12.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11719487124062378		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.11719487124062378 | validation: 0.21356207498307217]
	TIME [epoch: 12.2 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21343086533523167		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.21343086533523167 | validation: 0.12858781256886595]
	TIME [epoch: 12.2 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09539730489241469		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.09539730489241469 | validation: 0.2206853612517558]
	TIME [epoch: 12.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15409934250828924		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.15409934250828924 | validation: 0.15445167909517593]
	TIME [epoch: 12.2 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17970635349953484		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.17970635349953484 | validation: 0.14841852985993897]
	TIME [epoch: 12.2 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11624322477205856		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.11624322477205856 | validation: 0.1715840825572331]
	TIME [epoch: 12.2 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17595409990177754		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.17595409990177754 | validation: 0.09929025411264522]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09461352333359693		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.09461352333359693 | validation: 0.14183144474074677]
	TIME [epoch: 12.2 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12178707754115659		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.12178707754115659 | validation: 0.13734847865362299]
	TIME [epoch: 12.2 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13740358047818677		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.13740358047818677 | validation: 0.2358256798944655]
	TIME [epoch: 12.2 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17443903237038533		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.17443903237038533 | validation: 0.18748095411416246]
	TIME [epoch: 12.2 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12482699131198484		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.12482699131198484 | validation: 0.11562519200201365]
	TIME [epoch: 12.2 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14271464071006557		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.14271464071006557 | validation: 0.16235982854735714]
	TIME [epoch: 12.2 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10319163904151737		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.10319163904151737 | validation: 0.1910898501083087]
	TIME [epoch: 12.2 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558551523187223		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.1558551523187223 | validation: 0.10927548325751257]
	TIME [epoch: 12.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21846089974664346		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.21846089974664346 | validation: 0.1715251699217904]
	TIME [epoch: 12.2 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13472066163261096		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.13472066163261096 | validation: 0.16936592655395688]
	TIME [epoch: 12.2 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046813727183043		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.10046813727183043 | validation: 0.11930924114076699]
	TIME [epoch: 12.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10053221272420962		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.10053221272420962 | validation: 0.1363049533899569]
	TIME [epoch: 12.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16732143515555195		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.16732143515555195 | validation: 0.12749906506745265]
	TIME [epoch: 12.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563780085892814		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.08563780085892814 | validation: 0.15951529975310952]
	TIME [epoch: 12.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16486341873222135		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.16486341873222135 | validation: 0.09107958537254948]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757329004995463		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.07757329004995463 | validation: 0.09801844152697319]
	TIME [epoch: 12.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1228166198634659		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.1228166198634659 | validation: 0.25069051641561707]
	TIME [epoch: 12.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16763402244411796		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.16763402244411796 | validation: 0.13665998190625148]
	TIME [epoch: 12.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949872523329573		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.0949872523329573 | validation: 0.09011397539163224]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163530865582017		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.12163530865582017 | validation: 0.29176694704732176]
	TIME [epoch: 12.2 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13498559935861587		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.13498559935861587 | validation: 0.09607512661034831]
	TIME [epoch: 12.2 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08711422136510154		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.08711422136510154 | validation: 0.1802654666670529]
	TIME [epoch: 12.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12018163188144107		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.12018163188144107 | validation: 0.12837215733288462]
	TIME [epoch: 12.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17235001820263246		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17235001820263246 | validation: 0.11161590095130772]
	TIME [epoch: 12.1 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715565624268625		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.06715565624268625 | validation: 0.08946590768547463]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674020604778365		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.11674020604778365 | validation: 0.11161524416842764]
	TIME [epoch: 12.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11757219711654618		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.11757219711654618 | validation: 0.18145347451417243]
	TIME [epoch: 12.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1433337853608116		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.1433337853608116 | validation: 0.12487482686338149]
	TIME [epoch: 12.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867335221328752		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.08867335221328752 | validation: 0.1417490890155193]
	TIME [epoch: 12.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11327794836480279		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.11327794836480279 | validation: 0.09362615985824795]
	TIME [epoch: 12.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15425554110351564		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.15425554110351564 | validation: 0.13094321032205755]
	TIME [epoch: 12.2 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09357342080080192		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.09357342080080192 | validation: 0.16278363412050276]
	TIME [epoch: 12.1 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133508603866491		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.133508603866491 | validation: 0.11025292846276873]
	TIME [epoch: 12.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0920541732171364		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.0920541732171364 | validation: 0.10112717369960689]
	TIME [epoch: 12.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09512304036070524		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.09512304036070524 | validation: 0.10856344051751382]
	TIME [epoch: 12.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918441741826099		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.10918441741826099 | validation: 0.2467197285588706]
	TIME [epoch: 12.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13210235929735217		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.13210235929735217 | validation: 0.08893906632992983]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11939466180095012		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.11939466180095012 | validation: 0.11793801191069996]
	TIME [epoch: 12.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10017944082900863		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.10017944082900863 | validation: 0.11648940937004965]
	TIME [epoch: 12.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10069819683919462		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.10069819683919462 | validation: 0.14932552324112658]
	TIME [epoch: 12.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14190608870368604		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.14190608870368604 | validation: 0.1306238625226519]
	TIME [epoch: 12.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592438808005015		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.08592438808005015 | validation: 0.1523574033675113]
	TIME [epoch: 12.2 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11969916988717373		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.11969916988717373 | validation: 0.09291545726113667]
	TIME [epoch: 12.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10329942117894401		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.10329942117894401 | validation: 0.11724916722599568]
	TIME [epoch: 12.2 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10214859042704583		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.10214859042704583 | validation: 0.12583797830471016]
	TIME [epoch: 12.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09872289827882931		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.09872289827882931 | validation: 0.13369668101686777]
	TIME [epoch: 12.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0981721504616592		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.0981721504616592 | validation: 0.13927549845951226]
	TIME [epoch: 12.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13946087719452716		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.13946087719452716 | validation: 0.12681201759311228]
	TIME [epoch: 12.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08799828056590019		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.08799828056590019 | validation: 0.09490021578371641]
	TIME [epoch: 12.2 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12289859528234756		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.12289859528234756 | validation: 0.1391766721614442]
	TIME [epoch: 12.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10393774956804348		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.10393774956804348 | validation: 0.14193936198483645]
	TIME [epoch: 12.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556211927419443		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.09556211927419443 | validation: 0.13965688146411545]
	TIME [epoch: 12.2 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006353251625242		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.11006353251625242 | validation: 0.11957373694700296]
	TIME [epoch: 12.2 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08505274279601012		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.08505274279601012 | validation: 0.14770807239095607]
	TIME [epoch: 12.2 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11851381366756836		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.11851381366756836 | validation: 0.11413603543961442]
	TIME [epoch: 12.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09633739737966497		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.09633739737966497 | validation: 0.09146867097429079]
	TIME [epoch: 12.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08417031826347257		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.08417031826347257 | validation: 0.11021113521873174]
	TIME [epoch: 12.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08758089974580668		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.08758089974580668 | validation: 0.15800753841836881]
	TIME [epoch: 12.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13527448470203285		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.13527448470203285 | validation: 0.13256793859904037]
	TIME [epoch: 12.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909311672260733		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.0909311672260733 | validation: 0.10558076958023424]
	TIME [epoch: 12.2 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411594189429477		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.10411594189429477 | validation: 0.08895192606894306]
	TIME [epoch: 12.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09110558000827854		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.09110558000827854 | validation: 0.09134687416816817]
	TIME [epoch: 12.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09498756059039935		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.09498756059039935 | validation: 0.2021301885315816]
	TIME [epoch: 12.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1082970558467787		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1082970558467787 | validation: 0.09694194737523462]
	TIME [epoch: 12.2 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08132385989718875		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.08132385989718875 | validation: 0.15943339650700836]
	TIME [epoch: 12.2 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11817897606778471		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.11817897606778471 | validation: 0.15573376593565225]
	TIME [epoch: 12.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0892876119798907		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.0892876119798907 | validation: 0.09239059007914188]
	TIME [epoch: 12.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06713280092270713		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.06713280092270713 | validation: 0.08861240550852112]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15565117939190787		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.15565117939190787 | validation: 0.2023283160194268]
	TIME [epoch: 12.2 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522201348452802		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.10522201348452802 | validation: 0.08801301412912674]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06766320212285815		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.06766320212285815 | validation: 0.07711561178637084]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914206697301117		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.09914206697301117 | validation: 0.14367199033585767]
	TIME [epoch: 12.2 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08988936151165888		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.08988936151165888 | validation: 0.10071814314938538]
	TIME [epoch: 12.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09438754125607482		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.09438754125607482 | validation: 0.08438560991549078]
	TIME [epoch: 12.2 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797674429524998		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.0797674429524998 | validation: 0.15179393580366296]
	TIME [epoch: 12.2 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09151734518177675		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.09151734518177675 | validation: 0.09194345304259861]
	TIME [epoch: 12.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450788928795152		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.07450788928795152 | validation: 0.1017620109779556]
	TIME [epoch: 12.2 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09075379558587743		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.09075379558587743 | validation: 0.08065476034387874]
	TIME [epoch: 12.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08361674014282156		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.08361674014282156 | validation: 0.0948183186197146]
	TIME [epoch: 12.2 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09842556158236393		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.09842556158236393 | validation: 0.14465498849455316]
	TIME [epoch: 12.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09124474975826254		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.09124474975826254 | validation: 0.11474010638687737]
	TIME [epoch: 12.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644305245489666		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.07644305245489666 | validation: 0.07870825147642027]
	TIME [epoch: 12.1 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08960250672059594		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.08960250672059594 | validation: 0.10824257538238402]
	TIME [epoch: 12.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07466201229387479		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.07466201229387479 | validation: 0.08686936914639418]
	TIME [epoch: 12.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10880979527446438		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.10880979527446438 | validation: 0.09852980909874878]
	TIME [epoch: 12.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10635414092676047		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.10635414092676047 | validation: 0.11064625329194759]
	TIME [epoch: 12.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0702909366354656		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.0702909366354656 | validation: 0.09945977290721411]
	TIME [epoch: 12.2 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1019073103938668		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.1019073103938668 | validation: 0.08869329611613602]
	TIME [epoch: 12.1 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07186207724584802		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.07186207724584802 | validation: 0.09039177316472985]
	TIME [epoch: 12.2 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944258077279615		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.07944258077279615 | validation: 0.08360593209833814]
	TIME [epoch: 12.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07652477460949546		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.07652477460949546 | validation: 0.13737987522109968]
	TIME [epoch: 12.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11516670058545501		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.11516670058545501 | validation: 0.13121030040659523]
	TIME [epoch: 12.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07434513769710795		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.07434513769710795 | validation: 0.07921580844883536]
	TIME [epoch: 12.2 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07547521923911882		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.07547521923911882 | validation: 0.10370005234622329]
	TIME [epoch: 12.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06538240572355407		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.06538240572355407 | validation: 0.08810613577221746]
	TIME [epoch: 12.2 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11880512204306415		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.11880512204306415 | validation: 0.06743409324587513]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478628083235588		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.07478628083235588 | validation: 0.1514334388938271]
	TIME [epoch: 12.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10351839069823897		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.10351839069823897 | validation: 0.08322016437831428]
	TIME [epoch: 12.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07745237512468152		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.07745237512468152 | validation: 0.07948822950075898]
	TIME [epoch: 12.2 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07082308310584956		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.07082308310584956 | validation: 0.10603727623483622]
	TIME [epoch: 12.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174092511573301		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.08174092511573301 | validation: 0.0721876328611089]
	TIME [epoch: 12.2 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08162613684025388		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.08162613684025388 | validation: 0.09469448468719943]
	TIME [epoch: 12.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818593328158241		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.07818593328158241 | validation: 0.14493285629827868]
	TIME [epoch: 12.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10399558785499506		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.10399558785499506 | validation: 0.06356854362751925]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05782879059411824		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.05782879059411824 | validation: 0.06799157114134076]
	TIME [epoch: 12.2 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103517866567466		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.07103517866567466 | validation: 0.09398860703880195]
	TIME [epoch: 12.2 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06959283886073754		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.06959283886073754 | validation: 0.06789741711870746]
	TIME [epoch: 12.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075909704740218		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.1075909704740218 | validation: 0.07229908441197615]
	TIME [epoch: 12.2 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05913940468319977		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.05913940468319977 | validation: 0.11424986193985238]
	TIME [epoch: 12.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07014412439270454		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.07014412439270454 | validation: 0.08068261743132595]
	TIME [epoch: 12.2 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0834253005346441		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.0834253005346441 | validation: 0.0808169255099131]
	TIME [epoch: 12.2 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090864475780061		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.06090864475780061 | validation: 0.13175170282497595]
	TIME [epoch: 12.2 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087914674024199		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.1087914674024199 | validation: 0.10133287533963518]
	TIME [epoch: 12.2 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06960514278886784		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.06960514278886784 | validation: 0.07781479194000243]
	TIME [epoch: 12.2 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08836570607771851		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.08836570607771851 | validation: 0.06709150271496572]
	TIME [epoch: 12.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05782216319007423		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.05782216319007423 | validation: 0.0751310563837487]
	TIME [epoch: 12.2 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06644026001093616		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.06644026001093616 | validation: 0.10781214082029517]
	TIME [epoch: 12.2 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479844798269364		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.07479844798269364 | validation: 0.07971751683636652]
	TIME [epoch: 12.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1011330994290798		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.1011330994290798 | validation: 0.06386210228234386]
	TIME [epoch: 12.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0587361566860398		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.0587361566860398 | validation: 0.08077695440070978]
	TIME [epoch: 12.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426640003155451		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.09426640003155451 | validation: 0.1255238213983433]
	TIME [epoch: 12.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07249573141117072		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.07249573141117072 | validation: 0.06404593235720808]
	TIME [epoch: 12.2 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787265057875676		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.06787265057875676 | validation: 0.12222540240641974]
	TIME [epoch: 12.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755784014879521		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.0755784014879521 | validation: 0.07188150457187445]
	TIME [epoch: 12.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05862391231905579		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.05862391231905579 | validation: 0.1392402847185446]
	TIME [epoch: 12.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832375779509601		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.07832375779509601 | validation: 0.07309652412118493]
	TIME [epoch: 12.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058678344888510675		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.058678344888510675 | validation: 0.12970221930864956]
	TIME [epoch: 12.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827306249686527		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.11827306249686527 | validation: 0.09591078033247966]
	TIME [epoch: 12.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06606342714733514		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.06606342714733514 | validation: 0.07696569327859984]
	TIME [epoch: 12.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458284145834618		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.06458284145834618 | validation: 0.0649687483504057]
	TIME [epoch: 12.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06504128835996867		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.06504128835996867 | validation: 0.07515679488839141]
	TIME [epoch: 12.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436881101430351		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.06436881101430351 | validation: 0.09792233515284668]
	TIME [epoch: 12.2 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08455227083943333		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.08455227083943333 | validation: 0.0703643641863308]
	TIME [epoch: 12.2 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06854964090263493		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.06854964090263493 | validation: 0.09271771127405973]
	TIME [epoch: 12.2 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07256177645653794		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.07256177645653794 | validation: 0.10010860889889363]
	TIME [epoch: 12.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737212942398851		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.0737212942398851 | validation: 0.07681546750286902]
	TIME [epoch: 12.2 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057991779561434836		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.057991779561434836 | validation: 0.08531812936140876]
	TIME [epoch: 12.2 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07790948395730266		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.07790948395730266 | validation: 0.08200641164856838]
	TIME [epoch: 12.2 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0685602879800944		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.0685602879800944 | validation: 0.08350159940085004]
	TIME [epoch: 12.2 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056722196538241225		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.056722196538241225 | validation: 0.07898374261365035]
	TIME [epoch: 12.2 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06851090410587476		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.06851090410587476 | validation: 0.07112525900233933]
	TIME [epoch: 12.2 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0765360368718912		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.0765360368718912 | validation: 0.10437061803087072]
	TIME [epoch: 12.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07938869454548109		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.07938869454548109 | validation: 0.06727687129565185]
	TIME [epoch: 12.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06573217379859486		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.06573217379859486 | validation: 0.08886999379281182]
	TIME [epoch: 12.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06721607260490822		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.06721607260490822 | validation: 0.0815802418751885]
	TIME [epoch: 12.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07713510673344737		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.07713510673344737 | validation: 0.07766927708814986]
	TIME [epoch: 12.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05710553690401169		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.05710553690401169 | validation: 0.06458813188432289]
	TIME [epoch: 12.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540759538643775		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.05540759538643775 | validation: 0.06953668290632493]
	TIME [epoch: 12.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08057639341826354		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.08057639341826354 | validation: 0.061007162549799696]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09350113519374505		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.09350113519374505 | validation: 0.07137073555518417]
	TIME [epoch: 12.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776733307032107		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.05776733307032107 | validation: 0.08889319927922176]
	TIME [epoch: 12.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06950369317630802		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.06950369317630802 | validation: 0.07047582385733453]
	TIME [epoch: 12.2 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05251506673396804		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.05251506673396804 | validation: 0.0694809200380966]
	TIME [epoch: 12.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07717056619576103		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.07717056619576103 | validation: 0.07713688192612364]
	TIME [epoch: 12.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06990537726283662		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.06990537726283662 | validation: 0.09283737571430586]
	TIME [epoch: 12.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419560910782136		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.06419560910782136 | validation: 0.0724632156449311]
	TIME [epoch: 12.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964859827507381		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.05964859827507381 | validation: 0.10890143205302841]
	TIME [epoch: 12.2 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07283456149032505		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.07283456149032505 | validation: 0.07509028703698065]
	TIME [epoch: 12.2 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05576001775936091		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.05576001775936091 | validation: 0.07496444717319464]
	TIME [epoch: 12.2 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07661345996305255		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.07661345996305255 | validation: 0.07717120846637099]
	TIME [epoch: 12.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361014898212817		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.07361014898212817 | validation: 0.08100287521027555]
	TIME [epoch: 12.1 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069194111460976		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.05069194111460976 | validation: 0.07662681755144551]
	TIME [epoch: 12.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08211485401156474		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.08211485401156474 | validation: 0.0752227424072266]
	TIME [epoch: 12.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05970428820661741		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.05970428820661741 | validation: 0.060685481563226534]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058334231228235		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.07058334231228235 | validation: 0.09855852738981996]
	TIME [epoch: 12.2 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06436296222119095		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.06436296222119095 | validation: 0.062154631492279136]
	TIME [epoch: 12.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786935647831913		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.05786935647831913 | validation: 0.08171010165018243]
	TIME [epoch: 12.1 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06386363999523777		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.06386363999523777 | validation: 0.08580823521071634]
	TIME [epoch: 12.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991033803443953		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.08991033803443953 | validation: 0.07276107052792166]
	TIME [epoch: 12.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06389482146095968		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.06389482146095968 | validation: 0.07358563427327286]
	TIME [epoch: 12.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05663729359640418		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.05663729359640418 | validation: 0.061068889122398384]
	TIME [epoch: 12.1 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976180465908507		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.04976180465908507 | validation: 0.06231681595227928]
	TIME [epoch: 12.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06507685228008102		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.06507685228008102 | validation: 0.09990128855933411]
	TIME [epoch: 12.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07439724597264935		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.07439724597264935 | validation: 0.08020405869771097]
	TIME [epoch: 12.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06899918947553497		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.06899918947553497 | validation: 0.05841971891153458]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05895107711057639		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.05895107711057639 | validation: 0.05497024892715292]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049641880192742294		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.049641880192742294 | validation: 0.06670366534937928]
	TIME [epoch: 12.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06130364772970823		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.06130364772970823 | validation: 0.08640212086315374]
	TIME [epoch: 12.1 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07006417217905277		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.07006417217905277 | validation: 0.07393908965843911]
	TIME [epoch: 12.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662259621333936		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.05662259621333936 | validation: 0.061973803824123375]
	TIME [epoch: 12.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334241634303011		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.05334241634303011 | validation: 0.08288737553098438]
	TIME [epoch: 12.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642452708134251		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.07642452708134251 | validation: 0.06144102730930189]
	TIME [epoch: 12.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05997643735648289		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.05997643735648289 | validation: 0.06721185232024363]
	TIME [epoch: 12.1 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05268973415348955		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.05268973415348955 | validation: 0.051974071984198573]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968898369485864		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.04968898369485864 | validation: 0.0715569379042491]
	TIME [epoch: 12.2 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07772303029452897		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.07772303029452897 | validation: 0.06757415443373083]
	TIME [epoch: 12.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06914888071065459		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.06914888071065459 | validation: 0.08389808044574726]
	TIME [epoch: 12.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431997712222539		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.05431997712222539 | validation: 0.05437190605291714]
	TIME [epoch: 12.1 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048257582761589965		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.048257582761589965 | validation: 0.08093389099937173]
	TIME [epoch: 12.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06961782300539773		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.06961782300539773 | validation: 0.07937194606704631]
	TIME [epoch: 12.2 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057757542898306855		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.057757542898306855 | validation: 0.0847021117644963]
	TIME [epoch: 12.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057123452113599205		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.057123452113599205 | validation: 0.07186184948181264]
	TIME [epoch: 12.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05311459435145743		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.05311459435145743 | validation: 0.0644764109473325]
	TIME [epoch: 12.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07103886975635278		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.07103886975635278 | validation: 0.077606269715965]
	TIME [epoch: 12.2 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05623394343322156		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.05623394343322156 | validation: 0.05685743284132744]
	TIME [epoch: 12.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582671280267239		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.0582671280267239 | validation: 0.0861335376437938]
	TIME [epoch: 12.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05544491826085201		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.05544491826085201 | validation: 0.07320784635594152]
	TIME [epoch: 12.2 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05934382901919423		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.05934382901919423 | validation: 0.08110696675047034]
	TIME [epoch: 12.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06059134924733046		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.06059134924733046 | validation: 0.07737669235130201]
	TIME [epoch: 12.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05536882037394973		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.05536882037394973 | validation: 0.06105004680878275]
	TIME [epoch: 12.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0572286581854002		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.0572286581854002 | validation: 0.06915103708637071]
	TIME [epoch: 12.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350658329349448		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.06350658329349448 | validation: 0.07292939284427338]
	TIME [epoch: 12.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057262277526699976		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.057262277526699976 | validation: 0.06363904471824121]
	TIME [epoch: 12.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053057490233882225		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.053057490233882225 | validation: 0.052290685476521465]
	TIME [epoch: 12.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047769284287183834		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.047769284287183834 | validation: 0.07004755964489667]
	TIME [epoch: 12.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053596509272251465		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.053596509272251465 | validation: 0.06351094326812004]
	TIME [epoch: 12.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07340992188942137		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.07340992188942137 | validation: 0.06434133474649509]
	TIME [epoch: 12.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719436883227656		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.05719436883227656 | validation: 0.06773606536684608]
	TIME [epoch: 12.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04800664572960428		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.04800664572960428 | validation: 0.05669433196864722]
	TIME [epoch: 12.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057042769585681254		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.057042769585681254 | validation: 0.06142766848492847]
	TIME [epoch: 12.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056052653772167345		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.056052653772167345 | validation: 0.08132183990485052]
	TIME [epoch: 12.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07112410715087823		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.07112410715087823 | validation: 0.05642927498562332]
	TIME [epoch: 12.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242765295367519		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.04242765295367519 | validation: 0.07972056010807319]
	TIME [epoch: 12.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06861867525785237		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.06861867525785237 | validation: 0.07890095350049948]
	TIME [epoch: 12.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05825010229826859		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.05825010229826859 | validation: 0.05528276987667142]
	TIME [epoch: 12.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05124476509924046		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.05124476509924046 | validation: 0.05775005922669431]
	TIME [epoch: 12.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0615169692996521		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.0615169692996521 | validation: 0.060476575502866045]
	TIME [epoch: 12.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727824899374568		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.04727824899374568 | validation: 0.054331585728006615]
	TIME [epoch: 12.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04709476024490587		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04709476024490587 | validation: 0.08220369359464108]
	TIME [epoch: 12.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05020852181544906		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.05020852181544906 | validation: 0.08620102316748027]
	TIME [epoch: 12.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775439648734275		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.07775439648734275 | validation: 0.05407942482659901]
	TIME [epoch: 12.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04358731885481802		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.04358731885481802 | validation: 0.07560440153810635]
	TIME [epoch: 12.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05389927017693862		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.05389927017693862 | validation: 0.05931109286681028]
	TIME [epoch: 12.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05856867836366013		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.05856867836366013 | validation: 0.055132846975634836]
	TIME [epoch: 12.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045693069349538346		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.045693069349538346 | validation: 0.09028571091852672]
	TIME [epoch: 12.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929546530133719		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.05929546530133719 | validation: 0.061733301382966496]
	TIME [epoch: 12.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05338402215028514		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.05338402215028514 | validation: 0.07764970636868623]
	TIME [epoch: 12.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055054916443497394		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.055054916443497394 | validation: 0.05679072366739304]
	TIME [epoch: 12.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050235523375007266		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.050235523375007266 | validation: 0.06506666577600889]
	TIME [epoch: 12.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05522529256067553		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.05522529256067553 | validation: 0.052718868974873684]
	TIME [epoch: 12.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04212678193766004		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.04212678193766004 | validation: 0.09547909132221308]
	TIME [epoch: 12.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.070362004448565		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.070362004448565 | validation: 0.07269271460299448]
	TIME [epoch: 12.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927793672076311		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.05927793672076311 | validation: 0.06669542696240317]
	TIME [epoch: 12.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0526035676793056		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.0526035676793056 | validation: 0.06367135501335042]
	TIME [epoch: 12.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05098327324390815		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.05098327324390815 | validation: 0.0511889784842635]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04363731866620956		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.04363731866620956 | validation: 0.108053824025145]
	TIME [epoch: 12.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098994285881098		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.06098994285881098 | validation: 0.052706504664606746]
	TIME [epoch: 12.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050680109106590016		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.050680109106590016 | validation: 0.06422843568820696]
	TIME [epoch: 12.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0635392527486979		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.0635392527486979 | validation: 0.0660362367529162]
	TIME [epoch: 12.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05169082117139316		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.05169082117139316 | validation: 0.054142588470209876]
	TIME [epoch: 12.2 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04958415327468364		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.04958415327468364 | validation: 0.06702704033867615]
	TIME [epoch: 12.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048554781722026166		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.048554781722026166 | validation: 0.058429706691082]
	TIME [epoch: 12.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04867641286245334		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.04867641286245334 | validation: 0.0587011292290401]
	TIME [epoch: 12.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511494581417465		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.05511494581417465 | validation: 0.09705280193832552]
	TIME [epoch: 12.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053580791956708174		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.053580791956708174 | validation: 0.057283367539088595]
	TIME [epoch: 12.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04982056657989623		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.04982056657989623 | validation: 0.04960206412763132]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164512715775965		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.05164512715775965 | validation: 0.05958666971026593]
	TIME [epoch: 12.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044852393290254096		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.044852393290254096 | validation: 0.05825942671190759]
	TIME [epoch: 12.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0531703601276738		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.0531703601276738 | validation: 0.07716843421169606]
	TIME [epoch: 12.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360369380011594		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.05360369380011594 | validation: 0.0635733473386187]
	TIME [epoch: 12.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05265886902608076		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.05265886902608076 | validation: 0.054816341476201486]
	TIME [epoch: 12.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04422597257163644		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.04422597257163644 | validation: 0.07159939441142957]
	TIME [epoch: 12.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060423851216322155		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.060423851216322155 | validation: 0.06290925983394555]
	TIME [epoch: 12.2 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048446939906828884		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.048446939906828884 | validation: 0.06246167502457649]
	TIME [epoch: 12.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548349751314552		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.04548349751314552 | validation: 0.06762671180842787]
	TIME [epoch: 12.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572408916026155		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.04572408916026155 | validation: 0.07533253995737152]
	TIME [epoch: 12.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05959235394889767		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.05959235394889767 | validation: 0.06964715235885445]
	TIME [epoch: 12.2 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047836743835411276		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.047836743835411276 | validation: 0.08123469612252401]
	TIME [epoch: 12.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05125234196985352		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.05125234196985352 | validation: 0.04537763330907646]
	TIME [epoch: 12.2 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04380092614629355		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.04380092614629355 | validation: 0.047581276556995664]
	TIME [epoch: 12.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423603128808355		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.04423603128808355 | validation: 0.05447611725983192]
	TIME [epoch: 12.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04987595315263215		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.04987595315263215 | validation: 0.06898296939118527]
	TIME [epoch: 12.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056715875491334916		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.056715875491334916 | validation: 0.05162752972206115]
	TIME [epoch: 12.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0435430805009906		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.0435430805009906 | validation: 0.052726461045010956]
	TIME [epoch: 12.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326246016086605		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.04326246016086605 | validation: 0.050342959662790045]
	TIME [epoch: 380 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05165852990959774		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.05165852990959774 | validation: 0.07108207259801014]
	TIME [epoch: 26 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05191232148612322		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.05191232148612322 | validation: 0.05938494110788611]
	TIME [epoch: 26 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050405409132462387		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.050405409132462387 | validation: 0.049041075873870923]
	TIME [epoch: 26 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04255225448587855		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.04255225448587855 | validation: 0.054189424245464]
	TIME [epoch: 26 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0480003555010644		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.0480003555010644 | validation: 0.059198834105316886]
	TIME [epoch: 26 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05007454769320964		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.05007454769320964 | validation: 0.053135007718562534]
	TIME [epoch: 26 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260536569729638		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.04260536569729638 | validation: 0.066813431062097]
	TIME [epoch: 26 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04927253060113752		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.04927253060113752 | validation: 0.06127672433271256]
	TIME [epoch: 26 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04729140736465566		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.04729140736465566 | validation: 0.06378821047858033]
	TIME [epoch: 26 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047407473263322245		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.047407473263322245 | validation: 0.0662310717569679]
	TIME [epoch: 26 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052642186005555626		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.052642186005555626 | validation: 0.05165865641547118]
	TIME [epoch: 26 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0419464361383885		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.0419464361383885 | validation: 0.05914327622139877]
	TIME [epoch: 26 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048600555365230516		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.048600555365230516 | validation: 0.056546404359094235]
	TIME [epoch: 26 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04776955624058542		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.04776955624058542 | validation: 0.06077032415301667]
	TIME [epoch: 26 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672033511157879		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.04672033511157879 | validation: 0.06893490477382128]
	TIME [epoch: 26 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045851884753162236		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.045851884753162236 | validation: 0.06116715712596886]
	TIME [epoch: 26 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04489605866887188		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.04489605866887188 | validation: 0.05050084315603102]
	TIME [epoch: 26 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309861265427696		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.04309861265427696 | validation: 0.07748658444746334]
	TIME [epoch: 26 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570975876958402		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.05570975876958402 | validation: 0.05191310286152233]
	TIME [epoch: 26 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0380388868316363		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.0380388868316363 | validation: 0.04665428904180104]
	TIME [epoch: 26 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511346764649697		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.04511346764649697 | validation: 0.0714077603469939]
	TIME [epoch: 26 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770378492934226		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.04770378492934226 | validation: 0.0649791320114681]
	TIME [epoch: 26 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047690695682611625		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.047690695682611625 | validation: 0.06393540303349544]
	TIME [epoch: 26 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04542228335852774		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.04542228335852774 | validation: 0.051304953038166415]
	TIME [epoch: 26 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569909136013743		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.04569909136013743 | validation: 0.05039111663648091]
	TIME [epoch: 26 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044554138889861955		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.044554138889861955 | validation: 0.05580521483877142]
	TIME [epoch: 26 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727591888106281		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.04727591888106281 | validation: 0.05489660023165403]
	TIME [epoch: 26 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04454438457581344		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.04454438457581344 | validation: 0.04947517212637648]
	TIME [epoch: 26 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799861974570021		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.04799861974570021 | validation: 0.05363712573933592]
	TIME [epoch: 26.1 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843472401539703		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.04843472401539703 | validation: 0.05459040742370626]
	TIME [epoch: 26 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044964583017435486		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.044964583017435486 | validation: 0.06457967069249047]
	TIME [epoch: 26 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0511604336757415		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.0511604336757415 | validation: 0.04915510492787295]
	TIME [epoch: 26 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039477430390655266		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.039477430390655266 | validation: 0.04648074026440617]
	TIME [epoch: 26 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083393410792599		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.04083393410792599 | validation: 0.046507925160489516]
	TIME [epoch: 26 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484566461066091		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.0484566461066091 | validation: 0.06798948940372876]
	TIME [epoch: 26 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148942078335163		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.05148942078335163 | validation: 0.049890894347724854]
	TIME [epoch: 26 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04143915372356365		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.04143915372356365 | validation: 0.050436210235540055]
	TIME [epoch: 26 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04589023059172395		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.04589023059172395 | validation: 0.054537050834095574]
	TIME [epoch: 26 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462944955838681		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.04462944955838681 | validation: 0.06298220683123569]
	TIME [epoch: 26 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042987437561136654		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.042987437561136654 | validation: 0.04766591026581499]
	TIME [epoch: 26 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049155838607684355		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.049155838607684355 | validation: 0.056731788723681655]
	TIME [epoch: 26 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583572472799596		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.04583572472799596 | validation: 0.05286953792203296]
	TIME [epoch: 26 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038853476809039875		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.038853476809039875 | validation: 0.04750927853161556]
	TIME [epoch: 26 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046511048199686295		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.046511048199686295 | validation: 0.06165527742985338]
	TIME [epoch: 26 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044065630158450046		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.044065630158450046 | validation: 0.048731278720524907]
	TIME [epoch: 26 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043708322971831935		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.043708322971831935 | validation: 0.05661687333719701]
	TIME [epoch: 26 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042563624047022526		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.042563624047022526 | validation: 0.05794279224985727]
	TIME [epoch: 26 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735592048736905		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.04735592048736905 | validation: 0.0485597766456807]
	TIME [epoch: 26 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039702237998445175		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.039702237998445175 | validation: 0.0576433498669411]
	TIME [epoch: 26 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042480052995228314		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.042480052995228314 | validation: 0.05428825811338553]
	TIME [epoch: 26 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041561725813679805		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.041561725813679805 | validation: 0.045917057248351587]
	TIME [epoch: 26 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04415309416444434		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.04415309416444434 | validation: 0.04859535445446174]
	TIME [epoch: 26 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05060892094294879		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.05060892094294879 | validation: 0.056079670111320985]
	TIME [epoch: 26 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04393119454236036		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.04393119454236036 | validation: 0.04683120072721682]
	TIME [epoch: 26 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03985882699118355		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.03985882699118355 | validation: 0.05497164023666923]
	TIME [epoch: 26 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042378864320965874		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.042378864320965874 | validation: 0.05105856133736502]
	TIME [epoch: 26 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041641649034567414		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.041641649034567414 | validation: 0.04646979597509255]
	TIME [epoch: 26 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854612060449318		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.04854612060449318 | validation: 0.05831957460553314]
	TIME [epoch: 26 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308308579711481		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.04308308579711481 | validation: 0.05566369012465551]
	TIME [epoch: 26 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0409199800667119		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.0409199800667119 | validation: 0.05228031493039467]
	TIME [epoch: 26 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512927690785958		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.04512927690785958 | validation: 0.054960249695927]
	TIME [epoch: 26 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587063378711249		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.04587063378711249 | validation: 0.04591778886910758]
	TIME [epoch: 26 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0428773706690247		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.0428773706690247 | validation: 0.04654690977698857]
	TIME [epoch: 26 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042146630550486515		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.042146630550486515 | validation: 0.0424818433309891]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04068531000323602		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.04068531000323602 | validation: 0.06555928042886798]
	TIME [epoch: 26 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049025893751209824		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.049025893751209824 | validation: 0.05652383648289068]
	TIME [epoch: 26 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04047383364275302		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.04047383364275302 | validation: 0.05073550017552951]
	TIME [epoch: 26 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512726584012905		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.04512726584012905 | validation: 0.048173055795803915]
	TIME [epoch: 26 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678882128149285		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.04678882128149285 | validation: 0.04670472173720055]
	TIME [epoch: 26 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04305474487084744		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.04305474487084744 | validation: 0.0551484327098894]
	TIME [epoch: 26 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976900226550279		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.03976900226550279 | validation: 0.04793213019228734]
	TIME [epoch: 26 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042789415099997605		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.042789415099997605 | validation: 0.05152903707181775]
	TIME [epoch: 26 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042524446620288696		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.042524446620288696 | validation: 0.04526668980464832]
	TIME [epoch: 26 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038232795857876416		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.038232795857876416 | validation: 0.05187909764165218]
	TIME [epoch: 26 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190926044808635		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.04190926044808635 | validation: 0.05426242387991836]
	TIME [epoch: 26 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463992175235015		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0463992175235015 | validation: 0.051359522393894824]
	TIME [epoch: 26 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04140207499480769		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.04140207499480769 | validation: 0.04594881658139359]
	TIME [epoch: 26 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693813169059744		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.03693813169059744 | validation: 0.0429663507188219]
	TIME [epoch: 26 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038063063787819956		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.038063063787819956 | validation: 0.059507576523736894]
	TIME [epoch: 26 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254085667965177		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.04254085667965177 | validation: 0.046107055927192]
	TIME [epoch: 26 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042063357754169535		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.042063357754169535 | validation: 0.045756032920320905]
	TIME [epoch: 26 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774348760706932		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.03774348760706932 | validation: 0.04547353773182004]
	TIME [epoch: 26 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043904087693724766		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.043904087693724766 | validation: 0.04670350390972744]
	TIME [epoch: 26 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04573787606486386		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.04573787606486386 | validation: 0.050740094847608615]
	TIME [epoch: 26 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043316060606707445		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.043316060606707445 | validation: 0.04638482234808883]
	TIME [epoch: 26 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04005419890274004		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.04005419890274004 | validation: 0.04624183058673828]
	TIME [epoch: 26 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0408913528789758		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.0408913528789758 | validation: 0.04654069669951104]
	TIME [epoch: 26 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03977783331665131		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.03977783331665131 | validation: 0.05060518552771216]
	TIME [epoch: 26 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03964787123959215		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.03964787123959215 | validation: 0.05013226384071725]
	TIME [epoch: 26 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951472291175726		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.03951472291175726 | validation: 0.0455424396320739]
	TIME [epoch: 26 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060864937181849		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.04060864937181849 | validation: 0.05297668146084884]
	TIME [epoch: 26 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041802284221187605		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.041802284221187605 | validation: 0.04720333565471377]
	TIME [epoch: 26 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03910241051167514		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.03910241051167514 | validation: 0.054677108213892614]
	TIME [epoch: 26 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040667216590640154		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.040667216590640154 | validation: 0.048298043605272734]
	TIME [epoch: 26 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132018269695839		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.04132018269695839 | validation: 0.041864962651235495]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039348740577462314		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.039348740577462314 | validation: 0.04750255157330113]
	TIME [epoch: 26 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043926016347421465		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.043926016347421465 | validation: 0.06062139627257508]
	TIME [epoch: 26 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038795307063372315		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.038795307063372315 | validation: 0.04795960738878363]
	TIME [epoch: 26 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069101375178176		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.04069101375178176 | validation: 0.05509555256954399]
	TIME [epoch: 26 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040058035460495856		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.040058035460495856 | validation: 0.05121780430572295]
	TIME [epoch: 26 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04040162571740902		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.04040162571740902 | validation: 0.0468363682930088]
	TIME [epoch: 26 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177946824978135		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.04177946824978135 | validation: 0.048003697072452625]
	TIME [epoch: 26 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041162257596726454		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.041162257596726454 | validation: 0.05417672676512447]
	TIME [epoch: 26 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03925264310607357		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.03925264310607357 | validation: 0.04679644834427063]
	TIME [epoch: 26 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512555223645517		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.03512555223645517 | validation: 0.04301772673798]
	TIME [epoch: 26 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041805660729729646		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.041805660729729646 | validation: 0.05731344486310717]
	TIME [epoch: 26 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043502318968617414		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.043502318968617414 | validation: 0.04898072927152447]
	TIME [epoch: 26 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03992200092638427		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.03992200092638427 | validation: 0.05399982829032891]
	TIME [epoch: 26 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153398404914594		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.04153398404914594 | validation: 0.05195253520389361]
	TIME [epoch: 26 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040554413240283985		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.040554413240283985 | validation: 0.04735269215930708]
	TIME [epoch: 26 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039930501740056294		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.039930501740056294 | validation: 0.04603077231615816]
	TIME [epoch: 26 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03669073313894615		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.03669073313894615 | validation: 0.044600585989324634]
	TIME [epoch: 26 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828306723348781		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.03828306723348781 | validation: 0.045848028803941454]
	TIME [epoch: 26 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04461277410958766		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.04461277410958766 | validation: 0.04489637790532439]
	TIME [epoch: 26 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03689733345884968		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.03689733345884968 | validation: 0.04373382640664803]
	TIME [epoch: 26 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734753448848635		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.03734753448848635 | validation: 0.04802426168175293]
	TIME [epoch: 26 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03910788694726251		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.03910788694726251 | validation: 0.05767213133634408]
	TIME [epoch: 26 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04206861209958496		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.04206861209958496 | validation: 0.050291656368753504]
	TIME [epoch: 26 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03825466678277604		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.03825466678277604 | validation: 0.05145987238778969]
	TIME [epoch: 26 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03778007219532847		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.03778007219532847 | validation: 0.047816314910902616]
	TIME [epoch: 26 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038597423180794226		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.038597423180794226 | validation: 0.05011796148473116]
	TIME [epoch: 26 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03652713130507788		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.03652713130507788 | validation: 0.051079939131905235]
	TIME [epoch: 26 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03853222659052215		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.03853222659052215 | validation: 0.04687421395519978]
	TIME [epoch: 26 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038312827565850166		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.038312827565850166 | validation: 0.04700240527279497]
	TIME [epoch: 26 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039641056199026345		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.039641056199026345 | validation: 0.06455836028629822]
	TIME [epoch: 26 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112396239250313		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.04112396239250313 | validation: 0.047061941267321175]
	TIME [epoch: 26 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037805147082044896		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.037805147082044896 | validation: 0.05239188799764367]
	TIME [epoch: 26 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03984116093107675		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.03984116093107675 | validation: 0.04462650445976393]
	TIME [epoch: 26.1 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550207570861494		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.03550207570861494 | validation: 0.05182860268507425]
	TIME [epoch: 26 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909202767343914		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.03909202767343914 | validation: 0.04574298367043217]
	TIME [epoch: 26 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03915051097035224		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.03915051097035224 | validation: 0.05049547274762477]
	TIME [epoch: 26 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750950211190255		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.03750950211190255 | validation: 0.04360649546170341]
	TIME [epoch: 26 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040457219133765834		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.040457219133765834 | validation: 0.043547103213273125]
	TIME [epoch: 26 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530279741905345		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.03530279741905345 | validation: 0.04357371462285814]
	TIME [epoch: 26 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244548325974329		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.04244548325974329 | validation: 0.04191326895102587]
	TIME [epoch: 26 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035484180968068005		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.035484180968068005 | validation: 0.044693841495532086]
	TIME [epoch: 26 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378234045143029		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.0378234045143029 | validation: 0.04213074494351865]
	TIME [epoch: 26 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03868391763201077		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.03868391763201077 | validation: 0.04705023872036308]
	TIME [epoch: 26 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03696369358921458		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.03696369358921458 | validation: 0.04739978023651839]
	TIME [epoch: 26 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03883304079473461		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.03883304079473461 | validation: 0.046531862727508234]
	TIME [epoch: 26 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529240783241029		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.03529240783241029 | validation: 0.04572707480706336]
	TIME [epoch: 26 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693562765714549		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.03693562765714549 | validation: 0.04690275219392707]
	TIME [epoch: 26 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03792407574069586		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.03792407574069586 | validation: 0.05407525159810492]
	TIME [epoch: 26 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403580763863496		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0403580763863496 | validation: 0.0414505708253415]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_645.pth
	Model improved!!!
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033466537514840085		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.033466537514840085 | validation: 0.04267556939042061]
	TIME [epoch: 26 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623303192953184		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.03623303192953184 | validation: 0.05473173035281273]
	TIME [epoch: 26 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997430160794739		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.03997430160794739 | validation: 0.045383885955350804]
	TIME [epoch: 26 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847190685972298		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.03847190685972298 | validation: 0.04076057661307082]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038610862916115485		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.038610862916115485 | validation: 0.05090363744519698]
	TIME [epoch: 26 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03679863175622341		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.03679863175622341 | validation: 0.04660149134841714]
	TIME [epoch: 26 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357891153485953		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.0357891153485953 | validation: 0.04131014663804247]
	TIME [epoch: 26 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671509957325064		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.03671509957325064 | validation: 0.05355978064992155]
	TIME [epoch: 26 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03943535998615035		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.03943535998615035 | validation: 0.05177296981709112]
	TIME [epoch: 26 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037371434308306896		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.037371434308306896 | validation: 0.04701769968484533]
	TIME [epoch: 26 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039279724540420724		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.039279724540420724 | validation: 0.047652709592877485]
	TIME [epoch: 26 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03693303340734849		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.03693303340734849 | validation: 0.05138921680030813]
	TIME [epoch: 26 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039794638746438966		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.039794638746438966 | validation: 0.040632177188489965]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03643580285304434		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.03643580285304434 | validation: 0.043321449361646225]
	TIME [epoch: 26 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03444191605298807		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.03444191605298807 | validation: 0.04399123609952326]
	TIME [epoch: 26 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03580256727413155		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.03580256727413155 | validation: 0.043665179023327706]
	TIME [epoch: 26 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03562820421046033		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.03562820421046033 | validation: 0.04276443214357328]
	TIME [epoch: 26 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532037053375384		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.03532037053375384 | validation: 0.04992758847105884]
	TIME [epoch: 26 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039312885697126924		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.039312885697126924 | validation: 0.04820553814860358]
	TIME [epoch: 26 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365610760108212		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.0365610760108212 | validation: 0.04412363394477319]
	TIME [epoch: 26 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036299051271893715		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.036299051271893715 | validation: 0.0453543064739728]
	TIME [epoch: 26.1 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035314283659925366		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.035314283659925366 | validation: 0.04661771998579115]
	TIME [epoch: 26 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038241964362533805		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.038241964362533805 | validation: 0.04325836443516207]
	TIME [epoch: 26 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035405788051441366		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.035405788051441366 | validation: 0.04662325737266783]
	TIME [epoch: 26 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03552580390031623		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.03552580390031623 | validation: 0.048550644315191155]
	TIME [epoch: 26 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03593429501137621		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.03593429501137621 | validation: 0.043171165751560145]
	TIME [epoch: 26 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530394038575487		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.03530394038575487 | validation: 0.04548421109086369]
	TIME [epoch: 26 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035860542622398156		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.035860542622398156 | validation: 0.049591974655209564]
	TIME [epoch: 26 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03741531212887898		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.03741531212887898 | validation: 0.046336317229405885]
	TIME [epoch: 26 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03945115571488986		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.03945115571488986 | validation: 0.04433316974555992]
	TIME [epoch: 26 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033500177170368545		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.033500177170368545 | validation: 0.04612846172862427]
	TIME [epoch: 26 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550434558166067		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.03550434558166067 | validation: 0.04277375912275297]
	TIME [epoch: 26 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033619525678531624		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.033619525678531624 | validation: 0.04824024621150626]
	TIME [epoch: 26 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03821565535052621		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.03821565535052621 | validation: 0.044472771618012774]
	TIME [epoch: 26 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034645715554921144		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.034645715554921144 | validation: 0.051202276803667186]
	TIME [epoch: 26 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037412368476574205		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.037412368476574205 | validation: 0.04873147538965937]
	TIME [epoch: 26 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03694395551131867		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.03694395551131867 | validation: 0.04565132414448628]
	TIME [epoch: 26 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03695856064966288		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.03695856064966288 | validation: 0.04637849496473166]
	TIME [epoch: 26.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03794069229997357		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.03794069229997357 | validation: 0.047021755956366526]
	TIME [epoch: 26 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035611616070341995		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.035611616070341995 | validation: 0.043939420254558596]
	TIME [epoch: 26 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0344201372453552		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0344201372453552 | validation: 0.0481795724482227]
	TIME [epoch: 26 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04094611570300771		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.04094611570300771 | validation: 0.049756021325185404]
	TIME [epoch: 26 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0353664422986283		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0353664422986283 | validation: 0.0489680446990874]
	TIME [epoch: 26 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034668244247365206		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.034668244247365206 | validation: 0.04399254585697738]
	TIME [epoch: 26 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035426325669062085		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.035426325669062085 | validation: 0.04148856040207197]
	TIME [epoch: 26 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036302601419772276		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.036302601419772276 | validation: 0.045634568481506405]
	TIME [epoch: 26 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473825573090847		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.03473825573090847 | validation: 0.041245545449900015]
	TIME [epoch: 26 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336889145029733		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.03336889145029733 | validation: 0.04463581934401134]
	TIME [epoch: 26 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354317895903916		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0354317895903916 | validation: 0.04138409457452526]
	TIME [epoch: 26 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730991001031971		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.03730991001031971 | validation: 0.05746760178436158]
	TIME [epoch: 26 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03629074707023151		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.03629074707023151 | validation: 0.042532674050006124]
	TIME [epoch: 26 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032471564323673596		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.032471564323673596 | validation: 0.042288825731294805]
	TIME [epoch: 26 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0368164761641365		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.0368164761641365 | validation: 0.04117102237413983]
	TIME [epoch: 26 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03558232801900472		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.03558232801900472 | validation: 0.0460392726531285]
	TIME [epoch: 26 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664759362998726		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.03664759362998726 | validation: 0.043659178313562585]
	TIME [epoch: 26 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036869227570699784		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.036869227570699784 | validation: 0.03937076687425024]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03451653072270565		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.03451653072270565 | validation: 0.04575783954358957]
	TIME [epoch: 26 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03543112838327511		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.03543112838327511 | validation: 0.042517933749573474]
	TIME [epoch: 26 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037846861695963976		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.037846861695963976 | validation: 0.04441393713129507]
	TIME [epoch: 26 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251539656174879		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.03251539656174879 | validation: 0.042708209417782445]
	TIME [epoch: 26 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03597271867096428		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.03597271867096428 | validation: 0.04921108686529349]
	TIME [epoch: 26 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03631289452911933		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.03631289452911933 | validation: 0.04446161765845416]
	TIME [epoch: 26 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477523603286002		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.03477523603286002 | validation: 0.04651897385329162]
	TIME [epoch: 26 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034390014145167		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.034390014145167 | validation: 0.04130346247849902]
	TIME [epoch: 26 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034355067877821874		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.034355067877821874 | validation: 0.04547858815286883]
	TIME [epoch: 26 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033180140504037885		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.033180140504037885 | validation: 0.04639403780049121]
	TIME [epoch: 26 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667935766311192		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.03667935766311192 | validation: 0.05357620802255868]
	TIME [epoch: 26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037629615088172634		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.037629615088172634 | validation: 0.0423396117923956]
	TIME [epoch: 26 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531076954840757		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.03531076954840757 | validation: 0.04409592561525441]
	TIME [epoch: 26 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03486004887527487		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.03486004887527487 | validation: 0.0475348308947053]
	TIME [epoch: 26 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03502285358794998		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.03502285358794998 | validation: 0.0416665149402629]
	TIME [epoch: 26 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431158302669256		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.03431158302669256 | validation: 0.04078622567055296]
	TIME [epoch: 26 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03479416404610584		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.03479416404610584 | validation: 0.046892425287499415]
	TIME [epoch: 26.1 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491767263657625		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.03491767263657625 | validation: 0.04881015495105811]
	TIME [epoch: 26.1 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357448384328112		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.0357448384328112 | validation: 0.04299167427724231]
	TIME [epoch: 26 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03340069597271183		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.03340069597271183 | validation: 0.040825835734068804]
	TIME [epoch: 26 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03468202335105673		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.03468202335105673 | validation: 0.04593718030020619]
	TIME [epoch: 26 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03501268988835468		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.03501268988835468 | validation: 0.04486695043760516]
	TIME [epoch: 26.1 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03427850737252477		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.03427850737252477 | validation: 0.040977206185267664]
	TIME [epoch: 26 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0341463570054721		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.0341463570054721 | validation: 0.04986317342395473]
	TIME [epoch: 26 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035037938780064684		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.035037938780064684 | validation: 0.04141296842215976]
	TIME [epoch: 26 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314982591765395		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.03314982591765395 | validation: 0.04055731401581386]
	TIME [epoch: 26 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033987756093223215		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.033987756093223215 | validation: 0.04617433256063869]
	TIME [epoch: 26 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033585109096850196		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.033585109096850196 | validation: 0.04319742263105898]
	TIME [epoch: 26.1 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623458922285228		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.03623458922285228 | validation: 0.04595566815260786]
	TIME [epoch: 26 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033689876704938254		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.033689876704938254 | validation: 0.039789284725354715]
	TIME [epoch: 26.1 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428032840194285		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.03428032840194285 | validation: 0.04373665617403995]
	TIME [epoch: 26 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03475316084816267		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.03475316084816267 | validation: 0.049540764039127286]
	TIME [epoch: 26 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03469387698222723		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.03469387698222723 | validation: 0.044546165599845436]
	TIME [epoch: 26 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03367365675710862		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.03367365675710862 | validation: 0.045528421097377814]
	TIME [epoch: 26 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034675510031171364		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.034675510031171364 | validation: 0.041034621326640826]
	TIME [epoch: 26 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296067259297939		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.03296067259297939 | validation: 0.043141177512464934]
	TIME [epoch: 26.1 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03374501121245806		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.03374501121245806 | validation: 0.04482037522920981]
	TIME [epoch: 26 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346850747240645		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.03346850747240645 | validation: 0.04408997873842699]
	TIME [epoch: 26 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412401414103399		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.03412401414103399 | validation: 0.045431672773123]
	TIME [epoch: 26 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03394194837529522		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.03394194837529522 | validation: 0.040740326449552104]
	TIME [epoch: 26 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034546796544727865		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.034546796544727865 | validation: 0.042014284244655586]
	TIME [epoch: 26 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03452758705427268		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.03452758705427268 | validation: 0.04468312069977855]
	TIME [epoch: 26 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032401889709968136		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.032401889709968136 | validation: 0.04051216927463448]
	TIME [epoch: 26 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033391673629894654		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.033391673629894654 | validation: 0.04147781488556554]
	TIME [epoch: 26 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031956197405507876		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.031956197405507876 | validation: 0.041695343424812174]
	TIME [epoch: 26 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034579799796441206		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.034579799796441206 | validation: 0.049303111899103344]
	TIME [epoch: 26 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037143714556788096		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.037143714556788096 | validation: 0.0432011315830966]
	TIME [epoch: 26 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03342010118357806		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.03342010118357806 | validation: 0.04348276481273192]
	TIME [epoch: 26 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577720292981763		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.03577720292981763 | validation: 0.04292829192398971]
	TIME [epoch: 26 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033194898839952316		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.033194898839952316 | validation: 0.04390294480170796]
	TIME [epoch: 26.1 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136479975223211		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.03136479975223211 | validation: 0.04358406627105958]
	TIME [epoch: 26.1 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033499462411705955		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.033499462411705955 | validation: 0.042686083931777405]
	TIME [epoch: 26.1 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033961430490829114		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.033961430490829114 | validation: 0.04292092828758805]
	TIME [epoch: 26.1 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184554675010835		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.03184554675010835 | validation: 0.04235356395301109]
	TIME [epoch: 26.1 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0342779979581966		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.0342779979581966 | validation: 0.04287529175574277]
	TIME [epoch: 26.1 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304065049703159		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.03304065049703159 | validation: 0.048272846971116994]
	TIME [epoch: 26 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03329314385753563		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.03329314385753563 | validation: 0.04370802378381729]
	TIME [epoch: 26 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033641277730675		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.033641277730675 | validation: 0.040958108143717156]
	TIME [epoch: 26 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0355514856900586		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.0355514856900586 | validation: 0.045977190143305285]
	TIME [epoch: 26 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032807750718892956		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.032807750718892956 | validation: 0.039986799910437514]
	TIME [epoch: 26 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03210505326623776		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.03210505326623776 | validation: 0.04371135220032282]
	TIME [epoch: 26 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033175664054435276		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.033175664054435276 | validation: 0.041206171904095056]
	TIME [epoch: 26 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282349639285546		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.03282349639285546 | validation: 0.04069695789441808]
	TIME [epoch: 26 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032139060649369416		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.032139060649369416 | validation: 0.04197431698316737]
	TIME [epoch: 26 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033672716832009224		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.033672716832009224 | validation: 0.040746763351045004]
	TIME [epoch: 26 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338383257879756		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0338383257879756 | validation: 0.04200040115597835]
	TIME [epoch: 26 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337557637141491		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.0337557637141491 | validation: 0.04199723305400864]
	TIME [epoch: 26.1 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239403635542894		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.03239403635542894 | validation: 0.04314147785749329]
	TIME [epoch: 26.1 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253099806410123		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.03253099806410123 | validation: 0.0418786822073677]
	TIME [epoch: 26 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033676427280565184		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.033676427280565184 | validation: 0.03873537456578035]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03191436990305595		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.03191436990305595 | validation: 0.04243123614408189]
	TIME [epoch: 26 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200114459062337		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.03200114459062337 | validation: 0.042142910616030954]
	TIME [epoch: 26 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03264436204611914		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.03264436204611914 | validation: 0.04274736559423656]
	TIME [epoch: 26 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032865690649199086		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.032865690649199086 | validation: 0.045629195311757596]
	TIME [epoch: 26 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03356747306081797		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.03356747306081797 | validation: 0.04098094537535155]
	TIME [epoch: 26 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03227525116974587		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.03227525116974587 | validation: 0.03888233007328552]
	TIME [epoch: 26 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234777337348125		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.03234777337348125 | validation: 0.04061679975736082]
	TIME [epoch: 26.1 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03401740418714075		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.03401740418714075 | validation: 0.042446132313176475]
	TIME [epoch: 26 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232732221582576		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.03232732221582576 | validation: 0.044543726954322606]
	TIME [epoch: 26 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030937833446955484		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.030937833446955484 | validation: 0.045401476442645756]
	TIME [epoch: 26 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032652260268703534		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.032652260268703534 | validation: 0.041896552725260716]
	TIME [epoch: 26 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033350961199308554		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.033350961199308554 | validation: 0.04153711696120489]
	TIME [epoch: 26 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036857898104268594		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.036857898104268594 | validation: 0.042699222743056195]
	TIME [epoch: 26 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032820317204194926		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.032820317204194926 | validation: 0.04838230741129099]
	TIME [epoch: 26 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032358453046552285		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.032358453046552285 | validation: 0.03813967438700315]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_786.pth
	Model improved!!!
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0317124860040031		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.0317124860040031 | validation: 0.042788070757985956]
	TIME [epoch: 26 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034852028223449946		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.034852028223449946 | validation: 0.04377515091171361]
	TIME [epoch: 26 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252952584648749		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.03252952584648749 | validation: 0.04222683162511512]
	TIME [epoch: 26 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03435701235454038		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.03435701235454038 | validation: 0.04271480042559153]
	TIME [epoch: 26 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153874388456546		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.03153874388456546 | validation: 0.03948323461692117]
	TIME [epoch: 26 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127406199316978		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.03127406199316978 | validation: 0.04159134249542299]
	TIME [epoch: 26 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031649450300518564		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.031649450300518564 | validation: 0.0440540180516692]
	TIME [epoch: 26 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268792968073816		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.03268792968073816 | validation: 0.042097671836254444]
	TIME [epoch: 26 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03242457210816457		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.03242457210816457 | validation: 0.04330252341288321]
	TIME [epoch: 26 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03238758254083353		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.03238758254083353 | validation: 0.042338782653437546]
	TIME [epoch: 26 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031069989600279322		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.031069989600279322 | validation: 0.044569479050388904]
	TIME [epoch: 26 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032605206054685254		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.032605206054685254 | validation: 0.041838462880243885]
	TIME [epoch: 26.1 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03305398116040763		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.03305398116040763 | validation: 0.04392208688171662]
	TIME [epoch: 26 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150975154434978		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.03150975154434978 | validation: 0.04262870998034529]
	TIME [epoch: 26 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261432836410102		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.03261432836410102 | validation: 0.04152112698144901]
	TIME [epoch: 26 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032842575619344366		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.032842575619344366 | validation: 0.045841794722077]
	TIME [epoch: 26 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032052292743144556		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.032052292743144556 | validation: 0.040945075520886845]
	TIME [epoch: 26.1 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03220469600874734		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.03220469600874734 | validation: 0.04288848011238]
	TIME [epoch: 26 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154611581888946		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.03154611581888946 | validation: 0.042371574703199855]
	TIME [epoch: 26 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033037764577607306		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.033037764577607306 | validation: 0.0418730316174218]
	TIME [epoch: 26 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147717532276282		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.03147717532276282 | validation: 0.04326290199944198]
	TIME [epoch: 26 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032031930420275724		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.032031930420275724 | validation: 0.04317239726778847]
	TIME [epoch: 26 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032673914985563164		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.032673914985563164 | validation: 0.04274540868287712]
	TIME [epoch: 26 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268357572449426		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.03268357572449426 | validation: 0.04412095890140367]
	TIME [epoch: 26 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03326792383736549		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.03326792383736549 | validation: 0.04098009438549896]
	TIME [epoch: 26 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225402873598658		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.03225402873598658 | validation: 0.04023554905949463]
	TIME [epoch: 26 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032823936743180016		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.032823936743180016 | validation: 0.04089164413958928]
	TIME [epoch: 26 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099695826691539		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.03099695826691539 | validation: 0.043737121447578194]
	TIME [epoch: 26 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03275645333947861		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.03275645333947861 | validation: 0.04002213106534454]
	TIME [epoch: 26 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03261696234752836		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.03261696234752836 | validation: 0.04170764997761883]
	TIME [epoch: 26 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032152807202792275		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.032152807202792275 | validation: 0.03933116933259571]
	TIME [epoch: 26 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140093699093304		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.03140093699093304 | validation: 0.03800385328957989]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_818.pth
	Model improved!!!
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03122039832680009		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.03122039832680009 | validation: 0.04223154377666437]
	TIME [epoch: 26 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232667872726162		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.03232667872726162 | validation: 0.04012961930220303]
	TIME [epoch: 26 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03159512592093111		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.03159512592093111 | validation: 0.04095561016101128]
	TIME [epoch: 26 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034068017881384645		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.034068017881384645 | validation: 0.04525770977778172]
	TIME [epoch: 26 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030770237550922026		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.030770237550922026 | validation: 0.04322524010841146]
	TIME [epoch: 26 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03126178667158584		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03126178667158584 | validation: 0.039509332145144085]
	TIME [epoch: 26 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030713629971737166		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.030713629971737166 | validation: 0.040530868879104634]
	TIME [epoch: 26 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030677761980978914		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.030677761980978914 | validation: 0.04081281444369127]
	TIME [epoch: 26 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032162387253193585		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.032162387253193585 | validation: 0.040012518243993]
	TIME [epoch: 26 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313748000197811		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.0313748000197811 | validation: 0.04264577355959555]
	TIME [epoch: 26 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327617192034567		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.0327617192034567 | validation: 0.043548315776330976]
	TIME [epoch: 26 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142547897870861		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.03142547897870861 | validation: 0.04192849723187208]
	TIME [epoch: 26 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030724326926634057		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.030724326926634057 | validation: 0.037804930436654206]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03074106435550855		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.03074106435550855 | validation: 0.04003687129761609]
	TIME [epoch: 26 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03149811884063873		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.03149811884063873 | validation: 0.041195838736384244]
	TIME [epoch: 26 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03141535533300419		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.03141535533300419 | validation: 0.040007086287599386]
	TIME [epoch: 26 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290313232314637		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.03290313232314637 | validation: 0.039666881391959084]
	TIME [epoch: 26 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124046351609202		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.03124046351609202 | validation: 0.038203573726292614]
	TIME [epoch: 26 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029897035903038202		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.029897035903038202 | validation: 0.04411390730556389]
	TIME [epoch: 26 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325858852743176		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.03325858852743176 | validation: 0.039444310866512844]
	TIME [epoch: 26 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031027513273485574		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.031027513273485574 | validation: 0.04099959691094464]
	TIME [epoch: 26 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032930250489257865		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.032930250489257865 | validation: 0.04163887153060594]
	TIME [epoch: 26 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116059833293417		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.03116059833293417 | validation: 0.03742417070011538]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_841.pth
	Model improved!!!
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030763869448982514		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.030763869448982514 | validation: 0.03912699113836139]
	TIME [epoch: 26 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268935658364926		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.03268935658364926 | validation: 0.0383494673581922]
	TIME [epoch: 26 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03051907826182514		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.03051907826182514 | validation: 0.042496769444450286]
	TIME [epoch: 26 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116380543942761		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.03116380543942761 | validation: 0.04431620559981341]
	TIME [epoch: 26 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03296350187233221		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.03296350187233221 | validation: 0.06872173504616799]
	TIME [epoch: 26 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038161760385253755		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.038161760385253755 | validation: 0.04446028633644036]
	TIME [epoch: 26 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03071928676269928		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.03071928676269928 | validation: 0.04484499417901971]
	TIME [epoch: 26 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030201360265217934		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.030201360265217934 | validation: 0.042762278923392835]
	TIME [epoch: 26 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030246026851998342		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.030246026851998342 | validation: 0.04118207959382433]
	TIME [epoch: 26 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030500600912148786		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.030500600912148786 | validation: 0.04050025235546334]
	TIME [epoch: 26 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031162821294378928		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.031162821294378928 | validation: 0.04074331347088749]
	TIME [epoch: 26 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03087168561891908		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03087168561891908 | validation: 0.04138451412268439]
	TIME [epoch: 26 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03193047854223819		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03193047854223819 | validation: 0.03875496636997659]
	TIME [epoch: 26 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02974452815065856		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.02974452815065856 | validation: 0.03930985392624785]
	TIME [epoch: 26 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03046742773784665		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.03046742773784665 | validation: 0.039006141922678844]
	TIME [epoch: 26 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919650839015836		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.02919650839015836 | validation: 0.040879863611269066]
	TIME [epoch: 26 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031316957336189874		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.031316957336189874 | validation: 0.039517806638569596]
	TIME [epoch: 26 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031795070016748965		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.031795070016748965 | validation: 0.039734047548769955]
	TIME [epoch: 26 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140221435953604		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.03140221435953604 | validation: 0.04115970002080592]
	TIME [epoch: 26 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03065204829057461		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.03065204829057461 | validation: 0.04020976486998354]
	TIME [epoch: 26 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03037362076260161		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03037362076260161 | validation: 0.04071449848288668]
	TIME [epoch: 26 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03096560828609583		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.03096560828609583 | validation: 0.039986528920536106]
	TIME [epoch: 26 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03053021154077053		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03053021154077053 | validation: 0.042909009911017]
	TIME [epoch: 26 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03079410638686618		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.03079410638686618 | validation: 0.040030073877332636]
	TIME [epoch: 26 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031458500200092984		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.031458500200092984 | validation: 0.041820884818016116]
	TIME [epoch: 26 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030585193659814554		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.030585193659814554 | validation: 0.03898583012816584]
	TIME [epoch: 26 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03055330719619159		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.03055330719619159 | validation: 0.04403231829518349]
	TIME [epoch: 26 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967405330808391		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.02967405330808391 | validation: 0.04225802727686628]
	TIME [epoch: 26 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142388436497888		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.03142388436497888 | validation: 0.047058642551244534]
	TIME [epoch: 26 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031707886958908756		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.031707886958908756 | validation: 0.038361637440378536]
	TIME [epoch: 26 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048317556557654		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.03048317556557654 | validation: 0.039943033122099104]
	TIME [epoch: 26 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030333361366816084		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.030333361366816084 | validation: 0.039675056292660625]
	TIME [epoch: 26 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170295260233748		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.03170295260233748 | validation: 0.03960737781681169]
	TIME [epoch: 26 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03172910727344598		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.03172910727344598 | validation: 0.04385836223394992]
	TIME [epoch: 26 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03083615936121855		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.03083615936121855 | validation: 0.040115137217079995]
	TIME [epoch: 26 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029935621061372347		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.029935621061372347 | validation: 0.04184224013970787]
	TIME [epoch: 26 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030433629979960915		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.030433629979960915 | validation: 0.036570746832222986]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184555034239131		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.03184555034239131 | validation: 0.03971542986021177]
	TIME [epoch: 26 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03064804059913298		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.03064804059913298 | validation: 0.038983824365727796]
	TIME [epoch: 26 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030737366066200724		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.030737366066200724 | validation: 0.040860097755589624]
	TIME [epoch: 26 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030149347881675177		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.030149347881675177 | validation: 0.036876129978469736]
	TIME [epoch: 26 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03045794154788018		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.03045794154788018 | validation: 0.04248065745194604]
	TIME [epoch: 26 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03077984388331183		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.03077984388331183 | validation: 0.04446978166766896]
	TIME [epoch: 25.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140019156674784		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.03140019156674784 | validation: 0.04064275752971823]
	TIME [epoch: 26 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03085848443972449		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.03085848443972449 | validation: 0.04034933966283134]
	TIME [epoch: 26 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031265443684230225		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.031265443684230225 | validation: 0.04094188954687715]
	TIME [epoch: 26 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030105921356491983		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.030105921356491983 | validation: 0.03885764579556264]
	TIME [epoch: 26 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03065298987839975		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.03065298987839975 | validation: 0.03756992145347834]
	TIME [epoch: 26 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030622701399511378		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.030622701399511378 | validation: 0.04175343489949215]
	TIME [epoch: 26 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0306261371416886		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0306261371416886 | validation: 0.038217207447936566]
	TIME [epoch: 26 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0305753174669121		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0305753174669121 | validation: 0.039678226145939195]
	TIME [epoch: 26 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130414340737434		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.03130414340737434 | validation: 0.04144931611857741]
	TIME [epoch: 26 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030328687392337128		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.030328687392337128 | validation: 0.03976727347094021]
	TIME [epoch: 26 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030617848347466985		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.030617848347466985 | validation: 0.03873451060285325]
	TIME [epoch: 26 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030936038309730105		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.030936038309730105 | validation: 0.03969556288554843]
	TIME [epoch: 26 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030243468488397193		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.030243468488397193 | validation: 0.040583883021270584]
	TIME [epoch: 26 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030748405151683547		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.030748405151683547 | validation: 0.04405071387980376]
	TIME [epoch: 26 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03150723705994293		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03150723705994293 | validation: 0.03875010976729631]
	TIME [epoch: 26 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030963086244864626		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.030963086244864626 | validation: 0.03948131812748926]
	TIME [epoch: 26 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030048190324604818		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.030048190324604818 | validation: 0.04148482446455953]
	TIME [epoch: 26 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03010331806405013		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.03010331806405013 | validation: 0.03936827419834429]
	TIME [epoch: 26 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029412877703877016		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.029412877703877016 | validation: 0.04175185352747844]
	TIME [epoch: 26 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029954073296823116		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.029954073296823116 | validation: 0.04066911531617464]
	TIME [epoch: 26 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03055968730675218		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.03055968730675218 | validation: 0.04244519768917268]
	TIME [epoch: 26 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029887395962628016		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.029887395962628016 | validation: 0.04024237787762238]
	TIME [epoch: 26 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030488415461927452		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.030488415461927452 | validation: 0.03943380315784217]
	TIME [epoch: 26 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029777428690744366		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.029777428690744366 | validation: 0.04023795462857771]
	TIME [epoch: 26 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031125642524706395		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.031125642524706395 | validation: 0.038739373653226994]
	TIME [epoch: 26 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030825859184064594		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.030825859184064594 | validation: 0.0388195546630085]
	TIME [epoch: 26 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02980267007541116		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.02980267007541116 | validation: 0.039843963592485473]
	TIME [epoch: 26 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029468408036109926		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.029468408036109926 | validation: 0.03874011745253175]
	TIME [epoch: 26 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03036325861047654		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.03036325861047654 | validation: 0.045862326932128515]
	TIME [epoch: 26 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030378423118685022		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.030378423118685022 | validation: 0.039558201712561275]
	TIME [epoch: 26 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02951864080960525		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.02951864080960525 | validation: 0.0381609632986151]
	TIME [epoch: 26 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030047375693168663		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.030047375693168663 | validation: 0.03968698864441238]
	TIME [epoch: 26 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168679618146808		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.03168679618146808 | validation: 0.042000775631336425]
	TIME [epoch: 26 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029472818286619757		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.029472818286619757 | validation: 0.04150134300226277]
	TIME [epoch: 26 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030079283805585937		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.030079283805585937 | validation: 0.03923294320238531]
	TIME [epoch: 26 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029885632069816696		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.029885632069816696 | validation: 0.04036310244388511]
	TIME [epoch: 26 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029967755812360594		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.029967755812360594 | validation: 0.040270367349264966]
	TIME [epoch: 26 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029613294157993783		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.029613294157993783 | validation: 0.04027912330269853]
	TIME [epoch: 26 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030630618892125643		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.030630618892125643 | validation: 0.03935399668367079]
	TIME [epoch: 26 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03108368390223573		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.03108368390223573 | validation: 0.03850238691567329]
	TIME [epoch: 26 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029181520899351478		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.029181520899351478 | validation: 0.037730689847882026]
	TIME [epoch: 26 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029508465213749484		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.029508465213749484 | validation: 0.039995876568195046]
	TIME [epoch: 26 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030352726865855467		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.030352726865855467 | validation: 0.04214401109784152]
	TIME [epoch: 26 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03014109776069549		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.03014109776069549 | validation: 0.038795298653275516]
	TIME [epoch: 26 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03034000175968523		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.03034000175968523 | validation: 0.04139941320550339]
	TIME [epoch: 26 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029229755830809494		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.029229755830809494 | validation: 0.03819848591390115]
	TIME [epoch: 26 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030501918107083238		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.030501918107083238 | validation: 0.04271519902730606]
	TIME [epoch: 26 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03007209850978127		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.03007209850978127 | validation: 0.040568543697900986]
	TIME [epoch: 26 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03068683628342144		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.03068683628342144 | validation: 0.03892539457629984]
	TIME [epoch: 26 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030879830177747106		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.030879830177747106 | validation: 0.039109006935129684]
	TIME [epoch: 26 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03060983783245172		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.03060983783245172 | validation: 0.03905957063544935]
	TIME [epoch: 26 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029464569697879202		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.029464569697879202 | validation: 0.03928394912899168]
	TIME [epoch: 26 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029544103156645036		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.029544103156645036 | validation: 0.03750890406449701]
	TIME [epoch: 26 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029469932140428333		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.029469932140428333 | validation: 0.03906016772835741]
	TIME [epoch: 26 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0305470473942215		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0305470473942215 | validation: 0.03913302618290501]
	TIME [epoch: 26 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030366791837693023		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.030366791837693023 | validation: 0.03934124977501783]
	TIME [epoch: 26 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029197084043192156		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.029197084043192156 | validation: 0.03915581327964053]
	TIME [epoch: 26 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02886743139353684		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.02886743139353684 | validation: 0.03765366677733506]
	TIME [epoch: 26 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03054712915286494		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.03054712915286494 | validation: 0.04205520266111844]
	TIME [epoch: 26 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029128128265640423		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.029128128265640423 | validation: 0.039298499675720064]
	TIME [epoch: 26 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028822748214330063		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.028822748214330063 | validation: 0.03993166705337]
	TIME [epoch: 26 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919093187582466		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.02919093187582466 | validation: 0.04057761610413403]
	TIME [epoch: 26 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02917149320727688		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.02917149320727688 | validation: 0.038990492707387664]
	TIME [epoch: 26 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969003686339481		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.02969003686339481 | validation: 0.037952642372151776]
	TIME [epoch: 26 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030074047192281433		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.030074047192281433 | validation: 0.039518046554801414]
	TIME [epoch: 26 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02977406448256241		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.02977406448256241 | validation: 0.0384860721798898]
	TIME [epoch: 26 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029633446792530164		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.029633446792530164 | validation: 0.04067028033821635]
	TIME [epoch: 26 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03091833459964992		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.03091833459964992 | validation: 0.04217137729193028]
	TIME [epoch: 26 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029633147022687434		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.029633147022687434 | validation: 0.0376469996345799]
	TIME [epoch: 26 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028326632840950952		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.028326632840950952 | validation: 0.03780118043064966]
	TIME [epoch: 26 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028806735498547127		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.028806735498547127 | validation: 0.0371716743826494]
	TIME [epoch: 26 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028631064006781032		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.028631064006781032 | validation: 0.0387761604400472]
	TIME [epoch: 26 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029729730504252674		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.029729730504252674 | validation: 0.041625409572937984]
	TIME [epoch: 26 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909144634135752		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.02909144634135752 | validation: 0.03860000197015677]
	TIME [epoch: 26 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029726359502737658		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.029726359502737658 | validation: 0.04078183054334276]
	TIME [epoch: 26 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029449277553722585		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.029449277553722585 | validation: 0.037463488587826804]
	TIME [epoch: 26 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03005814760441916		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.03005814760441916 | validation: 0.03975522732487599]
	TIME [epoch: 26 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029199636967329662		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.029199636967329662 | validation: 0.03976429643592864]
	TIME [epoch: 26 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029864110619977124		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.029864110619977124 | validation: 0.038780508339692675]
	TIME [epoch: 26 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029139098541403133		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.029139098541403133 | validation: 0.039080068943438656]
	TIME [epoch: 26 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02938027456131445		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.02938027456131445 | validation: 0.036845866974087635]
	TIME [epoch: 26 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029512468725806245		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.029512468725806245 | validation: 0.03815447252025096]
	TIME [epoch: 26 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029562682835648703		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.029562682835648703 | validation: 0.037340565702370765]
	TIME [epoch: 26 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028498704038250024		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.028498704038250024 | validation: 0.03908291984844716]
	TIME [epoch: 26 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030075388141808178		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.030075388141808178 | validation: 0.03889913109480219]
	TIME [epoch: 26 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028280371484609		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.028280371484609 | validation: 0.03921956144839684]
	TIME [epoch: 26 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029891847697279567		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.029891847697279567 | validation: 0.03923939183311837]
	TIME [epoch: 26 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029944475371136793		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.029944475371136793 | validation: 0.0401126930641232]
	TIME [epoch: 26 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02918908960670421		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.02918908960670421 | validation: 0.040405632869355994]
	TIME [epoch: 26 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028715957289716		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.028715957289716 | validation: 0.03799668768904921]
	TIME [epoch: 26 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029660850410453573		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.029660850410453573 | validation: 0.03760836582991914]
	TIME [epoch: 26 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028852114051768393		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.028852114051768393 | validation: 0.03797621400612602]
	TIME [epoch: 26 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02870956533070209		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.02870956533070209 | validation: 0.041790473192061806]
	TIME [epoch: 26 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029179747957761244		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.029179747957761244 | validation: 0.03993048153407182]
	TIME [epoch: 26 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028753201220380054		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.028753201220380054 | validation: 0.0382847251176232]
	TIME [epoch: 26 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1d_3_v_mmd1_20250611_133046/states/model_phi1_1a_saddle_v1d_3_v_mmd1_979.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 18562.502 seconds.
