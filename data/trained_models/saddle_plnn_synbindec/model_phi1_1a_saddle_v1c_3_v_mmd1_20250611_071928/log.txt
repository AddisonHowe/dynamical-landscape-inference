Args:
Namespace(name='model_phi1_1a_saddle_v1c_3_v_mmd1', outdir='out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1', training_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1c_3/training', validation_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1c_3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05166919529438019, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1432655771

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.72096607338089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.72096607338089 | validation: 6.665078793102143]
	TIME [epoch: 374 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.392785032750034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.392785032750034 | validation: 6.392710291667605]
	TIME [epoch: 6.18 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.165986669028828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.165986669028828 | validation: 6.386576722047812]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7823422941765985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7823422941765985 | validation: 5.769035247344776]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.805815247668537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.805815247668537 | validation: 5.3035495972309095]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.758909726606059		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.758909726606059 | validation: 4.0135171128602725]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.161390139187635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.161390139187635 | validation: 3.8386226321906545]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022450622651506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.022450622651506 | validation: 3.7085110528451315]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9240436316862977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9240436316862977 | validation: 3.738292691800809]
	TIME [epoch: 6.09 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.90541336917321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.90541336917321 | validation: 3.625334745767586]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8940410139219326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8940410139219326 | validation: 3.5562326244447355]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8135697032699247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8135697032699247 | validation: 3.534692871271208]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.803153075448847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.803153075448847 | validation: 3.5051651423082375]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7351285803031717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7351285803031717 | validation: 3.508975075792445]
	TIME [epoch: 6.09 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7126595687770614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7126595687770614 | validation: 3.4594670663365035]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.629471905847538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.629471905847538 | validation: 3.3473325014895474]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.515159429818203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.515159429818203 | validation: 3.0610695207826186]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1214166909887204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1214166909887204 | validation: 2.7941877686933685]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9287647758121884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9287647758121884 | validation: 2.6663383145505684]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.839432154511628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.839432154511628 | validation: 2.6768731535969184]
	TIME [epoch: 6.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8157756752893546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8157756752893546 | validation: 2.7144123546904853]
	TIME [epoch: 6.09 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.873275330093992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.873275330093992 | validation: 2.6587968770055244]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.812081626944738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.812081626944738 | validation: 2.705370705716546]
	TIME [epoch: 6.09 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799310667892951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.799310667892951 | validation: 2.647252729723379]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8199826181812164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8199826181812164 | validation: 2.7099012704400653]
	TIME [epoch: 6.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.780835195900605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.780835195900605 | validation: 2.5847026842745136]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.620617439530581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.620617439530581 | validation: 2.5189852619540476]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6474310386261104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6474310386261104 | validation: 2.507199529727064]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.518499029406529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.518499029406529 | validation: 2.325754573950699]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4037117969462356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4037117969462356 | validation: 2.4317590813255494]
	TIME [epoch: 6.09 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3299819691696992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3299819691696992 | validation: 2.1006803647038996]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2734905198126154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2734905198126154 | validation: 2.183253886858572]
	TIME [epoch: 6.1 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.080275770380487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.080275770380487 | validation: 1.806850607199174]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9044109954029653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9044109954029653 | validation: 1.6127650416402233]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7775140097120952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7775140097120952 | validation: 1.7740414560458895]
	TIME [epoch: 6.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.582751513585519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.582751513585519 | validation: 1.6352912244100772]
	TIME [epoch: 6.1 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6804515879515216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6804515879515216 | validation: 1.3499720592426026]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2961218186695456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2961218186695456 | validation: 1.2182003296087163]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.173235083869034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.173235083869034 | validation: 1.1258892046795057]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293685365536136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0293685365536136 | validation: 1.1754503449647744]
	TIME [epoch: 6.1 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1840218690278523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1840218690278523 | validation: 1.2296588964566961]
	TIME [epoch: 6.09 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1785566011333086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1785566011333086 | validation: 1.1074546237410678]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9816764296261811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9816764296261811 | validation: 0.8951491723856694]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0029828628947615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0029828628947615 | validation: 0.9306689126704696]
	TIME [epoch: 6.1 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067128743837924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9067128743837924 | validation: 1.0134206217119672]
	TIME [epoch: 6.09 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9444369603656256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9444369603656256 | validation: 1.0435521161047723]
	TIME [epoch: 6.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9264404800168193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9264404800168193 | validation: 1.2205148521636535]
	TIME [epoch: 6.09 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9706281965869178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9706281965869178 | validation: 0.8288956844376693]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339344042439219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7339344042439219 | validation: 0.7266106714741537]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8107697751751723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8107697751751723 | validation: 0.7632956950078302]
	TIME [epoch: 6.09 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7878619342732911		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.7878619342732911 | validation: 0.9992872702101641]
	TIME [epoch: 6.09 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9891343277096859		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.9891343277096859 | validation: 0.7717743040062026]
	TIME [epoch: 6.1 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7955051088376		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.7955051088376 | validation: 0.7358653275192055]
	TIME [epoch: 6.09 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396960290287625		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.6396960290287625 | validation: 0.9035513145075612]
	TIME [epoch: 6.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0092264636911477		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.0092264636911477 | validation: 0.9591546030868107]
	TIME [epoch: 6.09 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186042039827196		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.8186042039827196 | validation: 0.6284209061050055]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790105255121417		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5790105255121417 | validation: 0.5947108529303264]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6669568602217841		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.6669568602217841 | validation: 0.842544487230831]
	TIME [epoch: 6.09 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.867228756625141		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.867228756625141 | validation: 1.1363959081222386]
	TIME [epoch: 6.08 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8812199498184348		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.8812199498184348 | validation: 0.7367655318010773]
	TIME [epoch: 6.09 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5980066324025148		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.5980066324025148 | validation: 0.5420908510987144]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5890994389475779		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5890994389475779 | validation: 0.7439188264021337]
	TIME [epoch: 6.11 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9775323088363992		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.9775323088363992 | validation: 1.019603573788526]
	TIME [epoch: 6.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200709836199174		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.7200709836199174 | validation: 0.5136678087934007]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307193293682071		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.6307193293682071 | validation: 0.8297922979037775]
	TIME [epoch: 6.11 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970571903007601		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 0.6970571903007601 | validation: 0.5991321768619792]
	TIME [epoch: 6.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749466680107576		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.5749466680107576 | validation: 0.7514691348483431]
	TIME [epoch: 6.11 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6711043264434665		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.6711043264434665 | validation: 0.9466022742327016]
	TIME [epoch: 6.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8310384601285874		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.8310384601285874 | validation: 0.681064825239569]
	TIME [epoch: 6.11 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6379622825541317		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.6379622825541317 | validation: 0.5160617431309218]
	TIME [epoch: 6.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120825198800864		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5120825198800864 | validation: 0.44662679195686056]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46202245897600236		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.46202245897600236 | validation: 0.6982368055013082]
	TIME [epoch: 6.12 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6214910846074604		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.6214910846074604 | validation: 0.4296103460025116]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871617503022172		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.5871617503022172 | validation: 0.4900577495501093]
	TIME [epoch: 6.09 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6902891936462714		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6902891936462714 | validation: 0.673918148205345]
	TIME [epoch: 6.08 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454694210037814		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5454694210037814 | validation: 0.5620096192938913]
	TIME [epoch: 6.09 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5693187248096285		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.5693187248096285 | validation: 0.6477692641444801]
	TIME [epoch: 6.09 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678856660204178		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.6678856660204178 | validation: 0.5441813716455037]
	TIME [epoch: 6.08 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5457666276296718		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.5457666276296718 | validation: 0.5736319794518707]
	TIME [epoch: 6.09 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838422043958999		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6838422043958999 | validation: 0.669142972431585]
	TIME [epoch: 6.09 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232268780186846		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5232268780186846 | validation: 0.4061539932838939]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290296692885345		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.5290296692885345 | validation: 0.9271163110728977]
	TIME [epoch: 6.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312932187641295		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.6312932187641295 | validation: 0.6571812453228547]
	TIME [epoch: 6.1 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369816062890313		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.7369816062890313 | validation: 0.4972616415981362]
	TIME [epoch: 6.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600695266371649		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.5600695266371649 | validation: 0.4191282763936456]
	TIME [epoch: 6.1 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603220848772182		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.4603220848772182 | validation: 0.6266460536973787]
	TIME [epoch: 6.1 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921492257589361		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5921492257589361 | validation: 0.6445159149284494]
	TIME [epoch: 6.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5533492360815975		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.5533492360815975 | validation: 0.5000313742973092]
	TIME [epoch: 6.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47982297105991834		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.47982297105991834 | validation: 0.5462683389991171]
	TIME [epoch: 6.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636228477766952		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.636228477766952 | validation: 0.5152256948406531]
	TIME [epoch: 6.11 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468530449414684		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4468530449414684 | validation: 0.523689065674802]
	TIME [epoch: 6.1 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6045088261359772		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.6045088261359772 | validation: 0.5416857141209348]
	TIME [epoch: 6.09 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5448678766319809		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.5448678766319809 | validation: 0.43312019566979487]
	TIME [epoch: 6.08 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153619026805665		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4153619026805665 | validation: 0.5185164271530582]
	TIME [epoch: 6.08 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6737500794060123		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.6737500794060123 | validation: 0.6879242718197749]
	TIME [epoch: 6.08 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.536751980945176		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.536751980945176 | validation: 0.46319609184507926]
	TIME [epoch: 6.09 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4332263516123816		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.4332263516123816 | validation: 0.5541874339309592]
	TIME [epoch: 6.09 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191994401047983		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5191994401047983 | validation: 0.3799186547806465]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4343339731711232		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.4343339731711232 | validation: 0.47492895704991406]
	TIME [epoch: 6.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142293168725273		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5142293168725273 | validation: 0.4717457341807394]
	TIME [epoch: 6.09 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41668502368707083		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.41668502368707083 | validation: 0.5435353788574164]
	TIME [epoch: 6.09 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068800922805723		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5068800922805723 | validation: 0.4413406250372969]
	TIME [epoch: 6.08 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47499561542152235		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.47499561542152235 | validation: 0.6169094164930007]
	TIME [epoch: 6.09 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792222197428014		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.5792222197428014 | validation: 0.3587668472450458]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4732658118495827		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4732658118495827 | validation: 0.6432643669828817]
	TIME [epoch: 6.09 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4636455546421608		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.4636455546421608 | validation: 0.442363608185053]
	TIME [epoch: 6.11 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4099074778887685		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.4099074778887685 | validation: 0.503303172063933]
	TIME [epoch: 6.09 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7879202245368584		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.7879202245368584 | validation: 0.6551564909838665]
	TIME [epoch: 6.09 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630971792713819		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.5630971792713819 | validation: 0.40371517175759153]
	TIME [epoch: 6.08 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4098756204443346		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.4098756204443346 | validation: 0.360539035284579]
	TIME [epoch: 6.09 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.396810262329122		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.396810262329122 | validation: 0.3784003438062673]
	TIME [epoch: 6.09 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47236152785583074		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.47236152785583074 | validation: 0.36662953871666215]
	TIME [epoch: 6.08 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44371544560206955		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.44371544560206955 | validation: 0.6129052621872442]
	TIME [epoch: 6.08 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404305728145656		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5404305728145656 | validation: 0.35073437067400537]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37363704848524243		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.37363704848524243 | validation: 0.47560681418804374]
	TIME [epoch: 6.11 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130238932298316		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.4130238932298316 | validation: 0.47065444023760356]
	TIME [epoch: 6.09 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40127138745923885		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.40127138745923885 | validation: 0.4199502059707396]
	TIME [epoch: 6.09 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4309935207245327		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.4309935207245327 | validation: 0.5426626992147586]
	TIME [epoch: 6.09 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5709210456169364		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5709210456169364 | validation: 0.6185654936893724]
	TIME [epoch: 6.09 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093177515783882		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.5093177515783882 | validation: 0.6205458224053979]
	TIME [epoch: 6.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4563592554216364		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4563592554216364 | validation: 0.27214769618070955]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702422879774918		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3702422879774918 | validation: 0.33422753998145815]
	TIME [epoch: 6.09 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39522932392374815		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.39522932392374815 | validation: 0.41480895426867204]
	TIME [epoch: 6.08 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4181937420286311		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4181937420286311 | validation: 0.32598142551705767]
	TIME [epoch: 6.09 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886437768720844		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.3886437768720844 | validation: 0.4438740171816008]
	TIME [epoch: 6.09 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389191274766853		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.389191274766853 | validation: 0.36087979966632305]
	TIME [epoch: 6.09 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35060956335074833		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.35060956335074833 | validation: 0.5353484048176543]
	TIME [epoch: 6.09 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386223335092511		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3386223335092511 | validation: 0.38743210618624435]
	TIME [epoch: 6.08 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296300369906089		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.4296300369906089 | validation: 0.46611814865362516]
	TIME [epoch: 6.09 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37564032078719817		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.37564032078719817 | validation: 0.4250776550848887]
	TIME [epoch: 6.09 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42721646237366845		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.42721646237366845 | validation: 0.3978848636633929]
	TIME [epoch: 6.09 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35031320856133386		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.35031320856133386 | validation: 0.2769631337891528]
	TIME [epoch: 6.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957788448404516		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3957788448404516 | validation: 0.38350135055226314]
	TIME [epoch: 6.09 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4012756292122679		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.4012756292122679 | validation: 0.41425605939340254]
	TIME [epoch: 6.08 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389020542542401		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.389020542542401 | validation: 0.3616389355670248]
	TIME [epoch: 6.09 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3459972886189937		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.3459972886189937 | validation: 0.3036997243426476]
	TIME [epoch: 6.09 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061793823426613		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.3061793823426613 | validation: 0.39975899366727835]
	TIME [epoch: 6.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901191454733872		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 0.3901191454733872 | validation: 0.36023808327745965]
	TIME [epoch: 6.09 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3663059314033614		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3663059314033614 | validation: 0.36106239099891646]
	TIME [epoch: 6.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851963211459023		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3851963211459023 | validation: 0.397683002424451]
	TIME [epoch: 6.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33243719881369727		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.33243719881369727 | validation: 0.29734974723381546]
	TIME [epoch: 6.09 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754513421962651		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.2754513421962651 | validation: 0.3202188117139526]
	TIME [epoch: 6.09 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4081877745081921		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.4081877745081921 | validation: 0.38471018459441386]
	TIME [epoch: 6.09 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34003546235832055		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.34003546235832055 | validation: 0.2567547139151028]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906296912192011		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.2906296912192011 | validation: 0.46813591149924]
	TIME [epoch: 6.09 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37255102535152734		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.37255102535152734 | validation: 0.2979890282712766]
	TIME [epoch: 6.08 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264006405330367		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3264006405330367 | validation: 0.2709415591953502]
	TIME [epoch: 6.08 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047036981268356		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.3047036981268356 | validation: 0.29221123673852845]
	TIME [epoch: 6.09 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685887816297961		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.2685887816297961 | validation: 0.3588123386948594]
	TIME [epoch: 6.08 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32514697443266005		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.32514697443266005 | validation: 0.3899984390516456]
	TIME [epoch: 6.09 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218373828913057		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.3218373828913057 | validation: 0.38656274817554326]
	TIME [epoch: 6.09 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299897808117259		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3299897808117259 | validation: 0.4053655588678946]
	TIME [epoch: 6.08 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3176403385802982		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3176403385802982 | validation: 1.0809777003741365]
	TIME [epoch: 6.08 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7706354669709152		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.7706354669709152 | validation: 0.4199952954975568]
	TIME [epoch: 6.09 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590840299134947		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.3590840299134947 | validation: 0.34154320219218615]
	TIME [epoch: 6.09 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27690510345172326		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.27690510345172326 | validation: 0.273488760100547]
	TIME [epoch: 6.09 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27973117236730677		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.27973117236730677 | validation: 0.378808361513275]
	TIME [epoch: 6.08 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28976691777722896		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.28976691777722896 | validation: 0.2933537412173718]
	TIME [epoch: 6.09 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3160154629978522		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3160154629978522 | validation: 0.3160178847406582]
	TIME [epoch: 6.09 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627072755909789		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2627072755909789 | validation: 0.2641141566447547]
	TIME [epoch: 6.09 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28046035964293115		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 0.28046035964293115 | validation: 0.2596434373044092]
	TIME [epoch: 6.09 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3102487600412388		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3102487600412388 | validation: 0.2983545649052469]
	TIME [epoch: 6.08 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859496092564933		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.2859496092564933 | validation: 0.26640658802184936]
	TIME [epoch: 6.09 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25149733804556784		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.25149733804556784 | validation: 0.323339866848343]
	TIME [epoch: 6.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3371234968276737		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.3371234968276737 | validation: 0.29507144563090987]
	TIME [epoch: 6.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25549278424275984		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.25549278424275984 | validation: 0.37648546742302746]
	TIME [epoch: 6.09 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24539620188002653		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.24539620188002653 | validation: 0.24407927051723016]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.241203055845637		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.241203055845637 | validation: 0.45720515290994446]
	TIME [epoch: 6.09 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30066673504156644		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.30066673504156644 | validation: 0.32746319588083606]
	TIME [epoch: 6.09 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23327402351549925		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.23327402351549925 | validation: 0.32866648490786154]
	TIME [epoch: 6.08 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28902587478404623		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.28902587478404623 | validation: 0.3064805160916821]
	TIME [epoch: 6.09 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842192332915957		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2842192332915957 | validation: 0.22225207603677694]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24673355691685056		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.24673355691685056 | validation: 0.24306120865192812]
	TIME [epoch: 6.09 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2798510579809653		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2798510579809653 | validation: 0.3799069916207781]
	TIME [epoch: 6.1 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26396272856668895		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.26396272856668895 | validation: 0.3616353921235872]
	TIME [epoch: 6.09 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174958296957951		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 0.2174958296957951 | validation: 0.23977864555686929]
	TIME [epoch: 6.09 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25679571966474585		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.25679571966474585 | validation: 0.1890570525780621]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23214379236881083		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.23214379236881083 | validation: 0.31723461764801925]
	TIME [epoch: 6.11 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23724434365026192		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.23724434365026192 | validation: 0.2910777130239045]
	TIME [epoch: 6.09 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720168830111206		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2720168830111206 | validation: 0.2886842674572593]
	TIME [epoch: 6.08 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22565181787831873		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.22565181787831873 | validation: 0.1926201226549148]
	TIME [epoch: 6.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19258067211065139		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.19258067211065139 | validation: 0.4069165324801701]
	TIME [epoch: 6.09 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3091440864012981		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.3091440864012981 | validation: 0.3177268029247263]
	TIME [epoch: 6.09 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2471674217306945		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.2471674217306945 | validation: 0.288341811748745]
	TIME [epoch: 6.09 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24704202943119735		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.24704202943119735 | validation: 0.2852618227447784]
	TIME [epoch: 6.08 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2580866820901815		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2580866820901815 | validation: 0.23943889485579378]
	TIME [epoch: 6.09 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4200698687680548		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.4200698687680548 | validation: 0.39059285090994555]
	TIME [epoch: 6.09 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828615485566205		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.2828615485566205 | validation: 0.28176502222461697]
	TIME [epoch: 6.08 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21815722392517112		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.21815722392517112 | validation: 0.23520897523914555]
	TIME [epoch: 6.09 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19741605721241468		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.19741605721241468 | validation: 0.22142621645569843]
	TIME [epoch: 6.09 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2445971475737809		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2445971475737809 | validation: 0.23385013025697426]
	TIME [epoch: 6.09 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25810032049383236		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.25810032049383236 | validation: 0.20048845136793783]
	TIME [epoch: 6.09 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194945543702845		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.194945543702845 | validation: 0.27160976585574226]
	TIME [epoch: 6.09 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2398242898396262		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2398242898396262 | validation: 0.22845037873114832]
	TIME [epoch: 6.09 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20237568504516146		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.20237568504516146 | validation: 0.25742038124405636]
	TIME [epoch: 6.08 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2612626886360872		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.2612626886360872 | validation: 0.22429147524998974]
	TIME [epoch: 6.08 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22032820950980578		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.22032820950980578 | validation: 0.24335288507990652]
	TIME [epoch: 6.08 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1999821212850829		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.1999821212850829 | validation: 0.24575697212658232]
	TIME [epoch: 6.09 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22490604154734387		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.22490604154734387 | validation: 0.3123420514004483]
	TIME [epoch: 6.09 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18226008488937445		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.18226008488937445 | validation: 0.21000374373146427]
	TIME [epoch: 6.09 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20324711142197444		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.20324711142197444 | validation: 0.28394855821683584]
	TIME [epoch: 397 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20872307555355252		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.20872307555355252 | validation: 0.23340853020842317]
	TIME [epoch: 12 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22572040189989495		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.22572040189989495 | validation: 0.1872342131909625]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17622377380381943		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.17622377380381943 | validation: 0.238226027357119]
	TIME [epoch: 12 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22231710643494024		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.22231710643494024 | validation: 0.2355487694156576]
	TIME [epoch: 12 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17476330827680342		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.17476330827680342 | validation: 0.2190324369558781]
	TIME [epoch: 12 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24561385800905083		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.24561385800905083 | validation: 0.2234389124028056]
	TIME [epoch: 12 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553804805178553		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.2553804805178553 | validation: 0.27133356652368995]
	TIME [epoch: 12 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2504852981496909		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2504852981496909 | validation: 0.23504286011333209]
	TIME [epoch: 12 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1867452125752886		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.1867452125752886 | validation: 0.21690734281741075]
	TIME [epoch: 12 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2084760341259811		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.2084760341259811 | validation: 0.20773632753937277]
	TIME [epoch: 12 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16770761146713656		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.16770761146713656 | validation: 0.20270080619521558]
	TIME [epoch: 12 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561356319974656		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2561356319974656 | validation: 0.19128945784888018]
	TIME [epoch: 12 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20740584188544223		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.20740584188544223 | validation: 0.19545826880020184]
	TIME [epoch: 12 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2178609873952473		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2178609873952473 | validation: 0.28096429433910297]
	TIME [epoch: 12 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15263787800738482		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.15263787800738482 | validation: 0.2072874784894126]
	TIME [epoch: 12 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053166106311387		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.2053166106311387 | validation: 0.20019716289191813]
	TIME [epoch: 12 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1704215880236372		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.1704215880236372 | validation: 0.20629458367220843]
	TIME [epoch: 12 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27861696306305095		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.27861696306305095 | validation: 0.27617805684497876]
	TIME [epoch: 12 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20534094859322588		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.20534094859322588 | validation: 0.19431697408452525]
	TIME [epoch: 12 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282721305586474		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.14282721305586474 | validation: 0.2041440575179386]
	TIME [epoch: 12 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18830538186263818		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.18830538186263818 | validation: 0.19864503912596515]
	TIME [epoch: 12 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2051578236350579		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.2051578236350579 | validation: 0.185075287747684]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17398916573794		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.17398916573794 | validation: 0.30807781909644383]
	TIME [epoch: 12 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22413716920579882		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.22413716920579882 | validation: 0.19998822276473682]
	TIME [epoch: 12 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1661196283482565		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.1661196283482565 | validation: 0.2318580646869553]
	TIME [epoch: 12 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.182946360841144		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.182946360841144 | validation: 0.2139808529934295]
	TIME [epoch: 12 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824493451629722		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.1824493451629722 | validation: 0.14806491156611967]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14784710008776847		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.14784710008776847 | validation: 0.14048747621137433]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23052889626841633		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.23052889626841633 | validation: 0.18899520995827096]
	TIME [epoch: 12 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16075062173995172		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.16075062173995172 | validation: 0.21386775126083174]
	TIME [epoch: 12 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18206947162325376		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.18206947162325376 | validation: 0.1408753278445258]
	TIME [epoch: 12 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16647506323401814		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.16647506323401814 | validation: 0.14774595580425204]
	TIME [epoch: 12 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1319702913030292		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.1319702913030292 | validation: 0.25071364475430896]
	TIME [epoch: 12 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19159436943015412		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.19159436943015412 | validation: 0.14563250675035166]
	TIME [epoch: 12 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1440673971654317		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.1440673971654317 | validation: 0.15983908115717804]
	TIME [epoch: 12 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17023647070845122		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.17023647070845122 | validation: 0.16260802358843257]
	TIME [epoch: 12 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18246108057684984		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.18246108057684984 | validation: 0.2140247821100017]
	TIME [epoch: 12 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20222797184502053		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.20222797184502053 | validation: 0.2014972036203107]
	TIME [epoch: 12 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439979053301783		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.1439979053301783 | validation: 0.18911210058881806]
	TIME [epoch: 12 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16605111412333248		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.16605111412333248 | validation: 0.1607882427924548]
	TIME [epoch: 12 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15738073900802907		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.15738073900802907 | validation: 0.14819018153582036]
	TIME [epoch: 12 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14331140948549081		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.14331140948549081 | validation: 0.18304753476874355]
	TIME [epoch: 12 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19719214546570973		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.19719214546570973 | validation: 0.16954283823093788]
	TIME [epoch: 12 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488828798564981		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.1488828798564981 | validation: 0.25542912796405165]
	TIME [epoch: 12 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357326788005164		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.1357326788005164 | validation: 0.24423551699507734]
	TIME [epoch: 12 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19241369639643732		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.19241369639643732 | validation: 0.20477848180842217]
	TIME [epoch: 12 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510810284391265		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2510810284391265 | validation: 0.21621810731320318]
	TIME [epoch: 12 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12267353234811355		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.12267353234811355 | validation: 0.13232141002957679]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13712144099422868		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.13712144099422868 | validation: 0.23504475262829058]
	TIME [epoch: 12 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16115903331914888		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.16115903331914888 | validation: 0.1629424237657452]
	TIME [epoch: 12 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13942572591445823		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.13942572591445823 | validation: 0.11456166805784003]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18751523462203545		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.18751523462203545 | validation: 0.17660129112512765]
	TIME [epoch: 12 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350983268782261		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.1350983268782261 | validation: 0.1587971439365646]
	TIME [epoch: 12 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16013652992196395		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.16013652992196395 | validation: 0.15447171211145042]
	TIME [epoch: 12 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12252246786243334		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.12252246786243334 | validation: 0.1653898237956756]
	TIME [epoch: 12 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350529974268877		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.1350529974268877 | validation: 0.17564065742985724]
	TIME [epoch: 12 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.132882940174995		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.132882940174995 | validation: 0.13804498182412356]
	TIME [epoch: 12 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1369888351688253		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.1369888351688253 | validation: 0.19432485168718766]
	TIME [epoch: 12 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1552481614125229		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.1552481614125229 | validation: 0.12069223498104872]
	TIME [epoch: 12 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09768788962510982		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.09768788962510982 | validation: 0.1424518554914367]
	TIME [epoch: 12 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13514000148374383		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.13514000148374383 | validation: 0.2714422071623861]
	TIME [epoch: 12 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15715084232354173		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.15715084232354173 | validation: 0.13495917105630215]
	TIME [epoch: 12 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13262004777669312		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.13262004777669312 | validation: 0.14833316986043515]
	TIME [epoch: 12 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16233524692129014		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.16233524692129014 | validation: 0.19908806198590465]
	TIME [epoch: 12 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894834058328394		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.12894834058328394 | validation: 0.13117435381256054]
	TIME [epoch: 12 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1128083892931204		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.1128083892931204 | validation: 0.2596127616377312]
	TIME [epoch: 12 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15761007128176063		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.15761007128176063 | validation: 0.14580149876211254]
	TIME [epoch: 12 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449049744189191		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.1449049744189191 | validation: 0.15272619415552127]
	TIME [epoch: 12 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1245082345312067		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.1245082345312067 | validation: 0.14685736326505427]
	TIME [epoch: 12 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11808650140079996		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.11808650140079996 | validation: 0.14399306796521844]
	TIME [epoch: 12 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521902915629755		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.10521902915629755 | validation: 0.22308454653915727]
	TIME [epoch: 12 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1602810289460223		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.1602810289460223 | validation: 0.13263957267346338]
	TIME [epoch: 12 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355298509995112		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.1355298509995112 | validation: 0.12572124372951343]
	TIME [epoch: 12 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10687860024264714		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.10687860024264714 | validation: 0.15110732684297692]
	TIME [epoch: 12 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15807112377019145		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.15807112377019145 | validation: 0.21148401663611077]
	TIME [epoch: 12 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15313395799274127		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.15313395799274127 | validation: 0.10278128949288183]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792140411166731		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.07792140411166731 | validation: 0.11588650125134899]
	TIME [epoch: 12 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1192377608092706		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.1192377608092706 | validation: 0.14889439780738975]
	TIME [epoch: 12 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111203513304419		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.1111203513304419 | validation: 0.18872648725225813]
	TIME [epoch: 12 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13056859267630788		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.13056859267630788 | validation: 0.1620096166080349]
	TIME [epoch: 12 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10524698998302746		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.10524698998302746 | validation: 0.1190139711419076]
	TIME [epoch: 12 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803865011470176		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.13803865011470176 | validation: 0.15833711740431133]
	TIME [epoch: 12 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138990225795518		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.138990225795518 | validation: 0.1257608086903582]
	TIME [epoch: 12 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11517836361187703		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.11517836361187703 | validation: 0.12136250737106456]
	TIME [epoch: 12 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12353776545306548		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.12353776545306548 | validation: 0.1268904968184364]
	TIME [epoch: 12 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15706982332616407		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.15706982332616407 | validation: 0.2752457325833306]
	TIME [epoch: 12 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18863318191706566		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.18863318191706566 | validation: 0.12225878089092394]
	TIME [epoch: 12 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589305569814095		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.09589305569814095 | validation: 0.16205253373749667]
	TIME [epoch: 12 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12063093551840301		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.12063093551840301 | validation: 0.11048590293331878]
	TIME [epoch: 12 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002858825394701		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.09002858825394701 | validation: 0.16572702578563148]
	TIME [epoch: 12 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13367092945713013		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.13367092945713013 | validation: 0.09985650292225448]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0806464278766987		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.0806464278766987 | validation: 0.14109023214855834]
	TIME [epoch: 12 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12496547597353758		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.12496547597353758 | validation: 0.11249087854969206]
	TIME [epoch: 12 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10778053830453685		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.10778053830453685 | validation: 0.15134162818131416]
	TIME [epoch: 12 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11827059593476791		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.11827059593476791 | validation: 0.1005063005768668]
	TIME [epoch: 12 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0898600618524463		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.0898600618524463 | validation: 0.11440943503513779]
	TIME [epoch: 12 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1456820568382062		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.1456820568382062 | validation: 0.16586142885640784]
	TIME [epoch: 12 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11212894310091825		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.11212894310091825 | validation: 0.10553101565187822]
	TIME [epoch: 12 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11048020600944844		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.11048020600944844 | validation: 0.0877628826986992]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12686527632513955		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.12686527632513955 | validation: 0.10386658736744211]
	TIME [epoch: 12 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09617606207143713		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.09617606207143713 | validation: 0.0898844532509954]
	TIME [epoch: 12.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378535332847285		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.12378535332847285 | validation: 0.21576970553330754]
	TIME [epoch: 12 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573382727055852		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.1573382727055852 | validation: 0.10882119865723472]
	TIME [epoch: 12 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489866598760765		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.10489866598760765 | validation: 0.15142708169146218]
	TIME [epoch: 12 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713619365723646		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.11713619365723646 | validation: 0.08999293307793327]
	TIME [epoch: 12 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737275900163609		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.08737275900163609 | validation: 0.1650021489997418]
	TIME [epoch: 12 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050494657064874		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.1050494657064874 | validation: 0.11650710915665313]
	TIME [epoch: 12 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091125551571212		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.09091125551571212 | validation: 0.10707987075335901]
	TIME [epoch: 12 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12341195662421206		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.12341195662421206 | validation: 0.1431189048792324]
	TIME [epoch: 12 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508688683702166		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.10508688683702166 | validation: 0.11590657355961101]
	TIME [epoch: 12 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09545589009046025		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.09545589009046025 | validation: 0.14292585812200467]
	TIME [epoch: 12 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11815930851110795		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.11815930851110795 | validation: 0.10059026256327958]
	TIME [epoch: 12 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590954831023391		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.08590954831023391 | validation: 0.11862174148541302]
	TIME [epoch: 12 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10539005613348178		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.10539005613348178 | validation: 0.09297306543538009]
	TIME [epoch: 12 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09860322063826346		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.09860322063826346 | validation: 0.12688448762979704]
	TIME [epoch: 12 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10424288491114651		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.10424288491114651 | validation: 0.19917864039513772]
	TIME [epoch: 12 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649777890798032		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.10649777890798032 | validation: 0.08985539770414498]
	TIME [epoch: 12 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723468146950579		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.08723468146950579 | validation: 0.15518848316008993]
	TIME [epoch: 12 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09023545898232332		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.09023545898232332 | validation: 0.131388866861687]
	TIME [epoch: 12 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09919300547923338		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.09919300547923338 | validation: 0.09825908095703972]
	TIME [epoch: 12 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07797558314618311		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.07797558314618311 | validation: 0.10170220782979497]
	TIME [epoch: 12 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201209897293973		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.08201209897293973 | validation: 0.0933171640722761]
	TIME [epoch: 12 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10874670090138058		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.10874670090138058 | validation: 0.17465858810793933]
	TIME [epoch: 12 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10881824523420462		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.10881824523420462 | validation: 0.08449618523590907]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08305021411969973		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.08305021411969973 | validation: 0.09180610103877684]
	TIME [epoch: 12 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864388884600286		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.08864388884600286 | validation: 0.10944855586478396]
	TIME [epoch: 12 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12406801196732337		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.12406801196732337 | validation: 0.1077823163525451]
	TIME [epoch: 12 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09695580203046619		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.09695580203046619 | validation: 0.09948849170519083]
	TIME [epoch: 12 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09502016400968402		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.09502016400968402 | validation: 0.1329018470728311]
	TIME [epoch: 12 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087804424331916		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.1087804424331916 | validation: 0.6901154205430712]
	TIME [epoch: 12 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4308838660298721		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.4308838660298721 | validation: 0.13680475531523062]
	TIME [epoch: 12 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105409536699115		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.08105409536699115 | validation: 0.1010961483649812]
	TIME [epoch: 12 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573785586336293		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.10573785586336293 | validation: 0.09402508447643788]
	TIME [epoch: 12 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06751938832106913		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.06751938832106913 | validation: 0.07896915707565352]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08072846371983658		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.08072846371983658 | validation: 0.0841503674865349]
	TIME [epoch: 12 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09175589831472956		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.09175589831472956 | validation: 0.12468731497365876]
	TIME [epoch: 12 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334546190749997		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.11334546190749997 | validation: 0.10654530907487386]
	TIME [epoch: 12 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08965880154031777		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.08965880154031777 | validation: 0.12344277937597858]
	TIME [epoch: 12 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805805725381446		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.07805805725381446 | validation: 0.12562561056525495]
	TIME [epoch: 12.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08750049655879896		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.08750049655879896 | validation: 0.12838590446025275]
	TIME [epoch: 12 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14757014658360101		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.14757014658360101 | validation: 0.12765867142126164]
	TIME [epoch: 12.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09559955902154198		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.09559955902154198 | validation: 0.08889577876345395]
	TIME [epoch: 12 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07982247091149576		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.07982247091149576 | validation: 0.09072322925883872]
	TIME [epoch: 12 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679025647024165		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.07679025647024165 | validation: 0.13831014973127748]
	TIME [epoch: 12 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09640477858715746		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.09640477858715746 | validation: 0.10051877678421814]
	TIME [epoch: 12 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091978465234143		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.07091978465234143 | validation: 0.08322717407276374]
	TIME [epoch: 12 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11705248856399958		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.11705248856399958 | validation: 0.1860714650564428]
	TIME [epoch: 12 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12606178457080675		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.12606178457080675 | validation: 0.11391748709937474]
	TIME [epoch: 12 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08465033142324858		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.08465033142324858 | validation: 0.12282994449982071]
	TIME [epoch: 12 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07366210998175086		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.07366210998175086 | validation: 0.12319607841633623]
	TIME [epoch: 12 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07379802422008354		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.07379802422008354 | validation: 0.11743700004655915]
	TIME [epoch: 12 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09083361939596957		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.09083361939596957 | validation: 0.10095622531910048]
	TIME [epoch: 12 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10243332971059432		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.10243332971059432 | validation: 0.11059080879129088]
	TIME [epoch: 12 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0917213787504158		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.0917213787504158 | validation: 0.0661101483391071]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_355.pth
	Model improved!!!
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06843251535335435		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.06843251535335435 | validation: 0.11213805092434793]
	TIME [epoch: 12 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110523260376504		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.1110523260376504 | validation: 0.0815090895697492]
	TIME [epoch: 12 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06943036571641882		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.06943036571641882 | validation: 0.09677451047047203]
	TIME [epoch: 12 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784493007664668		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.07784493007664668 | validation: 0.11300193191921942]
	TIME [epoch: 12 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09204379622355548		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.09204379622355548 | validation: 0.0823702265752767]
	TIME [epoch: 12 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06486377138798552		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.06486377138798552 | validation: 0.09384326563272025]
	TIME [epoch: 12 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09487000005733712		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.09487000005733712 | validation: 0.10101960455139895]
	TIME [epoch: 12 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06664493265684604		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.06664493265684604 | validation: 0.09039341782068924]
	TIME [epoch: 12 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09402609419472865		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.09402609419472865 | validation: 0.06835247567025758]
	TIME [epoch: 12 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0614574254476477		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.0614574254476477 | validation: 0.07304651765991126]
	TIME [epoch: 12 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07534044844522474		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.07534044844522474 | validation: 0.09900331961218524]
	TIME [epoch: 12 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09079187936512381		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.09079187936512381 | validation: 0.11429930115259698]
	TIME [epoch: 12 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104154130723865		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.08104154130723865 | validation: 0.1088186506245695]
	TIME [epoch: 12 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553273456510749		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.08553273456510749 | validation: 0.06627718698820302]
	TIME [epoch: 12 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307993968561518		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.06307993968561518 | validation: 0.07176949283126022]
	TIME [epoch: 12 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06820983617161092		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.06820983617161092 | validation: 0.07974617537201156]
	TIME [epoch: 12 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06688452874640534		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.06688452874640534 | validation: 0.09368185327354792]
	TIME [epoch: 12 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08281899480029833		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.08281899480029833 | validation: 0.11239708481604314]
	TIME [epoch: 12 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880464923390496		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.07880464923390496 | validation: 0.11014080457788122]
	TIME [epoch: 12 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062302682413404864		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.062302682413404864 | validation: 0.15142489339460358]
	TIME [epoch: 12 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1016283685287172		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.1016283685287172 | validation: 0.07572923280250794]
	TIME [epoch: 12 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051293659052415536		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.051293659052415536 | validation: 0.08198101416744148]
	TIME [epoch: 12 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351968170055855		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.09351968170055855 | validation: 0.0788001497524782]
	TIME [epoch: 12 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06841945660623201		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.06841945660623201 | validation: 0.07476636378133991]
	TIME [epoch: 12 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314742761820951		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.05314742761820951 | validation: 0.09833407874547778]
	TIME [epoch: 12 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09841906774982365		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.09841906774982365 | validation: 0.11014957873986345]
	TIME [epoch: 12 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07475957413098001		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.07475957413098001 | validation: 0.07347218487309387]
	TIME [epoch: 12 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06681546840339883		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.06681546840339883 | validation: 0.0869890251627086]
	TIME [epoch: 12 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07799724039413115		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.07799724039413115 | validation: 0.08950884235241652]
	TIME [epoch: 12 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07292850204625975		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.07292850204625975 | validation: 0.07887276076461805]
	TIME [epoch: 12 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056316503328711826		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.056316503328711826 | validation: 0.06751021495221163]
	TIME [epoch: 12 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0633522607564958		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.0633522607564958 | validation: 0.09840452184396146]
	TIME [epoch: 12 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06877138688544107		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.06877138688544107 | validation: 0.08000563442256929]
	TIME [epoch: 12 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08552623496162158		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.08552623496162158 | validation: 0.06782567593804475]
	TIME [epoch: 12 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440993534068674		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.06440993534068674 | validation: 0.0961357756439821]
	TIME [epoch: 12 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06301750996272681		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.06301750996272681 | validation: 0.07415805456219585]
	TIME [epoch: 12 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578658639678538		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.06578658639678538 | validation: 0.10952802369678127]
	TIME [epoch: 12 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06738642837850406		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.06738642837850406 | validation: 0.0601077248372049]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549967861739789		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.05549967861739789 | validation: 0.09689127287693627]
	TIME [epoch: 12 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09262059574336175		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09262059574336175 | validation: 0.08013681627376336]
	TIME [epoch: 12 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0719079674624152		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.0719079674624152 | validation: 0.07018161496979482]
	TIME [epoch: 12 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10324417523007871		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.10324417523007871 | validation: 0.07008148269003091]
	TIME [epoch: 12 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0582243890841755		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.0582243890841755 | validation: 0.11625505351944157]
	TIME [epoch: 12 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06283778829045113		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.06283778829045113 | validation: 0.06697380388450236]
	TIME [epoch: 12 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969376212357087		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.06969376212357087 | validation: 0.06567606641376142]
	TIME [epoch: 12 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438203559978878		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.05438203559978878 | validation: 0.09083184989238671]
	TIME [epoch: 12 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06183103367162429		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.06183103367162429 | validation: 0.08080993298678514]
	TIME [epoch: 12 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2421463313295534		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.2421463313295534 | validation: 0.10679209100083192]
	TIME [epoch: 12 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727585805775171		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.0727585805775171 | validation: 0.0743706235493641]
	TIME [epoch: 12 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059274038668604964		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.059274038668604964 | validation: 0.06665699122344204]
	TIME [epoch: 12 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255397309434258		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.05255397309434258 | validation: 0.06796119448298725]
	TIME [epoch: 12 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06743158366569507		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.06743158366569507 | validation: 0.06193506478082646]
	TIME [epoch: 12 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213938269110235		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.05213938269110235 | validation: 0.07232502129047602]
	TIME [epoch: 12 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060925527483253514		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.060925527483253514 | validation: 0.08179192611600537]
	TIME [epoch: 12 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05485453027943838		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.05485453027943838 | validation: 0.08778742636861923]
	TIME [epoch: 12 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647365363434855		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.0647365363434855 | validation: 0.09982469799275981]
	TIME [epoch: 12 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06179145497901831		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.06179145497901831 | validation: 0.08721431169067809]
	TIME [epoch: 12 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0676975030894434		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.0676975030894434 | validation: 0.061691385698844595]
	TIME [epoch: 12 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05816459362029543		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.05816459362029543 | validation: 0.0765223979940309]
	TIME [epoch: 12 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0624259466203331		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.0624259466203331 | validation: 0.06999733521048762]
	TIME [epoch: 12 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603592549663004		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.05603592549663004 | validation: 0.07006636938456746]
	TIME [epoch: 12 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365150823673289		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.06365150823673289 | validation: 0.06496222124462347]
	TIME [epoch: 12 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049466748823710466		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.049466748823710466 | validation: 0.06249146304113823]
	TIME [epoch: 12 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04774906584310604		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.04774906584310604 | validation: 0.08443267314325131]
	TIME [epoch: 12 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.065359051402627		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.065359051402627 | validation: 0.07357356746226414]
	TIME [epoch: 12 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06374350053755849		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.06374350053755849 | validation: 0.045942286450628506]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04208940497156406		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.04208940497156406 | validation: 0.07733329793967021]
	TIME [epoch: 12 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05977023615430614		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.05977023615430614 | validation: 0.15647364951365844]
	TIME [epoch: 12 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08083292712996237		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.08083292712996237 | validation: 0.06670104288785551]
	TIME [epoch: 12 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05440364011410754		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.05440364011410754 | validation: 0.06152109515464735]
	TIME [epoch: 12 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381982238062824		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.06381982238062824 | validation: 0.10210637689330909]
	TIME [epoch: 12 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438227542271761		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.05438227542271761 | validation: 0.07373796837475144]
	TIME [epoch: 12 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04602728684233298		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.04602728684233298 | validation: 0.05311257777017506]
	TIME [epoch: 12 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0639655446152541		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.0639655446152541 | validation: 0.051327223601887]
	TIME [epoch: 12 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051535588202821205		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.051535588202821205 | validation: 0.06341021051760702]
	TIME [epoch: 12 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044684640487516136		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.044684640487516136 | validation: 0.048416852277775604]
	TIME [epoch: 12 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04625709279315984		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.04625709279315984 | validation: 0.059922223333312874]
	TIME [epoch: 12 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703154482968786		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.06703154482968786 | validation: 0.06595503493797204]
	TIME [epoch: 12 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04304411431139275		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.04304411431139275 | validation: 0.055109388681287744]
	TIME [epoch: 12 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040212410864282795		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.040212410864282795 | validation: 0.07045499157936905]
	TIME [epoch: 12 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06504233390138293		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.06504233390138293 | validation: 0.05882222442455276]
	TIME [epoch: 12 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743860847112703		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.04743860847112703 | validation: 0.10185868848688026]
	TIME [epoch: 12 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06806344768393265		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.06806344768393265 | validation: 0.06955144508001887]
	TIME [epoch: 12 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038335876965792395		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.038335876965792395 | validation: 0.05751675002174925]
	TIME [epoch: 12 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051671846687963006		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.051671846687963006 | validation: 0.04678604139585718]
	TIME [epoch: 12 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048847865648324565		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.048847865648324565 | validation: 0.06766588851786554]
	TIME [epoch: 12 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626432750405799		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.05626432750405799 | validation: 0.056374945958290026]
	TIME [epoch: 12 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619075058544865		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.04619075058544865 | validation: 0.059092809393129594]
	TIME [epoch: 12 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07335967233439301		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.07335967233439301 | validation: 0.046858613770796725]
	TIME [epoch: 12 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040670913737364506		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.040670913737364506 | validation: 0.05920784680450836]
	TIME [epoch: 12 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080996259282067		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.04080996259282067 | validation: 0.06345039698685911]
	TIME [epoch: 12 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044054508256551286		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.044054508256551286 | validation: 0.07010677884557696]
	TIME [epoch: 12 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521869784091584		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.07521869784091584 | validation: 0.05563155903023273]
	TIME [epoch: 12 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258571613083264		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.05258571613083264 | validation: 0.0608675013180484]
	TIME [epoch: 12 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939915571783131		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.04939915571783131 | validation: 0.04421061590523881]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966556280691551		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.03966556280691551 | validation: 0.05461043294632025]
	TIME [epoch: 12 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972860470418563		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.03972860470418563 | validation: 0.0520857815039749]
	TIME [epoch: 12 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051590042607033655		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.051590042607033655 | validation: 0.07727235379661335]
	TIME [epoch: 12 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059138578493732004		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.059138578493732004 | validation: 0.04879054144418982]
	TIME [epoch: 12 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04194138432046078		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04194138432046078 | validation: 0.05262916379828894]
	TIME [epoch: 12 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04687907659267551		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.04687907659267551 | validation: 0.05074032394248758]
	TIME [epoch: 12 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193407820252129		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.04193407820252129 | validation: 0.05445009901375125]
	TIME [epoch: 12 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047928486389980436		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.047928486389980436 | validation: 0.0753952165916883]
	TIME [epoch: 12 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798729709485639		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.04798729709485639 | validation: 0.044967443081761316]
	TIME [epoch: 12 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337387073607051		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.04337387073607051 | validation: 0.049179110813077104]
	TIME [epoch: 12 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379100214758258		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.03379100214758258 | validation: 0.06715348102003874]
	TIME [epoch: 12 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052418555975773815		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.052418555975773815 | validation: 0.06385814350190996]
	TIME [epoch: 12 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05647874703019074		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.05647874703019074 | validation: 0.04694832065154125]
	TIME [epoch: 12 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03698150220293397		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.03698150220293397 | validation: 0.05096526577897701]
	TIME [epoch: 12 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04621526975321184		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.04621526975321184 | validation: 0.05199630013900762]
	TIME [epoch: 12 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397501477508681		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.04397501477508681 | validation: 0.05449828469389729]
	TIME [epoch: 12 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824892929559153		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.03824892929559153 | validation: 0.05112022744619225]
	TIME [epoch: 12 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04415006276894627		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.04415006276894627 | validation: 0.0612646856970821]
	TIME [epoch: 12 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04547190709104554		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.04547190709104554 | validation: 0.05298078197135513]
	TIME [epoch: 12 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048691692291388304		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.048691692291388304 | validation: 0.054492096880963195]
	TIME [epoch: 12 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644430609006843		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.04644430609006843 | validation: 0.04544526165569845]
	TIME [epoch: 12 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475923678168113		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.0475923678168113 | validation: 0.06696633403435015]
	TIME [epoch: 12 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0394857864817247		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.0394857864817247 | validation: 0.042812348029940855]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_473.pth
	Model improved!!!
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155286096301996		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.03155286096301996 | validation: 0.07696834396110051]
	TIME [epoch: 12 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445768851609913		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.04445768851609913 | validation: 0.05497735930086446]
	TIME [epoch: 12 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447991821501982		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.04447991821501982 | validation: 0.051048667187516425]
	TIME [epoch: 12 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05761275824393087		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.05761275824393087 | validation: 0.054156850226724666]
	TIME [epoch: 12 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038300021552819745		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.038300021552819745 | validation: 0.05215989971299434]
	TIME [epoch: 12 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038435643821292984		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.038435643821292984 | validation: 0.05179749274563511]
	TIME [epoch: 12 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04578004036452547		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.04578004036452547 | validation: 0.07112803875326504]
	TIME [epoch: 12 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352728593925685		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.04352728593925685 | validation: 0.048006906424420945]
	TIME [epoch: 12 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05271925236581508		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.05271925236581508 | validation: 0.08040521671933892]
	TIME [epoch: 12 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04741993098987096		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.04741993098987096 | validation: 0.0459443038180785]
	TIME [epoch: 12 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297794431161274		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.03297794431161274 | validation: 0.033843775232466365]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039629211313982796		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.039629211313982796 | validation: 0.05743354885121339]
	TIME [epoch: 12 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534365927794051		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.04534365927794051 | validation: 0.03159187353056009]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029638381789263105		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.029638381789263105 | validation: 0.06644374227056518]
	TIME [epoch: 12 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04905487399349652		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.04905487399349652 | validation: 0.050057603939987]
	TIME [epoch: 12 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048012202365853074		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.048012202365853074 | validation: 0.03663314427453036]
	TIME [epoch: 12 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03436674309466158		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.03436674309466158 | validation: 0.04797648840011756]
	TIME [epoch: 12 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010488391079354		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.06010488391079354 | validation: 0.03871097252216005]
	TIME [epoch: 12 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03187031311665043		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.03187031311665043 | validation: 0.04137297692940978]
	TIME [epoch: 12 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049327524350946256		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.049327524350946256 | validation: 0.04268609429709522]
	TIME [epoch: 12 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03529880857646283		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.03529880857646283 | validation: 0.04376245002231759]
	TIME [epoch: 12 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04714859749433503		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.04714859749433503 | validation: 0.0617510703505149]
	TIME [epoch: 12 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04581368862381534		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.04581368862381534 | validation: 0.04749998342240097]
	TIME [epoch: 12 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038175973493022514		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.038175973493022514 | validation: 0.037301129706448874]
	TIME [epoch: 12 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03177097712991124		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.03177097712991124 | validation: 0.039466598131284794]
	TIME [epoch: 12 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464246699349232		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.03464246699349232 | validation: 0.04239062212060639]
	TIME [epoch: 12 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041522435280585995		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.041522435280585995 | validation: 0.07498833583049316]
	TIME [epoch: 12 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044408558044168836		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.044408558044168836 | validation: 0.05208469678849273]
	TIME [epoch: 435 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04206782439434588		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.04206782439434588 | validation: 0.057893056609827645]
	TIME [epoch: 25.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041581244990015975		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.041581244990015975 | validation: 0.034352076553829616]
	TIME [epoch: 25.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029510555523400032		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.029510555523400032 | validation: 0.04244397653660135]
	TIME [epoch: 25.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824755621228001		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.04824755621228001 | validation: 0.05502426366730338]
	TIME [epoch: 25.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03666301886444198		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.03666301886444198 | validation: 0.05110808885145346]
	TIME [epoch: 25.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041096758441932654		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.041096758441932654 | validation: 0.045679184813511756]
	TIME [epoch: 25.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03341916164418475		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.03341916164418475 | validation: 0.06954317552546563]
	TIME [epoch: 25.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04316602264236908		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.04316602264236908 | validation: 0.050094617787726795]
	TIME [epoch: 25.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03570544764201311		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.03570544764201311 | validation: 0.06547417857844984]
	TIME [epoch: 25.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044466614254943235		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.044466614254943235 | validation: 0.043361378512362714]
	TIME [epoch: 25.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03830954893045258		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.03830954893045258 | validation: 0.03259238324552757]
	TIME [epoch: 25.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04197346903727558		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.04197346903727558 | validation: 0.058268428515044865]
	TIME [epoch: 25.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337335992921002		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.0337335992921002 | validation: 0.05214516355438645]
	TIME [epoch: 25.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034482518378230076		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.034482518378230076 | validation: 0.04429717580129707]
	TIME [epoch: 25.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04640320964969444		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.04640320964969444 | validation: 0.039122271629095845]
	TIME [epoch: 25.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029691895500108943		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.029691895500108943 | validation: 0.04119888846585629]
	TIME [epoch: 25.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414714653574901		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.0414714653574901 | validation: 0.047603928512820304]
	TIME [epoch: 25.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03527896003004456		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.03527896003004456 | validation: 0.046973701005949726]
	TIME [epoch: 25.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223183931581284		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.03223183931581284 | validation: 0.038534619787681273]
	TIME [epoch: 25.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035676907497485685		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.035676907497485685 | validation: 0.05861768845201225]
	TIME [epoch: 25.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257466052423222		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.04257466052423222 | validation: 0.038087704746287636]
	TIME [epoch: 25.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028480442226524055		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.028480442226524055 | validation: 0.04868224343419056]
	TIME [epoch: 25.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298692051600124		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.04298692051600124 | validation: 0.052625860182184514]
	TIME [epoch: 25.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574034697442619		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.03574034697442619 | validation: 0.05999507569218823]
	TIME [epoch: 25.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03392117215519255		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.03392117215519255 | validation: 0.03469484295669338]
	TIME [epoch: 25.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02808949005904643		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.02808949005904643 | validation: 0.032744702676349734]
	TIME [epoch: 25.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02592920575029725		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.02592920575029725 | validation: 0.04556765584197363]
	TIME [epoch: 25.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039722385897357396		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.039722385897357396 | validation: 0.04692032639555348]
	TIME [epoch: 25.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036282866616980936		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.036282866616980936 | validation: 0.04909472299166616]
	TIME [epoch: 25.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441429443460581		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.04441429443460581 | validation: 0.06118349958947319]
	TIME [epoch: 25.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04882774967068167		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.04882774967068167 | validation: 0.03545474594516566]
	TIME [epoch: 25.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02659772549641614		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.02659772549641614 | validation: 0.040512146792220864]
	TIME [epoch: 25.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030067751333433104		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.030067751333433104 | validation: 0.03366262136508398]
	TIME [epoch: 25.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036353940012719084		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.036353940012719084 | validation: 0.06752039535134267]
	TIME [epoch: 25.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04503180684144694		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.04503180684144694 | validation: 0.04750225750361883]
	TIME [epoch: 25.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025584496814593696		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.025584496814593696 | validation: 0.03915272153497788]
	TIME [epoch: 25.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029062814278896586		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.029062814278896586 | validation: 0.2727950015283028]
	TIME [epoch: 25.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22947026293463096		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.22947026293463096 | validation: 0.13655510929435027]
	TIME [epoch: 25.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09629612852658867		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.09629612852658867 | validation: 0.038985011943192205]
	TIME [epoch: 25.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02989621694999266		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.02989621694999266 | validation: 0.03335179477984752]
	TIME [epoch: 25.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024276471582300525		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.024276471582300525 | validation: 0.03973862204624364]
	TIME [epoch: 25.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025486196633242864		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.025486196633242864 | validation: 0.03294475220739433]
	TIME [epoch: 25.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028367275910414914		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.028367275910414914 | validation: 0.05291834580257412]
	TIME [epoch: 25.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539669167946687		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.03539669167946687 | validation: 0.0328189552728071]
	TIME [epoch: 25.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027947938704248474		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.027947938704248474 | validation: 0.03478876723152724]
	TIME [epoch: 25.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02732286799324518		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.02732286799324518 | validation: 0.04211557871890756]
	TIME [epoch: 25.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02875121363760732		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.02875121363760732 | validation: 0.043286578753398836]
	TIME [epoch: 25.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030575559316428785		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.030575559316428785 | validation: 0.06485657665126171]
	TIME [epoch: 25.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0400881875089031		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.0400881875089031 | validation: 0.03564259652889544]
	TIME [epoch: 25.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03059391952409571		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.03059391952409571 | validation: 0.04911945464008581]
	TIME [epoch: 25.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02701653046799354		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.02701653046799354 | validation: 0.031434095199286805]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0296771896836523		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.0296771896836523 | validation: 0.05067472904728485]
	TIME [epoch: 25.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037961999992101626		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.037961999992101626 | validation: 0.03434127818353363]
	TIME [epoch: 25.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026804788133029805		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.026804788133029805 | validation: 0.038484452371696065]
	TIME [epoch: 25.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028840214905562038		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.028840214905562038 | validation: 0.043647961889401066]
	TIME [epoch: 25.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031225294345248816		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.031225294345248816 | validation: 0.05317164051621717]
	TIME [epoch: 25.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03656016766278855		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.03656016766278855 | validation: 0.04253784034256253]
	TIME [epoch: 25.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03495556587182167		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.03495556587182167 | validation: 0.027888993705078698]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025707283363435883		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.025707283363435883 | validation: 0.03570801912597053]
	TIME [epoch: 25.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027551288615449178		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.027551288615449178 | validation: 0.046731238910901474]
	TIME [epoch: 25.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03609810843099006		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.03609810843099006 | validation: 0.036969951616146995]
	TIME [epoch: 25.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714706665123698		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.02714706665123698 | validation: 0.038185156457025235]
	TIME [epoch: 25.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036974209555082335		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.036974209555082335 | validation: 0.03522490474228847]
	TIME [epoch: 25.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027179248341698006		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.027179248341698006 | validation: 0.0321204861121404]
	TIME [epoch: 25.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04079737506098635		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.04079737506098635 | validation: 0.03110805728106454]
	TIME [epoch: 25.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027099598410807148		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.027099598410807148 | validation: 0.04379801352783016]
	TIME [epoch: 25.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03211779469638135		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.03211779469638135 | validation: 0.03298241774954641]
	TIME [epoch: 25.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028938980889760293		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.028938980889760293 | validation: 0.03793609969393595]
	TIME [epoch: 25.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0259971562946182		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0259971562946182 | validation: 0.03229221877144479]
	TIME [epoch: 25.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022909065744964006		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.022909065744964006 | validation: 0.04729689349023776]
	TIME [epoch: 25.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032566994562023104		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.032566994562023104 | validation: 0.03209768206467257]
	TIME [epoch: 25.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448166179581889		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.03448166179581889 | validation: 0.04025780706684705]
	TIME [epoch: 25.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024606185373294533		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.024606185373294533 | validation: 0.03575081028332627]
	TIME [epoch: 25.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03209988498374154		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.03209988498374154 | validation: 0.03885352595247639]
	TIME [epoch: 25.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851528847067359		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.02851528847067359 | validation: 0.030308933011929797]
	TIME [epoch: 25.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029430401158222767		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.029430401158222767 | validation: 0.03322378266749053]
	TIME [epoch: 25.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017338503387896		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.03017338503387896 | validation: 0.03690310061928309]
	TIME [epoch: 25.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027894634270436158		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.027894634270436158 | validation: 0.03471745201619275]
	TIME [epoch: 25.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028560370655278507		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.028560370655278507 | validation: 0.040523121202172926]
	TIME [epoch: 25.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02903640412792722		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.02903640412792722 | validation: 0.045660202462619634]
	TIME [epoch: 25.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026920282260930444		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.026920282260930444 | validation: 0.04901434557973815]
	TIME [epoch: 25.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027141449281662247		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.027141449281662247 | validation: 0.0305982930057271]
	TIME [epoch: 25.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025405117886851184		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.025405117886851184 | validation: 0.029039881481979044]
	TIME [epoch: 25.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02463831711803667		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.02463831711803667 | validation: 0.03384869846208427]
	TIME [epoch: 25.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03212727470091398		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.03212727470091398 | validation: 0.03330153808258935]
	TIME [epoch: 25.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03505750842548976		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.03505750842548976 | validation: 0.04979668717080886]
	TIME [epoch: 25.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645405115064798		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.02645405115064798 | validation: 0.03335739510694851]
	TIME [epoch: 25.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035454721704211226		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.035454721704211226 | validation: 0.04863345023317213]
	TIME [epoch: 25.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02282296022160658		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.02282296022160658 | validation: 0.03051051296366624]
	TIME [epoch: 25.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029000336352862786		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.029000336352862786 | validation: 0.04148750249077431]
	TIME [epoch: 25.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025683725400945004		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.025683725400945004 | validation: 0.02931522893395519]
	TIME [epoch: 25.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02385152937831998		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.02385152937831998 | validation: 0.03204286810429103]
	TIME [epoch: 25.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030357117726199475		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.030357117726199475 | validation: 0.03263646518468996]
	TIME [epoch: 25.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025629574984114698		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.025629574984114698 | validation: 0.03876365715898443]
	TIME [epoch: 25.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027788739786902637		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.027788739786902637 | validation: 0.030262768682073192]
	TIME [epoch: 25.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02158837117190833		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.02158837117190833 | validation: 0.044987908374733515]
	TIME [epoch: 25.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851275015762397		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.02851275015762397 | validation: 0.029883654525997366]
	TIME [epoch: 25.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02632189050367387		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.02632189050367387 | validation: 0.04600122542498418]
	TIME [epoch: 25.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028226741233074913		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.028226741233074913 | validation: 0.04321627377946982]
	TIME [epoch: 25.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026201887885378902		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.026201887885378902 | validation: 0.02950399328698993]
	TIME [epoch: 25.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025737860816035806		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.025737860816035806 | validation: 0.036565564682698]
	TIME [epoch: 25.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02862727987800575		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.02862727987800575 | validation: 0.027467280155946235]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020736631036828736		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.020736631036828736 | validation: 0.03664140671835471]
	TIME [epoch: 25.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027141153889582607		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.027141153889582607 | validation: 0.03626664610265483]
	TIME [epoch: 25.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022067317490402076		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.022067317490402076 | validation: 0.03893608657400782]
	TIME [epoch: 25.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052348711406984		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.03052348711406984 | validation: 0.03674979089674636]
	TIME [epoch: 25.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02686211436542448		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.02686211436542448 | validation: 0.02784332985976966]
	TIME [epoch: 25.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025238049683508457		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.025238049683508457 | validation: 0.03005195156069884]
	TIME [epoch: 25.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021569622641864367		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.021569622641864367 | validation: 0.033066492628785395]
	TIME [epoch: 25.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029966651593857217		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.029966651593857217 | validation: 0.05855402942810833]
	TIME [epoch: 25.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031354700403044625		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.031354700403044625 | validation: 0.029711385227751175]
	TIME [epoch: 25.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02800619815235406		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.02800619815235406 | validation: 0.031353069304029535]
	TIME [epoch: 25.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021300923572841905		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.021300923572841905 | validation: 0.03297862977587552]
	TIME [epoch: 25.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030860861819670397		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.030860861819670397 | validation: 0.032501460998121096]
	TIME [epoch: 25.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029638271760960677		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.029638271760960677 | validation: 0.024723866205069254]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021749283540181116		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.021749283540181116 | validation: 0.03185145467794845]
	TIME [epoch: 25.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022920880927817983		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.022920880927817983 | validation: 0.03193375306822564]
	TIME [epoch: 25.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030689183641749614		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.030689183641749614 | validation: 0.03366697736542777]
	TIME [epoch: 25.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021293989900004643		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.021293989900004643 | validation: 0.03342665835732855]
	TIME [epoch: 25.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024412547727328857		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.024412547727328857 | validation: 0.0363747179090568]
	TIME [epoch: 25.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02868481949151454		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.02868481949151454 | validation: 0.032164553477149596]
	TIME [epoch: 25.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022892740351778663		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.022892740351778663 | validation: 0.02933732575825581]
	TIME [epoch: 25.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024459214624361864		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.024459214624361864 | validation: 0.03938728714426301]
	TIME [epoch: 25.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02342944245856785		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.02342944245856785 | validation: 0.027984954553679723]
	TIME [epoch: 25.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02139620008633271		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.02139620008633271 | validation: 0.03735623104244208]
	TIME [epoch: 25.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026054662843357328		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.026054662843357328 | validation: 0.03434955752809851]
	TIME [epoch: 25.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02488522773194213		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.02488522773194213 | validation: 0.030376955005576887]
	TIME [epoch: 25.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026059982788106784		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.026059982788106784 | validation: 0.02730297272737476]
	TIME [epoch: 25.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02137370057240337		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.02137370057240337 | validation: 0.031717319880291736]
	TIME [epoch: 25.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0213229042792865		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0213229042792865 | validation: 0.033053946021507886]
	TIME [epoch: 25.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026121496845571225		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.026121496845571225 | validation: 0.038377742264615204]
	TIME [epoch: 25.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031191563287025936		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.031191563287025936 | validation: 0.033880738767459916]
	TIME [epoch: 25.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02049182408601998		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.02049182408601998 | validation: 0.033107108728671224]
	TIME [epoch: 25.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021462220555553278		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.021462220555553278 | validation: 0.028230912194569878]
	TIME [epoch: 25.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409711395605716		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.02409711395605716 | validation: 0.0402342320390182]
	TIME [epoch: 25.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024415038295912763		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.024415038295912763 | validation: 0.029538468166913388]
	TIME [epoch: 25.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021566166484095255		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.021566166484095255 | validation: 0.029173488255265015]
	TIME [epoch: 25.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022805611474433447		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.022805611474433447 | validation: 0.03161377631355383]
	TIME [epoch: 25.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026732273388818888		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.026732273388818888 | validation: 0.028337149581840908]
	TIME [epoch: 25.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02499719488168243		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.02499719488168243 | validation: 0.024774074254059184]
	TIME [epoch: 25.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023610361842556687		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.023610361842556687 | validation: 0.030212343959814397]
	TIME [epoch: 25.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03473341966862558		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.03473341966862558 | validation: 0.03916504703753986]
	TIME [epoch: 25.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023655570357211247		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.023655570357211247 | validation: 0.02528479846003495]
	TIME [epoch: 25.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019083635546834992		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.019083635546834992 | validation: 0.031791941598144566]
	TIME [epoch: 25.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023301853091736848		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.023301853091736848 | validation: 0.02752164702430953]
	TIME [epoch: 25.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024136736641382498		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.024136736641382498 | validation: 0.030569901728407546]
	TIME [epoch: 25.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0215070606101285		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0215070606101285 | validation: 0.025984848439629657]
	TIME [epoch: 25.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02088856939874283		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.02088856939874283 | validation: 0.031376457415724916]
	TIME [epoch: 25.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02493518771766106		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.02493518771766106 | validation: 0.029948180518199453]
	TIME [epoch: 25.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253354820495143		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.02253354820495143 | validation: 0.035105803876833055]
	TIME [epoch: 25.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021359933745039254		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.021359933745039254 | validation: 0.02728918180974134]
	TIME [epoch: 25.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167334115143991		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.02167334115143991 | validation: 0.023598417382274958]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02226334046416611		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.02226334046416611 | validation: 0.027703550238218626]
	TIME [epoch: 25.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020560502704787667		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.020560502704787667 | validation: 0.03793956443331259]
	TIME [epoch: 25.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028981542054954325		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.028981542054954325 | validation: 0.028980778848861098]
	TIME [epoch: 25.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02015361816970543		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.02015361816970543 | validation: 0.02934071269118721]
	TIME [epoch: 25.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960869221086389		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.01960869221086389 | validation: 0.029748056294966317]
	TIME [epoch: 25.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02457246953887002		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.02457246953887002 | validation: 0.03470834550052219]
	TIME [epoch: 25.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021501264301514052		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.021501264301514052 | validation: 0.030403698290952]
	TIME [epoch: 25.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021026746532516905		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.021026746532516905 | validation: 0.02776099481384796]
	TIME [epoch: 25.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045387561746978		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.02045387561746978 | validation: 0.029024725602218623]
	TIME [epoch: 25.6 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02416152067319499		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.02416152067319499 | validation: 0.035183828152339246]
	TIME [epoch: 25.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021514374968241632		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.021514374968241632 | validation: 0.028866676941029318]
	TIME [epoch: 25.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045880265063773		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.02045880265063773 | validation: 0.025473870365765157]
	TIME [epoch: 25.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019000390277554943		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.019000390277554943 | validation: 0.02543065514331614]
	TIME [epoch: 25.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022895496658857824		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.022895496658857824 | validation: 0.04474780573780583]
	TIME [epoch: 25.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026600784804766013		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.026600784804766013 | validation: 0.026284727950974137]
	TIME [epoch: 25.6 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020475762769988314		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.020475762769988314 | validation: 0.02609384110812446]
	TIME [epoch: 25.6 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019722259766109355		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.019722259766109355 | validation: 0.028661843067326997]
	TIME [epoch: 25.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114205740361073		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.02114205740361073 | validation: 0.02601092822675044]
	TIME [epoch: 25.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019709563824547166		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.019709563824547166 | validation: 0.03037915891990822]
	TIME [epoch: 25.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02215165180147453		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.02215165180147453 | validation: 0.028001298857941708]
	TIME [epoch: 25.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020070402881048496		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.020070402881048496 | validation: 0.03730489354747096]
	TIME [epoch: 25.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02464011551115805		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.02464011551115805 | validation: 0.03139316356452239]
	TIME [epoch: 25.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019499294427054753		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.019499294427054753 | validation: 0.0249302938695873]
	TIME [epoch: 25.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021590049944268365		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.021590049944268365 | validation: 0.025323644283337464]
	TIME [epoch: 25.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02197989235251655		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.02197989235251655 | validation: 0.02853723246941369]
	TIME [epoch: 25.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018312398851243524		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.018312398851243524 | validation: 0.03268315010088736]
	TIME [epoch: 25.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01966711583183815		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.01966711583183815 | validation: 0.027009770365033624]
	TIME [epoch: 25.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025545208758532233		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.025545208758532233 | validation: 0.02628979620760595]
	TIME [epoch: 25.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01830236302696317		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.01830236302696317 | validation: 0.028362845078926186]
	TIME [epoch: 25.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021333662923118626		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.021333662923118626 | validation: 0.02238681473327794]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018201852750443632		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.018201852750443632 | validation: 0.023954737944222326]
	TIME [epoch: 25.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021357485963065984		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.021357485963065984 | validation: 0.02773863969345248]
	TIME [epoch: 25.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01921455030711038		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.01921455030711038 | validation: 0.02488934882824676]
	TIME [epoch: 25.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015920255095808456		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.015920255095808456 | validation: 0.024504392768232613]
	TIME [epoch: 25.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020126088318219618		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.020126088318219618 | validation: 0.04247995258029921]
	TIME [epoch: 25.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525311093983396		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.02525311093983396 | validation: 0.05410143348165872]
	TIME [epoch: 25.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023940234460306117		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.023940234460306117 | validation: 0.026578891449405298]
	TIME [epoch: 25.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021450208576505127		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.021450208576505127 | validation: 0.03314088642996295]
	TIME [epoch: 25.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017885290108752703		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.017885290108752703 | validation: 0.023982831027987327]
	TIME [epoch: 25.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021513834442902585		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.021513834442902585 | validation: 0.02841930074662584]
	TIME [epoch: 25.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018506966473822495		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.018506966473822495 | validation: 0.02305016435083602]
	TIME [epoch: 25.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222529007021		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.02222529007021 | validation: 0.03183543469834923]
	TIME [epoch: 25.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020267323877301582		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.020267323877301582 | validation: 0.025925877421594815]
	TIME [epoch: 25.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019499911505529655		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.019499911505529655 | validation: 0.03157166163615148]
	TIME [epoch: 25.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020096570581083634		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.020096570581083634 | validation: 0.028733960306226304]
	TIME [epoch: 25.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020283425941669563		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.020283425941669563 | validation: 0.028875245426019013]
	TIME [epoch: 25.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018933422102620535		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.018933422102620535 | validation: 0.02272613182727074]
	TIME [epoch: 25.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01878839081191706		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.01878839081191706 | validation: 0.023314837856466954]
	TIME [epoch: 25.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021566225494558666		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.021566225494558666 | validation: 0.025305579444171722]
	TIME [epoch: 25.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01891221372089552		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.01891221372089552 | validation: 0.029635340504930396]
	TIME [epoch: 25.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01814618524807314		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.01814618524807314 | validation: 0.027741123273372283]
	TIME [epoch: 25.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02091541582889222		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.02091541582889222 | validation: 0.028540611292127066]
	TIME [epoch: 25.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021213880917592652		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.021213880917592652 | validation: 0.02527746227459722]
	TIME [epoch: 25.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019183309204647114		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.019183309204647114 | validation: 0.026274960104369735]
	TIME [epoch: 25.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01978013564541034		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.01978013564541034 | validation: 0.02260287529610577]
	TIME [epoch: 25.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016381630472498923		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.016381630472498923 | validation: 0.029434085422155094]
	TIME [epoch: 25.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020354563134866065		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.020354563134866065 | validation: 0.029762890453294933]
	TIME [epoch: 25.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019859900882816483		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.019859900882816483 | validation: 0.027041127597271973]
	TIME [epoch: 25.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018593935911199427		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.018593935911199427 | validation: 0.02700819998378507]
	TIME [epoch: 25.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020483300442992215		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.020483300442992215 | validation: 0.027661777871461936]
	TIME [epoch: 25.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879428519116809		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.01879428519116809 | validation: 0.02373513016744693]
	TIME [epoch: 25.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019506115497110274		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.019506115497110274 | validation: 0.03097577988596109]
	TIME [epoch: 25.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0195808859235743		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0195808859235743 | validation: 0.029925204169105282]
	TIME [epoch: 25.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016231446293579723		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.016231446293579723 | validation: 0.024244808568423117]
	TIME [epoch: 25.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017914023029099644		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.017914023029099644 | validation: 0.03013393715648465]
	TIME [epoch: 25.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021072197491725588		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.021072197491725588 | validation: 0.025607464367957824]
	TIME [epoch: 25.6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01950468329851182		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.01950468329851182 | validation: 0.025967470269661355]
	TIME [epoch: 25.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01639743941888898		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.01639743941888898 | validation: 0.02551612785068584]
	TIME [epoch: 25.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019915471334150264		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.019915471334150264 | validation: 0.027868627685248757]
	TIME [epoch: 25.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017769649056742207		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.017769649056742207 | validation: 0.02406791558116403]
	TIME [epoch: 25.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01691335266314315		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.01691335266314315 | validation: 0.02454176644814316]
	TIME [epoch: 25.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020736988240724275		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.020736988240724275 | validation: 0.03228289197949172]
	TIME [epoch: 25.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0180043290302238		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.0180043290302238 | validation: 0.022929269410126008]
	TIME [epoch: 25.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015842144299623273		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.015842144299623273 | validation: 0.024248795243437378]
	TIME [epoch: 25.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02233005744548809		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.02233005744548809 | validation: 0.02307422432442604]
	TIME [epoch: 25.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021641379981975847		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.021641379981975847 | validation: 0.027713809181184944]
	TIME [epoch: 25.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018181507643859583		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.018181507643859583 | validation: 0.02535016339612696]
	TIME [epoch: 25.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017949841195151164		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.017949841195151164 | validation: 0.02657708364240119]
	TIME [epoch: 25.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01992255566064413		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.01992255566064413 | validation: 0.027402579457581178]
	TIME [epoch: 25.6 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017409675172887214		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.017409675172887214 | validation: 0.025969969454000742]
	TIME [epoch: 25.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016333886741484255		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.016333886741484255 | validation: 0.024534992167767458]
	TIME [epoch: 25.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017735687681537056		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.017735687681537056 | validation: 0.031102040390368707]
	TIME [epoch: 25.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017370121855803416		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.017370121855803416 | validation: 0.024806587291812378]
	TIME [epoch: 25.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016848124076006138		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.016848124076006138 | validation: 0.027993059069779017]
	TIME [epoch: 25.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021380780959664236		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.021380780959664236 | validation: 0.023609339640768758]
	TIME [epoch: 25.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648419927433193		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.01648419927433193 | validation: 0.02197162142995638]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015351550052641818		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.015351550052641818 | validation: 0.03232418453241953]
	TIME [epoch: 25.6 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017244167456756068		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.017244167456756068 | validation: 0.025971861424667394]
	TIME [epoch: 25.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018493085239880504		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.018493085239880504 | validation: 0.02375829472143181]
	TIME [epoch: 25.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015850788387784795		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.015850788387784795 | validation: 0.023095263011253607]
	TIME [epoch: 25.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018120740028650807		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.018120740028650807 | validation: 0.033415349496534755]
	TIME [epoch: 25.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020461332366672087		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.020461332366672087 | validation: 0.02652048929650606]
	TIME [epoch: 25.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019652690539891878		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.019652690539891878 | validation: 0.029980414305710204]
	TIME [epoch: 25.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020050173203547208		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.020050173203547208 | validation: 0.022318673302851987]
	TIME [epoch: 25.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01514291808104751		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.01514291808104751 | validation: 0.020514283701809154]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016497809748253652		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.016497809748253652 | validation: 0.029863473436409167]
	TIME [epoch: 25.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017519177045527246		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.017519177045527246 | validation: 0.023256788170248396]
	TIME [epoch: 25.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01868177096396112		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.01868177096396112 | validation: 0.02770347359816586]
	TIME [epoch: 25.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01891857484775076		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.01891857484775076 | validation: 0.03553186845393691]
	TIME [epoch: 25.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019249712243527076		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.019249712243527076 | validation: 0.021132779121164368]
	TIME [epoch: 25.6 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015067817880574583		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.015067817880574583 | validation: 0.029788291313712446]
	TIME [epoch: 25.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977356073566945		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.01977356073566945 | validation: 0.024248673435116087]
	TIME [epoch: 25.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015965370159416414		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.015965370159416414 | validation: 0.022628136820254226]
	TIME [epoch: 25.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01693188081422546		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.01693188081422546 | validation: 0.025204741742320465]
	TIME [epoch: 25.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018484234861710143		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.018484234861710143 | validation: 0.027428564754385574]
	TIME [epoch: 25.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01534057276572439		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.01534057276572439 | validation: 0.02331462661828313]
	TIME [epoch: 25.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014619780540151674		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.014619780540151674 | validation: 0.03227896911747842]
	TIME [epoch: 25.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019968226525051442		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.019968226525051442 | validation: 0.02877049413773781]
	TIME [epoch: 25.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016525953933367393		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.016525953933367393 | validation: 0.02302064355540691]
	TIME [epoch: 25.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01517466215717835		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.01517466215717835 | validation: 0.02356160509429088]
	TIME [epoch: 25.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014937493713220387		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.014937493713220387 | validation: 0.02235452324384921]
	TIME [epoch: 25.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016413476335142067		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.016413476335142067 | validation: 0.024624013286249642]
	TIME [epoch: 25.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01851540661620084		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.01851540661620084 | validation: 0.025621279828795786]
	TIME [epoch: 25.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01675302816067283		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.01675302816067283 | validation: 0.024039168298119484]
	TIME [epoch: 25.6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016546895561647665		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.016546895561647665 | validation: 0.027076453445272534]
	TIME [epoch: 25.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015293970770540809		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.015293970770540809 | validation: 0.02595531794443133]
	TIME [epoch: 25.6 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01747124145479449		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.01747124145479449 | validation: 0.02825477064786398]
	TIME [epoch: 25.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016642091850165654		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.016642091850165654 | validation: 0.024096174585333516]
	TIME [epoch: 25.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015563071621400436		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.015563071621400436 | validation: 0.023735355564651825]
	TIME [epoch: 25.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018866687509055707		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.018866687509055707 | validation: 0.023627630851386534]
	TIME [epoch: 25.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015724571440547775		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.015724571440547775 | validation: 0.024854572171838105]
	TIME [epoch: 25.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015413833666795508		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.015413833666795508 | validation: 0.0245457443599547]
	TIME [epoch: 25.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015532231577484557		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.015532231577484557 | validation: 0.02881814882962576]
	TIME [epoch: 25.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019069732519889797		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.019069732519889797 | validation: 0.023688708441259358]
	TIME [epoch: 25.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01601091101826281		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.01601091101826281 | validation: 0.019600331667696556]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_778.pth
	Model improved!!!
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017272551683303886		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.017272551683303886 | validation: 0.021786455640424]
	TIME [epoch: 25.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01561500738844206		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.01561500738844206 | validation: 0.023436776505967333]
	TIME [epoch: 25.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017891480276356574		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.017891480276356574 | validation: 0.028701646633575897]
	TIME [epoch: 25.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951605961898794		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.01951605961898794 | validation: 0.024893542840857576]
	TIME [epoch: 25.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014498833811719462		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.014498833811719462 | validation: 0.0238039149736757]
	TIME [epoch: 25.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015348760079295316		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.015348760079295316 | validation: 0.03216294389626152]
	TIME [epoch: 25.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017495992830117272		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.017495992830117272 | validation: 0.021943267899921175]
	TIME [epoch: 25.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013509596026085681		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.013509596026085681 | validation: 0.023243848859344548]
	TIME [epoch: 25.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01649719300256936		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.01649719300256936 | validation: 0.026478888856288196]
	TIME [epoch: 25.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01785993423451772		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.01785993423451772 | validation: 0.023906821756333484]
	TIME [epoch: 25.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015248317716688227		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.015248317716688227 | validation: 0.02338057520128907]
	TIME [epoch: 25.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015316712649744027		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.015316712649744027 | validation: 0.029280155481470012]
	TIME [epoch: 25.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016261907914221913		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.016261907914221913 | validation: 0.02330545822992732]
	TIME [epoch: 25.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013925482493191822		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.013925482493191822 | validation: 0.028800748020686003]
	TIME [epoch: 25.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017177862650863292		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.017177862650863292 | validation: 0.025207534555052195]
	TIME [epoch: 25.6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014986392514834437		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.014986392514834437 | validation: 0.020547916501035015]
	TIME [epoch: 25.6 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01635459382581714		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.01635459382581714 | validation: 0.02082998089045318]
	TIME [epoch: 25.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03268589169371342		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.03268589169371342 | validation: 0.06524542130222824]
	TIME [epoch: 25.6 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03157091426535446		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.03157091426535446 | validation: 0.027466345286033103]
	TIME [epoch: 25.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01576525951126132		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.01576525951126132 | validation: 0.024045624459697244]
	TIME [epoch: 25.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014677969723569405		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.014677969723569405 | validation: 0.024547782504418157]
	TIME [epoch: 25.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014925320553203787		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.014925320553203787 | validation: 0.021996339743786238]
	TIME [epoch: 25.6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01409246087832111		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.01409246087832111 | validation: 0.027931868485891444]
	TIME [epoch: 25.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018371991582737814		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.018371991582737814 | validation: 0.023093642462723926]
	TIME [epoch: 25.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014129645649809269		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.014129645649809269 | validation: 0.02135220827933613]
	TIME [epoch: 25.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01470048533463866		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.01470048533463866 | validation: 0.026969667327451444]
	TIME [epoch: 25.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016119584105530108		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.016119584105530108 | validation: 0.02357222244448748]
	TIME [epoch: 25.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014179928745485812		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.014179928745485812 | validation: 0.025714937567176018]
	TIME [epoch: 25.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016188476880585608		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.016188476880585608 | validation: 0.023671953590705307]
	TIME [epoch: 25.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015512530535207038		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.015512530535207038 | validation: 0.029351331262501307]
	TIME [epoch: 25.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015783246545848627		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.015783246545848627 | validation: 0.0252522910176006]
	TIME [epoch: 25.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014125512159145875		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.014125512159145875 | validation: 0.02185585740551841]
	TIME [epoch: 25.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01732451546060597		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.01732451546060597 | validation: 0.020914009226593457]
	TIME [epoch: 25.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014816278715075466		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.014816278715075466 | validation: 0.022456013950565554]
	TIME [epoch: 25.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016700430620333818		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.016700430620333818 | validation: 0.024376548349472664]
	TIME [epoch: 25.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014823412280476468		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.014823412280476468 | validation: 0.022466355996883527]
	TIME [epoch: 25.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014940969572891937		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.014940969572891937 | validation: 0.022663864478562216]
	TIME [epoch: 25.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016459208011818983		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.016459208011818983 | validation: 0.020765394289972018]
	TIME [epoch: 25.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014329446068695566		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.014329446068695566 | validation: 0.027381143534519085]
	TIME [epoch: 25.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01555194928147089		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.01555194928147089 | validation: 0.02186037680756424]
	TIME [epoch: 25.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014794098181663941		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.014794098181663941 | validation: 0.02320925771315205]
	TIME [epoch: 25.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016683955741104095		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.016683955741104095 | validation: 0.022303205711868133]
	TIME [epoch: 25.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014959678589164948		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.014959678589164948 | validation: 0.023675897276083054]
	TIME [epoch: 25.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01534182778464752		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.01534182778464752 | validation: 0.020713852072995507]
	TIME [epoch: 25.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014010433834655027		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.014010433834655027 | validation: 0.021818394738600182]
	TIME [epoch: 25.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015414837710764167		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.015414837710764167 | validation: 0.023298802609015658]
	TIME [epoch: 25.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015032727572948795		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.015032727572948795 | validation: 0.021057484293883204]
	TIME [epoch: 25.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0147227449287495		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0147227449287495 | validation: 0.02280444093294158]
	TIME [epoch: 25.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01579165458864781		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.01579165458864781 | validation: 0.024104901014240485]
	TIME [epoch: 25.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014132934185285991		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.014132934185285991 | validation: 0.024394284156742475]
	TIME [epoch: 25.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015462332867492204		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.015462332867492204 | validation: 0.021120491333964292]
	TIME [epoch: 25.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013238073350052709		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.013238073350052709 | validation: 0.022242978349396883]
	TIME [epoch: 25.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014910046657166002		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.014910046657166002 | validation: 0.023124665394252456]
	TIME [epoch: 25.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015313291997833047		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.015313291997833047 | validation: 0.035878366539462546]
	TIME [epoch: 25.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01595851705081981		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.01595851705081981 | validation: 0.022126631329127497]
	TIME [epoch: 25.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01524795900839142		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.01524795900839142 | validation: 0.024086596366952033]
	TIME [epoch: 25.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014796600656813366		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.014796600656813366 | validation: 0.02175061475020874]
	TIME [epoch: 25.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014447470148122414		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.014447470148122414 | validation: 0.022828539672079436]
	TIME [epoch: 25.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01490013784476417		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.01490013784476417 | validation: 0.020849078425107144]
	TIME [epoch: 25.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01439790720536704		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.01439790720536704 | validation: 0.023380803353342777]
	TIME [epoch: 25.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015073013047702184		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.015073013047702184 | validation: 0.020511289552656204]
	TIME [epoch: 25.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016151334644053526		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.016151334644053526 | validation: 0.02492848521640568]
	TIME [epoch: 25.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015212336775669908		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.015212336775669908 | validation: 0.022983386863978203]
	TIME [epoch: 25.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013897104435730109		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.013897104435730109 | validation: 0.024916436447027193]
	TIME [epoch: 25.7 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014470084720891811		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.014470084720891811 | validation: 0.021323984261470003]
	TIME [epoch: 25.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014092018733053567		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.014092018733053567 | validation: 0.02059363663636512]
	TIME [epoch: 25.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014405390305824798		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.014405390305824798 | validation: 0.02279495017480495]
	TIME [epoch: 25.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016837170060787214		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.016837170060787214 | validation: 0.02393907772055061]
	TIME [epoch: 25.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013704656155856334		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.013704656155856334 | validation: 0.021319243436488312]
	TIME [epoch: 25.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013807242524143244		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.013807242524143244 | validation: 0.020058782434659087]
	TIME [epoch: 25.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013410144616646469		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.013410144616646469 | validation: 0.022188857665388115]
	TIME [epoch: 25.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015660812696324255		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.015660812696324255 | validation: 0.021241841461872364]
	TIME [epoch: 25.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013461268359452707		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.013461268359452707 | validation: 0.02367647462219463]
	TIME [epoch: 25.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016110152899899182		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.016110152899899182 | validation: 0.022032953961690104]
	TIME [epoch: 25.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015640998193886462		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.015640998193886462 | validation: 0.021542754671428826]
	TIME [epoch: 25.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014553749822818783		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.014553749822818783 | validation: 0.02145919685215903]
	TIME [epoch: 25.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013575491841680085		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.013575491841680085 | validation: 0.02190602925804875]
	TIME [epoch: 25.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013823892615524013		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.013823892615524013 | validation: 0.022640692000906425]
	TIME [epoch: 25.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014400441382130664		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.014400441382130664 | validation: 0.02025568770784787]
	TIME [epoch: 25.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012982742766136653		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.012982742766136653 | validation: 0.02060301852601959]
	TIME [epoch: 25.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015998966895073036		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.015998966895073036 | validation: 0.02990188460421963]
	TIME [epoch: 25.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015937501595575696		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.015937501595575696 | validation: 0.02224758759652537]
	TIME [epoch: 25.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01359251605935873		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.01359251605935873 | validation: 0.02469470543667448]
	TIME [epoch: 25.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014957756183173054		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.014957756183173054 | validation: 0.02367720815923622]
	TIME [epoch: 25.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015724337610707153		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.015724337610707153 | validation: 0.021609468397808168]
	TIME [epoch: 25.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013265787197354842		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.013265787197354842 | validation: 0.023114472102456936]
	TIME [epoch: 25.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01434377491008157		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.01434377491008157 | validation: 0.02327152835107787]
	TIME [epoch: 25.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013983977010971848		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.013983977010971848 | validation: 0.018865392374851134]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_866.pth
	Model improved!!!
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012719373826332411		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.012719373826332411 | validation: 0.020937542214594023]
	TIME [epoch: 25.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013711016528926628		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.013711016528926628 | validation: 0.020447447476477212]
	TIME [epoch: 25.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013692574355874388		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.013692574355874388 | validation: 0.020721564422156377]
	TIME [epoch: 25.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013755461892938033		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.013755461892938033 | validation: 0.02346263751077477]
	TIME [epoch: 25.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014348711529035087		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.014348711529035087 | validation: 0.022826942912682616]
	TIME [epoch: 25.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01411837741547274		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.01411837741547274 | validation: 0.026233057412832356]
	TIME [epoch: 25.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013810631322685164		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.013810631322685164 | validation: 0.022391768508637076]
	TIME [epoch: 25.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014267119220451218		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.014267119220451218 | validation: 0.022792314973206038]
	TIME [epoch: 25.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013528919249812105		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.013528919249812105 | validation: 0.02198876518753809]
	TIME [epoch: 25.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014375160089563372		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.014375160089563372 | validation: 0.02163219741512888]
	TIME [epoch: 25.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01353344503507772		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.01353344503507772 | validation: 0.02210197488187271]
	TIME [epoch: 25.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01338191546811852		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.01338191546811852 | validation: 0.020732592806005888]
	TIME [epoch: 25.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017278496114719162		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.017278496114719162 | validation: 0.02228272920010308]
	TIME [epoch: 25.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01349602259238707		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.01349602259238707 | validation: 0.020321231035027178]
	TIME [epoch: 25.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014404033950747849		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.014404033950747849 | validation: 0.02684589385230663]
	TIME [epoch: 25.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013242538212268517		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.013242538212268517 | validation: 0.022563843269996595]
	TIME [epoch: 25.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012502540727995995		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.012502540727995995 | validation: 0.024143542487023273]
	TIME [epoch: 25.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012802610929473459		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.012802610929473459 | validation: 0.020595569292420415]
	TIME [epoch: 25.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014001296023897613		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.014001296023897613 | validation: 0.02071039898443243]
	TIME [epoch: 25.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014024007429948353		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.014024007429948353 | validation: 0.023853346222538978]
	TIME [epoch: 25.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013829078890644967		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.013829078890644967 | validation: 0.02095792032609728]
	TIME [epoch: 25.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012588222658169912		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.012588222658169912 | validation: 0.019940061527273196]
	TIME [epoch: 25.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01351428459342361		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.01351428459342361 | validation: 0.023798968149400763]
	TIME [epoch: 25.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013396246408668374		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.013396246408668374 | validation: 0.020559211134261055]
	TIME [epoch: 25.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013065777299232209		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.013065777299232209 | validation: 0.022045131907964144]
	TIME [epoch: 25.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014385076890115167		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.014385076890115167 | validation: 0.0201920392054579]
	TIME [epoch: 25.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012955167533442334		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.012955167533442334 | validation: 0.020866849010041495]
	TIME [epoch: 25.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014132677408846613		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.014132677408846613 | validation: 0.020412492678184]
	TIME [epoch: 25.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01326076428187542		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.01326076428187542 | validation: 0.021942397278145148]
	TIME [epoch: 25.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013018258873950058		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.013018258873950058 | validation: 0.021002626387602856]
	TIME [epoch: 25.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014444382529027279		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.014444382529027279 | validation: 0.022055725963041888]
	TIME [epoch: 25.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013258882883555952		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.013258882883555952 | validation: 0.02040323216725619]
	TIME [epoch: 25.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013280646113339435		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.013280646113339435 | validation: 0.02204782244085296]
	TIME [epoch: 25.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012734158154966684		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.012734158154966684 | validation: 0.02152971489893126]
	TIME [epoch: 25.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012755209012308578		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.012755209012308578 | validation: 0.02534866522523703]
	TIME [epoch: 25.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013763392053036397		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.013763392053036397 | validation: 0.02047779104212263]
	TIME [epoch: 25.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013028833357719417		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.013028833357719417 | validation: 0.021934888531731186]
	TIME [epoch: 25.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013928071287436634		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.013928071287436634 | validation: 0.03174889276100217]
	TIME [epoch: 25.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017106669383441332		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.017106669383441332 | validation: 0.02018627818554737]
	TIME [epoch: 25.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013087417949716847		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.013087417949716847 | validation: 0.023735559082152802]
	TIME [epoch: 25.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013302400230030167		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.013302400230030167 | validation: 0.023473149531873287]
	TIME [epoch: 25.6 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012979027328014195		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.012979027328014195 | validation: 0.021564999127431733]
	TIME [epoch: 25.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013238161075654984		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.013238161075654984 | validation: 0.021223749239019353]
	TIME [epoch: 25.6 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013151194116113226		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.013151194116113226 | validation: 0.022503910365583073]
	TIME [epoch: 25.6 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012719097197666979		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.012719097197666979 | validation: 0.023075602277281212]
	TIME [epoch: 25.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012566479450920678		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.012566479450920678 | validation: 0.022945294821508068]
	TIME [epoch: 25.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013027438080723448		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.013027438080723448 | validation: 0.019206901728769772]
	TIME [epoch: 25.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01389966236759493		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.01389966236759493 | validation: 0.02387251263717173]
	TIME [epoch: 25.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012875005121360323		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.012875005121360323 | validation: 0.022596406619965346]
	TIME [epoch: 25.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01194290699753445		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.01194290699753445 | validation: 0.02037159441312122]
	TIME [epoch: 25.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01400647626377657		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.01400647626377657 | validation: 0.02080784343161823]
	TIME [epoch: 25.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01264062206971961		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.01264062206971961 | validation: 0.020925013448259713]
	TIME [epoch: 25.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013139325931796182		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.013139325931796182 | validation: 0.020461279201882843]
	TIME [epoch: 25.7 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012399940419728304		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.012399940419728304 | validation: 0.02265926663845943]
	TIME [epoch: 25.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011992082820022704		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.011992082820022704 | validation: 0.022832377090664255]
	TIME [epoch: 25.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01604255160355862		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.01604255160355862 | validation: 0.03163909946235192]
	TIME [epoch: 25.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01570807693515083		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.01570807693515083 | validation: 0.018931119193851015]
	TIME [epoch: 25.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012154605864673275		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.012154605864673275 | validation: 0.023570795875754873]
	TIME [epoch: 25.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012774293480743317		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.012774293480743317 | validation: 0.023295531146148442]
	TIME [epoch: 25.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014064880148985315		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.014064880148985315 | validation: 0.02123499447371216]
	TIME [epoch: 25.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012883756946367028		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.012883756946367028 | validation: 0.019041405395441833]
	TIME [epoch: 25.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012204963556730706		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.012204963556730706 | validation: 0.02283492084405224]
	TIME [epoch: 25.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012758875917072025		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.012758875917072025 | validation: 0.019670958710488486]
	TIME [epoch: 25.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012337705032622985		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.012337705032622985 | validation: 0.020818551355633114]
	TIME [epoch: 25.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013383142008299096		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.013383142008299096 | validation: 0.018381993037438166]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_931.pth
	Model improved!!!
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012629988822899695		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.012629988822899695 | validation: 0.01937895629643203]
	TIME [epoch: 25.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01320480500986907		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.01320480500986907 | validation: 0.020909981858158296]
	TIME [epoch: 25.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013084466493678308		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.013084466493678308 | validation: 0.020738374403941738]
	TIME [epoch: 25.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012826175541556451		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.012826175541556451 | validation: 0.020193573651523883]
	TIME [epoch: 25.6 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012580290439934895		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.012580290439934895 | validation: 0.02157067876523429]
	TIME [epoch: 25.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012346539125714798		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.012346539125714798 | validation: 0.02072871714272538]
	TIME [epoch: 25.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012668946149455337		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.012668946149455337 | validation: 0.01993702103264471]
	TIME [epoch: 25.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014515131865441617		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.014515131865441617 | validation: 0.024883385639870553]
	TIME [epoch: 25.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012432669695754801		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.012432669695754801 | validation: 0.020265060041608527]
	TIME [epoch: 25.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013260194998743128		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.013260194998743128 | validation: 0.020588284986922417]
	TIME [epoch: 25.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012321750572268865		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.012321750572268865 | validation: 0.040764900472601936]
	TIME [epoch: 25.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01697214776977379		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.01697214776977379 | validation: 0.02532256826317862]
	TIME [epoch: 25.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01448472752086122		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.01448472752086122 | validation: 0.021061063688344657]
	TIME [epoch: 25.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01265750948372453		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.01265750948372453 | validation: 0.019013749164909586]
	TIME [epoch: 25.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011612756997837936		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.011612756997837936 | validation: 0.02137614027004889]
	TIME [epoch: 25.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012512723588173827		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.012512723588173827 | validation: 0.020168631451681504]
	TIME [epoch: 25.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011861787262933896		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.011861787262933896 | validation: 0.0213996689419893]
	TIME [epoch: 25.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012697418919832608		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.012697418919832608 | validation: 0.02245229078769121]
	TIME [epoch: 25.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012040628821119973		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.012040628821119973 | validation: 0.020925419622610634]
	TIME [epoch: 25.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013282114088006758		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.013282114088006758 | validation: 0.02447646269450869]
	TIME [epoch: 25.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012863612157989954		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.012863612157989954 | validation: 0.020173375736840603]
	TIME [epoch: 25.6 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012316041316600319		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.012316041316600319 | validation: 0.020156493278824197]
	TIME [epoch: 25.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01304309132867398		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.01304309132867398 | validation: 0.021059075165776285]
	TIME [epoch: 25.6 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012070074912099502		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.012070074912099502 | validation: 0.02088798269849012]
	TIME [epoch: 25.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012577587784940107		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.012577587784940107 | validation: 0.01973176769157072]
	TIME [epoch: 25.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012806039952250903		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.012806039952250903 | validation: 0.02064981644557923]
	TIME [epoch: 25.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011860493060881376		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.011860493060881376 | validation: 0.021101622852955297]
	TIME [epoch: 25.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012209923596246596		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.012209923596246596 | validation: 0.020865368236056503]
	TIME [epoch: 25.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011703218368558426		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.011703218368558426 | validation: 0.021373693657561137]
	TIME [epoch: 25.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011467327260433553		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.011467327260433553 | validation: 0.019440395018143243]
	TIME [epoch: 25.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013787907881701904		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.013787907881701904 | validation: 0.020569404871989327]
	TIME [epoch: 25.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012277566875651694		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.012277566875651694 | validation: 0.022020933649049487]
	TIME [epoch: 25.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011787573747887631		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.011787573747887631 | validation: 0.020502250868108206]
	TIME [epoch: 25.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011474860956725176		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.011474860956725176 | validation: 0.01954220656774672]
	TIME [epoch: 25.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01285057869788046		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.01285057869788046 | validation: 0.020896290139184842]
	TIME [epoch: 25.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01273934621685794		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.01273934621685794 | validation: 0.04356212903365293]
	TIME [epoch: 25.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017199535284416884		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.017199535284416884 | validation: 0.02401240679738911]
	TIME [epoch: 25.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012469547876188073		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.012469547876188073 | validation: 0.021030178309408745]
	TIME [epoch: 25.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012038197963453645		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.012038197963453645 | validation: 0.02425215284753953]
	TIME [epoch: 25.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011771922759256441		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.011771922759256441 | validation: 0.018911650491742565]
	TIME [epoch: 25.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01240145847307237		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.01240145847307237 | validation: 0.019491394769949117]
	TIME [epoch: 25.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0127872660799371		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0127872660799371 | validation: 0.01924352514378213]
	TIME [epoch: 25.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011713644651602288		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.011713644651602288 | validation: 0.018432141485728314]
	TIME [epoch: 25.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011832750627221089		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.011832750627221089 | validation: 0.021045941898418394]
	TIME [epoch: 25.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012191757733649118		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.012191757733649118 | validation: 0.01797562740970458]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011623923819067596		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.011623923819067596 | validation: 0.01984736623139634]
	TIME [epoch: 25.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011675261638989317		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.011675261638989317 | validation: 0.026371519326743947]
	TIME [epoch: 25.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013653129131553705		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.013653129131553705 | validation: 0.02017857856327774]
	TIME [epoch: 25.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01237171817862037		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.01237171817862037 | validation: 0.020444218480463405]
	TIME [epoch: 25.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011652356850709688		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.011652356850709688 | validation: 0.019634809630911392]
	TIME [epoch: 25.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012115274585276593		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.012115274585276593 | validation: 0.019960703955561997]
	TIME [epoch: 25.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011757266789812608		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.011757266789812608 | validation: 0.019915019700024864]
	TIME [epoch: 25.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012146891527507045		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.012146891527507045 | validation: 0.024852782754382123]
	TIME [epoch: 25.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012259632383948848		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.012259632383948848 | validation: 0.01891024185248135]
	TIME [epoch: 25.6 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013610338448340116		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.013610338448340116 | validation: 0.023622794032161012]
	TIME [epoch: 25.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013222670326526093		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.013222670326526093 | validation: 0.018118813777585323]
	TIME [epoch: 25.6 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011488456146199526		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.011488456146199526 | validation: 0.0196781217945872]
	TIME [epoch: 25.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012181426830318212		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.012181426830318212 | validation: 0.019257532703281628]
	TIME [epoch: 25.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01230345052125713		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.01230345052125713 | validation: 0.01808746765410745]
	TIME [epoch: 25.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01225196181803341		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.01225196181803341 | validation: 0.020132960109080805]
	TIME [epoch: 25.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011490124047639225		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.011490124047639225 | validation: 0.02033635300987081]
	TIME [epoch: 25.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011750992269454096		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.011750992269454096 | validation: 0.020828434264874324]
	TIME [epoch: 25.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012632478735929119		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.012632478735929119 | validation: 0.020196314384382186]
	TIME [epoch: 25.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012095411761481673		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.012095411761481673 | validation: 0.020157060333507143]
	TIME [epoch: 25.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011932123761788465		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.011932123761788465 | validation: 0.02221299870075874]
	TIME [epoch: 25.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012525829446551345		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.012525829446551345 | validation: 0.018902486453206274]
	TIME [epoch: 25.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011917760339494961		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.011917760339494961 | validation: 0.021299912797959748]
	TIME [epoch: 25.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012221690349748175		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.012221690349748175 | validation: 0.018886811703634886]
	TIME [epoch: 25.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012304133325808164		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.012304133325808164 | validation: 0.018901946455569026]
	TIME [epoch: 25.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011682546074141206		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.011682546074141206 | validation: 0.026046721249094587]
	TIME [epoch: 416 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012613555662909804		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.012613555662909804 | validation: 0.0197226346891939]
	TIME [epoch: 54.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011714593947166854		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.011714593947166854 | validation: 0.019812607864569717]
	TIME [epoch: 54.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013504284143526984		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.013504284143526984 | validation: 0.021165314631213246]
	TIME [epoch: 54.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011888813194581531		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.011888813194581531 | validation: 0.020689169464798533]
	TIME [epoch: 54.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011105295091143224		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.011105295091143224 | validation: 0.019701923558655316]
	TIME [epoch: 54.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01205890388821934		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.01205890388821934 | validation: 0.022326854437742426]
	TIME [epoch: 54.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012228223817050278		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.012228223817050278 | validation: 0.020105288156039985]
	TIME [epoch: 54.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01191142211412869		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.01191142211412869 | validation: 0.021166235676876352]
	TIME [epoch: 54.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011948192720477344		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.011948192720477344 | validation: 0.019302798113979107]
	TIME [epoch: 54.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011881063336156857		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.011881063336156857 | validation: 0.019612107788968387]
	TIME [epoch: 54.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011747776788047455		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.011747776788047455 | validation: 0.020056531253443623]
	TIME [epoch: 54.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012126237746245303		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.012126237746245303 | validation: 0.020385521232399825]
	TIME [epoch: 54.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012176076622559194		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.012176076622559194 | validation: 0.01872491664813217]
	TIME [epoch: 54.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011506810083672214		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.011506810083672214 | validation: 0.019652768616909323]
	TIME [epoch: 54.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012226341167935686		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.012226341167935686 | validation: 0.020647626680277052]
	TIME [epoch: 54.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011974278065995818		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.011974278065995818 | validation: 0.01983341845777463]
	TIME [epoch: 54.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012219677662210002		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.012219677662210002 | validation: 0.01961635153501437]
	TIME [epoch: 54.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011407822278198981		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.011407822278198981 | validation: 0.02101941957130539]
	TIME [epoch: 54.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011171818750820291		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.011171818750820291 | validation: 0.018421436565834327]
	TIME [epoch: 54.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011378262214295245		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.011378262214295245 | validation: 0.018407157460523335]
	TIME [epoch: 54.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011658471954170085		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.011658471954170085 | validation: 0.02111894251265846]
	TIME [epoch: 54.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011807392967656316		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.011807392967656316 | validation: 0.019535165682682255]
	TIME [epoch: 54.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011462567559123036		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.011462567559123036 | validation: 0.019273292959021884]
	TIME [epoch: 54.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011754086782450117		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.011754086782450117 | validation: 0.017375590365735875]
	TIME [epoch: 54.3 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_1025.pth
	Model improved!!!
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011536951194202623		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.011536951194202623 | validation: 0.018880292042170954]
	TIME [epoch: 54.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010885904379239319		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.010885904379239319 | validation: 0.019127953012134866]
	TIME [epoch: 54.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011262751558647009		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.011262751558647009 | validation: 0.021734315869873427]
	TIME [epoch: 54.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011265124826050986		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.011265124826050986 | validation: 0.020740987703400948]
	TIME [epoch: 54.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011884212140192236		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.011884212140192236 | validation: 0.020265467579493844]
	TIME [epoch: 54.4 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011131754446466826		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.011131754446466826 | validation: 0.02142444153957664]
	TIME [epoch: 54.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012157400838986272		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.012157400838986272 | validation: 0.01877161430371807]
	TIME [epoch: 54.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011739376709269028		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.011739376709269028 | validation: 0.020035536526761016]
	TIME [epoch: 54.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012363585584794317		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.012363585584794317 | validation: 0.02021303500314007]
	TIME [epoch: 54.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011241451722507654		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.011241451722507654 | validation: 0.020659280147276603]
	TIME [epoch: 54.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011257890736043118		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.011257890736043118 | validation: 0.020843710646586154]
	TIME [epoch: 54.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010962693808827959		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.010962693808827959 | validation: 0.020306728357776974]
	TIME [epoch: 54.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011213250696808006		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.011213250696808006 | validation: 0.01942894525288958]
	TIME [epoch: 54.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01160342559935229		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.01160342559935229 | validation: 0.021080723404639165]
	TIME [epoch: 54.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011315178902877643		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.011315178902877643 | validation: 0.019769824771456192]
	TIME [epoch: 54.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01593997449054921		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.01593997449054921 | validation: 0.024222924403745287]
	TIME [epoch: 54.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012848857016016978		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.012848857016016978 | validation: 0.01951760156653644]
	TIME [epoch: 54.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011584853205454554		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.011584853205454554 | validation: 0.020546743325489527]
	TIME [epoch: 54.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010827781040041024		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.010827781040041024 | validation: 0.02076654831153939]
	TIME [epoch: 54.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01247228353246711		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.01247228353246711 | validation: 0.02023042026335674]
	TIME [epoch: 54.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011146490176458992		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.011146490176458992 | validation: 0.020782036164124294]
	TIME [epoch: 54.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011554718308342041		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.011554718308342041 | validation: 0.020497610496107033]
	TIME [epoch: 54.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01113002498452996		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.01113002498452996 | validation: 0.023063343108668394]
	TIME [epoch: 54.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011284481521912646		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.011284481521912646 | validation: 0.019172337075125334]
	TIME [epoch: 54.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011630042371807339		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.011630042371807339 | validation: 0.026469064698423323]
	TIME [epoch: 54.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012271187466003012		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.012271187466003012 | validation: 0.019295380569407553]
	TIME [epoch: 54.4 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011023602728636932		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.011023602728636932 | validation: 0.019305574720514553]
	TIME [epoch: 54.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014063627630122432		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.014063627630122432 | validation: 0.025238317181120344]
	TIME [epoch: 54.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012095585548698207		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.012095585548698207 | validation: 0.02081039521323097]
	TIME [epoch: 54.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011708944169491546		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.011708944169491546 | validation: 0.02303052794683602]
	TIME [epoch: 54.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011096816235577463		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.011096816235577463 | validation: 0.020314571515468324]
	TIME [epoch: 54.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014205091454432772		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.014205091454432772 | validation: 0.022732721371555457]
	TIME [epoch: 54.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012713133650793042		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.012713133650793042 | validation: 0.01790481713069342]
	TIME [epoch: 54.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010936147438608766		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.010936147438608766 | validation: 0.018781823512338987]
	TIME [epoch: 54.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010910855623483933		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.010910855623483933 | validation: 0.019881255278137156]
	TIME [epoch: 54.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01142252384715649		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.01142252384715649 | validation: 0.019708277970159643]
	TIME [epoch: 54.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010651307253538366		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.010651307253538366 | validation: 0.018285037010784405]
	TIME [epoch: 54.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01092250208913312		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.01092250208913312 | validation: 0.018221496761868915]
	TIME [epoch: 54.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01091615216202878		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.01091615216202878 | validation: 0.020769185407829047]
	TIME [epoch: 54.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01122295908039782		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.01122295908039782 | validation: 0.01790284567737354]
	TIME [epoch: 54.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010966332306697241		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.010966332306697241 | validation: 0.01991677777510787]
	TIME [epoch: 54.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011507425057931852		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.011507425057931852 | validation: 0.017590151231162445]
	TIME [epoch: 54.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011133496638709186		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.011133496638709186 | validation: 0.019035780484398614]
	TIME [epoch: 54.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011187802655288648		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.011187802655288648 | validation: 0.01787050057901507]
	TIME [epoch: 54.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012023820702826876		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.012023820702826876 | validation: 0.01844023753169932]
	TIME [epoch: 54.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011199969700942112		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.011199969700942112 | validation: 0.018298442068899263]
	TIME [epoch: 54.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010786162548999374		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.010786162548999374 | validation: 0.01926801417398219]
	TIME [epoch: 54.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010501163995826089		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.010501163995826089 | validation: 0.017875990647894996]
	TIME [epoch: 54.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010725276321958825		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.010725276321958825 | validation: 0.020003250552462985]
	TIME [epoch: 54.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011232291845138844		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.011232291845138844 | validation: 0.019637097945016085]
	TIME [epoch: 54.4 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011131326016443389		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.011131326016443389 | validation: 0.01858497169829475]
	TIME [epoch: 54.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010749184258093498		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.010749184258093498 | validation: 0.01943801685002748]
	TIME [epoch: 54.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011574950860950574		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.011574950860950574 | validation: 0.01943407190510448]
	TIME [epoch: 54.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01098364621729693		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.01098364621729693 | validation: 0.019584833784530548]
	TIME [epoch: 54.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011888370536204153		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.011888370536204153 | validation: 0.02291101794527739]
	TIME [epoch: 54.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010869556675092764		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.010869556675092764 | validation: 0.018559284174512573]
	TIME [epoch: 54.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010819488019129962		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.010819488019129962 | validation: 0.02023037603465397]
	TIME [epoch: 54.4 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010926220334960208		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.010926220334960208 | validation: 0.02027814100421733]
	TIME [epoch: 54.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010950910857738073		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.010950910857738073 | validation: 0.018274790100929125]
	TIME [epoch: 54.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011241416739630054		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.011241416739630054 | validation: 0.019285699816651007]
	TIME [epoch: 54.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010973600588553921		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.010973600588553921 | validation: 0.01951111143020097]
	TIME [epoch: 54.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010664784884289421		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.010664784884289421 | validation: 0.0200486305415637]
	TIME [epoch: 54.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011328567768512713		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.011328567768512713 | validation: 0.019258500386886666]
	TIME [epoch: 54.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010991862667169125		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.010991862667169125 | validation: 0.019987791799135787]
	TIME [epoch: 54.4 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011318721582685593		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.011318721582685593 | validation: 0.01987628266529056]
	TIME [epoch: 54.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011212958294141583		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.011212958294141583 | validation: 0.018380976656027358]
	TIME [epoch: 54.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011471287827708806		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.011471287827708806 | validation: 0.018446797298176172]
	TIME [epoch: 54.3 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010943967774313317		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.010943967774313317 | validation: 0.019649697538852914]
	TIME [epoch: 54.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0110032842176125		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.0110032842176125 | validation: 0.019398519279032227]
	TIME [epoch: 54.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010852846756555453		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.010852846756555453 | validation: 0.018977650181022244]
	TIME [epoch: 54.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0109684123152033		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.0109684123152033 | validation: 0.017569287645898445]
	TIME [epoch: 54.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010980781012772363		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.010980781012772363 | validation: 0.018534566928038343]
	TIME [epoch: 54.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01158311257753982		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.01158311257753982 | validation: 0.019200478139989176]
	TIME [epoch: 54.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011440688941172105		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.011440688941172105 | validation: 0.017479343218631975]
	TIME [epoch: 54.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010742913568062428		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.010742913568062428 | validation: 0.020118549392838303]
	TIME [epoch: 54.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010470321893088665		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.010470321893088665 | validation: 0.018945290881253095]
	TIME [epoch: 54.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010750318504204617		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.010750318504204617 | validation: 0.017889314465729757]
	TIME [epoch: 54.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010864550696328162		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.010864550696328162 | validation: 0.018805093169882266]
	TIME [epoch: 54.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011056409424586446		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.011056409424586446 | validation: 0.02150620903343342]
	TIME [epoch: 54.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010932434412416868		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.010932434412416868 | validation: 0.019359918707560684]
	TIME [epoch: 54.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01121699349502531		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.01121699349502531 | validation: 0.019840831937324614]
	TIME [epoch: 54.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011008516923578054		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.011008516923578054 | validation: 0.019748922751401894]
	TIME [epoch: 54.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010656165424427369		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.010656165424427369 | validation: 0.020327423448335227]
	TIME [epoch: 54.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010691788947116745		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.010691788947116745 | validation: 0.020343100996771467]
	TIME [epoch: 54.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011813480457235823		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.011813480457235823 | validation: 0.022300959646064614]
	TIME [epoch: 54.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010423698098978054		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.010423698098978054 | validation: 0.017424088091059428]
	TIME [epoch: 54.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011126257180647657		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.011126257180647657 | validation: 0.021051780389115336]
	TIME [epoch: 54.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010501042798570923		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.010501042798570923 | validation: 0.01989126248046033]
	TIME [epoch: 54.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011053523229294494		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.011053523229294494 | validation: 0.019456718258146308]
	TIME [epoch: 54.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010322419699599399		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.010322419699599399 | validation: 0.018558494847351652]
	TIME [epoch: 54.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01080975913609845		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.01080975913609845 | validation: 0.01891207987045672]
	TIME [epoch: 54.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010805138519392271		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.010805138519392271 | validation: 0.018750215245787183]
	TIME [epoch: 54.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011095182640978012		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.011095182640978012 | validation: 0.018065301001506075]
	TIME [epoch: 54.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01046063728251672		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.01046063728251672 | validation: 0.017717350592664795]
	TIME [epoch: 54.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011054369600836868		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.011054369600836868 | validation: 0.019187566530825054]
	TIME [epoch: 54.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011137384277483555		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.011137384277483555 | validation: 0.01830829435631364]
	TIME [epoch: 54.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01127419578076495		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.01127419578076495 | validation: 0.02036689214131569]
	TIME [epoch: 54.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010527357443941291		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.010527357443941291 | validation: 0.018252439931052803]
	TIME [epoch: 54.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01045866041050339		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.01045866041050339 | validation: 0.018562966125807573]
	TIME [epoch: 54.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010918074289498366		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.010918074289498366 | validation: 0.01954958631180601]
	TIME [epoch: 54.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011026244100883771		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.011026244100883771 | validation: 0.01884717006765937]
	TIME [epoch: 54.3 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1c_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1c_3_v_mmd1_1126.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 26128.602 seconds.
