Args:
Namespace(name='model_phi1_1a_saddle_v1b_3_v_mmd1', outdir='out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1', training_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1b_3/training', validation_data='data/training_data/saddle_v1/data_phi1_1a_saddle_v1b_3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05198487639427185, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2561257954

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344616918228741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.344616918228741 | validation: 4.684300956196342]
	TIME [epoch: 386 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.712795616311774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.712795616311774 | validation: 4.403716076060244]
	TIME [epoch: 6.16 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2603046061662635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2603046061662635 | validation: 3.721568273763651]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110321340453314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.110321340453314 | validation: 3.5828009419533986]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7356936838604953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7356936838604953 | validation: 3.298387160157689]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457563201724149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.457563201724149 | validation: 3.08117268261661]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3246740245519693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3246740245519693 | validation: 2.888497033711673]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.149963921285102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.149963921285102 | validation: 2.9605730786298103]
	TIME [epoch: 6.12 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0996429935618393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0996429935618393 | validation: 2.8349088054820726]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.082279153757399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.082279153757399 | validation: 2.838450349237877]
	TIME [epoch: 6.12 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0574166402127765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0574166402127765 | validation: 2.8803864862879403]
	TIME [epoch: 6.12 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0658173948340703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0658173948340703 | validation: 2.819138367736117]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0217041083921465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0217041083921465 | validation: 2.8052919211861465]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.023733352422301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.023733352422301 | validation: 2.8777783586109456]
	TIME [epoch: 6.11 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0088352146557047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0088352146557047 | validation: 2.7599151654274308]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.972784562497732		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.972784562497732 | validation: 2.767956531118646]
	TIME [epoch: 6.12 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9861991138122836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9861991138122836 | validation: 2.7390618735880583]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9634794494967527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9634794494967527 | validation: 2.7348784715340155]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9292497306402145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9292497306402145 | validation: 2.7285639606737346]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9429428619268245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9429428619268245 | validation: 2.7303372818011233]
	TIME [epoch: 6.11 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9211749856759477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9211749856759477 | validation: 2.7114791276361547]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8912475458652205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8912475458652205 | validation: 2.696720208282356]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.933645355459964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.933645355459964 | validation: 2.698352226195202]
	TIME [epoch: 6.11 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8481746935928367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8481746935928367 | validation: 2.7187735128043276]
	TIME [epoch: 6.11 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7960281814365593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7960281814365593 | validation: 2.7870140703918125]
	TIME [epoch: 6.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.762045029816661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.762045029816661 | validation: 2.503915038152218]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8886161511994137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8886161511994137 | validation: 2.5965807693160508]
	TIME [epoch: 6.1 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5677346001587873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5677346001587873 | validation: 2.3314058402051994]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3407460123490296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3407460123490296 | validation: 2.1487744431966735]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3376406659404587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3376406659404587 | validation: 2.0821241848214376]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.294373062777218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.294373062777218 | validation: 2.0242457414114434]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.195109434027967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.195109434027967 | validation: 1.9697656934475294]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1856520503077843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1856520503077843 | validation: 2.063942930753602]
	TIME [epoch: 6.1 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0388574506446533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0388574506446533 | validation: 1.8837431322922908]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0613668407900936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0613668407900936 | validation: 2.083153063556403]
	TIME [epoch: 6.11 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0175994257093186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0175994257093186 | validation: 1.824852579857307]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.992888150805232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.992888150805232 | validation: 1.929297166024468]
	TIME [epoch: 6.12 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0190780647667825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0190780647667825 | validation: 2.2368504222914414]
	TIME [epoch: 6.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.044533991829513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.044533991829513 | validation: 1.7372078750225577]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8678294185220636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8678294185220636 | validation: 1.7953346383063904]
	TIME [epoch: 6.13 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.267071557504632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.267071557504632 | validation: 1.708445645837162]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.79145205871291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.79145205871291 | validation: 1.6549559857034688]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8154803160727166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8154803160727166 | validation: 1.6767908379579692]
	TIME [epoch: 6.11 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7728779828342764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7728779828342764 | validation: 1.5101959775071263]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8278509173377342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8278509173377342 | validation: 1.8920315802487995]
	TIME [epoch: 6.11 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8496189972887387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8496189972887387 | validation: 1.8329022860931665]
	TIME [epoch: 6.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7339322162773139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7339322162773139 | validation: 1.3872403554839747]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8293413757986623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8293413757986623 | validation: 2.03006453427566]
	TIME [epoch: 6.1 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9117255940201912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9117255940201912 | validation: 1.5362167314024786]
	TIME [epoch: 6.1 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5513486282437194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5513486282437194 | validation: 1.5579957298078766]
	TIME [epoch: 6.11 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6269331851392983		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.6269331851392983 | validation: 1.7579105838152613]
	TIME [epoch: 6.1 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8757744938476688		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.8757744938476688 | validation: 1.3018633031315692]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3465468817074506		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.3465468817074506 | validation: 1.2592163416187725]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301561758870706		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.301561758870706 | validation: 1.0554504669340794]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2614171399792207		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.2614171399792207 | validation: 1.2853525330849687]
	TIME [epoch: 6.11 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5219827167196383		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.5219827167196383 | validation: 1.270649372982144]
	TIME [epoch: 6.1 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2930663920412884		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.2930663920412884 | validation: 1.4726151319491385]
	TIME [epoch: 6.1 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152868996349042		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.152868996349042 | validation: 0.9452097099215333]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3733946516740372		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.3733946516740372 | validation: 0.908162014530074]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1088247590402152		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.1088247590402152 | validation: 1.0437144068412108]
	TIME [epoch: 6.11 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0889862067697187		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.0889862067697187 | validation: 0.8510581972356699]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0030459208864517		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.0030459208864517 | validation: 1.159538312788294]
	TIME [epoch: 6.1 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1001919603689365		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.1001919603689365 | validation: 0.9450258543382856]
	TIME [epoch: 6.09 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.17355633674889		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.17355633674889 | validation: 1.5080802440454535]
	TIME [epoch: 6.1 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1709020570083877		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.1709020570083877 | validation: 0.8412886062103306]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8889017379076882		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 0.8889017379076882 | validation: 0.8481518120955003]
	TIME [epoch: 6.1 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.871889622454224		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.871889622454224 | validation: 0.7665714836055894]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0014677008588682		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.0014677008588682 | validation: 0.7747274949449534]
	TIME [epoch: 6.1 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9146677488669674		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.9146677488669674 | validation: 1.0846971795448248]
	TIME [epoch: 6.11 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0571545706773895		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.0571545706773895 | validation: 0.8756013164032799]
	TIME [epoch: 6.1 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8708255674508385		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.8708255674508385 | validation: 0.9426547408829611]
	TIME [epoch: 6.1 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7372268258014171		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.7372268258014171 | validation: 0.5878295266065692]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9642758617055751		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.9642758617055751 | validation: 0.8303526541892083]
	TIME [epoch: 6.11 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8211911736078858		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.8211911736078858 | validation: 0.7295884351590773]
	TIME [epoch: 6.1 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786114374709158		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.786114374709158 | validation: 0.6777902251949406]
	TIME [epoch: 6.1 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7065294246265494		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.7065294246265494 | validation: 0.8627793235061376]
	TIME [epoch: 6.11 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8132368143307729		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.8132368143307729 | validation: 0.5221208193733475]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6609894159997838		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.6609894159997838 | validation: 1.0222353457058682]
	TIME [epoch: 6.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9458143499523365		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.9458143499523365 | validation: 0.9061324298648106]
	TIME [epoch: 6.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996532372344564		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.6996532372344564 | validation: 0.5907501533140971]
	TIME [epoch: 6.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567847329975432		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.567847329975432 | validation: 0.5564513325998213]
	TIME [epoch: 6.1 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111593217038579		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6111593217038579 | validation: 0.5736347761736316]
	TIME [epoch: 6.1 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180217556777402		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.5180217556777402 | validation: 0.9166855937221906]
	TIME [epoch: 6.11 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477290208894027		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6477290208894027 | validation: 0.5302668221167989]
	TIME [epoch: 6.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7621834435540364		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.7621834435540364 | validation: 0.5588132711253053]
	TIME [epoch: 6.11 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5716816485834532		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5716816485834532 | validation: 0.43909997562737263]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839611039265126		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.4839611039265126 | validation: 0.9125485454603567]
	TIME [epoch: 6.1 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9945860988797972		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.9945860988797972 | validation: 0.5743705991030272]
	TIME [epoch: 6.11 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5320643819425168		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.5320643819425168 | validation: 0.4397516780173364]
	TIME [epoch: 6.14 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556098134807729		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.4556098134807729 | validation: 0.6527000681785162]
	TIME [epoch: 6.11 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229241445894682		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.7229241445894682 | validation: 0.9324917251540129]
	TIME [epoch: 6.11 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9099169108558759		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.9099169108558759 | validation: 0.6266492108084502]
	TIME [epoch: 6.11 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560569825141029		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.560569825141029 | validation: 0.37862737950921]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4742611494115294		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4742611494115294 | validation: 0.6297373557742381]
	TIME [epoch: 6.11 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504086008686666		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.504086008686666 | validation: 0.3648504107150832]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691822328674505		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.6691822328674505 | validation: 0.6257412053772262]
	TIME [epoch: 6.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775851638528942		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.6775851638528942 | validation: 0.5889194909264306]
	TIME [epoch: 6.11 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49574979136921304		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.49574979136921304 | validation: 0.35939267233570993]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424281770352663		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.6424281770352663 | validation: 0.44083071595894135]
	TIME [epoch: 6.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43220777519325715		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.43220777519325715 | validation: 0.503658957761694]
	TIME [epoch: 6.11 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44244926194250134		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.44244926194250134 | validation: 0.48998484017708266]
	TIME [epoch: 6.1 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188296947885579		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5188296947885579 | validation: 1.0051815136127702]
	TIME [epoch: 6.11 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.794798737036666		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.794798737036666 | validation: 0.5449888878189055]
	TIME [epoch: 6.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47544346149626976		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.47544346149626976 | validation: 0.5752492424393053]
	TIME [epoch: 6.1 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4664860979863082		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4664860979863082 | validation: 0.3755306432421789]
	TIME [epoch: 6.1 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5192466558401163		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5192466558401163 | validation: 0.6340995081057482]
	TIME [epoch: 6.11 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6066851160936207		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.6066851160936207 | validation: 0.517420953162078]
	TIME [epoch: 6.11 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45313468005554697		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.45313468005554697 | validation: 0.37597476186509815]
	TIME [epoch: 6.1 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44964108371747114		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.44964108371747114 | validation: 0.4433621170519926]
	TIME [epoch: 6.11 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43374110954436085		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.43374110954436085 | validation: 0.3870316524530911]
	TIME [epoch: 6.11 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4545072860863508		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.4545072860863508 | validation: 0.45718401454395674]
	TIME [epoch: 6.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5151032841935547		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.5151032841935547 | validation: 0.3671214983327585]
	TIME [epoch: 6.11 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36847755705682067		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.36847755705682067 | validation: 0.40247918790142556]
	TIME [epoch: 6.1 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5225929644796468		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.5225929644796468 | validation: 0.8209174140798171]
	TIME [epoch: 6.11 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124351250252767		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.6124351250252767 | validation: 0.5012526866548908]
	TIME [epoch: 6.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943352187889397		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.3943352187889397 | validation: 0.3327913261777812]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3105725127046414		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.3105725127046414 | validation: 0.425377762288637]
	TIME [epoch: 6.11 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316462518808265		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.5316462518808265 | validation: 0.6431522843390443]
	TIME [epoch: 6.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205550523664857		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.5205550523664857 | validation: 0.42503849058637944]
	TIME [epoch: 6.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3418059713929844		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.3418059713929844 | validation: 0.40257111824132297]
	TIME [epoch: 6.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4559762866027749		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.4559762866027749 | validation: 0.4748477124404489]
	TIME [epoch: 6.11 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46118344091836605		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.46118344091836605 | validation: 0.46037670451166157]
	TIME [epoch: 6.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38859770657706477		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.38859770657706477 | validation: 0.3288729836560556]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3943893779309907		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.3943893779309907 | validation: 0.3311643129432661]
	TIME [epoch: 6.11 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587804161029575		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5587804161029575 | validation: 0.6523411560619832]
	TIME [epoch: 6.1 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201342323512076		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.5201342323512076 | validation: 0.36010521603879575]
	TIME [epoch: 6.11 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3140336217074058		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3140336217074058 | validation: 0.3700343360807493]
	TIME [epoch: 6.11 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39411183903259794		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.39411183903259794 | validation: 0.3555630069354063]
	TIME [epoch: 6.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37105917807776934		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.37105917807776934 | validation: 0.2965458887691863]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37093956528930583		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.37093956528930583 | validation: 0.5657213367639038]
	TIME [epoch: 6.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4558390046205194		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.4558390046205194 | validation: 0.41190319231653516]
	TIME [epoch: 6.1 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3719043643523035		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.3719043643523035 | validation: 0.40530827645199075]
	TIME [epoch: 6.09 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637847974482823		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.3637847974482823 | validation: 0.5037621818584559]
	TIME [epoch: 6.1 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3850308173449557		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.3850308173449557 | validation: 0.3362760504251127]
	TIME [epoch: 6.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34289239892938017		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.34289239892938017 | validation: 0.3503696854180973]
	TIME [epoch: 6.11 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36812768788684214		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.36812768788684214 | validation: 0.431962801684684]
	TIME [epoch: 6.09 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717809233930868		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.4717809233930868 | validation: 0.4893737621438389]
	TIME [epoch: 6.09 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38076442162827884		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 0.38076442162827884 | validation: 0.29450245628738847]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3218557526410857		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3218557526410857 | validation: 0.4783977070558715]
	TIME [epoch: 6.11 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221607843895054		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.4221607843895054 | validation: 0.427584271220031]
	TIME [epoch: 6.1 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622109770447789		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3622109770447789 | validation: 0.31900510096232915]
	TIME [epoch: 6.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172147642667025		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3172147642667025 | validation: 0.35274785418411814]
	TIME [epoch: 6.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40543066674090567		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.40543066674090567 | validation: 0.3790499960844565]
	TIME [epoch: 6.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35475100324500536		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.35475100324500536 | validation: 0.3739477435199364]
	TIME [epoch: 6.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32901787203778565		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.32901787203778565 | validation: 0.35582945591461124]
	TIME [epoch: 6.09 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3446767696512143		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3446767696512143 | validation: 0.2618596712834678]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545974822865933		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.2545974822865933 | validation: 0.3454130951910915]
	TIME [epoch: 6.11 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34295315191574366		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.34295315191574366 | validation: 0.47065514640963435]
	TIME [epoch: 6.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128011735146685		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.4128011735146685 | validation: 0.3505390741951465]
	TIME [epoch: 6.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825383810754763		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.2825383810754763 | validation: 0.2656504995333945]
	TIME [epoch: 6.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808254521370446		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.2808254521370446 | validation: 0.3638544708990603]
	TIME [epoch: 6.11 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056265111751114		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3056265111751114 | validation: 0.38683848555638184]
	TIME [epoch: 6.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762828565923187		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.2762828565923187 | validation: 0.37473130034508706]
	TIME [epoch: 6.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3453900911904657		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3453900911904657 | validation: 0.2977872287036961]
	TIME [epoch: 6.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2738137141717137		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.2738137141717137 | validation: 0.2635154142871672]
	TIME [epoch: 6.11 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699184515093783		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.2699184515093783 | validation: 0.27184214845226945]
	TIME [epoch: 6.12 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32437474499607816		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.32437474499607816 | validation: 0.38467034792811466]
	TIME [epoch: 6.11 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3299087098917459		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3299087098917459 | validation: 0.2558123047005043]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827683129977746		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.2827683129977746 | validation: 0.2684241251869488]
	TIME [epoch: 6.11 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788373122450757		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.2788373122450757 | validation: 0.3308767039882098]
	TIME [epoch: 6.12 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29952124362120647		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 0.29952124362120647 | validation: 0.28031435182065095]
	TIME [epoch: 6.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610741380644602		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.2610741380644602 | validation: 0.3506577062194843]
	TIME [epoch: 6.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527403904787433		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.3527403904787433 | validation: 0.31454511171851607]
	TIME [epoch: 6.1 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33909506912023113		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.33909506912023113 | validation: 0.31709271169100983]
	TIME [epoch: 6.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2492106495760451		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.2492106495760451 | validation: 0.31747550290625526]
	TIME [epoch: 6.1 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26013701899392877		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.26013701899392877 | validation: 0.25150538694209396]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23063569552912638		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.23063569552912638 | validation: 0.3117514662472446]
	TIME [epoch: 6.1 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23641049683978263		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.23641049683978263 | validation: 0.2685341108811543]
	TIME [epoch: 6.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011071092718519		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4011071092718519 | validation: 0.30572841839094783]
	TIME [epoch: 6.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26309447247508433		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.26309447247508433 | validation: 0.2637581561339343]
	TIME [epoch: 6.19 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24585438068748963		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.24585438068748963 | validation: 0.2868726286713378]
	TIME [epoch: 6.24 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259010779884594		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.259010779884594 | validation: 0.247239568873319]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26486991468099064		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.26486991468099064 | validation: 0.2045768613840978]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23977647356961657		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.23977647356961657 | validation: 0.22381043822031738]
	TIME [epoch: 6.11 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19347614897591509		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.19347614897591509 | validation: 0.26380228014570045]
	TIME [epoch: 6.12 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3113761019243916		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 0.3113761019243916 | validation: 0.4308015049895593]
	TIME [epoch: 6.11 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3172273942663544		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3172273942663544 | validation: 0.24308343921022765]
	TIME [epoch: 6.11 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20317127668945772		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.20317127668945772 | validation: 0.19699671926322512]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21613044938561082		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.21613044938561082 | validation: 0.22572394855636008]
	TIME [epoch: 6.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2835572411136882		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.2835572411136882 | validation: 0.3795794075100368]
	TIME [epoch: 6.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24704578034759672		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.24704578034759672 | validation: 0.24609319288395753]
	TIME [epoch: 6.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20818294406368182		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.20818294406368182 | validation: 0.2358330617953489]
	TIME [epoch: 6.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20844361603754183		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.20844361603754183 | validation: 0.2619922214864612]
	TIME [epoch: 6.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821090206936115		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.1821090206936115 | validation: 0.35152288115115704]
	TIME [epoch: 6.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20886959903511035		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.20886959903511035 | validation: 0.2926548266140656]
	TIME [epoch: 6.11 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2108596841168382		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.2108596841168382 | validation: 0.17650961192192577]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17531615248757873		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.17531615248757873 | validation: 0.2998677401254708]
	TIME [epoch: 6.11 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22932863364732314		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.22932863364732314 | validation: 0.18890653295643922]
	TIME [epoch: 6.11 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066576225993949		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.2066576225993949 | validation: 0.22568633644596697]
	TIME [epoch: 6.11 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20538049115338233		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.20538049115338233 | validation: 0.3343174914853597]
	TIME [epoch: 6.11 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23290016481774517		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.23290016481774517 | validation: 0.18217504415165592]
	TIME [epoch: 6.11 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19901638943353792		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.19901638943353792 | validation: 0.2652563134014843]
	TIME [epoch: 6.11 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20694022944916124		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.20694022944916124 | validation: 0.25879955480050615]
	TIME [epoch: 6.11 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2256530118795254		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2256530118795254 | validation: 0.19374411592975402]
	TIME [epoch: 6.12 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1886343874101711		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.1886343874101711 | validation: 0.31357047179810427]
	TIME [epoch: 6.11 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2336518500417443		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.2336518500417443 | validation: 0.198219299618551]
	TIME [epoch: 6.11 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1808983660179605		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.1808983660179605 | validation: 0.1738163761692808]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524522320230174		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.1524522320230174 | validation: 0.3251657031722449]
	TIME [epoch: 6.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26370162443175515		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.26370162443175515 | validation: 0.2759980531179177]
	TIME [epoch: 6.11 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506355844684817		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.2506355844684817 | validation: 0.2162452777108147]
	TIME [epoch: 6.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16803303450740076		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.16803303450740076 | validation: 0.17559591634860255]
	TIME [epoch: 421 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16370984253334808		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.16370984253334808 | validation: 0.1868177572947702]
	TIME [epoch: 12 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13924946159610693		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.13924946159610693 | validation: 0.1529314913452144]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23504646273449137		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.23504646273449137 | validation: 0.22023042863309483]
	TIME [epoch: 12 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054223610697905		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.2054223610697905 | validation: 0.18916450312569572]
	TIME [epoch: 12 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526677799107704		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.1526677799107704 | validation: 0.20458026742243163]
	TIME [epoch: 12 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1856165065517553		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.1856165065517553 | validation: 0.36193978567650836]
	TIME [epoch: 12 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.271709411037303		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.271709411037303 | validation: 0.16237784104495784]
	TIME [epoch: 12 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13822441772877775		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.13822441772877775 | validation: 0.21960697921870248]
	TIME [epoch: 12 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15707824052033015		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.15707824052033015 | validation: 0.15202066081489826]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838633847037746		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.13838633847037746 | validation: 0.20305927895280504]
	TIME [epoch: 12 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520415355120743		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.1520415355120743 | validation: 0.15842353812740823]
	TIME [epoch: 12 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16178291236531803		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.16178291236531803 | validation: 0.1841002695744506]
	TIME [epoch: 12 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22291812859229232		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.22291812859229232 | validation: 0.1698635035047615]
	TIME [epoch: 12 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1461344268878136		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1461344268878136 | validation: 0.1747126338665841]
	TIME [epoch: 12 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11747578167826762		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.11747578167826762 | validation: 0.13025634847154516]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10967986455151532		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.10967986455151532 | validation: 0.1635980777106208]
	TIME [epoch: 12 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14435847694371912		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.14435847694371912 | validation: 0.2831721650560338]
	TIME [epoch: 12 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17044113612364153		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.17044113612364153 | validation: 0.18025911195765199]
	TIME [epoch: 12 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12128450795766871		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.12128450795766871 | validation: 0.21793020320298134]
	TIME [epoch: 12 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17024812365460634		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.17024812365460634 | validation: 0.1603626334125249]
	TIME [epoch: 12 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11297020147993019		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.11297020147993019 | validation: 0.21562923507357587]
	TIME [epoch: 12 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13838995291520567		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.13838995291520567 | validation: 0.13281718626632374]
	TIME [epoch: 12 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13404987971208263		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.13404987971208263 | validation: 0.2631734534263933]
	TIME [epoch: 12 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20180321601872026		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.20180321601872026 | validation: 0.1516928922181538]
	TIME [epoch: 12 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1217940580708023		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.1217940580708023 | validation: 0.12391173800097152]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11915502761537941		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.11915502761537941 | validation: 0.13401277865308875]
	TIME [epoch: 12 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104292372344773		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.09104292372344773 | validation: 0.15355367542364287]
	TIME [epoch: 12 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16184579518028783		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.16184579518028783 | validation: 0.1689755592679007]
	TIME [epoch: 12 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14653788170438742		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.14653788170438742 | validation: 0.15928258854364669]
	TIME [epoch: 12 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698139094308925		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.12698139094308925 | validation: 0.11317494066097665]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462182389887227		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.12462182389887227 | validation: 0.1507917726225989]
	TIME [epoch: 12 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10602875101895712		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.10602875101895712 | validation: 0.12396619990992691]
	TIME [epoch: 12 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1283905972899877		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.1283905972899877 | validation: 0.28320934835816414]
	TIME [epoch: 12 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1695454318928464		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1695454318928464 | validation: 0.17356481584358077]
	TIME [epoch: 12 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10762481508602294		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.10762481508602294 | validation: 0.1101156254440805]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11299885594123021		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.11299885594123021 | validation: 0.17497799054191332]
	TIME [epoch: 12 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920666033268511		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.10920666033268511 | validation: 0.10414178038982348]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09539487148186994		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.09539487148186994 | validation: 0.17207138725218565]
	TIME [epoch: 12 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14432373372234916		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.14432373372234916 | validation: 0.10390408083729996]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09997510266117748		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.09997510266117748 | validation: 0.12781938173709734]
	TIME [epoch: 12 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11749621067413987		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.11749621067413987 | validation: 0.12417097773233324]
	TIME [epoch: 12 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08455169308310351		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.08455169308310351 | validation: 0.10468859058908853]
	TIME [epoch: 12 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12214756360820046		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.12214756360820046 | validation: 0.1318134044138111]
	TIME [epoch: 12 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14113464512210633		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.14113464512210633 | validation: 0.1674607979650973]
	TIME [epoch: 12 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11097028953165917		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.11097028953165917 | validation: 0.18433217744272454]
	TIME [epoch: 12 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11608820326784869		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.11608820326784869 | validation: 0.1650646486313928]
	TIME [epoch: 12 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10018773810199956		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.10018773810199956 | validation: 0.10480888604987076]
	TIME [epoch: 12 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09133141239533067		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.09133141239533067 | validation: 0.12415494166126406]
	TIME [epoch: 12 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09986872737173264		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.09986872737173264 | validation: 0.08415887045436751]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11081573571817618		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.11081573571817618 | validation: 0.10269953878588538]
	TIME [epoch: 12 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775572701279132		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.07775572701279132 | validation: 0.10484552483945772]
	TIME [epoch: 12 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1417368032791825		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.1417368032791825 | validation: 0.12814462126387427]
	TIME [epoch: 12 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08645873216565139		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.08645873216565139 | validation: 0.10625761896529287]
	TIME [epoch: 12 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07399629316597103		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.07399629316597103 | validation: 0.11026632464484187]
	TIME [epoch: 12 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280370247194884		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.09280370247194884 | validation: 0.2509051948275244]
	TIME [epoch: 12.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13179471112558275		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.13179471112558275 | validation: 0.0931220197183423]
	TIME [epoch: 12 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06380396349473777		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.06380396349473777 | validation: 0.08671593206470973]
	TIME [epoch: 12 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414214565554078		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.10414214565554078 | validation: 0.08263684908264105]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10377025357030258		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.10377025357030258 | validation: 0.1333477060356499]
	TIME [epoch: 12 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08035744256536535		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.08035744256536535 | validation: 0.10947560519610058]
	TIME [epoch: 12 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09799491228581379		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.09799491228581379 | validation: 0.07648274224958537]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697978700863439		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.07697978700863439 | validation: 0.13087081360212063]
	TIME [epoch: 12 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09154863436836985		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.09154863436836985 | validation: 0.11195803256655851]
	TIME [epoch: 12 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09899680101314244		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09899680101314244 | validation: 0.11302869642848681]
	TIME [epoch: 12 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08175655335863705		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.08175655335863705 | validation: 0.12852185878909142]
	TIME [epoch: 12 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07883116234258226		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.07883116234258226 | validation: 0.08508445182866158]
	TIME [epoch: 12 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09429089128074039		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.09429089128074039 | validation: 0.10184819837106751]
	TIME [epoch: 12 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08634890675116196		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.08634890675116196 | validation: 0.10652921127356134]
	TIME [epoch: 12 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07143586830068491		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.07143586830068491 | validation: 0.21960679217238166]
	TIME [epoch: 12 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11369675110401958		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.11369675110401958 | validation: 0.07505745934712996]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08576194277395834		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.08576194277395834 | validation: 0.10199523892419965]
	TIME [epoch: 12 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07190586614493033		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.07190586614493033 | validation: 0.13922598849074058]
	TIME [epoch: 12.1 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10303852284816262		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.10303852284816262 | validation: 0.08431088987017026]
	TIME [epoch: 12.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04907541977000967		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.04907541977000967 | validation: 0.06346322500141541]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670612751190259		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.0670612751190259 | validation: 0.1420023667678239]
	TIME [epoch: 12 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11741037313367067		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.11741037313367067 | validation: 0.07067839611255322]
	TIME [epoch: 12 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059508695574679166		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.059508695574679166 | validation: 0.07100336820675479]
	TIME [epoch: 12 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08259171839991314		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.08259171839991314 | validation: 0.11435277281227199]
	TIME [epoch: 12 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07123491388371829		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.07123491388371829 | validation: 0.09513745872047737]
	TIME [epoch: 12 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08438553207394349		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.08438553207394349 | validation: 0.09200109031369508]
	TIME [epoch: 12.1 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0890065135341572		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.0890065135341572 | validation: 0.09971127237847216]
	TIME [epoch: 12 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335617899505278		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.08335617899505278 | validation: 0.11699459038878621]
	TIME [epoch: 12 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148196397871976		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.08148196397871976 | validation: 0.07852691832101172]
	TIME [epoch: 12.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06635486903050203		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.06635486903050203 | validation: 0.08276847101783466]
	TIME [epoch: 12 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0775675646288483		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.0775675646288483 | validation: 0.08281304446018412]
	TIME [epoch: 12 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054445426548345		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.06054445426548345 | validation: 0.08925942156214069]
	TIME [epoch: 12 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07726435163060166		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.07726435163060166 | validation: 0.06870772249494472]
	TIME [epoch: 12 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08654038061131777		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.08654038061131777 | validation: 0.07565122076576755]
	TIME [epoch: 12.1 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06772232223563587		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.06772232223563587 | validation: 0.12741435557354658]
	TIME [epoch: 12 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07569659301133556		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.07569659301133556 | validation: 0.09762970861271597]
	TIME [epoch: 12 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07728888403383072		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.07728888403383072 | validation: 0.11881480395057101]
	TIME [epoch: 12.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08625171176871926		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.08625171176871926 | validation: 0.09360251505682674]
	TIME [epoch: 12 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06615347619620734		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.06615347619620734 | validation: 0.12632564458429058]
	TIME [epoch: 12 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07810374950606525		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.07810374950606525 | validation: 0.07692148322588996]
	TIME [epoch: 12 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06153702962654546		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.06153702962654546 | validation: 0.06379732745818736]
	TIME [epoch: 12.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840079881951243		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.06840079881951243 | validation: 0.07132951508784802]
	TIME [epoch: 12.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06048502610744649		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.06048502610744649 | validation: 0.0765469192240108]
	TIME [epoch: 12.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242484328147973		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.06242484328147973 | validation: 0.11269475222111645]
	TIME [epoch: 12 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08288108428450851		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.08288108428450851 | validation: 0.06142359273291242]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058836904606635945		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.058836904606635945 | validation: 0.14495982985004158]
	TIME [epoch: 12 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486121361883222		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.07486121361883222 | validation: 0.06863308495103355]
	TIME [epoch: 12.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053401436429010574		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.053401436429010574 | validation: 0.152855497812048]
	TIME [epoch: 12 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890165412882547		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.08890165412882547 | validation: 0.07913545138048682]
	TIME [epoch: 12.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07730402047538044		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.07730402047538044 | validation: 0.06420823883990893]
	TIME [epoch: 12.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05465140180722618		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.05465140180722618 | validation: 0.09043826270423704]
	TIME [epoch: 12 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05883706739892586		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.05883706739892586 | validation: 0.1056633861847768]
	TIME [epoch: 12 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757509561495668		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.07757509561495668 | validation: 0.06379749116111522]
	TIME [epoch: 12 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054810801445973154		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.054810801445973154 | validation: 0.12920642155477177]
	TIME [epoch: 12.1 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104272862118077		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.08104272862118077 | validation: 0.06624188479022391]
	TIME [epoch: 12.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053652911499528		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.053652911499528 | validation: 0.06320379647437667]
	TIME [epoch: 12 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06856437507247806		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.06856437507247806 | validation: 0.07278678178956399]
	TIME [epoch: 12 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07017460858719943		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.07017460858719943 | validation: 0.08044426530975561]
	TIME [epoch: 12 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06113075632783001		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.06113075632783001 | validation: 0.06398359430996567]
	TIME [epoch: 12 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049324955787766384		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.049324955787766384 | validation: 0.07386368462413012]
	TIME [epoch: 12.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08513434456605573		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.08513434456605573 | validation: 0.07076923077166922]
	TIME [epoch: 12 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893943479717124		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.05893943479717124 | validation: 0.07125631359861324]
	TIME [epoch: 12.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06603072026492847		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.06603072026492847 | validation: 0.06472045070355595]
	TIME [epoch: 12 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565171490966877		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.0565171490966877 | validation: 0.06139749117289786]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0693489881988032		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.0693489881988032 | validation: 0.07873036232006227]
	TIME [epoch: 12 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05533665639414317		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.05533665639414317 | validation: 0.061636018289105796]
	TIME [epoch: 12 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255860968705518		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.05255860968705518 | validation: 0.10250693035866]
	TIME [epoch: 12 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453426179853222		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.06453426179853222 | validation: 0.06980863091786689]
	TIME [epoch: 12 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0766694121575814		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.0766694121575814 | validation: 0.06433974276540819]
	TIME [epoch: 12 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054025181870988495		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.054025181870988495 | validation: 0.07471845974727725]
	TIME [epoch: 12 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350985886013641		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.06350985886013641 | validation: 0.06701458311000769]
	TIME [epoch: 12 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05679154787700271		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.05679154787700271 | validation: 0.07647460770394528]
	TIME [epoch: 12 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05127387605327246		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.05127387605327246 | validation: 0.098176015498793]
	TIME [epoch: 12 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06390449859061914		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.06390449859061914 | validation: 0.08311471269372628]
	TIME [epoch: 12 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262031425285883		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.06262031425285883 | validation: 0.09233148604775623]
	TIME [epoch: 12 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05787568858050256		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.05787568858050256 | validation: 0.06977283541767094]
	TIME [epoch: 12 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048334938923119984		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.048334938923119984 | validation: 0.07011891929722094]
	TIME [epoch: 12 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06617354636841274		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.06617354636841274 | validation: 0.07215478974538181]
	TIME [epoch: 12 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049770746515443595		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.049770746515443595 | validation: 0.06941431993547692]
	TIME [epoch: 12 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041782699577050185		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.041782699577050185 | validation: 0.07842259707464276]
	TIME [epoch: 12 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009373683169425		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.08009373683169425 | validation: 0.06501141633537702]
	TIME [epoch: 12 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052515989804324856		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.052515989804324856 | validation: 0.09413503131825415]
	TIME [epoch: 12 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06540180568934509		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.06540180568934509 | validation: 0.07556728759694908]
	TIME [epoch: 12 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050072995980720625		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.050072995980720625 | validation: 0.06579314408055832]
	TIME [epoch: 12 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04435040486975603		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.04435040486975603 | validation: 0.05063620491155062]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06514435847445219		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.06514435847445219 | validation: 0.06264184325235733]
	TIME [epoch: 12 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05852852300286501		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.05852852300286501 | validation: 0.05736000961238977]
	TIME [epoch: 12 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434827770141974		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.04434827770141974 | validation: 0.0646536602292297]
	TIME [epoch: 12 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314095518535844		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.05314095518535844 | validation: 0.08748923791774446]
	TIME [epoch: 12 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472722737409646		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.06472722737409646 | validation: 0.05172439778827948]
	TIME [epoch: 12 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04994330176088104		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.04994330176088104 | validation: 0.06477008359001787]
	TIME [epoch: 12 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05717139303651095		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.05717139303651095 | validation: 0.06209419116825787]
	TIME [epoch: 12 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04456969030613792		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.04456969030613792 | validation: 0.05037286968068659]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171399239440609		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.09171399239440609 | validation: 0.1053227616076603]
	TIME [epoch: 12 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06431601376362123		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.06431601376362123 | validation: 0.04753071522863802]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044352807264100805		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.044352807264100805 | validation: 0.08749257216037278]
	TIME [epoch: 12 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058519532837120705		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.058519532837120705 | validation: 0.057261703675084104]
	TIME [epoch: 12.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04931602411561674		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.04931602411561674 | validation: 0.07846374216234851]
	TIME [epoch: 12 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058324341558791806		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.058324341558791806 | validation: 0.05375042791582603]
	TIME [epoch: 12 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549959124619863		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.04549959124619863 | validation: 0.05148942467504935]
	TIME [epoch: 12 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05337764280649986		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.05337764280649986 | validation: 0.08227794387389656]
	TIME [epoch: 12 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04833521642693023		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.04833521642693023 | validation: 0.05707057741428944]
	TIME [epoch: 12 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05507952857408087		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.05507952857408087 | validation: 0.0876802665546085]
	TIME [epoch: 12 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05429770687506222		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.05429770687506222 | validation: 0.05587401912824992]
	TIME [epoch: 12 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04272056630546766		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.04272056630546766 | validation: 0.05986183738886431]
	TIME [epoch: 12 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048242004063069985		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.048242004063069985 | validation: 0.07578514128772804]
	TIME [epoch: 12 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573441071834532		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.05573441071834532 | validation: 0.0651070310575338]
	TIME [epoch: 12 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046380838431847		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.046380838431847 | validation: 0.04763613229237887]
	TIME [epoch: 12.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05822564607154922		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.05822564607154922 | validation: 0.08099403167752492]
	TIME [epoch: 12.1 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439428183901661		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.04439428183901661 | validation: 0.04838225817348576]
	TIME [epoch: 12.1 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059245346420914585		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.059245346420914585 | validation: 0.047815973343840135]
	TIME [epoch: 12 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847675706828037		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.03847675706828037 | validation: 0.05509422219210042]
	TIME [epoch: 12 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441706541457846		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.04441706541457846 | validation: 0.06685495641013833]
	TIME [epoch: 12.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055317190284253116		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.055317190284253116 | validation: 0.05210017990858715]
	TIME [epoch: 12.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578178118957607		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.03578178118957607 | validation: 0.08899596808292479]
	TIME [epoch: 12 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664723256859145		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.0664723256859145 | validation: 0.05922800588275247]
	TIME [epoch: 12.1 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038732767287134144		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.038732767287134144 | validation: 0.07719892039617686]
	TIME [epoch: 12.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04317786837460276		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.04317786837460276 | validation: 0.04247984790528325]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035548902792687936		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.035548902792687936 | validation: 0.10561589910848587]
	TIME [epoch: 12 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476409619805909		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.06476409619805909 | validation: 0.04712618852799822]
	TIME [epoch: 12 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0532765971231057		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.0532765971231057 | validation: 0.07541127763653391]
	TIME [epoch: 12.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04670080233508923		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.04670080233508923 | validation: 0.06246810165072267]
	TIME [epoch: 12 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406763700798582		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.0406763700798582 | validation: 0.06289217708232714]
	TIME [epoch: 12 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04831031694028844		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.04831031694028844 | validation: 0.06542977322439153]
	TIME [epoch: 12 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04253631074010905		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.04253631074010905 | validation: 0.06167132717601999]
	TIME [epoch: 12 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038354314995207736		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.038354314995207736 | validation: 0.07444681852681428]
	TIME [epoch: 12 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04972439471930623		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.04972439471930623 | validation: 0.101026628008659]
	TIME [epoch: 12 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05873812686123982		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.05873812686123982 | validation: 0.04517733582726641]
	TIME [epoch: 12 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022156536019063		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.04022156536019063 | validation: 0.05887591313768116]
	TIME [epoch: 12 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045941474926458455		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.045941474926458455 | validation: 0.06880046958600136]
	TIME [epoch: 12 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046350676585982395		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.046350676585982395 | validation: 0.06068670562206489]
	TIME [epoch: 12 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054037307548527355		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.054037307548527355 | validation: 0.055205209910447306]
	TIME [epoch: 12 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03835811785339205		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.03835811785339205 | validation: 0.06181867874193924]
	TIME [epoch: 12 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041363107028468626		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.041363107028468626 | validation: 0.04668861116344415]
	TIME [epoch: 12.1 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042790835691046934		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.042790835691046934 | validation: 0.061700469774996075]
	TIME [epoch: 12 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04374076511642528		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.04374076511642528 | validation: 0.062363870300662774]
	TIME [epoch: 12 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049593100537695056		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.049593100537695056 | validation: 0.05489661285223662]
	TIME [epoch: 12 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032440390668963676		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.032440390668963676 | validation: 0.06933361299979458]
	TIME [epoch: 12 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04428196630150907		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.04428196630150907 | validation: 0.08382982443570454]
	TIME [epoch: 12 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662778385700448		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.06662778385700448 | validation: 0.06142833415572738]
	TIME [epoch: 12 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040613117562247676		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.040613117562247676 | validation: 0.038613700949463106]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03039849449364379		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.03039849449364379 | validation: 0.048977668879647135]
	TIME [epoch: 12 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051374427302952455		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.051374427302952455 | validation: 0.05725133976538829]
	TIME [epoch: 12 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04813731864598857		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.04813731864598857 | validation: 0.04699349518468539]
	TIME [epoch: 12 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039084439087531675		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.039084439087531675 | validation: 0.057178955974606205]
	TIME [epoch: 12.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376963760084071		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.0376963760084071 | validation: 0.06314874111998352]
	TIME [epoch: 12 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0495396452120048		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.0495396452120048 | validation: 0.050046899891225]
	TIME [epoch: 12 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362289382656331		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.03362289382656331 | validation: 0.06508980843533055]
	TIME [epoch: 12 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05591495419553795		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.05591495419553795 | validation: 0.060965422089419796]
	TIME [epoch: 12 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03828369893707138		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.03828369893707138 | validation: 0.04192686123923989]
	TIME [epoch: 12.1 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06373842764390769		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.06373842764390769 | validation: 0.04945446841295006]
	TIME [epoch: 12 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039866723007853		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.039866723007853 | validation: 0.05298289725891092]
	TIME [epoch: 12 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03555807829699871		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.03555807829699871 | validation: 0.05898316361420814]
	TIME [epoch: 12 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04683151589831403		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.04683151589831403 | validation: 0.04718502372301908]
	TIME [epoch: 12 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042654736506540426		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.042654736506540426 | validation: 0.0480093209656175]
	TIME [epoch: 12 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419442206873794		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.04419442206873794 | validation: 0.05168556900112087]
	TIME [epoch: 12 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04421378937440541		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.04421378937440541 | validation: 0.06341100086093293]
	TIME [epoch: 12 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03783720596701146		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.03783720596701146 | validation: 0.060499378754638726]
	TIME [epoch: 12 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03774206488479455		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.03774206488479455 | validation: 0.039429169552432225]
	TIME [epoch: 12 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767763049957595		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.04767763049957595 | validation: 0.05661369953961091]
	TIME [epoch: 12.1 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03903653865220742		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.03903653865220742 | validation: 0.05543892449185567]
	TIME [epoch: 12 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003523461389007		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.04003523461389007 | validation: 0.047530001555451874]
	TIME [epoch: 12 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04110425625993036		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.04110425625993036 | validation: 0.043982408567282555]
	TIME [epoch: 12 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035034874117344836		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.035034874117344836 | validation: 0.04717613860852639]
	TIME [epoch: 12 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03971962686100989		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.03971962686100989 | validation: 0.0559401845475554]
	TIME [epoch: 12 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03983682609330087		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.03983682609330087 | validation: 0.06237950098822647]
	TIME [epoch: 12 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04290533821560495		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.04290533821560495 | validation: 0.04278738521498229]
	TIME [epoch: 12 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035792199049636444		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.035792199049636444 | validation: 0.06253347311565699]
	TIME [epoch: 12 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044054814120835166		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.044054814120835166 | validation: 0.05058581742144814]
	TIME [epoch: 12 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039673145484432126		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.039673145484432126 | validation: 0.05431894594376352]
	TIME [epoch: 12 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136716813242036		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.04136716813242036 | validation: 0.038084936709972886]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225055194556019		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.03225055194556019 | validation: 0.07864897231458537]
	TIME [epoch: 12 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397912376703464		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.04397912376703464 | validation: 0.043506472126533066]
	TIME [epoch: 12 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02880766917117654		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.02880766917117654 | validation: 0.05011868867615134]
	TIME [epoch: 12 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054323921897908134		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.054323921897908134 | validation: 0.0430416121886739]
	TIME [epoch: 12 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034395645397466576		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.034395645397466576 | validation: 0.05099586808735121]
	TIME [epoch: 12 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034820751536828475		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.034820751536828475 | validation: 0.06870124385188131]
	TIME [epoch: 12.1 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03915543060337685		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.03915543060337685 | validation: 0.04816082108859875]
	TIME [epoch: 12 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04254875931458242		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.04254875931458242 | validation: 0.05069313790547243]
	TIME [epoch: 12 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622666805778159		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.03622666805778159 | validation: 0.043028002531349974]
	TIME [epoch: 12 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397597512724441		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.03397597512724441 | validation: 0.05892094809189785]
	TIME [epoch: 12 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043266060323338885		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.043266060323338885 | validation: 0.06557751449757983]
	TIME [epoch: 12 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037587529584804595		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.037587529584804595 | validation: 0.04386067657026138]
	TIME [epoch: 12 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030403142162400445		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.030403142162400445 | validation: 0.05349239732858324]
	TIME [epoch: 12 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041119114561525005		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.041119114561525005 | validation: 0.04530027070077014]
	TIME [epoch: 12 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037337214439586444		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.037337214439586444 | validation: 0.04849242429093516]
	TIME [epoch: 12 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03905046745826397		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.03905046745826397 | validation: 0.05119969199548881]
	TIME [epoch: 12 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03492993803405628		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.03492993803405628 | validation: 0.050286460087349265]
	TIME [epoch: 12 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0388822864054827		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.0388822864054827 | validation: 0.04453488887257473]
	TIME [epoch: 12 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046681878367046514		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.046681878367046514 | validation: 0.06666018520785427]
	TIME [epoch: 12 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039569152978168785		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.039569152978168785 | validation: 0.04517826118814626]
	TIME [epoch: 12 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335819913086601		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.03335819913086601 | validation: 0.060480840006482135]
	TIME [epoch: 12 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0429435662345051		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.0429435662345051 | validation: 0.050589033091457486]
	TIME [epoch: 12 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03118841585411186		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.03118841585411186 | validation: 0.051066761382059164]
	TIME [epoch: 12 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03236710186377639		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.03236710186377639 | validation: 0.04851966344051602]
	TIME [epoch: 12 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155799974228069		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.04155799974228069 | validation: 0.0668377681728715]
	TIME [epoch: 12 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044387338276014265		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.044387338276014265 | validation: 0.04602562075575674]
	TIME [epoch: 12 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173140976701689		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.03173140976701689 | validation: 0.050613639813939015]
	TIME [epoch: 12 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03386935807761196		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.03386935807761196 | validation: 0.06805930203115423]
	TIME [epoch: 12 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04300522587680528		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04300522587680528 | validation: 0.0421010666850747]
	TIME [epoch: 12 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0280275366807121		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.0280275366807121 | validation: 0.043271885038547384]
	TIME [epoch: 12 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03384096637184096		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.03384096637184096 | validation: 0.04045905223616984]
	TIME [epoch: 12 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633531899697094		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.03633531899697094 | validation: 0.0735198040579072]
	TIME [epoch: 12 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413876103913958		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.04413876103913958 | validation: 0.039960892265503985]
	TIME [epoch: 12 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322093970796382		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.0322093970796382 | validation: 0.05319468317422435]
	TIME [epoch: 12 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03180977802929149		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.03180977802929149 | validation: 0.038916631651515404]
	TIME [epoch: 12 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03194705060297511		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.03194705060297511 | validation: 0.07146823400611622]
	TIME [epoch: 12 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04311455704738149		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.04311455704738149 | validation: 0.04906586843168531]
	TIME [epoch: 12 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033236504641246487		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.033236504641246487 | validation: 0.04359342161143797]
	TIME [epoch: 12 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03000219873160178		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.03000219873160178 | validation: 0.040727926796313894]
	TIME [epoch: 12 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04294712118711899		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.04294712118711899 | validation: 0.06216274750113478]
	TIME [epoch: 12 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03986882984163965		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.03986882984163965 | validation: 0.044747008651794644]
	TIME [epoch: 12.1 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026153068147853717		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.026153068147853717 | validation: 0.04508873737184574]
	TIME [epoch: 12 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023646079338592		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.04023646079338592 | validation: 0.04141727222577561]
	TIME [epoch: 12 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947461542593021		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.03947461542593021 | validation: 0.046031060005720284]
	TIME [epoch: 12 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03574242611902872		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.03574242611902872 | validation: 0.043081150690652326]
	TIME [epoch: 12 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03005586389549121		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.03005586389549121 | validation: 0.04629009865552661]
	TIME [epoch: 12 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03005031259722518		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.03005031259722518 | validation: 0.04035171686215539]
	TIME [epoch: 12 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023421121147235		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.04023421121147235 | validation: 0.047019891469082295]
	TIME [epoch: 12 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03790210973932319		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.03790210973932319 | validation: 0.03986517800208504]
	TIME [epoch: 12 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02955751247015568		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.02955751247015568 | validation: 0.04088545447345536]
	TIME [epoch: 12 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03354326644991725		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.03354326644991725 | validation: 0.04616737701147251]
	TIME [epoch: 12 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03415506315911424		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.03415506315911424 | validation: 0.042453324353911776]
	TIME [epoch: 12 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030905889380091395		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.030905889380091395 | validation: 0.0386796328033908]
	TIME [epoch: 12 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03314448298157721		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.03314448298157721 | validation: 0.056069231908585586]
	TIME [epoch: 12 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419402054839285		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.04419402054839285 | validation: 0.040128095755826]
	TIME [epoch: 12 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02836572636094152		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.02836572636094152 | validation: 0.04004740700733049]
	TIME [epoch: 12 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03142948709421813		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.03142948709421813 | validation: 0.04507891505598757]
	TIME [epoch: 12 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034003892102162876		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.034003892102162876 | validation: 0.040696256337464334]
	TIME [epoch: 12.1 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029851200282510017		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.029851200282510017 | validation: 0.05674929178087185]
	TIME [epoch: 12 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04164912569110246		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.04164912569110246 | validation: 0.05206160142963473]
	TIME [epoch: 12 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03282359205379938		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.03282359205379938 | validation: 0.042917303813655036]
	TIME [epoch: 12 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030696261683798454		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.030696261683798454 | validation: 0.050384372412041634]
	TIME [epoch: 12 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03822733338743097		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.03822733338743097 | validation: 0.04954350041971934]
	TIME [epoch: 12 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030179962883345138		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.030179962883345138 | validation: 0.04222747610570698]
	TIME [epoch: 12 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034592491943024134		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.034592491943024134 | validation: 0.049386369230429834]
	TIME [epoch: 12 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03652417133420245		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.03652417133420245 | validation: 0.04300895875092818]
	TIME [epoch: 12 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02994489807743527		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.02994489807743527 | validation: 0.038853233082038585]
	TIME [epoch: 12 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02829065664163878		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.02829065664163878 | validation: 0.04253827675509453]
	TIME [epoch: 12 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200663012407858		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.03200663012407858 | validation: 0.048022326378618474]
	TIME [epoch: 12 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038190945926635904		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.038190945926635904 | validation: 0.036254694041953334]
	TIME [epoch: 12 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026463997027339727		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.026463997027339727 | validation: 0.041962901903298794]
	TIME [epoch: 12 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034373281434366104		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.034373281434366104 | validation: 0.052082470338916304]
	TIME [epoch: 12 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033724988031177947		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.033724988031177947 | validation: 0.04613866684105061]
	TIME [epoch: 12 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031035472749951578		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.031035472749951578 | validation: 0.03697505732637596]
	TIME [epoch: 12 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032453887265666746		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.032453887265666746 | validation: 0.04871901892779382]
	TIME [epoch: 441 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412550171475147		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.03412550171475147 | validation: 0.04904391379667459]
	TIME [epoch: 25.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03138214062801624		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.03138214062801624 | validation: 0.045717129492998526]
	TIME [epoch: 25.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027037277077272714		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.027037277077272714 | validation: 0.04308066565331763]
	TIME [epoch: 25.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03279602733021318		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.03279602733021318 | validation: 0.0600719781662036]
	TIME [epoch: 25.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032338567457780146		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.032338567457780146 | validation: 0.04189409357374363]
	TIME [epoch: 25.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03034878986206429		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.03034878986206429 | validation: 0.04965663047464942]
	TIME [epoch: 25.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031243363217860115		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.031243363217860115 | validation: 0.048503208195302544]
	TIME [epoch: 25.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510722914569609		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.03510722914569609 | validation: 0.04142520040007594]
	TIME [epoch: 25.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02830721389417496		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.02830721389417496 | validation: 0.04984207834536344]
	TIME [epoch: 25.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03095748393711574		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.03095748393711574 | validation: 0.04409727216507192]
	TIME [epoch: 25.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03302053509030405		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.03302053509030405 | validation: 0.040832209905404225]
	TIME [epoch: 25.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03128673440445997		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.03128673440445997 | validation: 0.04844955226085499]
	TIME [epoch: 25.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02724572746601972		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.02724572746601972 | validation: 0.04315864466978563]
	TIME [epoch: 25.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02970724675966595		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.02970724675966595 | validation: 0.03903252022243718]
	TIME [epoch: 25.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036779528411051005		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.036779528411051005 | validation: 0.0391857392233054]
	TIME [epoch: 25.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029935845835847276		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.029935845835847276 | validation: 0.0393467033815434]
	TIME [epoch: 25.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02602902286166997		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.02602902286166997 | validation: 0.044306578572081944]
	TIME [epoch: 25.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030716640635945175		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.030716640635945175 | validation: 0.04111819683034873]
	TIME [epoch: 25.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03447784643791045		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.03447784643791045 | validation: 0.04315406805207575]
	TIME [epoch: 25.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027546983143132454		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.027546983143132454 | validation: 0.041160031545310186]
	TIME [epoch: 25.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029970951047786663		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.029970951047786663 | validation: 0.04996035239845499]
	TIME [epoch: 25.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03588872690684236		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.03588872690684236 | validation: 0.03906363751649587]
	TIME [epoch: 25.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026809664802401392		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.026809664802401392 | validation: 0.046966896155961155]
	TIME [epoch: 25.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032307043604206755		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.032307043604206755 | validation: 0.04878972729915593]
	TIME [epoch: 25.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031990951933907906		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.031990951933907906 | validation: 0.04135808444299975]
	TIME [epoch: 25.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027882677067151442		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.027882677067151442 | validation: 0.045464170460766735]
	TIME [epoch: 25.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02945990116728299		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.02945990116728299 | validation: 0.03988535092170783]
	TIME [epoch: 25.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028823756498835545		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.028823756498835545 | validation: 0.04755706709927571]
	TIME [epoch: 25.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029724930469484705		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.029724930469484705 | validation: 0.039576022742077804]
	TIME [epoch: 25.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028272257366428438		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.028272257366428438 | validation: 0.05377862534899759]
	TIME [epoch: 25.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037088988649235884		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.037088988649235884 | validation: 0.044289669813446064]
	TIME [epoch: 25.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0273291151858095		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.0273291151858095 | validation: 0.04265848966855339]
	TIME [epoch: 25.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028453604953182172		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.028453604953182172 | validation: 0.039235875424489974]
	TIME [epoch: 25.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03079242454644263		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.03079242454644263 | validation: 0.03802211381965846]
	TIME [epoch: 25.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027031339586149995		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.027031339586149995 | validation: 0.04324516766039979]
	TIME [epoch: 25.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032365386675025885		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.032365386675025885 | validation: 0.050412492897072954]
	TIME [epoch: 25.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027485575780266683		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.027485575780266683 | validation: 0.03873165796215954]
	TIME [epoch: 25.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326733095786813		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.0326733095786813 | validation: 0.05268832502985821]
	TIME [epoch: 25.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02940851054055041		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.02940851054055041 | validation: 0.0365122526585309]
	TIME [epoch: 25.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030428063572660674		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.030428063572660674 | validation: 0.038106385797869735]
	TIME [epoch: 25.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02891804720409272		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.02891804720409272 | validation: 0.04363240922021006]
	TIME [epoch: 25.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031396536615811384		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.031396536615811384 | validation: 0.03770729665977822]
	TIME [epoch: 25.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02613204706577622		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.02613204706577622 | validation: 0.035505694391288256]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025085187726527777		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.025085187726527777 | validation: 0.046389387477348415]
	TIME [epoch: 25.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028507021202672955		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.028507021202672955 | validation: 0.04673768751377358]
	TIME [epoch: 25.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033606539050159284		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.033606539050159284 | validation: 0.04147177817362331]
	TIME [epoch: 25.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028473174092512515		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.028473174092512515 | validation: 0.03674054631694302]
	TIME [epoch: 25.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025047340238439575		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.025047340238439575 | validation: 0.04055201390772557]
	TIME [epoch: 25.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099900913968583		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.03099900913968583 | validation: 0.03895029155556162]
	TIME [epoch: 25.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026099323979549366		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.026099323979549366 | validation: 0.039272293171970826]
	TIME [epoch: 25.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02771573184052422		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.02771573184052422 | validation: 0.0438456639188959]
	TIME [epoch: 25.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03524170944975396		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.03524170944975396 | validation: 0.044581269498755335]
	TIME [epoch: 25.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026676206826836586		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.026676206826836586 | validation: 0.03772813346123395]
	TIME [epoch: 25.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027534777039754717		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.027534777039754717 | validation: 0.044465745278565415]
	TIME [epoch: 25.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027713411241371604		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.027713411241371604 | validation: 0.04508638698338831]
	TIME [epoch: 25.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03004098947584756		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.03004098947584756 | validation: 0.036891708694287165]
	TIME [epoch: 25.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024971881525262894		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.024971881525262894 | validation: 0.037231644904369886]
	TIME [epoch: 25.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029324597096584464		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.029324597096584464 | validation: 0.04404093461619961]
	TIME [epoch: 25.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030632479558548344		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.030632479558548344 | validation: 0.04300546119525867]
	TIME [epoch: 25.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02419592197904676		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.02419592197904676 | validation: 0.037123404410002614]
	TIME [epoch: 25.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388679020772448		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.03388679020772448 | validation: 0.050814473388998235]
	TIME [epoch: 25.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026890046759043947		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.026890046759043947 | validation: 0.039383533760101154]
	TIME [epoch: 25.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02582679089204798		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.02582679089204798 | validation: 0.03766525736311876]
	TIME [epoch: 25.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02831312786738071		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.02831312786738071 | validation: 0.044539715180603665]
	TIME [epoch: 25.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02664615824717477		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.02664615824717477 | validation: 0.045657671814468156]
	TIME [epoch: 25.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032208123307281726		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.032208123307281726 | validation: 0.038924005908639786]
	TIME [epoch: 25.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02802423639701688		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.02802423639701688 | validation: 0.037352206218941655]
	TIME [epoch: 25.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749011072976598		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.02749011072976598 | validation: 0.04101665225409237]
	TIME [epoch: 25.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025535674478791695		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.025535674478791695 | validation: 0.04611569222216522]
	TIME [epoch: 25.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02760992792892164		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.02760992792892164 | validation: 0.0380292913408269]
	TIME [epoch: 25.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025659796352416626		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.025659796352416626 | validation: 0.042585443774527616]
	TIME [epoch: 25.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961374040308779		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.03961374040308779 | validation: 0.04325478279873368]
	TIME [epoch: 25.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028912296779304243		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.028912296779304243 | validation: 0.03797661188562686]
	TIME [epoch: 25.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02512805004229455		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.02512805004229455 | validation: 0.04019599774790631]
	TIME [epoch: 25.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027939007476887955		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.027939007476887955 | validation: 0.04267070108569061]
	TIME [epoch: 25.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278552813482505		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0278552813482505 | validation: 0.034837473144440315]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02705547552848022		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.02705547552848022 | validation: 0.03828558583800287]
	TIME [epoch: 25.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025095997191932427		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.025095997191932427 | validation: 0.041590028369423784]
	TIME [epoch: 25.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025946350853701457		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.025946350853701457 | validation: 0.04439020425773503]
	TIME [epoch: 25.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02662214323699383		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.02662214323699383 | validation: 0.03980376199071585]
	TIME [epoch: 25.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027581065207202757		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.027581065207202757 | validation: 0.03858923729542528]
	TIME [epoch: 25.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03200282818268839		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.03200282818268839 | validation: 0.037503291067797595]
	TIME [epoch: 25.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023657077880678824		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.023657077880678824 | validation: 0.040225744419970635]
	TIME [epoch: 25.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028958788561303676		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.028958788561303676 | validation: 0.03786402767444017]
	TIME [epoch: 25.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023343833397384522		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.023343833397384522 | validation: 0.03715857066969597]
	TIME [epoch: 25.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025888890097223283		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.025888890097223283 | validation: 0.04973486712387802]
	TIME [epoch: 25.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02724883251332884		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.02724883251332884 | validation: 0.03814041485561265]
	TIME [epoch: 25.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02750153854856834		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.02750153854856834 | validation: 0.048102952346455875]
	TIME [epoch: 25.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026496053627996195		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.026496053627996195 | validation: 0.03574337362862493]
	TIME [epoch: 25.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02547883061264338		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.02547883061264338 | validation: 0.03535003250877419]
	TIME [epoch: 25.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02475022926961091		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.02475022926961091 | validation: 0.043023119163886556]
	TIME [epoch: 25.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026250472117857963		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.026250472117857963 | validation: 0.036022238823887893]
	TIME [epoch: 25.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026559953168629198		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.026559953168629198 | validation: 0.038367998444536894]
	TIME [epoch: 25.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02453894821060302		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.02453894821060302 | validation: 0.041628128867398376]
	TIME [epoch: 25.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030394435888357527		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.030394435888357527 | validation: 0.03890802528141489]
	TIME [epoch: 25.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023763432445637722		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.023763432445637722 | validation: 0.037037320691912394]
	TIME [epoch: 25.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02513160051512133		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.02513160051512133 | validation: 0.0368431765019676]
	TIME [epoch: 25.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403989453319557		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.02403989453319557 | validation: 0.040221367086283946]
	TIME [epoch: 25.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030171791855290325		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.030171791855290325 | validation: 0.03978090621697972]
	TIME [epoch: 25.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02455460961871376		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.02455460961871376 | validation: 0.03433227737346425]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025197313173635678		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.025197313173635678 | validation: 0.04229961875699966]
	TIME [epoch: 25.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024951460771552268		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.024951460771552268 | validation: 0.03821494904282789]
	TIME [epoch: 25.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02500596261567741		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.02500596261567741 | validation: 0.039339300434263896]
	TIME [epoch: 25.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026472581276102993		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.026472581276102993 | validation: 0.0397567370676153]
	TIME [epoch: 25.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026609126517886654		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.026609126517886654 | validation: 0.037637701549280485]
	TIME [epoch: 25.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026630749528586135		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.026630749528586135 | validation: 0.03585976222494004]
	TIME [epoch: 25.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02494375731532538		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.02494375731532538 | validation: 0.04343547556610891]
	TIME [epoch: 25.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026276128055447084		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.026276128055447084 | validation: 0.04103891130461982]
	TIME [epoch: 25.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027737611500065117		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.027737611500065117 | validation: 0.04502009867312505]
	TIME [epoch: 25.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026414302486891438		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.026414302486891438 | validation: 0.03492726812760921]
	TIME [epoch: 25.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026042718796860896		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.026042718796860896 | validation: 0.04260376995893589]
	TIME [epoch: 25.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02864919085513189		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.02864919085513189 | validation: 0.032960010634810064]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02261566490065515		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.02261566490065515 | validation: 0.04153411058183184]
	TIME [epoch: 25.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026186302253824404		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.026186302253824404 | validation: 0.03584752521685228]
	TIME [epoch: 25.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027515699394195826		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.027515699394195826 | validation: 0.0330067471890658]
	TIME [epoch: 25.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024083246717041706		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.024083246717041706 | validation: 0.034886243341903746]
	TIME [epoch: 25.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02402074400525843		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.02402074400525843 | validation: 0.04591547890533877]
	TIME [epoch: 25.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02751664341062475		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.02751664341062475 | validation: 0.04133892633394812]
	TIME [epoch: 25.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02658049383997148		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.02658049383997148 | validation: 0.03701886386070465]
	TIME [epoch: 25.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024312186993001507		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.024312186993001507 | validation: 0.03616610036289808]
	TIME [epoch: 25.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025677255105785307		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.025677255105785307 | validation: 0.038450553549328276]
	TIME [epoch: 25.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024407467155066226		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.024407467155066226 | validation: 0.036701240418149636]
	TIME [epoch: 25.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022622668475002022		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.022622668475002022 | validation: 0.03710882555187005]
	TIME [epoch: 25.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026742297349453655		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.026742297349453655 | validation: 0.03554024455382239]
	TIME [epoch: 25.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024202449622927932		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.024202449622927932 | validation: 0.03725473628832103]
	TIME [epoch: 25.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0232150729086376		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.0232150729086376 | validation: 0.03974468025095535]
	TIME [epoch: 25.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024972321923722028		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.024972321923722028 | validation: 0.0398244669554149]
	TIME [epoch: 25.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024396236643757348		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.024396236643757348 | validation: 0.03954083686806431]
	TIME [epoch: 25.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909837317342325		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.02909837317342325 | validation: 0.04121020427656071]
	TIME [epoch: 25.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023333165814818833		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.023333165814818833 | validation: 0.03475652708249266]
	TIME [epoch: 25.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02361405334375648		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.02361405334375648 | validation: 0.03341514949362699]
	TIME [epoch: 25.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022641519794320285		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.022641519794320285 | validation: 0.03352689445934802]
	TIME [epoch: 25.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022532968545982718		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.022532968545982718 | validation: 0.039956390265013034]
	TIME [epoch: 25.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027944482337207713		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.027944482337207713 | validation: 0.03980893559372459]
	TIME [epoch: 25.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023983729465607548		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.023983729465607548 | validation: 0.04347292324355312]
	TIME [epoch: 25.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025834570552481347		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.025834570552481347 | validation: 0.03191972116100016]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02338838923582559		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.02338838923582559 | validation: 0.0322331280895395]
	TIME [epoch: 25.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025897352267345262		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.025897352267345262 | validation: 0.035160093942999036]
	TIME [epoch: 25.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02229332559620241		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.02229332559620241 | validation: 0.03429734040332127]
	TIME [epoch: 25.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023038154058071324		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.023038154058071324 | validation: 0.03618465776747326]
	TIME [epoch: 25.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023621366807173045		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.023621366807173045 | validation: 0.03769559343825852]
	TIME [epoch: 25.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025023005953081302		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.025023005953081302 | validation: 0.03509771833835133]
	TIME [epoch: 25.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02583386291878708		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.02583386291878708 | validation: 0.03844745347876813]
	TIME [epoch: 25.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023212389253780493		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.023212389253780493 | validation: 0.037223729582438525]
	TIME [epoch: 25.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023872663716316814		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.023872663716316814 | validation: 0.040931191194652224]
	TIME [epoch: 25.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024461998766457077		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.024461998766457077 | validation: 0.036865681360513894]
	TIME [epoch: 25.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026281334197878037		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.026281334197878037 | validation: 0.03979678172297162]
	TIME [epoch: 25.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024176177065794384		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.024176177065794384 | validation: 0.03442452558657963]
	TIME [epoch: 25.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0239498349178088		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0239498349178088 | validation: 0.03282118004714259]
	TIME [epoch: 25.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02267722208179871		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.02267722208179871 | validation: 0.037568099545047015]
	TIME [epoch: 25.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023557753853274736		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.023557753853274736 | validation: 0.03453665883833316]
	TIME [epoch: 25.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02438697358081849		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.02438697358081849 | validation: 0.044945385857925776]
	TIME [epoch: 25.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420136884771406		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.02420136884771406 | validation: 0.034877729421777144]
	TIME [epoch: 25.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024216039495786025		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.024216039495786025 | validation: 0.03703850952189458]
	TIME [epoch: 25.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0230867526142221		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.0230867526142221 | validation: 0.03213877889673437]
	TIME [epoch: 25.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026320058973132998		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.026320058973132998 | validation: 0.03969723530432097]
	TIME [epoch: 25.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024310276851112388		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.024310276851112388 | validation: 0.03399253644731055]
	TIME [epoch: 25.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02253554093413543		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.02253554093413543 | validation: 0.03548560182539195]
	TIME [epoch: 25.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021930619639851413		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.021930619639851413 | validation: 0.033981646337256366]
	TIME [epoch: 25.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023324984906826777		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.023324984906826777 | validation: 0.03610232539447214]
	TIME [epoch: 25.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02406319600042862		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.02406319600042862 | validation: 0.035051023607011025]
	TIME [epoch: 25.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025206237781351316		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.025206237781351316 | validation: 0.03623740598671858]
	TIME [epoch: 25.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024720251873746213		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.024720251873746213 | validation: 0.03455342552636427]
	TIME [epoch: 25.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02255903015493346		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.02255903015493346 | validation: 0.03814512800748746]
	TIME [epoch: 25.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022632708458875116		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.022632708458875116 | validation: 0.03320395382655398]
	TIME [epoch: 25.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02268486029671237		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.02268486029671237 | validation: 0.03306744282388982]
	TIME [epoch: 25.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024788204077763984		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.024788204077763984 | validation: 0.03748811244007512]
	TIME [epoch: 25.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02212144908770457		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.02212144908770457 | validation: 0.03488385152062251]
	TIME [epoch: 25.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023298496281803277		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.023298496281803277 | validation: 0.03533376495046618]
	TIME [epoch: 25.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024206032297951503		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.024206032297951503 | validation: 0.03326824179243887]
	TIME [epoch: 25.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023187889643007366		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.023187889643007366 | validation: 0.0346122475984302]
	TIME [epoch: 25.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022310776364239504		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.022310776364239504 | validation: 0.03550978002977474]
	TIME [epoch: 25.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02363657864914001		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.02363657864914001 | validation: 0.03772898078435769]
	TIME [epoch: 25.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312261341805928		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.02312261341805928 | validation: 0.03365606322639211]
	TIME [epoch: 25.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022546640596303784		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.022546640596303784 | validation: 0.034804827471683904]
	TIME [epoch: 25.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02277467667801187		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.02277467667801187 | validation: 0.030754066350660865]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022443187907427567		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.022443187907427567 | validation: 0.03314093889997204]
	TIME [epoch: 25.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02450651208344666		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.02450651208344666 | validation: 0.031025992685468178]
	TIME [epoch: 25.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021942106515651465		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.021942106515651465 | validation: 0.03641020363680953]
	TIME [epoch: 25.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025327074886547507		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.025327074886547507 | validation: 0.03345720458236476]
	TIME [epoch: 25.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021584579819558823		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.021584579819558823 | validation: 0.0343598830602915]
	TIME [epoch: 25.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022654545599279822		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.022654545599279822 | validation: 0.03586524734807028]
	TIME [epoch: 25.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02429852879737543		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.02429852879737543 | validation: 0.03504844355219158]
	TIME [epoch: 25.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023002022863846852		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.023002022863846852 | validation: 0.032997394423973106]
	TIME [epoch: 25.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023177141894002638		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.023177141894002638 | validation: 0.03404191082618909]
	TIME [epoch: 25.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021615917189498526		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.021615917189498526 | validation: 0.037785014332492844]
	TIME [epoch: 25.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263171378293358		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.02263171378293358 | validation: 0.03577652769759924]
	TIME [epoch: 25.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02293579942310469		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.02293579942310469 | validation: 0.03532943998269902]
	TIME [epoch: 25.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02371277686772195		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.02371277686772195 | validation: 0.03377883156270091]
	TIME [epoch: 25.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02357830850401376		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.02357830850401376 | validation: 0.03382074305279399]
	TIME [epoch: 25.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281564123171545		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.02281564123171545 | validation: 0.04143592090094289]
	TIME [epoch: 25.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311598843140123		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.02311598843140123 | validation: 0.03377445032706122]
	TIME [epoch: 25.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022488945862613838		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.022488945862613838 | validation: 0.036223591379485096]
	TIME [epoch: 25.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023614978604552115		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.023614978604552115 | validation: 0.03258985133600707]
	TIME [epoch: 25.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211188783734822		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.0211188783734822 | validation: 0.03549184893305219]
	TIME [epoch: 25.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021527632917275465		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.021527632917275465 | validation: 0.03539599932011328]
	TIME [epoch: 25.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022849312670098768		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.022849312670098768 | validation: 0.03231256541535424]
	TIME [epoch: 25.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024904945698063913		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.024904945698063913 | validation: 0.03624475001528188]
	TIME [epoch: 25.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023430297246569226		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.023430297246569226 | validation: 0.032877649003655696]
	TIME [epoch: 25.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022285182730003184		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.022285182730003184 | validation: 0.030795969877065496]
	TIME [epoch: 25.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02154162825985278		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.02154162825985278 | validation: 0.032175213717904]
	TIME [epoch: 25.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02192348635665637		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.02192348635665637 | validation: 0.03110037163705269]
	TIME [epoch: 25.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021900490634405023		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.021900490634405023 | validation: 0.0337506872111379]
	TIME [epoch: 25.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02178432222919137		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.02178432222919137 | validation: 0.034421770011852475]
	TIME [epoch: 25.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023249534925761997		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.023249534925761997 | validation: 0.03278415221121577]
	TIME [epoch: 25.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0205113346806068		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.0205113346806068 | validation: 0.03277662416599991]
	TIME [epoch: 25.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023092767532390437		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.023092767532390437 | validation: 0.03295678300788878]
	TIME [epoch: 25.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02307997601094922		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.02307997601094922 | validation: 0.032889080098349004]
	TIME [epoch: 25.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02194130528764246		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.02194130528764246 | validation: 0.031037249877007803]
	TIME [epoch: 25.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020266303668395727		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.020266303668395727 | validation: 0.03535611931646513]
	TIME [epoch: 25.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022076835394154004		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.022076835394154004 | validation: 0.03579738741444266]
	TIME [epoch: 25.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023644750321631484		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.023644750321631484 | validation: 0.03346789259039902]
	TIME [epoch: 25.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02175451183703186		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.02175451183703186 | validation: 0.03183925139360175]
	TIME [epoch: 25.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021690098582860032		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.021690098582860032 | validation: 0.03150270662527802]
	TIME [epoch: 25.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021921188167025867		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.021921188167025867 | validation: 0.03599262710244446]
	TIME [epoch: 25.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02319896685738818		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.02319896685738818 | validation: 0.03533448963894394]
	TIME [epoch: 25.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020638831673759017		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.020638831673759017 | validation: 0.032131356036135525]
	TIME [epoch: 25.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02042450025718856		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.02042450025718856 | validation: 0.03202024835459424]
	TIME [epoch: 25.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022905027341487208		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.022905027341487208 | validation: 0.03226814428841436]
	TIME [epoch: 25.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021659965027185535		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.021659965027185535 | validation: 0.03410338000571296]
	TIME [epoch: 25.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02088474940109696		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.02088474940109696 | validation: 0.03605817918920289]
	TIME [epoch: 25.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248960059871778		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0248960059871778 | validation: 0.032850773720093984]
	TIME [epoch: 25.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020751179898024292		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.020751179898024292 | validation: 0.032289099296601266]
	TIME [epoch: 25.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02062412733299823		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.02062412733299823 | validation: 0.03540045975602319]
	TIME [epoch: 25.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290204253611101		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.02290204253611101 | validation: 0.03192796355320448]
	TIME [epoch: 25.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022073962868785203		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.022073962868785203 | validation: 0.03252047471921252]
	TIME [epoch: 25.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02069287466708115		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.02069287466708115 | validation: 0.031614536475754705]
	TIME [epoch: 25.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021442151398884085		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.021442151398884085 | validation: 0.03356450776565065]
	TIME [epoch: 25.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02066126749151447		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.02066126749151447 | validation: 0.03181094893886469]
	TIME [epoch: 25.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021476254058882642		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.021476254058882642 | validation: 0.03201260376189805]
	TIME [epoch: 25.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020704648243383073		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.020704648243383073 | validation: 0.03381155816478211]
	TIME [epoch: 25.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311912669957492		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.02311912669957492 | validation: 0.0399881167643306]
	TIME [epoch: 25.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022849129639390557		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.022849129639390557 | validation: 0.029903960303523006]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02108366743817266		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.02108366743817266 | validation: 0.03247460430606305]
	TIME [epoch: 25.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020803373799869712		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.020803373799869712 | validation: 0.029449315042293513]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_736.pth
	Model improved!!!
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021902331740374575		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.021902331740374575 | validation: 0.03307122271890467]
	TIME [epoch: 25.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020449774648028843		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.020449774648028843 | validation: 0.03002386325534255]
	TIME [epoch: 25.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020850506030912912		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.020850506030912912 | validation: 0.031955366046951345]
	TIME [epoch: 25.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022816014091873546		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.022816014091873546 | validation: 0.03363209070172145]
	TIME [epoch: 25.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022635701285648062		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.022635701285648062 | validation: 0.032874720641125156]
	TIME [epoch: 25.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021950198212526546		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.021950198212526546 | validation: 0.03117009291311507]
	TIME [epoch: 25.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021429507274958706		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.021429507274958706 | validation: 0.03312149673807223]
	TIME [epoch: 25.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02113033642736281		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.02113033642736281 | validation: 0.03483402584856905]
	TIME [epoch: 25.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022417040172764247		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.022417040172764247 | validation: 0.03202589907388688]
	TIME [epoch: 25.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0201254643845667		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0201254643845667 | validation: 0.03294094335127646]
	TIME [epoch: 25.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020785113208851666		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.020785113208851666 | validation: 0.031648774570573586]
	TIME [epoch: 25.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02134466182643246		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.02134466182643246 | validation: 0.03321994727498922]
	TIME [epoch: 25.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02209425894799938		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.02209425894799938 | validation: 0.02951511052281]
	TIME [epoch: 25.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02082957977603113		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.02082957977603113 | validation: 0.03145618641094931]
	TIME [epoch: 25.6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020485665974560488		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.020485665974560488 | validation: 0.03352862459954596]
	TIME [epoch: 25.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02052734779226366		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.02052734779226366 | validation: 0.03149656961160058]
	TIME [epoch: 25.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021125936485205183		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.021125936485205183 | validation: 0.033623248586481705]
	TIME [epoch: 25.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020447241057574273		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.020447241057574273 | validation: 0.03247840080130511]
	TIME [epoch: 25.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021160298237218482		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.021160298237218482 | validation: 0.03113648284753552]
	TIME [epoch: 25.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020931218383897016		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.020931218383897016 | validation: 0.031285503417548086]
	TIME [epoch: 25.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019906252386796896		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.019906252386796896 | validation: 0.0316620229448735]
	TIME [epoch: 25.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019437932313939775		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.019437932313939775 | validation: 0.03260753228781596]
	TIME [epoch: 25.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021350033431620247		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.021350033431620247 | validation: 0.030729282083532136]
	TIME [epoch: 25.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02088496952296879		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.02088496952296879 | validation: 0.0332496527113013]
	TIME [epoch: 25.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02139269646900612		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.02139269646900612 | validation: 0.03058816139000274]
	TIME [epoch: 25.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020528300081420214		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.020528300081420214 | validation: 0.03569594582521492]
	TIME [epoch: 25.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020583707558044846		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.020583707558044846 | validation: 0.03229877888203027]
	TIME [epoch: 25.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021396954217055168		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.021396954217055168 | validation: 0.03030985066828818]
	TIME [epoch: 25.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01952580016487504		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.01952580016487504 | validation: 0.03006542245993994]
	TIME [epoch: 25.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019845109756437853		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.019845109756437853 | validation: 0.036528439965445386]
	TIME [epoch: 25.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02238200943089024		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.02238200943089024 | validation: 0.03368340249187172]
	TIME [epoch: 25.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02153667169991043		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.02153667169991043 | validation: 0.03351373613590805]
	TIME [epoch: 25.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019642309607963933		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.019642309607963933 | validation: 0.028965653087614698]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020102654816799768		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.020102654816799768 | validation: 0.031141240301236058]
	TIME [epoch: 25.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020624359098981162		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.020624359098981162 | validation: 0.03157690554340423]
	TIME [epoch: 25.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020110677052839532		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.020110677052839532 | validation: 0.03129492650299233]
	TIME [epoch: 25.6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021058730036857196		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.021058730036857196 | validation: 0.03345481147949102]
	TIME [epoch: 25.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202492076286911		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.02202492076286911 | validation: 0.031071991832367203]
	TIME [epoch: 25.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045021781904819		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.02045021781904819 | validation: 0.030709794272947837]
	TIME [epoch: 25.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01991893336505172		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.01991893336505172 | validation: 0.0289455624650688]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_776.pth
	Model improved!!!
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020433911635226593		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.020433911635226593 | validation: 0.03512189284074265]
	TIME [epoch: 25.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02117773840202458		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.02117773840202458 | validation: 0.030228132739663346]
	TIME [epoch: 25.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01972022484897125		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.01972022484897125 | validation: 0.0367134164895717]
	TIME [epoch: 25.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020710296108887583		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.020710296108887583 | validation: 0.03273836763839177]
	TIME [epoch: 25.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019285198337241193		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.019285198337241193 | validation: 0.02907078949496268]
	TIME [epoch: 25.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019994785406164672		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.019994785406164672 | validation: 0.03401663611625416]
	TIME [epoch: 25.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02019580964014629		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.02019580964014629 | validation: 0.02939599932800739]
	TIME [epoch: 25.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020621831367766748		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.020621831367766748 | validation: 0.03445579193220312]
	TIME [epoch: 25.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020247181065982806		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.020247181065982806 | validation: 0.032700412182248825]
	TIME [epoch: 25.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0198685447140977		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0198685447140977 | validation: 0.031227591586192427]
	TIME [epoch: 25.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021358630842416227		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.021358630842416227 | validation: 0.029252085039255638]
	TIME [epoch: 25.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0197040308820628		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.0197040308820628 | validation: 0.031441387749253466]
	TIME [epoch: 25.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020015210287864092		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.020015210287864092 | validation: 0.031659926656274345]
	TIME [epoch: 25.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02076665878128505		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.02076665878128505 | validation: 0.03089949350894579]
	TIME [epoch: 25.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020178745745583846		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.020178745745583846 | validation: 0.03212012938587097]
	TIME [epoch: 25.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020468803739467228		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.020468803739467228 | validation: 0.03565864668867294]
	TIME [epoch: 25.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020589914814485567		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.020589914814485567 | validation: 0.029482692820028706]
	TIME [epoch: 25.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02049667838618235		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.02049667838618235 | validation: 0.0311877267981698]
	TIME [epoch: 25.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01941919801122193		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.01941919801122193 | validation: 0.030141910249208544]
	TIME [epoch: 25.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020488649978501354		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.020488649978501354 | validation: 0.030165661702516035]
	TIME [epoch: 25.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021278579267480422		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.021278579267480422 | validation: 0.028946899548628512]
	TIME [epoch: 25.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019805481033854797		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.019805481033854797 | validation: 0.030160919668651365]
	TIME [epoch: 25.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02004047577527306		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.02004047577527306 | validation: 0.029814776320582964]
	TIME [epoch: 25.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01994323717555958		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.01994323717555958 | validation: 0.029396961621660705]
	TIME [epoch: 25.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02064026051927955		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.02064026051927955 | validation: 0.03560425579770217]
	TIME [epoch: 25.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019367861712694317		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.019367861712694317 | validation: 0.029250407193667283]
	TIME [epoch: 25.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019240890598179603		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.019240890598179603 | validation: 0.031193022369697145]
	TIME [epoch: 25.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020439546807478285		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.020439546807478285 | validation: 0.028585114546708944]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02030432859427571		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.02030432859427571 | validation: 0.03215515816814443]
	TIME [epoch: 25.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019704316832574686		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.019704316832574686 | validation: 0.02906225812960025]
	TIME [epoch: 25.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01892885537888934		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.01892885537888934 | validation: 0.03216616466098793]
	TIME [epoch: 25.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019851897037011214		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.019851897037011214 | validation: 0.0341241603517284]
	TIME [epoch: 25.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020999498077896646		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.020999498077896646 | validation: 0.030182975471682735]
	TIME [epoch: 25.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019515912410982203		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.019515912410982203 | validation: 0.029293326871187176]
	TIME [epoch: 25.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019290507577579746		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.019290507577579746 | validation: 0.030590452399440735]
	TIME [epoch: 25.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019015439724969083		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.019015439724969083 | validation: 0.03144764200396362]
	TIME [epoch: 25.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019926755823004794		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.019926755823004794 | validation: 0.027973286839304622]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_813.pth
	Model improved!!!
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986112132362783		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.01986112132362783 | validation: 0.030496251637462883]
	TIME [epoch: 25.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019641887491933584		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.019641887491933584 | validation: 0.028702062002376426]
	TIME [epoch: 25.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01928284521316255		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.01928284521316255 | validation: 0.03154260106565551]
	TIME [epoch: 25.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001808410267734		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.02001808410267734 | validation: 0.03364693398818926]
	TIME [epoch: 25.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951158389907303		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.01951158389907303 | validation: 0.03137699614848668]
	TIME [epoch: 25.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01902300010121285		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.01902300010121285 | validation: 0.029443438044776678]
	TIME [epoch: 25.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02021735839380745		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.02021735839380745 | validation: 0.028048595933712908]
	TIME [epoch: 25.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01956374175455339		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.01956374175455339 | validation: 0.029103437956160324]
	TIME [epoch: 25.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019146778124619922		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.019146778124619922 | validation: 0.028249240612027725]
	TIME [epoch: 25.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019632495610762236		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.019632495610762236 | validation: 0.02974188880593647]
	TIME [epoch: 25.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019880635329691643		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.019880635329691643 | validation: 0.029582990324014277]
	TIME [epoch: 25.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019818935615312675		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.019818935615312675 | validation: 0.027270998538497845]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018929547887139474		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.018929547887139474 | validation: 0.032686102695992814]
	TIME [epoch: 25.6 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019576217070932034		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.019576217070932034 | validation: 0.026714445202851322]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_827.pth
	Model improved!!!
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018725951322585914		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.018725951322585914 | validation: 0.03221521667280751]
	TIME [epoch: 25.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019373844827523058		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.019373844827523058 | validation: 0.03020224573608767]
	TIME [epoch: 25.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020006006021788623		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.020006006021788623 | validation: 0.028541187350273268]
	TIME [epoch: 25.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018346895245946654		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.018346895245946654 | validation: 0.029668933231414563]
	TIME [epoch: 25.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018899974282049644		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.018899974282049644 | validation: 0.034196207900228315]
	TIME [epoch: 25.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019731116435963696		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.019731116435963696 | validation: 0.030101963715565058]
	TIME [epoch: 25.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0193707716366231		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0193707716366231 | validation: 0.03373347359945765]
	TIME [epoch: 25.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0192601462106986		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0192601462106986 | validation: 0.028828838372407642]
	TIME [epoch: 25.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019095344656514725		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.019095344656514725 | validation: 0.027549642579056684]
	TIME [epoch: 25.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018899486940831794		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.018899486940831794 | validation: 0.029062383305847088]
	TIME [epoch: 25.6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018508343226673978		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.018508343226673978 | validation: 0.030294764606689572]
	TIME [epoch: 25.6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020166945561371157		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.020166945561371157 | validation: 0.03405468029539121]
	TIME [epoch: 25.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019380276958799566		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.019380276958799566 | validation: 0.027630333289442678]
	TIME [epoch: 25.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018716883922096084		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.018716883922096084 | validation: 0.029087446666284444]
	TIME [epoch: 25.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0180780961733178		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0180780961733178 | validation: 0.027046598960612223]
	TIME [epoch: 25.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01965487129269427		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.01965487129269427 | validation: 0.028470905134689625]
	TIME [epoch: 25.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01920328015942308		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.01920328015942308 | validation: 0.02884192284757977]
	TIME [epoch: 25.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018313469987028486		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.018313469987028486 | validation: 0.03159271299529501]
	TIME [epoch: 25.6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0190317979250143		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.0190317979250143 | validation: 0.027620523957856018]
	TIME [epoch: 25.6 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018504438154138644		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.018504438154138644 | validation: 0.028068121784942578]
	TIME [epoch: 25.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019226169084646198		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.019226169084646198 | validation: 0.028360868785226805]
	TIME [epoch: 25.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911355705524123		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.01911355705524123 | validation: 0.032349530831656405]
	TIME [epoch: 25.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019700687167938546		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.019700687167938546 | validation: 0.029768833649385203]
	TIME [epoch: 25.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019234294359949458		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.019234294359949458 | validation: 0.028277832017532804]
	TIME [epoch: 25.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018698501567114		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.018698501567114 | validation: 0.02788542430654216]
	TIME [epoch: 25.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018356420792735872		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.018356420792735872 | validation: 0.02547797630811075]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01851216354003253		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.01851216354003253 | validation: 0.02977293560862637]
	TIME [epoch: 25.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01888735084653352		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.01888735084653352 | validation: 0.02913790734053025]
	TIME [epoch: 25.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020681395639729205		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.020681395639729205 | validation: 0.02916140473625648]
	TIME [epoch: 25.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018606017588678053		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.018606017588678053 | validation: 0.02923563284193017]
	TIME [epoch: 25.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01924651472243831		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.01924651472243831 | validation: 0.03072567390703175]
	TIME [epoch: 25.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018339571257748193		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.018339571257748193 | validation: 0.028195031674872008]
	TIME [epoch: 25.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019007007802401565		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.019007007802401565 | validation: 0.027533089778753506]
	TIME [epoch: 25.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019400422906751744		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.019400422906751744 | validation: 0.030458124630306782]
	TIME [epoch: 25.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019015015005326364		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.019015015005326364 | validation: 0.03017883137632702]
	TIME [epoch: 25.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019145446569842288		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.019145446569842288 | validation: 0.02981741887268541]
	TIME [epoch: 25.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0197144471581379		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.0197144471581379 | validation: 0.02813356781492661]
	TIME [epoch: 25.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01818142557860749		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.01818142557860749 | validation: 0.02842578972269076]
	TIME [epoch: 25.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018359745348391174		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.018359745348391174 | validation: 0.029131871896965034]
	TIME [epoch: 25.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01993141641372312		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.01993141641372312 | validation: 0.02734906386394924]
	TIME [epoch: 25.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778743049452572		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.01778743049452572 | validation: 0.02734908926027245]
	TIME [epoch: 25.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018203986582048037		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.018203986582048037 | validation: 0.02925358174839679]
	TIME [epoch: 25.7 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01900786068053141		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.01900786068053141 | validation: 0.029303854883150855]
	TIME [epoch: 25.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01914818273561243		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.01914818273561243 | validation: 0.02696653251588666]
	TIME [epoch: 25.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018558833230233218		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.018558833230233218 | validation: 0.028326745232442732]
	TIME [epoch: 25.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01868904128753042		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.01868904128753042 | validation: 0.0251582141052513]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019285602411022507		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.019285602411022507 | validation: 0.02875320051576617]
	TIME [epoch: 25.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01928142049383195		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.01928142049383195 | validation: 0.02666987984856224]
	TIME [epoch: 25.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181805385066963		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.0181805385066963 | validation: 0.028801539153186145]
	TIME [epoch: 25.6 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018563033056067588		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.018563033056067588 | validation: 0.03197550833469514]
	TIME [epoch: 25.6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019005976800596416		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.019005976800596416 | validation: 0.02601346852584254]
	TIME [epoch: 25.6 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018621167828276705		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.018621167828276705 | validation: 0.02708688216793753]
	TIME [epoch: 25.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01810008201662256		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.01810008201662256 | validation: 0.029442089850774567]
	TIME [epoch: 25.6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01816710726207229		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.01816710726207229 | validation: 0.03234091545976708]
	TIME [epoch: 25.6 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019073313008384454		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.019073313008384454 | validation: 0.028585749803839898]
	TIME [epoch: 25.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018396100882889694		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.018396100882889694 | validation: 0.02889918870975169]
	TIME [epoch: 25.6 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018776748992445528		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.018776748992445528 | validation: 0.02830321543740541]
	TIME [epoch: 25.6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019273808338193695		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.019273808338193695 | validation: 0.027795943957365142]
	TIME [epoch: 25.6 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018834251118309234		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.018834251118309234 | validation: 0.029322919273230733]
	TIME [epoch: 25.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018291953149211383		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.018291953149211383 | validation: 0.02589417302641602]
	TIME [epoch: 25.6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017644803704731496		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.017644803704731496 | validation: 0.027885740874058144]
	TIME [epoch: 25.6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876716390639058		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.01876716390639058 | validation: 0.0276187160242978]
	TIME [epoch: 25.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01887883890254255		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.01887883890254255 | validation: 0.02979166127215978]
	TIME [epoch: 25.6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01748375479123772		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.01748375479123772 | validation: 0.028160695381215232]
	TIME [epoch: 25.6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01804283341205351		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.01804283341205351 | validation: 0.0260420696710143]
	TIME [epoch: 25.6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01863437442314584		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.01863437442314584 | validation: 0.028139433157402978]
	TIME [epoch: 25.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018427306210194304		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.018427306210194304 | validation: 0.026945884635429483]
	TIME [epoch: 25.6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019161803240144257		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.019161803240144257 | validation: 0.0254049115883851]
	TIME [epoch: 25.6 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018563559215489488		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.018563559215489488 | validation: 0.026891178745469875]
	TIME [epoch: 25.6 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017964858863345902		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.017964858863345902 | validation: 0.027793178348596796]
	TIME [epoch: 25.6 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017561998096966548		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.017561998096966548 | validation: 0.027617149935031872]
	TIME [epoch: 25.6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017859955539270767		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.017859955539270767 | validation: 0.027040138394552295]
	TIME [epoch: 25.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017784158401998477		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.017784158401998477 | validation: 0.02577866253759491]
	TIME [epoch: 25.6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019122886879717575		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.019122886879717575 | validation: 0.02727866157141689]
	TIME [epoch: 25.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017878753718885882		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.017878753718885882 | validation: 0.02592166699373869]
	TIME [epoch: 25.6 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019478400111242695		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.019478400111242695 | validation: 0.027041312876337896]
	TIME [epoch: 25.6 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017857276325106607		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.017857276325106607 | validation: 0.027962912008189025]
	TIME [epoch: 25.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018361450115299254		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.018361450115299254 | validation: 0.027194586572136067]
	TIME [epoch: 25.6 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01757877949572717		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.01757877949572717 | validation: 0.028864587596398282]
	TIME [epoch: 25.6 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0178699320126132		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0178699320126132 | validation: 0.025185763524669773]
	TIME [epoch: 25.7 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017538890881036107		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.017538890881036107 | validation: 0.027093987266516864]
	TIME [epoch: 25.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018597005547015842		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.018597005547015842 | validation: 0.02851339583287376]
	TIME [epoch: 25.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017626115287129686		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.017626115287129686 | validation: 0.02276682267974035]
	TIME [epoch: 25.7 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_910.pth
	Model improved!!!
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847085542051241		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.01847085542051241 | validation: 0.026576726249437292]
	TIME [epoch: 25.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01875249269764244		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.01875249269764244 | validation: 0.027532761456227607]
	TIME [epoch: 25.6 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017358621285783388		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.017358621285783388 | validation: 0.025287601959768292]
	TIME [epoch: 25.6 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018245361892096072		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.018245361892096072 | validation: 0.0309484767386351]
	TIME [epoch: 25.6 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181935432614209		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.0181935432614209 | validation: 0.025378576728616736]
	TIME [epoch: 25.6 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017790581797355196		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.017790581797355196 | validation: 0.028802455079247627]
	TIME [epoch: 25.6 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018276416435948267		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.018276416435948267 | validation: 0.02460992181864105]
	TIME [epoch: 25.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018355666962773323		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.018355666962773323 | validation: 0.028847788811859443]
	TIME [epoch: 25.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01765594649268269		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.01765594649268269 | validation: 0.030296452754370685]
	TIME [epoch: 25.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018896920999526945		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.018896920999526945 | validation: 0.025722433591338342]
	TIME [epoch: 25.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017430152573818886		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.017430152573818886 | validation: 0.02627242048568643]
	TIME [epoch: 25.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019005334749627515		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.019005334749627515 | validation: 0.026590811507311442]
	TIME [epoch: 25.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802054367063458		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.01802054367063458 | validation: 0.026574491931595473]
	TIME [epoch: 25.6 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831699008452508		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.01831699008452508 | validation: 0.028297583452448212]
	TIME [epoch: 25.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017422223158555673		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.017422223158555673 | validation: 0.024898686077785812]
	TIME [epoch: 25.6 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017806156023439434		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.017806156023439434 | validation: 0.02596170100199654]
	TIME [epoch: 25.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01743671927695192		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.01743671927695192 | validation: 0.02478220296344326]
	TIME [epoch: 25.6 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01775229508682683		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.01775229508682683 | validation: 0.02447873757265053]
	TIME [epoch: 25.6 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017706705796633		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.017706705796633 | validation: 0.023663706394654656]
	TIME [epoch: 25.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01784253157437993		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.01784253157437993 | validation: 0.02622804342142071]
	TIME [epoch: 25.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01819389311938468		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.01819389311938468 | validation: 0.025191982088728894]
	TIME [epoch: 25.6 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017741212758441816		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.017741212758441816 | validation: 0.02699728080016034]
	TIME [epoch: 25.6 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017671949196789067		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.017671949196789067 | validation: 0.03192740958037252]
	TIME [epoch: 25.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018511981532546844		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.018511981532546844 | validation: 0.024309258890700465]
	TIME [epoch: 25.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018354165517205694		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.018354165517205694 | validation: 0.025853527363969928]
	TIME [epoch: 25.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018017328407908744		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.018017328407908744 | validation: 0.027053304343264244]
	TIME [epoch: 25.6 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01747666657176869		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.01747666657176869 | validation: 0.023938477614437924]
	TIME [epoch: 25.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017098024144292748		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.017098024144292748 | validation: 0.026831007829404712]
	TIME [epoch: 25.6 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01786804277406489		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.01786804277406489 | validation: 0.02432600405158641]
	TIME [epoch: 25.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710536221086005		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.01710536221086005 | validation: 0.02619736846569655]
	TIME [epoch: 25.6 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018074492049672743		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.018074492049672743 | validation: 0.02567327894690636]
	TIME [epoch: 25.6 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018503716392913344		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.018503716392913344 | validation: 0.025499399864911454]
	TIME [epoch: 25.6 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017000555068220177		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.017000555068220177 | validation: 0.02641143126993457]
	TIME [epoch: 25.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017250030737746603		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.017250030737746603 | validation: 0.026031327334808528]
	TIME [epoch: 25.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016703662346705277		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.016703662346705277 | validation: 0.025895910343668463]
	TIME [epoch: 25.6 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01699737802136586		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.01699737802136586 | validation: 0.026222347060755123]
	TIME [epoch: 25.6 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742649803444035		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.01742649803444035 | validation: 0.026612221671465076]
	TIME [epoch: 25.6 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0182109850998646		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.0182109850998646 | validation: 0.024601848627834072]
	TIME [epoch: 25.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01770114317197559		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.01770114317197559 | validation: 0.028781089672334212]
	TIME [epoch: 25.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01748178437822567		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.01748178437822567 | validation: 0.02289689761592733]
	TIME [epoch: 25.6 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017449004322520466		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.017449004322520466 | validation: 0.024892013053197236]
	TIME [epoch: 25.6 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002080532624114		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.017002080532624114 | validation: 0.027727148508838978]
	TIME [epoch: 25.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017182985872804788		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.017182985872804788 | validation: 0.02590775044402885]
	TIME [epoch: 25.6 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017182980408027956		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.017182980408027956 | validation: 0.023620396873818943]
	TIME [epoch: 25.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017770533829974424		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.017770533829974424 | validation: 0.026150734580656296]
	TIME [epoch: 25.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018072007539742616		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.018072007539742616 | validation: 0.025818506043236697]
	TIME [epoch: 25.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017682182704869445		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.017682182704869445 | validation: 0.028527545295273557]
	TIME [epoch: 25.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01753439877324202		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.01753439877324202 | validation: 0.024289621161315184]
	TIME [epoch: 25.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016777797573805545		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.016777797573805545 | validation: 0.026715349471787435]
	TIME [epoch: 25.6 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0171598504610452		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.0171598504610452 | validation: 0.027097168735079967]
	TIME [epoch: 25.6 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017244472616868334		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.017244472616868334 | validation: 0.025115191152441804]
	TIME [epoch: 25.6 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018030512310024893		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.018030512310024893 | validation: 0.02704293253326184]
	TIME [epoch: 25.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017621851375333505		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.017621851375333505 | validation: 0.025480417338110968]
	TIME [epoch: 25.6 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0176044372828418		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.0176044372828418 | validation: 0.027686294355521703]
	TIME [epoch: 25.6 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791523015419979		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.01791523015419979 | validation: 0.02511872639613153]
	TIME [epoch: 25.6 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017120720558170502		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.017120720558170502 | validation: 0.027835171376873913]
	TIME [epoch: 25.6 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016843252298377777		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.016843252298377777 | validation: 0.025063937943932357]
	TIME [epoch: 25.6 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017109756708407378		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.017109756708407378 | validation: 0.02552122865589144]
	TIME [epoch: 25.6 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017057560391191044		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.017057560391191044 | validation: 0.02555281175174804]
	TIME [epoch: 25.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017465488861079098		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.017465488861079098 | validation: 0.025183977395955966]
	TIME [epoch: 25.6 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017078502342087798		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.017078502342087798 | validation: 0.025577571493638568]
	TIME [epoch: 25.6 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017885493679525542		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.017885493679525542 | validation: 0.024615170671671117]
	TIME [epoch: 25.6 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016943489454008302		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.016943489454008302 | validation: 0.025887851030860914]
	TIME [epoch: 25.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01738662722276447		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.01738662722276447 | validation: 0.02523562754761749]
	TIME [epoch: 25.6 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718534517970013		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.01718534517970013 | validation: 0.026318444527023876]
	TIME [epoch: 25.6 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698377779605142		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.01698377779605142 | validation: 0.025305507305572746]
	TIME [epoch: 25.6 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018381105624254827		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.018381105624254827 | validation: 0.024572284239159657]
	TIME [epoch: 25.6 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017253227072820496		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.017253227072820496 | validation: 0.02345444911644369]
	TIME [epoch: 25.6 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017083179210518825		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.017083179210518825 | validation: 0.025515002282565293]
	TIME [epoch: 25.6 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01656051226743347		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.01656051226743347 | validation: 0.0234987974201935]
	TIME [epoch: 25.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017361460908450362		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.017361460908450362 | validation: 0.024970883749149228]
	TIME [epoch: 25.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017045008944091073		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.017045008944091073 | validation: 0.024975580402509995]
	TIME [epoch: 25.6 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017466148842706017		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.017466148842706017 | validation: 0.027751443957770378]
	TIME [epoch: 25.6 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016899084068821804		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.016899084068821804 | validation: 0.023723431338374873]
	TIME [epoch: 25.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017027386106825186		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.017027386106825186 | validation: 0.024818157857808828]
	TIME [epoch: 25.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01746847186983823		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.01746847186983823 | validation: 0.024782194016532057]
	TIME [epoch: 25.6 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017480427631699876		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.017480427631699876 | validation: 0.024160619734903355]
	TIME [epoch: 25.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016899966532020822		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.016899966532020822 | validation: 0.02495101016861083]
	TIME [epoch: 25.6 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017020788517179794		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.017020788517179794 | validation: 0.024782454276801463]
	TIME [epoch: 25.6 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01694813151921331		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.01694813151921331 | validation: 0.02688200492214884]
	TIME [epoch: 25.6 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01724177259659654		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.01724177259659654 | validation: 0.026289284661333394]
	TIME [epoch: 25.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017066694433706626		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.017066694433706626 | validation: 0.026003714280169954]
	TIME [epoch: 25.6 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01730462938101486		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.01730462938101486 | validation: 0.02391840558298749]
	TIME [epoch: 25.6 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0168352712058027		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0168352712058027 | validation: 0.02286067957547596]
	TIME [epoch: 25.6 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01675983041895302		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.01675983041895302 | validation: 0.025075991134159772]
	TIME [epoch: 25.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017779369007400205		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.017779369007400205 | validation: 0.024571201953405498]
	TIME [epoch: 25.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016079459666533378		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.016079459666533378 | validation: 0.02652721921991014]
	TIME [epoch: 25.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017111133032772674		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.017111133032772674 | validation: 0.023859200707406093]
	TIME [epoch: 25.6 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016612834564861814		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.016612834564861814 | validation: 0.024107240612979794]
	TIME [epoch: 25.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016633478968503135		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.016633478968503135 | validation: 0.027798639946161136]
	TIME [epoch: 25.6 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016990126830151157		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.016990126830151157 | validation: 0.023973350593167422]
	TIME [epoch: 411 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017524316783539967		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.017524316783539967 | validation: 0.026481858386327627]
	TIME [epoch: 54.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016577085376454633		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.016577085376454633 | validation: 0.026755540485968045]
	TIME [epoch: 54.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017114094974921966		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.017114094974921966 | validation: 0.023181157413982537]
	TIME [epoch: 54.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01677786463046771		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.01677786463046771 | validation: 0.02521664416687026]
	TIME [epoch: 54.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016999833721397753		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.016999833721397753 | validation: 0.02533685306179546]
	TIME [epoch: 54.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017082342096300336		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.017082342096300336 | validation: 0.02328101032666481]
	TIME [epoch: 54.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016719105828789174		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.016719105828789174 | validation: 0.02460502575775657]
	TIME [epoch: 54.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016747539557769718		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.016747539557769718 | validation: 0.027119395058567405]
	TIME [epoch: 54.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016718143227296287		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.016718143227296287 | validation: 0.023841739806250935]
	TIME [epoch: 54.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017476888287993986		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.017476888287993986 | validation: 0.024907536604905536]
	TIME [epoch: 54.3 sec]
	Saving model to: out/model_training/model_phi1_1a_saddle_v1b_3_v_mmd1_20250611_071928/states/model_phi1_1a_saddle_v1b_3_v_mmd1_1011.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 19932.370 seconds.
