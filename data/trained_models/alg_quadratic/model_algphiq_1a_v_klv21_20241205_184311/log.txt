Args:
Namespace(name='model_algphiq_1a_v_klv21', outdir='out/model_training/model_algphiq_1a_v_klv21', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4211013672

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 8.934754817636534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.934754817636534 | validation: 9.063943580811998]
	TIME [epoch: 397 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 8.885711699758852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.885711699758852 | validation: 9.026145019786401]
	TIME [epoch: 2.61 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 8.852753809175749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.852753809175749 | validation: 8.998887249015354]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 8.825454255106617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.825454255106617 | validation: 8.972880524790597]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 8.79689698556423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.79689698556423 | validation: 8.946965381038279]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 8.764061892228613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.764061892228613 | validation: 8.91142485717721]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 8.718439279730374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.718439279730374 | validation: 8.863175497379105]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 8.652314599272058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.652314599272058 | validation: 8.79250213966523]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 8.554712318849207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.554712318849207 | validation: 8.68086781397289]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 8.39733607038588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.39733607038588 | validation: 8.482981335774625]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 8.10052110973716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.10052110973716 | validation: 8.465100409283272]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 7.813597198220924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.813597198220924 | validation: 8.34936292620603]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 7.637486556716075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.637486556716075 | validation: 8.171438043360652]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 7.469317733909418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.469317733909418 | validation: 8.033226325696036]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 7.278260230296562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.278260230296562 | validation: 7.843953799755492]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 7.062018101030399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.062018101030399 | validation: 7.604638782277666]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 6.77292927707611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.77292927707611 | validation: 7.399285562492716]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 6.48712705602688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.48712705602688 | validation: 7.090701985220177]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 6.155611109168821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.155611109168821 | validation: 6.787792346654838]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 5.8241014811026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8241014811026 | validation: 6.419279259941602]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 5.497487332369809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.497487332369809 | validation: 6.165063288998512]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 5.071335320684543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.071335320684543 | validation: 5.596259569102924]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 4.60342502515693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.60342502515693 | validation: 5.063411425291596]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 4.082694143336186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.082694143336186 | validation: 4.618552735290008]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 3.505397784534387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.505397784534387 | validation: 3.5773818534256883]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 2.879477043805311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.879477043805311 | validation: 2.7255365456395486]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 2.1896443533753422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1896443533753422 | validation: 1.985048180316398]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_27.pth
	Model improved!!!
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 1.6365295844479093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6365295844479093 | validation: 1.34124669561626]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 1.1217502726443274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1217502726443274 | validation: 0.8775705028007397]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8427883611929089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8427883611929089 | validation: 0.6169893681589719]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5736209897488233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5736209897488233 | validation: 0.46942902516705287]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3943131802988844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3943131802988844 | validation: 0.3316002898808699]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.33917258733550926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33917258733550926 | validation: 0.25827151865217013]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.274882879383441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.274882879383441 | validation: 0.31304001069741594]
	TIME [epoch: 2.56 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28049863926437374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28049863926437374 | validation: 0.2970019077799567]
	TIME [epoch: 2.54 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28357716565275964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28357716565275964 | validation: 0.270631447835055]
	TIME [epoch: 2.54 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2867118987212464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2867118987212464 | validation: 0.23030601641905565]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3406792295220115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3406792295220115 | validation: 0.4819416923812029]
	TIME [epoch: 2.55 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3495472810891935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3495472810891935 | validation: 0.17625880610085287]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.3219102659516845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3219102659516845 | validation: 0.489240855565826]
	TIME [epoch: 2.56 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4062246716325724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4062246716325724 | validation: 0.4246400304503072]
	TIME [epoch: 2.55 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2727394421689612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2727394421689612 | validation: 0.1705342854434571]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.285654573591433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.285654573591433 | validation: 0.18421922249667055]
	TIME [epoch: 2.55 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2592050572100468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2592050572100468 | validation: 0.24136243678541708]
	TIME [epoch: 2.54 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2929319797067075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2929319797067075 | validation: 0.18507438978864652]
	TIME [epoch: 2.54 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24495144328302343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24495144328302343 | validation: 0.1650983109322677]
	TIME [epoch: 2.55 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2810957177696764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2810957177696764 | validation: 0.22680766445350448]
	TIME [epoch: 2.56 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2703534023971264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2703534023971264 | validation: 0.19821441965219286]
	TIME [epoch: 2.55 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2168220331796776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2168220331796776 | validation: 0.16271623549934183]
	TIME [epoch: 2.54 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18496306113392214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18496306113392214 | validation: 0.4325344193992683]
	TIME [epoch: 2.55 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.28861232714312474		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.28861232714312474 | validation: 0.2216671003084092]
	TIME [epoch: 412 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2678695559225139		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.2678695559225139 | validation: 0.20728397209933985]
	TIME [epoch: 5 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23406940250320457		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.23406940250320457 | validation: 0.1937995956491902]
	TIME [epoch: 4.95 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21041604887609616		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.21041604887609616 | validation: 0.19079121517534486]
	TIME [epoch: 4.94 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21002370343895738		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.21002370343895738 | validation: 0.19518018573354373]
	TIME [epoch: 4.94 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19824120828970815		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.19824120828970815 | validation: 0.2195270665391638]
	TIME [epoch: 4.94 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21799130827250923		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.21799130827250923 | validation: 0.19008228634143937]
	TIME [epoch: 4.94 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1967772331338704		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.1967772331338704 | validation: 0.21459746387037804]
	TIME [epoch: 4.94 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.202879699831509		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.202879699831509 | validation: 0.2206516122380788]
	TIME [epoch: 4.94 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1928468553053124		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.1928468553053124 | validation: 0.24722777847749128]
	TIME [epoch: 4.94 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20190223728210585		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.20190223728210585 | validation: 0.2531648263244064]
	TIME [epoch: 4.95 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2127467126622808		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.2127467126622808 | validation: 0.18898158251653252]
	TIME [epoch: 4.95 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1864981445951115		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.1864981445951115 | validation: 0.14492779908289818]
	TIME [epoch: 4.96 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_63.pth
	Model improved!!!
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16103584938682458		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.16103584938682458 | validation: 0.3231284605100261]
	TIME [epoch: 4.97 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21251009251631794		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.21251009251631794 | validation: 0.21405544944944044]
	TIME [epoch: 4.96 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18382527531877935		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.18382527531877935 | validation: 0.17479987765121602]
	TIME [epoch: 4.96 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2253854085728787		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.2253854085728787 | validation: 0.13903621535085692]
	TIME [epoch: 4.95 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16245722800338713		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.16245722800338713 | validation: 0.15975901044137686]
	TIME [epoch: 4.97 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16182194085704546		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.16182194085704546 | validation: 0.16193367753080223]
	TIME [epoch: 4.95 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15888424726327566		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.15888424726327566 | validation: 0.128496969847387]
	TIME [epoch: 4.95 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1534826188735058		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.1534826188735058 | validation: 0.1329014960737041]
	TIME [epoch: 4.96 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1543161856893036		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.1543161856893036 | validation: 0.13362996974637165]
	TIME [epoch: 4.94 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.20645468728204835		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.20645468728204835 | validation: 0.13920978335188994]
	TIME [epoch: 4.95 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21867365107953068		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.21867365107953068 | validation: 0.2979132936218967]
	TIME [epoch: 4.95 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.24821253989120223		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.24821253989120223 | validation: 0.25614412280024124]
	TIME [epoch: 4.95 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16875540957558785		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.16875540957558785 | validation: 0.13522459730476516]
	TIME [epoch: 4.95 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14465652302124235		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.14465652302124235 | validation: 0.13221217779122477]
	TIME [epoch: 4.95 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14188051865397416		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.14188051865397416 | validation: 0.12661176007907754]
	TIME [epoch: 4.96 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1424149026129734		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.1424149026129734 | validation: 0.12594796301694966]
	TIME [epoch: 4.97 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13686282358527105		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.13686282358527105 | validation: 0.2880402877924454]
	TIME [epoch: 4.97 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22945991688878953		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.22945991688878953 | validation: 0.26684503909747326]
	TIME [epoch: 4.96 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.22172657950654776		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.22172657950654776 | validation: 0.12616979608412573]
	TIME [epoch: 4.95 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21356240041495386		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.21356240041495386 | validation: 0.18873014430561896]
	TIME [epoch: 4.95 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15520986866682496		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.15520986866682496 | validation: 0.15790392949487692]
	TIME [epoch: 4.96 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15680435559987668		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.15680435559987668 | validation: 0.14171341830168924]
	TIME [epoch: 4.96 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17839533921358902		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.17839533921358902 | validation: 0.10627200576330734]
	TIME [epoch: 4.96 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21790641844079836		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.21790641844079836 | validation: 0.19613379300914657]
	TIME [epoch: 4.97 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14109982330865148		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.14109982330865148 | validation: 0.10670266441218174]
	TIME [epoch: 4.95 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12689029632070012		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.12689029632070012 | validation: 0.09601339041970308]
	TIME [epoch: 4.95 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15371091802316975		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.15371091802316975 | validation: 0.10619565759887467]
	TIME [epoch: 4.96 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12202079495873423		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.12202079495873423 | validation: 0.09581567011881775]
	TIME [epoch: 4.94 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10781888577389738		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.10781888577389738 | validation: 0.09110034506287651]
	TIME [epoch: 4.96 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11672109109290987		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.11672109109290987 | validation: 0.10558849578773578]
	TIME [epoch: 4.95 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11786618939173846		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.11786618939173846 | validation: 0.10051293390797586]
	TIME [epoch: 4.95 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16733367618356523		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.16733367618356523 | validation: 0.1208712140173589]
	TIME [epoch: 4.95 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10681616800616517		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.10681616800616517 | validation: 0.1875735639818487]
	TIME [epoch: 4.95 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13750386922616376		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.13750386922616376 | validation: 0.10107431634525584]
	TIME [epoch: 4.95 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12644711000006248		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.12644711000006248 | validation: 0.13903911148900872]
	TIME [epoch: 4.95 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1268870054258921		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.1268870054258921 | validation: 0.12092926160124497]
	TIME [epoch: 4.95 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10986944106023419		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.10986944106023419 | validation: 0.08643014911283586]
	TIME [epoch: 4.95 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11537497137747846		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.11537497137747846 | validation: 0.13645029194677627]
	TIME [epoch: 426 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10279367742751377		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.10279367742751377 | validation: 0.08625435757121105]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11492825310544576		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.11492825310544576 | validation: 0.0689543804194506]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10414891782354721		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.10414891782354721 | validation: 0.10838559389874941]
	TIME [epoch: 11.2 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12999100799530272		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.12999100799530272 | validation: 0.11942817220720597]
	TIME [epoch: 11.2 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10397472563920444		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.10397472563920444 | validation: 0.0709334125942479]
	TIME [epoch: 11.2 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0979624268520046		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.0979624268520046 | validation: 0.12572814215248357]
	TIME [epoch: 11.2 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1580646226642544		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.1580646226642544 | validation: 0.1599602350486574]
	TIME [epoch: 11.2 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1337026224684354		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.1337026224684354 | validation: 0.11224947802153082]
	TIME [epoch: 11.2 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09731247720699665		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.09731247720699665 | validation: 0.07439427737854369]
	TIME [epoch: 11.2 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12597542212666807		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.12597542212666807 | validation: 0.09615001309279826]
	TIME [epoch: 11.2 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1160753979133595		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.1160753979133595 | validation: 0.1905741555029838]
	TIME [epoch: 11.2 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1307198240878101		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.1307198240878101 | validation: 0.0984042275364197]
	TIME [epoch: 11.2 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09830433951104348		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.09830433951104348 | validation: 0.12871992621005068]
	TIME [epoch: 11.2 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08949611149254721		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.08949611149254721 | validation: 0.10090019605647985]
	TIME [epoch: 11.2 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12480487134398102		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.12480487134398102 | validation: 0.19767536922026457]
	TIME [epoch: 11.2 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11956390665312673		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.11956390665312673 | validation: 0.08155152691756254]
	TIME [epoch: 11.2 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08429004671992313		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.08429004671992313 | validation: 0.07430218726694215]
	TIME [epoch: 11.2 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08436409069412229		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.08436409069412229 | validation: 0.08554399266053156]
	TIME [epoch: 11.2 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08084452855746817		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.08084452855746817 | validation: 0.08080153862073307]
	TIME [epoch: 11.2 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08673844195785294		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.08673844195785294 | validation: 0.09817317016608454]
	TIME [epoch: 11.2 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09789312552569092		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.09789312552569092 | validation: 0.07897604557157004]
	TIME [epoch: 11.2 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08127977342145787		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.08127977342145787 | validation: 0.1486955068186001]
	TIME [epoch: 11.2 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11740672892939455		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.11740672892939455 | validation: 0.09038554991849629]
	TIME [epoch: 11.2 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0723627668729505		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.0723627668729505 | validation: 0.06954372407929575]
	TIME [epoch: 11.2 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09083795408252486		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.09083795408252486 | validation: 0.06956750059796737]
	TIME [epoch: 11.2 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08101693087351484		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.08101693087351484 | validation: 0.07901315579176049]
	TIME [epoch: 11.2 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07207083200631786		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.07207083200631786 | validation: 0.080450920399715]
	TIME [epoch: 11.2 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07789447712714487		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.07789447712714487 | validation: 0.07049117061097931]
	TIME [epoch: 11.2 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07310295442389661		[learning rate: 0.0029399]
	Learning Rate: 0.00293991
	LOSS [training: 0.07310295442389661 | validation: 0.06727582751369672]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0694878816152167		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.0694878816152167 | validation: 0.1181499411923191]
	TIME [epoch: 11.2 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12410796610526713		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.12410796610526713 | validation: 0.06796714794962257]
	TIME [epoch: 11.2 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08535910386980304		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.08535910386980304 | validation: 0.07173510843133174]
	TIME [epoch: 11.2 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07121315873626004		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.07121315873626004 | validation: 0.09173670882516308]
	TIME [epoch: 11.2 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08993943961138165		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.08993943961138165 | validation: 0.2619782911160997]
	TIME [epoch: 11.2 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17342480883068934		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.17342480883068934 | validation: 0.07609913686866762]
	TIME [epoch: 11.2 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08415999748253128		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.08415999748253128 | validation: 0.0653627249026288]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_137.pth
	Model improved!!!
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0879754479700347		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.0879754479700347 | validation: 0.0611325762648632]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_138.pth
	Model improved!!!
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07805399314883375		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.07805399314883375 | validation: 0.06687659833542048]
	TIME [epoch: 11.2 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11863453609065838		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.11863453609065838 | validation: 0.18969099007908696]
	TIME [epoch: 11.2 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10899831243834461		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.10899831243834461 | validation: 0.09537698307918564]
	TIME [epoch: 11.2 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08849440806763831		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.08849440806763831 | validation: 0.11271339040635878]
	TIME [epoch: 11.2 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0781772492589343		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.0781772492589343 | validation: 0.07936996666318016]
	TIME [epoch: 11.2 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08489147662730705		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.08489147662730705 | validation: 0.0843709564497512]
	TIME [epoch: 11.2 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07673412607460234		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.07673412607460234 | validation: 0.05431809881346716]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0697100523834977		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.0697100523834977 | validation: 0.08732454421270404]
	TIME [epoch: 11.2 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0804177012724878		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.0804177012724878 | validation: 0.07418438925333841]
	TIME [epoch: 11.2 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06881672365258662		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.06881672365258662 | validation: 0.06912099180680363]
	TIME [epoch: 11.2 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06775193552996141		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.06775193552996141 | validation: 0.09037326950079896]
	TIME [epoch: 11.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0791822265312691		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.0791822265312691 | validation: 0.059920318422535354]
	TIME [epoch: 11.2 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07424076972583021		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.07424076972583021 | validation: 0.08687400656262248]
	TIME [epoch: 11.2 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07538087943490229		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.07538087943490229 | validation: 0.060910052857124815]
	TIME [epoch: 11.2 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06394205792006015		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.06394205792006015 | validation: 0.07796621099027745]
	TIME [epoch: 11.2 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07665325202802561		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.07665325202802561 | validation: 0.07806648793540594]
	TIME [epoch: 11.2 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07861257496611353		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.07861257496611353 | validation: 0.05817631914422462]
	TIME [epoch: 11.2 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06592198053051715		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.06592198053051715 | validation: 0.04690851366135361]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0881791873580758		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.0881791873580758 | validation: 0.0636120982912766]
	TIME [epoch: 11.2 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06639097625177601		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.06639097625177601 | validation: 0.06098570489824868]
	TIME [epoch: 11.2 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06562830520103093		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.06562830520103093 | validation: 0.06807341456406074]
	TIME [epoch: 11.2 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06600582027712038		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.06600582027712038 | validation: 0.04746365865457662]
	TIME [epoch: 11.2 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.058807339888015314		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.058807339888015314 | validation: 0.05525846998995576]
	TIME [epoch: 11.2 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0604678247138099		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.0604678247138099 | validation: 0.09587114565334369]
	TIME [epoch: 11.2 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0663951344917768		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.0663951344917768 | validation: 0.052661912418933435]
	TIME [epoch: 11.2 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06089438046292498		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.06089438046292498 | validation: 0.06142287114613143]
	TIME [epoch: 11.2 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05811471088209133		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.05811471088209133 | validation: 0.04157843998838172]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_165.pth
	Model improved!!!
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057709196922629574		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.057709196922629574 | validation: 0.050364487566589816]
	TIME [epoch: 11.2 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06375453644591778		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.06375453644591778 | validation: 0.052367067117636446]
	TIME [epoch: 11.2 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0684356734331734		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.0684356734331734 | validation: 0.05269868861423911]
	TIME [epoch: 11.2 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0670869446665466		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.0670869446665466 | validation: 0.08134432229336849]
	TIME [epoch: 11.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07698971696171442		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.07698971696171442 | validation: 0.11265603134967733]
	TIME [epoch: 11.2 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0740048928704641		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.0740048928704641 | validation: 0.05623799318450674]
	TIME [epoch: 11.2 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04795361908816657		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.04795361908816657 | validation: 0.05906344844810112]
	TIME [epoch: 11.2 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06229505872264761		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.06229505872264761 | validation: 0.054913616641957125]
	TIME [epoch: 11.2 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06091200639986163		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.06091200639986163 | validation: 0.04965610538132752]
	TIME [epoch: 11.2 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06401354791410765		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.06401354791410765 | validation: 0.08180235253313331]
	TIME [epoch: 11.2 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06765585605884242		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.06765585605884242 | validation: 0.08444047696169638]
	TIME [epoch: 11.2 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07230563564938623		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.07230563564938623 | validation: 0.04595448221660217]
	TIME [epoch: 11.2 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060904735945407865		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.060904735945407865 | validation: 0.08771216040991461]
	TIME [epoch: 11.2 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05994528272208664		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.05994528272208664 | validation: 0.05131629229070228]
	TIME [epoch: 11.2 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057159211395059153		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.057159211395059153 | validation: 0.06669282497789476]
	TIME [epoch: 11.2 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0543738685800026		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.0543738685800026 | validation: 0.05683004034312231]
	TIME [epoch: 11.2 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05897595986035303		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.05897595986035303 | validation: 0.05137124780075919]
	TIME [epoch: 11.2 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06333061317549374		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.06333061317549374 | validation: 0.06368357716345943]
	TIME [epoch: 11.2 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05925506894092665		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.05925506894092665 | validation: 0.05243768805478508]
	TIME [epoch: 11.2 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05699053397481684		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.05699053397481684 | validation: 0.06002395538722076]
	TIME [epoch: 11.2 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05451287366407251		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.05451287366407251 | validation: 0.051998571487079225]
	TIME [epoch: 11.2 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04976394896923593		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.04976394896923593 | validation: 0.05258678149118472]
	TIME [epoch: 11.2 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0435597124085779		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.0435597124085779 | validation: 0.08604864167292911]
	TIME [epoch: 11.2 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06813519540552714		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.06813519540552714 | validation: 0.04324194603804672]
	TIME [epoch: 11.2 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06545831740205114		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.06545831740205114 | validation: 0.04979046520893983]
	TIME [epoch: 11.2 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04360864374596789		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.04360864374596789 | validation: 0.04469671577431329]
	TIME [epoch: 11.2 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0442327648421258		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.0442327648421258 | validation: 0.06735552704899225]
	TIME [epoch: 11.2 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05507257762557522		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.05507257762557522 | validation: 0.042454857796829615]
	TIME [epoch: 11.2 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05211739885984245		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.05211739885984245 | validation: 0.04568391608902697]
	TIME [epoch: 11.2 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04190656448314119		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.04190656448314119 | validation: 0.04295975806973597]
	TIME [epoch: 11.2 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.049650305097321344		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.049650305097321344 | validation: 0.0617214689500626]
	TIME [epoch: 11.2 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.048350579247001334		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.048350579247001334 | validation: 0.051135130776017945]
	TIME [epoch: 11.2 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.053660722344643336		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.053660722344643336 | validation: 0.055250395889287186]
	TIME [epoch: 11.2 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0453415264500021		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.0453415264500021 | validation: 0.03870673675131574]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_199.pth
	Model improved!!!
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041037014561451216		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.041037014561451216 | validation: 0.04609296117907512]
	TIME [epoch: 11.2 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.040424389486140244		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.040424389486140244 | validation: 0.03854366816425793]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_201.pth
	Model improved!!!
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.042043156611008436		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.042043156611008436 | validation: 0.036493650711120096]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_202.pth
	Model improved!!!
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03879053889562307		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.03879053889562307 | validation: 0.03275621272242396]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_203.pth
	Model improved!!!
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041322357190669005		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.041322357190669005 | validation: 0.043399547834033075]
	TIME [epoch: 11.2 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.039572742539578674		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.039572742539578674 | validation: 0.03857235591198563]
	TIME [epoch: 11.2 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03932738783039031		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.03932738783039031 | validation: 0.039821350040337995]
	TIME [epoch: 11.2 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041568897917805624		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.041568897917805624 | validation: 0.04252745818441661]
	TIME [epoch: 11.2 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04255507626908675		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.04255507626908675 | validation: 0.04757033583523818]
	TIME [epoch: 11.2 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.036850593465567266		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.036850593465567266 | validation: 0.05352037348959619]
	TIME [epoch: 11.2 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07425636008710026		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.07425636008710026 | validation: 0.0496094403737965]
	TIME [epoch: 11.2 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04256649877003528		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.04256649877003528 | validation: 0.0344739551765168]
	TIME [epoch: 11.2 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.045257607613055674		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.045257607613055674 | validation: 0.03306547276335797]
	TIME [epoch: 11.2 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03688741921082079		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.03688741921082079 | validation: 0.04610437430185754]
	TIME [epoch: 11.2 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041096969543978054		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.041096969543978054 | validation: 0.04320297825193374]
	TIME [epoch: 11.2 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03638986641953598		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.03638986641953598 | validation: 0.05701115652681272]
	TIME [epoch: 11.2 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04459806087919827		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.04459806087919827 | validation: 0.030238875237094877]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_216.pth
	Model improved!!!
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04162071476203465		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.04162071476203465 | validation: 0.029305750853027748]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_217.pth
	Model improved!!!
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03744560643948655		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.03744560643948655 | validation: 0.042585760442817554]
	TIME [epoch: 11.2 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04042163333747287		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.04042163333747287 | validation: 0.04123575653226221]
	TIME [epoch: 11.2 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03620754722851547		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.03620754722851547 | validation: 0.04003185215249742]
	TIME [epoch: 11.2 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03960812502429956		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.03960812502429956 | validation: 0.037142849685588356]
	TIME [epoch: 11.2 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03560613435396523		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.03560613435396523 | validation: 0.03601736413443371]
	TIME [epoch: 11.2 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03953272041708171		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.03953272041708171 | validation: 0.048318552726199095]
	TIME [epoch: 11.2 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0458617503702986		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.0458617503702986 | validation: 0.0371673736243626]
	TIME [epoch: 11.2 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03629497969758674		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.03629497969758674 | validation: 0.04949107764232889]
	TIME [epoch: 11.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03716775499225497		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.03716775499225497 | validation: 0.03777519547493079]
	TIME [epoch: 11.2 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03320134460733893		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.03320134460733893 | validation: 0.03686397233341725]
	TIME [epoch: 11.2 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.047438750505254194		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.047438750505254194 | validation: 0.038869263490187704]
	TIME [epoch: 11.2 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03931529854143897		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.03931529854143897 | validation: 0.056331782447649914]
	TIME [epoch: 11.2 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03737741880487601		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.03737741880487601 | validation: 0.025416011195241395]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_230.pth
	Model improved!!!
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03573196337826766		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.03573196337826766 | validation: 0.030110615787488616]
	TIME [epoch: 11.2 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03539200078010811		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.03539200078010811 | validation: 0.03335898621434232]
	TIME [epoch: 11.2 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.034667223348585		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.034667223348585 | validation: 0.02936819944239921]
	TIME [epoch: 11.2 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035892518577237686		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.035892518577237686 | validation: 0.03576023218230666]
	TIME [epoch: 11.2 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030094515099253604		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.030094515099253604 | validation: 0.03473130777657578]
	TIME [epoch: 11.2 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03331670062946779		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.03331670062946779 | validation: 0.031738092368039574]
	TIME [epoch: 11.2 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030494792915053193		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.030494792915053193 | validation: 0.034529304079556275]
	TIME [epoch: 11.2 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031974858146497934		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.031974858146497934 | validation: 0.03069708991453012]
	TIME [epoch: 11.2 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03542260059103873		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.03542260059103873 | validation: 0.0389373318395292]
	TIME [epoch: 11.2 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03794091201156406		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.03794091201156406 | validation: 0.0400753433579067]
	TIME [epoch: 11.2 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03191192844521478		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.03191192844521478 | validation: 0.039530195621778424]
	TIME [epoch: 11.2 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03584925284201056		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.03584925284201056 | validation: 0.0356231541358404]
	TIME [epoch: 11.2 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02889623620287918		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.02889623620287918 | validation: 0.027786773619732537]
	TIME [epoch: 11.2 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.034516008411152335		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.034516008411152335 | validation: 0.043132301535969066]
	TIME [epoch: 11.2 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03306027225551603		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.03306027225551603 | validation: 0.03924124895168157]
	TIME [epoch: 11.2 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03956264747363967		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.03956264747363967 | validation: 0.030480608087692318]
	TIME [epoch: 11.2 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03454964874603608		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.03454964874603608 | validation: 0.04196326541860193]
	TIME [epoch: 11.2 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03421915284872165		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.03421915284872165 | validation: 0.04062727177933823]
	TIME [epoch: 11.2 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0335782518340409		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.0335782518340409 | validation: 0.047290172259157395]
	TIME [epoch: 11.2 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.045600485295423446		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.045600485295423446 | validation: 0.03920433929661188]
	TIME [epoch: 11.2 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.033986141305946606		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.033986141305946606 | validation: 0.03156665622709272]
	TIME [epoch: 446 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02848250699680303		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.02848250699680303 | validation: 0.02813266949451952]
	TIME [epoch: 25 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03270081655750984		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.03270081655750984 | validation: 0.042600635122215506]
	TIME [epoch: 24.9 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03173560094727947		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.03173560094727947 | validation: 0.036637189944214096]
	TIME [epoch: 24.9 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03019598597773437		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.03019598597773437 | validation: 0.027436224064077065]
	TIME [epoch: 24.9 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03058534417260851		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.03058534417260851 | validation: 0.029002286945759508]
	TIME [epoch: 24.9 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030100348687671283		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.030100348687671283 | validation: 0.033047659882073324]
	TIME [epoch: 24.9 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.033083140887603064		[learning rate: 0.0004121]
	Learning Rate: 0.000412097
	LOSS [training: 0.033083140887603064 | validation: 0.03218667105956885]
	TIME [epoch: 24.9 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03393640133206327		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.03393640133206327 | validation: 0.03190979769936473]
	TIME [epoch: 24.9 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030415777669589326		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.030415777669589326 | validation: 0.0377608629189445]
	TIME [epoch: 24.9 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027744448575645224		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.027744448575645224 | validation: 0.031437319206306324]
	TIME [epoch: 24.9 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026879001254131424		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.026879001254131424 | validation: 0.03462234376820006]
	TIME [epoch: 24.9 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027602429693431626		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.027602429693431626 | validation: 0.03146848932274735]
	TIME [epoch: 24.9 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024980346875928292		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.024980346875928292 | validation: 0.03583162837701982]
	TIME [epoch: 24.9 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02870711005226905		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: 0.02870711005226905 | validation: 0.03462298934893125]
	TIME [epoch: 24.9 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030627319293848276		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: 0.030627319293848276 | validation: 0.026314343545632918]
	TIME [epoch: 24.9 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027596774208096336		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.027596774208096336 | validation: 0.033554704200119786]
	TIME [epoch: 24.9 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026508830221176848		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.026508830221176848 | validation: 0.02962686277931783]
	TIME [epoch: 24.9 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0303173643431709		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: 0.0303173643431709 | validation: 0.03805769905757923]
	TIME [epoch: 24.9 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027303557424971245		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.027303557424971245 | validation: 0.028665861282034598]
	TIME [epoch: 24.9 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03430113475694198		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: 0.03430113475694198 | validation: 0.03056467984628633]
	TIME [epoch: 24.9 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: 0.041201353889231816		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: 0.041201353889231816 | validation: 0.023815056228704758]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_272.pth
	Model improved!!!
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030149937634353047		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: 0.030149937634353047 | validation: 0.03744571118962366]
	TIME [epoch: 24.9 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027706200595169206		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.027706200595169206 | validation: 0.027474310326263032]
	TIME [epoch: 24.9 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02951692255350651		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: 0.02951692255350651 | validation: 0.03499862233030811]
	TIME [epoch: 24.9 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04218370917559775		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: 0.04218370917559775 | validation: 0.047235123444618984]
	TIME [epoch: 24.9 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03728454348883466		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: 0.03728454348883466 | validation: 0.03461274389677307]
	TIME [epoch: 24.9 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027355641303720833		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: 0.027355641303720833 | validation: 0.032136235722228915]
	TIME [epoch: 24.9 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0306437724683868		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: 0.0306437724683868 | validation: 0.023896833310620272]
	TIME [epoch: 24.9 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02797895973399541		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: 0.02797895973399541 | validation: 0.03089130513407857]
	TIME [epoch: 24.9 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030927865091384555		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: 0.030927865091384555 | validation: 0.038369894897328186]
	TIME [epoch: 24.9 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030430582577088076		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: 0.030430582577088076 | validation: 0.021242058543634715]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_282.pth
	Model improved!!!
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027372986958109767		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: 0.027372986958109767 | validation: 0.024828883162329125]
	TIME [epoch: 24.9 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027797893854158928		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: 0.027797893854158928 | validation: 0.03352420162575602]
	TIME [epoch: 24.9 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027692119527931484		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.027692119527931484 | validation: 0.03386187344036559]
	TIME [epoch: 24.9 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02794453702303633		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: 0.02794453702303633 | validation: 0.0394268610744612]
	TIME [epoch: 24.9 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02468818962732565		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: 0.02468818962732565 | validation: 0.03638093120654907]
	TIME [epoch: 24.8 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027388165266888802		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: 0.027388165266888802 | validation: 0.02894145825410868]
	TIME [epoch: 24.8 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029506173664287063		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: 0.029506173664287063 | validation: 0.032616290245970486]
	TIME [epoch: 24.8 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02785023423030127		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: 0.02785023423030127 | validation: 0.04240279134462397]
	TIME [epoch: 24.8 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0256534277805342		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: 0.0256534277805342 | validation: 0.042195682436567336]
	TIME [epoch: 24.8 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02605825232408845		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: 0.02605825232408845 | validation: 0.037562699076088904]
	TIME [epoch: 24.8 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031695874827105744		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: 0.031695874827105744 | validation: 0.026749381895290907]
	TIME [epoch: 24.8 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030666402554402044		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: 0.030666402554402044 | validation: 0.02831039757912042]
	TIME [epoch: 24.9 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028118517462924153		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: 0.028118517462924153 | validation: 0.037116137664826326]
	TIME [epoch: 24.9 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02605221038544716		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: 0.02605221038544716 | validation: 0.022660414075584334]
	TIME [epoch: 24.9 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03115933545399122		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.03115933545399122 | validation: 0.026858665129688895]
	TIME [epoch: 24.9 sec]
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025794648003384386		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: 0.025794648003384386 | validation: 0.03211445609804965]
	TIME [epoch: 24.9 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025255287731298773		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: 0.025255287731298773 | validation: 0.031732754776543345]
	TIME [epoch: 24.9 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02914491712925702		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.02914491712925702 | validation: 0.03993956319148738]
	TIME [epoch: 24.9 sec]
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027484925545991874		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: 0.027484925545991874 | validation: 0.03444320271497926]
	TIME [epoch: 24.9 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025804425910772907		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: 0.025804425910772907 | validation: 0.03299665961999026]
	TIME [epoch: 24.9 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027732230436367463		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: 0.027732230436367463 | validation: 0.02758477973509222]
	TIME [epoch: 24.9 sec]
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02775517686948848		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: 0.02775517686948848 | validation: 0.028481191548987962]
	TIME [epoch: 24.9 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028769798504127954		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: 0.028769798504127954 | validation: 0.02550021022225527]
	TIME [epoch: 24.9 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03547024478802548		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: 0.03547024478802548 | validation: 0.029984020455067914]
	TIME [epoch: 24.9 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028658393564766398		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: 0.028658393564766398 | validation: 0.025826669121162764]
	TIME [epoch: 24.9 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028786647276732313		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: 0.028786647276732313 | validation: 0.026933550094357418]
	TIME [epoch: 24.9 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02899698528220963		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: 0.02899698528220963 | validation: 0.023465258691221437]
	TIME [epoch: 24.9 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03120773985929704		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: 0.03120773985929704 | validation: 0.03301884363812613]
	TIME [epoch: 24.9 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024559305894433447		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: 0.024559305894433447 | validation: 0.03240313041620485]
	TIME [epoch: 24.9 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025689437180605852		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: 0.025689437180605852 | validation: 0.027601980437981413]
	TIME [epoch: 24.9 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025762480090189128		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: 0.025762480090189128 | validation: 0.03555052885572376]
	TIME [epoch: 24.9 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02871177924335069		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: 0.02871177924335069 | validation: 0.04184527074038849]
	TIME [epoch: 24.9 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03079768132779182		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: 0.03079768132779182 | validation: 0.031871904613465216]
	TIME [epoch: 24.9 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029310230091798666		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: 0.029310230091798666 | validation: 0.030142076470232607]
	TIME [epoch: 24.9 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027349126479452285		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: 0.027349126479452285 | validation: 0.02488493944207843]
	TIME [epoch: 24.9 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025640725295851634		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: 0.025640725295851634 | validation: 0.029281582779562096]
	TIME [epoch: 24.9 sec]
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025291289829424697		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: 0.025291289829424697 | validation: 0.030303988935496164]
	TIME [epoch: 24.9 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021757002949284295		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: 0.021757002949284295 | validation: 0.03266108329096608]
	TIME [epoch: 24.9 sec]
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024976023972126855		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: 0.024976023972126855 | validation: 0.03391170956749574]
	TIME [epoch: 24.9 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029116481494033376		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: 0.029116481494033376 | validation: 0.02959077249692465]
	TIME [epoch: 24.9 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02948985068452504		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: 0.02948985068452504 | validation: 0.029272263654397643]
	TIME [epoch: 24.9 sec]
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027142652488045458		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.027142652488045458 | validation: 0.034571021204995736]
	TIME [epoch: 24.9 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026437202126014435		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: 0.026437202126014435 | validation: 0.03354051285494257]
	TIME [epoch: 24.9 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024265086519592756		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: 0.024265086519592756 | validation: 0.03121383149407947]
	TIME [epoch: 24.9 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027788994526266098		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: 0.027788994526266098 | validation: 0.03832539908474474]
	TIME [epoch: 24.9 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026104193822043254		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: 0.026104193822043254 | validation: 0.031283571581575166]
	TIME [epoch: 24.9 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026070255522173715		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: 0.026070255522173715 | validation: 0.031319085487855114]
	TIME [epoch: 24.9 sec]
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024878229866205588		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: 0.024878229866205588 | validation: 0.029532596347086874]
	TIME [epoch: 24.9 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02458433725466343		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: 0.02458433725466343 | validation: 0.03284307825255249]
	TIME [epoch: 24.9 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026099233256302104		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: 0.026099233256302104 | validation: 0.03995379630342398]
	TIME [epoch: 24.8 sec]
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025316034080429844		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: 0.025316034080429844 | validation: 0.0401256068178476]
	TIME [epoch: 24.9 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02370378349922272		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: 0.02370378349922272 | validation: 0.03687830996326303]
	TIME [epoch: 24.9 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027730310440672097		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: 0.027730310440672097 | validation: 0.031278410549190526]
	TIME [epoch: 24.9 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029169890587684155		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: 0.029169890587684155 | validation: 0.03249475555073803]
	TIME [epoch: 24.9 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03105984709537088		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: 0.03105984709537088 | validation: 0.0266668668589186]
	TIME [epoch: 24.9 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026342434159622022		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: 0.026342434159622022 | validation: 0.03202726739417004]
	TIME [epoch: 24.9 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029702735774824317		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: 0.029702735774824317 | validation: 0.03482418398967538]
	TIME [epoch: 24.9 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030444788158359763		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: 0.030444788158359763 | validation: 0.03175989264885411]
	TIME [epoch: 24.9 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02591520176933943		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: 0.02591520176933943 | validation: 0.02743512394440373]
	TIME [epoch: 24.9 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022905591532325346		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: 0.022905591532325346 | validation: 0.03241857447650085]
	TIME [epoch: 24.9 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02651178438374788		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: 0.02651178438374788 | validation: 0.03121841591634006]
	TIME [epoch: 24.9 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027163767169206904		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: 0.027163767169206904 | validation: 0.02539362943648591]
	TIME [epoch: 24.9 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027903691788178055		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: 0.027903691788178055 | validation: 0.02582318639731891]
	TIME [epoch: 24.9 sec]
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03044625058609363		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: 0.03044625058609363 | validation: 0.04503368965242299]
	TIME [epoch: 24.9 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023988745765671705		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: 0.023988745765671705 | validation: 0.02247907543805162]
	TIME [epoch: 24.9 sec]
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02643616915952831		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: 0.02643616915952831 | validation: 0.026076287641986207]
	TIME [epoch: 24.9 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029962844975704422		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: 0.029962844975704422 | validation: 0.03179005825538517]
	TIME [epoch: 24.9 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027605537955826764		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: 0.027605537955826764 | validation: 0.0274894279319179]
	TIME [epoch: 24.9 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029216205637821416		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.029216205637821416 | validation: 0.02758225831847072]
	TIME [epoch: 24.9 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02987586995568218		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: 0.02987586995568218 | validation: 0.02599192341902767]
	TIME [epoch: 24.9 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028582298759581064		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: 0.028582298759581064 | validation: 0.027609416760790324]
	TIME [epoch: 24.9 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027389040238611512		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: 0.027389040238611512 | validation: 0.029718576911296875]
	TIME [epoch: 24.9 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026477464234958642		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: 0.026477464234958642 | validation: 0.025967243305372922]
	TIME [epoch: 24.9 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023368194835519718		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: 0.023368194835519718 | validation: 0.035529114920048]
	TIME [epoch: 24.9 sec]
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023497473171251098		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: 0.023497473171251098 | validation: 0.02929700996143611]
	TIME [epoch: 24.9 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025700978858668004		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: 0.025700978858668004 | validation: 0.017101174355216506]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_358.pth
	Model improved!!!
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02438471991901651		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: 0.02438471991901651 | validation: 0.03194206819815301]
	TIME [epoch: 24.9 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02589028848271365		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: 0.02589028848271365 | validation: 0.030503545141682492]
	TIME [epoch: 24.9 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027405303896657438		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: 0.027405303896657438 | validation: 0.025954018651613404]
	TIME [epoch: 24.9 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026257597779778607		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: 0.026257597779778607 | validation: 0.03181192237452314]
	TIME [epoch: 24.9 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026441022203697068		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: 0.026441022203697068 | validation: 0.03203919906817297]
	TIME [epoch: 24.9 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0218897047555549		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: 0.0218897047555549 | validation: 0.028606884692563624]
	TIME [epoch: 24.9 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0224348144835646		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: 0.0224348144835646 | validation: 0.032186930126305205]
	TIME [epoch: 24.9 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026170722940563176		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: 0.026170722940563176 | validation: 0.031016856059772935]
	TIME [epoch: 24.9 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022562181526486744		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: 0.022562181526486744 | validation: 0.02808207054636139]
	TIME [epoch: 24.9 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028049011886468328		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: 0.028049011886468328 | validation: 0.026337664074751563]
	TIME [epoch: 24.9 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02990670470240097		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: 0.02990670470240097 | validation: 0.02587910996706177]
	TIME [epoch: 24.9 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020373205619120448		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: 0.020373205619120448 | validation: 0.03529749982684825]
	TIME [epoch: 24.9 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025179245074772438		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: 0.025179245074772438 | validation: 0.02624909450821744]
	TIME [epoch: 24.9 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026908830320412948		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: 0.026908830320412948 | validation: 0.02636879454025543]
	TIME [epoch: 24.9 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024004595484397498		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: 0.024004595484397498 | validation: 0.03903986884844687]
	TIME [epoch: 24.9 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023001409793544224		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: 0.023001409793544224 | validation: 0.026281547727728637]
	TIME [epoch: 24.9 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021427760803696808		[learning rate: 6.8391e-05]
	Learning Rate: 6.83911e-05
	LOSS [training: 0.021427760803696808 | validation: 0.02332341395834486]
	TIME [epoch: 24.9 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026237203978442227		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: 0.026237203978442227 | validation: 0.030244255416708228]
	TIME [epoch: 24.9 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02183265799185409		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: 0.02183265799185409 | validation: 0.02273333341694326]
	TIME [epoch: 24.9 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026891618071645643		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: 0.026891618071645643 | validation: 0.03173421220023892]
	TIME [epoch: 24.9 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023454540262545343		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: 0.023454540262545343 | validation: 0.03386847396394736]
	TIME [epoch: 24.9 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028773263338508187		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: 0.028773263338508187 | validation: 0.03445962998086526]
	TIME [epoch: 24.9 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026087325171018427		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: 0.026087325171018427 | validation: 0.03223928809274774]
	TIME [epoch: 24.9 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024526761290558793		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: 0.024526761290558793 | validation: 0.028520428238959283]
	TIME [epoch: 24.9 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026291738442381193		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: 0.026291738442381193 | validation: 0.029171178328360386]
	TIME [epoch: 24.9 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022157715505668314		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: 0.022157715505668314 | validation: 0.028427879380839023]
	TIME [epoch: 24.9 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027823224804176247		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: 0.027823224804176247 | validation: 0.02455510923936443]
	TIME [epoch: 24.9 sec]
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02608432766396781		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: 0.02608432766396781 | validation: 0.03521178863271007]
	TIME [epoch: 24.9 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022412987756534747		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: 0.022412987756534747 | validation: 0.026890979500974008]
	TIME [epoch: 24.9 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02422171069169707		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: 0.02422171069169707 | validation: 0.02929991098223317]
	TIME [epoch: 24.9 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023264908947636786		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: 0.023264908947636786 | validation: 0.017714188479221682]
	TIME [epoch: 24.9 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025897712988870537		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: 0.025897712988870537 | validation: 0.022512757710174004]
	TIME [epoch: 24.9 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026467549499180197		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: 0.026467549499180197 | validation: 0.027048219275713922]
	TIME [epoch: 24.9 sec]
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0263048359031748		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: 0.0263048359031748 | validation: 0.019799422782091975]
	TIME [epoch: 24.9 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025261522222246032		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: 0.025261522222246032 | validation: 0.026867983779803095]
	TIME [epoch: 24.9 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026263358275823566		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: 0.026263358275823566 | validation: 0.018348076489236347]
	TIME [epoch: 24.9 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026191022076743856		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: 0.026191022076743856 | validation: 0.027712312085484258]
	TIME [epoch: 24.9 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025344926798813505		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: 0.025344926798813505 | validation: 0.015224198807861359]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_396.pth
	Model improved!!!
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02837463704073122		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: 0.02837463704073122 | validation: 0.021051729339986867]
	TIME [epoch: 24.9 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023731719661656724		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: 0.023731719661656724 | validation: 0.025309336507227845]
	TIME [epoch: 24.9 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025967085636221816		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: 0.025967085636221816 | validation: 0.02580265025612254]
	TIME [epoch: 24.9 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022378889629922356		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: 0.022378889629922356 | validation: 0.030052427756678678]
	TIME [epoch: 24.9 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02710862466733968		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: 0.02710862466733968 | validation: 0.02782030933289261]
	TIME [epoch: 24.9 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027020162501666584		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: 0.027020162501666584 | validation: 0.03351337667721392]
	TIME [epoch: 24.9 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024986330541886197		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: 0.024986330541886197 | validation: 0.029552155460002213]
	TIME [epoch: 24.9 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025720084377561837		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: 0.025720084377561837 | validation: 0.025372842676163437]
	TIME [epoch: 24.9 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024664756741284544		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: 0.024664756741284544 | validation: 0.010886679387252907]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_klv21_20241205_184311/states/model_algphiq_1a_v_klv21_405.pth
	Model improved!!!
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026592130894523218		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: 0.026592130894523218 | validation: 0.025488694034990975]
	TIME [epoch: 24.9 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0282009565670416		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: 0.0282009565670416 | validation: 0.02667784140942167]
	TIME [epoch: 24.9 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02535538825171986		[learning rate: 4.121e-05]
	Learning Rate: 4.12097e-05
	LOSS [training: 0.02535538825171986 | validation: 0.022725353292998636]
	TIME [epoch: 24.9 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024106251677118187		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: 0.024106251677118187 | validation: 0.03165136699603773]
	TIME [epoch: 24.9 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020208538049124477		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: 0.020208538049124477 | validation: 0.03167501853931633]
	TIME [epoch: 24.9 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022440054304479595		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: 0.022440054304479595 | validation: 0.023758011540233125]
	TIME [epoch: 24.9 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029118467059046665		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: 0.029118467059046665 | validation: 0.019872690413774714]
	TIME [epoch: 24.9 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024553392569827758		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: 0.024553392569827758 | validation: 0.030897686536989676]
	TIME [epoch: 24.9 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022873807962288092		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: 0.022873807962288092 | validation: 0.027466906807240295]
	TIME [epoch: 24.9 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023731586032372458		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: 0.023731586032372458 | validation: 0.03006835419599691]
	TIME [epoch: 24.9 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02245318452829039		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: 0.02245318452829039 | validation: 0.03026122857537826]
	TIME [epoch: 24.9 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02791177100436691		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: 0.02791177100436691 | validation: 0.02380399144693849]
	TIME [epoch: 24.9 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02816188493634484		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: 0.02816188493634484 | validation: 0.028372782040282082]
	TIME [epoch: 24.9 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02630204138943016		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: 0.02630204138943016 | validation: 0.02678660795087557]
	TIME [epoch: 24.9 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019386774915644462		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: 0.019386774915644462 | validation: 0.025680905464864824]
	TIME [epoch: 24.9 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02454276856729819		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: 0.02454276856729819 | validation: 0.03041602152013568]
	TIME [epoch: 24.9 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02817133020338452		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: 0.02817133020338452 | validation: 0.028632901859450707]
	TIME [epoch: 24.8 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026544948931386772		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: 0.026544948931386772 | validation: 0.030586816141022998]
	TIME [epoch: 24.9 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028641477955537602		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: 0.028641477955537602 | validation: 0.02387677558258728]
	TIME [epoch: 24.9 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024712858486854453		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: 0.024712858486854453 | validation: 0.03499286507659477]
	TIME [epoch: 24.9 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02347854507396397		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: 0.02347854507396397 | validation: 0.02694649551043343]
	TIME [epoch: 24.9 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023861525855630488		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: 0.023861525855630488 | validation: 0.02289986340143557]
	TIME [epoch: 24.9 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02489871654684256		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: 0.02489871654684256 | validation: 0.018795378568064538]
	TIME [epoch: 24.9 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022806991696054085		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: 0.022806991696054085 | validation: 0.02803347650893322]
	TIME [epoch: 24.9 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026319715238000297		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: 0.026319715238000297 | validation: 0.02364851704829716]
	TIME [epoch: 24.9 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02616060281943626		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: 0.02616060281943626 | validation: 0.027758822535074522]
	TIME [epoch: 24.9 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023952597857486522		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: 0.023952597857486522 | validation: 0.027902618503268035]
	TIME [epoch: 24.9 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02244844722390275		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: 0.02244844722390275 | validation: 0.025075123166385674]
	TIME [epoch: 24.9 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021986074111653077		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: 0.021986074111653077 | validation: 0.0283837531220551]
	TIME [epoch: 24.9 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02825358847679509		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: 0.02825358847679509 | validation: 0.03819042176560539]
	TIME [epoch: 24.9 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026928689262850494		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: 0.026928689262850494 | validation: 0.032687172342592115]
	TIME [epoch: 24.9 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027506517471721913		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: 0.027506517471721913 | validation: 0.03390326355837725]
	TIME [epoch: 24.9 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02505000031386588		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: 0.02505000031386588 | validation: 0.017357497246973344]
	TIME [epoch: 24.9 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02343792558457176		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: 0.02343792558457176 | validation: 0.01989644658160932]
	TIME [epoch: 24.9 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024907289160210073		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: 0.024907289160210073 | validation: 0.024590159366591147]
	TIME [epoch: 24.9 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022898266351865357		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: 0.022898266351865357 | validation: 0.025050756783137167]
	TIME [epoch: 24.9 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022296923267849177		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: 0.022296923267849177 | validation: 0.026959229957223392]
	TIME [epoch: 24.9 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0239045824444383		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: 0.0239045824444383 | validation: 0.024366236788118157]
	TIME [epoch: 24.9 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02413783579177623		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: 0.02413783579177623 | validation: 0.02460870628044326]
	TIME [epoch: 24.9 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025426283164517154		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: 0.025426283164517154 | validation: 0.03690398903296082]
	TIME [epoch: 24.9 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024612809712515442		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: 0.024612809712515442 | validation: 0.032396435329781564]
	TIME [epoch: 24.9 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026746580652307048		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: 0.026746580652307048 | validation: 0.026535141929907434]
	TIME [epoch: 24.9 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019971944503946685		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: 0.019971944503946685 | validation: 0.03404189227668836]
	TIME [epoch: 24.9 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023046492322057327		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: 0.023046492322057327 | validation: 0.022656437805637072]
	TIME [epoch: 24.9 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025033488406418385		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: 0.025033488406418385 | validation: 0.02805788351533232]
	TIME [epoch: 24.9 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021169180301565046		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: 0.021169180301565046 | validation: 0.022036540113968515]
	TIME [epoch: 24.9 sec]
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026020924255398294		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: 0.026020924255398294 | validation: 0.027689332118498448]
	TIME [epoch: 24.9 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020019321589156314		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: 0.020019321589156314 | validation: 0.02529322082228022]
	TIME [epoch: 24.9 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023425582063390245		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: 0.023425582063390245 | validation: 0.02495144857006385]
	TIME [epoch: 24.9 sec]
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02342004935142391		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: 0.02342004935142391 | validation: 0.029169796898878275]
	TIME [epoch: 24.9 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024520844093670523		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: 0.024520844093670523 | validation: 0.026247852983835796]
	TIME [epoch: 24.9 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02125841623609035		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: 0.02125841623609035 | validation: 0.03375923568737019]
	TIME [epoch: 24.9 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02489361826498534		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: 0.02489361826498534 | validation: 0.018855149286067137]
	TIME [epoch: 24.9 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026230983494229903		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: 0.026230983494229903 | validation: 0.02432672992702897]
	TIME [epoch: 24.9 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02663674295307321		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: 0.02663674295307321 | validation: 0.02999749210545398]
	TIME [epoch: 24.9 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022863429366423042		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: 0.022863429366423042 | validation: 0.02695337959353465]
	TIME [epoch: 24.9 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023352511609858993		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: 0.023352511609858993 | validation: 0.0262245166732784]
	TIME [epoch: 24.9 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02451565563070284		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: 0.02451565563070284 | validation: 0.019302332683545843]
	TIME [epoch: 24.9 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024824575842638242		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: 0.024824575842638242 | validation: 0.03219933501194526]
	TIME [epoch: 24.9 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02411776530226522		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: 0.02411776530226522 | validation: 0.02278740433065544]
	TIME [epoch: 24.9 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02637226041226826		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: 0.02637226041226826 | validation: 0.028268159250766013]
	TIME [epoch: 24.9 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02749437985266165		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: 0.02749437985266165 | validation: 0.02798289090766449]
	TIME [epoch: 24.9 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023868599186666978		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: 0.023868599186666978 | validation: 0.017455255758545715]
	TIME [epoch: 24.9 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027953341416622483		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: 0.027953341416622483 | validation: 0.03624394152813834]
	TIME [epoch: 24.9 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025995034809063802		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: 0.025995034809063802 | validation: 0.03531377656945425]
	TIME [epoch: 24.9 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02451207582914043		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: 0.02451207582914043 | validation: 0.03667902678003966]
	TIME [epoch: 24.9 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019081379178583307		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: 0.019081379178583307 | validation: 0.02704885434640454]
	TIME [epoch: 24.9 sec]
EPOCH 473/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02311225445464969		[learning rate: 1.5194e-05]
	Learning Rate: 1.51938e-05
	LOSS [training: 0.02311225445464969 | validation: 0.018387981577018805]
	TIME [epoch: 24.9 sec]
EPOCH 474/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027032296318883438		[learning rate: 1.4962e-05]
	Learning Rate: 1.49624e-05
	LOSS [training: 0.027032296318883438 | validation: 0.030663960041700796]
	TIME [epoch: 24.9 sec]
EPOCH 475/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02511628617559358		[learning rate: 1.4734e-05]
	Learning Rate: 1.47344e-05
	LOSS [training: 0.02511628617559358 | validation: 0.03302804603661986]
	TIME [epoch: 24.9 sec]
EPOCH 476/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028446973691878753		[learning rate: 1.451e-05]
	Learning Rate: 1.451e-05
	LOSS [training: 0.028446973691878753 | validation: 0.031063744743669006]
	TIME [epoch: 24.9 sec]
EPOCH 477/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02295377004580741		[learning rate: 1.4289e-05]
	Learning Rate: 1.42889e-05
	LOSS [training: 0.02295377004580741 | validation: 0.029263463093157284]
	TIME [epoch: 24.9 sec]
EPOCH 478/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022773422893972883		[learning rate: 1.4071e-05]
	Learning Rate: 1.40713e-05
	LOSS [training: 0.022773422893972883 | validation: 0.021386022271117452]
	TIME [epoch: 24.9 sec]
EPOCH 479/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025857322458060474		[learning rate: 1.3857e-05]
	Learning Rate: 1.38569e-05
	LOSS [training: 0.025857322458060474 | validation: 0.012705338842089606]
	TIME [epoch: 24.9 sec]
EPOCH 480/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02402139384041122		[learning rate: 1.3646e-05]
	Learning Rate: 1.36458e-05
	LOSS [training: 0.02402139384041122 | validation: 0.02765115839302653]
	TIME [epoch: 24.9 sec]
EPOCH 481/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023373779207502103		[learning rate: 1.3438e-05]
	Learning Rate: 1.3438e-05
	LOSS [training: 0.023373779207502103 | validation: 0.02810569997621136]
	TIME [epoch: 24.9 sec]
EPOCH 482/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026508253963662815		[learning rate: 1.3233e-05]
	Learning Rate: 1.32333e-05
	LOSS [training: 0.026508253963662815 | validation: 0.02595559817032827]
	TIME [epoch: 24.9 sec]
EPOCH 483/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02678830839705063		[learning rate: 1.3032e-05]
	Learning Rate: 1.30317e-05
	LOSS [training: 0.02678830839705063 | validation: 0.02793618076807301]
	TIME [epoch: 24.9 sec]
EPOCH 484/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024159829359039597		[learning rate: 1.2833e-05]
	Learning Rate: 1.28332e-05
	LOSS [training: 0.024159829359039597 | validation: 0.020536373170665347]
	TIME [epoch: 24.9 sec]
EPOCH 485/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02738812852113902		[learning rate: 1.2638e-05]
	Learning Rate: 1.26377e-05
	LOSS [training: 0.02738812852113902 | validation: 0.025178354975937456]
	TIME [epoch: 24.9 sec]
EPOCH 486/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02171466632317544		[learning rate: 1.2445e-05]
	Learning Rate: 1.24451e-05
	LOSS [training: 0.02171466632317544 | validation: 0.02750450032340892]
	TIME [epoch: 24.9 sec]
EPOCH 487/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02430394320836151		[learning rate: 1.2256e-05]
	Learning Rate: 1.22556e-05
	LOSS [training: 0.02430394320836151 | validation: 0.02278103296025613]
	TIME [epoch: 24.9 sec]
EPOCH 488/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02579520259217485		[learning rate: 1.2069e-05]
	Learning Rate: 1.20689e-05
	LOSS [training: 0.02579520259217485 | validation: 0.02420342538106216]
	TIME [epoch: 24.9 sec]
EPOCH 489/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026172235447392632		[learning rate: 1.1885e-05]
	Learning Rate: 1.1885e-05
	LOSS [training: 0.026172235447392632 | validation: 0.025311240910297173]
	TIME [epoch: 24.9 sec]
EPOCH 490/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022031811869143762		[learning rate: 1.1704e-05]
	Learning Rate: 1.1704e-05
	LOSS [training: 0.022031811869143762 | validation: 0.033694679468583254]
	TIME [epoch: 24.9 sec]
EPOCH 491/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026141030138042514		[learning rate: 1.1526e-05]
	Learning Rate: 1.15257e-05
	LOSS [training: 0.026141030138042514 | validation: 0.038013445853878]
	TIME [epoch: 24.9 sec]
EPOCH 492/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02261251644178878		[learning rate: 1.135e-05]
	Learning Rate: 1.13501e-05
	LOSS [training: 0.02261251644178878 | validation: 0.019645130018226223]
	TIME [epoch: 24.9 sec]
EPOCH 493/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023386097307970345		[learning rate: 1.1177e-05]
	Learning Rate: 1.11772e-05
	LOSS [training: 0.023386097307970345 | validation: 0.0243785447854621]
	TIME [epoch: 24.9 sec]
EPOCH 494/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023026184476179518		[learning rate: 1.1007e-05]
	Learning Rate: 1.10069e-05
	LOSS [training: 0.023026184476179518 | validation: 0.022951881381426918]
	TIME [epoch: 24.9 sec]
EPOCH 495/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02215650998190772		[learning rate: 1.0839e-05]
	Learning Rate: 1.08393e-05
	LOSS [training: 0.02215650998190772 | validation: 0.031162083219410795]
	TIME [epoch: 24.9 sec]
EPOCH 496/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022626375747691684		[learning rate: 1.0674e-05]
	Learning Rate: 1.06741e-05
	LOSS [training: 0.022626375747691684 | validation: 0.02500811644469623]
	TIME [epoch: 24.9 sec]
EPOCH 497/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025376015113478416		[learning rate: 1.0512e-05]
	Learning Rate: 1.05115e-05
	LOSS [training: 0.025376015113478416 | validation: 0.02175255965953244]
	TIME [epoch: 24.9 sec]
EPOCH 498/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025788665253031914		[learning rate: 1.0351e-05]
	Learning Rate: 1.03514e-05
	LOSS [training: 0.025788665253031914 | validation: 0.02886211106386607]
	TIME [epoch: 24.9 sec]
EPOCH 499/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02166945361471531		[learning rate: 1.0194e-05]
	Learning Rate: 1.01937e-05
	LOSS [training: 0.02166945361471531 | validation: 0.03558561916014946]
	TIME [epoch: 24.9 sec]
EPOCH 500/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020757545477428967		[learning rate: 1.0038e-05]
	Learning Rate: 1.00384e-05
	LOSS [training: 0.020757545477428967 | validation: 0.022609390026114534]
	TIME [epoch: 24.9 sec]
Finished training in 9968.107 seconds.
