Args:
Namespace(name='model_algphiq_1a_v_kl1', outdir='out/model_training/model_algphiq_1a_v_kl1', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1027655082

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 8.802127743545132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.802127743545132 | validation: 8.886158048959945]
	TIME [epoch: 401 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 8.711295987163151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.711295987163151 | validation: 8.790455774489015]
	TIME [epoch: 2.65 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 8.606931485751712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.606931485751712 | validation: 8.663561394531401]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 8.453643471247505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.453643471247505 | validation: 8.455641514558216]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 8.223034520989282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.223034520989282 | validation: 8.347508441218654]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 8.157814400797339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.157814400797339 | validation: 8.311605299655312]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 8.114522583412828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.114522583412828 | validation: 8.267799265399491]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 8.069617702809266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.069617702809266 | validation: 8.215611200427428]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 8.015586233024987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.015586233024987 | validation: 8.163383628093332]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 7.936013179891144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.936013179891144 | validation: 8.065316113719096]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 7.832341775945411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.832341775945411 | validation: 7.939817173372296]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 7.655029869812286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.655029869812286 | validation: 7.685854808582824]
	TIME [epoch: 2.59 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 7.344147668912909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.344147668912909 | validation: 7.177449859817375]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 6.7426334227646425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7426334227646425 | validation: 6.070539489902519]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 4.8876408345910205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8876408345910205 | validation: 0.7157827624191786]
	TIME [epoch: 2.56 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 1.38074631089312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.38074631089312 | validation: 0.8606220414602934]
	TIME [epoch: 2.57 sec]
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5168297475579458		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5168297475579458 | validation: 0.786792998303873]
	TIME [epoch: 2.58 sec]
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5681123099722916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5681123099722916 | validation: 0.2083381194063819]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34016942713007225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34016942713007225 | validation: 0.1316924113394889]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.29628180025592626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29628180025592626 | validation: 0.1057320776899628]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11112673764091527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11112673764091527 | validation: 0.050886511497141025]
	TIME [epoch: 2.57 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.2141853479933888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2141853479933888 | validation: 0.04931509710165291]
	TIME [epoch: 2.59 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19335123447084418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19335123447084418 | validation: 0.022646684231321233]
	TIME [epoch: 2.58 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23557009796844003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23557009796844003 | validation: 0.042803395659848205]
	TIME [epoch: 2.57 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18182285740028628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18182285740028628 | validation: 0.048013477229731455]
	TIME [epoch: 2.56 sec]
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17767996555762688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17767996555762688 | validation: 0.03309745334287842]
	TIME [epoch: 2.57 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18434747480914054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18434747480914054 | validation: 0.034619464453367575]
	TIME [epoch: 2.56 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.17472847416100348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17472847416100348 | validation: 0.0235432435710734]
	TIME [epoch: 2.58 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05836790412242427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05836790412242427 | validation: 0.06681795286718578]
	TIME [epoch: 2.57 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054625554091080324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054625554091080324 | validation: 0.07157454680622034]
	TIME [epoch: 2.56 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05546495444948183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05546495444948183 | validation: 0.046008170208438684]
	TIME [epoch: 2.56 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.4340296765378973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4340296765378973 | validation: 0.7276592991228445]
	TIME [epoch: 2.56 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.48387991199294045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48387991199294045 | validation: 0.46337655537072453]
	TIME [epoch: 2.56 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.19082584724598098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19082584724598098 | validation: 0.1304109344051143]
	TIME [epoch: 2.57 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08848914606538066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08848914606538066 | validation: 0.10135499740404881]
	TIME [epoch: 2.57 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06587919983813269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06587919983813269 | validation: 0.053404270312615854]
	TIME [epoch: 2.56 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06828020884808995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06828020884808995 | validation: 0.04192951895035374]
	TIME [epoch: 2.56 sec]
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05242820488092151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05242820488092151 | validation: 0.058229740386332676]
	TIME [epoch: 2.56 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06657512518065467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06657512518065467 | validation: 0.105075313729099]
	TIME [epoch: 2.55 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06602536358326082		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06602536358326082 | validation: 0.05003202707843668]
	TIME [epoch: 2.56 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06682880230114713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06682880230114713 | validation: 0.03145648921101103]
	TIME [epoch: 2.58 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.057921901642538055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057921901642538055 | validation: 0.029398304091083488]
	TIME [epoch: 2.57 sec]
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06308791507844645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06308791507844645 | validation: 0.04183362849858781]
	TIME [epoch: 2.55 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06635095171771764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06635095171771764 | validation: 0.05444878644462109]
	TIME [epoch: 2.56 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06276981034876143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06276981034876143 | validation: 0.0331393240274635]
	TIME [epoch: 2.56 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05451911426600925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05451911426600925 | validation: 0.03996769531647927]
	TIME [epoch: 2.57 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.059476670993974065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059476670993974065 | validation: 0.02880302832941523]
	TIME [epoch: 2.57 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07370187649794435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07370187649794435 | validation: 0.1408834043470127]
	TIME [epoch: 2.57 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08307785285822956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08307785285822956 | validation: 0.0564968703231258]
	TIME [epoch: 2.56 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07042942747772636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07042942747772636 | validation: 0.0767148663285703]
	TIME [epoch: 2.56 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0572755384264123		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.0572755384264123 | validation: 0.07515035708209772]
	TIME [epoch: 417 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05979775748480909		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.05979775748480909 | validation: 0.06926148135215726]
	TIME [epoch: 5.03 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.048931333645833686		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.048931333645833686 | validation: 0.053524591263421364]
	TIME [epoch: 4.98 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03671249806945295		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.03671249806945295 | validation: 0.07586301612456622]
	TIME [epoch: 4.99 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05132045849145446		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.05132045849145446 | validation: 0.07912335754117268]
	TIME [epoch: 4.98 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04412987531711539		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.04412987531711539 | validation: 0.060235255483762476]
	TIME [epoch: 4.97 sec]
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05791942691718031		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.05791942691718031 | validation: 0.044252016551800374]
	TIME [epoch: 4.99 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.037052002117495604		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.037052002117495604 | validation: 0.05130119420768569]
	TIME [epoch: 4.99 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.23363144629654053		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.23363144629654053 | validation: 0.04880444931592928]
	TIME [epoch: 4.98 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.16696154589120493		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.16696154589120493 | validation: 0.05627699247256028]
	TIME [epoch: 4.98 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1644365249726954		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.1644365249726954 | validation: 0.09883200487912802]
	TIME [epoch: 4.99 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.18278747653021774		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.18278747653021774 | validation: 0.08042417923252938]
	TIME [epoch: 4.97 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13070204129593282		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.13070204129593282 | validation: 0.09248021336951273]
	TIME [epoch: 4.98 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11504327720802394		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.11504327720802394 | validation: 0.13048010559331508]
	TIME [epoch: 4.99 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15339907680693377		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.15339907680693377 | validation: 0.13659284628991863]
	TIME [epoch: 4.98 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14629238219455806		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.14629238219455806 | validation: 0.16809624390185846]
	TIME [epoch: 4.96 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11733801924662576		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.11733801924662576 | validation: 0.31868504302048556]
	TIME [epoch: 4.99 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1482106251960725		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.1482106251960725 | validation: 0.2658477360608209]
	TIME [epoch: 4.99 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.14022366212888704		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.14022366212888704 | validation: 0.2571990771933699]
	TIME [epoch: 4.97 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12353669450472465		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.12353669450472465 | validation: 0.3443044972383501]
	TIME [epoch: 4.98 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.13429300667408667		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.13429300667408667 | validation: 0.07041890241291124]
	TIME [epoch: 4.98 sec]
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05950437026195981		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.05950437026195981 | validation: 0.026885797613547233]
	TIME [epoch: 4.98 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.048512015123580665		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.048512015123580665 | validation: 0.42765977748335426]
	TIME [epoch: 4.98 sec]
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.32255896707459875		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.32255896707459875 | validation: 0.45256804232456915]
	TIME [epoch: 5 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.1533593481423804		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.1533593481423804 | validation: 0.23734568315245197]
	TIME [epoch: 4.98 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10639151093451202		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.10639151093451202 | validation: 0.20010695891053637]
	TIME [epoch: 4.98 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10440182917538682		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.10440182917538682 | validation: 0.21665948319736547]
	TIME [epoch: 4.99 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12140283611834007		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.12140283611834007 | validation: 0.07532651293851508]
	TIME [epoch: 4.99 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08514477992529729		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.08514477992529729 | validation: 0.07298777959959128]
	TIME [epoch: 4.98 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09970240083718113		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.09970240083718113 | validation: 0.06329326188493181]
	TIME [epoch: 4.99 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08547185194783818		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.08547185194783818 | validation: 0.06060884624197223]
	TIME [epoch: 4.98 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0742849694207467		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.0742849694207467 | validation: 0.11226866513577637]
	TIME [epoch: 4.97 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07013297804120126		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.07013297804120126 | validation: 0.11495831593499314]
	TIME [epoch: 4.97 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0663921580392515		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.0663921580392515 | validation: 0.13614636531157354]
	TIME [epoch: 4.97 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.07554470516089516		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.07554470516089516 | validation: 0.10677301103958334]
	TIME [epoch: 4.96 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06751644734683569		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.06751644734683569 | validation: 0.09997121949149812]
	TIME [epoch: 4.97 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05924216434982193		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.05924216434982193 | validation: 0.1060854898748495]
	TIME [epoch: 4.98 sec]
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05241334956526289		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.05241334956526289 | validation: 0.08474204632321242]
	TIME [epoch: 4.97 sec]
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060488887342854215		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.060488887342854215 | validation: 0.09941257063395431]
	TIME [epoch: 4.97 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05459930556731017		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.05459930556731017 | validation: 0.17962563784236307]
	TIME [epoch: 4.99 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.08199494491604394		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.08199494491604394 | validation: 0.08660323113348163]
	TIME [epoch: 4.97 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04545375653282038		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.04545375653282038 | validation: 0.08051652708923465]
	TIME [epoch: 4.96 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.054208924660811494		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.054208924660811494 | validation: 0.06942818649562146]
	TIME [epoch: 4.98 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05560578286320715		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.05560578286320715 | validation: 0.08699463451446063]
	TIME [epoch: 4.97 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04991204996321844		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.04991204996321844 | validation: 0.09219394581560188]
	TIME [epoch: 4.96 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05101398612977948		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.05101398612977948 | validation: 0.13291703039818803]
	TIME [epoch: 4.98 sec]
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.10774100013747974		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.10774100013747974 | validation: 0.06120655448557268]
	TIME [epoch: 4.98 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03965054334923451		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.03965054334923451 | validation: 0.06107372370007355]
	TIME [epoch: 4.97 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.043871431701879314		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.043871431701879314 | validation: 0.05388190744433244]
	TIME [epoch: 4.98 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03665993637555838		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.03665993637555838 | validation: 0.03643516800052038]
	TIME [epoch: 4.99 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04475788095911966		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.04475788095911966 | validation: 0.044143757905976994]
	TIME [epoch: 430 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03635246093409879		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.03635246093409879 | validation: 0.04734047873831319]
	TIME [epoch: 11.3 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05849722970004007		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.05849722970004007 | validation: 0.02659295476615627]
	TIME [epoch: 11.3 sec]
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027511531378332475		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.027511531378332475 | validation: 0.23403673303816763]
	TIME [epoch: 11.3 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.15048747613512733		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.15048747613512733 | validation: 0.12269187496919419]
	TIME [epoch: 11.2 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.09613674042303383		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.09613674042303383 | validation: 0.02595589073524235]
	TIME [epoch: 11.2 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.06201800012409287		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.06201800012409287 | validation: 0.014947975503448875]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03913697285613833		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.03913697285613833 | validation: 0.03890184732538071]
	TIME [epoch: 11.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.11419062848933684		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.11419062848933684 | validation: 0.04561680268779961]
	TIME [epoch: 11.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04647177801990369		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.04647177801990369 | validation: -0.006035245125926954]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.027034658957733087		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.027034658957733087 | validation: 0.05282685220101807]
	TIME [epoch: 11.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03906561261241656		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.03906561261241656 | validation: 0.0649886415962686]
	TIME [epoch: 11.3 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02162962169734336		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.02162962169734336 | validation: 0.09683015170443601]
	TIME [epoch: 11.3 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0327424007846704		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.0327424007846704 | validation: 0.06323437838164184]
	TIME [epoch: 11.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.031234895763732718		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.031234895763732718 | validation: 0.012158649647244689]
	TIME [epoch: 11.3 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01961689513047569		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.01961689513047569 | validation: 0.017705970046787946]
	TIME [epoch: 11.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017086567288048905		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.017086567288048905 | validation: 0.02347555904200503]
	TIME [epoch: 11.2 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03916505522070297		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.03916505522070297 | validation: 0.012046908323881982]
	TIME [epoch: 11.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017455674311738577		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.017455674311738577 | validation: 0.008941013977066795]
	TIME [epoch: 11.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028153980176094974		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.028153980176094974 | validation: 0.15680458268286881]
	TIME [epoch: 11.2 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05592402719874176		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.05592402719874176 | validation: 0.0839584123563898]
	TIME [epoch: 11.2 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03454236630027918		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.03454236630027918 | validation: 0.08978859402133425]
	TIME [epoch: 11.2 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.060365839670093645		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.060365839670093645 | validation: 0.1411092887540562]
	TIME [epoch: 11.2 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05057944907858905		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.05057944907858905 | validation: -0.0009425822497280695]
	TIME [epoch: 11.3 sec]
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020121081486832785		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.020121081486832785 | validation: -9.710885020614387e-05]
	TIME [epoch: 11.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013318885430315595		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.013318885430315595 | validation: 0.011402629620317456]
	TIME [epoch: 11.2 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0724565340941251		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.0724565340941251 | validation: 0.031117758182621497]
	TIME [epoch: 11.2 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.039814583762297164		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.039814583762297164 | validation: 0.06837763896895291]
	TIME [epoch: 11.3 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.040655431827852626		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.040655431827852626 | validation: 0.0051990490719595155]
	TIME [epoch: 11.3 sec]
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02558589305518874		[learning rate: 0.0029399]
	Learning Rate: 0.00293991
	LOSS [training: 0.02558589305518874 | validation: 0.024241039121498727]
	TIME [epoch: 11.2 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03615582602030085		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.03615582602030085 | validation: 0.0006787913010352346]
	TIME [epoch: 11.2 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020460698501468137		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.020460698501468137 | validation: 0.04844055849145712]
	TIME [epoch: 11.2 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026656326484393894		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.026656326484393894 | validation: 0.01783895191985629]
	TIME [epoch: 11.2 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012393360182921705		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.012393360182921705 | validation: -0.004518985804719686]
	TIME [epoch: 11.2 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01640069383756743		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.01640069383756743 | validation: 0.03690597011912137]
	TIME [epoch: 11.3 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.040184780393198206		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.040184780393198206 | validation: 0.006910442583923817]
	TIME [epoch: 11.2 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0174658056345578		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.0174658056345578 | validation: 0.07396332572472264]
	TIME [epoch: 11.3 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0386885708154228		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.0386885708154228 | validation: 0.0404192350667561]
	TIME [epoch: 11.3 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.029402826071703483		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.029402826071703483 | validation: 0.0033703784575201323]
	TIME [epoch: 11.3 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022779843498543003		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.022779843498543003 | validation: -0.003952934947750968]
	TIME [epoch: 11.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03135610950090559		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.03135610950090559 | validation: -0.00445787869535331]
	TIME [epoch: 11.3 sec]
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.000882045275768256		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.000882045275768256 | validation: 0.009834820178574611]
	TIME [epoch: 11.2 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.036768018043660096		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.036768018043660096 | validation: 0.03008453403181053]
	TIME [epoch: 11.2 sec]
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01679192130500898		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.01679192130500898 | validation: 0.00791392347961956]
	TIME [epoch: 11.2 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.028425111332369444		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.028425111332369444 | validation: 0.03551414884284123]
	TIME [epoch: 11.2 sec]
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012035811754992477		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.012035811754992477 | validation: 0.022446278911687417]
	TIME [epoch: 11.2 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04119959851129313		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.04119959851129313 | validation: 0.031120091094135563]
	TIME [epoch: 11.2 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.004765543888956147		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.004765543888956147 | validation: 0.010184236283819256]
	TIME [epoch: 11.3 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0156730538052143		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.0156730538052143 | validation: 0.09369476001612934]
	TIME [epoch: 11.3 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.04400734059130276		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.04400734059130276 | validation: 0.042792347589282013]
	TIME [epoch: 11.2 sec]
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009816894919913177		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.009816894919913177 | validation: -0.0011753026524898836]
	TIME [epoch: 11.2 sec]
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005116845341040378		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.005116845341040378 | validation: 0.006777131863302449]
	TIME [epoch: 11.2 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0010757030045989578		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.0010757030045989578 | validation: 0.005743667907767002]
	TIME [epoch: 11.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010637036757176527		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: -0.0010637036757176527 | validation: 0.015808713193947225]
	TIME [epoch: 11.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009656447228830564		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.009656447228830564 | validation: 0.019196318688260133]
	TIME [epoch: 11.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0019222709992988206		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.0019222709992988206 | validation: 0.002787497411124124]
	TIME [epoch: 11.3 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0010631394233672905		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.0010631394233672905 | validation: -0.00177453807672606]
	TIME [epoch: 11.3 sec]
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0035072581385750074		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: -0.0035072581385750074 | validation: -0.002647925421497765]
	TIME [epoch: 11.3 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010400762936081923		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: -0.0010400762936081923 | validation: 0.0036458796764222675]
	TIME [epoch: 11.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005404604528922124		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: -0.005404604528922124 | validation: 0.005284267237560317]
	TIME [epoch: 11.2 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031030569739338714		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: -0.0031030569739338714 | validation: 0.006886772795944677]
	TIME [epoch: 11.2 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0066380047564910125		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: -0.0066380047564910125 | validation: 0.006318191351989675]
	TIME [epoch: 11.2 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0017369041079741932		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.0017369041079741932 | validation: 0.014791284677099135]
	TIME [epoch: 11.2 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00132614476703907		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: -0.00132614476703907 | validation: 0.013880487333586664]
	TIME [epoch: 11.2 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069433488677432455		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.0069433488677432455 | validation: 0.0019698387246185733]
	TIME [epoch: 11.2 sec]
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021334991073021906		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.021334991073021906 | validation: 0.0012650462265841656]
	TIME [epoch: 11.2 sec]
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0033088695136337643		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: -0.0033088695136337643 | validation: 0.018235727191951046]
	TIME [epoch: 11.2 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0022522724597316395		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.0022522724597316395 | validation: -0.003976175246010922]
	TIME [epoch: 11.2 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00224890531939477		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: -0.00224890531939477 | validation: 0.006025337145928504]
	TIME [epoch: 11.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0007388480231528343		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.0007388480231528343 | validation: 0.018690880528322025]
	TIME [epoch: 11.2 sec]
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025981718655472105		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.025981718655472105 | validation: 0.05530211316259094]
	TIME [epoch: 11.2 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013678313374417392		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.013678313374417392 | validation: 0.006568778273771959]
	TIME [epoch: 11.2 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00020731077394362213		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: -0.00020731077394362213 | validation: -0.0041696675744513165]
	TIME [epoch: 11.2 sec]
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0005894198096054965		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: -0.0005894198096054965 | validation: 0.007149025049469328]
	TIME [epoch: 11.2 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002020816906233065		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: -0.002020816906233065 | validation: 0.029897566331293812]
	TIME [epoch: 11.2 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005322493804291281		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.005322493804291281 | validation: 0.006236973740628165]
	TIME [epoch: 11.2 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006260326653741715		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: -0.006260326653741715 | validation: 0.005483555270508896]
	TIME [epoch: 11.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02017042044232062		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.02017042044232062 | validation: 0.009596800450298404]
	TIME [epoch: 11.2 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007467668310912608		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.007467668310912608 | validation: 0.042507178211798294]
	TIME [epoch: 11.2 sec]
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007231519310918065		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.007231519310918065 | validation: 0.015753859980691724]
	TIME [epoch: 11.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031269160355425047		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: -0.0031269160355425047 | validation: -0.0012163246243777636]
	TIME [epoch: 11.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005321548311178635		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: -0.005321548311178635 | validation: 0.00962194667171451]
	TIME [epoch: 11.3 sec]
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0019312926190684762		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.0019312926190684762 | validation: -0.015509557111281342]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_183.pth
	Model improved!!!
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006142989102631164		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: -0.006142989102631164 | validation: -0.0007453268136653828]
	TIME [epoch: 11.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00586694967261692		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: -0.00586694967261692 | validation: 0.01387323358904184]
	TIME [epoch: 11.2 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015037643542753188		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.015037643542753188 | validation: 0.08723961992955362]
	TIME [epoch: 11.2 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.035094950895529595		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.035094950895529595 | validation: 0.011908609810063257]
	TIME [epoch: 11.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005130858895662595		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.005130858895662595 | validation: 0.00803316552310931]
	TIME [epoch: 11.3 sec]
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008676943590313532		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: -0.008676943590313532 | validation: 0.018020502272727727]
	TIME [epoch: 11.2 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002497228424561591		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: -0.002497228424561591 | validation: -7.100350695670105e-05]
	TIME [epoch: 11.2 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0011690730163446985		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: -0.0011690730163446985 | validation: 0.0003395429982183517]
	TIME [epoch: 11.3 sec]
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.002353371786436234		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.002353371786436234 | validation: -0.0034718559952228007]
	TIME [epoch: 11.3 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00507177214965393		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: -0.00507177214965393 | validation: -0.005939287267435456]
	TIME [epoch: 11.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0026823187861084357		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: -0.0026823187861084357 | validation: 0.0012849984917103646]
	TIME [epoch: 11.3 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002323934377494696		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: -0.002323934377494696 | validation: 0.018843319396083195]
	TIME [epoch: 11.2 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007558845803348998		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.007558845803348998 | validation: -0.005313660671331776]
	TIME [epoch: 11.2 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008857794622469788		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: -0.008857794622469788 | validation: -0.006005158394439986]
	TIME [epoch: 11.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0014607413830974524		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.0014607413830974524 | validation: 0.0098251768177492]
	TIME [epoch: 11.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0028318664235019836		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: -0.0028318664235019836 | validation: 0.008838222499647646]
	TIME [epoch: 11.2 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005018078173140676		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: -0.005018078173140676 | validation: 0.0014699793004733898]
	TIME [epoch: 11.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005171519707721305		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.005171519707721305 | validation: 0.04664654979987423]
	TIME [epoch: 11.3 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067245517639478065		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.0067245517639478065 | validation: 0.007415411793871297]
	TIME [epoch: 11.3 sec]
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0021605017921956632		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: -0.0021605017921956632 | validation: -0.00746894151795886]
	TIME [epoch: 11.3 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005985151688876896		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: -0.005985151688876896 | validation: 0.015030243721040556]
	TIME [epoch: 11.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0015550357369363325		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.0015550357369363325 | validation: -0.003872627086509978]
	TIME [epoch: 11.3 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004522890402045216		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: -0.004522890402045216 | validation: 0.015844569143682395]
	TIME [epoch: 11.3 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005189681380081064		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: -0.005189681380081064 | validation: 0.030851151726401294]
	TIME [epoch: 11.3 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.005133575834379641		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.005133575834379641 | validation: -0.0015724263203040255]
	TIME [epoch: 11.3 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004614884409757325		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: -0.004614884409757325 | validation: 0.016137569937411365]
	TIME [epoch: 11.3 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008881050512207847		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: -0.008881050512207847 | validation: 0.0021491497822042466]
	TIME [epoch: 11.3 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019611006122681872		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.019611006122681872 | validation: 0.013444910236040181]
	TIME [epoch: 11.3 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008136125994168701		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.008136125994168701 | validation: 0.011504584921064884]
	TIME [epoch: 11.2 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005950952152828998		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: -0.005950952152828998 | validation: 0.004182036954414057]
	TIME [epoch: 11.2 sec]
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006770682600190228		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: -0.006770682600190228 | validation: -0.008282784259537207]
	TIME [epoch: 11.3 sec]
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006047092051191825		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: -0.006047092051191825 | validation: -0.001454170418738675]
	TIME [epoch: 11.2 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0057119947835103085		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: -0.0057119947835103085 | validation: -0.004040734762884279]
	TIME [epoch: 11.2 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007744840904327473		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: -0.007744840904327473 | validation: -0.009211572466215843]
	TIME [epoch: 11.3 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007723237147986582		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: -0.007723237147986582 | validation: 0.000827984511389779]
	TIME [epoch: 11.3 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031569365722011015		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: -0.0031569365722011015 | validation: 0.00552752894165511]
	TIME [epoch: 11.2 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0032567223461248216		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.0032567223461248216 | validation: 0.024621754380924822]
	TIME [epoch: 11.2 sec]
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0006046412059349847		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: -0.0006046412059349847 | validation: 0.0036386352620596412]
	TIME [epoch: 11.3 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009890191623581533		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: -0.009890191623581533 | validation: 0.0027451753100716067]
	TIME [epoch: 11.3 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012646793853065729		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: -0.012646793853065729 | validation: 0.0015177772826716791]
	TIME [epoch: 11.3 sec]
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004301401957036292		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: -0.004301401957036292 | validation: -0.003286790880869755]
	TIME [epoch: 11.3 sec]
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008976418986515935		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: -0.008976418986515935 | validation: 0.006170331562006807]
	TIME [epoch: 11.3 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0012973756213966146		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: -0.0012973756213966146 | validation: 0.004463569409176976]
	TIME [epoch: 11.3 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008579515130219127		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: -0.008579515130219127 | validation: -0.005780057395452915]
	TIME [epoch: 11.3 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006706483310102716		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: -0.006706483310102716 | validation: 0.01784101401677831]
	TIME [epoch: 11.3 sec]
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0018169854750296629		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: -0.0018169854750296629 | validation: -0.0054961627256190455]
	TIME [epoch: 11.3 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0052120774958834964		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: -0.0052120774958834964 | validation: -0.00598732349380875]
	TIME [epoch: 11.3 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00807800555573113		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: -0.00807800555573113 | validation: -0.00326098892496956]
	TIME [epoch: 11.3 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005247954167838385		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: -0.005247954167838385 | validation: -0.007679447656415881]
	TIME [epoch: 11.3 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003009533388259298		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: -0.003009533388259298 | validation: 0.011316396299006262]
	TIME [epoch: 11.3 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004960611564052034		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: -0.004960611564052034 | validation: -0.004247311909091672]
	TIME [epoch: 11.3 sec]
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006399644658990849		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: -0.006399644658990849 | validation: 0.008466777487520352]
	TIME [epoch: 11.2 sec]
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: -0.002760040538599271		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: -0.002760040538599271 | validation: 0.01150154205917854]
	TIME [epoch: 11.3 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0031068903938840167		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: -0.0031068903938840167 | validation: -0.003041927664609901]
	TIME [epoch: 11.3 sec]
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012845728504778274		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: -0.012845728504778274 | validation: -0.012208821594282493]
	TIME [epoch: 11.3 sec]
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00833892741661798		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: -0.00833892741661798 | validation: -0.004622447083097257]
	TIME [epoch: 11.2 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010998289054683459		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: -0.0010998289054683459 | validation: 0.015242530354462058]
	TIME [epoch: 11.2 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005330980334805299		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: -0.005330980334805299 | validation: 0.003755318160785019]
	TIME [epoch: 11.2 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003859203201435641		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: -0.003859203201435641 | validation: 0.0032626130361769175]
	TIME [epoch: 11.2 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: -0.003173792353366735		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: -0.003173792353366735 | validation: 0.007038025519014035]
	TIME [epoch: 11.2 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011200988322237246		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: -0.011200988322237246 | validation: 0.007833430396860993]
	TIME [epoch: 11.2 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: -0.005603690945782249		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: -0.005603690945782249 | validation: -8.259133896534193e-05]
	TIME [epoch: 11.2 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0084836839434935		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: -0.0084836839434935 | validation: -0.005536623711613207]
	TIME [epoch: 11.3 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0010267336778407954		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: -0.0010267336778407954 | validation: 0.020731509754908756]
	TIME [epoch: 11.3 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0070585697279727955		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: -0.0070585697279727955 | validation: -0.0019240436956397358]
	TIME [epoch: 11.2 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008176005729224719		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: -0.008176005729224719 | validation: 0.0006841286146119624]
	TIME [epoch: 11.2 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008437414039210318		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: -0.008437414039210318 | validation: -0.0009083001742750541]
	TIME [epoch: 11.2 sec]
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007214709649842427		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: -0.007214709649842427 | validation: 0.0034060247258968315]
	TIME [epoch: 449 sec]
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00600008408598209		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: -0.00600008408598209 | validation: -0.001562558241259428]
	TIME [epoch: 25 sec]
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: -0.012097822471573712		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: -0.012097822471573712 | validation: -0.004901287966596096]
	TIME [epoch: 25 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006140351522658036		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: -0.006140351522658036 | validation: -0.0030649187229526355]
	TIME [epoch: 24.9 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00737230987482311		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: -0.00737230987482311 | validation: -0.0028773045906575517]
	TIME [epoch: 24.9 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: -0.004401940035888479		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: -0.004401940035888479 | validation: 0.011893548302662376]
	TIME [epoch: 24.9 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0064886563064700375		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: -0.0064886563064700375 | validation: 0.0034984394895503333]
	TIME [epoch: 24.9 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009376098664216907		[learning rate: 0.0004121]
	Learning Rate: 0.000412097
	LOSS [training: -0.009376098664216907 | validation: 0.0024471362558978176]
	TIME [epoch: 24.9 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0096413032536911		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: -0.0096413032536911 | validation: -0.011645979961212933]
	TIME [epoch: 24.9 sec]
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: -0.008390368496584786		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: -0.008390368496584786 | validation: -0.007427930084048102]
	TIME [epoch: 24.9 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: -0.011342669650181773		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: -0.011342669650181773 | validation: 0.0006285319600894097]
	TIME [epoch: 24.9 sec]
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007487954528255167		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: -0.007487954528255167 | validation: 0.0061971484917503]
	TIME [epoch: 24.9 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010042042659123836		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: -0.010042042659123836 | validation: -0.0017739332399112522]
	TIME [epoch: 24.9 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007617604224805417		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: -0.007617604224805417 | validation: 0.0029049771242456186]
	TIME [epoch: 24.9 sec]
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0029295529081606554		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: -0.0029295529081606554 | validation: -0.01260714886913496]
	TIME [epoch: 24.9 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009916289266684628		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: -0.009916289266684628 | validation: 0.0024395957742298227]
	TIME [epoch: 24.9 sec]
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.003071035229338101		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.003071035229338101 | validation: 0.017509587175770086]
	TIME [epoch: 24.9 sec]
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01085155438026878		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.01085155438026878 | validation: 0.003945191347772048]
	TIME [epoch: 24.9 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009561248320543432		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: -0.009561248320543432 | validation: -0.0008992757348860283]
	TIME [epoch: 24.9 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009721428536308412		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: -0.009721428536308412 | validation: 0.002165820734310791]
	TIME [epoch: 24.9 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009044937156388707		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: -0.009044937156388707 | validation: -0.0041652282541327825]
	TIME [epoch: 24.9 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: -0.01334957549628549		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: -0.01334957549628549 | validation: 0.0038480170152240074]
	TIME [epoch: 24.9 sec]
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010237460398728498		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: -0.010237460398728498 | validation: -0.006375389102624898]
	TIME [epoch: 24.9 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0003755974256876215		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.0003755974256876215 | validation: 9.918949877130287e-05]
	TIME [epoch: 24.9 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: -0.0070136304778207915		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: -0.0070136304778207915 | validation: -0.0008355702014124144]
	TIME [epoch: 24.9 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010243095128073866		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: -0.010243095128073866 | validation: 0.00044599847245346]
	TIME [epoch: 24.9 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: -0.006156860136846295		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: -0.006156860136846295 | validation: 0.0033482067799148188]
	TIME [epoch: 24.9 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: -0.00972143607164774		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: -0.00972143607164774 | validation: 0.008786880624799171]
	TIME [epoch: 24.9 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009844717105870388		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: -0.009844717105870388 | validation: -0.0004959925727720993]
	TIME [epoch: 24.9 sec]
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: -0.009652093256336512		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: -0.009652093256336512 | validation: 0.0015068823654985808]
	TIME [epoch: 24.9 sec]
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010588525246965786		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: -0.010588525246965786 | validation: -0.006284656827898329]
	TIME [epoch: 24.9 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: -0.007077514586012118		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: -0.007077514586012118 | validation: -0.008625160760889997]
	TIME [epoch: 24.9 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: -0.010267858564565913		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: -0.010267858564565913 | validation: -0.0046954474849544]
	TIME [epoch: 24.9 sec]
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: -0.013809913002600325		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: -0.013809913002600325 | validation: -0.00849808899555845]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_kl1_20241205_184216/states/model_algphiq_1a_v_kl1_284.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 4585.243 seconds.
