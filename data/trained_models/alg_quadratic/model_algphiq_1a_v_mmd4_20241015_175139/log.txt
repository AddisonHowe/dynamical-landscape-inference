Args:
Namespace(name='model_algphiq_1a_v_mmd4', outdir='out/model_training/model_algphiq_1a_v_mmd4', training_data='data/training_data/basic/data_phiq_1a/training', validation_data='data/training_data/basic/data_phiq_1a/validation', model_type='quadratic', nsims_training=None, nsims_validation=None, num_epochs=500, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=False, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 250], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=False, confinement_factor=1.0, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], phi_final_act='softplus', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=0.0, init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.1], optimizer='rms', momentum=0.0, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2886389118

Training model...

Saving initial model state to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8374204613112621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8374204613112621 | validation: 0.8162485091868845]
	TIME [epoch: 96.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 4/4] avg loss: 0.8041779894336741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8041779894336741 | validation: 0.786811982527772]
	TIME [epoch: 4.33 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7753550489988723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7753550489988723 | validation: 0.7594292611030137]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7479340124509234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7479340124509234 | validation: 0.7318335407254604]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 4/4] avg loss: 0.7195288109954391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7195288109954391 | validation: 0.7030378752970573]
	TIME [epoch: 4.32 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6893473139319138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6893473139319138 | validation: 0.671367215182083]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6589389422317513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6589389422317513 | validation: 0.6398018886743766]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 4/4] avg loss: 0.6254893606055356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6254893606055356 | validation: 0.6062755644126425]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5912660564180334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5912660564180334 | validation: 0.571061230471416]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5567050933160711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5567050933160711 | validation: 0.5348619803511641]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 4/4] avg loss: 0.5186779949617533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5186779949617533 | validation: 0.49493643196605197]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 4/4] avg loss: 0.47868292894212927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47868292894212927 | validation: 0.45461794356402]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 4/4] avg loss: 0.43826734449335536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43826734449335536 | validation: 0.4136623886107567]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 4/4] avg loss: 0.39451184558904306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39451184558904306 | validation: 0.3677838815533675]
	TIME [epoch: 4.31 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 4/4] avg loss: 0.34765841160576355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34765841160576355 | validation: 0.31691666103615457]
	TIME [epoch: 4.28 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 4/4] avg loss: 0.29261294096017243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29261294096017243 | validation: 0.2535780008993292]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 4/4] avg loss: 0.21781670248215876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21781670248215876 | validation: 0.1567870458135162]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 4/4] avg loss: 0.12001527149183115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12001527149183115 | validation: 0.07637060456436306]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 4/4] avg loss: 0.05441983931075344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05441983931075344 | validation: 0.03341643911522488]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 4/4] avg loss: 0.03192345127786896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03192345127786896 | validation: 0.02938519577293084]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 4/4] avg loss: 0.030033856374255874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.030033856374255874 | validation: 0.02027021636969111]
	TIME [epoch: 4.29 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026226125008339166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026226125008339166 | validation: 0.02039856976700818]
	TIME [epoch: 4.3 sec]
EPOCH 23/500:
	Training over batches...
		[batch 4/4] avg loss: 0.026450652098246832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.026450652098246832 | validation: 0.01876144327543112]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 4/4] avg loss: 0.025173946086736947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.025173946086736947 | validation: 0.019192893477749235]
	TIME [epoch: 4.27 sec]
EPOCH 25/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024841120169952255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024841120169952255 | validation: 0.018587981904288453]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02407034788007871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02407034788007871 | validation: 0.019724661284244407]
	TIME [epoch: 4.27 sec]
EPOCH 27/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02408431246189434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02408431246189434 | validation: 0.020454853174335506]
	TIME [epoch: 4.27 sec]
EPOCH 28/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024235803813123694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024235803813123694 | validation: 0.020285133433879485]
	TIME [epoch: 4.27 sec]
EPOCH 29/500:
	Training over batches...
		[batch 4/4] avg loss: 0.024265747177780905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.024265747177780905 | validation: 0.018721492337144104]
	TIME [epoch: 4.26 sec]
EPOCH 30/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022817686320618452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022817686320618452 | validation: 0.0196397556082958]
	TIME [epoch: 4.28 sec]
EPOCH 31/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023504457268993112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023504457268993112 | validation: 0.020165666985164657]
	TIME [epoch: 4.29 sec]
EPOCH 32/500:
	Training over batches...
		[batch 4/4] avg loss: 0.023180062358201886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.023180062358201886 | validation: 0.020533599092571263]
	TIME [epoch: 4.27 sec]
EPOCH 33/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02328755393193827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02328755393193827 | validation: 0.018921514896843093]
	TIME [epoch: 4.27 sec]
EPOCH 34/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02307473374877673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02307473374877673 | validation: 0.01970388075649938]
	TIME [epoch: 4.27 sec]
EPOCH 35/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022285350371529466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022285350371529466 | validation: 0.020582481609851606]
	TIME [epoch: 4.27 sec]
EPOCH 36/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022952826357768512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022952826357768512 | validation: 0.01985061550142922]
	TIME [epoch: 4.26 sec]
EPOCH 37/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02239869325382607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02239869325382607 | validation: 0.01823303621538512]
	TIME [epoch: 4.27 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021889132654909514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021889132654909514 | validation: 0.018278229510913305]
	TIME [epoch: 4.27 sec]
EPOCH 39/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021570272892606303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021570272892606303 | validation: 0.018782133035896997]
	TIME [epoch: 4.29 sec]
EPOCH 40/500:
	Training over batches...
		[batch 4/4] avg loss: 0.022265853179396812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.022265853179396812 | validation: 0.018519084629845712]
	TIME [epoch: 4.29 sec]
EPOCH 41/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02153689258131658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02153689258131658 | validation: 0.01862055920105358]
	TIME [epoch: 4.26 sec]
EPOCH 42/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021657401187073964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021657401187073964 | validation: 0.017644438510732448]
	TIME [epoch: 4.26 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020760606179730134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020760606179730134 | validation: 0.018474668931478415]
	TIME [epoch: 4.27 sec]
EPOCH 44/500:
	Training over batches...
		[batch 4/4] avg loss: 0.021290420086711025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.021290420086711025 | validation: 0.018537750202636625]
	TIME [epoch: 4.27 sec]
EPOCH 45/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02092269463826749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02092269463826749 | validation: 0.017802947109989878]
	TIME [epoch: 4.26 sec]
EPOCH 46/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020645850225913188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020645850225913188 | validation: 0.017971057107850224]
	TIME [epoch: 4.27 sec]
EPOCH 47/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020739420902008508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020739420902008508 | validation: 0.019353438049645184]
	TIME [epoch: 4.27 sec]
EPOCH 48/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020185142971049317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.020185142971049317 | validation: 0.019373928053062234]
	TIME [epoch: 4.28 sec]
EPOCH 49/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02073520858041577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02073520858041577 | validation: 0.01845172076876433]
	TIME [epoch: 4.29 sec]
EPOCH 50/500:
	Training over batches...
		[batch 4/4] avg loss: 0.02014317264049687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.02014317264049687 | validation: 0.019441109498390962]
	TIME [epoch: 4.27 sec]
EPOCH 51/500:
	Training over batches...
		[batch 4/4] avg loss: 0.020147831521329276		[learning rate: 0.0098855]
	Learning Rate: 0.00988553
	LOSS [training: 0.020147831521329276 | validation: 0.019096441979099703]
	TIME [epoch: 101 sec]
EPOCH 52/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019627613543839476		[learning rate: 0.0097349]
	Learning Rate: 0.00973494
	LOSS [training: 0.019627613543839476 | validation: 0.018888644976572347]
	TIME [epoch: 8.47 sec]
EPOCH 53/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019867425579963426		[learning rate: 0.0095866]
	Learning Rate: 0.00958665
	LOSS [training: 0.019867425579963426 | validation: 0.018571374557131107]
	TIME [epoch: 8.38 sec]
EPOCH 54/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019039395923991984		[learning rate: 0.0094406]
	Learning Rate: 0.00944061
	LOSS [training: 0.019039395923991984 | validation: 0.017919115188651708]
	TIME [epoch: 8.38 sec]
EPOCH 55/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019045149191220107		[learning rate: 0.0092968]
	Learning Rate: 0.0092968
	LOSS [training: 0.019045149191220107 | validation: 0.018200427703696682]
	TIME [epoch: 8.37 sec]
EPOCH 56/500:
	Training over batches...
		[batch 4/4] avg loss: 0.019356014165507862		[learning rate: 0.0091552]
	Learning Rate: 0.00915517
	LOSS [training: 0.019356014165507862 | validation: 0.016463767661481415]
	TIME [epoch: 8.36 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018413017850963873		[learning rate: 0.0090157]
	Learning Rate: 0.00901571
	LOSS [training: 0.018413017850963873 | validation: 0.018018758064706056]
	TIME [epoch: 8.43 sec]
EPOCH 58/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01918606756362312		[learning rate: 0.0088784]
	Learning Rate: 0.00887837
	LOSS [training: 0.01918606756362312 | validation: 0.01764618382018126]
	TIME [epoch: 8.39 sec]
EPOCH 59/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018520678246574385		[learning rate: 0.0087431]
	Learning Rate: 0.00874312
	LOSS [training: 0.018520678246574385 | validation: 0.017571464607604635]
	TIME [epoch: 8.39 sec]
EPOCH 60/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018243241195052		[learning rate: 0.0086099]
	Learning Rate: 0.00860994
	LOSS [training: 0.018243241195052 | validation: 0.018200925408173443]
	TIME [epoch: 8.39 sec]
EPOCH 61/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018582518082781475		[learning rate: 0.0084788]
	Learning Rate: 0.00847878
	LOSS [training: 0.018582518082781475 | validation: 0.017248499550327163]
	TIME [epoch: 8.36 sec]
EPOCH 62/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017696623564419686		[learning rate: 0.0083496]
	Learning Rate: 0.00834962
	LOSS [training: 0.017696623564419686 | validation: 0.017105644750252048]
	TIME [epoch: 8.39 sec]
EPOCH 63/500:
	Training over batches...
		[batch 4/4] avg loss: 0.018394984039872497		[learning rate: 0.0082224]
	Learning Rate: 0.00822243
	LOSS [training: 0.018394984039872497 | validation: 0.01765845855476442]
	TIME [epoch: 8.42 sec]
EPOCH 64/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01743089951756513		[learning rate: 0.0080972]
	Learning Rate: 0.00809717
	LOSS [training: 0.01743089951756513 | validation: 0.017799697762717663]
	TIME [epoch: 8.38 sec]
EPOCH 65/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017401002497996088		[learning rate: 0.0079738]
	Learning Rate: 0.00797382
	LOSS [training: 0.017401002497996088 | validation: 0.017404625469920845]
	TIME [epoch: 8.39 sec]
EPOCH 66/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017557055490054166		[learning rate: 0.0078524]
	Learning Rate: 0.00785236
	LOSS [training: 0.017557055490054166 | validation: 0.017022307430046926]
	TIME [epoch: 8.38 sec]
EPOCH 67/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01726048390823357		[learning rate: 0.0077327]
	Learning Rate: 0.00773274
	LOSS [training: 0.01726048390823357 | validation: 0.017835474633704548]
	TIME [epoch: 8.38 sec]
EPOCH 68/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01728655540493069		[learning rate: 0.0076149]
	Learning Rate: 0.00761494
	LOSS [training: 0.01728655540493069 | validation: 0.017442205689615672]
	TIME [epoch: 8.42 sec]
EPOCH 69/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017102778780536232		[learning rate: 0.0074989]
	Learning Rate: 0.00749894
	LOSS [training: 0.017102778780536232 | validation: 0.016555613954871998]
	TIME [epoch: 8.39 sec]
EPOCH 70/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016455514060707513		[learning rate: 0.0073847]
	Learning Rate: 0.00738471
	LOSS [training: 0.016455514060707513 | validation: 0.017079002765360125]
	TIME [epoch: 8.39 sec]
EPOCH 71/500:
	Training over batches...
		[batch 4/4] avg loss: 0.017277521237771695		[learning rate: 0.0072722]
	Learning Rate: 0.00727221
	LOSS [training: 0.017277521237771695 | validation: 0.015742983195666492]
	TIME [epoch: 8.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016282274390529993		[learning rate: 0.0071614]
	Learning Rate: 0.00716143
	LOSS [training: 0.016282274390529993 | validation: 0.016576877759393205]
	TIME [epoch: 8.38 sec]
EPOCH 73/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01681969405219886		[learning rate: 0.0070523]
	Learning Rate: 0.00705234
	LOSS [training: 0.01681969405219886 | validation: 0.014623387164632278]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015993216084339696		[learning rate: 0.0069449]
	Learning Rate: 0.00694491
	LOSS [training: 0.015993216084339696 | validation: 0.01625277446513251]
	TIME [epoch: 8.38 sec]
EPOCH 75/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016315669812236987		[learning rate: 0.0068391]
	Learning Rate: 0.00683912
	LOSS [training: 0.016315669812236987 | validation: 0.015326318315129397]
	TIME [epoch: 8.36 sec]
EPOCH 76/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01619077099246688		[learning rate: 0.0067349]
	Learning Rate: 0.00673493
	LOSS [training: 0.01619077099246688 | validation: 0.01620160176099269]
	TIME [epoch: 8.37 sec]
EPOCH 77/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01625935002469039		[learning rate: 0.0066323]
	Learning Rate: 0.00663234
	LOSS [training: 0.01625935002469039 | validation: 0.014991615927944901]
	TIME [epoch: 8.37 sec]
EPOCH 78/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015841896686900454		[learning rate: 0.0065313]
	Learning Rate: 0.00653131
	LOSS [training: 0.015841896686900454 | validation: 0.01610211583575954]
	TIME [epoch: 8.41 sec]
EPOCH 79/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015556110857345637		[learning rate: 0.0064318]
	Learning Rate: 0.00643181
	LOSS [training: 0.015556110857345637 | validation: 0.014706483487671836]
	TIME [epoch: 8.38 sec]
EPOCH 80/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015052173122663106		[learning rate: 0.0063338]
	Learning Rate: 0.00633383
	LOSS [training: 0.015052173122663106 | validation: 0.016204991764453516]
	TIME [epoch: 8.38 sec]
EPOCH 81/500:
	Training over batches...
		[batch 4/4] avg loss: 0.016349333044845354		[learning rate: 0.0062373]
	Learning Rate: 0.00623735
	LOSS [training: 0.016349333044845354 | validation: 0.015450912245779998]
	TIME [epoch: 8.37 sec]
EPOCH 82/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015437088261951828		[learning rate: 0.0061423]
	Learning Rate: 0.00614233
	LOSS [training: 0.015437088261951828 | validation: 0.015011627593655638]
	TIME [epoch: 8.38 sec]
EPOCH 83/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01455112068176009		[learning rate: 0.0060488]
	Learning Rate: 0.00604876
	LOSS [training: 0.01455112068176009 | validation: 0.014749207428303287]
	TIME [epoch: 8.42 sec]
EPOCH 84/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015326629727062224		[learning rate: 0.0059566]
	Learning Rate: 0.00595662
	LOSS [training: 0.015326629727062224 | validation: 0.015294731687443639]
	TIME [epoch: 8.39 sec]
EPOCH 85/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015616678611024264		[learning rate: 0.0058659]
	Learning Rate: 0.00586588
	LOSS [training: 0.015616678611024264 | validation: 0.014941227015923684]
	TIME [epoch: 8.35 sec]
EPOCH 86/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014311251548550407		[learning rate: 0.0057765]
	Learning Rate: 0.00577653
	LOSS [training: 0.014311251548550407 | validation: 0.014723956275634092]
	TIME [epoch: 8.38 sec]
EPOCH 87/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015537996388894174		[learning rate: 0.0056885]
	Learning Rate: 0.00568853
	LOSS [training: 0.015537996388894174 | validation: 0.014455874240427406]
	TIME [epoch: 8.39 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_87.pth
	Model improved!!!
EPOCH 88/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015093810735166012		[learning rate: 0.0056019]
	Learning Rate: 0.00560187
	LOSS [training: 0.015093810735166012 | validation: 0.013542803587931274]
	TIME [epoch: 8.38 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01464358614762043		[learning rate: 0.0055165]
	Learning Rate: 0.00551654
	LOSS [training: 0.01464358614762043 | validation: 0.01403561536664175]
	TIME [epoch: 8.39 sec]
EPOCH 90/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014151795297230286		[learning rate: 0.0054325]
	Learning Rate: 0.0054325
	LOSS [training: 0.014151795297230286 | validation: 0.01467699640061262]
	TIME [epoch: 8.36 sec]
EPOCH 91/500:
	Training over batches...
		[batch 4/4] avg loss: 0.015081661273599521		[learning rate: 0.0053497]
	Learning Rate: 0.00534975
	LOSS [training: 0.015081661273599521 | validation: 0.01371638331343391]
	TIME [epoch: 8.37 sec]
EPOCH 92/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013784310660745702		[learning rate: 0.0052683]
	Learning Rate: 0.00526825
	LOSS [training: 0.013784310660745702 | validation: 0.014567598743072107]
	TIME [epoch: 8.36 sec]
EPOCH 93/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014298783846179284		[learning rate: 0.005188]
	Learning Rate: 0.005188
	LOSS [training: 0.014298783846179284 | validation: 0.013990064670522804]
	TIME [epoch: 8.36 sec]
EPOCH 94/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014260124011253678		[learning rate: 0.005109]
	Learning Rate: 0.00510897
	LOSS [training: 0.014260124011253678 | validation: 0.013951444415315428]
	TIME [epoch: 8.4 sec]
EPOCH 95/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014104901479492513		[learning rate: 0.0050311]
	Learning Rate: 0.00503114
	LOSS [training: 0.014104901479492513 | validation: 0.014818977355403457]
	TIME [epoch: 8.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014329055251384129		[learning rate: 0.0049545]
	Learning Rate: 0.0049545
	LOSS [training: 0.014329055251384129 | validation: 0.012941284972472237]
	TIME [epoch: 8.35 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01353757318606984		[learning rate: 0.004879]
	Learning Rate: 0.00487903
	LOSS [training: 0.01353757318606984 | validation: 0.013750399145174681]
	TIME [epoch: 8.37 sec]
EPOCH 98/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013651760537735456		[learning rate: 0.0048047]
	Learning Rate: 0.0048047
	LOSS [training: 0.013651760537735456 | validation: 0.013887327646819554]
	TIME [epoch: 8.35 sec]
EPOCH 99/500:
	Training over batches...
		[batch 4/4] avg loss: 0.014389809640436527		[learning rate: 0.0047315]
	Learning Rate: 0.00473151
	LOSS [training: 0.014389809640436527 | validation: 0.013772146052668327]
	TIME [epoch: 8.36 sec]
EPOCH 100/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013595583543429289		[learning rate: 0.0046594]
	Learning Rate: 0.00465944
	LOSS [training: 0.013595583543429289 | validation: 0.0130456751984614]
	TIME [epoch: 8.38 sec]
EPOCH 101/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013222347272940355		[learning rate: 0.0045885]
	Learning Rate: 0.00458846
	LOSS [training: 0.013222347272940355 | validation: 0.013533420310547698]
	TIME [epoch: 113 sec]
EPOCH 102/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01396715316862572		[learning rate: 0.0045186]
	Learning Rate: 0.00451856
	LOSS [training: 0.01396715316862572 | validation: 0.013530284800578267]
	TIME [epoch: 19.1 sec]
EPOCH 103/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012907798372562559		[learning rate: 0.0044497]
	Learning Rate: 0.00444973
	LOSS [training: 0.012907798372562559 | validation: 0.012382814643924581]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013036409947550167		[learning rate: 0.0043819]
	Learning Rate: 0.00438194
	LOSS [training: 0.013036409947550167 | validation: 0.01392532372211451]
	TIME [epoch: 19.1 sec]
EPOCH 105/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013534275041164032		[learning rate: 0.0043152]
	Learning Rate: 0.00431519
	LOSS [training: 0.013534275041164032 | validation: 0.013081131517407283]
	TIME [epoch: 19.2 sec]
EPOCH 106/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013542447952096482		[learning rate: 0.0042495]
	Learning Rate: 0.00424946
	LOSS [training: 0.013542447952096482 | validation: 0.01383378472716125]
	TIME [epoch: 19.1 sec]
EPOCH 107/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01284420441234362		[learning rate: 0.0041847]
	Learning Rate: 0.00418472
	LOSS [training: 0.01284420441234362 | validation: 0.013289577805024244]
	TIME [epoch: 19.2 sec]
EPOCH 108/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013498705068818246		[learning rate: 0.004121]
	Learning Rate: 0.00412098
	LOSS [training: 0.013498705068818246 | validation: 0.01284315454117355]
	TIME [epoch: 19.1 sec]
EPOCH 109/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012590610337482164		[learning rate: 0.0040582]
	Learning Rate: 0.0040582
	LOSS [training: 0.012590610337482164 | validation: 0.01181797704483855]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012804342958258868		[learning rate: 0.0039964]
	Learning Rate: 0.00399638
	LOSS [training: 0.012804342958258868 | validation: 0.012963297578356067]
	TIME [epoch: 19.1 sec]
EPOCH 111/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012864730460654623		[learning rate: 0.0039355]
	Learning Rate: 0.0039355
	LOSS [training: 0.012864730460654623 | validation: 0.013168728943679407]
	TIME [epoch: 19.1 sec]
EPOCH 112/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013033048185026354		[learning rate: 0.0038755]
	Learning Rate: 0.00387555
	LOSS [training: 0.013033048185026354 | validation: 0.012567104785186741]
	TIME [epoch: 19.2 sec]
EPOCH 113/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012698099659555288		[learning rate: 0.0038165]
	Learning Rate: 0.00381651
	LOSS [training: 0.012698099659555288 | validation: 0.012828924570400475]
	TIME [epoch: 19.1 sec]
EPOCH 114/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012409312052964413		[learning rate: 0.0037584]
	Learning Rate: 0.00375837
	LOSS [training: 0.012409312052964413 | validation: 0.011890915331874533]
	TIME [epoch: 19.1 sec]
EPOCH 115/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012205907588496642		[learning rate: 0.0037011]
	Learning Rate: 0.00370112
	LOSS [training: 0.012205907588496642 | validation: 0.01196169436828477]
	TIME [epoch: 19.2 sec]
EPOCH 116/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012045230812799563		[learning rate: 0.0036447]
	Learning Rate: 0.00364474
	LOSS [training: 0.012045230812799563 | validation: 0.011957730322374252]
	TIME [epoch: 19.1 sec]
EPOCH 117/500:
	Training over batches...
		[batch 4/4] avg loss: 0.013158083558078307		[learning rate: 0.0035892]
	Learning Rate: 0.00358922
	LOSS [training: 0.013158083558078307 | validation: 0.012529948366610037]
	TIME [epoch: 19.2 sec]
EPOCH 118/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012789562103928726		[learning rate: 0.0035345]
	Learning Rate: 0.00353454
	LOSS [training: 0.012789562103928726 | validation: 0.011520622663167892]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_118.pth
	Model improved!!!
EPOCH 119/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011932525536386617		[learning rate: 0.0034807]
	Learning Rate: 0.0034807
	LOSS [training: 0.011932525536386617 | validation: 0.011546825347538585]
	TIME [epoch: 19.1 sec]
EPOCH 120/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012514668136412945		[learning rate: 0.0034277]
	Learning Rate: 0.00342768
	LOSS [training: 0.012514668136412945 | validation: 0.01189203744062337]
	TIME [epoch: 19.1 sec]
EPOCH 121/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012153361002688497		[learning rate: 0.0033755]
	Learning Rate: 0.00337546
	LOSS [training: 0.012153361002688497 | validation: 0.01153387681559259]
	TIME [epoch: 19.1 sec]
EPOCH 122/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012218990393322497		[learning rate: 0.003324]
	Learning Rate: 0.00332404
	LOSS [training: 0.012218990393322497 | validation: 0.011677853300313786]
	TIME [epoch: 19.1 sec]
EPOCH 123/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012391842598170381		[learning rate: 0.0032734]
	Learning Rate: 0.00327341
	LOSS [training: 0.012391842598170381 | validation: 0.011608049616479906]
	TIME [epoch: 19.1 sec]
EPOCH 124/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011927604007813983		[learning rate: 0.0032235]
	Learning Rate: 0.00322354
	LOSS [training: 0.011927604007813983 | validation: 0.011439807675830613]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01152172965349562		[learning rate: 0.0031744]
	Learning Rate: 0.00317444
	LOSS [training: 0.01152172965349562 | validation: 0.011078173818880231]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_125.pth
	Model improved!!!
EPOCH 126/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011688437079588346		[learning rate: 0.0031261]
	Learning Rate: 0.00312608
	LOSS [training: 0.011688437079588346 | validation: 0.01258795875360678]
	TIME [epoch: 19.1 sec]
EPOCH 127/500:
	Training over batches...
		[batch 4/4] avg loss: 0.012655163409987995		[learning rate: 0.0030785]
	Learning Rate: 0.00307846
	LOSS [training: 0.012655163409987995 | validation: 0.01119004124329235]
	TIME [epoch: 19 sec]
EPOCH 128/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011924828895562052		[learning rate: 0.0030316]
	Learning Rate: 0.00303156
	LOSS [training: 0.011924828895562052 | validation: 0.011507203427715593]
	TIME [epoch: 19.1 sec]
EPOCH 129/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01198275704710875		[learning rate: 0.0029854]
	Learning Rate: 0.00298538
	LOSS [training: 0.01198275704710875 | validation: 0.010894960549336143]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_129.pth
	Model improved!!!
EPOCH 130/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01123104522690106		[learning rate: 0.0029399]
	Learning Rate: 0.0029399
	LOSS [training: 0.01123104522690106 | validation: 0.01101048462159878]
	TIME [epoch: 19 sec]
EPOCH 131/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011375352597971199		[learning rate: 0.0028951]
	Learning Rate: 0.00289512
	LOSS [training: 0.011375352597971199 | validation: 0.011683721511244388]
	TIME [epoch: 19.1 sec]
EPOCH 132/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01234083936519129		[learning rate: 0.002851]
	Learning Rate: 0.00285102
	LOSS [training: 0.01234083936519129 | validation: 0.011701305488531847]
	TIME [epoch: 19 sec]
EPOCH 133/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011377762881325498		[learning rate: 0.0028076]
	Learning Rate: 0.00280759
	LOSS [training: 0.011377762881325498 | validation: 0.011079773081707621]
	TIME [epoch: 19.1 sec]
EPOCH 134/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011222395399365398		[learning rate: 0.0027648]
	Learning Rate: 0.00276482
	LOSS [training: 0.011222395399365398 | validation: 0.010987658928811515]
	TIME [epoch: 19 sec]
EPOCH 135/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011565893475528619		[learning rate: 0.0027227]
	Learning Rate: 0.0027227
	LOSS [training: 0.011565893475528619 | validation: 0.011629860079275505]
	TIME [epoch: 19 sec]
EPOCH 136/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011458097138515316		[learning rate: 0.0026812]
	Learning Rate: 0.00268123
	LOSS [training: 0.011458097138515316 | validation: 0.01101753201129648]
	TIME [epoch: 19.1 sec]
EPOCH 137/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01137912205762599		[learning rate: 0.0026404]
	Learning Rate: 0.00264038
	LOSS [training: 0.01137912205762599 | validation: 0.011151336821916281]
	TIME [epoch: 19 sec]
EPOCH 138/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011693657827010507		[learning rate: 0.0026002]
	Learning Rate: 0.00260016
	LOSS [training: 0.011693657827010507 | validation: 0.011178031330850786]
	TIME [epoch: 19.1 sec]
EPOCH 139/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01110366030337525		[learning rate: 0.0025606]
	Learning Rate: 0.00256055
	LOSS [training: 0.01110366030337525 | validation: 0.010964863580070013]
	TIME [epoch: 19 sec]
EPOCH 140/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011219119925432005		[learning rate: 0.0025215]
	Learning Rate: 0.00252154
	LOSS [training: 0.011219119925432005 | validation: 0.010951719728561427]
	TIME [epoch: 19.1 sec]
EPOCH 141/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011271722697720504		[learning rate: 0.0024831]
	Learning Rate: 0.00248313
	LOSS [training: 0.011271722697720504 | validation: 0.010868547811371828]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_141.pth
	Model improved!!!
EPOCH 142/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011410971065499305		[learning rate: 0.0024453]
	Learning Rate: 0.00244531
	LOSS [training: 0.011410971065499305 | validation: 0.011045541171489204]
	TIME [epoch: 19.1 sec]
EPOCH 143/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011201976636392233		[learning rate: 0.0024081]
	Learning Rate: 0.00240806
	LOSS [training: 0.011201976636392233 | validation: 0.010660399724917112]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_143.pth
	Model improved!!!
EPOCH 144/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011054347676370464		[learning rate: 0.0023714]
	Learning Rate: 0.00237137
	LOSS [training: 0.011054347676370464 | validation: 0.01097015813844621]
	TIME [epoch: 19.1 sec]
EPOCH 145/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01084622989680976		[learning rate: 0.0023352]
	Learning Rate: 0.00233525
	LOSS [training: 0.01084622989680976 | validation: 0.010491326473038767]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010842880802436214		[learning rate: 0.0022997]
	Learning Rate: 0.00229968
	LOSS [training: 0.010842880802436214 | validation: 0.01092023540268278]
	TIME [epoch: 19 sec]
EPOCH 147/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01112104563797887		[learning rate: 0.0022646]
	Learning Rate: 0.00226464
	LOSS [training: 0.01112104563797887 | validation: 0.011215556024478802]
	TIME [epoch: 19.1 sec]
EPOCH 148/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011127742509890626		[learning rate: 0.0022301]
	Learning Rate: 0.00223015
	LOSS [training: 0.011127742509890626 | validation: 0.010597629123055303]
	TIME [epoch: 19.1 sec]
EPOCH 149/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010716982182588108		[learning rate: 0.0021962]
	Learning Rate: 0.00219617
	LOSS [training: 0.010716982182588108 | validation: 0.01069714640317547]
	TIME [epoch: 19 sec]
EPOCH 150/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010759681373327917		[learning rate: 0.0021627]
	Learning Rate: 0.00216272
	LOSS [training: 0.010759681373327917 | validation: 0.010423260058349301]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_150.pth
	Model improved!!!
EPOCH 151/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01069117781384531		[learning rate: 0.0021298]
	Learning Rate: 0.00212977
	LOSS [training: 0.01069117781384531 | validation: 0.010379923214905776]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_151.pth
	Model improved!!!
EPOCH 152/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010672396333689514		[learning rate: 0.0020973]
	Learning Rate: 0.00209733
	LOSS [training: 0.010672396333689514 | validation: 0.010785943017750687]
	TIME [epoch: 19.1 sec]
EPOCH 153/500:
	Training over batches...
		[batch 4/4] avg loss: 0.011362057646311265		[learning rate: 0.0020654]
	Learning Rate: 0.00206538
	LOSS [training: 0.011362057646311265 | validation: 0.010193598908919807]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_153.pth
	Model improved!!!
EPOCH 154/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010507808021252106		[learning rate: 0.0020339]
	Learning Rate: 0.00203392
	LOSS [training: 0.010507808021252106 | validation: 0.00998205569581076]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01055475669496967		[learning rate: 0.0020029]
	Learning Rate: 0.00200293
	LOSS [training: 0.01055475669496967 | validation: 0.010287519823008861]
	TIME [epoch: 19.1 sec]
EPOCH 156/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010683933409964552		[learning rate: 0.0019724]
	Learning Rate: 0.00197242
	LOSS [training: 0.010683933409964552 | validation: 0.010221049232489371]
	TIME [epoch: 19.1 sec]
EPOCH 157/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010517106698977808		[learning rate: 0.0019424]
	Learning Rate: 0.00194238
	LOSS [training: 0.010517106698977808 | validation: 0.009845300732580897]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_157.pth
	Model improved!!!
EPOCH 158/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010271962740789998		[learning rate: 0.0019128]
	Learning Rate: 0.00191279
	LOSS [training: 0.010271962740789998 | validation: 0.010217098603946397]
	TIME [epoch: 19 sec]
EPOCH 159/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010419920400555997		[learning rate: 0.0018836]
	Learning Rate: 0.00188365
	LOSS [training: 0.010419920400555997 | validation: 0.010658132344245355]
	TIME [epoch: 19.1 sec]
EPOCH 160/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010802039399847875		[learning rate: 0.001855]
	Learning Rate: 0.00185495
	LOSS [training: 0.010802039399847875 | validation: 0.010286239824299612]
	TIME [epoch: 19 sec]
EPOCH 161/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010327061781773948		[learning rate: 0.0018267]
	Learning Rate: 0.0018267
	LOSS [training: 0.010327061781773948 | validation: 0.01000540005870402]
	TIME [epoch: 19 sec]
EPOCH 162/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01030618892111072		[learning rate: 0.0017989]
	Learning Rate: 0.00179887
	LOSS [training: 0.01030618892111072 | validation: 0.00995775227636727]
	TIME [epoch: 19.1 sec]
EPOCH 163/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010425181979257766		[learning rate: 0.0017715]
	Learning Rate: 0.00177147
	LOSS [training: 0.010425181979257766 | validation: 0.010350153608232479]
	TIME [epoch: 19 sec]
EPOCH 164/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010323623154992825		[learning rate: 0.0017445]
	Learning Rate: 0.00174448
	LOSS [training: 0.010323623154992825 | validation: 0.009981000461546676]
	TIME [epoch: 19 sec]
EPOCH 165/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010204088078492837		[learning rate: 0.0017179]
	Learning Rate: 0.00171791
	LOSS [training: 0.010204088078492837 | validation: 0.009778201384927056]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_165.pth
	Model improved!!!
EPOCH 166/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010155938345651906		[learning rate: 0.0016917]
	Learning Rate: 0.00169174
	LOSS [training: 0.010155938345651906 | validation: 0.009712718388679079]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_166.pth
	Model improved!!!
EPOCH 167/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010163594768666136		[learning rate: 0.001666]
	Learning Rate: 0.00166597
	LOSS [training: 0.010163594768666136 | validation: 0.010268667523337875]
	TIME [epoch: 19 sec]
EPOCH 168/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010522239981135198		[learning rate: 0.0016406]
	Learning Rate: 0.00164059
	LOSS [training: 0.010522239981135198 | validation: 0.010013014263963902]
	TIME [epoch: 19 sec]
EPOCH 169/500:
	Training over batches...
		[batch 4/4] avg loss: 0.01006886864217215		[learning rate: 0.0016156]
	Learning Rate: 0.0016156
	LOSS [training: 0.01006886864217215 | validation: 0.009875766520478457]
	TIME [epoch: 19 sec]
EPOCH 170/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00998685772184878		[learning rate: 0.001591]
	Learning Rate: 0.00159099
	LOSS [training: 0.00998685772184878 | validation: 0.009417269751346595]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_170.pth
	Model improved!!!
EPOCH 171/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009992485991371263		[learning rate: 0.0015668]
	Learning Rate: 0.00156675
	LOSS [training: 0.009992485991371263 | validation: 0.00976862857691059]
	TIME [epoch: 19.1 sec]
EPOCH 172/500:
	Training over batches...
		[batch 4/4] avg loss: 0.010023310928743003		[learning rate: 0.0015429]
	Learning Rate: 0.00154288
	LOSS [training: 0.010023310928743003 | validation: 0.009691617803067095]
	TIME [epoch: 19 sec]
EPOCH 173/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009917541264464046		[learning rate: 0.0015194]
	Learning Rate: 0.00151938
	LOSS [training: 0.009917541264464046 | validation: 0.009386573301568429]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_173.pth
	Model improved!!!
EPOCH 174/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009879015618150966		[learning rate: 0.0014962]
	Learning Rate: 0.00149624
	LOSS [training: 0.009879015618150966 | validation: 0.009396874601516506]
	TIME [epoch: 19.1 sec]
EPOCH 175/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00982331296101159		[learning rate: 0.0014734]
	Learning Rate: 0.00147344
	LOSS [training: 0.00982331296101159 | validation: 0.00963424831629759]
	TIME [epoch: 19 sec]
EPOCH 176/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009857653960866204		[learning rate: 0.001451]
	Learning Rate: 0.001451
	LOSS [training: 0.009857653960866204 | validation: 0.009781758462333447]
	TIME [epoch: 19.1 sec]
EPOCH 177/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009801367755520691		[learning rate: 0.0014289]
	Learning Rate: 0.00142889
	LOSS [training: 0.009801367755520691 | validation: 0.00954069497490896]
	TIME [epoch: 19 sec]
EPOCH 178/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009950850249220879		[learning rate: 0.0014071]
	Learning Rate: 0.00140713
	LOSS [training: 0.009950850249220879 | validation: 0.009568596029215646]
	TIME [epoch: 19.1 sec]
EPOCH 179/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009683844010779694		[learning rate: 0.0013857]
	Learning Rate: 0.00138569
	LOSS [training: 0.009683844010779694 | validation: 0.009194215091733085]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_179.pth
	Model improved!!!
EPOCH 180/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009707703094235819		[learning rate: 0.0013646]
	Learning Rate: 0.00136458
	LOSS [training: 0.009707703094235819 | validation: 0.009129326336773304]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_180.pth
	Model improved!!!
EPOCH 181/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00977237827806509		[learning rate: 0.0013438]
	Learning Rate: 0.0013438
	LOSS [training: 0.00977237827806509 | validation: 0.009340928731691985]
	TIME [epoch: 19.1 sec]
EPOCH 182/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009801850593591798		[learning rate: 0.0013233]
	Learning Rate: 0.00132333
	LOSS [training: 0.009801850593591798 | validation: 0.009084789647686158]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_182.pth
	Model improved!!!
EPOCH 183/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00956797458331858		[learning rate: 0.0013032]
	Learning Rate: 0.00130317
	LOSS [training: 0.00956797458331858 | validation: 0.009217812596755477]
	TIME [epoch: 19.1 sec]
EPOCH 184/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009543979008610917		[learning rate: 0.0012833]
	Learning Rate: 0.00128332
	LOSS [training: 0.009543979008610917 | validation: 0.009115444526123409]
	TIME [epoch: 19.1 sec]
EPOCH 185/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009500978750105572		[learning rate: 0.0012638]
	Learning Rate: 0.00126377
	LOSS [training: 0.009500978750105572 | validation: 0.00955157430027254]
	TIME [epoch: 19.1 sec]
EPOCH 186/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009740187006400662		[learning rate: 0.0012445]
	Learning Rate: 0.00124451
	LOSS [training: 0.009740187006400662 | validation: 0.00931934602289065]
	TIME [epoch: 19.1 sec]
EPOCH 187/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009515120152182498		[learning rate: 0.0012256]
	Learning Rate: 0.00122556
	LOSS [training: 0.009515120152182498 | validation: 0.009221435756536557]
	TIME [epoch: 19.1 sec]
EPOCH 188/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009497974163391841		[learning rate: 0.0012069]
	Learning Rate: 0.00120689
	LOSS [training: 0.009497974163391841 | validation: 0.008920108634882552]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_188.pth
	Model improved!!!
EPOCH 189/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00956595122071086		[learning rate: 0.0011885]
	Learning Rate: 0.0011885
	LOSS [training: 0.00956595122071086 | validation: 0.009216855465334692]
	TIME [epoch: 19 sec]
EPOCH 190/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009522986166613368		[learning rate: 0.0011704]
	Learning Rate: 0.0011704
	LOSS [training: 0.009522986166613368 | validation: 0.008941440976148945]
	TIME [epoch: 19.1 sec]
EPOCH 191/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009410074597449988		[learning rate: 0.0011526]
	Learning Rate: 0.00115257
	LOSS [training: 0.009410074597449988 | validation: 0.008795714820127889]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_191.pth
	Model improved!!!
EPOCH 192/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00932809824474494		[learning rate: 0.001135]
	Learning Rate: 0.00113501
	LOSS [training: 0.00932809824474494 | validation: 0.008966126946550797]
	TIME [epoch: 19.1 sec]
EPOCH 193/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009366137056293479		[learning rate: 0.0011177]
	Learning Rate: 0.00111772
	LOSS [training: 0.009366137056293479 | validation: 0.00887315118703783]
	TIME [epoch: 19.1 sec]
EPOCH 194/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009216552812711552		[learning rate: 0.0011007]
	Learning Rate: 0.00110069
	LOSS [training: 0.009216552812711552 | validation: 0.008922626224988205]
	TIME [epoch: 19.1 sec]
EPOCH 195/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009454317857988762		[learning rate: 0.0010839]
	Learning Rate: 0.00108393
	LOSS [training: 0.009454317857988762 | validation: 0.009154491151168497]
	TIME [epoch: 19.1 sec]
EPOCH 196/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009329435304587205		[learning rate: 0.0010674]
	Learning Rate: 0.00106741
	LOSS [training: 0.009329435304587205 | validation: 0.008816717730019089]
	TIME [epoch: 19 sec]
EPOCH 197/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009243304490105363		[learning rate: 0.0010512]
	Learning Rate: 0.00105115
	LOSS [training: 0.009243304490105363 | validation: 0.008825150493122384]
	TIME [epoch: 19.1 sec]
EPOCH 198/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009170707964306902		[learning rate: 0.0010351]
	Learning Rate: 0.00103514
	LOSS [training: 0.009170707964306902 | validation: 0.008677372734067379]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_198.pth
	Model improved!!!
EPOCH 199/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009204588194879118		[learning rate: 0.0010194]
	Learning Rate: 0.00101937
	LOSS [training: 0.009204588194879118 | validation: 0.008916605088456903]
	TIME [epoch: 19.2 sec]
EPOCH 200/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009227856277230313		[learning rate: 0.0010038]
	Learning Rate: 0.00100384
	LOSS [training: 0.009227856277230313 | validation: 0.008740167189480959]
	TIME [epoch: 19.1 sec]
EPOCH 201/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00915891118440426		[learning rate: 0.00098855]
	Learning Rate: 0.000988553
	LOSS [training: 0.00915891118440426 | validation: 0.008710581363100779]
	TIME [epoch: 19.1 sec]
EPOCH 202/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009071685129145333		[learning rate: 0.00097349]
	Learning Rate: 0.000973494
	LOSS [training: 0.009071685129145333 | validation: 0.008572135646864078]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_202.pth
	Model improved!!!
EPOCH 203/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009085630105454894		[learning rate: 0.00095866]
	Learning Rate: 0.000958664
	LOSS [training: 0.009085630105454894 | validation: 0.008746369256513134]
	TIME [epoch: 19.1 sec]
EPOCH 204/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009051822092041403		[learning rate: 0.00094406]
	Learning Rate: 0.000944061
	LOSS [training: 0.009051822092041403 | validation: 0.008409957901628018]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_204.pth
	Model improved!!!
EPOCH 205/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009056487077508186		[learning rate: 0.00092968]
	Learning Rate: 0.00092968
	LOSS [training: 0.009056487077508186 | validation: 0.008540310527101292]
	TIME [epoch: 19.1 sec]
EPOCH 206/500:
	Training over batches...
		[batch 4/4] avg loss: 0.009015562519852268		[learning rate: 0.00091552]
	Learning Rate: 0.000915518
	LOSS [training: 0.009015562519852268 | validation: 0.00848714359535439]
	TIME [epoch: 19 sec]
EPOCH 207/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008999603032041767		[learning rate: 0.00090157]
	Learning Rate: 0.000901571
	LOSS [training: 0.008999603032041767 | validation: 0.008708235774855425]
	TIME [epoch: 19.1 sec]
EPOCH 208/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00897138477705806		[learning rate: 0.00088784]
	Learning Rate: 0.000887837
	LOSS [training: 0.00897138477705806 | validation: 0.008450465400886856]
	TIME [epoch: 19 sec]
EPOCH 209/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008920348106955207		[learning rate: 0.00087431]
	Learning Rate: 0.000874312
	LOSS [training: 0.008920348106955207 | validation: 0.008519382098003458]
	TIME [epoch: 19.1 sec]
EPOCH 210/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008896458327499279		[learning rate: 0.00086099]
	Learning Rate: 0.000860994
	LOSS [training: 0.008896458327499279 | validation: 0.008520345369831959]
	TIME [epoch: 19 sec]
EPOCH 211/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008843885735748847		[learning rate: 0.00084788]
	Learning Rate: 0.000847878
	LOSS [training: 0.008843885735748847 | validation: 0.008482329118616013]
	TIME [epoch: 19.1 sec]
EPOCH 212/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008897489611536413		[learning rate: 0.00083496]
	Learning Rate: 0.000834962
	LOSS [training: 0.008897489611536413 | validation: 0.0084674757277542]
	TIME [epoch: 19 sec]
EPOCH 213/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008841045640592385		[learning rate: 0.00082224]
	Learning Rate: 0.000822243
	LOSS [training: 0.008841045640592385 | validation: 0.008332410779994462]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_213.pth
	Model improved!!!
EPOCH 214/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008704506040271648		[learning rate: 0.00080972]
	Learning Rate: 0.000809717
	LOSS [training: 0.008704506040271648 | validation: 0.008220601657371316]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_214.pth
	Model improved!!!
EPOCH 215/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008815533818391336		[learning rate: 0.00079738]
	Learning Rate: 0.000797382
	LOSS [training: 0.008815533818391336 | validation: 0.008282883973400141]
	TIME [epoch: 18.9 sec]
EPOCH 216/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008784755367005924		[learning rate: 0.00078524]
	Learning Rate: 0.000785236
	LOSS [training: 0.008784755367005924 | validation: 0.00826437792755487]
	TIME [epoch: 18.8 sec]
EPOCH 217/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008648555776514454		[learning rate: 0.00077327]
	Learning Rate: 0.000773274
	LOSS [training: 0.008648555776514454 | validation: 0.008288241283826651]
	TIME [epoch: 18.8 sec]
EPOCH 218/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008718521535396487		[learning rate: 0.00076149]
	Learning Rate: 0.000761494
	LOSS [training: 0.008718521535396487 | validation: 0.008424045228269533]
	TIME [epoch: 19 sec]
EPOCH 219/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00872093668846711		[learning rate: 0.00074989]
	Learning Rate: 0.000749894
	LOSS [training: 0.00872093668846711 | validation: 0.008447859222484783]
	TIME [epoch: 19 sec]
EPOCH 220/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008652588954368757		[learning rate: 0.00073847]
	Learning Rate: 0.000738471
	LOSS [training: 0.008652588954368757 | validation: 0.008212965815856454]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_220.pth
	Model improved!!!
EPOCH 221/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00857250606356724		[learning rate: 0.00072722]
	Learning Rate: 0.000727221
	LOSS [training: 0.00857250606356724 | validation: 0.008329416093520108]
	TIME [epoch: 19.1 sec]
EPOCH 222/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008622203247560316		[learning rate: 0.00071614]
	Learning Rate: 0.000716143
	LOSS [training: 0.008622203247560316 | validation: 0.008326147737214695]
	TIME [epoch: 19 sec]
EPOCH 223/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008566653971078808		[learning rate: 0.00070523]
	Learning Rate: 0.000705234
	LOSS [training: 0.008566653971078808 | validation: 0.008108917742212967]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_223.pth
	Model improved!!!
EPOCH 224/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008558806856406732		[learning rate: 0.00069449]
	Learning Rate: 0.000694491
	LOSS [training: 0.008558806856406732 | validation: 0.007849899233050128]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_224.pth
	Model improved!!!
EPOCH 225/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008592901423880717		[learning rate: 0.00068391]
	Learning Rate: 0.000683912
	LOSS [training: 0.008592901423880717 | validation: 0.008140208371338756]
	TIME [epoch: 19.1 sec]
EPOCH 226/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008497334317818298		[learning rate: 0.00067349]
	Learning Rate: 0.000673493
	LOSS [training: 0.008497334317818298 | validation: 0.007929387502852358]
	TIME [epoch: 19.1 sec]
EPOCH 227/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008523640113379357		[learning rate: 0.00066323]
	Learning Rate: 0.000663234
	LOSS [training: 0.008523640113379357 | validation: 0.007934742985594316]
	TIME [epoch: 19 sec]
EPOCH 228/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008454025494018858		[learning rate: 0.00065313]
	Learning Rate: 0.00065313
	LOSS [training: 0.008454025494018858 | validation: 0.007824122034680936]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_228.pth
	Model improved!!!
EPOCH 229/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008390171451187563		[learning rate: 0.00064318]
	Learning Rate: 0.000643181
	LOSS [training: 0.008390171451187563 | validation: 0.008046952147042388]
	TIME [epoch: 19 sec]
EPOCH 230/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008401043796121308		[learning rate: 0.00063338]
	Learning Rate: 0.000633383
	LOSS [training: 0.008401043796121308 | validation: 0.007893233857986272]
	TIME [epoch: 19.1 sec]
EPOCH 231/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00842714975466162		[learning rate: 0.00062373]
	Learning Rate: 0.000623735
	LOSS [training: 0.00842714975466162 | validation: 0.007846553761465572]
	TIME [epoch: 19 sec]
EPOCH 232/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0084174687721633		[learning rate: 0.00061423]
	Learning Rate: 0.000614233
	LOSS [training: 0.0084174687721633 | validation: 0.007867730069526832]
	TIME [epoch: 19.1 sec]
EPOCH 233/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00835548123538623		[learning rate: 0.00060488]
	Learning Rate: 0.000604876
	LOSS [training: 0.00835548123538623 | validation: 0.007866845697759932]
	TIME [epoch: 19.1 sec]
EPOCH 234/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008323636143007436		[learning rate: 0.00059566]
	Learning Rate: 0.000595662
	LOSS [training: 0.008323636143007436 | validation: 0.007798919750362204]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_234.pth
	Model improved!!!
EPOCH 235/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008310520537996751		[learning rate: 0.00058659]
	Learning Rate: 0.000586588
	LOSS [training: 0.008310520537996751 | validation: 0.007667490168451642]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_235.pth
	Model improved!!!
EPOCH 236/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00831649253871128		[learning rate: 0.00057765]
	Learning Rate: 0.000577652
	LOSS [training: 0.00831649253871128 | validation: 0.00774929794765053]
	TIME [epoch: 19 sec]
EPOCH 237/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008274709150468821		[learning rate: 0.00056885]
	Learning Rate: 0.000568853
	LOSS [training: 0.008274709150468821 | validation: 0.007656555812509462]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_237.pth
	Model improved!!!
EPOCH 238/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00836706805730752		[learning rate: 0.00056019]
	Learning Rate: 0.000560187
	LOSS [training: 0.00836706805730752 | validation: 0.0075486662225326615]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_238.pth
	Model improved!!!
EPOCH 239/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00819811715318789		[learning rate: 0.00055165]
	Learning Rate: 0.000551654
	LOSS [training: 0.00819811715318789 | validation: 0.007860631533481146]
	TIME [epoch: 19 sec]
EPOCH 240/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008154956301657633		[learning rate: 0.00054325]
	Learning Rate: 0.00054325
	LOSS [training: 0.008154956301657633 | validation: 0.007679901753636852]
	TIME [epoch: 19 sec]
EPOCH 241/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008216315519887878		[learning rate: 0.00053497]
	Learning Rate: 0.000534975
	LOSS [training: 0.008216315519887878 | validation: 0.00767935973113898]
	TIME [epoch: 19 sec]
EPOCH 242/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008235527071852657		[learning rate: 0.00052683]
	Learning Rate: 0.000526825
	LOSS [training: 0.008235527071852657 | validation: 0.007612190299679397]
	TIME [epoch: 19 sec]
EPOCH 243/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008117819076138334		[learning rate: 0.0005188]
	Learning Rate: 0.0005188
	LOSS [training: 0.008117819076138334 | validation: 0.007636628874682517]
	TIME [epoch: 19 sec]
EPOCH 244/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008152214310132154		[learning rate: 0.0005109]
	Learning Rate: 0.000510897
	LOSS [training: 0.008152214310132154 | validation: 0.007589011324483955]
	TIME [epoch: 19 sec]
EPOCH 245/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008168708672495747		[learning rate: 0.00050311]
	Learning Rate: 0.000503114
	LOSS [training: 0.008168708672495747 | validation: 0.007569489521703688]
	TIME [epoch: 19.1 sec]
EPOCH 246/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008071712819638706		[learning rate: 0.00049545]
	Learning Rate: 0.00049545
	LOSS [training: 0.008071712819638706 | validation: 0.0076042921185160185]
	TIME [epoch: 19 sec]
EPOCH 247/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008058368702334597		[learning rate: 0.0004879]
	Learning Rate: 0.000487903
	LOSS [training: 0.008058368702334597 | validation: 0.0076082489179003536]
	TIME [epoch: 19.1 sec]
EPOCH 248/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00802398491739358		[learning rate: 0.00048047]
	Learning Rate: 0.00048047
	LOSS [training: 0.00802398491739358 | validation: 0.007603400347956941]
	TIME [epoch: 19 sec]
EPOCH 249/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00811124186517189		[learning rate: 0.00047315]
	Learning Rate: 0.000473151
	LOSS [training: 0.00811124186517189 | validation: 0.0075897818688448184]
	TIME [epoch: 19 sec]
EPOCH 250/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007985401201872017		[learning rate: 0.00046594]
	Learning Rate: 0.000465944
	LOSS [training: 0.007985401201872017 | validation: 0.0075370676583954195]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_250.pth
	Model improved!!!
EPOCH 251/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00800843254993833		[learning rate: 0.00045885]
	Learning Rate: 0.000458846
	LOSS [training: 0.00800843254993833 | validation: 0.007284612835788781]
	TIME [epoch: 136 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_251.pth
	Model improved!!!
EPOCH 252/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007957060428033617		[learning rate: 0.00045186]
	Learning Rate: 0.000451856
	LOSS [training: 0.007957060428033617 | validation: 0.00726072825151602]
	TIME [epoch: 42.5 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_252.pth
	Model improved!!!
EPOCH 253/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008031989161087608		[learning rate: 0.00044497]
	Learning Rate: 0.000444973
	LOSS [training: 0.008031989161087608 | validation: 0.00743371933747043]
	TIME [epoch: 42.3 sec]
EPOCH 254/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007972186237183045		[learning rate: 0.00043819]
	Learning Rate: 0.000438194
	LOSS [training: 0.007972186237183045 | validation: 0.007313944492041443]
	TIME [epoch: 42.3 sec]
EPOCH 255/500:
	Training over batches...
		[batch 4/4] avg loss: 0.008016155564946031		[learning rate: 0.00043152]
	Learning Rate: 0.000431519
	LOSS [training: 0.008016155564946031 | validation: 0.007406394372848757]
	TIME [epoch: 42.4 sec]
EPOCH 256/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007943619411006672		[learning rate: 0.00042495]
	Learning Rate: 0.000424946
	LOSS [training: 0.007943619411006672 | validation: 0.007590322680653166]
	TIME [epoch: 42.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007908621304314375		[learning rate: 0.00041847]
	Learning Rate: 0.000418472
	LOSS [training: 0.007908621304314375 | validation: 0.007304983175164456]
	TIME [epoch: 42.4 sec]
EPOCH 258/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007867705257966177		[learning rate: 0.0004121]
	Learning Rate: 0.000412098
	LOSS [training: 0.007867705257966177 | validation: 0.007274086846973948]
	TIME [epoch: 42.4 sec]
EPOCH 259/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007874013775675287		[learning rate: 0.00040582]
	Learning Rate: 0.00040582
	LOSS [training: 0.007874013775675287 | validation: 0.007226681732665895]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_259.pth
	Model improved!!!
EPOCH 260/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007892074512597122		[learning rate: 0.00039964]
	Learning Rate: 0.000399638
	LOSS [training: 0.007892074512597122 | validation: 0.007265312431141426]
	TIME [epoch: 42.4 sec]
EPOCH 261/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007945374339594816		[learning rate: 0.00039355]
	Learning Rate: 0.00039355
	LOSS [training: 0.007945374339594816 | validation: 0.007204803796835543]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_261.pth
	Model improved!!!
EPOCH 262/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00786548857507482		[learning rate: 0.00038755]
	Learning Rate: 0.000387555
	LOSS [training: 0.00786548857507482 | validation: 0.007301842506513459]
	TIME [epoch: 42.4 sec]
EPOCH 263/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00784104425783696		[learning rate: 0.00038165]
	Learning Rate: 0.000381651
	LOSS [training: 0.00784104425783696 | validation: 0.0073697222749407425]
	TIME [epoch: 42.4 sec]
EPOCH 264/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00775081000489414		[learning rate: 0.00037584]
	Learning Rate: 0.000375837
	LOSS [training: 0.00775081000489414 | validation: 0.0071384017368450875]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_264.pth
	Model improved!!!
EPOCH 265/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007723031699751871		[learning rate: 0.00037011]
	Learning Rate: 0.000370112
	LOSS [training: 0.007723031699751871 | validation: 0.0072677871636174125]
	TIME [epoch: 42.2 sec]
EPOCH 266/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007696995921012203		[learning rate: 0.00036447]
	Learning Rate: 0.000364474
	LOSS [training: 0.007696995921012203 | validation: 0.007116498833654969]
	TIME [epoch: 42.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_266.pth
	Model improved!!!
EPOCH 267/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0077416377060843975		[learning rate: 0.00035892]
	Learning Rate: 0.000358922
	LOSS [training: 0.0077416377060843975 | validation: 0.007051954617838461]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_267.pth
	Model improved!!!
EPOCH 268/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007774825726636186		[learning rate: 0.00035345]
	Learning Rate: 0.000353454
	LOSS [training: 0.007774825726636186 | validation: 0.007058178738295191]
	TIME [epoch: 42.3 sec]
EPOCH 269/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007728468659307245		[learning rate: 0.00034807]
	Learning Rate: 0.00034807
	LOSS [training: 0.007728468659307245 | validation: 0.00713159831161319]
	TIME [epoch: 42.2 sec]
EPOCH 270/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007720348489353871		[learning rate: 0.00034277]
	Learning Rate: 0.000342768
	LOSS [training: 0.007720348489353871 | validation: 0.007143241484440235]
	TIME [epoch: 42.3 sec]
EPOCH 271/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00766018052323061		[learning rate: 0.00033755]
	Learning Rate: 0.000337546
	LOSS [training: 0.00766018052323061 | validation: 0.007067141749642052]
	TIME [epoch: 42.3 sec]
EPOCH 272/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007671409102820367		[learning rate: 0.0003324]
	Learning Rate: 0.000332404
	LOSS [training: 0.007671409102820367 | validation: 0.006940931861308666]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_272.pth
	Model improved!!!
EPOCH 273/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007758045388173934		[learning rate: 0.00032734]
	Learning Rate: 0.000327341
	LOSS [training: 0.007758045388173934 | validation: 0.007075137430448932]
	TIME [epoch: 42.4 sec]
EPOCH 274/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007663860549235235		[learning rate: 0.00032235]
	Learning Rate: 0.000322354
	LOSS [training: 0.007663860549235235 | validation: 0.007087879831220348]
	TIME [epoch: 42.4 sec]
EPOCH 275/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007662168076172637		[learning rate: 0.00031744]
	Learning Rate: 0.000317444
	LOSS [training: 0.007662168076172637 | validation: 0.007084011442155166]
	TIME [epoch: 42.4 sec]
EPOCH 276/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007635799120180051		[learning rate: 0.00031261]
	Learning Rate: 0.000312608
	LOSS [training: 0.007635799120180051 | validation: 0.006984101943933658]
	TIME [epoch: 42.3 sec]
EPOCH 277/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007579642876218642		[learning rate: 0.00030785]
	Learning Rate: 0.000307846
	LOSS [training: 0.007579642876218642 | validation: 0.007050599400615403]
	TIME [epoch: 42.4 sec]
EPOCH 278/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007591263196558902		[learning rate: 0.00030316]
	Learning Rate: 0.000303156
	LOSS [training: 0.007591263196558902 | validation: 0.006969666383102902]
	TIME [epoch: 42.4 sec]
EPOCH 279/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00765460681819055		[learning rate: 0.00029854]
	Learning Rate: 0.000298538
	LOSS [training: 0.00765460681819055 | validation: 0.006914584834942445]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_279.pth
	Model improved!!!
EPOCH 280/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007667263410450636		[learning rate: 0.00029399]
	Learning Rate: 0.000293991
	LOSS [training: 0.007667263410450636 | validation: 0.006867503763032421]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_280.pth
	Model improved!!!
EPOCH 281/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007564503951694055		[learning rate: 0.00028951]
	Learning Rate: 0.000289512
	LOSS [training: 0.007564503951694055 | validation: 0.007029914580658471]
	TIME [epoch: 42.4 sec]
EPOCH 282/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007556631244567208		[learning rate: 0.0002851]
	Learning Rate: 0.000285102
	LOSS [training: 0.007556631244567208 | validation: 0.006989236136194759]
	TIME [epoch: 42.3 sec]
EPOCH 283/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007459646002471053		[learning rate: 0.00028076]
	Learning Rate: 0.000280759
	LOSS [training: 0.007459646002471053 | validation: 0.006728510415965519]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_283.pth
	Model improved!!!
EPOCH 284/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007529953300091655		[learning rate: 0.00027648]
	Learning Rate: 0.000276482
	LOSS [training: 0.007529953300091655 | validation: 0.006893459155311319]
	TIME [epoch: 42.3 sec]
EPOCH 285/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007527346774450292		[learning rate: 0.00027227]
	Learning Rate: 0.00027227
	LOSS [training: 0.007527346774450292 | validation: 0.006944152863392988]
	TIME [epoch: 42.3 sec]
EPOCH 286/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0074879403374952585		[learning rate: 0.00026812]
	Learning Rate: 0.000268123
	LOSS [training: 0.0074879403374952585 | validation: 0.00685211242598593]
	TIME [epoch: 42.2 sec]
EPOCH 287/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007423727631353199		[learning rate: 0.00026404]
	Learning Rate: 0.000264038
	LOSS [training: 0.007423727631353199 | validation: 0.006881598464745356]
	TIME [epoch: 42.3 sec]
EPOCH 288/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007494755423341508		[learning rate: 0.00026002]
	Learning Rate: 0.000260016
	LOSS [training: 0.007494755423341508 | validation: 0.006987996687366781]
	TIME [epoch: 42.3 sec]
EPOCH 289/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007496942516597193		[learning rate: 0.00025606]
	Learning Rate: 0.000256055
	LOSS [training: 0.007496942516597193 | validation: 0.006774109695435871]
	TIME [epoch: 42.3 sec]
EPOCH 290/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0074798936736310325		[learning rate: 0.00025215]
	Learning Rate: 0.000252154
	LOSS [training: 0.0074798936736310325 | validation: 0.006812791906396741]
	TIME [epoch: 42.3 sec]
EPOCH 291/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0073905389461529185		[learning rate: 0.00024831]
	Learning Rate: 0.000248313
	LOSS [training: 0.0073905389461529185 | validation: 0.006756460722625453]
	TIME [epoch: 42.3 sec]
EPOCH 292/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007403455617963128		[learning rate: 0.00024453]
	Learning Rate: 0.000244531
	LOSS [training: 0.007403455617963128 | validation: 0.006970619213057924]
	TIME [epoch: 42.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007409256749836786		[learning rate: 0.00024081]
	Learning Rate: 0.000240806
	LOSS [training: 0.007409256749836786 | validation: 0.006867610475464326]
	TIME [epoch: 42.4 sec]
EPOCH 294/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007394782945416428		[learning rate: 0.00023714]
	Learning Rate: 0.000237137
	LOSS [training: 0.007394782945416428 | validation: 0.0067325278787104086]
	TIME [epoch: 42.4 sec]
EPOCH 295/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007424229212972876		[learning rate: 0.00023352]
	Learning Rate: 0.000233525
	LOSS [training: 0.007424229212972876 | validation: 0.006923650309095576]
	TIME [epoch: 42.3 sec]
EPOCH 296/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007401472287846888		[learning rate: 0.00022997]
	Learning Rate: 0.000229968
	LOSS [training: 0.007401472287846888 | validation: 0.0068803818455869786]
	TIME [epoch: 42.3 sec]
EPOCH 297/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007359922280254087		[learning rate: 0.00022646]
	Learning Rate: 0.000226464
	LOSS [training: 0.007359922280254087 | validation: 0.006725267548537619]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_297.pth
	Model improved!!!
EPOCH 298/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007364073769696055		[learning rate: 0.00022301]
	Learning Rate: 0.000223015
	LOSS [training: 0.007364073769696055 | validation: 0.006832240041473177]
	TIME [epoch: 42.3 sec]
EPOCH 299/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0073982748814720774		[learning rate: 0.00021962]
	Learning Rate: 0.000219617
	LOSS [training: 0.0073982748814720774 | validation: 0.006777719640429628]
	TIME [epoch: 42.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007313237861139009		[learning rate: 0.00021627]
	Learning Rate: 0.000216272
	LOSS [training: 0.007313237861139009 | validation: 0.006525127871513366]
	TIME [epoch: 42.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_300.pth
	Model improved!!!
EPOCH 301/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007285773844491152		[learning rate: 0.00021298]
	Learning Rate: 0.000212977
	LOSS [training: 0.007285773844491152 | validation: 0.006730367225775058]
	TIME [epoch: 42.3 sec]
EPOCH 302/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007396830899432022		[learning rate: 0.00020973]
	Learning Rate: 0.000209733
	LOSS [training: 0.007396830899432022 | validation: 0.006883813568740387]
	TIME [epoch: 42.3 sec]
EPOCH 303/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007365696817224996		[learning rate: 0.00020654]
	Learning Rate: 0.000206538
	LOSS [training: 0.007365696817224996 | validation: 0.006482567163334887]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_303.pth
	Model improved!!!
EPOCH 304/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007233587781009281		[learning rate: 0.00020339]
	Learning Rate: 0.000203392
	LOSS [training: 0.007233587781009281 | validation: 0.0065417120712897]
	TIME [epoch: 42.3 sec]
EPOCH 305/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007318212734035557		[learning rate: 0.00020029]
	Learning Rate: 0.000200293
	LOSS [training: 0.007318212734035557 | validation: 0.00666606349038459]
	TIME [epoch: 42.2 sec]
EPOCH 306/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007299281666699491		[learning rate: 0.00019724]
	Learning Rate: 0.000197242
	LOSS [training: 0.007299281666699491 | validation: 0.006497416107227248]
	TIME [epoch: 42.2 sec]
EPOCH 307/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007214123411265795		[learning rate: 0.00019424]
	Learning Rate: 0.000194238
	LOSS [training: 0.007214123411265795 | validation: 0.006835647859641026]
	TIME [epoch: 42.2 sec]
EPOCH 308/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00728692971573525		[learning rate: 0.00019128]
	Learning Rate: 0.000191279
	LOSS [training: 0.00728692971573525 | validation: 0.006508667556565614]
	TIME [epoch: 42.2 sec]
EPOCH 309/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007296022245975001		[learning rate: 0.00018836]
	Learning Rate: 0.000188365
	LOSS [training: 0.007296022245975001 | validation: 0.006619602797426831]
	TIME [epoch: 42.2 sec]
EPOCH 310/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007296310255624459		[learning rate: 0.0001855]
	Learning Rate: 0.000185495
	LOSS [training: 0.007296310255624459 | validation: 0.006646645270670519]
	TIME [epoch: 42.2 sec]
EPOCH 311/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007303067616716387		[learning rate: 0.00018267]
	Learning Rate: 0.00018267
	LOSS [training: 0.007303067616716387 | validation: 0.006680456191316381]
	TIME [epoch: 42.3 sec]
EPOCH 312/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0072406351832363346		[learning rate: 0.00017989]
	Learning Rate: 0.000179887
	LOSS [training: 0.0072406351832363346 | validation: 0.006599027533598799]
	TIME [epoch: 42.4 sec]
EPOCH 313/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00724782451022714		[learning rate: 0.00017715]
	Learning Rate: 0.000177147
	LOSS [training: 0.00724782451022714 | validation: 0.006577494460760766]
	TIME [epoch: 42.4 sec]
EPOCH 314/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0072420095973401806		[learning rate: 0.00017445]
	Learning Rate: 0.000174448
	LOSS [training: 0.0072420095973401806 | validation: 0.006512509010179577]
	TIME [epoch: 42.3 sec]
EPOCH 315/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0072400470461327195		[learning rate: 0.00017179]
	Learning Rate: 0.000171791
	LOSS [training: 0.0072400470461327195 | validation: 0.006499458969412021]
	TIME [epoch: 42.3 sec]
EPOCH 316/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007267411639144249		[learning rate: 0.00016917]
	Learning Rate: 0.000169174
	LOSS [training: 0.007267411639144249 | validation: 0.0065941265404166815]
	TIME [epoch: 42.3 sec]
EPOCH 317/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007189302798894463		[learning rate: 0.0001666]
	Learning Rate: 0.000166597
	LOSS [training: 0.007189302798894463 | validation: 0.0065686698731118355]
	TIME [epoch: 42.3 sec]
EPOCH 318/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007189379253382537		[learning rate: 0.00016406]
	Learning Rate: 0.000164059
	LOSS [training: 0.007189379253382537 | validation: 0.006479029999998415]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_318.pth
	Model improved!!!
EPOCH 319/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007195411486079186		[learning rate: 0.00016156]
	Learning Rate: 0.00016156
	LOSS [training: 0.007195411486079186 | validation: 0.006505473249088001]
	TIME [epoch: 42.3 sec]
EPOCH 320/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0071675483313285975		[learning rate: 0.0001591]
	Learning Rate: 0.000159099
	LOSS [training: 0.0071675483313285975 | validation: 0.0064468224385921735]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_320.pth
	Model improved!!!
EPOCH 321/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0072510823235209		[learning rate: 0.00015668]
	Learning Rate: 0.000156675
	LOSS [training: 0.0072510823235209 | validation: 0.006578296498912971]
	TIME [epoch: 42.3 sec]
EPOCH 322/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007225488794755914		[learning rate: 0.00015429]
	Learning Rate: 0.000154288
	LOSS [training: 0.007225488794755914 | validation: 0.006524465612100548]
	TIME [epoch: 42.3 sec]
EPOCH 323/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0071183144132863935		[learning rate: 0.00015194]
	Learning Rate: 0.000151938
	LOSS [training: 0.0071183144132863935 | validation: 0.006424327436449782]
	TIME [epoch: 42.4 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_323.pth
	Model improved!!!
EPOCH 324/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007155742173562385		[learning rate: 0.00014962]
	Learning Rate: 0.000149624
	LOSS [training: 0.007155742173562385 | validation: 0.00644187846090377]
	TIME [epoch: 42.4 sec]
EPOCH 325/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0072123683758828026		[learning rate: 0.00014734]
	Learning Rate: 0.000147344
	LOSS [training: 0.0072123683758828026 | validation: 0.00651134159439792]
	TIME [epoch: 42.4 sec]
EPOCH 326/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007129702203921904		[learning rate: 0.0001451]
	Learning Rate: 0.0001451
	LOSS [training: 0.007129702203921904 | validation: 0.0065486276004880755]
	TIME [epoch: 42.4 sec]
EPOCH 327/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007188917068420823		[learning rate: 0.00014289]
	Learning Rate: 0.000142889
	LOSS [training: 0.007188917068420823 | validation: 0.006553295315611099]
	TIME [epoch: 42.6 sec]
EPOCH 328/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007080595258159069		[learning rate: 0.00014071]
	Learning Rate: 0.000140713
	LOSS [training: 0.007080595258159069 | validation: 0.006513936248477354]
	TIME [epoch: 42.3 sec]
EPOCH 329/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007123318910972688		[learning rate: 0.00013857]
	Learning Rate: 0.000138569
	LOSS [training: 0.007123318910972688 | validation: 0.0064056984162996645]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_329.pth
	Model improved!!!
EPOCH 330/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007151706246592956		[learning rate: 0.00013646]
	Learning Rate: 0.000136458
	LOSS [training: 0.007151706246592956 | validation: 0.0064965952107989364]
	TIME [epoch: 42.4 sec]
EPOCH 331/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007134203582662606		[learning rate: 0.00013438]
	Learning Rate: 0.00013438
	LOSS [training: 0.007134203582662606 | validation: 0.006625866216298921]
	TIME [epoch: 42.5 sec]
EPOCH 332/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007136985043536126		[learning rate: 0.00013233]
	Learning Rate: 0.000132333
	LOSS [training: 0.007136985043536126 | validation: 0.006313797667604951]
	TIME [epoch: 42.6 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_332.pth
	Model improved!!!
EPOCH 333/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007173675097962778		[learning rate: 0.00013032]
	Learning Rate: 0.000130317
	LOSS [training: 0.007173675097962778 | validation: 0.0064838378395559275]
	TIME [epoch: 42.4 sec]
EPOCH 334/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007111986845933664		[learning rate: 0.00012833]
	Learning Rate: 0.000128332
	LOSS [training: 0.007111986845933664 | validation: 0.006401133457584331]
	TIME [epoch: 42.4 sec]
EPOCH 335/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007086637154619709		[learning rate: 0.00012638]
	Learning Rate: 0.000126377
	LOSS [training: 0.007086637154619709 | validation: 0.006519449182832173]
	TIME [epoch: 42.4 sec]
EPOCH 336/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007025331269626528		[learning rate: 0.00012445]
	Learning Rate: 0.000124451
	LOSS [training: 0.007025331269626528 | validation: 0.006432840411098964]
	TIME [epoch: 42.4 sec]
EPOCH 337/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007071564928891404		[learning rate: 0.00012256]
	Learning Rate: 0.000122556
	LOSS [training: 0.007071564928891404 | validation: 0.006390853323696379]
	TIME [epoch: 42.3 sec]
EPOCH 338/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007079924287610716		[learning rate: 0.00012069]
	Learning Rate: 0.000120689
	LOSS [training: 0.007079924287610716 | validation: 0.0065673045275824295]
	TIME [epoch: 42.3 sec]
EPOCH 339/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007137679052594564		[learning rate: 0.00011885]
	Learning Rate: 0.00011885
	LOSS [training: 0.007137679052594564 | validation: 0.006337720823911402]
	TIME [epoch: 42.4 sec]
EPOCH 340/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006988930996382932		[learning rate: 0.00011704]
	Learning Rate: 0.00011704
	LOSS [training: 0.006988930996382932 | validation: 0.006523814559660694]
	TIME [epoch: 42.4 sec]
EPOCH 341/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0070673733970472545		[learning rate: 0.00011526]
	Learning Rate: 0.000115257
	LOSS [training: 0.0070673733970472545 | validation: 0.00639380411806433]
	TIME [epoch: 42.3 sec]
EPOCH 342/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007092687578833066		[learning rate: 0.0001135]
	Learning Rate: 0.000113501
	LOSS [training: 0.007092687578833066 | validation: 0.006512843446046081]
	TIME [epoch: 42.3 sec]
EPOCH 343/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007069285498706529		[learning rate: 0.00011177]
	Learning Rate: 0.000111772
	LOSS [training: 0.007069285498706529 | validation: 0.0064028776663561954]
	TIME [epoch: 42.3 sec]
EPOCH 344/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007031539087617564		[learning rate: 0.00011007]
	Learning Rate: 0.000110069
	LOSS [training: 0.007031539087617564 | validation: 0.006482234988462975]
	TIME [epoch: 42.3 sec]
EPOCH 345/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006992827071479323		[learning rate: 0.00010839]
	Learning Rate: 0.000108393
	LOSS [training: 0.006992827071479323 | validation: 0.0062516566494559625]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_345.pth
	Model improved!!!
EPOCH 346/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007041756118208841		[learning rate: 0.00010674]
	Learning Rate: 0.000106742
	LOSS [training: 0.007041756118208841 | validation: 0.006367440693198834]
	TIME [epoch: 42.2 sec]
EPOCH 347/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007072672495020873		[learning rate: 0.00010512]
	Learning Rate: 0.000105115
	LOSS [training: 0.007072672495020873 | validation: 0.006244922129195737]
	TIME [epoch: 42.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_347.pth
	Model improved!!!
EPOCH 348/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007131475569430183		[learning rate: 0.00010351]
	Learning Rate: 0.000103514
	LOSS [training: 0.007131475569430183 | validation: 0.006246795304458161]
	TIME [epoch: 42.3 sec]
EPOCH 349/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006915099555002766		[learning rate: 0.00010194]
	Learning Rate: 0.000101937
	LOSS [training: 0.006915099555002766 | validation: 0.006358070508901864]
	TIME [epoch: 42.2 sec]
EPOCH 350/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0070110346966931174		[learning rate: 0.00010038]
	Learning Rate: 0.000100385
	LOSS [training: 0.0070110346966931174 | validation: 0.006331066113193253]
	TIME [epoch: 42.3 sec]
EPOCH 351/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006998750482398661		[learning rate: 9.8855e-05]
	Learning Rate: 9.88553e-05
	LOSS [training: 0.006998750482398661 | validation: 0.006398535312117129]
	TIME [epoch: 42.3 sec]
EPOCH 352/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00703437109491303		[learning rate: 9.7349e-05]
	Learning Rate: 9.73494e-05
	LOSS [training: 0.00703437109491303 | validation: 0.006410755122607591]
	TIME [epoch: 42.4 sec]
EPOCH 353/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007059613959734546		[learning rate: 9.5866e-05]
	Learning Rate: 9.58665e-05
	LOSS [training: 0.007059613959734546 | validation: 0.006284849156136339]
	TIME [epoch: 42.3 sec]
EPOCH 354/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007014287369132684		[learning rate: 9.4406e-05]
	Learning Rate: 9.44061e-05
	LOSS [training: 0.007014287369132684 | validation: 0.006314838464675744]
	TIME [epoch: 42.3 sec]
EPOCH 355/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069605032607098355		[learning rate: 9.2968e-05]
	Learning Rate: 9.2968e-05
	LOSS [training: 0.0069605032607098355 | validation: 0.006249615458309198]
	TIME [epoch: 42.3 sec]
EPOCH 356/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007024134044717228		[learning rate: 9.1552e-05]
	Learning Rate: 9.15518e-05
	LOSS [training: 0.007024134044717228 | validation: 0.006163012291133091]
	TIME [epoch: 42.2 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_356.pth
	Model improved!!!
EPOCH 357/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069715197921666515		[learning rate: 9.0157e-05]
	Learning Rate: 9.01571e-05
	LOSS [training: 0.0069715197921666515 | validation: 0.006392255273886184]
	TIME [epoch: 42.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006950723457286683		[learning rate: 8.8784e-05]
	Learning Rate: 8.87837e-05
	LOSS [training: 0.006950723457286683 | validation: 0.006307344231506987]
	TIME [epoch: 42.3 sec]
EPOCH 359/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069453512181857115		[learning rate: 8.7431e-05]
	Learning Rate: 8.74312e-05
	LOSS [training: 0.0069453512181857115 | validation: 0.0064511801646904045]
	TIME [epoch: 42.2 sec]
EPOCH 360/500:
	Training over batches...
		[batch 4/4] avg loss: 0.007036062951957545		[learning rate: 8.6099e-05]
	Learning Rate: 8.60994e-05
	LOSS [training: 0.007036062951957545 | validation: 0.0062218874262413085]
	TIME [epoch: 42.3 sec]
EPOCH 361/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006912757681073881		[learning rate: 8.4788e-05]
	Learning Rate: 8.47878e-05
	LOSS [training: 0.006912757681073881 | validation: 0.0063922898079346365]
	TIME [epoch: 42.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069720931918400095		[learning rate: 8.3496e-05]
	Learning Rate: 8.34962e-05
	LOSS [training: 0.0069720931918400095 | validation: 0.006336904397906466]
	TIME [epoch: 42.3 sec]
EPOCH 363/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006918840366076231		[learning rate: 8.2224e-05]
	Learning Rate: 8.22243e-05
	LOSS [training: 0.006918840366076231 | validation: 0.006226959585697709]
	TIME [epoch: 42.3 sec]
EPOCH 364/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006941713049565208		[learning rate: 8.0972e-05]
	Learning Rate: 8.09717e-05
	LOSS [training: 0.006941713049565208 | validation: 0.006226797342101587]
	TIME [epoch: 42.3 sec]
EPOCH 365/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006882819417013416		[learning rate: 7.9738e-05]
	Learning Rate: 7.97382e-05
	LOSS [training: 0.006882819417013416 | validation: 0.006245680800402114]
	TIME [epoch: 42.2 sec]
EPOCH 366/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006946519945251997		[learning rate: 7.8524e-05]
	Learning Rate: 7.85235e-05
	LOSS [training: 0.006946519945251997 | validation: 0.006182561122442044]
	TIME [epoch: 42.2 sec]
EPOCH 367/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006936235563905066		[learning rate: 7.7327e-05]
	Learning Rate: 7.73274e-05
	LOSS [training: 0.006936235563905066 | validation: 0.0061965331121445364]
	TIME [epoch: 42.1 sec]
EPOCH 368/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00698664000084606		[learning rate: 7.6149e-05]
	Learning Rate: 7.61494e-05
	LOSS [training: 0.00698664000084606 | validation: 0.006406611350669126]
	TIME [epoch: 42.3 sec]
EPOCH 369/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006851036995362426		[learning rate: 7.4989e-05]
	Learning Rate: 7.49894e-05
	LOSS [training: 0.006851036995362426 | validation: 0.006432160827801981]
	TIME [epoch: 42.3 sec]
EPOCH 370/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00688765529831945		[learning rate: 7.3847e-05]
	Learning Rate: 7.38471e-05
	LOSS [training: 0.00688765529831945 | validation: 0.006185614054493952]
	TIME [epoch: 42.3 sec]
EPOCH 371/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00693550274590288		[learning rate: 7.2722e-05]
	Learning Rate: 7.27221e-05
	LOSS [training: 0.00693550274590288 | validation: 0.0063416106201735385]
	TIME [epoch: 42.3 sec]
EPOCH 372/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006912749271017579		[learning rate: 7.1614e-05]
	Learning Rate: 7.16143e-05
	LOSS [training: 0.006912749271017579 | validation: 0.006417700507960698]
	TIME [epoch: 42.2 sec]
EPOCH 373/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0069396602006418775		[learning rate: 7.0523e-05]
	Learning Rate: 7.05234e-05
	LOSS [training: 0.0069396602006418775 | validation: 0.006175709499665751]
	TIME [epoch: 42.3 sec]
EPOCH 374/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006882901782955128		[learning rate: 6.9449e-05]
	Learning Rate: 6.94491e-05
	LOSS [training: 0.006882901782955128 | validation: 0.006234954277931408]
	TIME [epoch: 42.2 sec]
EPOCH 375/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006962392122820765		[learning rate: 6.8391e-05]
	Learning Rate: 6.83912e-05
	LOSS [training: 0.006962392122820765 | validation: 0.006348599664545722]
	TIME [epoch: 41.9 sec]
EPOCH 376/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006914173901423274		[learning rate: 6.7349e-05]
	Learning Rate: 6.73493e-05
	LOSS [training: 0.006914173901423274 | validation: 0.006258735359542885]
	TIME [epoch: 41.9 sec]
EPOCH 377/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006902591295247784		[learning rate: 6.6323e-05]
	Learning Rate: 6.63234e-05
	LOSS [training: 0.006902591295247784 | validation: 0.0062176689650855505]
	TIME [epoch: 41.7 sec]
EPOCH 378/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006848796770325325		[learning rate: 6.5313e-05]
	Learning Rate: 6.5313e-05
	LOSS [training: 0.006848796770325325 | validation: 0.0063448114103473365]
	TIME [epoch: 41.7 sec]
EPOCH 379/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006840410325463624		[learning rate: 6.4318e-05]
	Learning Rate: 6.43181e-05
	LOSS [training: 0.006840410325463624 | validation: 0.006174512900988443]
	TIME [epoch: 41.7 sec]
EPOCH 380/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006883256111050133		[learning rate: 6.3338e-05]
	Learning Rate: 6.33383e-05
	LOSS [training: 0.006883256111050133 | validation: 0.006184069554870381]
	TIME [epoch: 41.8 sec]
EPOCH 381/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00686197068758861		[learning rate: 6.2373e-05]
	Learning Rate: 6.23735e-05
	LOSS [training: 0.00686197068758861 | validation: 0.006261500036814297]
	TIME [epoch: 41.8 sec]
EPOCH 382/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00689874130475587		[learning rate: 6.1423e-05]
	Learning Rate: 6.14233e-05
	LOSS [training: 0.00689874130475587 | validation: 0.0063440566380938545]
	TIME [epoch: 41.7 sec]
EPOCH 383/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006903594506138967		[learning rate: 6.0488e-05]
	Learning Rate: 6.04876e-05
	LOSS [training: 0.006903594506138967 | validation: 0.006214560668677001]
	TIME [epoch: 41.8 sec]
EPOCH 384/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006904250120834924		[learning rate: 5.9566e-05]
	Learning Rate: 5.95662e-05
	LOSS [training: 0.006904250120834924 | validation: 0.006246084414379703]
	TIME [epoch: 41.8 sec]
EPOCH 385/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006864611815055159		[learning rate: 5.8659e-05]
	Learning Rate: 5.86588e-05
	LOSS [training: 0.006864611815055159 | validation: 0.006063465547383696]
	TIME [epoch: 41.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_385.pth
	Model improved!!!
EPOCH 386/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006854863151011267		[learning rate: 5.7765e-05]
	Learning Rate: 5.77652e-05
	LOSS [training: 0.006854863151011267 | validation: 0.006284917758765449]
	TIME [epoch: 41.8 sec]
EPOCH 387/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006862510850748605		[learning rate: 5.6885e-05]
	Learning Rate: 5.68853e-05
	LOSS [training: 0.006862510850748605 | validation: 0.006157950056767779]
	TIME [epoch: 41.8 sec]
EPOCH 388/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006875048076676513		[learning rate: 5.6019e-05]
	Learning Rate: 5.60187e-05
	LOSS [training: 0.006875048076676513 | validation: 0.006436417000028661]
	TIME [epoch: 41.8 sec]
EPOCH 389/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006818168742536221		[learning rate: 5.5165e-05]
	Learning Rate: 5.51654e-05
	LOSS [training: 0.006818168742536221 | validation: 0.006160734052253243]
	TIME [epoch: 42.1 sec]
EPOCH 390/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006862075092096032		[learning rate: 5.4325e-05]
	Learning Rate: 5.4325e-05
	LOSS [training: 0.006862075092096032 | validation: 0.00619602048422329]
	TIME [epoch: 42.3 sec]
EPOCH 391/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006813305037139829		[learning rate: 5.3497e-05]
	Learning Rate: 5.34975e-05
	LOSS [training: 0.006813305037139829 | validation: 0.005903737394106155]
	TIME [epoch: 42.3 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_391.pth
	Model improved!!!
EPOCH 392/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006891101666819593		[learning rate: 5.2683e-05]
	Learning Rate: 5.26825e-05
	LOSS [training: 0.006891101666819593 | validation: 0.006294923260730294]
	TIME [epoch: 42.6 sec]
EPOCH 393/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006887298946855337		[learning rate: 5.188e-05]
	Learning Rate: 5.188e-05
	LOSS [training: 0.006887298946855337 | validation: 0.006174344697033636]
	TIME [epoch: 42.6 sec]
EPOCH 394/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006926862439170399		[learning rate: 5.109e-05]
	Learning Rate: 5.10897e-05
	LOSS [training: 0.006926862439170399 | validation: 0.006098655635581438]
	TIME [epoch: 42.6 sec]
EPOCH 395/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006832294737182424		[learning rate: 5.0311e-05]
	Learning Rate: 5.03114e-05
	LOSS [training: 0.006832294737182424 | validation: 0.006257653177337858]
	TIME [epoch: 42.6 sec]
EPOCH 396/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006865271110475564		[learning rate: 4.9545e-05]
	Learning Rate: 4.9545e-05
	LOSS [training: 0.006865271110475564 | validation: 0.006102883199901033]
	TIME [epoch: 42.6 sec]
EPOCH 397/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006848976866259674		[learning rate: 4.879e-05]
	Learning Rate: 4.87903e-05
	LOSS [training: 0.006848976866259674 | validation: 0.006023753520515456]
	TIME [epoch: 42.6 sec]
EPOCH 398/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006869070241245848		[learning rate: 4.8047e-05]
	Learning Rate: 4.8047e-05
	LOSS [training: 0.006869070241245848 | validation: 0.0061225239467850075]
	TIME [epoch: 42.6 sec]
EPOCH 399/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006798093462188795		[learning rate: 4.7315e-05]
	Learning Rate: 4.73151e-05
	LOSS [training: 0.006798093462188795 | validation: 0.006301514966689527]
	TIME [epoch: 42.6 sec]
EPOCH 400/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006864343805746584		[learning rate: 4.6594e-05]
	Learning Rate: 4.65944e-05
	LOSS [training: 0.006864343805746584 | validation: 0.006044962761518441]
	TIME [epoch: 42.5 sec]
EPOCH 401/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006837968415013125		[learning rate: 4.5885e-05]
	Learning Rate: 4.58846e-05
	LOSS [training: 0.006837968415013125 | validation: 0.006202874341876309]
	TIME [epoch: 42.5 sec]
EPOCH 402/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006727104810882578		[learning rate: 4.5186e-05]
	Learning Rate: 4.51856e-05
	LOSS [training: 0.006727104810882578 | validation: 0.006123430741339609]
	TIME [epoch: 42.5 sec]
EPOCH 403/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006812867792329718		[learning rate: 4.4497e-05]
	Learning Rate: 4.44973e-05
	LOSS [training: 0.006812867792329718 | validation: 0.006236353214328606]
	TIME [epoch: 42.5 sec]
EPOCH 404/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0068531124696022076		[learning rate: 4.3819e-05]
	Learning Rate: 4.38194e-05
	LOSS [training: 0.0068531124696022076 | validation: 0.00607062454328767]
	TIME [epoch: 42.5 sec]
EPOCH 405/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006804644378964464		[learning rate: 4.3152e-05]
	Learning Rate: 4.31519e-05
	LOSS [training: 0.006804644378964464 | validation: 0.005909025637869901]
	TIME [epoch: 42.5 sec]
EPOCH 406/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006792892720380428		[learning rate: 4.2495e-05]
	Learning Rate: 4.24946e-05
	LOSS [training: 0.006792892720380428 | validation: 0.006011447046575182]
	TIME [epoch: 42.5 sec]
EPOCH 407/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00692018151235704		[learning rate: 4.1847e-05]
	Learning Rate: 4.18472e-05
	LOSS [training: 0.00692018151235704 | validation: 0.006105471898083602]
	TIME [epoch: 42.5 sec]
EPOCH 408/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006867884886762845		[learning rate: 4.121e-05]
	Learning Rate: 4.12098e-05
	LOSS [training: 0.006867884886762845 | validation: 0.0061638669299544785]
	TIME [epoch: 42.5 sec]
EPOCH 409/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0068003573585229595		[learning rate: 4.0582e-05]
	Learning Rate: 4.0582e-05
	LOSS [training: 0.0068003573585229595 | validation: 0.006076121050565838]
	TIME [epoch: 42.2 sec]
EPOCH 410/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067919795878345676		[learning rate: 3.9964e-05]
	Learning Rate: 3.99638e-05
	LOSS [training: 0.0067919795878345676 | validation: 0.006243108310523736]
	TIME [epoch: 41.8 sec]
EPOCH 411/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006860345136080356		[learning rate: 3.9355e-05]
	Learning Rate: 3.9355e-05
	LOSS [training: 0.006860345136080356 | validation: 0.006008230372426343]
	TIME [epoch: 41.8 sec]
EPOCH 412/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006744813117002545		[learning rate: 3.8755e-05]
	Learning Rate: 3.87555e-05
	LOSS [training: 0.006744813117002545 | validation: 0.00614255186245722]
	TIME [epoch: 41.8 sec]
EPOCH 413/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00679098452688863		[learning rate: 3.8165e-05]
	Learning Rate: 3.81651e-05
	LOSS [training: 0.00679098452688863 | validation: 0.006155786733484742]
	TIME [epoch: 41.8 sec]
EPOCH 414/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006829249825248091		[learning rate: 3.7584e-05]
	Learning Rate: 3.75837e-05
	LOSS [training: 0.006829249825248091 | validation: 0.006220643106441315]
	TIME [epoch: 41.8 sec]
EPOCH 415/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006783819863792473		[learning rate: 3.7011e-05]
	Learning Rate: 3.70112e-05
	LOSS [training: 0.006783819863792473 | validation: 0.006146199521855982]
	TIME [epoch: 41.8 sec]
EPOCH 416/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00679583468696289		[learning rate: 3.6447e-05]
	Learning Rate: 3.64474e-05
	LOSS [training: 0.00679583468696289 | validation: 0.0061995326560056775]
	TIME [epoch: 41.8 sec]
EPOCH 417/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006801102610451228		[learning rate: 3.5892e-05]
	Learning Rate: 3.58922e-05
	LOSS [training: 0.006801102610451228 | validation: 0.006126965391063182]
	TIME [epoch: 41.8 sec]
EPOCH 418/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00683208313985512		[learning rate: 3.5345e-05]
	Learning Rate: 3.53454e-05
	LOSS [training: 0.00683208313985512 | validation: 0.006180729778733605]
	TIME [epoch: 41.8 sec]
EPOCH 419/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00685822774904745		[learning rate: 3.4807e-05]
	Learning Rate: 3.4807e-05
	LOSS [training: 0.00685822774904745 | validation: 0.006085672454895379]
	TIME [epoch: 41.8 sec]
EPOCH 420/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006757387260332623		[learning rate: 3.4277e-05]
	Learning Rate: 3.42768e-05
	LOSS [training: 0.006757387260332623 | validation: 0.0061981061052173835]
	TIME [epoch: 41.8 sec]
EPOCH 421/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067838927087460615		[learning rate: 3.3755e-05]
	Learning Rate: 3.37546e-05
	LOSS [training: 0.0067838927087460615 | validation: 0.006230252748771036]
	TIME [epoch: 41.8 sec]
EPOCH 422/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006779094763768066		[learning rate: 3.324e-05]
	Learning Rate: 3.32404e-05
	LOSS [training: 0.006779094763768066 | validation: 0.006219126116024079]
	TIME [epoch: 41.8 sec]
EPOCH 423/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006772689402365258		[learning rate: 3.2734e-05]
	Learning Rate: 3.27341e-05
	LOSS [training: 0.006772689402365258 | validation: 0.006303689503396699]
	TIME [epoch: 41.8 sec]
EPOCH 424/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006853909744533399		[learning rate: 3.2235e-05]
	Learning Rate: 3.22354e-05
	LOSS [training: 0.006853909744533399 | validation: 0.00611402046288559]
	TIME [epoch: 41.9 sec]
EPOCH 425/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067133266353784846		[learning rate: 3.1744e-05]
	Learning Rate: 3.17444e-05
	LOSS [training: 0.0067133266353784846 | validation: 0.0059523539165961285]
	TIME [epoch: 41.8 sec]
EPOCH 426/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006738263893634801		[learning rate: 3.1261e-05]
	Learning Rate: 3.12608e-05
	LOSS [training: 0.006738263893634801 | validation: 0.006033667132342]
	TIME [epoch: 41.9 sec]
EPOCH 427/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006856823356131008		[learning rate: 3.0785e-05]
	Learning Rate: 3.07846e-05
	LOSS [training: 0.006856823356131008 | validation: 0.006006915995262398]
	TIME [epoch: 41.8 sec]
EPOCH 428/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006793989384760312		[learning rate: 3.0316e-05]
	Learning Rate: 3.03156e-05
	LOSS [training: 0.006793989384760312 | validation: 0.005981108594361439]
	TIME [epoch: 41.8 sec]
EPOCH 429/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006758625653416883		[learning rate: 2.9854e-05]
	Learning Rate: 2.98538e-05
	LOSS [training: 0.006758625653416883 | validation: 0.006244390498027521]
	TIME [epoch: 41.8 sec]
EPOCH 430/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006832492970372657		[learning rate: 2.9399e-05]
	Learning Rate: 2.9399e-05
	LOSS [training: 0.006832492970372657 | validation: 0.0061865645869483826]
	TIME [epoch: 41.9 sec]
EPOCH 431/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067241912486120416		[learning rate: 2.8951e-05]
	Learning Rate: 2.89512e-05
	LOSS [training: 0.0067241912486120416 | validation: 0.006099057799812983]
	TIME [epoch: 41.9 sec]
EPOCH 432/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006778366344860572		[learning rate: 2.851e-05]
	Learning Rate: 2.85102e-05
	LOSS [training: 0.006778366344860572 | validation: 0.006187187777249935]
	TIME [epoch: 41.9 sec]
EPOCH 433/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067875932381897775		[learning rate: 2.8076e-05]
	Learning Rate: 2.80759e-05
	LOSS [training: 0.0067875932381897775 | validation: 0.006145104989538413]
	TIME [epoch: 41.9 sec]
EPOCH 434/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006677528457280573		[learning rate: 2.7648e-05]
	Learning Rate: 2.76482e-05
	LOSS [training: 0.006677528457280573 | validation: 0.006346292404872705]
	TIME [epoch: 41.8 sec]
EPOCH 435/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006849338628983162		[learning rate: 2.7227e-05]
	Learning Rate: 2.7227e-05
	LOSS [training: 0.006849338628983162 | validation: 0.006344246376371003]
	TIME [epoch: 41.8 sec]
EPOCH 436/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006753862635845053		[learning rate: 2.6812e-05]
	Learning Rate: 2.68122e-05
	LOSS [training: 0.006753862635845053 | validation: 0.006127706828482503]
	TIME [epoch: 41.8 sec]
EPOCH 437/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006814421148934619		[learning rate: 2.6404e-05]
	Learning Rate: 2.64038e-05
	LOSS [training: 0.006814421148934619 | validation: 0.006111156696303066]
	TIME [epoch: 41.8 sec]
EPOCH 438/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006812150268204956		[learning rate: 2.6002e-05]
	Learning Rate: 2.60016e-05
	LOSS [training: 0.006812150268204956 | validation: 0.006039514122308336]
	TIME [epoch: 41.8 sec]
EPOCH 439/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006751693988635224		[learning rate: 2.5605e-05]
	Learning Rate: 2.56055e-05
	LOSS [training: 0.006751693988635224 | validation: 0.005907027306441698]
	TIME [epoch: 41.8 sec]
EPOCH 440/500:
	Training over batches...
		[batch 4/4] avg loss: 0.00680912720177276		[learning rate: 2.5215e-05]
	Learning Rate: 2.52154e-05
	LOSS [training: 0.00680912720177276 | validation: 0.006039163222179277]
	TIME [epoch: 41.8 sec]
EPOCH 441/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006753041899871885		[learning rate: 2.4831e-05]
	Learning Rate: 2.48313e-05
	LOSS [training: 0.006753041899871885 | validation: 0.006079871914179926]
	TIME [epoch: 41.8 sec]
EPOCH 442/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006825256462763329		[learning rate: 2.4453e-05]
	Learning Rate: 2.44531e-05
	LOSS [training: 0.006825256462763329 | validation: 0.006082552841410495]
	TIME [epoch: 41.8 sec]
EPOCH 443/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006843019947922822		[learning rate: 2.4081e-05]
	Learning Rate: 2.40806e-05
	LOSS [training: 0.006843019947922822 | validation: 0.006157436203899187]
	TIME [epoch: 41.8 sec]
EPOCH 444/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006807660663778795		[learning rate: 2.3714e-05]
	Learning Rate: 2.37137e-05
	LOSS [training: 0.006807660663778795 | validation: 0.006105707413727655]
	TIME [epoch: 41.8 sec]
EPOCH 445/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006773879275784111		[learning rate: 2.3352e-05]
	Learning Rate: 2.33525e-05
	LOSS [training: 0.006773879275784111 | validation: 0.005980124912751657]
	TIME [epoch: 41.8 sec]
EPOCH 446/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006836246330406096		[learning rate: 2.2997e-05]
	Learning Rate: 2.29968e-05
	LOSS [training: 0.006836246330406096 | validation: 0.005950739636821718]
	TIME [epoch: 41.8 sec]
EPOCH 447/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006733806748842607		[learning rate: 2.2646e-05]
	Learning Rate: 2.26464e-05
	LOSS [training: 0.006733806748842607 | validation: 0.006089785290259749]
	TIME [epoch: 41.8 sec]
EPOCH 448/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006776645051209364		[learning rate: 2.2301e-05]
	Learning Rate: 2.23015e-05
	LOSS [training: 0.006776645051209364 | validation: 0.0059920734105397624]
	TIME [epoch: 41.8 sec]
EPOCH 449/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006776515572087372		[learning rate: 2.1962e-05]
	Learning Rate: 2.19617e-05
	LOSS [training: 0.006776515572087372 | validation: 0.006100553199775388]
	TIME [epoch: 41.8 sec]
EPOCH 450/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006768305796883543		[learning rate: 2.1627e-05]
	Learning Rate: 2.16272e-05
	LOSS [training: 0.006768305796883543 | validation: 0.006114375205024502]
	TIME [epoch: 41.8 sec]
EPOCH 451/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006743049986306494		[learning rate: 2.1298e-05]
	Learning Rate: 2.12977e-05
	LOSS [training: 0.006743049986306494 | validation: 0.005800654759156514]
	TIME [epoch: 41.8 sec]
	Saving model to: out/model_training/model_algphiq_1a_v_mmd4_20241015_175139/states/model_algphiq_1a_v_mmd4_451.pth
	Model improved!!!
EPOCH 452/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006835818491918888		[learning rate: 2.0973e-05]
	Learning Rate: 2.09733e-05
	LOSS [training: 0.006835818491918888 | validation: 0.006013177409910132]
	TIME [epoch: 41.8 sec]
EPOCH 453/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006708544309362124		[learning rate: 2.0654e-05]
	Learning Rate: 2.06538e-05
	LOSS [training: 0.006708544309362124 | validation: 0.006023991484299025]
	TIME [epoch: 41.8 sec]
EPOCH 454/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006729432702163468		[learning rate: 2.0339e-05]
	Learning Rate: 2.03392e-05
	LOSS [training: 0.006729432702163468 | validation: 0.006154379288356347]
	TIME [epoch: 41.8 sec]
EPOCH 455/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006740807639574293		[learning rate: 2.0029e-05]
	Learning Rate: 2.00293e-05
	LOSS [training: 0.006740807639574293 | validation: 0.006030170307203811]
	TIME [epoch: 41.8 sec]
EPOCH 456/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006736357027101201		[learning rate: 1.9724e-05]
	Learning Rate: 1.97242e-05
	LOSS [training: 0.006736357027101201 | validation: 0.006222062503293595]
	TIME [epoch: 41.8 sec]
EPOCH 457/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006770213690919676		[learning rate: 1.9424e-05]
	Learning Rate: 1.94238e-05
	LOSS [training: 0.006770213690919676 | validation: 0.006088883948809656]
	TIME [epoch: 41.8 sec]
EPOCH 458/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006792296682701971		[learning rate: 1.9128e-05]
	Learning Rate: 1.91279e-05
	LOSS [training: 0.006792296682701971 | validation: 0.006139303043675024]
	TIME [epoch: 41.8 sec]
EPOCH 459/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006768621274679483		[learning rate: 1.8836e-05]
	Learning Rate: 1.88365e-05
	LOSS [training: 0.006768621274679483 | validation: 0.006110693682416672]
	TIME [epoch: 41.8 sec]
EPOCH 460/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067304380016719		[learning rate: 1.855e-05]
	Learning Rate: 1.85495e-05
	LOSS [training: 0.0067304380016719 | validation: 0.005905093567743197]
	TIME [epoch: 41.8 sec]
EPOCH 461/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006709054944875555		[learning rate: 1.8267e-05]
	Learning Rate: 1.8267e-05
	LOSS [training: 0.006709054944875555 | validation: 0.0059802671093252486]
	TIME [epoch: 41.8 sec]
EPOCH 462/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006685036717973651		[learning rate: 1.7989e-05]
	Learning Rate: 1.79887e-05
	LOSS [training: 0.006685036717973651 | validation: 0.006049814831382456]
	TIME [epoch: 41.8 sec]
EPOCH 463/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006747048632934926		[learning rate: 1.7715e-05]
	Learning Rate: 1.77147e-05
	LOSS [training: 0.006747048632934926 | validation: 0.006084827828008954]
	TIME [epoch: 41.8 sec]
EPOCH 464/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006746591711440606		[learning rate: 1.7445e-05]
	Learning Rate: 1.74448e-05
	LOSS [training: 0.006746591711440606 | validation: 0.006191842834357251]
	TIME [epoch: 41.8 sec]
EPOCH 465/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006686259248556905		[learning rate: 1.7179e-05]
	Learning Rate: 1.71791e-05
	LOSS [training: 0.006686259248556905 | validation: 0.00597565868122135]
	TIME [epoch: 41.8 sec]
EPOCH 466/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006777065579759205		[learning rate: 1.6917e-05]
	Learning Rate: 1.69174e-05
	LOSS [training: 0.006777065579759205 | validation: 0.006028289709330649]
	TIME [epoch: 41.8 sec]
EPOCH 467/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006771417631044805		[learning rate: 1.666e-05]
	Learning Rate: 1.66597e-05
	LOSS [training: 0.006771417631044805 | validation: 0.005985379084680189]
	TIME [epoch: 41.8 sec]
EPOCH 468/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006697234735431367		[learning rate: 1.6406e-05]
	Learning Rate: 1.64059e-05
	LOSS [training: 0.006697234735431367 | validation: 0.006074126180170848]
	TIME [epoch: 41.8 sec]
EPOCH 469/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006667389928394481		[learning rate: 1.6156e-05]
	Learning Rate: 1.6156e-05
	LOSS [training: 0.006667389928394481 | validation: 0.006173715174827883]
	TIME [epoch: 41.8 sec]
EPOCH 470/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006768901635076872		[learning rate: 1.591e-05]
	Learning Rate: 1.59099e-05
	LOSS [training: 0.006768901635076872 | validation: 0.0060746655353220835]
	TIME [epoch: 41.8 sec]
EPOCH 471/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006771630217827924		[learning rate: 1.5668e-05]
	Learning Rate: 1.56675e-05
	LOSS [training: 0.006771630217827924 | validation: 0.006238254793399234]
	TIME [epoch: 41.9 sec]
EPOCH 472/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006709808354452315		[learning rate: 1.5429e-05]
	Learning Rate: 1.54288e-05
	LOSS [training: 0.006709808354452315 | validation: 0.006074039239489193]
	TIME [epoch: 41.8 sec]
EPOCH 473/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006731160073954435		[learning rate: 1.5194e-05]
	Learning Rate: 1.51938e-05
	LOSS [training: 0.006731160073954435 | validation: 0.006140768860233306]
	TIME [epoch: 41.8 sec]
EPOCH 474/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006708480019786616		[learning rate: 1.4962e-05]
	Learning Rate: 1.49624e-05
	LOSS [training: 0.006708480019786616 | validation: 0.005997540374918805]
	TIME [epoch: 41.8 sec]
EPOCH 475/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006751749038744306		[learning rate: 1.4734e-05]
	Learning Rate: 1.47344e-05
	LOSS [training: 0.006751749038744306 | validation: 0.006155298760425115]
	TIME [epoch: 41.8 sec]
EPOCH 476/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067708960560632055		[learning rate: 1.451e-05]
	Learning Rate: 1.451e-05
	LOSS [training: 0.0067708960560632055 | validation: 0.0061223715619352255]
	TIME [epoch: 41.8 sec]
EPOCH 477/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006736313020052356		[learning rate: 1.4289e-05]
	Learning Rate: 1.42889e-05
	LOSS [training: 0.006736313020052356 | validation: 0.006033610648854499]
	TIME [epoch: 41.8 sec]
EPOCH 478/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006758608962427273		[learning rate: 1.4071e-05]
	Learning Rate: 1.40713e-05
	LOSS [training: 0.006758608962427273 | validation: 0.006110275983995833]
	TIME [epoch: 41.8 sec]
EPOCH 479/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006704969303936863		[learning rate: 1.3857e-05]
	Learning Rate: 1.38569e-05
	LOSS [training: 0.006704969303936863 | validation: 0.006044995069334067]
	TIME [epoch: 41.8 sec]
EPOCH 480/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067512365113106005		[learning rate: 1.3646e-05]
	Learning Rate: 1.36458e-05
	LOSS [training: 0.0067512365113106005 | validation: 0.006054983151943916]
	TIME [epoch: 41.8 sec]
EPOCH 481/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006752373464853311		[learning rate: 1.3438e-05]
	Learning Rate: 1.3438e-05
	LOSS [training: 0.006752373464853311 | validation: 0.005989439641441727]
	TIME [epoch: 41.8 sec]
EPOCH 482/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067429820105660305		[learning rate: 1.3233e-05]
	Learning Rate: 1.32333e-05
	LOSS [training: 0.0067429820105660305 | validation: 0.006094523943327081]
	TIME [epoch: 41.8 sec]
EPOCH 483/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006688771810382085		[learning rate: 1.3032e-05]
	Learning Rate: 1.30317e-05
	LOSS [training: 0.006688771810382085 | validation: 0.006018748191909289]
	TIME [epoch: 41.8 sec]
EPOCH 484/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006710239412185507		[learning rate: 1.2833e-05]
	Learning Rate: 1.28332e-05
	LOSS [training: 0.006710239412185507 | validation: 0.005976904081182378]
	TIME [epoch: 41.8 sec]
EPOCH 485/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006687296288531471		[learning rate: 1.2638e-05]
	Learning Rate: 1.26377e-05
	LOSS [training: 0.006687296288531471 | validation: 0.006063227432038078]
	TIME [epoch: 41.8 sec]
EPOCH 486/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006758006103566812		[learning rate: 1.2445e-05]
	Learning Rate: 1.24451e-05
	LOSS [training: 0.006758006103566812 | validation: 0.006094192691520553]
	TIME [epoch: 41.8 sec]
EPOCH 487/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006663626374835038		[learning rate: 1.2256e-05]
	Learning Rate: 1.22556e-05
	LOSS [training: 0.006663626374835038 | validation: 0.006146847624605786]
	TIME [epoch: 41.8 sec]
EPOCH 488/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006757791600658809		[learning rate: 1.2069e-05]
	Learning Rate: 1.20689e-05
	LOSS [training: 0.006757791600658809 | validation: 0.005957879707726909]
	TIME [epoch: 41.8 sec]
EPOCH 489/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006703470201059028		[learning rate: 1.1885e-05]
	Learning Rate: 1.1885e-05
	LOSS [training: 0.006703470201059028 | validation: 0.006132407248870209]
	TIME [epoch: 41.8 sec]
EPOCH 490/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006723904200602702		[learning rate: 1.1704e-05]
	Learning Rate: 1.1704e-05
	LOSS [training: 0.006723904200602702 | validation: 0.006047399823890772]
	TIME [epoch: 41.8 sec]
EPOCH 491/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006706916976103135		[learning rate: 1.1526e-05]
	Learning Rate: 1.15257e-05
	LOSS [training: 0.006706916976103135 | validation: 0.005813457192398524]
	TIME [epoch: 41.8 sec]
EPOCH 492/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006607938352584119		[learning rate: 1.135e-05]
	Learning Rate: 1.13501e-05
	LOSS [training: 0.006607938352584119 | validation: 0.006024470549139729]
	TIME [epoch: 41.8 sec]
EPOCH 493/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067578432903223845		[learning rate: 1.1177e-05]
	Learning Rate: 1.11772e-05
	LOSS [training: 0.0067578432903223845 | validation: 0.006015348063233273]
	TIME [epoch: 41.8 sec]
EPOCH 494/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006785215832071021		[learning rate: 1.1007e-05]
	Learning Rate: 1.10069e-05
	LOSS [training: 0.006785215832071021 | validation: 0.00588299598251494]
	TIME [epoch: 41.8 sec]
EPOCH 495/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006683081826323949		[learning rate: 1.0839e-05]
	Learning Rate: 1.08393e-05
	LOSS [training: 0.006683081826323949 | validation: 0.006078493699180421]
	TIME [epoch: 41.8 sec]
EPOCH 496/500:
	Training over batches...
		[batch 4/4] avg loss: 0.0067575526833495445		[learning rate: 1.0674e-05]
	Learning Rate: 1.06741e-05
	LOSS [training: 0.0067575526833495445 | validation: 0.005850271685581205]
	TIME [epoch: 41.8 sec]
EPOCH 497/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006659285453051303		[learning rate: 1.0512e-05]
	Learning Rate: 1.05115e-05
	LOSS [training: 0.006659285453051303 | validation: 0.006043152059057751]
	TIME [epoch: 41.8 sec]
EPOCH 498/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006705193883714992		[learning rate: 1.0351e-05]
	Learning Rate: 1.03514e-05
	LOSS [training: 0.006705193883714992 | validation: 0.006093538910757356]
	TIME [epoch: 41.8 sec]
EPOCH 499/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006701528838668408		[learning rate: 1.0194e-05]
	Learning Rate: 1.01937e-05
	LOSS [training: 0.006701528838668408 | validation: 0.005985733610247955]
	TIME [epoch: 41.8 sec]
EPOCH 500/500:
	Training over batches...
		[batch 4/4] avg loss: 0.006747464026114103		[learning rate: 1.0038e-05]
	Learning Rate: 1.00384e-05
	LOSS [training: 0.006747464026114103 | validation: 0.006111354849284259]
	TIME [epoch: 41.8 sec]
Finished training in 14471.064 seconds.
