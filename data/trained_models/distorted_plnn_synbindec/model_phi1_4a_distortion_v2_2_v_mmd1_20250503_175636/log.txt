Args:
Namespace(name='model_phi1_4a_distortion_v2_2_v_mmd1', outdir='out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1', training_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_2/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4054180648

Training model...

Saving initial model state to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.399446128050313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.399446128050313 | validation: 5.345628605973747]
	TIME [epoch: 167 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.080556769926257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.080556769926257 | validation: 5.434269004281848]
	TIME [epoch: 0.81 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.986436597511041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.986436597511041 | validation: 5.242407128537451]
	TIME [epoch: 0.698 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.738315873480604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.738315873480604 | validation: 5.27957692517026]
	TIME [epoch: 0.695 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.5404858748140935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5404858748140935 | validation: 5.453809946074635]
	TIME [epoch: 0.687 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.2525735900942925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2525735900942925 | validation: 5.4002299889109]
	TIME [epoch: 0.693 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.256910528087554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.256910528087554 | validation: 5.096613266160837]
	TIME [epoch: 0.697 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.934188090782982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.934188090782982 | validation: 4.954255721960942]
	TIME [epoch: 0.688 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.113146476576998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.113146476576998 | validation: 4.503842869344846]
	TIME [epoch: 0.687 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.949440627153442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.949440627153442 | validation: 4.012425966237155]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8422025594735816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8422025594735816 | validation: 3.7003243504797427]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6302730769652896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6302730769652896 | validation: 3.385070212329232]
	TIME [epoch: 0.689 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.357217878856559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.357217878856559 | validation: 3.0219923469485055]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0345737086475904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0345737086475904 | validation: 2.9419619876366694]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6564916121163606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6564916121163606 | validation: 2.5878660986862054]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3511086681750033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3511086681750033 | validation: 3.8004979612405543]
	TIME [epoch: 0.686 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8937152879982904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8937152879982904 | validation: 3.526319115201166]
	TIME [epoch: 0.689 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5526666128081685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5526666128081685 | validation: 1.937099674474113]
	TIME [epoch: 0.688 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.208798838772454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.208798838772454 | validation: 2.484842494909561]
	TIME [epoch: 0.694 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.047616785877456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.047616785877456 | validation: 2.4543018500224925]
	TIME [epoch: 0.691 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0109419524511853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0109419524511853 | validation: 1.9605435606516979]
	TIME [epoch: 0.69 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9686107983711487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9686107983711487 | validation: 2.0197375879599004]
	TIME [epoch: 0.689 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.943441411579209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.943441411579209 | validation: 2.059244131440781]
	TIME [epoch: 0.69 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9216014860510269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9216014860510269 | validation: 2.1525626215703144]
	TIME [epoch: 0.69 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9219521171348346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9219521171348346 | validation: 1.9109523674664772]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9357079660800867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9357079660800867 | validation: 1.862703677759229]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8809410095158148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8809410095158148 | validation: 1.8461326295413194]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8355860275691973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8355860275691973 | validation: 1.9243020614293223]
	TIME [epoch: 0.69 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8130021338731672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8130021338731672 | validation: 1.868929179578025]
	TIME [epoch: 0.691 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7943142636722216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7943142636722216 | validation: 1.7708550894260242]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7820188646464359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7820188646464359 | validation: 1.743873488512632]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.759890606948619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.759890606948619 | validation: 1.707666335517934]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7222636510221185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7222636510221185 | validation: 1.6364823925256076]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6971544167930142		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6971544167930142 | validation: 1.5802804443462348]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6609106567475178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6609106567475178 | validation: 1.5363343339276339]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6101438188716395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6101438188716395 | validation: 1.5040572460588286]
	TIME [epoch: 0.692 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5580494293634228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5580494293634228 | validation: 1.5194266744123244]
	TIME [epoch: 0.693 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4892726545828328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4892726545828328 | validation: 1.5316127396520125]
	TIME [epoch: 0.69 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4144698418463808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4144698418463808 | validation: 1.5337851753797773]
	TIME [epoch: 0.692 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3622740654002308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3622740654002308 | validation: 3.1364875702188613]
	TIME [epoch: 0.692 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.4398534985902565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4398534985902565 | validation: 1.960335964244601]
	TIME [epoch: 0.691 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9392597554446664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9392597554446664 | validation: 1.8171813673850086]
	TIME [epoch: 0.69 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8374207818147854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8374207818147854 | validation: 1.4527846288137927]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4907017601076045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4907017601076045 | validation: 1.5171310103581876]
	TIME [epoch: 0.694 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3437368391568543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3437368391568543 | validation: 1.5128605834717401]
	TIME [epoch: 0.69 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3086521489414087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3086521489414087 | validation: 1.3669195512713497]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.230949805964452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.230949805964452 | validation: 1.4376502581337087]
	TIME [epoch: 0.695 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.19243141617745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.19243141617745 | validation: 1.499963054570361]
	TIME [epoch: 0.69 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1808220951751707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1808220951751707 | validation: 1.3908262418879602]
	TIME [epoch: 0.69 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1538546679837254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1538546679837254 | validation: 1.5306893897482245]
	TIME [epoch: 0.69 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1498680511980952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1498680511980952 | validation: 1.3084580708542157]
	TIME [epoch: 0.689 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1997325485913786		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 1.1997325485913786 | validation: 1.6509437434223646]
	TIME [epoch: 0.691 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2197330782328164		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 1.2197330782328164 | validation: 1.3715104553072364]
	TIME [epoch: 0.69 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4633735774525436		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 1.4633735774525436 | validation: 1.1912014322191813]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2157356942102044		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 1.2157356942102044 | validation: 2.0755002038183026]
	TIME [epoch: 0.692 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5321612341549167		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 1.5321612341549167 | validation: 1.287128514588423]
	TIME [epoch: 0.691 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4803927683861349		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 1.4803927683861349 | validation: 1.2700467154215282]
	TIME [epoch: 0.69 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5105403144256258		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 1.5105403144256258 | validation: 1.1594183392090702]
	TIME [epoch: 0.689 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2649522953276877		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 1.2649522953276877 | validation: 1.5532072029168313]
	TIME [epoch: 0.69 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2022218082758744		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 1.2022218082758744 | validation: 1.228661219181537]
	TIME [epoch: 0.69 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0741274741924267		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 1.0741274741924267 | validation: 1.2491881214466654]
	TIME [epoch: 0.69 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0394395793509288		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 1.0394395793509288 | validation: 1.276827826379336]
	TIME [epoch: 0.689 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.042768243006964		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 1.042768243006964 | validation: 1.1193978709069332]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.134206368431676		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 1.134206368431676 | validation: 1.3591678394444824]
	TIME [epoch: 0.694 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1209644841947648		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 1.1209644841947648 | validation: 1.1421510051601178]
	TIME [epoch: 0.693 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3225754192465644		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 1.3225754192465644 | validation: 1.0361227422383317]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0766826400455463		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 1.0766826400455463 | validation: 1.875277659957176]
	TIME [epoch: 0.693 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5233539604483988		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 1.5233539604483988 | validation: 1.197588238459208]
	TIME [epoch: 0.693 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4329075270533433		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 1.4329075270533433 | validation: 1.1808736463899334]
	TIME [epoch: 0.692 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4492673795877757		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 1.4492673795877757 | validation: 1.0610604209035714]
	TIME [epoch: 0.695 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1634044267192485		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 1.1634044267192485 | validation: 1.5458551572756882]
	TIME [epoch: 0.692 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.232157394584687		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 1.232157394584687 | validation: 1.0718225285891638]
	TIME [epoch: 0.692 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.140143505664019		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 1.140143505664019 | validation: 1.0452366272446028]
	TIME [epoch: 0.692 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0281622228995773		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 1.0281622228995773 | validation: 1.3191628760658691]
	TIME [epoch: 0.693 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.11444914532049		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 1.11444914532049 | validation: 1.0599147690804749]
	TIME [epoch: 0.692 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1108637749969388		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 1.1108637749969388 | validation: 1.0149556234376877]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9566897526718904		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.9566897526718904 | validation: 1.2449802942283392]
	TIME [epoch: 0.693 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0752369668539894		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 1.0752369668539894 | validation: 1.0284002124722567]
	TIME [epoch: 0.691 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1625106825590417		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 1.1625106825590417 | validation: 0.9547897335692653]
	TIME [epoch: 0.692 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9647352381054247		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 0.9647352381054247 | validation: 1.3590311311943228]
	TIME [epoch: 0.691 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1966376310015177		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 1.1966376310015177 | validation: 1.0402083572214533]
	TIME [epoch: 0.69 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.226786619698975		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 1.226786619698975 | validation: 0.9685745197329498]
	TIME [epoch: 0.69 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0529004562856066		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 1.0529004562856066 | validation: 1.3396546364758923]
	TIME [epoch: 0.69 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1614127535948158		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 1.1614127535948158 | validation: 0.9810293676266106]
	TIME [epoch: 0.69 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1376411032396994		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 1.1376411032396994 | validation: 0.9326410355293309]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.957465794916437		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.957465794916437 | validation: 1.255612700445499]
	TIME [epoch: 0.691 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1593006470689002		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 1.1593006470689002 | validation: 0.969520976014789]
	TIME [epoch: 0.691 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0766059719322316		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 1.0766059719322316 | validation: 0.9325043004019655]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9371171952679949		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 0.9371171952679949 | validation: 1.142542548530777]
	TIME [epoch: 0.696 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.038723136678093		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 1.038723136678093 | validation: 0.9713208942890468]
	TIME [epoch: 0.694 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0578765072089862		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 1.0578765072089862 | validation: 0.9248498693405737]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8905899803618715		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.8905899803618715 | validation: 1.0239491026897174]
	TIME [epoch: 0.694 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9561640086619291		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 0.9561640086619291 | validation: 0.8811914020487827]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0670429327782367		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 1.0670429327782367 | validation: 0.9401541233010065]
	TIME [epoch: 0.694 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8915500390500443		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 0.8915500390500443 | validation: 0.8827423845478665]
	TIME [epoch: 0.693 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8667350758350526		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 0.8667350758350526 | validation: 0.839149758006883]
	TIME [epoch: 0.695 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8869954485904812		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.8869954485904812 | validation: 0.9741175732974838]
	TIME [epoch: 0.691 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9632816967697782		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.9632816967697782 | validation: 0.9245345246056079]
	TIME [epoch: 0.691 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.218221283464886		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 1.218221283464886 | validation: 0.8494706904296994]
	TIME [epoch: 0.692 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8764024874510676		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 0.8764024874510676 | validation: 1.073620602343563]
	TIME [epoch: 0.691 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.038803828680133		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 1.038803828680133 | validation: 0.9996864814715409]
	TIME [epoch: 0.691 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2571643474251972		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 1.2571643474251972 | validation: 0.8321710677007783]
	TIME [epoch: 0.697 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8933885267514685		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 0.8933885267514685 | validation: 1.3030445455892368]
	TIME [epoch: 0.687 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2662305530527596		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 1.2662305530527596 | validation: 0.8951388487130046]
	TIME [epoch: 0.687 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.041569805994666		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 1.041569805994666 | validation: 0.8321793651722068]
	TIME [epoch: 0.687 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8698538272150472		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.8698538272150472 | validation: 1.028692689831673]
	TIME [epoch: 0.687 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9891935613999695		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.9891935613999695 | validation: 0.841977767408635]
	TIME [epoch: 0.686 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0031241610548216		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 1.0031241610548216 | validation: 0.8330209594958218]
	TIME [epoch: 0.69 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8472837289510505		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 0.8472837289510505 | validation: 0.8785990041390805]
	TIME [epoch: 0.688 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8697114383101189		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.8697114383101189 | validation: 0.782903449848956]
	TIME [epoch: 0.686 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9533360812800242		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 0.9533360812800242 | validation: 0.908773316879179]
	TIME [epoch: 0.69 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8855560094674764		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.8855560094674764 | validation: 0.7580915554065554]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8950966552943743		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 0.8950966552943743 | validation: 0.89700258375674]
	TIME [epoch: 0.693 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8879366654588259		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.8879366654588259 | validation: 0.7542233122395445]
	TIME [epoch: 0.692 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9173411983072332		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 0.9173411983072332 | validation: 0.8912579949052554]
	TIME [epoch: 0.692 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9037440904208481		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 0.9037440904208481 | validation: 0.7777004573983677]
	TIME [epoch: 0.69 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9328812044079502		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.9328812044079502 | validation: 0.8841127833527885]
	TIME [epoch: 0.691 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.886319248673394		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.886319248673394 | validation: 0.7453910909739957]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8821290694904909		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.8821290694904909 | validation: 0.8581012925181075]
	TIME [epoch: 0.69 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8629616063252773		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 0.8629616063252773 | validation: 0.7436079205709272]
	TIME [epoch: 0.687 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8921482050507281		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 0.8921482050507281 | validation: 0.8937682838314963]
	TIME [epoch: 0.695 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8941273174704634		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.8941273174704634 | validation: 0.7450611374757184]
	TIME [epoch: 0.693 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.920153809545104		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 0.920153809545104 | validation: 0.8770429529205703]
	TIME [epoch: 0.693 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9005473449422362		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 0.9005473449422362 | validation: 0.7383125177839679]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9058192400018211		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 0.9058192400018211 | validation: 0.7956459508811179]
	TIME [epoch: 0.696 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8366300522415179		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.8366300522415179 | validation: 0.6929129314777068]
	TIME [epoch: 0.693 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8365428568238571		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.8365428568238571 | validation: 0.8043974280453354]
	TIME [epoch: 0.695 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8471379911429474		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 0.8471379911429474 | validation: 0.7325950623965505]
	TIME [epoch: 0.694 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8991779243380849		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 0.8991779243380849 | validation: 0.929821457876236]
	TIME [epoch: 0.693 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9262156299412081		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.9262156299412081 | validation: 0.717385207826626]
	TIME [epoch: 0.694 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9310808113530575		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 0.9310808113530575 | validation: 0.8123172819627534]
	TIME [epoch: 0.695 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8630478572114497		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.8630478572114497 | validation: 0.731080706256062]
	TIME [epoch: 0.695 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8511093577025031		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 0.8511093577025031 | validation: 0.75301569515518]
	TIME [epoch: 0.694 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8290747958479269		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.8290747958479269 | validation: 0.6793980831122135]
	TIME [epoch: 0.695 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8294651522254424		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 0.8294651522254424 | validation: 0.777784404405661]
	TIME [epoch: 0.692 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8444902879904982		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 0.8444902879904982 | validation: 0.7115428861587884]
	TIME [epoch: 0.691 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8963659011221877		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.8963659011221877 | validation: 0.8678767592791502]
	TIME [epoch: 0.7 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8953564476504852		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.8953564476504852 | validation: 0.6751316710664472]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8703122060268669		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 0.8703122060268669 | validation: 0.7533243439264945]
	TIME [epoch: 0.69 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8278673391341951		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 0.8278673391341951 | validation: 0.6782663406946245]
	TIME [epoch: 0.691 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8261831612154257		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.8261831612154257 | validation: 0.7399600046169322]
	TIME [epoch: 0.692 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8264046613702357		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.8264046613702357 | validation: 0.6636889395614207]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8420246898421563		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 0.8420246898421563 | validation: 0.7586304884607333]
	TIME [epoch: 0.688 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8278689431232548		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 0.8278689431232548 | validation: 0.68244976930539]
	TIME [epoch: 0.688 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8358276612402865		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 0.8358276612402865 | validation: 0.7993378348354351]
	TIME [epoch: 0.687 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.864757676809515		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.864757676809515 | validation: 0.7091976938564968]
	TIME [epoch: 0.688 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8893414260190534		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.8893414260190534 | validation: 0.7881630220495183]
	TIME [epoch: 0.691 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8398428952198065		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.8398428952198065 | validation: 0.6650203373811188]
	TIME [epoch: 0.692 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8350795748430612		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.8350795748430612 | validation: 0.7551639593772265]
	TIME [epoch: 0.69 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8293354979300063		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.8293354979300063 | validation: 0.6593444617114248]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8199771504831026		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 0.8199771504831026 | validation: 0.7255821154605773]
	TIME [epoch: 0.693 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8115228647113634		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 0.8115228647113634 | validation: 0.6367601766755027]
	TIME [epoch: 0.689 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8046782236297113		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.8046782236297113 | validation: 0.7116628136647687]
	TIME [epoch: 0.694 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8030840454892545		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.8030840454892545 | validation: 0.6522466977827325]
	TIME [epoch: 0.693 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8193627390282111		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.8193627390282111 | validation: 0.8032293957686047]
	TIME [epoch: 0.693 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8444322605973358		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 0.8444322605973358 | validation: 0.660999228094445]
	TIME [epoch: 0.692 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8675159492303864		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.8675159492303864 | validation: 0.7792238779693968]
	TIME [epoch: 0.692 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8555478185120334		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.8555478185120334 | validation: 0.6333428564313212]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8188280637296356		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.8188280637296356 | validation: 0.7079019547231202]
	TIME [epoch: 0.688 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7950645973159937		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.7950645973159937 | validation: 0.6415635257607835]
	TIME [epoch: 0.688 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7985539615828825		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.7985539615828825 | validation: 0.6739685449818178]
	TIME [epoch: 0.688 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7935286204430372		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 0.7935286204430372 | validation: 0.6222607991372813]
	TIME [epoch: 0.687 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7843797574668085		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.7843797574668085 | validation: 0.6986601914968209]
	TIME [epoch: 0.692 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7946617796246119		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.7946617796246119 | validation: 0.6577607792747433]
	TIME [epoch: 0.69 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8316808654203653		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.8316808654203653 | validation: 0.8171337489576191]
	TIME [epoch: 0.691 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8844247381108208		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.8844247381108208 | validation: 0.647540448732676]
	TIME [epoch: 0.69 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8631909585262956		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.8631909585262956 | validation: 0.7213276825320047]
	TIME [epoch: 0.693 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8071523319697951		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 0.8071523319697951 | validation: 0.615242714613407]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_168.pth
	Model improved!!!
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7807444129996287		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.7807444129996287 | validation: 0.6655318454857395]
	TIME [epoch: 0.692 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7818418950287982		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.7818418950287982 | validation: 0.6321595716186466]
	TIME [epoch: 0.691 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7884611658304058		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.7884611658304058 | validation: 0.6433506755755195]
	TIME [epoch: 0.692 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7865524137038363		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.7865524137038363 | validation: 0.6079042819865147]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7815443287868789		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.7815443287868789 | validation: 0.6631198511281812]
	TIME [epoch: 0.695 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7874023854442221		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.7874023854442221 | validation: 0.6385491915090536]
	TIME [epoch: 0.688 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8154857616882057		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.8154857616882057 | validation: 0.7715768176284264]
	TIME [epoch: 0.688 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8502874823245473		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.8502874823245473 | validation: 0.6538338116733304]
	TIME [epoch: 0.687 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8458588198226127		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.8458588198226127 | validation: 0.6951318132814102]
	TIME [epoch: 0.687 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.796574905431477		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.796574905431477 | validation: 0.6071305263622206]
	TIME [epoch: 0.689 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7716084952353999		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 0.7716084952353999 | validation: 0.6341265014339313]
	TIME [epoch: 0.688 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7628695396858031		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.7628695396858031 | validation: 0.6094221233898676]
	TIME [epoch: 0.687 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7646303536287693		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.7646303536287693 | validation: 0.6380969729538087]
	TIME [epoch: 0.687 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7600854025711578		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.7600854025711578 | validation: 0.6018037617027366]
	TIME [epoch: 0.687 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7890051001031168		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 0.7890051001031168 | validation: 0.7262134401602423]
	TIME [epoch: 0.69 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8414920247017545		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.8414920247017545 | validation: 0.6142671578257107]
	TIME [epoch: 0.691 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8315034309143451		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.8315034309143451 | validation: 0.7350768770394602]
	TIME [epoch: 0.691 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8314495472058968		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.8314495472058968 | validation: 0.6428557049337527]
	TIME [epoch: 0.689 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8286115593070079		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.8286115593070079 | validation: 0.6559762749311916]
	TIME [epoch: 0.689 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7691971061478745		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 0.7691971061478745 | validation: 0.6147381051209084]
	TIME [epoch: 0.691 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7547285415150795		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.7547285415150795 | validation: 0.6151127027810969]
	TIME [epoch: 0.691 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7533154540375226		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.7533154540375226 | validation: 0.6133822270555072]
	TIME [epoch: 0.691 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7463261602851342		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.7463261602851342 | validation: 0.597500317025155]
	TIME [epoch: 0.69 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7535194213653496		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.7535194213653496 | validation: 0.6151973693819491]
	TIME [epoch: 0.694 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.758971507862212		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.758971507862212 | validation: 0.5949813770538198]
	TIME [epoch: 0.694 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7786518786251108		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.7786518786251108 | validation: 0.7440379378958695]
	TIME [epoch: 0.691 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8156817564677104		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 0.8156817564677104 | validation: 0.6293986374331018]
	TIME [epoch: 0.692 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8774630658143686		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.8774630658143686 | validation: 0.7264265353855619]
	TIME [epoch: 0.691 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8424775681221863		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.8424775681221863 | validation: 0.5894111058333108]
	TIME [epoch: 0.691 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7715989264667554		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.7715989264667554 | validation: 0.6164463129282973]
	TIME [epoch: 0.69 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7678109087416424		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.7678109087416424 | validation: 0.622830966265728]
	TIME [epoch: 0.688 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7622104716894106		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.7622104716894106 | validation: 0.5884843097508877]
	TIME [epoch: 0.687 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7636241439183726		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 0.7636241439183726 | validation: 0.6379559482247026]
	TIME [epoch: 177 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7544458606702472		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.7544458606702472 | validation: 0.5854618129940886]
	TIME [epoch: 1.36 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7678640356656752		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.7678640356656752 | validation: 0.6715521561626585]
	TIME [epoch: 1.35 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7658890294829113		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.7658890294829113 | validation: 0.5895266361785708]
	TIME [epoch: 1.35 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7738873576145976		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.7738873576145976 | validation: 0.6671954410025178]
	TIME [epoch: 1.35 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7806583397302822		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.7806583397302822 | validation: 0.5785288676337059]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7736991253051199		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.7736991253051199 | validation: 0.6487178458123536]
	TIME [epoch: 1.35 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7627150539752439		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.7627150539752439 | validation: 0.5844084101048262]
	TIME [epoch: 1.36 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7548950235435855		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.7548950235435855 | validation: 0.6104195197662565]
	TIME [epoch: 1.35 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7612825077136414		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.7612825077136414 | validation: 0.570788918819718]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.771451904494271		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.771451904494271 | validation: 0.6068464712553738]
	TIME [epoch: 1.35 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7576082225248236		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.7576082225248236 | validation: 0.5813075465539054]
	TIME [epoch: 1.35 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7419427374610189		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.7419427374610189 | validation: 0.5782271218210521]
	TIME [epoch: 1.35 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7358870112546783		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.7358870112546783 | validation: 0.5817645851359924]
	TIME [epoch: 1.35 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7421023688551779		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.7421023688551779 | validation: 0.5741173789533951]
	TIME [epoch: 1.35 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.743194936329323		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 0.743194936329323 | validation: 0.5800494892390478]
	TIME [epoch: 1.35 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7476848502733947		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.7476848502733947 | validation: 0.6745180661439566]
	TIME [epoch: 1.35 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7757140581082266		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.7757140581082266 | validation: 0.6675882195827324]
	TIME [epoch: 1.35 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8575903599211219		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.8575903599211219 | validation: 0.8136845888353076]
	TIME [epoch: 1.35 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.895630385268181		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.895630385268181 | validation: 0.5585486085632786]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7468532416193985		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.7468532416193985 | validation: 0.5633257372340804]
	TIME [epoch: 1.34 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7449895047203703		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.7449895047203703 | validation: 0.6172421127129385]
	TIME [epoch: 1.34 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7569052740699735		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 0.7569052740699735 | validation: 0.5669306200395733]
	TIME [epoch: 1.34 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7421386853385354		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.7421386853385354 | validation: 0.5755982303055882]
	TIME [epoch: 1.34 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7332195009457902		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.7332195009457902 | validation: 0.5701483094953862]
	TIME [epoch: 1.35 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7325744426718487		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.7325744426718487 | validation: 0.5710949801291031]
	TIME [epoch: 1.35 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7286404755227031		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.7286404755227031 | validation: 0.5756716572975642]
	TIME [epoch: 1.35 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7325474800643358		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.7325474800643358 | validation: 0.5588731369762904]
	TIME [epoch: 1.35 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7614572926564904		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.7614572926564904 | validation: 0.6574411712900924]
	TIME [epoch: 1.35 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7969727684711653		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.7969727684711653 | validation: 0.5650012022578579]
	TIME [epoch: 1.36 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7380790542790256		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.7380790542790256 | validation: 0.6003770072648243]
	TIME [epoch: 1.35 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7337258632291558		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.7337258632291558 | validation: 0.5610282312567122]
	TIME [epoch: 1.35 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7562630856952717		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 0.7562630856952717 | validation: 0.6567815172924664]
	TIME [epoch: 1.35 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.767706772500907		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.767706772500907 | validation: 0.5851992148950086]
	TIME [epoch: 1.35 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.782831096200893		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.782831096200893 | validation: 0.6298828092901751]
	TIME [epoch: 1.35 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7462671034242654		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.7462671034242654 | validation: 0.5494018208861794]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7235902730470555		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.7235902730470555 | validation: 0.5612922377830624]
	TIME [epoch: 1.34 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7169141982740765		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.7169141982740765 | validation: 0.5681554943393536]
	TIME [epoch: 1.34 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7166059438479391		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.7166059438479391 | validation: 0.5426853829485445]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7129280999896034		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.7129280999896034 | validation: 0.550612339479333]
	TIME [epoch: 1.34 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7204571193633126		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.7204571193633126 | validation: 0.53973500889811]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7269956410296929		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.7269956410296929 | validation: 0.7046615795420994]
	TIME [epoch: 1.35 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7748067044018907		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 0.7748067044018907 | validation: 0.6259437252540881]
	TIME [epoch: 1.35 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8184540532516984		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.8184540532516984 | validation: 0.6484352766982108]
	TIME [epoch: 1.35 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7614443344421781		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.7614443344421781 | validation: 0.5428536715148512]
	TIME [epoch: 1.35 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7195242936815006		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.7195242936815006 | validation: 0.545228980483239]
	TIME [epoch: 1.35 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7205709551606495		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.7205709551606495 | validation: 0.5944084207820668]
	TIME [epoch: 1.35 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7240749130998063		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.7240749130998063 | validation: 0.5580732677298583]
	TIME [epoch: 1.35 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7158962886980952		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.7158962886980952 | validation: 0.5609558160981744]
	TIME [epoch: 1.35 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7146164200512155		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.7146164200512155 | validation: 0.546896794277017]
	TIME [epoch: 1.36 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7045102654499974		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.7045102654499974 | validation: 0.5493866173254971]
	TIME [epoch: 1.35 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7007952324226311		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.7007952324226311 | validation: 0.5537830518987396]
	TIME [epoch: 1.35 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.70273070744866		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.70273070744866 | validation: 0.5292168813023385]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7120833761986888		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.7120833761986888 | validation: 0.564427864533747]
	TIME [epoch: 1.35 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7118814737446698		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.7118814737446698 | validation: 0.539153628267909]
	TIME [epoch: 1.35 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7229433841125947		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.7229433841125947 | validation: 0.661758655056276]
	TIME [epoch: 1.35 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7566528942121985		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.7566528942121985 | validation: 0.6871383286205872]
	TIME [epoch: 1.35 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8538545771736893		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.8538545771736893 | validation: 0.678320070932112]
	TIME [epoch: 1.35 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7607133480938114		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.7607133480938114 | validation: 0.5400209163144151]
	TIME [epoch: 1.35 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7114153393852216		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.7114153393852216 | validation: 0.5376771153963261]
	TIME [epoch: 1.35 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7082888622279648		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.7082888622279648 | validation: 0.5641467371042737]
	TIME [epoch: 1.35 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7068421305109215		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.7068421305109215 | validation: 0.5358266075102315]
	TIME [epoch: 1.35 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6986493109526601		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.6986493109526601 | validation: 0.5509388170482086]
	TIME [epoch: 1.35 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6948020302563566		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.6948020302563566 | validation: 0.5438293143716061]
	TIME [epoch: 1.35 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6905173094564548		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.6905173094564548 | validation: 0.54613892733868]
	TIME [epoch: 1.35 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6899458504304957		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.6899458504304957 | validation: 0.5285550665712284]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_266.pth
	Model improved!!!
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6882339693005665		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.6882339693005665 | validation: 0.5725480901893821]
	TIME [epoch: 1.34 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6923026649250897		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.6923026649250897 | validation: 0.5238122272589308]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7152365367589207		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.7152365367589207 | validation: 0.6964099038574467]
	TIME [epoch: 1.34 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7556884260486055		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.7556884260486055 | validation: 0.5623047651777383]
	TIME [epoch: 1.34 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7572280105846292		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.7572280105846292 | validation: 0.5528180684549113]
	TIME [epoch: 1.35 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.695865026179451		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.695865026179451 | validation: 0.5648257587921833]
	TIME [epoch: 1.34 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6961757569885992		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.6961757569885992 | validation: 0.5167991733320302]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_273.pth
	Model improved!!!
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7008566320610302		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.7008566320610302 | validation: 0.5546794528509106]
	TIME [epoch: 1.34 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.688658824005097		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.688658824005097 | validation: 0.5348602339393548]
	TIME [epoch: 1.34 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6835569241870165		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.6835569241870165 | validation: 0.5438665784433887]
	TIME [epoch: 1.34 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6858446774754283		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.6858446774754283 | validation: 0.5515132067324909]
	TIME [epoch: 1.34 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.696417739646108		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.696417739646108 | validation: 0.5469406220749955]
	TIME [epoch: 1.35 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7107431907280315		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.7107431907280315 | validation: 0.5996049039379995]
	TIME [epoch: 1.34 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.705453978486014		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.705453978486014 | validation: 0.5333682246152982]
	TIME [epoch: 1.34 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7036904780357197		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.7036904780357197 | validation: 0.6119999296332687]
	TIME [epoch: 1.34 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7050804486672629		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.7050804486672629 | validation: 0.5210579782317959]
	TIME [epoch: 1.34 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6897671558475632		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.6897671558475632 | validation: 0.5385499208980218]
	TIME [epoch: 1.34 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6726922669174425		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.6726922669174425 | validation: 0.5313719671288969]
	TIME [epoch: 1.34 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6665045757403684		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.6665045757403684 | validation: 0.5143429531965875]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6662529201325788		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.6662529201325788 | validation: 0.5260225189598032]
	TIME [epoch: 1.34 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6557031393371837		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.6557031393371837 | validation: 0.4981823487177054]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6606268188370984		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.6606268188370984 | validation: 0.5871147283950605]
	TIME [epoch: 1.34 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6806616710347123		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 0.6806616710347123 | validation: 0.7057054331641852]
	TIME [epoch: 1.34 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8412840167598589		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.8412840167598589 | validation: 0.6850001751774387]
	TIME [epoch: 1.34 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7222276319511667		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.7222276319511667 | validation: 0.5212008830441915]
	TIME [epoch: 1.34 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.65410864705803		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.65410864705803 | validation: 0.500156134315999]
	TIME [epoch: 1.35 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6714262313903305		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.6714262313903305 | validation: 0.5399868883530525]
	TIME [epoch: 1.34 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6568371893801884		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.6568371893801884 | validation: 0.5259653314800978]
	TIME [epoch: 1.35 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6566092294863844		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.6566092294863844 | validation: 0.5066071018956194]
	TIME [epoch: 1.34 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6478214968731709		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.6478214968731709 | validation: 0.5085776933232978]
	TIME [epoch: 1.34 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6443704446491688		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.6443704446491688 | validation: 0.5076755950899676]
	TIME [epoch: 1.34 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6384987638722687		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.6384987638722687 | validation: 0.5230706857057122]
	TIME [epoch: 1.34 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6355433026235969		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.6355433026235969 | validation: 0.5019608171580264]
	TIME [epoch: 1.34 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6509650805961065		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.6509650805961065 | validation: 0.6145926412663879]
	TIME [epoch: 1.34 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6879624975404015		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.6879624975404015 | validation: 0.6077987225474193]
	TIME [epoch: 1.34 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7684895587688046		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.7684895587688046 | validation: 0.5428419886350032]
	TIME [epoch: 1.34 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6557464134759903		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.6557464134759903 | validation: 0.49700821567705733]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.653646411121874		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.653646411121874 | validation: 0.5001199148880444]
	TIME [epoch: 1.34 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6347672256422365		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.6347672256422365 | validation: 0.5087037027011555]
	TIME [epoch: 1.34 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6193617399376957		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.6193617399376957 | validation: 0.4705294733641576]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6117674574437091		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.6117674574437091 | validation: 0.4840076607668891]
	TIME [epoch: 1.34 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6079470935107265		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.6079470935107265 | validation: 0.46352813810278426]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6049522979257064		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.6049522979257064 | validation: 0.5189221007148136]
	TIME [epoch: 1.34 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.612542910474459		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.612542910474459 | validation: 0.5452714175326986]
	TIME [epoch: 1.34 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.698852431591595		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.698852431591595 | validation: 0.8576899153919308]
	TIME [epoch: 1.34 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.782683380908471		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.782683380908471 | validation: 0.47334325738814587]
	TIME [epoch: 1.35 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6550216207491328		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.6550216207491328 | validation: 0.447239761665152]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6096406860454979		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.6096406860454979 | validation: 0.5380932187313198]
	TIME [epoch: 1.35 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6300838981154587		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.6300838981154587 | validation: 0.46076553692125694]
	TIME [epoch: 1.35 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5920872646480564		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.5920872646480564 | validation: 0.45566254712663357]
	TIME [epoch: 1.35 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5953228740771254		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.5953228740771254 | validation: 0.4752587547627002]
	TIME [epoch: 1.35 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5870138942708415		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.5870138942708415 | validation: 0.4433263229858817]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_318.pth
	Model improved!!!
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5727439433165736		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.5727439433165736 | validation: 0.4437640580888008]
	TIME [epoch: 1.34 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5696588945693043		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.5696588945693043 | validation: 0.4215940746547895]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5721805653240755		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.5721805653240755 | validation: 0.43647322929621507]
	TIME [epoch: 1.35 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5654655923074556		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.5654655923074556 | validation: 0.42506045591445096]
	TIME [epoch: 1.35 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6086726049963511		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.6086726049963511 | validation: 0.9871811319764355]
	TIME [epoch: 1.35 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8830126694132143		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.8830126694132143 | validation: 0.5027329881815205]
	TIME [epoch: 1.35 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7049359534951259		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.7049359534951259 | validation: 0.42769528017749403]
	TIME [epoch: 1.35 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6154402094251775		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.6154402094251775 | validation: 0.4995772207428898]
	TIME [epoch: 1.35 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6004715673443929		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.6004715673443929 | validation: 0.4574941420560736]
	TIME [epoch: 1.35 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.567501588206672		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.567501588206672 | validation: 0.4469216672545462]
	TIME [epoch: 1.35 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.571288159937067		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.571288159937067 | validation: 0.46523129740628716]
	TIME [epoch: 1.35 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.553027702919117		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.553027702919117 | validation: 0.4165139883511206]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5514984978862993		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.5514984978862993 | validation: 0.39579979245540287]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5527355031780282		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.5527355031780282 | validation: 0.4008164658231593]
	TIME [epoch: 1.35 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5420855125419723		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.5420855125419723 | validation: 0.40848483790942264]
	TIME [epoch: 1.34 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5329002044633032		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.5329002044633032 | validation: 0.37693655280035565]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5328945654392814		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.5328945654392814 | validation: 0.41323999670703415]
	TIME [epoch: 1.35 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5296470051551933		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.5296470051551933 | validation: 0.36218676885117296]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5848799514540296		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.5848799514540296 | validation: 1.0087323959379473]
	TIME [epoch: 1.35 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.89717195624916		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.89717195624916 | validation: 0.4808009581324079]
	TIME [epoch: 1.35 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.668011590067126		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.668011590067126 | validation: 0.3479757411345193]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5774937069655985		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.5774937069655985 | validation: 0.5388460174408847]
	TIME [epoch: 1.36 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5872884001426567		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.5872884001426567 | validation: 0.4084776292846772]
	TIME [epoch: 1.36 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5315766854730732		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.5315766854730732 | validation: 0.3793330827908146]
	TIME [epoch: 1.35 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5393062134977918		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.5393062134977918 | validation: 0.39724336969012297]
	TIME [epoch: 1.35 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206619699373782		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.5206619699373782 | validation: 0.40673659085636804]
	TIME [epoch: 1.36 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206452305982834		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.5206452305982834 | validation: 0.3673683067246494]
	TIME [epoch: 1.36 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5135316632879695		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.5135316632879695 | validation: 0.3572570477102726]
	TIME [epoch: 1.36 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5071584933042751		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.5071584933042751 | validation: 0.35633560549343796]
	TIME [epoch: 1.35 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5006247329970972		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.5006247329970972 | validation: 0.34809372135467204]
	TIME [epoch: 1.35 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4967937622524724		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.4967937622524724 | validation: 0.32843837402317144]
	TIME [epoch: 1.36 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48975075114053085		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.48975075114053085 | validation: 0.4289491131889744]
	TIME [epoch: 1.36 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5343522290423146		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.5343522290423146 | validation: 0.43327347957001106]
	TIME [epoch: 1.36 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7031065422700126		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.7031065422700126 | validation: 0.5098228040439893]
	TIME [epoch: 1.36 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5425651668798986		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.5425651668798986 | validation: 0.316028276207156]
	TIME [epoch: 1.36 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.520978903539077		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.520978903539077 | validation: 0.4036274779184492]
	TIME [epoch: 1.35 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49907010796512946		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.49907010796512946 | validation: 0.32268645967709486]
	TIME [epoch: 1.36 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48311974572987426		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.48311974572987426 | validation: 0.3873487888957028]
	TIME [epoch: 1.35 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4939954687855109		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.4939954687855109 | validation: 0.31970420317284054]
	TIME [epoch: 1.36 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5177268694620876		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.5177268694620876 | validation: 0.48128964133664315]
	TIME [epoch: 1.36 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5295144916105161		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.5295144916105161 | validation: 0.3600550074987]
	TIME [epoch: 1.36 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6039040076016637		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.6039040076016637 | validation: 0.44049430982283017]
	TIME [epoch: 1.36 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5082407839692104		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.5082407839692104 | validation: 0.31538786405198826]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4770208994372554		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.4770208994372554 | validation: 0.34721979175273116]
	TIME [epoch: 1.36 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46972558240682705		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.46972558240682705 | validation: 0.37460014239911416]
	TIME [epoch: 1.35 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4714216831171784		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.4714216831171784 | validation: 0.3013090781397375]
	TIME [epoch: 1.36 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47947782220115154		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.47947782220115154 | validation: 0.46076214041839675]
	TIME [epoch: 1.36 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49281265510760086		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.49281265510760086 | validation: 0.34353460015728043]
	TIME [epoch: 1.36 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6140102899674622		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.6140102899674622 | validation: 0.4743914460034011]
	TIME [epoch: 1.36 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5038365258396691		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.5038365258396691 | validation: 0.2879412146476566]
	TIME [epoch: 1.36 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.477414747663795		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.477414747663795 | validation: 0.3645854312083676]
	TIME [epoch: 1.36 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.456644968456644		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.456644968456644 | validation: 0.3155794035986922]
	TIME [epoch: 1.36 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4487565586102153		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.4487565586102153 | validation: 0.37981166291182866]
	TIME [epoch: 1.36 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4532431536260825		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.4532431536260825 | validation: 0.2735475185859017]
	TIME [epoch: 1.37 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4873989887241727		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.4873989887241727 | validation: 0.5785161714387484]
	TIME [epoch: 1.36 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5631293062101638		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.5631293062101638 | validation: 0.3719582001114081]
	TIME [epoch: 1.36 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5678196959137859		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.5678196959137859 | validation: 0.3169025296125382]
	TIME [epoch: 1.35 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43699927108846054		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.43699927108846054 | validation: 0.3979729533085729]
	TIME [epoch: 1.36 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44750232204664897		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.44750232204664897 | validation: 0.2865351905584107]
	TIME [epoch: 1.36 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4511318850137826		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.4511318850137826 | validation: 0.38589610193671964]
	TIME [epoch: 1.36 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4394093768281265		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.4394093768281265 | validation: 0.25931552680468545]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.449102669218961		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.449102669218961 | validation: 0.46658208462938316]
	TIME [epoch: 1.36 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.456821280569893		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.456821280569893 | validation: 0.27087017490833654]
	TIME [epoch: 1.36 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48776160838954824		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.48776160838954824 | validation: 0.4797810256448287]
	TIME [epoch: 1.36 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46521759172033184		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.46521759172033184 | validation: 0.2767506792681741]
	TIME [epoch: 1.35 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4441691187115779		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.4441691187115779 | validation: 0.39872545300951384]
	TIME [epoch: 1.35 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42516452171821884		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.42516452171821884 | validation: 0.2971892387689657]
	TIME [epoch: 1.35 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42127290274587337		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.42127290274587337 | validation: 0.37894681093217497]
	TIME [epoch: 1.35 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4306590263430259		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.4306590263430259 | validation: 0.2917470427687277]
	TIME [epoch: 1.36 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4080087167563009		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.4080087167563009 | validation: 0.3859029901214615]
	TIME [epoch: 1.36 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41211900588438505		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.41211900588438505 | validation: 0.25635417502688757]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_389.pth
	Model improved!!!
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4394767164652022		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.4394767164652022 | validation: 0.5826281521766637]
	TIME [epoch: 1.36 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5184782149599253		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.5184782149599253 | validation: 0.3164061781061263]
	TIME [epoch: 1.35 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5417174746275261		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.5417174746275261 | validation: 0.3891340198995512]
	TIME [epoch: 1.35 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39773312654247406		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.39773312654247406 | validation: 0.3727051546786695]
	TIME [epoch: 1.36 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39663005907448295		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.39663005907448295 | validation: 0.26777100491096195]
	TIME [epoch: 1.35 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.454934162514717		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.454934162514717 | validation: 0.45399085342602563]
	TIME [epoch: 1.35 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4282041277193982		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.4282041277193982 | validation: 0.26351377027726375]
	TIME [epoch: 1.35 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38851102833500023		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.38851102833500023 | validation: 0.35282779164135303]
	TIME [epoch: 1.36 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38045236164856167		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.38045236164856167 | validation: 0.3123075751912594]
	TIME [epoch: 1.35 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36719181824019737		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.36719181824019737 | validation: 0.2826963824146938]
	TIME [epoch: 1.35 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3711871695335131		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.3711871695335131 | validation: 0.3447230357842103]
	TIME [epoch: 1.36 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36968955637171774		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.36968955637171774 | validation: 0.25261362708865515]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3637294672113153		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.3637294672113153 | validation: 0.4132352121378052]
	TIME [epoch: 1.35 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37348395864337486		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.37348395864337486 | validation: 0.24270317182450257]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4342854178233037		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.4342854178233037 | validation: 0.6633395550525428]
	TIME [epoch: 1.35 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5253983922978014		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.5253983922978014 | validation: 0.27672476699506104]
	TIME [epoch: 1.35 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41417387954120616		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.41417387954120616 | validation: 0.3139284715103037]
	TIME [epoch: 1.35 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34841982426610474		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.34841982426610474 | validation: 0.3794171342750744]
	TIME [epoch: 1.35 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35044170436069283		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.35044170436069283 | validation: 0.2519075861426856]
	TIME [epoch: 1.35 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4585436615111416		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.4585436615111416 | validation: 0.44517854823388386]
	TIME [epoch: 1.35 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40406404907217175		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.40406404907217175 | validation: 0.2986634708392285]
	TIME [epoch: 1.35 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35274134763894394		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.35274134763894394 | validation: 0.3374820399523955]
	TIME [epoch: 1.35 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3496642381785624		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.3496642381785624 | validation: 0.27778238310282577]
	TIME [epoch: 1.35 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3339800070067588		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.3339800070067588 | validation: 0.3862035257142769]
	TIME [epoch: 1.35 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34985741729549946		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.34985741729549946 | validation: 0.24712865617925514]
	TIME [epoch: 1.36 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39006730638672327		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.39006730638672327 | validation: 0.4695347141862331]
	TIME [epoch: 1.35 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38518457532645545		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.38518457532645545 | validation: 0.2428912460294407]
	TIME [epoch: 1.35 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4015025567726016		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.4015025567726016 | validation: 0.351466129176378]
	TIME [epoch: 1.35 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3242905505607628		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.3242905505607628 | validation: 0.3531133674296157]
	TIME [epoch: 1.35 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3187216388352208		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.3187216388352208 | validation: 0.26161233126460226]
	TIME [epoch: 1.35 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.353096304796304		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.353096304796304 | validation: 0.44141946438486396]
	TIME [epoch: 1.36 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38881417198634505		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.38881417198634505 | validation: 0.2647942900856305]
	TIME [epoch: 1.35 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33452435958404514		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.33452435958404514 | validation: 0.3289675569394079]
	TIME [epoch: 1.35 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30925318970777965		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.30925318970777965 | validation: 0.24687824202556002]
	TIME [epoch: 1.35 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42476808679454814		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.42476808679454814 | validation: 0.47522073057380326]
	TIME [epoch: 1.35 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37547337898261635		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.37547337898261635 | validation: 0.24930860362115703]
	TIME [epoch: 1.35 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34119081092193143		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.34119081092193143 | validation: 0.44855802411555745]
	TIME [epoch: 1.35 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3428982418304949		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.3428982418304949 | validation: 0.2416373070866853]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37194248264996943		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.37194248264996943 | validation: 0.4368026299121149]
	TIME [epoch: 1.34 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3599797505326848		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.3599797505326848 | validation: 0.2803321999810231]
	TIME [epoch: 1.34 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34192490704925677		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.34192490704925677 | validation: 0.3407642857564901]
	TIME [epoch: 1.34 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3282493954251893		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.3282493954251893 | validation: 0.3669756867523124]
	TIME [epoch: 1.34 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3190813276690924		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.3190813276690924 | validation: 0.2572575379242541]
	TIME [epoch: 1.34 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3133798439181299		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.3133798439181299 | validation: 0.3820083055892724]
	TIME [epoch: 1.35 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32194647483200656		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.32194647483200656 | validation: 0.2740151198451469]
	TIME [epoch: 1.34 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2974895658020558		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.2974895658020558 | validation: 0.3059810536630324]
	TIME [epoch: 1.35 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2861099489207396		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.2861099489207396 | validation: 0.27310287821669654]
	TIME [epoch: 1.34 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.279769459661828		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.279769459661828 | validation: 0.34885852941766765]
	TIME [epoch: 1.34 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2890251520842357		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.2890251520842357 | validation: 0.2390626213417198]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2934470868300753		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.2934470868300753 | validation: 0.4046399030346981]
	TIME [epoch: 1.35 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3094023239192931		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.3094023239192931 | validation: 0.2318761150338629]
	TIME [epoch: 1.35 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.351480429724099		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.351480429724099 | validation: 0.535574189941383]
	TIME [epoch: 1.34 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3971114474002401		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.3971114474002401 | validation: 0.2394961921417088]
	TIME [epoch: 1.34 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33682078136281823		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.33682078136281823 | validation: 0.33147772989118396]
	TIME [epoch: 1.34 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29422171041270717		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.29422171041270717 | validation: 0.3241916286060831]
	TIME [epoch: 1.34 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27562890884752295		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.27562890884752295 | validation: 0.23238300412807217]
	TIME [epoch: 1.34 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32473604552547797		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.32473604552547797 | validation: 0.38874760233485417]
	TIME [epoch: 1.34 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29902258439165813		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.29902258439165813 | validation: 0.2519194386215093]
	TIME [epoch: 1.34 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2764994334000913		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.2764994334000913 | validation: 0.28641857535812565]
	TIME [epoch: 1.34 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4199712379672258		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.4199712379672258 | validation: 0.45771237187035824]
	TIME [epoch: 1.34 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36156839844996		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.36156839844996 | validation: 0.27015403568478863]
	TIME [epoch: 1.34 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2820922710238958		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.2820922710238958 | validation: 0.34964099964144274]
	TIME [epoch: 1.34 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.593348329548017		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.593348329548017 | validation: 0.31679238503350904]
	TIME [epoch: 1.34 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.483763603875953		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.483763603875953 | validation: 0.5043283833696445]
	TIME [epoch: 1.34 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3460300215530478		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.3460300215530478 | validation: 0.2837632284436955]
	TIME [epoch: 1.34 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34737493440566525		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.34737493440566525 | validation: 0.39998145009875463]
	TIME [epoch: 1.34 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29082015733086214		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.29082015733086214 | validation: 0.35833538009771515]
	TIME [epoch: 1.35 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2786174685067462		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.2786174685067462 | validation: 0.3153284638003373]
	TIME [epoch: 1.34 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27293991116828403		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.27293991116828403 | validation: 0.3387072685334256]
	TIME [epoch: 1.34 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26726111522994345		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.26726111522994345 | validation: 0.30411269761524046]
	TIME [epoch: 1.34 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2535637018750632		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.2535637018750632 | validation: 0.32150183953396577]
	TIME [epoch: 1.34 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2568674252499199		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.2568674252499199 | validation: 0.2913414687374362]
	TIME [epoch: 1.34 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2559458622061517		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.2559458622061517 | validation: 0.2982478200197446]
	TIME [epoch: 1.34 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26277439732363034		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.26277439732363034 | validation: 0.364571306019913]
	TIME [epoch: 1.34 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29558387584838897		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.29558387584838897 | validation: 0.24073102292602094]
	TIME [epoch: 1.34 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3650508760761447		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.3650508760761447 | validation: 0.547875420355752]
	TIME [epoch: 1.34 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.368526756175769		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.368526756175769 | validation: 0.24862197122630683]
	TIME [epoch: 1.34 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3051963826565448		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.3051963826565448 | validation: 0.3153615297730414]
	TIME [epoch: 1.34 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2574315077661424		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.2574315077661424 | validation: 0.3174530231272815]
	TIME [epoch: 1.34 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2462980811607507		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.2462980811607507 | validation: 0.25971015446429496]
	TIME [epoch: 1.34 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24796348225296735		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.24796348225296735 | validation: 0.336123559391186]
	TIME [epoch: 1.34 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2572435535642639		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.2572435535642639 | validation: 0.2610465003431403]
	TIME [epoch: 1.34 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2478575487100083		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.2478575487100083 | validation: 0.2750338856296292]
	TIME [epoch: 1.34 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2645326762894643		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.2645326762894643 | validation: 0.3730746975524222]
	TIME [epoch: 1.34 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2788737960667589		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.2788737960667589 | validation: 0.2283455087831059]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2784447667029867		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.2784447667029867 | validation: 0.4270938708054284]
	TIME [epoch: 1.34 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2997765565950457		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.2997765565950457 | validation: 0.23287479450603207]
	TIME [epoch: 1.34 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2669053060624056		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.2669053060624056 | validation: 0.3829786740905484]
	TIME [epoch: 1.34 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27606605662056544		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.27606605662056544 | validation: 0.23185411890189853]
	TIME [epoch: 1.35 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27932932477211286		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.27932932477211286 | validation: 0.45561968476169645]
	TIME [epoch: 1.34 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34929960964440926		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.34929960964440926 | validation: 0.24621336809432126]
	TIME [epoch: 1.34 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24982829081867522		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.24982829081867522 | validation: 0.29010571087866555]
	TIME [epoch: 1.34 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23715526146403762		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.23715526146403762 | validation: 0.3040209463070187]
	TIME [epoch: 1.34 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25015385191410283		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.25015385191410283 | validation: 0.22455256616065747]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25864683908838165		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.25864683908838165 | validation: 0.4594208697795919]
	TIME [epoch: 1.34 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33316977440222983		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.33316977440222983 | validation: 0.22276848515303682]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2774701248256834		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.2774701248256834 | validation: 0.32304605790685537]
	TIME [epoch: 1.34 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2503911389603891		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.2503911389603891 | validation: 0.24745698763386087]
	TIME [epoch: 1.34 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2346670775230642		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.2346670775230642 | validation: 0.31091300690058943]
	TIME [epoch: 1.34 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2478347850247631		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.2478347850247631 | validation: 0.2519748058429964]
	TIME [epoch: 1.34 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24097662641017464		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.24097662641017464 | validation: 0.29276001200222435]
	TIME [epoch: 1.34 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23524205714434945		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.23524205714434945 | validation: 0.26457680127060995]
	TIME [epoch: 1.34 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2393875361239377		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.2393875361239377 | validation: 0.2572914018941522]
	TIME [epoch: 1.34 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23904509640913854		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.23904509640913854 | validation: 0.33882610751137765]
	TIME [epoch: 1.34 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24716402567954512		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.24716402567954512 | validation: 0.24232073565851728]
	TIME [epoch: 1.34 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2533672550598113		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.2533672550598113 | validation: 0.3561409189326418]
	TIME [epoch: 1.34 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2531238076945144		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.2531238076945144 | validation: 0.20317506304733685]
	TIME [epoch: 1.34 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.283222695826808		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.283222695826808 | validation: 0.4606153862702341]
	TIME [epoch: 1.34 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3473813157612514		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.3473813157612514 | validation: 0.20941788454504892]
	TIME [epoch: 1.34 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27720564815795834		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.27720564815795834 | validation: 0.29494631841095387]
	TIME [epoch: 1.35 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2308613839365365		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.2308613839365365 | validation: 0.2960334881295925]
	TIME [epoch: 1.34 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23775568404275021		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.23775568404275021 | validation: 0.476089329458475]
	TIME [epoch: 180 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7422409401764146		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.7422409401764146 | validation: 0.5339871980921498]
	TIME [epoch: 2.68 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.804108725928968		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.804108725928968 | validation: 0.4186572635882425]
	TIME [epoch: 2.66 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7153495902348093		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.7153495902348093 | validation: 0.331812255364274]
	TIME [epoch: 2.66 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6092638918095663		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.6092638918095663 | validation: 0.3261771651804952]
	TIME [epoch: 2.66 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46211256811652035		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.46211256811652035 | validation: 0.4584452239821033]
	TIME [epoch: 2.66 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2837992265985493		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.2837992265985493 | validation: 0.42742492845328484]
	TIME [epoch: 2.67 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28638002648803146		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.28638002648803146 | validation: 0.2976715736235313]
	TIME [epoch: 2.66 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2363049913375506		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.2363049913375506 | validation: 0.3443399043361441]
	TIME [epoch: 2.66 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23776977892701326		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.23776977892701326 | validation: 0.2860134303874157]
	TIME [epoch: 2.66 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22626884946282935		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.22626884946282935 | validation: 0.2755991695277561]
	TIME [epoch: 2.67 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22697661023990862		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.22697661023990862 | validation: 0.33533054120248507]
	TIME [epoch: 2.67 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23837422075360462		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.23837422075360462 | validation: 0.2538092563076168]
	TIME [epoch: 2.67 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24017731496829606		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.24017731496829606 | validation: 0.31024399305809774]
	TIME [epoch: 2.67 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23543646178575436		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.23543646178575436 | validation: 0.2647225652776168]
	TIME [epoch: 2.67 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2288104226854552		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.2288104226854552 | validation: 0.30170312487036227]
	TIME [epoch: 2.67 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2231188572848898		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.2231188572848898 | validation: 0.25391822366030736]
	TIME [epoch: 2.67 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22062744182741947		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.22062744182741947 | validation: 0.287699632787311]
	TIME [epoch: 2.67 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2184895403467958		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.2184895403467958 | validation: 0.26358231837176965]
	TIME [epoch: 2.67 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2174659804858017		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.2174659804858017 | validation: 0.3049588961489398]
	TIME [epoch: 2.67 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22756859516113545		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.22756859516113545 | validation: 0.20252856536067868]
	TIME [epoch: 2.67 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28199361205923623		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.28199361205923623 | validation: 0.4988545877292449]
	TIME [epoch: 2.66 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3261542540295409		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.3261542540295409 | validation: 0.2051101332087419]
	TIME [epoch: 2.67 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31537450870416833		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.31537450870416833 | validation: 0.2397802423622042]
	TIME [epoch: 2.66 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25080967621056255		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.25080967621056255 | validation: 0.4183420863712288]
	TIME [epoch: 2.67 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28896264890041673		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.28896264890041673 | validation: 0.25009831869802646]
	TIME [epoch: 2.67 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2242816550862915		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.2242816550862915 | validation: 0.2851819908717224]
	TIME [epoch: 2.66 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2154779267138215		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.2154779267138215 | validation: 0.30740260495406474]
	TIME [epoch: 2.67 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21997827429992012		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.21997827429992012 | validation: 0.2728699510484708]
	TIME [epoch: 2.67 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2376666333059189		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.2376666333059189 | validation: 0.3050596965256223]
	TIME [epoch: 2.67 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23675270710647545		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.23675270710647545 | validation: 0.25631714308059067]
	TIME [epoch: 2.67 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21720954426353417		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.21720954426353417 | validation: 0.2849681623298775]
	TIME [epoch: 2.67 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21534660798622626		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.21534660798622626 | validation: 0.22843619655072214]
	TIME [epoch: 2.67 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2108079296976806		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.2108079296976806 | validation: 0.3062355072536871]
	TIME [epoch: 2.69 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22058688044661107		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.22058688044661107 | validation: 0.23469802971823334]
	TIME [epoch: 2.67 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22010218330519024		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.22010218330519024 | validation: 0.27698723486590426]
	TIME [epoch: 2.68 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21390953012119585		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.21390953012119585 | validation: 0.22641473600830478]
	TIME [epoch: 2.68 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21043764321999625		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.21043764321999625 | validation: 0.36560995628353277]
	TIME [epoch: 2.68 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28276321523493436		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.28276321523493436 | validation: 0.2811724737520704]
	TIME [epoch: 2.67 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5097325127838714		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.5097325127838714 | validation: 0.3222059626530728]
	TIME [epoch: 2.67 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3882325817823257		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.3882325817823257 | validation: 0.312091178875193]
	TIME [epoch: 2.67 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23920652925414349		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.23920652925414349 | validation: 0.34202614775663004]
	TIME [epoch: 2.67 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2676674129862012		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.2676674129862012 | validation: 0.2256403336762523]
	TIME [epoch: 2.68 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22448623492312375		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.22448623492312375 | validation: 0.39079877407051766]
	TIME [epoch: 2.67 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24499254496830047		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.24499254496830047 | validation: 0.20828409664972056]
	TIME [epoch: 2.69 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22424913745564776		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.22424913745564776 | validation: 0.2747687993812344]
	TIME [epoch: 2.67 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20958391216325428		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.20958391216325428 | validation: 0.27218953547364866]
	TIME [epoch: 2.67 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20506613860610784		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.20506613860610784 | validation: 0.23846956079693712]
	TIME [epoch: 2.67 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20214410218844278		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.20214410218844278 | validation: 0.2643135289465026]
	TIME [epoch: 2.68 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20271646436298038		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.20271646436298038 | validation: 0.27874235654049645]
	TIME [epoch: 2.67 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20986580882130781		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.20986580882130781 | validation: 0.23279763222583522]
	TIME [epoch: 2.68 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.205904778959722		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.205904778959722 | validation: 0.2967826622422048]
	TIME [epoch: 2.67 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21778806881742627		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.21778806881742627 | validation: 0.21678616482279384]
	TIME [epoch: 2.68 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22444304712261157		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.22444304712261157 | validation: 0.32393944457202856]
	TIME [epoch: 2.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2590480671787748		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.2590480671787748 | validation: 0.21429731049749773]
	TIME [epoch: 2.67 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3610585062875591		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.3610585062875591 | validation: 0.3100677905675621]
	TIME [epoch: 2.68 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21911939920036713		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.21911939920036713 | validation: 0.3238669985865234]
	TIME [epoch: 2.67 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.274299363474753		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.274299363474753 | validation: 0.2161966084073419]
	TIME [epoch: 2.68 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2371133594870834		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.2371133594870834 | validation: 0.34788400125677943]
	TIME [epoch: 2.68 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22956670579238572		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.22956670579238572 | validation: 0.22097357546103424]
	TIME [epoch: 2.67 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22360631384949523		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.22360631384949523 | validation: 0.24546893228577937]
	TIME [epoch: 2.67 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20022025697464038		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.20022025697464038 | validation: 0.29450994948123854]
	TIME [epoch: 2.67 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21246093916761305		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.21246093916761305 | validation: 0.20911397397806805]
	TIME [epoch: 2.68 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.218983388436294		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.218983388436294 | validation: 0.33123516148708204]
	TIME [epoch: 2.67 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22471649288099108		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.22471649288099108 | validation: 0.21194240724944644]
	TIME [epoch: 2.68 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20634803263044746		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.20634803263044746 | validation: 0.28198239609753417]
	TIME [epoch: 2.67 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20702317804804937		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.20702317804804937 | validation: 0.20573555644785868]
	TIME [epoch: 2.69 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.214104721978006		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.214104721978006 | validation: 0.2381902064913507]
	TIME [epoch: 2.68 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21132291855321494		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.21132291855321494 | validation: 0.3449364918866155]
	TIME [epoch: 2.68 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2473064871367707		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.2473064871367707 | validation: 0.1995954092060993]
	TIME [epoch: 2.67 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2947761767683922		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.2947761767683922 | validation: 0.3324498636566773]
	TIME [epoch: 2.67 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22248680129938683		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.22248680129938683 | validation: 0.25024939179616446]
	TIME [epoch: 2.67 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20095330748682222		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.20095330748682222 | validation: 0.26930233093519473]
	TIME [epoch: 2.68 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20804107311883782		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.20804107311883782 | validation: 0.27026554812532305]
	TIME [epoch: 2.67 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2039380390689783		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.2039380390689783 | validation: 0.23650886490199774]
	TIME [epoch: 2.68 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20817633675184277		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.20817633675184277 | validation: 0.21539015634723035]
	TIME [epoch: 2.67 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.203329554646781		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.203329554646781 | validation: 0.2928719266579017]
	TIME [epoch: 2.68 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2071998314814863		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.2071998314814863 | validation: 0.23065140083065572]
	TIME [epoch: 2.68 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20898249548222833		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.20898249548222833 | validation: 0.2939688548425464]
	TIME [epoch: 2.67 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21308070894301268		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.21308070894301268 | validation: 0.18711610413044155]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23695062217015092		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.23695062217015092 | validation: 0.3866770829604572]
	TIME [epoch: 2.66 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26400346890769383		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.26400346890769383 | validation: 0.19794209385671716]
	TIME [epoch: 2.66 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21880052888152826		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.21880052888152826 | validation: 0.2995747533444446]
	TIME [epoch: 2.66 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22014465573831551		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.22014465573831551 | validation: 0.211598102346741]
	TIME [epoch: 2.66 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2590375865738791		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.2590375865738791 | validation: 0.25223600276499936]
	TIME [epoch: 2.66 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19856025098545937		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.19856025098545937 | validation: 0.2976435176563979]
	TIME [epoch: 2.66 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23302727791679154		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.23302727791679154 | validation: 0.22139787934452504]
	TIME [epoch: 2.66 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19934281403014908		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.19934281403014908 | validation: 0.2628694918520731]
	TIME [epoch: 2.67 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19907037026324104		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.19907037026324104 | validation: 0.24752345441335236]
	TIME [epoch: 2.68 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19874924619247852		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.19874924619247852 | validation: 0.21230490947153632]
	TIME [epoch: 2.66 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1965913014900433		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.1965913014900433 | validation: 0.2797295125738774]
	TIME [epoch: 2.66 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20600806185275797		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.20600806185275797 | validation: 0.18977665439433308]
	TIME [epoch: 2.66 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24317696517305018		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.24317696517305018 | validation: 0.3357564861428981]
	TIME [epoch: 2.66 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24812589883072206		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.24812589883072206 | validation: 0.2292151735824063]
	TIME [epoch: 2.66 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19831684889149587		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.19831684889149587 | validation: 0.23178857051281368]
	TIME [epoch: 2.66 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19317111156017927		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.19317111156017927 | validation: 0.41579534147735986]
	TIME [epoch: 2.66 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3323543210003752		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.3323543210003752 | validation: 0.19925613830622768]
	TIME [epoch: 2.66 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2357702152135192		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.2357702152135192 | validation: 0.27729767885781337]
	TIME [epoch: 2.66 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21003142515962836		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.21003142515962836 | validation: 0.24253238597942037]
	TIME [epoch: 2.66 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2032650181223788		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.2032650181223788 | validation: 0.21110356632214877]
	TIME [epoch: 2.67 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1996243140459477		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.1996243140459477 | validation: 0.26286613244901663]
	TIME [epoch: 2.66 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20404334784008693		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.20404334784008693 | validation: 0.2388131804852046]
	TIME [epoch: 2.66 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19968652474028922		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.19968652474028922 | validation: 0.20316733916791324]
	TIME [epoch: 2.66 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2039808902783558		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.2039808902783558 | validation: 0.2620725473228511]
	TIME [epoch: 2.68 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20145245895693645		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.20145245895693645 | validation: 0.21687703437856093]
	TIME [epoch: 2.66 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2007350062100256		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.2007350062100256 | validation: 0.23681268857243395]
	TIME [epoch: 2.66 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1938773946244421		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.1938773946244421 | validation: 0.23359295416274192]
	TIME [epoch: 2.66 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19030759352179719		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.19030759352179719 | validation: 0.23894687883854268]
	TIME [epoch: 2.66 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19198353580600597		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.19198353580600597 | validation: 0.20700745382879263]
	TIME [epoch: 2.66 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18904421650057784		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.18904421650057784 | validation: 0.2730824004623868]
	TIME [epoch: 2.66 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.197908086954867		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.197908086954867 | validation: 0.19289953595893108]
	TIME [epoch: 2.67 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2044279214006953		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.2044279214006953 | validation: 0.3645558089781374]
	TIME [epoch: 2.66 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2618238498763388		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.2618238498763388 | validation: 0.18719704978030682]
	TIME [epoch: 2.66 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3027659763622189		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.3027659763622189 | validation: 0.25432764974741123]
	TIME [epoch: 2.66 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19824477580142866		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.19824477580142866 | validation: 0.2793959341790716]
	TIME [epoch: 2.67 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22032035073548842		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.22032035073548842 | validation: 0.2081740392014827]
	TIME [epoch: 2.67 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20118766319228634		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.20118766319228634 | validation: 0.3494233619780322]
	TIME [epoch: 2.67 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27637176429503		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.27637176429503 | validation: 0.19834001066254325]
	TIME [epoch: 2.67 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20999678478727113		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.20999678478727113 | validation: 0.19938768257941467]
	TIME [epoch: 2.66 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19638165732912272		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.19638165732912272 | validation: 0.2666655554163346]
	TIME [epoch: 2.66 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20353992104059962		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.20353992104059962 | validation: 0.21863236907056752]
	TIME [epoch: 2.66 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1915138574236767		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.1915138574236767 | validation: 0.2338537978719198]
	TIME [epoch: 2.67 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18986947736855583		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.18986947736855583 | validation: 0.23342859940167734]
	TIME [epoch: 2.66 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18548652818027567		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.18548652818027567 | validation: 0.2211407243340612]
	TIME [epoch: 2.66 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19081067087043813		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.19081067087043813 | validation: 0.21339447999488065]
	TIME [epoch: 2.66 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19220088938913396		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.19220088938913396 | validation: 0.24952556927228886]
	TIME [epoch: 2.66 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19158660690703047		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.19158660690703047 | validation: 0.20267124955183724]
	TIME [epoch: 2.66 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20638957366459984		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.20638957366459984 | validation: 0.266513849089907]
	TIME [epoch: 2.66 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20551665342940995		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.20551665342940995 | validation: 0.19092648664819034]
	TIME [epoch: 2.66 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19731232523609799		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.19731232523609799 | validation: 0.21862372242410688]
	TIME [epoch: 2.66 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.188391946780512		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.188391946780512 | validation: 0.21489498050715464]
	TIME [epoch: 2.66 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18772552965365474		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.18772552965365474 | validation: 0.2159731155224438]
	TIME [epoch: 2.66 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18823525749643083		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.18823525749643083 | validation: 0.19760160697841855]
	TIME [epoch: 2.67 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19045870702572792		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.19045870702572792 | validation: 0.2466707164709966]
	TIME [epoch: 2.66 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20019844542959375		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.20019844542959375 | validation: 0.1853933247185377]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19905479313017943		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.19905479313017943 | validation: 0.36235775259807473]
	TIME [epoch: 2.66 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25593397377301186		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.25593397377301186 | validation: 0.1734633481293991]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24122456009639798		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.24122456009639798 | validation: 0.26901433730877006]
	TIME [epoch: 2.66 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20430793681607962		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.20430793681607962 | validation: 0.20159112832436601]
	TIME [epoch: 2.66 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19038789858068977		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.19038789858068977 | validation: 0.22447015156772673]
	TIME [epoch: 2.66 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18692065681893177		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.18692065681893177 | validation: 0.24913845395956125]
	TIME [epoch: 2.66 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20245934147800376		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.20245934147800376 | validation: 0.19681693065939548]
	TIME [epoch: 2.66 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18806805008854788		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.18806805008854788 | validation: 0.22235456666354808]
	TIME [epoch: 2.66 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19146580077179096		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.19146580077179096 | validation: 0.23279804012520527]
	TIME [epoch: 2.66 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19758325276111696		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.19758325276111696 | validation: 0.1975715795031838]
	TIME [epoch: 2.66 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19354178254275856		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.19354178254275856 | validation: 0.2771025222001579]
	TIME [epoch: 2.66 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21287661517319315		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.21287661517319315 | validation: 0.17558607381707356]
	TIME [epoch: 2.66 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3000114454600287		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.3000114454600287 | validation: 0.26862549342270586]
	TIME [epoch: 2.66 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.199863469946659		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.199863469946659 | validation: 0.20726669002895745]
	TIME [epoch: 2.66 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1836425469486016		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.1836425469486016 | validation: 0.20184326835650648]
	TIME [epoch: 2.66 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18693522091592735		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.18693522091592735 | validation: 0.2548162532872788]
	TIME [epoch: 2.66 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19102748992745733		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.19102748992745733 | validation: 0.2311884925855633]
	TIME [epoch: 2.66 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1916356861052568		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.1916356861052568 | validation: 0.20235010980579005]
	TIME [epoch: 2.66 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20420724570622908		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.20420724570622908 | validation: 0.2299696184389055]
	TIME [epoch: 2.66 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18719329971161755		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.18719329971161755 | validation: 0.23424312899826708]
	TIME [epoch: 2.67 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1939344986666014		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.1939344986666014 | validation: 0.20161256750563172]
	TIME [epoch: 2.66 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18585126642371286		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.18585126642371286 | validation: 0.24183371728738978]
	TIME [epoch: 2.66 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1875080411528653		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.1875080411528653 | validation: 0.2061416407855131]
	TIME [epoch: 2.66 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36299588598723614		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.36299588598723614 | validation: 0.25698822234972596]
	TIME [epoch: 2.66 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21086840900899126		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.21086840900899126 | validation: 0.2900210881808305]
	TIME [epoch: 2.66 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23947250707860826		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.23947250707860826 | validation: 0.21762644528134772]
	TIME [epoch: 2.66 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20535666729541924		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.20535666729541924 | validation: 0.18980493075980523]
	TIME [epoch: 2.66 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22537107012891938		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.22537107012891938 | validation: 0.3288788544620344]
	TIME [epoch: 2.66 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21776137974077447		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.21776137974077447 | validation: 0.19919132865327926]
	TIME [epoch: 2.66 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.183889766767128		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.183889766767128 | validation: 0.22363573091179578]
	TIME [epoch: 2.66 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1869453616620861		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.1869453616620861 | validation: 0.2523271240813076]
	TIME [epoch: 2.67 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18899834767117069		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.18899834767117069 | validation: 0.21851979498845897]
	TIME [epoch: 2.66 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18448797818065746		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.18448797818065746 | validation: 0.19142987064868633]
	TIME [epoch: 2.66 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1831332222873358		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.1831332222873358 | validation: 0.25060459987083555]
	TIME [epoch: 2.66 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18864796972367998		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.18864796972367998 | validation: 0.19797630546755723]
	TIME [epoch: 2.66 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18403475528294624		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.18403475528294624 | validation: 0.21235334881293624]
	TIME [epoch: 2.66 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18154176329015242		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.18154176329015242 | validation: 0.24019487530333633]
	TIME [epoch: 2.66 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19282666403125148		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.19282666403125148 | validation: 0.18609207215791435]
	TIME [epoch: 2.66 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19176639841481213		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.19176639841481213 | validation: 0.22323694027945754]
	TIME [epoch: 2.66 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19030623238737857		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.19030623238737857 | validation: 0.21206865392719976]
	TIME [epoch: 2.66 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18414148435789726		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.18414148435789726 | validation: 0.26816705350837194]
	TIME [epoch: 2.66 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2234468817214602		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.2234468817214602 | validation: 0.17661573914315168]
	TIME [epoch: 2.66 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2677656957848991		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.2677656957848991 | validation: 0.2972836878436992]
	TIME [epoch: 2.66 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20941307102918605		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.20941307102918605 | validation: 0.27153371985566044]
	TIME [epoch: 2.66 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20698573445529952		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.20698573445529952 | validation: 0.2105048864179791]
	TIME [epoch: 2.66 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1974994300704335		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.1974994300704335 | validation: 0.22007302216288327]
	TIME [epoch: 2.66 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1820203178753961		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.1820203178753961 | validation: 0.1873662648028323]
	TIME [epoch: 2.66 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19861142845772178		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.19861142845772178 | validation: 0.24935314738930636]
	TIME [epoch: 2.66 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1843353467584279		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.1843353467584279 | validation: 0.2200727682786099]
	TIME [epoch: 2.66 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18344637590895016		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.18344637590895016 | validation: 0.2076531341273111]
	TIME [epoch: 2.66 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18315091675752945		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.18315091675752945 | validation: 0.2371045166367205]
	TIME [epoch: 2.66 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18332964246522576		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.18332964246522576 | validation: 0.1912289474409054]
	TIME [epoch: 2.66 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17871937991165152		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.17871937991165152 | validation: 0.2202571057867307]
	TIME [epoch: 2.66 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18373055190820817		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.18373055190820817 | validation: 0.19072359682544057]
	TIME [epoch: 2.67 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18081162861012626		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.18081162861012626 | validation: 0.2502634397273546]
	TIME [epoch: 2.66 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1939027271565497		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.1939027271565497 | validation: 0.17503653064398703]
	TIME [epoch: 2.66 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.196548871318357		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.196548871318357 | validation: 0.2500819084978505]
	TIME [epoch: 2.67 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19161037569256195		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.19161037569256195 | validation: 0.20256778710427295]
	TIME [epoch: 2.66 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18019725178859475		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.18019725178859475 | validation: 0.18291280352065772]
	TIME [epoch: 2.67 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18155592809998441		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.18155592809998441 | validation: 0.25318688614230844]
	TIME [epoch: 2.66 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1909122363776993		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.1909122363776993 | validation: 0.16961539041581197]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_696.pth
	Model improved!!!
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1927529953471953		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.1927529953471953 | validation: 0.2872868513148912]
	TIME [epoch: 2.66 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21601450869263297		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.21601450869263297 | validation: 0.1643282098417561]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19355965139413753		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.19355965139413753 | validation: 0.2350855016793283]
	TIME [epoch: 2.67 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18033765194449275		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.18033765194449275 | validation: 0.22681845747274798]
	TIME [epoch: 2.66 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18562750736242983		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.18562750736242983 | validation: 0.17606413099011942]
	TIME [epoch: 2.66 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18479531844116268		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.18479531844116268 | validation: 0.24877402845248342]
	TIME [epoch: 2.66 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19014122776896128		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.19014122776896128 | validation: 0.17663840865724123]
	TIME [epoch: 2.66 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18543642140790317		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.18543642140790317 | validation: 0.2244446743420766]
	TIME [epoch: 2.66 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18663823917717906		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.18663823917717906 | validation: 0.17977143615947577]
	TIME [epoch: 2.66 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1922361332284338		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.1922361332284338 | validation: 0.23636827238833807]
	TIME [epoch: 2.66 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18141735561728364		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.18141735561728364 | validation: 0.19488528173042075]
	TIME [epoch: 2.66 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17743506681684615		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.17743506681684615 | validation: 0.223633295068783]
	TIME [epoch: 2.66 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17861934288345196		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.17861934288345196 | validation: 0.18546347154546097]
	TIME [epoch: 2.66 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18153776431076726		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.18153776431076726 | validation: 0.21222792675954594]
	TIME [epoch: 2.67 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1899038065565304		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.1899038065565304 | validation: 0.2340978785965934]
	TIME [epoch: 2.66 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1982905753960002		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.1982905753960002 | validation: 0.1851081674887275]
	TIME [epoch: 2.66 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18647740921711628		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.18647740921711628 | validation: 0.21175792499933951]
	TIME [epoch: 2.66 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19989887707249324		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.19989887707249324 | validation: 0.21102407670312925]
	TIME [epoch: 2.66 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17745646287864658		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.17745646287864658 | validation: 0.2628066321329889]
	TIME [epoch: 2.66 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20772224022217212		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.20772224022217212 | validation: 0.17060869839928894]
	TIME [epoch: 2.66 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20328888507777026		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.20328888507777026 | validation: 0.2711162514469888]
	TIME [epoch: 2.66 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1932698873237244		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.1932698873237244 | validation: 0.213882302151005]
	TIME [epoch: 2.66 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17850058440107242		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.17850058440107242 | validation: 0.25219107050473244]
	TIME [epoch: 2.66 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.473809212827795		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.473809212827795 | validation: 0.25232673055230975]
	TIME [epoch: 2.66 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39875409961616193		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.39875409961616193 | validation: 0.2967553788599017]
	TIME [epoch: 2.67 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.265377186222587		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.265377186222587 | validation: 0.2731771642451796]
	TIME [epoch: 2.66 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1891041670584378		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.1891041670584378 | validation: 0.24445418669697086]
	TIME [epoch: 2.66 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19552600698621533		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.19552600698621533 | validation: 0.2282174199605561]
	TIME [epoch: 2.66 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19027873110335647		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.19027873110335647 | validation: 0.2436200843146585]
	TIME [epoch: 2.66 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18032478288766104		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.18032478288766104 | validation: 0.23270809832948058]
	TIME [epoch: 2.66 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17638164004151563		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.17638164004151563 | validation: 0.21491775279049696]
	TIME [epoch: 2.66 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17193337261366562		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.17193337261366562 | validation: 0.21593373990439424]
	TIME [epoch: 2.66 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17406303228535677		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.17406303228535677 | validation: 0.2315101786541658]
	TIME [epoch: 2.66 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17848417502671673		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.17848417502671673 | validation: 0.17969312032723952]
	TIME [epoch: 2.66 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1925160400338467		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.1925160400338467 | validation: 0.20990618522996393]
	TIME [epoch: 2.66 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18018969180159983		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.18018969180159983 | validation: 0.2439400606502166]
	TIME [epoch: 2.66 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18176976770920195		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.18176976770920195 | validation: 0.20144374425676387]
	TIME [epoch: 2.67 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17675260592608005		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.17675260592608005 | validation: 0.20567420780977286]
	TIME [epoch: 2.66 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17709468216950178		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.17709468216950178 | validation: 0.2144878924099748]
	TIME [epoch: 2.66 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17488416782251906		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.17488416782251906 | validation: 0.19821644338992123]
	TIME [epoch: 2.66 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1741851413456246		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.1741851413456246 | validation: 0.21946103589757593]
	TIME [epoch: 2.66 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17330570276486046		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.17330570276486046 | validation: 0.20597949623964734]
	TIME [epoch: 2.66 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1752437987660875		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.1752437987660875 | validation: 0.21373743489925326]
	TIME [epoch: 2.66 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17808576555012065		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.17808576555012065 | validation: 0.22622029595370005]
	TIME [epoch: 2.68 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18183148531547857		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.18183148531547857 | validation: 0.19382884855988786]
	TIME [epoch: 2.66 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17598558084479363		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.17598558084479363 | validation: 0.22815020439738368]
	TIME [epoch: 2.66 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40285988454143906		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.40285988454143906 | validation: 0.30535047218513417]
	TIME [epoch: 2.66 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3115279171282976		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.3115279171282976 | validation: 0.261702331925716]
	TIME [epoch: 2.66 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19684914681182433		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.19684914681182433 | validation: 0.22957489737943365]
	TIME [epoch: 2.66 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19040937487309825		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.19040937487309825 | validation: 0.195213805936621]
	TIME [epoch: 2.66 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1968286931391468		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.1968286931391468 | validation: 0.2099547370172704]
	TIME [epoch: 2.66 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17326210974626957		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.17326210974626957 | validation: 0.23584513677071373]
	TIME [epoch: 2.66 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17857057365780235		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.17857057365780235 | validation: 0.19622458955599123]
	TIME [epoch: 2.66 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.169485976789629		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.169485976789629 | validation: 0.2496545935188597]
	TIME [epoch: 2.66 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47547638388285135		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.47547638388285135 | validation: 0.26713671860731114]
	TIME [epoch: 2.66 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46019368062111343		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.46019368062111343 | validation: 0.31294072773582626]
	TIME [epoch: 2.66 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3668890965937742		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.3668890965937742 | validation: 0.2714623569588495]
	TIME [epoch: 2.66 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22790907883678324		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.22790907883678324 | validation: 0.22805436325492381]
	TIME [epoch: 2.66 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17315701840797515		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.17315701840797515 | validation: 0.23860997383932436]
	TIME [epoch: 2.67 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18644406563038018		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.18644406563038018 | validation: 0.24367484268142828]
	TIME [epoch: 2.66 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18996689849601198		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.18996689849601198 | validation: 0.2353051354342225]
	TIME [epoch: 2.66 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1832081276074321		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.1832081276074321 | validation: 0.22106885734380521]
	TIME [epoch: 2.66 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1753399877476942		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.1753399877476942 | validation: 0.2166828325975189]
	TIME [epoch: 2.66 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17054423904185137		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.17054423904185137 | validation: 0.2188625605375669]
	TIME [epoch: 2.66 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1705375000857088		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.1705375000857088 | validation: 0.21490996878106566]
	TIME [epoch: 2.66 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1728305089992467		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.1728305089992467 | validation: 0.22654302900613446]
	TIME [epoch: 2.66 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1763624152622005		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.1763624152622005 | validation: 0.20668647594394784]
	TIME [epoch: 2.66 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17422007935782652		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.17422007935782652 | validation: 0.2135415437577282]
	TIME [epoch: 2.66 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17835455598916394		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.17835455598916394 | validation: 0.2076640587958556]
	TIME [epoch: 2.66 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17358159709497697		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.17358159709497697 | validation: 0.19514970082778982]
	TIME [epoch: 2.67 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1729652175401342		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.1729652175401342 | validation: 0.19696092057004577]
	TIME [epoch: 2.66 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16879568476582765		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.16879568476582765 | validation: 0.2161201799182083]
	TIME [epoch: 2.66 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17135465839381073		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.17135465839381073 | validation: 0.1943974409589937]
	TIME [epoch: 2.66 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17419477497792676		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.17419477497792676 | validation: 0.20060185725311377]
	TIME [epoch: 2.66 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1690149258993855		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.1690149258993855 | validation: 0.23680545809275855]
	TIME [epoch: 2.66 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17367691894737683		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.17367691894737683 | validation: 0.20289652882272638]
	TIME [epoch: 2.66 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17695056792385475		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.17695056792385475 | validation: 0.21175689352919386]
	TIME [epoch: 2.66 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17811481360015333		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.17811481360015333 | validation: 0.19267320536037597]
	TIME [epoch: 2.66 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17241959001408388		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.17241959001408388 | validation: 0.20285498702620908]
	TIME [epoch: 2.66 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17439624066554174		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.17439624066554174 | validation: 0.18997385379721754]
	TIME [epoch: 2.66 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17112246737161882		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.17112246737161882 | validation: 0.2224251175856832]
	TIME [epoch: 2.67 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17573796252145607		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.17573796252145607 | validation: 0.18446084130847057]
	TIME [epoch: 2.66 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17645547412561302		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.17645547412561302 | validation: 0.20222076415605894]
	TIME [epoch: 2.66 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17304754755272853		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.17304754755272853 | validation: 0.1893761905819158]
	TIME [epoch: 2.66 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.167663128184797		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.167663128184797 | validation: 0.2631587374029581]
	TIME [epoch: 2.66 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20368658511461818		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.20368658511461818 | validation: 0.16579378865564903]
	TIME [epoch: 2.66 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2033879718479119		[learning rate: 0.0007479]
	Learning Rate: 0.000747905
	LOSS [training: 0.2033879718479119 | validation: 0.2407256332457781]
	TIME [epoch: 2.66 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18223255048135822		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.18223255048135822 | validation: 0.19171566957928401]
	TIME [epoch: 2.66 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1729819212369081		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.1729819212369081 | validation: 0.18621367718261891]
	TIME [epoch: 2.66 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17499419146059075		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.17499419146059075 | validation: 0.21870183646203278]
	TIME [epoch: 2.66 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1778051510708842		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.1778051510708842 | validation: 0.19433944721544727]
	TIME [epoch: 2.66 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.171457130194473		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.171457130194473 | validation: 0.1902592452377468]
	TIME [epoch: 2.67 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16721691244722553		[learning rate: 0.00073218]
	Learning Rate: 0.000732176
	LOSS [training: 0.16721691244722553 | validation: 0.1940665334219721]
	TIME [epoch: 2.66 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16974559063983388		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.16974559063983388 | validation: 0.16552328441175124]
	TIME [epoch: 2.66 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17358495615217245		[learning rate: 0.00072701]
	Learning Rate: 0.000727007
	LOSS [training: 0.17358495615217245 | validation: 0.2569289466890429]
	TIME [epoch: 2.66 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19241097437374194		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.19241097437374194 | validation: 0.1838415391198263]
	TIME [epoch: 2.66 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17550532722675694		[learning rate: 0.00072187]
	Learning Rate: 0.000721874
	LOSS [training: 0.17550532722675694 | validation: 0.17577710893519286]
	TIME [epoch: 2.66 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1686406596835854		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.1686406596835854 | validation: 0.23353027938144302]
	TIME [epoch: 2.66 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17440160832523025		[learning rate: 0.00071678]
	Learning Rate: 0.000716778
	LOSS [training: 0.17440160832523025 | validation: 0.22046864277547878]
	TIME [epoch: 2.66 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19410483214750152		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.19410483214750152 | validation: 0.1766299030253884]
	TIME [epoch: 2.66 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18700463836488013		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.18700463836488013 | validation: 0.2223389439452697]
	TIME [epoch: 2.66 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17994073940850844		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.17994073940850844 | validation: 0.1806756038030721]
	TIME [epoch: 2.66 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1714085620532378		[learning rate: 0.00070669]
	Learning Rate: 0.000706693
	LOSS [training: 0.1714085620532378 | validation: 0.16839091205804216]
	TIME [epoch: 2.66 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_2_v_mmd1_20250503_175636/states/model_phi1_4a_distortion_v2_2_v_mmd1_799.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1941.999 seconds.
