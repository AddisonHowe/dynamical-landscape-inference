Args:
Namespace(name='model_phi1_4a_distortion_v2_9_v_mmd4', outdir='out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4', training_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_9/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_9/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.02262462, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2211886852

Training model...

Saving initial model state to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.211351954899576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.211351954899576 | validation: 5.688056199319785]
	TIME [epoch: 171 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.936143597898798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.936143597898798 | validation: 4.9671667891904745]
	TIME [epoch: 0.696 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.6513291648790975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6513291648790975 | validation: 4.623684598596044]
	TIME [epoch: 0.658 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.5376203668985715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5376203668985715 | validation: 5.1262449715183855]
	TIME [epoch: 0.651 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.43631788292719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.43631788292719 | validation: 4.505636710904702]
	TIME [epoch: 0.657 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.124317379192271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.124317379192271 | validation: 3.991501493134521]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9251176072316714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9251176072316714 | validation: 4.194660991400744]
	TIME [epoch: 0.652 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.623672302945912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.623672302945912 | validation: 4.279370046252426]
	TIME [epoch: 0.651 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9698110296817677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9698110296817677 | validation: 3.568758836132922]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.528375713723546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.528375713723546 | validation: 3.334884582894838]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.299313403647642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.299313403647642 | validation: 3.5086303644314714]
	TIME [epoch: 0.655 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2820524093429184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2820524093429184 | validation: 2.7428712465996146]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.849265742009826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.849265742009826 | validation: 3.0920394692589097]
	TIME [epoch: 0.65 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6600504802520204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6600504802520204 | validation: 2.3905838552524146]
	TIME [epoch: 0.651 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6564292669064806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6564292669064806 | validation: 2.7766790982124885]
	TIME [epoch: 0.657 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5748239435401095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5748239435401095 | validation: 3.2841616157454667]
	TIME [epoch: 0.656 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.105629967685757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.105629967685757 | validation: 3.3206674593126566]
	TIME [epoch: 0.658 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2704530014649014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2704530014649014 | validation: 2.980236255911583]
	TIME [epoch: 0.657 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.884085726679783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.884085726679783 | validation: 2.9271091424182565]
	TIME [epoch: 0.655 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7007960875337758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7007960875337758 | validation: 2.2807526213346634]
	TIME [epoch: 0.654 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.4088861528180625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4088861528180625 | validation: 2.334714011867786]
	TIME [epoch: 0.656 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3938349696620147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3938349696620147 | validation: 2.668557286409036]
	TIME [epoch: 0.654 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.4029219588132573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4029219588132573 | validation: 2.3071566388049187]
	TIME [epoch: 0.654 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.356421233739798		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.356421233739798 | validation: 2.1959388772753208]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.291796571424315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.291796571424315 | validation: 2.4569704601787]
	TIME [epoch: 0.649 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.264438256654959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.264438256654959 | validation: 2.1417135534381884]
	TIME [epoch: 0.654 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2543732079491616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2543732079491616 | validation: 2.3824068615165515]
	TIME [epoch: 0.649 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.256460401560053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.256460401560053 | validation: 2.191388718888415]
	TIME [epoch: 0.649 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.33969862042906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.33969862042906 | validation: 2.5160166814133804]
	TIME [epoch: 0.648 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.404395004622044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.404395004622044 | validation: 2.0581663987581815]
	TIME [epoch: 0.647 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2601654543933005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2601654543933005 | validation: 2.4577804222649777]
	TIME [epoch: 0.651 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1802422117244924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1802422117244924 | validation: 2.0778567716634977]
	TIME [epoch: 0.652 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1598049670933164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1598049670933164 | validation: 2.364376446817108]
	TIME [epoch: 0.652 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1527911369941366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1527911369941366 | validation: 2.1041631864707044]
	TIME [epoch: 0.651 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1969125142821815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1969125142821815 | validation: 2.389704422316389]
	TIME [epoch: 0.656 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2742852694747793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2742852694747793 | validation: 2.080760180331269]
	TIME [epoch: 0.651 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1945737564189516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1945737564189516 | validation: 2.25734673521568]
	TIME [epoch: 0.652 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.139979403243894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.139979403243894 | validation: 2.2284145390626606]
	TIME [epoch: 0.652 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0939111140781934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0939111140781934 | validation: 2.1725139812657366]
	TIME [epoch: 0.652 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.125391335412299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.125391335412299 | validation: 2.173530322321136]
	TIME [epoch: 0.651 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.037632047230176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.037632047230176 | validation: 2.1443961219848426]
	TIME [epoch: 0.656 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0421794651547627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0421794651547627 | validation: 2.034400258558386]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0583947678279513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0583947678279513 | validation: 2.6446451646502087]
	TIME [epoch: 0.657 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.258809173973956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.258809173973956 | validation: 2.1689107109372823]
	TIME [epoch: 0.653 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.388278265580714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.388278265580714 | validation: 2.0196037087947047]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.995277763100619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.995277763100619 | validation: 2.5655115205362855]
	TIME [epoch: 0.655 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2360893399059147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2360893399059147 | validation: 1.901514412527822]
	TIME [epoch: 0.653 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9659531806895656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9659531806895656 | validation: 1.8958982770922868]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9379457352527218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9379457352527218 | validation: 2.0851248099888746]
	TIME [epoch: 0.657 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.930813041948163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.930813041948163 | validation: 2.1728433385355257]
	TIME [epoch: 0.654 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9226933694356525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9226933694356525 | validation: 1.960867480919136]
	TIME [epoch: 0.653 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9433933552042586		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 1.9433933552042586 | validation: 1.889522117075175]
	TIME [epoch: 0.653 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.860162192414564		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 1.860162192414564 | validation: 2.050494228157862]
	TIME [epoch: 0.656 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8341146687557086		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 1.8341146687557086 | validation: 1.8638246468261528]
	TIME [epoch: 0.653 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8187074389108044		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 1.8187074389108044 | validation: 1.9799139144422009]
	TIME [epoch: 0.657 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8097086356131957		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 1.8097086356131957 | validation: 1.993089376771054]
	TIME [epoch: 0.653 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8478126414969156		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 1.8478126414969156 | validation: 2.155437328618356]
	TIME [epoch: 0.651 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9754524972036778		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 1.9754524972036778 | validation: 1.7698083269088158]
	TIME [epoch: 0.653 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7897762527348835		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 1.7897762527348835 | validation: 2.6792645294166615]
	TIME [epoch: 0.655 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0007656486732905		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 2.0007656486732905 | validation: 1.9853339186640924]
	TIME [epoch: 0.653 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1418189714657077		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 2.1418189714657077 | validation: 1.7064626280380075]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7513897229585247		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 1.7513897229585247 | validation: 2.157456708266967]
	TIME [epoch: 0.649 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8368376596909877		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 1.8368376596909877 | validation: 1.83822394766422]
	TIME [epoch: 0.649 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7895621908562895		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 1.7895621908562895 | validation: 1.896772458141745]
	TIME [epoch: 0.648 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.808679803012202		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 1.808679803012202 | validation: 1.7569990045561632]
	TIME [epoch: 0.649 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7006584703657939		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 1.7006584703657939 | validation: 1.8944302610484116]
	TIME [epoch: 0.651 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7031023336456321		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 1.7031023336456321 | validation: 1.867963111300702]
	TIME [epoch: 0.653 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7181250947296907		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 1.7181250947296907 | validation: 1.7364477898720225]
	TIME [epoch: 0.651 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7013117370371953		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 1.7013117370371953 | validation: 1.848259178759009]
	TIME [epoch: 0.653 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6658255704708824		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 1.6658255704708824 | validation: 1.73494142287071]
	TIME [epoch: 0.651 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6465982360844442		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 1.6465982360844442 | validation: 1.7683112595823098]
	TIME [epoch: 0.654 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.651546733978683		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 1.651546733978683 | validation: 1.6806266066040891]
	TIME [epoch: 0.649 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6514883833117475		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 1.6514883833117475 | validation: 2.0388051546451833]
	TIME [epoch: 0.656 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7551952459640927		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 1.7551952459640927 | validation: 1.8138580667451423]
	TIME [epoch: 0.653 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.010589068038534		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 2.010589068038534 | validation: 1.8660908009707329]
	TIME [epoch: 0.653 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6535512419923246		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 1.6535512419923246 | validation: 1.947596253061875]
	TIME [epoch: 0.651 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7807542386531292		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 1.7807542386531292 | validation: 1.60856410316839]
	TIME [epoch: 0.651 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6216494667182724		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 1.6216494667182724 | validation: 1.7800607688594234]
	TIME [epoch: 0.654 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6427119146707905		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 1.6427119146707905 | validation: 1.7884331453302669]
	TIME [epoch: 0.652 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6469288159431972		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 1.6469288159431972 | validation: 1.6072896493348132]
	TIME [epoch: 0.649 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5607762878999816		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 1.5607762878999816 | validation: 1.8232449960190913]
	TIME [epoch: 0.654 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5893210369137472		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 1.5893210369137472 | validation: 1.674803027681903]
	TIME [epoch: 0.651 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.604742862568162		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 1.604742862568162 | validation: 1.9555717214487485]
	TIME [epoch: 0.651 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.632417569605123		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 1.632417569605123 | validation: 1.609169271715578]
	TIME [epoch: 0.653 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.714992321352207		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 1.714992321352207 | validation: 1.8242906847332236]
	TIME [epoch: 0.65 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5884839690373957		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 1.5884839690373957 | validation: 1.5981527112520642]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5441894412921777		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 1.5441894412921777 | validation: 1.6228359728317452]
	TIME [epoch: 0.653 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5334997898458522		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 1.5334997898458522 | validation: 1.7048436184016926]
	TIME [epoch: 0.652 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.518611201133187		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 1.518611201133187 | validation: 1.5851326660240568]
	TIME [epoch: 0.651 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5184936430409786		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 1.5184936430409786 | validation: 1.8117466493293382]
	TIME [epoch: 0.654 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.557339857005589		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 1.557339857005589 | validation: 1.6820514185371949]
	TIME [epoch: 0.653 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7928270748850146		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 1.7928270748850146 | validation: 2.0613950185317385]
	TIME [epoch: 0.651 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6628689814478528		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 1.6628689814478528 | validation: 1.5339748163901135]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5571220274116722		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 1.5571220274116722 | validation: 1.6021628544479538]
	TIME [epoch: 0.652 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5236381033126176		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 1.5236381033126176 | validation: 1.7013599687148333]
	TIME [epoch: 0.651 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5253350403933263		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 1.5253350403933263 | validation: 1.6706625575851763]
	TIME [epoch: 0.651 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5431956480629558		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 1.5431956480629558 | validation: 1.67506016924075]
	TIME [epoch: 0.651 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5464046174443502		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 1.5464046174443502 | validation: 1.6896615679425626]
	TIME [epoch: 0.649 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5739642142485597		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 1.5739642142485597 | validation: 1.5478813012378094]
	TIME [epoch: 0.649 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6004587459712734		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 1.6004587459712734 | validation: 1.907245736039017]
	TIME [epoch: 0.652 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.613096916227516		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 1.613096916227516 | validation: 1.5764018216721578]
	TIME [epoch: 0.652 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6782785288967883		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 1.6782785288967883 | validation: 1.730076650714991]
	TIME [epoch: 0.652 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.521867360286263		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 1.521867360286263 | validation: 1.6288758404610164]
	TIME [epoch: 0.653 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4932553293884792		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 1.4932553293884792 | validation: 1.531240731698838]
	TIME [epoch: 0.649 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.500709963875389		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 1.500709963875389 | validation: 1.695886742784377]
	TIME [epoch: 0.652 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4828163703907435		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 1.4828163703907435 | validation: 1.5342759736198237]
	TIME [epoch: 0.649 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.512688327743922		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 1.512688327743922 | validation: 1.8311634298092607]
	TIME [epoch: 0.65 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5457317076646402		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 1.5457317076646402 | validation: 1.5255744391614747]
	TIME [epoch: 0.648 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6240272270530351		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 1.6240272270530351 | validation: 1.7032118606911013]
	TIME [epoch: 0.653 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5015911442131773		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 1.5015911442131773 | validation: 1.491512353433196]
	TIME [epoch: 0.651 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.453701688541101		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 1.453701688541101 | validation: 1.5162907048386485]
	TIME [epoch: 0.652 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4404659497341572		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 1.4404659497341572 | validation: 1.6199731799735126]
	TIME [epoch: 0.649 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4427213022137133		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 1.4427213022137133 | validation: 1.4885435045185944]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5417467056051306		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 1.5417467056051306 | validation: 2.029686878220127]
	TIME [epoch: 0.654 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7553188408134797		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 1.7553188408134797 | validation: 1.5738545551971856]
	TIME [epoch: 0.659 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7544567717476758		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 1.7544567717476758 | validation: 1.6953251975146229]
	TIME [epoch: 0.65 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.61041304516124		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 1.61041304516124 | validation: 1.730879253760886]
	TIME [epoch: 0.652 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6330685240108722		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 1.6330685240108722 | validation: 1.500403407034666]
	TIME [epoch: 0.65 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4699470217570254		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 1.4699470217570254 | validation: 1.6631860707150723]
	TIME [epoch: 0.649 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.544817719274503		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 1.544817719274503 | validation: 1.5623657820782526]
	TIME [epoch: 0.651 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4588959716472545		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 1.4588959716472545 | validation: 1.548296874962569]
	TIME [epoch: 0.65 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.425749967774546		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 1.425749967774546 | validation: 1.4674520408156404]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4275897760752019		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 1.4275897760752019 | validation: 1.507662833906128]
	TIME [epoch: 0.657 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4166629995846574		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 1.4166629995846574 | validation: 1.4412153125786178]
	TIME [epoch: 0.651 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.400072710049315		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 1.400072710049315 | validation: 1.740460907509489]
	TIME [epoch: 0.655 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4916033471556316		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 1.4916033471556316 | validation: 1.790238986087599]
	TIME [epoch: 0.651 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8495112254413277		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 1.8495112254413277 | validation: 1.6962006052077396]
	TIME [epoch: 0.651 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5050069895789324		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 1.5050069895789324 | validation: 1.5330910445824413]
	TIME [epoch: 0.649 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4108913141372628		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 1.4108913141372628 | validation: 1.429106724279847]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4331509332142012		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 1.4331509332142012 | validation: 1.6774180135173653]
	TIME [epoch: 0.655 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.437078220862092		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 1.437078220862092 | validation: 1.4442353406269544]
	TIME [epoch: 0.653 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4361258671997377		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 1.4361258671997377 | validation: 1.5815139007864858]
	TIME [epoch: 0.652 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4178030985141634		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 1.4178030985141634 | validation: 1.3536706511977243]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3949421786054028		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 1.3949421786054028 | validation: 1.5083827211764704]
	TIME [epoch: 0.655 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.37729721701587		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 1.37729721701587 | validation: 1.3891809863181437]
	TIME [epoch: 0.651 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4347376372180327		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 1.4347376372180327 | validation: 1.7761105546985918]
	TIME [epoch: 0.652 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5575829070314557		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 1.5575829070314557 | validation: 1.4187100481581645]
	TIME [epoch: 0.652 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6233002206910672		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 1.6233002206910672 | validation: 1.4466760258421978]
	TIME [epoch: 0.651 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3833962953504138		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 1.3833962953504138 | validation: 1.5466766246975803]
	TIME [epoch: 0.649 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4739234173566416		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 1.4739234173566416 | validation: 1.3956862573110471]
	TIME [epoch: 0.65 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4019960914750405		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 1.4019960914750405 | validation: 1.4233385885327496]
	TIME [epoch: 0.651 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.337832153169327		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 1.337832153169327 | validation: 1.364346466468893]
	TIME [epoch: 0.65 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3199382085893347		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 1.3199382085893347 | validation: 1.4406096521618883]
	TIME [epoch: 0.649 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3435012033058056		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 1.3435012033058056 | validation: 1.4627877714562327]
	TIME [epoch: 0.65 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4470139469887233		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 1.4470139469887233 | validation: 2.3237676543687256]
	TIME [epoch: 0.65 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7830448220077324		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 1.7830448220077324 | validation: 1.316184874058763]
	TIME [epoch: 0.649 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5219135248524882		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 1.5219135248524882 | validation: 1.3972623378844915]
	TIME [epoch: 0.654 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3667462451470311		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 1.3667462451470311 | validation: 1.4446370963042785]
	TIME [epoch: 0.65 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.33828951598006		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 1.33828951598006 | validation: 1.411611739967471]
	TIME [epoch: 0.65 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3966064564565839		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 1.3966064564565839 | validation: 1.6267953511181916]
	TIME [epoch: 0.651 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.428221839845956		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 1.428221839845956 | validation: 1.3197925359830915]
	TIME [epoch: 0.651 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4472717983882541		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 1.4472717983882541 | validation: 1.4155085021011604]
	TIME [epoch: 0.65 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3151213800964225		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 1.3151213800964225 | validation: 1.3497380225418891]
	TIME [epoch: 0.649 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2810663532104856		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 1.2810663532104856 | validation: 1.3112599914001082]
	TIME [epoch: 0.653 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3015633904255999		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 1.3015633904255999 | validation: 1.4500182575586422]
	TIME [epoch: 0.655 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3519521618345636		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 1.3519521618345636 | validation: 1.2777119047105068]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4553492162743766		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 1.4553492162743766 | validation: 1.6131308159559703]
	TIME [epoch: 0.655 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4102439964933768		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 1.4102439964933768 | validation: 1.335276713947283]
	TIME [epoch: 0.655 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4103398989669653		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 1.4103398989669653 | validation: 1.6379832175499336]
	TIME [epoch: 0.652 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4406584940663063		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 1.4406584940663063 | validation: 1.4314271962441767]
	TIME [epoch: 0.652 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4179575260874526		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 1.4179575260874526 | validation: 1.3575929141128587]
	TIME [epoch: 0.651 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2860583535255545		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 1.2860583535255545 | validation: 1.2500891178502067]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2689729803966503		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 1.2689729803966503 | validation: 1.3409411590398843]
	TIME [epoch: 0.654 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.291275622756951		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 1.291275622756951 | validation: 1.2980308565961431]
	TIME [epoch: 0.654 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3067949372525232		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 1.3067949372525232 | validation: 1.286167380831945]
	TIME [epoch: 0.651 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2984419163584122		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 1.2984419163584122 | validation: 1.2816147695915827]
	TIME [epoch: 0.653 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2517509072302488		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 1.2517509072302488 | validation: 1.2076720837049881]
	TIME [epoch: 0.65 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2577578492467336		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 1.2577578492467336 | validation: 1.8933860505161826]
	TIME [epoch: 0.658 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5801708691729601		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 1.5801708691729601 | validation: 1.5457741418377502]
	TIME [epoch: 0.655 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.822210208760219		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 1.822210208760219 | validation: 1.2344102054811514]
	TIME [epoch: 0.653 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3002635139681704		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 1.3002635139681704 | validation: 1.5988139696797614]
	TIME [epoch: 0.654 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4424611036767783		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 1.4424611036767783 | validation: 1.2663393526636932]
	TIME [epoch: 0.653 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3574051828096783		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 1.3574051828096783 | validation: 1.2809037543323563]
	TIME [epoch: 0.652 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2359474684977694		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 1.2359474684977694 | validation: 1.3192310001903373]
	TIME [epoch: 0.653 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2741672691238943		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 1.2741672691238943 | validation: 1.1894002344028871]
	TIME [epoch: 0.654 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2597537399602379		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 1.2597537399602379 | validation: 1.2497677204917552]
	TIME [epoch: 0.654 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2193009236827226		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 1.2193009236827226 | validation: 1.1781847467262707]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2151054742729677		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 1.2151054742729677 | validation: 1.245863442683266]
	TIME [epoch: 0.657 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2137318800870591		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 1.2137318800870591 | validation: 1.2358424752700683]
	TIME [epoch: 0.652 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2933626680402108		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 1.2933626680402108 | validation: 1.9003783958948148]
	TIME [epoch: 0.652 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.556379080978668		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 1.556379080978668 | validation: 1.229531128648213]
	TIME [epoch: 0.652 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4196353649137228		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 1.4196353649137228 | validation: 1.291194301881089]
	TIME [epoch: 0.651 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2518129810337728		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 1.2518129810337728 | validation: 1.1686341316256341]
	TIME [epoch: 0.652 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2171087681300932		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 1.2171087681300932 | validation: 1.2156543650374043]
	TIME [epoch: 0.658 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.221873706369358		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 1.221873706369358 | validation: 1.1414194024892657]
	TIME [epoch: 0.657 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2088567177786056		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 1.2088567177786056 | validation: 1.2061977828541093]
	TIME [epoch: 0.654 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2169459568031573		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 1.2169459568031573 | validation: 1.0960106410787713]
	TIME [epoch: 0.654 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.217185963031117		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 1.217185963031117 | validation: 1.5133575950779907]
	TIME [epoch: 0.656 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.376575267535767		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 1.376575267535767 | validation: 1.4263246250147743]
	TIME [epoch: 0.653 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6671595367625378		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 1.6671595367625378 | validation: 1.3335439738981072]
	TIME [epoch: 0.654 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.30837576824517		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 1.30837576824517 | validation: 1.2658907052382622]
	TIME [epoch: 0.654 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2653254384053785		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 1.2653254384053785 | validation: 1.121405133040737]
	TIME [epoch: 0.658 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2513013615275885		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 1.2513013615275885 | validation: 1.349034329002655]
	TIME [epoch: 0.651 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.249775127086386		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 1.249775127086386 | validation: 1.200750320937003]
	TIME [epoch: 0.653 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2730500348999656		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 1.2730500348999656 | validation: 1.2882536670443432]
	TIME [epoch: 0.652 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2377497351342095		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 1.2377497351342095 | validation: 1.1128680133581612]
	TIME [epoch: 0.652 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.206595849942332		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 1.206595849942332 | validation: 1.2549449675771074]
	TIME [epoch: 0.652 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1974833887566891		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 1.1974833887566891 | validation: 1.0680546820863175]
	TIME [epoch: 0.655 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2341855547772271		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 1.2341855547772271 | validation: 1.2813731965968662]
	TIME [epoch: 0.654 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2299004465845995		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 1.2299004465845995 | validation: 1.0902517061391206]
	TIME [epoch: 0.654 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.257850238804597		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 1.257850238804597 | validation: 1.376631905073221]
	TIME [epoch: 179 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.271016807494341		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 1.271016807494341 | validation: 1.1450582167682233]
	TIME [epoch: 1.29 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.261070636629775		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 1.261070636629775 | validation: 1.2603974240059383]
	TIME [epoch: 1.28 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2312695175934867		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 1.2312695175934867 | validation: 1.1202483212225067]
	TIME [epoch: 1.28 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1874412466918178		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 1.1874412466918178 | validation: 1.1699048686323732]
	TIME [epoch: 1.27 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.177198173669675		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 1.177198173669675 | validation: 1.0662929660248541]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_206.pth
	Model improved!!!
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.173399923499992		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 1.173399923499992 | validation: 1.2313039951804057]
	TIME [epoch: 1.28 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1983292898623477		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 1.1983292898623477 | validation: 1.0975540250157174]
	TIME [epoch: 1.28 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.310189982243767		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 1.310189982243767 | validation: 1.370406642754815]
	TIME [epoch: 1.28 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2968179701071139		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 1.2968179701071139 | validation: 1.0456747582036285]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.23361862186183		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 1.23361862186183 | validation: 1.1745268754838036]
	TIME [epoch: 1.28 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1673645349215882		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 1.1673645349215882 | validation: 1.1337228646967223]
	TIME [epoch: 1.27 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1748163974306656		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 1.1748163974306656 | validation: 1.1373931796363201]
	TIME [epoch: 1.27 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2111710129896118		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 1.2111710129896118 | validation: 1.148105338487143]
	TIME [epoch: 1.28 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2274472771532867		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 1.2274472771532867 | validation: 1.2346616202044567]
	TIME [epoch: 1.27 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1963759163872232		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 1.1963759163872232 | validation: 1.0779126750202999]
	TIME [epoch: 1.27 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2325870772589658		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 1.2325870772589658 | validation: 1.3662339584049938]
	TIME [epoch: 1.28 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2606247715869883		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 1.2606247715869883 | validation: 1.045498077161682]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2561409237066183		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 1.2561409237066183 | validation: 1.1816901114290996]
	TIME [epoch: 1.28 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.163341504370348		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 1.163341504370348 | validation: 1.0437201638533449]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1442211455019795		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 1.1442211455019795 | validation: 1.1085378214597181]
	TIME [epoch: 1.28 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.130987324110727		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 1.130987324110727 | validation: 1.0233533119236753]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1616925460307825		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 1.1616925460307825 | validation: 1.2744923325473154]
	TIME [epoch: 1.28 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2178913028739344		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 1.2178913028739344 | validation: 1.1434197557142545]
	TIME [epoch: 1.28 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2908949531966187		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 1.2908949531966187 | validation: 1.3357245552691053]
	TIME [epoch: 1.28 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2407705572412995		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 1.2407705572412995 | validation: 1.0440625533111574]
	TIME [epoch: 1.28 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1544011601937705		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 1.1544011601937705 | validation: 1.0829406058306708]
	TIME [epoch: 1.28 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.119894797785868		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 1.119894797785868 | validation: 1.0208919188946073]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1055418539027482		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 1.1055418539027482 | validation: 1.0117189930099657]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1078199223989638		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 1.1078199223989638 | validation: 1.0356035901145657]
	TIME [epoch: 1.28 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0970783213796478		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 1.0970783213796478 | validation: 1.0039177797738577]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1075848537528965		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 1.1075848537528965 | validation: 1.0585473768339895]
	TIME [epoch: 1.27 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1637805937240397		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 1.1637805937240397 | validation: 1.1613689855180287]
	TIME [epoch: 1.27 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2373738055003363		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 1.2373738055003363 | validation: 1.1317292719733172]
	TIME [epoch: 1.27 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2545540787563736		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 1.2545540787563736 | validation: 1.6937558370566987]
	TIME [epoch: 1.27 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4432674324701322		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 1.4432674324701322 | validation: 0.9871562962135155]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.403563479710751		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 1.403563479710751 | validation: 0.984297203727911]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1000542791142969		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 1.1000542791142969 | validation: 1.2367833875319547]
	TIME [epoch: 1.28 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2295487605626383		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 1.2295487605626383 | validation: 1.020807902261365]
	TIME [epoch: 1.28 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1997770528986815		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 1.1997770528986815 | validation: 1.1257872975886651]
	TIME [epoch: 1.27 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.13887319493087		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 1.13887319493087 | validation: 1.0096367822073433]
	TIME [epoch: 1.28 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.122117530296826		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 1.122117530296826 | validation: 1.0428664459258101]
	TIME [epoch: 1.27 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.106616375948029		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 1.106616375948029 | validation: 0.9637885273013194]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0975667012080075		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 1.0975667012080075 | validation: 1.0737240720590708]
	TIME [epoch: 1.28 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1066335536454772		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 1.1066335536454772 | validation: 0.9627996673001846]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1362450706637839		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 1.1362450706637839 | validation: 1.2929307126178178]
	TIME [epoch: 1.28 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2142563347285504		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 1.2142563347285504 | validation: 1.1093354797194142]
	TIME [epoch: 1.28 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.26260393828595		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 1.26260393828595 | validation: 1.1994113425644677]
	TIME [epoch: 1.29 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1732473688135931		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 1.1732473688135931 | validation: 1.0056242402452757]
	TIME [epoch: 1.28 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0957294697321145		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 1.0957294697321145 | validation: 1.0260752034281035]
	TIME [epoch: 1.28 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0785585678234906		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 1.0785585678234906 | validation: 0.9949647656633247]
	TIME [epoch: 1.28 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0751900547184507		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 1.0751900547184507 | validation: 0.9489255277395667]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0709764411458291		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 1.0709764411458291 | validation: 1.0239167784461853]
	TIME [epoch: 1.27 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0786515743909777		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 1.0786515743909777 | validation: 1.0075166721301416]
	TIME [epoch: 1.27 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1481573306303043		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 1.1481573306303043 | validation: 1.464670587119059]
	TIME [epoch: 1.27 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3192648006372931		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 1.3192648006372931 | validation: 1.0148867467089968]
	TIME [epoch: 1.27 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2297107945383217		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 1.2297107945383217 | validation: 1.1114363936316434]
	TIME [epoch: 1.27 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1176480401463433		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 1.1176480401463433 | validation: 0.9441748968288709]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_258.pth
	Model improved!!!
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.116672718953884		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 1.116672718953884 | validation: 1.067861981975838]
	TIME [epoch: 1.28 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.094528293127357		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 1.094528293127357 | validation: 0.9221211539601573]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0863113704170269		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 1.0863113704170269 | validation: 0.9997773912888732]
	TIME [epoch: 1.27 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.066402298208722		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 1.066402298208722 | validation: 0.9250731380881044]
	TIME [epoch: 1.27 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0792153975734582		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 1.0792153975734582 | validation: 1.123375660877305]
	TIME [epoch: 1.27 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.122533058444544		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 1.122533058444544 | validation: 0.9801611577589606]
	TIME [epoch: 1.27 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2123269158922687		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 1.2123269158922687 | validation: 1.2987706393776195]
	TIME [epoch: 1.27 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2235105326690718		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 1.2235105326690718 | validation: 1.0477036068051901]
	TIME [epoch: 1.27 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1567897021359737		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 1.1567897021359737 | validation: 1.0190533339382946]
	TIME [epoch: 1.27 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0854651000632654		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 1.0854651000632654 | validation: 0.9777876215390919]
	TIME [epoch: 1.27 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0626061806908513		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 1.0626061806908513 | validation: 0.97545899123791]
	TIME [epoch: 1.27 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.051528737186097		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 1.051528737186097 | validation: 0.929860111124537]
	TIME [epoch: 1.27 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0518791089091868		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 1.0518791089091868 | validation: 1.007663641169334]
	TIME [epoch: 1.27 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0619228669576586		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 1.0619228669576586 | validation: 0.958973414773949]
	TIME [epoch: 1.27 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.122359521314143		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 1.122359521314143 | validation: 1.374755396272148]
	TIME [epoch: 1.27 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2443041150860819		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 1.2443041150860819 | validation: 0.9479530014694245]
	TIME [epoch: 1.27 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.200299616432877		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 1.200299616432877 | validation: 1.0049034539899695]
	TIME [epoch: 1.27 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0696625801360318		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 1.0696625801360318 | validation: 1.008273838167825]
	TIME [epoch: 1.27 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0705745645476805		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 1.0705745645476805 | validation: 0.94551290279965]
	TIME [epoch: 1.27 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0830755759276463		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 1.0830755759276463 | validation: 1.0156844989411369]
	TIME [epoch: 1.27 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0885975018700498		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 1.0885975018700498 | validation: 0.9088979635643096]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0609950873274638		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 1.0609950873274638 | validation: 0.9486078653779858]
	TIME [epoch: 1.27 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.047061105511656		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 1.047061105511656 | validation: 0.9649848677849701]
	TIME [epoch: 1.27 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.047077914765823		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 1.047077914765823 | validation: 0.9410321743689279]
	TIME [epoch: 1.27 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0928984703129296		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 1.0928984703129296 | validation: 1.4450396891737436]
	TIME [epoch: 1.27 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2783021069282656		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 1.2783021069282656 | validation: 0.9725964398623692]
	TIME [epoch: 1.27 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1941959414761416		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 1.1941959414761416 | validation: 1.0366170821536962]
	TIME [epoch: 1.27 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0705329446871938		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 1.0705329446871938 | validation: 0.9576706143435904]
	TIME [epoch: 1.27 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0465003786733675		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 1.0465003786733675 | validation: 0.9274008013190621]
	TIME [epoch: 1.26 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.02631842611144		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 1.02631842611144 | validation: 0.96212561797774]
	TIME [epoch: 1.27 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0312589265989411		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 1.0312589265989411 | validation: 0.8771022009580168]
	TIME [epoch: 1.26 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0369409470202493		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 1.0369409470202493 | validation: 1.0415736956341861]
	TIME [epoch: 1.27 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0615138378797797		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 1.0615138378797797 | validation: 0.8878571224940837]
	TIME [epoch: 1.27 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1411380232054622		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 1.1411380232054622 | validation: 1.1919392526047865]
	TIME [epoch: 1.27 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1401874258803724		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 1.1401874258803724 | validation: 0.9655319866175098]
	TIME [epoch: 1.27 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1485392066412652		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 1.1485392066412652 | validation: 1.1111442204837911]
	TIME [epoch: 1.27 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.159309268794457		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 1.159309268794457 | validation: 1.0479292709874872]
	TIME [epoch: 1.27 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.111987614630629		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 1.111987614630629 | validation: 0.9343988317363465]
	TIME [epoch: 1.27 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.02154818391967		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 1.02154818391967 | validation: 0.9028500345527167]
	TIME [epoch: 1.27 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0286551049643566		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 1.0286551049643566 | validation: 0.9460266608088489]
	TIME [epoch: 1.27 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0274300458301426		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 1.0274300458301426 | validation: 0.9246922078224369]
	TIME [epoch: 1.26 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0278455787838354		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 1.0278455787838354 | validation: 0.8978752227931341]
	TIME [epoch: 1.27 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0264323617910012		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 1.0264323617910012 | validation: 1.0617031224371611]
	TIME [epoch: 1.27 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0681443921063782		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 1.0681443921063782 | validation: 1.0366056590113928]
	TIME [epoch: 1.27 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2080130994343579		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 1.2080130994343579 | validation: 1.242895942629205]
	TIME [epoch: 1.27 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.171221141649928		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 1.171221141649928 | validation: 0.9008921844589942]
	TIME [epoch: 1.27 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0439309578548797		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 1.0439309578548797 | validation: 0.9254343100366814]
	TIME [epoch: 1.27 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0114011999693284		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 1.0114011999693284 | validation: 0.946634504445158]
	TIME [epoch: 1.27 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0110362489120275		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 1.0110362489120275 | validation: 0.8724408675511935]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0154272957400163		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 1.0154272957400163 | validation: 0.9569317238858815]
	TIME [epoch: 1.27 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0232173986021815		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 1.0232173986021815 | validation: 0.8837386575941673]
	TIME [epoch: 1.27 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0562767826804367		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 1.0562767826804367 | validation: 1.2244092707976786]
	TIME [epoch: 1.27 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.14225137281441		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 1.14225137281441 | validation: 0.9484644790271908]
	TIME [epoch: 1.27 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1330746527427769		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 1.1330746527427769 | validation: 1.027314337472318]
	TIME [epoch: 1.27 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0664378185345447		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 1.0664378185345447 | validation: 1.0136322066746737]
	TIME [epoch: 1.27 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0588521803710165		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 1.0588521803710165 | validation: 0.8736523120515471]
	TIME [epoch: 1.27 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.035624392679768		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 1.035624392679768 | validation: 0.9418542826865416]
	TIME [epoch: 1.27 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.018076576072496		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 1.018076576072496 | validation: 0.872267763378811]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0004022682885814		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 1.0004022682885814 | validation: 0.9423464122830398]
	TIME [epoch: 1.27 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.015607710181392		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 1.015607710181392 | validation: 0.8862139502644141]
	TIME [epoch: 1.27 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0278518629327134		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 1.0278518629327134 | validation: 1.112700788431116]
	TIME [epoch: 1.27 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.100734633831281		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 1.100734633831281 | validation: 0.9682250186648382]
	TIME [epoch: 1.26 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.131353130455163		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 1.131353130455163 | validation: 1.0859118905486602]
	TIME [epoch: 1.27 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0869326158579946		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 1.0869326158579946 | validation: 0.9276496368321997]
	TIME [epoch: 1.27 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0125847559867032		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 1.0125847559867032 | validation: 0.8918390555438631]
	TIME [epoch: 1.27 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.001679702163033		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 1.001679702163033 | validation: 0.9368027172114731]
	TIME [epoch: 1.27 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9958555520040477		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.9958555520040477 | validation: 0.8373480755534719]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_325.pth
	Model improved!!!
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.010537337019718		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 1.010537337019718 | validation: 1.0125215713184792]
	TIME [epoch: 1.28 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.030957236485128		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 1.030957236485128 | validation: 0.8900848263392644]
	TIME [epoch: 1.27 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0761915556900372		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 1.0761915556900372 | validation: 1.1167028317932364]
	TIME [epoch: 1.27 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0788392904796202		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 1.0788392904796202 | validation: 0.9359423814335724]
	TIME [epoch: 1.27 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.06042063123155		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 1.06042063123155 | validation: 0.9886118980430679]
	TIME [epoch: 1.27 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.057458601104898		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 1.057458601104898 | validation: 0.9695310803313559]
	TIME [epoch: 1.27 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0200839793258336		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 1.0200839793258336 | validation: 0.8824979388764561]
	TIME [epoch: 1.27 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9864870355941017		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.9864870355941017 | validation: 0.8998488718451872]
	TIME [epoch: 1.27 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9816091119629199		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.9816091119629199 | validation: 0.8574823340422739]
	TIME [epoch: 1.27 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9772132684497545		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.9772132684497545 | validation: 0.8991246119695891]
	TIME [epoch: 1.26 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9871079061552746		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.9871079061552746 | validation: 0.8466826629288099]
	TIME [epoch: 1.27 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9853160004188217		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.9853160004188217 | validation: 0.9907592004918975]
	TIME [epoch: 1.26 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.03111616313165		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 1.03111616313165 | validation: 1.004125012975398]
	TIME [epoch: 1.27 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1673211836541477		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 1.1673211836541477 | validation: 1.2449295949978003]
	TIME [epoch: 1.27 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1516707658735583		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 1.1516707658735583 | validation: 0.8287942088459606]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0079667158305585		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 1.0079667158305585 | validation: 0.8993384768162347]
	TIME [epoch: 1.27 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9826910049441415		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.9826910049441415 | validation: 0.9153784084078052]
	TIME [epoch: 1.27 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9895656221497262		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.9895656221497262 | validation: 0.9085866537113856]
	TIME [epoch: 1.26 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0013169314084214		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 1.0013169314084214 | validation: 0.9397340141811817]
	TIME [epoch: 1.27 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.011431057034785		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 1.011431057034785 | validation: 0.8948011209786915]
	TIME [epoch: 1.26 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0177541711141935		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 1.0177541711141935 | validation: 1.0067871014059893]
	TIME [epoch: 1.27 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0112557274803915		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 1.0112557274803915 | validation: 0.8499840076551376]
	TIME [epoch: 1.26 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.046784533706045		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 1.046784533706045 | validation: 1.0330949405826673]
	TIME [epoch: 1.27 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0257934352283673		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 1.0257934352283673 | validation: 0.8271979730223132]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0119313598169097		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 1.0119313598169097 | validation: 0.93501664488601]
	TIME [epoch: 1.27 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9749370595968467		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.9749370595968467 | validation: 0.8662117525287116]
	TIME [epoch: 1.27 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.965150557494142		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.965150557494142 | validation: 0.8692548025524176]
	TIME [epoch: 1.27 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9792193692020769		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.9792193692020769 | validation: 0.8951058972718716]
	TIME [epoch: 1.27 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9768783842964195		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.9768783842964195 | validation: 0.9071538063238261]
	TIME [epoch: 1.27 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0273306363855153		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 1.0273306363855153 | validation: 1.0787084606694213]
	TIME [epoch: 1.27 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0767594530073648		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 1.0767594530073648 | validation: 0.8920248661030095]
	TIME [epoch: 1.27 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0429977599778952		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 1.0429977599778952 | validation: 1.0233207139153557]
	TIME [epoch: 1.27 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0110694948952297		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 1.0110694948952297 | validation: 0.8303381466120765]
	TIME [epoch: 1.27 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9975222128472617		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.9975222128472617 | validation: 0.9566798087336402]
	TIME [epoch: 1.27 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9945456281921122		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.9945456281921122 | validation: 0.8309020808856868]
	TIME [epoch: 1.27 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.983159059446287		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.983159059446287 | validation: 0.9372537663107852]
	TIME [epoch: 1.27 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9742863977527426		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.9742863977527426 | validation: 0.8355388048967272]
	TIME [epoch: 1.27 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9718962315830002		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.9718962315830002 | validation: 0.9147496027226589]
	TIME [epoch: 1.27 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9682409664602727		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.9682409664602727 | validation: 0.879202586593345]
	TIME [epoch: 1.27 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0011613928943683		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 1.0011613928943683 | validation: 0.9893981115004321]
	TIME [epoch: 1.27 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0471211780454903		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 1.0471211780454903 | validation: 0.9065924045426519]
	TIME [epoch: 1.27 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0349149501510428		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 1.0349149501510428 | validation: 0.98121028253232]
	TIME [epoch: 1.27 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0002047009061565		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 1.0002047009061565 | validation: 0.820189036791716]
	TIME [epoch: 1.27 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_368.pth
	Model improved!!!
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9887455624582886		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.9887455624582886 | validation: 0.9438200074929448]
	TIME [epoch: 1.28 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9756541864080057		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.9756541864080057 | validation: 0.8271518329929748]
	TIME [epoch: 1.28 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.961714937933877		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.961714937933877 | validation: 0.9066514663728944]
	TIME [epoch: 1.28 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9508777034770876		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.9508777034770876 | validation: 0.8108385979164825]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_372.pth
	Model improved!!!
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9505335778334998		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.9505335778334998 | validation: 0.8699346926384269]
	TIME [epoch: 1.28 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9505548471909042		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.9505548471909042 | validation: 0.8143917334335516]
	TIME [epoch: 1.28 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9589899016967616		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.9589899016967616 | validation: 0.8863200897612207]
	TIME [epoch: 1.28 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9680330523081938		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.9680330523081938 | validation: 0.8567336134858204]
	TIME [epoch: 1.27 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.986717948478603		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.986717948478603 | validation: 0.9118949905664989]
	TIME [epoch: 1.28 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0337683658962342		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 1.0337683658962342 | validation: 1.2026184074834534]
	TIME [epoch: 1.27 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.111331706831156		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 1.111331706831156 | validation: 0.8329792196625356]
	TIME [epoch: 1.28 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0444806561490347		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 1.0444806561490347 | validation: 0.9180168330502131]
	TIME [epoch: 1.27 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9537799227387204		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.9537799227387204 | validation: 0.8903470192270281]
	TIME [epoch: 1.28 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9492383555900922		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.9492383555900922 | validation: 0.8246156930312492]
	TIME [epoch: 1.28 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.962232168301994		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.962232168301994 | validation: 0.9695185223212142]
	TIME [epoch: 1.28 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9625318602412332		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.9625318602412332 | validation: 0.8327712708990943]
	TIME [epoch: 1.28 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9669860272771681		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.9669860272771681 | validation: 0.9222940363573859]
	TIME [epoch: 1.28 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9611104723173512		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.9611104723173512 | validation: 0.8771987687927734]
	TIME [epoch: 1.27 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9709754642841361		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.9709754642841361 | validation: 0.9260827351980805]
	TIME [epoch: 1.28 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9914639201826441		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.9914639201826441 | validation: 0.8511806531032594]
	TIME [epoch: 1.28 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9891838780096707		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.9891838780096707 | validation: 0.9600846501109823]
	TIME [epoch: 1.28 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9745853630447039		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.9745853630447039 | validation: 0.8105791329628174]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_390.pth
	Model improved!!!
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9701560541242411		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.9701560541242411 | validation: 0.9671729252315387]
	TIME [epoch: 1.28 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9734555155634504		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.9734555155634504 | validation: 0.8118045915628707]
	TIME [epoch: 1.27 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9560068288810191		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.9560068288810191 | validation: 0.8859577198558899]
	TIME [epoch: 1.28 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9352161205979109		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.9352161205979109 | validation: 0.8283660908936176]
	TIME [epoch: 1.28 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9305314670780885		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.9305314670780885 | validation: 0.8715728105655443]
	TIME [epoch: 1.28 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9339292249393458		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.9339292249393458 | validation: 0.8169242641768908]
	TIME [epoch: 1.28 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9313828923575715		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.9313828923575715 | validation: 0.8582266829142203]
	TIME [epoch: 1.28 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9331707861177699		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.9331707861177699 | validation: 0.7987842030263913]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9417268919390921		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.9417268919390921 | validation: 0.9277765491217406]
	TIME [epoch: 1.29 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9697661865625264		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.9697661865625264 | validation: 0.7885299728162986]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9756542401281993		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.9756542401281993 | validation: 0.8692385335227958]
	TIME [epoch: 1.28 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9471010452000114		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.9471010452000114 | validation: 0.8391088686123713]
	TIME [epoch: 1.27 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9310891057134038		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.9310891057134038 | validation: 0.8212106366786419]
	TIME [epoch: 1.28 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9635591158363039		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.9635591158363039 | validation: 1.286334702437422]
	TIME [epoch: 1.27 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1472516206120213		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 1.1472516206120213 | validation: 0.8132460729568192]
	TIME [epoch: 1.28 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.995416671795315		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.995416671795315 | validation: 0.8457487824502444]
	TIME [epoch: 1.27 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9239659572216032		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.9239659572216032 | validation: 0.8925926223429834]
	TIME [epoch: 1.28 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9204720972921644		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.9204720972921644 | validation: 0.8206393710955521]
	TIME [epoch: 1.27 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9346097656828662		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.9346097656828662 | validation: 0.9250375514191482]
	TIME [epoch: 1.28 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9542834435922921		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.9542834435922921 | validation: 0.828575633219233]
	TIME [epoch: 1.27 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9622491619270895		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.9622491619270895 | validation: 0.9281176560942956]
	TIME [epoch: 1.28 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9732461965689398		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.9732461965689398 | validation: 0.8497364318619637]
	TIME [epoch: 1.28 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.971864840272954		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.971864840272954 | validation: 0.8708843530063164]
	TIME [epoch: 1.28 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9403994867690884		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.9403994867690884 | validation: 0.8110260361565074]
	TIME [epoch: 1.27 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9215653119286165		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.9215653119286165 | validation: 0.8348550180030764]
	TIME [epoch: 1.28 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9124213986537281		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.9124213986537281 | validation: 0.7796846960931852]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9225404406554075		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.9225404406554075 | validation: 0.8812194582387266]
	TIME [epoch: 1.29 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9281761181606257		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.9281761181606257 | validation: 0.7876060425975306]
	TIME [epoch: 1.28 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9444200344704896		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.9444200344704896 | validation: 0.9616804723530388]
	TIME [epoch: 1.28 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.954877070291929		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.954877070291929 | validation: 0.7980682065556347]
	TIME [epoch: 1.28 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9704652932029043		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.9704652932029043 | validation: 0.932119060270903]
	TIME [epoch: 1.28 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9557644509810831		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.9557644509810831 | validation: 0.8703621820937028]
	TIME [epoch: 1.28 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9680379480745457		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.9680379480745457 | validation: 0.877920408260867]
	TIME [epoch: 1.28 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9577149072728522		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.9577149072728522 | validation: 0.8312979119339791]
	TIME [epoch: 1.28 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9351770126891237		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.9351770126891237 | validation: 0.836061835205366]
	TIME [epoch: 1.28 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9076722977747332		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.9076722977747332 | validation: 0.7961214682266297]
	TIME [epoch: 1.28 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9091371788415228		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.9091371788415228 | validation: 0.886187486837655]
	TIME [epoch: 1.28 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9171657413083274		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.9171657413083274 | validation: 0.7749482937113139]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9301896591420246		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.9301896591420246 | validation: 0.953929954634474]
	TIME [epoch: 1.28 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9560530582284154		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.9560530582284154 | validation: 0.7960275431020284]
	TIME [epoch: 1.28 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9432980327060275		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.9432980327060275 | validation: 0.8691025844155486]
	TIME [epoch: 1.28 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9492098168599915		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.9492098168599915 | validation: 0.8437418863616654]
	TIME [epoch: 1.27 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.935527115297203		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.935527115297203 | validation: 0.8238195061278635]
	TIME [epoch: 1.28 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9144902463757791		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.9144902463757791 | validation: 0.8309136492172169]
	TIME [epoch: 1.28 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9089780857683182		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.9089780857683182 | validation: 0.8190607461766345]
	TIME [epoch: 1.27 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8905500980555294		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.8905500980555294 | validation: 0.8046564215344194]
	TIME [epoch: 1.27 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9003929689356955		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.9003929689356955 | validation: 0.8220310566518579]
	TIME [epoch: 1.27 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9009927167978817		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.9009927167978817 | validation: 0.7942977181737847]
	TIME [epoch: 1.28 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9215406463902476		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.9215406463902476 | validation: 1.0781547561689349]
	TIME [epoch: 1.27 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.019520396360891		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 1.019520396360891 | validation: 0.800392271570882]
	TIME [epoch: 1.28 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9860379162241867		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.9860379162241867 | validation: 0.8714580135331954]
	TIME [epoch: 1.28 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9218473045814269		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.9218473045814269 | validation: 0.8140077755682003]
	TIME [epoch: 1.28 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8983573322567164		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.8983573322567164 | validation: 0.8158064963341025]
	TIME [epoch: 1.27 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.89484080288115		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.89484080288115 | validation: 0.8600653616292635]
	TIME [epoch: 1.27 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8973845277539908		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.8973845277539908 | validation: 0.744785625343286]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9320949106217683		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.9320949106217683 | validation: 0.8844072715492454]
	TIME [epoch: 1.28 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9231948072206604		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.9231948072206604 | validation: 0.7383326992311073]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_447.pth
	Model improved!!!
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9056263994737798		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.9056263994737798 | validation: 0.8177736618304853]
	TIME [epoch: 1.28 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9001035570830612		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.9001035570830612 | validation: 0.8186760826179018]
	TIME [epoch: 1.28 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8883735208135449		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.8883735208135449 | validation: 0.7616121566088289]
	TIME [epoch: 1.27 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8867105379998571		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.8867105379998571 | validation: 0.9251137303781093]
	TIME [epoch: 1.27 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9374060033301577		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.9374060033301577 | validation: 0.8571101178200362]
	TIME [epoch: 1.28 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0126309397534874		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 1.0126309397534874 | validation: 0.9796003346320821]
	TIME [epoch: 1.28 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9888753064472109		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.9888753064472109 | validation: 0.7940516026556116]
	TIME [epoch: 1.28 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9037282963263888		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.9037282963263888 | validation: 0.798396269651137]
	TIME [epoch: 1.27 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8875061515901373		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.8875061515901373 | validation: 0.8450069351012133]
	TIME [epoch: 1.28 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8910837818770421		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.8910837818770421 | validation: 0.7804925432938521]
	TIME [epoch: 1.27 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9043665855798986		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.9043665855798986 | validation: 0.8743861108328173]
	TIME [epoch: 1.27 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.912588906537937		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.912588906537937 | validation: 0.7628463762233441]
	TIME [epoch: 1.27 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9187031718960923		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.9187031718960923 | validation: 0.8888261561371815]
	TIME [epoch: 1.28 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9137294528439498		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.9137294528439498 | validation: 0.7742197375455553]
	TIME [epoch: 1.27 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9097138333789225		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.9097138333789225 | validation: 0.8306241190040737]
	TIME [epoch: 1.27 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9009349791150999		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.9009349791150999 | validation: 0.8120197772568556]
	TIME [epoch: 1.28 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9039949175631086		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.9039949175631086 | validation: 0.8154087291649653]
	TIME [epoch: 1.28 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9122768644482294		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.9122768644482294 | validation: 0.7908412675316433]
	TIME [epoch: 1.27 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8942911570402324		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.8942911570402324 | validation: 0.7800743196540844]
	TIME [epoch: 1.28 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8891135530082711		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.8891135530082711 | validation: 0.807232997828945]
	TIME [epoch: 1.27 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8898135088360887		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.8898135088360887 | validation: 0.7731636860653841]
	TIME [epoch: 1.28 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8760418151433629		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.8760418151433629 | validation: 0.8122424066802005]
	TIME [epoch: 1.27 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8844048677016886		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.8844048677016886 | validation: 0.7398177333381751]
	TIME [epoch: 1.27 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8877560657211326		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.8877560657211326 | validation: 0.8799580507226626]
	TIME [epoch: 1.28 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9161775303370212		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.9161775303370212 | validation: 0.7023457974949869]
	TIME [epoch: 1.28 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9734779143576083		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.9734779143576083 | validation: 0.9131443619102143]
	TIME [epoch: 1.28 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9248285556950684		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.9248285556950684 | validation: 0.8092168054441763]
	TIME [epoch: 1.28 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9285927556468039		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.9285927556468039 | validation: 0.8569189909584813]
	TIME [epoch: 1.28 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9442592831485911		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.9442592831485911 | validation: 0.7933135893939863]
	TIME [epoch: 1.27 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8883976997163572		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.8883976997163572 | validation: 0.7825482647636228]
	TIME [epoch: 1.28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8690797031120764		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.8690797031120764 | validation: 0.7599282800150906]
	TIME [epoch: 1.28 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8743059407145449		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.8743059407145449 | validation: 0.7752480087680218]
	TIME [epoch: 1.28 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8732966176153382		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.8732966176153382 | validation: 0.7894215424301859]
	TIME [epoch: 1.28 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8823650350885304		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.8823650350885304 | validation: 0.7462887750722959]
	TIME [epoch: 1.28 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8684316474223428		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.8684316474223428 | validation: 0.8610615895753857]
	TIME [epoch: 1.28 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8896558536334408		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.8896558536334408 | validation: 0.7794215883533648]
	TIME [epoch: 1.28 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9591927100972123		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.9591927100972123 | validation: 1.0052563544689133]
	TIME [epoch: 1.27 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9686074131192292		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.9686074131192292 | validation: 0.7969579590786893]
	TIME [epoch: 1.28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8824232040617578		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.8824232040617578 | validation: 0.7621835407802677]
	TIME [epoch: 1.28 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.865801655760709		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.865801655760709 | validation: 0.8244929249533904]
	TIME [epoch: 1.28 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8753292134125167		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.8753292134125167 | validation: 0.7418612282038256]
	TIME [epoch: 1.28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8759993148058857		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.8759993148058857 | validation: 0.8427960331289953]
	TIME [epoch: 1.28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8749469891288105		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.8749469891288105 | validation: 0.7377183943629576]
	TIME [epoch: 1.28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8989776375159193		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.8989776375159193 | validation: 0.8399073690828527]
	TIME [epoch: 1.28 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8908306605911125		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.8908306605911125 | validation: 0.799396139862785]
	TIME [epoch: 1.28 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9046253556184057		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.9046253556184057 | validation: 0.8162164424527953]
	TIME [epoch: 1.28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8967341983342172		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.8967341983342172 | validation: 0.7643908745114949]
	TIME [epoch: 1.28 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8818131335977638		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.8818131335977638 | validation: 0.8186873109034013]
	TIME [epoch: 1.28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8718072437170525		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.8718072437170525 | validation: 0.7456902060442117]
	TIME [epoch: 1.28 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8701850001628253		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.8701850001628253 | validation: 0.8346714625198693]
	TIME [epoch: 1.28 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8758293972826147		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.8758293972826147 | validation: 0.7134985438984411]
	TIME [epoch: 1.28 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8911133572322067		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.8911133572322067 | validation: 0.8736911063207139]
	TIME [epoch: 1.28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8925747086257101		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.8925747086257101 | validation: 0.7198830064141211]
	TIME [epoch: 1.28 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8802079895422454		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.8802079895422454 | validation: 0.795000587714582]
	TIME [epoch: 183 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8725660686172888		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.8725660686172888 | validation: 0.763598111196619]
	TIME [epoch: 2.55 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8726832561171531		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.8726832561171531 | validation: 0.7805265099653934]
	TIME [epoch: 2.53 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8816303775990982		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.8816303775990982 | validation: 0.8152879910100739]
	TIME [epoch: 2.53 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9137057642207862		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.9137057642207862 | validation: 0.8595186871850875]
	TIME [epoch: 2.53 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9198874136858709		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.9198874136858709 | validation: 0.7598134270184264]
	TIME [epoch: 2.53 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8932088925878532		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.8932088925878532 | validation: 0.7931197175209149]
	TIME [epoch: 2.54 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8706340804679258		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.8706340804679258 | validation: 0.7566486900188983]
	TIME [epoch: 2.53 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8650295480742609		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.8650295480742609 | validation: 0.7830523235891973]
	TIME [epoch: 2.53 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8627460871556798		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.8627460871556798 | validation: 0.7336242531868812]
	TIME [epoch: 2.54 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8603550753299797		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.8603550753299797 | validation: 0.8112957481131171]
	TIME [epoch: 2.53 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8602708976400686		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.8602708976400686 | validation: 0.6956615250457556]
	TIME [epoch: 2.53 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.869053177637207		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.869053177637207 | validation: 0.9049339232437501]
	TIME [epoch: 2.53 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8957786652150506		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.8957786652150506 | validation: 0.6986690295682338]
	TIME [epoch: 2.54 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9052311536262514		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.9052311536262514 | validation: 0.8548396201191655]
	TIME [epoch: 2.53 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8801504310062125		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.8801504310062125 | validation: 0.8074287250368553]
	TIME [epoch: 2.53 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9012595961253724		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.9012595961253724 | validation: 0.8169541510841501]
	TIME [epoch: 2.53 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9021055577311304		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.9021055577311304 | validation: 0.7709712050145897]
	TIME [epoch: 2.53 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8785613059771713		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.8785613059771713 | validation: 0.807092222654826]
	TIME [epoch: 2.53 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8746208711013372		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.8746208711013372 | validation: 0.7188205906163755]
	TIME [epoch: 2.53 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.861055886113956		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.861055886113956 | validation: 0.8366340234080216]
	TIME [epoch: 2.53 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8652268072862004		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.8652268072862004 | validation: 0.7388533020760649]
	TIME [epoch: 2.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8632193321134327		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.8632193321134327 | validation: 0.798653388463007]
	TIME [epoch: 2.53 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8588409655121666		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.8588409655121666 | validation: 0.7672644894922978]
	TIME [epoch: 2.53 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.85959648634771		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.85959648634771 | validation: 0.8112398246327619]
	TIME [epoch: 2.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8685297791264293		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.8685297791264293 | validation: 0.7798252645547525]
	TIME [epoch: 2.54 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9021386242601603		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.9021386242601603 | validation: 0.9223653040863278]
	TIME [epoch: 2.53 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9198137795751232		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.9198137795751232 | validation: 0.7561795694591473]
	TIME [epoch: 2.53 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8875817791498025		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.8875817791498025 | validation: 0.839954518077427]
	TIME [epoch: 2.53 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8536182569898		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.8536182569898 | validation: 0.741176159208711]
	TIME [epoch: 2.53 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8442083256879354		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.8442083256879354 | validation: 0.7504797366741077]
	TIME [epoch: 2.53 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8446261341694257		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.8446261341694257 | validation: 0.8167817841462652]
	TIME [epoch: 2.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8624374768844709		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.8624374768844709 | validation: 0.7458891780336915]
	TIME [epoch: 2.53 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8619278847018412		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.8619278847018412 | validation: 0.8822419028906373]
	TIME [epoch: 2.53 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8850873463350243		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.8850873463350243 | validation: 0.7826726776947702]
	TIME [epoch: 2.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9052578646446711		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.9052578646446711 | validation: 0.8210737031656798]
	TIME [epoch: 2.53 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.894590030670602		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.894590030670602 | validation: 0.8102105053889037]
	TIME [epoch: 2.53 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.874147965282042		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.874147965282042 | validation: 0.7511223474682639]
	TIME [epoch: 2.54 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8524012243199113		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.8524012243199113 | validation: 0.7676842652712107]
	TIME [epoch: 2.53 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8423163480994893		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.8423163480994893 | validation: 0.7312544743906134]
	TIME [epoch: 2.53 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8397745064355223		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.8397745064355223 | validation: 0.7877832323110655]
	TIME [epoch: 2.53 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8614108473635019		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.8614108473635019 | validation: 0.7444290378762157]
	TIME [epoch: 2.53 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8662942958160099		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.8662942958160099 | validation: 0.8925774069323862]
	TIME [epoch: 2.53 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9010085731457141		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.9010085731457141 | validation: 0.7363383902403903]
	TIME [epoch: 2.53 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.888271815462116		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.888271815462116 | validation: 0.8114281342313646]
	TIME [epoch: 2.53 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8594910617806119		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.8594910617806119 | validation: 0.7628147341087086]
	TIME [epoch: 2.53 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8510771439626328		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.8510771439626328 | validation: 0.7580451506887501]
	TIME [epoch: 2.53 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8414385475441196		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.8414385475441196 | validation: 0.7677417880113939]
	TIME [epoch: 2.54 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8392178425791177		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.8392178425791177 | validation: 0.7526885421960716]
	TIME [epoch: 2.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8488955330778402		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.8488955330778402 | validation: 0.7691511126765036]
	TIME [epoch: 2.53 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8571601158127355		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.8571601158127355 | validation: 0.7747032309640484]
	TIME [epoch: 2.53 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8777841168902845		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.8777841168902845 | validation: 0.7811471910918955]
	TIME [epoch: 2.53 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8862550831069055		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.8862550831069055 | validation: 0.830073967989517]
	TIME [epoch: 2.53 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8767446715981078		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.8767446715981078 | validation: 0.7058610493257066]
	TIME [epoch: 2.53 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8792856740368677		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.8792856740368677 | validation: 0.8567331009458194]
	TIME [epoch: 2.53 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8758527004544532		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.8758527004544532 | validation: 0.6894929106016751]
	TIME [epoch: 2.53 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8441778751835335		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.8441778751835335 | validation: 0.7816317859445816]
	TIME [epoch: 2.53 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8407484071553476		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.8407484071553476 | validation: 0.7930488209515448]
	TIME [epoch: 2.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8492010304078553		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.8492010304078553 | validation: 0.7288992422174717]
	TIME [epoch: 2.53 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8530620403241941		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.8530620403241941 | validation: 0.8588750911830916]
	TIME [epoch: 2.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8571260129828933		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.8571260129828933 | validation: 0.722923691156562]
	TIME [epoch: 2.54 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.855899935788776		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.855899935788776 | validation: 0.7773016426301745]
	TIME [epoch: 2.53 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8673078037751237		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.8673078037751237 | validation: 0.78681761068401]
	TIME [epoch: 2.54 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8681500449736188		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.8681500449736188 | validation: 0.806082760206921]
	TIME [epoch: 2.53 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8694611765444681		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.8694611765444681 | validation: 0.7147503138355151]
	TIME [epoch: 2.54 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8547701936330134		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.8547701936330134 | validation: 0.7978711372627734]
	TIME [epoch: 2.53 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8432685417162502		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.8432685417162502 | validation: 0.7256796647540452]
	TIME [epoch: 2.53 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8362502115891034		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.8362502115891034 | validation: 0.8170182812956338]
	TIME [epoch: 2.53 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8494721717017387		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.8494721717017387 | validation: 0.7116569716693492]
	TIME [epoch: 2.53 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8518640294130922		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.8518640294130922 | validation: 0.7998120434664386]
	TIME [epoch: 2.53 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8431520863342635		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.8431520863342635 | validation: 0.7451527192387867]
	TIME [epoch: 2.54 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.854405897533978		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.854405897533978 | validation: 0.8236199172378346]
	TIME [epoch: 2.53 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8608703074648582		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.8608703074648582 | validation: 0.7720822643808914]
	TIME [epoch: 2.54 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8738372775033142		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.8738372775033142 | validation: 0.7936559007136745]
	TIME [epoch: 2.53 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8631328233046311		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.8631328233046311 | validation: 0.7393919670559194]
	TIME [epoch: 2.53 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8364988556235861		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.8364988556235861 | validation: 0.7659074619002949]
	TIME [epoch: 2.53 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8352196634764322		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.8352196634764322 | validation: 0.721996842835376]
	TIME [epoch: 2.53 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8338496242734875		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.8338496242734875 | validation: 0.7668566717789471]
	TIME [epoch: 2.53 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8394290591572611		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.8394290591572611 | validation: 0.704424967512447]
	TIME [epoch: 2.53 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8346784282497427		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.8346784282497427 | validation: 0.8037466158967304]
	TIME [epoch: 2.53 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8422921236798064		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.8422921236798064 | validation: 0.6917482636692465]
	TIME [epoch: 2.54 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.866191808253278		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.866191808253278 | validation: 0.8839991988661631]
	TIME [epoch: 2.53 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8691893855826314		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.8691893855826314 | validation: 0.7093969861220023]
	TIME [epoch: 2.54 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8567578004414383		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.8567578004414383 | validation: 0.7802997361070523]
	TIME [epoch: 2.53 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8577578307914447		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.8577578307914447 | validation: 0.8314735945945178]
	TIME [epoch: 2.54 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.873112570607269		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.873112570607269 | validation: 0.7534151322853129]
	TIME [epoch: 2.52 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8584406577319968		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.8584406577319968 | validation: 0.7461917478846938]
	TIME [epoch: 2.54 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.838511226631599		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.838511226631599 | validation: 0.7656046849668346]
	TIME [epoch: 2.54 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8323287538508085		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.8323287538508085 | validation: 0.730226046946524]
	TIME [epoch: 2.53 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8293586223302921		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.8293586223302921 | validation: 0.7484387037245175]
	TIME [epoch: 2.53 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8417296980925236		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.8417296980925236 | validation: 0.8097370232723095]
	TIME [epoch: 2.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8671217626878476		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.8671217626878476 | validation: 0.7213659449761943]
	TIME [epoch: 2.52 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8800544681563344		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.8800544681563344 | validation: 0.8282334462126543]
	TIME [epoch: 2.54 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8557712940481172		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.8557712940481172 | validation: 0.7110777901837698]
	TIME [epoch: 2.52 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8397928329424553		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.8397928329424553 | validation: 0.7493093598172225]
	TIME [epoch: 2.53 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8235661646415947		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.8235661646415947 | validation: 0.7485382556508311]
	TIME [epoch: 2.52 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8312875463069407		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.8312875463069407 | validation: 0.7369089539515301]
	TIME [epoch: 2.54 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8303495623262345		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.8303495623262345 | validation: 0.7656518511415397]
	TIME [epoch: 2.52 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8390098652838642		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.8390098652838642 | validation: 0.7376975215118127]
	TIME [epoch: 2.53 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8332140377649324		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.8332140377649324 | validation: 0.7484533493887073]
	TIME [epoch: 2.53 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8404319100303722		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.8404319100303722 | validation: 0.7043575476197491]
	TIME [epoch: 2.54 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8465869640000887		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.8465869640000887 | validation: 0.7727029839886357]
	TIME [epoch: 2.53 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8269045608341733		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.8269045608341733 | validation: 0.6980904591771655]
	TIME [epoch: 2.53 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8359061515253834		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.8359061515253834 | validation: 0.7901903955786473]
	TIME [epoch: 2.53 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8259030198672238		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.8259030198672238 | validation: 0.6886619889841021]
	TIME [epoch: 2.53 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8417101176766226		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.8417101176766226 | validation: 0.8827352123729324]
	TIME [epoch: 2.54 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8624015493476175		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.8624015493476175 | validation: 0.731905059918305]
	TIME [epoch: 2.53 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8864196589228661		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.8864196589228661 | validation: 0.8051845539681962]
	TIME [epoch: 2.54 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8515686541471696		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.8515686541471696 | validation: 0.7614662281003249]
	TIME [epoch: 2.53 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8315113277024411		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.8315113277024411 | validation: 0.732481051594591]
	TIME [epoch: 2.54 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8327529882306892		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.8327529882306892 | validation: 0.7691239863732086]
	TIME [epoch: 2.53 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8264152908403223		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.8264152908403223 | validation: 0.7151048493933113]
	TIME [epoch: 2.53 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8319313711435397		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.8319313711435397 | validation: 0.793110418564862]
	TIME [epoch: 2.53 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.839956575549576		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.839956575549576 | validation: 0.7124138596315175]
	TIME [epoch: 2.53 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8467170074165081		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.8467170074165081 | validation: 0.7530705444629746]
	TIME [epoch: 2.54 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8391610013603122		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.8391610013603122 | validation: 0.7476236502407763]
	TIME [epoch: 2.53 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8351503512756392		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.8351503512756392 | validation: 0.7048258106043641]
	TIME [epoch: 2.54 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8258127284036054		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.8258127284036054 | validation: 0.742965563455849]
	TIME [epoch: 2.53 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8330583129112626		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.8330583129112626 | validation: 0.729281683027061]
	TIME [epoch: 2.53 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8184366210308335		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.8184366210308335 | validation: 0.7222099110582587]
	TIME [epoch: 2.54 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8348864209994799		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.8348864209994799 | validation: 0.8082791981649708]
	TIME [epoch: 2.53 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8511812555541124		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.8511812555541124 | validation: 0.7270010102893101]
	TIME [epoch: 2.53 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8799657847397501		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.8799657847397501 | validation: 0.8474285221130238]
	TIME [epoch: 2.53 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8643291424367314		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.8643291424367314 | validation: 0.7160042819468014]
	TIME [epoch: 2.53 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8373920078977918		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.8373920078977918 | validation: 0.7292014981654924]
	TIME [epoch: 2.53 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8268249343533629		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.8268249343533629 | validation: 0.7509240079241415]
	TIME [epoch: 2.53 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8286760293893681		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.8286760293893681 | validation: 0.7205620186070694]
	TIME [epoch: 2.53 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8314214986983341		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.8314214986983341 | validation: 0.7932079266502362]
	TIME [epoch: 2.53 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8360601838376941		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.8360601838376941 | validation: 0.7013697214892561]
	TIME [epoch: 2.53 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8396231072243012		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.8396231072243012 | validation: 0.7696479986166349]
	TIME [epoch: 2.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8382089683551346		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.8382089683551346 | validation: 0.7384031721948313]
	TIME [epoch: 2.54 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8300830130301486		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.8300830130301486 | validation: 0.7489645023601121]
	TIME [epoch: 2.54 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8333321851251785		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.8333321851251785 | validation: 0.7148402385353547]
	TIME [epoch: 2.53 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8295533309183842		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.8295533309183842 | validation: 0.7496821064903009]
	TIME [epoch: 2.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8341665446915056		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.8341665446915056 | validation: 0.7261134457328384]
	TIME [epoch: 2.54 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.83460720080117		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.83460720080117 | validation: 0.7818992787239195]
	TIME [epoch: 2.53 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.831594778404001		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.831594778404001 | validation: 0.6748763393532727]
	TIME [epoch: 2.53 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.837577692907735		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.837577692907735 | validation: 0.8117991193943794]
	TIME [epoch: 2.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8396612710115428		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.8396612710115428 | validation: 0.6763592909496075]
	TIME [epoch: 2.52 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8376233468521543		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.8376233468521543 | validation: 0.7219163920351286]
	TIME [epoch: 2.52 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8269378712547549		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.8269378712547549 | validation: 0.7716307621405356]
	TIME [epoch: 2.52 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8153791731824541		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.8153791731824541 | validation: 0.6903598847096061]
	TIME [epoch: 2.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.83019149610078		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.83019149610078 | validation: 0.7958233285413607]
	TIME [epoch: 2.52 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8276708066447117		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.8276708066447117 | validation: 0.6630317705359586]
	TIME [epoch: 2.52 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8270005564289394		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.8270005564289394 | validation: 0.7560397797240309]
	TIME [epoch: 2.52 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8292680263733503		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.8292680263733503 | validation: 0.7729142018847013]
	TIME [epoch: 2.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8478298649543058		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.8478298649543058 | validation: 0.7599654530746499]
	TIME [epoch: 2.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8526730901666895		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.8526730901666895 | validation: 0.7138459780679839]
	TIME [epoch: 2.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8249363937339156		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.8249363937339156 | validation: 0.7732671713828853]
	TIME [epoch: 2.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8246052881063757		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.8246052881063757 | validation: 0.7164533813176757]
	TIME [epoch: 2.52 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8310843927998159		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.8310843927998159 | validation: 0.7945135569014785]
	TIME [epoch: 2.52 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8276915512628057		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.8276915512628057 | validation: 0.6777524782814055]
	TIME [epoch: 2.53 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8284974900643636		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.8284974900643636 | validation: 0.7348929153310135]
	TIME [epoch: 2.52 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8206790202796568		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.8206790202796568 | validation: 0.7344984440889613]
	TIME [epoch: 2.53 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8208718989238082		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.8208718989238082 | validation: 0.730740112110541]
	TIME [epoch: 2.52 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8241806023861921		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.8241806023861921 | validation: 0.7263513650772608]
	TIME [epoch: 2.53 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8150370560304668		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.8150370560304668 | validation: 0.7586437742623211]
	TIME [epoch: 2.52 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8212398511851714		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.8212398511851714 | validation: 0.7178893821042139]
	TIME [epoch: 2.53 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8457590491346337		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.8457590491346337 | validation: 0.8019720672691601]
	TIME [epoch: 2.52 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8443391198467631		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.8443391198467631 | validation: 0.705893993552955]
	TIME [epoch: 2.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.848276584165738		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.848276584165738 | validation: 0.81219846467617]
	TIME [epoch: 2.52 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8257206665777327		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.8257206665777327 | validation: 0.7014519100718811]
	TIME [epoch: 2.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8191520810535051		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.8191520810535051 | validation: 0.7162141107918035]
	TIME [epoch: 2.52 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8218988421706552		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.8218988421706552 | validation: 0.7404937920961145]
	TIME [epoch: 2.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8168216319855919		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.8168216319855919 | validation: 0.713794057521448]
	TIME [epoch: 2.53 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8146628399425017		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.8146628399425017 | validation: 0.7365768304578273]
	TIME [epoch: 2.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8122881187841212		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.8122881187841212 | validation: 0.6982066174443137]
	TIME [epoch: 2.53 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8069310767334136		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.8069310767334136 | validation: 0.786120259430377]
	TIME [epoch: 2.52 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8312568377354372		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.8312568377354372 | validation: 0.65295795254203]
	TIME [epoch: 2.53 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8430689869544485		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.8430689869544485 | validation: 0.8250822951442599]
	TIME [epoch: 2.52 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8333451654219627		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.8333451654219627 | validation: 0.7110106363203693]
	TIME [epoch: 2.51 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8174298703887777		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.8174298703887777 | validation: 0.7429853613044624]
	TIME [epoch: 2.51 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8319042194498931		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.8319042194498931 | validation: 0.7252529858785656]
	TIME [epoch: 2.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8507518543865743		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.8507518543865743 | validation: 0.7835287692493996]
	TIME [epoch: 2.51 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8283932573364118		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.8283932573364118 | validation: 0.713648598656543]
	TIME [epoch: 2.51 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8275260740227672		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.8275260740227672 | validation: 0.7574634461298149]
	TIME [epoch: 2.52 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8233108706418255		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.8233108706418255 | validation: 0.7060906042617459]
	TIME [epoch: 2.51 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8196261619910924		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.8196261619910924 | validation: 0.7165464987950964]
	TIME [epoch: 2.51 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8076797308197885		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.8076797308197885 | validation: 0.7105185625119534]
	TIME [epoch: 2.51 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8171090485580311		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.8171090485580311 | validation: 0.7342979412011398]
	TIME [epoch: 2.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8206856250097789		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.8206856250097789 | validation: 0.7134530530811504]
	TIME [epoch: 2.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8200634013768832		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.8200634013768832 | validation: 0.8158499364099623]
	TIME [epoch: 2.51 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.839628026324233		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.839628026324233 | validation: 0.7006396527707635]
	TIME [epoch: 2.5 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8475117674485005		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.8475117674485005 | validation: 0.7605150290284126]
	TIME [epoch: 2.51 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8274603092470241		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.8274603092470241 | validation: 0.7467200492848534]
	TIME [epoch: 2.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8179638270261427		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.8179638270261427 | validation: 0.7116158809656682]
	TIME [epoch: 2.51 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8217623221103514		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.8217623221103514 | validation: 0.7350747058138309]
	TIME [epoch: 2.5 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8152649271883519		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.8152649271883519 | validation: 0.6614581848561946]
	TIME [epoch: 2.51 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8220837158535449		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.8220837158535449 | validation: 0.8013953073039698]
	TIME [epoch: 2.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8153841531239366		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.8153841531239366 | validation: 0.700042163672556]
	TIME [epoch: 2.52 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8193811684809239		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.8193811684809239 | validation: 0.7576040494100806]
	TIME [epoch: 2.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8224773919910083		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.8224773919910083 | validation: 0.6899717120634101]
	TIME [epoch: 2.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8118643766491832		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.8118643766491832 | validation: 0.7534217147966992]
	TIME [epoch: 2.53 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8147239596075341		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.8147239596075341 | validation: 0.711123490788799]
	TIME [epoch: 2.53 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8159303065727437		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.8159303065727437 | validation: 0.7700609615815074]
	TIME [epoch: 2.53 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8196553000326151		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.8196553000326151 | validation: 0.7029407001886214]
	TIME [epoch: 2.52 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.81505943323165		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.81505943323165 | validation: 0.7659502673741598]
	TIME [epoch: 2.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8172680781106711		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.8172680781106711 | validation: 0.7071701618169167]
	TIME [epoch: 2.52 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8109793948543302		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.8109793948543302 | validation: 0.7108405370023154]
	TIME [epoch: 2.52 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8176797121838649		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.8176797121838649 | validation: 0.7557699841049981]
	TIME [epoch: 2.52 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8107817395920577		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.8107817395920577 | validation: 0.6933318036142938]
	TIME [epoch: 2.53 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8309867833059016		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.8309867833059016 | validation: 0.7846423508571589]
	TIME [epoch: 2.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8301427693086576		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.8301427693086576 | validation: 0.7292637159292178]
	TIME [epoch: 2.52 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8166395124921577		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.8166395124921577 | validation: 0.7009107730356897]
	TIME [epoch: 2.52 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8063815124782348		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.8063815124782348 | validation: 0.7934733121140662]
	TIME [epoch: 2.52 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8170849774502281		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.8170849774502281 | validation: 0.6892843517762901]
	TIME [epoch: 2.51 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8221546104880807		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.8221546104880807 | validation: 0.7904216546582707]
	TIME [epoch: 2.52 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8248511261396811		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.8248511261396811 | validation: 0.7035995618348004]
	TIME [epoch: 2.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.828003226323697		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.828003226323697 | validation: 0.7453642007284874]
	TIME [epoch: 2.51 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8184865585255716		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.8184865585255716 | validation: 0.7367485207302832]
	TIME [epoch: 2.52 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.812134445548065		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.812134445548065 | validation: 0.6975656308189174]
	TIME [epoch: 2.52 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8138791649294743		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.8138791649294743 | validation: 0.7152492832659259]
	TIME [epoch: 2.52 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7996215057705074		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.7996215057705074 | validation: 0.756161357748824]
	TIME [epoch: 2.52 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8057122506302709		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.8057122506302709 | validation: 0.717621802396119]
	TIME [epoch: 2.52 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8166086502510942		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.8166086502510942 | validation: 0.767668686146613]
	TIME [epoch: 2.52 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8129778351869468		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.8129778351869468 | validation: 0.6851921495504935]
	TIME [epoch: 2.51 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8159695580797112		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.8159695580797112 | validation: 0.7857315009212756]
	TIME [epoch: 2.52 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8145146869400861		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.8145146869400861 | validation: 0.7132041815114771]
	TIME [epoch: 2.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8209621512188481		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.8209621512188481 | validation: 0.7616470232949215]
	TIME [epoch: 2.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8215783372106807		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.8215783372106807 | validation: 0.7083472198227814]
	TIME [epoch: 2.51 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8327805507622472		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.8327805507622472 | validation: 0.7925059470916248]
	TIME [epoch: 2.52 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8401119602752062		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.8401119602752062 | validation: 0.6781779463640908]
	TIME [epoch: 2.52 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8129048840399964		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.8129048840399964 | validation: 0.7331550913943593]
	TIME [epoch: 2.52 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7987317280479489		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.7987317280479489 | validation: 0.7535306660383058]
	TIME [epoch: 2.52 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8113401487129897		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.8113401487129897 | validation: 0.7133558297998801]
	TIME [epoch: 2.52 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8069599382746142		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.8069599382746142 | validation: 0.7317194113105315]
	TIME [epoch: 2.52 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7994057978525649		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.7994057978525649 | validation: 0.7171467853934264]
	TIME [epoch: 2.52 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8078573445706551		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.8078573445706551 | validation: 0.7477661776329649]
	TIME [epoch: 2.53 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8080252093203854		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.8080252093203854 | validation: 0.6853744712430243]
	TIME [epoch: 2.52 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8082756293329468		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.8082756293329468 | validation: 0.8014866309948732]
	TIME [epoch: 2.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8292958093605026		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.8292958093605026 | validation: 0.6780421807551895]
	TIME [epoch: 2.52 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8207485692152169		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.8207485692152169 | validation: 0.7533567229341485]
	TIME [epoch: 2.52 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8189698649545446		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.8189698649545446 | validation: 0.7353233236086816]
	TIME [epoch: 2.52 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.824258964333355		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.824258964333355 | validation: 0.7231835755623939]
	TIME [epoch: 2.52 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8107933462969115		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.8107933462969115 | validation: 0.7055147761288164]
	TIME [epoch: 2.53 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8025937629292174		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.8025937629292174 | validation: 0.7220752302936697]
	TIME [epoch: 2.52 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8057276683721548		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.8057276683721548 | validation: 0.7111532431498914]
	TIME [epoch: 2.53 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7965335020979398		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.7965335020979398 | validation: 0.7806969684213437]
	TIME [epoch: 2.52 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8179567842654695		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.8179567842654695 | validation: 0.665446133889966]
	TIME [epoch: 2.53 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8252404648699636		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.8252404648699636 | validation: 0.7599893092128487]
	TIME [epoch: 2.53 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8091690481327448		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.8091690481327448 | validation: 0.6891844206612628]
	TIME [epoch: 2.52 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8056375738771584		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.8056375738771584 | validation: 0.7294859504290716]
	TIME [epoch: 2.52 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7988028138312407		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.7988028138312407 | validation: 0.7074391227335319]
	TIME [epoch: 2.52 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8048637946500631		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.8048637946500631 | validation: 0.7463629517362484]
	TIME [epoch: 2.53 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8167089478178241		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.8167089478178241 | validation: 0.6836036320245674]
	TIME [epoch: 2.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8266693360421714		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.8266693360421714 | validation: 0.7625177013169906]
	TIME [epoch: 2.52 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8241664999173457		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.8241664999173457 | validation: 0.715144853114319]
	TIME [epoch: 2.53 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8148133379778504		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.8148133379778504 | validation: 0.7307360044270126]
	TIME [epoch: 2.53 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8022308665105178		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.8022308665105178 | validation: 0.7033337321445399]
	TIME [epoch: 2.53 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7973747913672002		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.7973747913672002 | validation: 0.6968515486109587]
	TIME [epoch: 2.52 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8035307400440677		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.8035307400440677 | validation: 0.7010908465749149]
	TIME [epoch: 2.53 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.801933004926064		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.801933004926064 | validation: 0.7263721027982986]
	TIME [epoch: 2.52 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8052438525172432		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.8052438525172432 | validation: 0.711372269221914]
	TIME [epoch: 2.53 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8025002072001507		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.8025002072001507 | validation: 0.7141917791980659]
	TIME [epoch: 2.52 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8070979533149288		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.8070979533149288 | validation: 0.7367783625666863]
	TIME [epoch: 2.53 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.81143371298894		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.81143371298894 | validation: 0.7003666055150058]
	TIME [epoch: 2.52 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8191614664628312		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.8191614664628312 | validation: 0.7878251061774453]
	TIME [epoch: 2.52 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8283221870205684		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.8283221870205684 | validation: 0.6975971850963211]
	TIME [epoch: 2.53 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8258182111030213		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.8258182111030213 | validation: 0.7314018335965602]
	TIME [epoch: 2.53 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8033718880039061		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.8033718880039061 | validation: 0.7468624364566974]
	TIME [epoch: 2.54 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8017019166758086		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.8017019166758086 | validation: 0.701421434492566]
	TIME [epoch: 2.52 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.814935596071755		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.814935596071755 | validation: 0.7713674241824093]
	TIME [epoch: 2.53 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.808894397833757		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.808894397833757 | validation: 0.6713117474397722]
	TIME [epoch: 2.52 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8073901533067528		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.8073901533067528 | validation: 0.7662041474940329]
	TIME [epoch: 2.52 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8062708665443974		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.8062708665443974 | validation: 0.7027879364432158]
	TIME [epoch: 2.53 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8016751566349015		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.8016751566349015 | validation: 0.7026884371847132]
	TIME [epoch: 2.53 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8036309681756846		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.8036309681756846 | validation: 0.7164794061424004]
	TIME [epoch: 2.52 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.797777906626941		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.797777906626941 | validation: 0.7214216380107303]
	TIME [epoch: 2.52 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8112432117557691		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.8112432117557691 | validation: 0.7196943025078002]
	TIME [epoch: 2.51 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8067844569518278		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.8067844569518278 | validation: 0.7285289302909818]
	TIME [epoch: 2.52 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_9_v_mmd4_20250519_185624/states/model_phi1_4a_distortion_v2_9_v_mmd4_770.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1793.084 seconds.
