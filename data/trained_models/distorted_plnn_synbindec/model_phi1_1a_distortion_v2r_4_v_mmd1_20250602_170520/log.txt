Args:
Namespace(name='model_phi1_1a_distortion_v2r_4_v_mmd1', outdir='out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1', training_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v2r_4/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v2r_4/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.028015178, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2361546385

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.39663362741658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.39663362741658 | validation: 5.943700329499164]
	TIME [epoch: 412 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.587004941945646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.587004941945646 | validation: 5.93705777147948]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.131637758113742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.131637758113742 | validation: 4.898037939080522]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.885394896473507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.885394896473507 | validation: 3.953916006220772]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.174694029886266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.174694029886266 | validation: 4.131209816282571]
	TIME [epoch: 6 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9761577918966475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9761577918966475 | validation: 3.7608518966854474]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4941923587124863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4941923587124863 | validation: 3.6351698087898185]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5787938817022735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5787938817022735 | validation: 3.3561308190934116]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.085436245105419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.085436245105419 | validation: 3.2637588656023944]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2092240120386366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2092240120386366 | validation: 3.416569759203653]
	TIME [epoch: 6.01 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.017362152131963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.017362152131963 | validation: 2.736647190228236]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7299578973251295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7299578973251295 | validation: 2.630904479243093]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.617811973946552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.617811973946552 | validation: 2.8591708381735206]
	TIME [epoch: 5.98 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5604240981719206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5604240981719206 | validation: 2.5026606527343263]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.397605602489663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.397605602489663 | validation: 2.454669364916037]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3068197636432406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3068197636432406 | validation: 2.421648614899458]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2186753830591996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2186753830591996 | validation: 2.2810604301331123]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2061382442040514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2061382442040514 | validation: 2.3642161491550855]
	TIME [epoch: 6 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1099054244823034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1099054244823034 | validation: 2.101052645152737]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0570427725923306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0570427725923306 | validation: 2.1093678230002704]
	TIME [epoch: 5.99 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041077660342998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.041077660342998 | validation: 2.3360970753250645]
	TIME [epoch: 5.99 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0336853745827543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0336853745827543 | validation: 2.08965010593886]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9928021412016526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9928021412016526 | validation: 2.1439362467443868]
	TIME [epoch: 6 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9709783950990531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9709783950990531 | validation: 2.0539239596119425]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0106549555696236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0106549555696236 | validation: 2.0397025628876384]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.94135795660401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.94135795660401 | validation: 2.098252453688371]
	TIME [epoch: 6 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9277462427732543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9277462427732543 | validation: 2.213317255449989]
	TIME [epoch: 5.99 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.034855973856439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.034855973856439 | validation: 2.172020844707128]
	TIME [epoch: 5.98 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.969280163926524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.969280163926524 | validation: 2.014462538786975]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8862352590928213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8862352590928213 | validation: 2.0087427998604435]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9612430741314872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9612430741314872 | validation: 1.9385730486751647]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.915450819301846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.915450819301846 | validation: 1.9402850749611047]
	TIME [epoch: 6 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.893680287572642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.893680287572642 | validation: 1.925260219648441]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9636480347793872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9636480347793872 | validation: 1.9790199113563147]
	TIME [epoch: 5.99 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8299844851768836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8299844851768836 | validation: 1.8044762511140326]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8286308302798178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8286308302798178 | validation: 3.05607795028432]
	TIME [epoch: 5.99 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.242720138321474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.242720138321474 | validation: 1.9271241001392585]
	TIME [epoch: 6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.771265665915502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.771265665915502 | validation: 1.7655108646035091]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6853099306708328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6853099306708328 | validation: 1.5674534024231455]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.008149139375676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.008149139375676 | validation: 1.9313002564863466]
	TIME [epoch: 5.99 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8176614768743447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8176614768743447 | validation: 1.632699119531019]
	TIME [epoch: 5.99 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6132215706832769		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6132215706832769 | validation: 1.4842049070328638]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.676718594540613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.676718594540613 | validation: 1.420181354020924]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.471714321717652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.471714321717652 | validation: 1.525204152373664]
	TIME [epoch: 5.99 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.719582428658401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.719582428658401 | validation: 1.5812926291840352]
	TIME [epoch: 5.99 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5822879633581297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5822879633581297 | validation: 1.3514110773180197]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3355491916994033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3355491916994033 | validation: 1.3209796898121446]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3168419443686739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3168419443686739 | validation: 1.587201647287464]
	TIME [epoch: 6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6027398703132771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6027398703132771 | validation: 1.4418058734680215]
	TIME [epoch: 5.99 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3201211569783686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3201211569783686 | validation: 1.2125025682633164]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3516316989224106		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 1.3516316989224106 | validation: 1.315430932572914]
	TIME [epoch: 6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345880758234178		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 1.2345880758234178 | validation: 1.2779582273659376]
	TIME [epoch: 6 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29807374069918		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.29807374069918 | validation: 1.519680397096106]
	TIME [epoch: 5.99 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2592078675172587		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.2592078675172587 | validation: 1.2478362761014123]
	TIME [epoch: 5.99 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1850597212699712		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.1850597212699712 | validation: 1.3619832377757368]
	TIME [epoch: 5.99 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2186896632335247		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.2186896632335247 | validation: 1.0323056785920195]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0896314188653553		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.0896314188653553 | validation: 1.609790516705338]
	TIME [epoch: 6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3282806239357718		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.3282806239357718 | validation: 1.2676128939688822]
	TIME [epoch: 5.99 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.088797856731686		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.088797856731686 | validation: 1.3475877732199246]
	TIME [epoch: 5.98 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.221395052390159		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.221395052390159 | validation: 1.2113543256003818]
	TIME [epoch: 5.99 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217572072619534		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.0217572072619534 | validation: 1.222248611820706]
	TIME [epoch: 5.99 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1169895744570573		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.1169895744570573 | validation: 0.9899265099278501]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0090867215021293		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.0090867215021293 | validation: 0.9087267934170042]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9576950379125657		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.9576950379125657 | validation: 0.9106450265355803]
	TIME [epoch: 5.99 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9491258928784944		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.9491258928784944 | validation: 1.0137334158093343]
	TIME [epoch: 5.99 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9021063392340841		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 0.9021063392340841 | validation: 0.8930857011745221]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509736121020877		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.8509736121020877 | validation: 0.9762126921246868]
	TIME [epoch: 5.99 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.91460040680093		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.91460040680093 | validation: 0.6851561986868961]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701114756020487		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.7701114756020487 | validation: 0.9831694289088526]
	TIME [epoch: 5.99 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.857353530019787		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.857353530019787 | validation: 0.6185227518816736]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7981835621585761		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.7981835621585761 | validation: 0.7589153955454957]
	TIME [epoch: 6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8491506322087092		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.8491506322087092 | validation: 0.9860025768654428]
	TIME [epoch: 5.98 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7375325033212123		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.7375325033212123 | validation: 0.6368421757205586]
	TIME [epoch: 5.98 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8402485927962977		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.8402485927962977 | validation: 0.6351573594786813]
	TIME [epoch: 5.98 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629537202277207		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.6629537202277207 | validation: 1.3545820696859217]
	TIME [epoch: 5.98 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0459403060825343		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.0459403060825343 | validation: 0.8118903884542099]
	TIME [epoch: 5.99 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693464236846214		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.6693464236846214 | validation: 0.809533530409487]
	TIME [epoch: 5.98 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1598916858550625		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.1598916858550625 | validation: 0.6965473181494852]
	TIME [epoch: 5.99 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7040032222602723		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.7040032222602723 | validation: 0.5828334519171302]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7992588045800642		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.7992588045800642 | validation: 0.8155773848185186]
	TIME [epoch: 5.99 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442638709003145		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.6442638709003145 | validation: 0.583555894111988]
	TIME [epoch: 5.99 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6855450737661789		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.6855450737661789 | validation: 0.7455680371874873]
	TIME [epoch: 5.99 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6248845009255981		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.6248845009255981 | validation: 0.7623250201593867]
	TIME [epoch: 6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6679311273217972		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.6679311273217972 | validation: 0.5602657085580542]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469024112125382		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.6469024112125382 | validation: 0.5892600595496802]
	TIME [epoch: 6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620062411146788		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.620062411146788 | validation: 0.7251904118211621]
	TIME [epoch: 5.99 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6360307147515012		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.6360307147515012 | validation: 0.6867515662467167]
	TIME [epoch: 5.99 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867098230487187		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.6867098230487187 | validation: 0.5729117789955189]
	TIME [epoch: 5.99 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6082699990510179		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.6082699990510179 | validation: 0.5908639232402795]
	TIME [epoch: 5.99 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960402562800926		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.5960402562800926 | validation: 0.8414162023224021]
	TIME [epoch: 5.99 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6081494740826286		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.6081494740826286 | validation: 0.5184600938165309]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5541434668131006		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.5541434668131006 | validation: 0.9896548841697322]
	TIME [epoch: 5.99 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733609046601252		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.6733609046601252 | validation: 0.5736462413613979]
	TIME [epoch: 5.99 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5704299550867475		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.5704299550867475 | validation: 0.5527438255663558]
	TIME [epoch: 5.99 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975486716722639		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.5975486716722639 | validation: 0.6420248799155055]
	TIME [epoch: 5.99 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558688481039341		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.558688481039341 | validation: 0.6377214699229179]
	TIME [epoch: 5.99 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564878537695865		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.5564878537695865 | validation: 0.6466725103165105]
	TIME [epoch: 5.98 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749725434438329		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.5749725434438329 | validation: 0.4175515736330523]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335154453862743		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.5335154453862743 | validation: 0.5272214494567725]
	TIME [epoch: 5.99 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5849196219978104		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.5849196219978104 | validation: 0.4230962605763148]
	TIME [epoch: 6 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099645308380356		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5099645308380356 | validation: 0.4832580224734888]
	TIME [epoch: 5.99 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740552245742531		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.5740552245742531 | validation: 0.6355580426770315]
	TIME [epoch: 5.99 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376980839790481		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.5376980839790481 | validation: 0.567150506553105]
	TIME [epoch: 5.99 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519513199505983		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.5519513199505983 | validation: 0.3932691856698673]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4831240730778221		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.4831240730778221 | validation: 0.5999851262185147]
	TIME [epoch: 5.99 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579878521244813		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.5579878521244813 | validation: 0.5187934187974766]
	TIME [epoch: 5.99 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43149275005297083		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.43149275005297083 | validation: 0.5277816400434947]
	TIME [epoch: 5.99 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6726068208469118		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.6726068208469118 | validation: 0.43783941881478977]
	TIME [epoch: 5.99 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533925168295072		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.533925168295072 | validation: 0.49502869408295747]
	TIME [epoch: 5.99 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833057221838861		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.4833057221838861 | validation: 0.513984752317737]
	TIME [epoch: 6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4771928960369528		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.4771928960369528 | validation: 0.44208824235166627]
	TIME [epoch: 5.99 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4388713251257397		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4388713251257397 | validation: 0.47889077394515966]
	TIME [epoch: 5.98 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5932689257651502		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.5932689257651502 | validation: 0.5120612190471262]
	TIME [epoch: 5.98 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45675503727778866		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.45675503727778866 | validation: 0.481659774421848]
	TIME [epoch: 5.99 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5234746110022518		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.5234746110022518 | validation: 0.36143522518969246]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727558951607182		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.4727558951607182 | validation: 0.4715987019115526]
	TIME [epoch: 5.99 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49750830242461314		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.49750830242461314 | validation: 0.39064297546777293]
	TIME [epoch: 5.99 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4946794290820241		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.4946794290820241 | validation: 0.6259257603179906]
	TIME [epoch: 5.99 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891896154186337		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.4891896154186337 | validation: 0.4542870813265991]
	TIME [epoch: 6.05 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542340289806839		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.542340289806839 | validation: 0.45599701018059957]
	TIME [epoch: 5.99 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390546377309779		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.390546377309779 | validation: 0.5218274906775422]
	TIME [epoch: 5.98 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174714244970404		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.5174714244970404 | validation: 0.5735724384017593]
	TIME [epoch: 5.99 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41093451943785997		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.41093451943785997 | validation: 0.39854868589421255]
	TIME [epoch: 5.99 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45684843485188215		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.45684843485188215 | validation: 0.6902845278728804]
	TIME [epoch: 5.99 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293455316992589		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.5293455316992589 | validation: 0.5879590464559914]
	TIME [epoch: 5.99 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4403310605052505		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.4403310605052505 | validation: 0.5973536451382067]
	TIME [epoch: 5.99 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656711728931908		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.4656711728931908 | validation: 0.4694240655544666]
	TIME [epoch: 5.99 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48058483032621585		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.48058483032621585 | validation: 0.3900851785551688]
	TIME [epoch: 5.98 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42592762944148643		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.42592762944148643 | validation: 0.31921140386378133]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.458092132646546		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.458092132646546 | validation: 0.3990967412350152]
	TIME [epoch: 6 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4618246579190558		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.4618246579190558 | validation: 0.3686868748542306]
	TIME [epoch: 5.99 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43974076711572335		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.43974076711572335 | validation: 0.419094708772379]
	TIME [epoch: 5.99 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240427622426881		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.5240427622426881 | validation: 0.45969988494889025]
	TIME [epoch: 5.99 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42283036964675447		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.42283036964675447 | validation: 0.5750477916149324]
	TIME [epoch: 5.99 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4865351088080293		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.4865351088080293 | validation: 0.3743829620119937]
	TIME [epoch: 6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36545820887890756		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.36545820887890756 | validation: 0.34825281473085534]
	TIME [epoch: 5.98 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438959312390585		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.438959312390585 | validation: 0.28710994914475235]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.449929303328407		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 0.449929303328407 | validation: 0.3268691013893578]
	TIME [epoch: 6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3889593190758602		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3889593190758602 | validation: 0.3752772222880706]
	TIME [epoch: 6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43503963949425295		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.43503963949425295 | validation: 0.40280242357763785]
	TIME [epoch: 6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4910714440681113		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.4910714440681113 | validation: 0.5193399777049368]
	TIME [epoch: 5.99 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4416817102662634		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.4416817102662634 | validation: 0.35162997042899374]
	TIME [epoch: 6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39095965792567267		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.39095965792567267 | validation: 0.46419365718296807]
	TIME [epoch: 6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37451543930776215		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.37451543930776215 | validation: 0.3835765487866236]
	TIME [epoch: 5.98 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487750576238281		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.4487750576238281 | validation: 0.28961523430370434]
	TIME [epoch: 5.99 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41724459701019734		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.41724459701019734 | validation: 0.2931468102007794]
	TIME [epoch: 5.99 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38108435276773983		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.38108435276773983 | validation: 0.32789231250147133]
	TIME [epoch: 6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4152367563344902		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.4152367563344902 | validation: 0.2944112174563872]
	TIME [epoch: 6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3375708972920852		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3375708972920852 | validation: 0.4587714517897492]
	TIME [epoch: 6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38777512358162175		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.38777512358162175 | validation: 0.7888216199097149]
	TIME [epoch: 6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342916170084508		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.5342916170084508 | validation: 0.33472511731826693]
	TIME [epoch: 5.99 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497322809020205		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.3497322809020205 | validation: 0.30954415442350613]
	TIME [epoch: 5.99 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598968314733392		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.3598968314733392 | validation: 0.3954274161808187]
	TIME [epoch: 5.99 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971062479034406		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.4971062479034406 | validation: 0.3753615396076689]
	TIME [epoch: 6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4397830290264457		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.4397830290264457 | validation: 0.25673093550547943]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35040604030448563		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.35040604030448563 | validation: 0.45365851015705205]
	TIME [epoch: 5.99 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39139001941709195		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.39139001941709195 | validation: 0.2746995394762523]
	TIME [epoch: 5.99 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3132846694557074		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3132846694557074 | validation: 0.38340021987124545]
	TIME [epoch: 5.99 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435300531560265		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.5435300531560265 | validation: 0.2514672847131361]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805201949508711		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3805201949508711 | validation: 0.2873599770803705]
	TIME [epoch: 5.98 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37005950112577357		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 0.37005950112577357 | validation: 0.2801680781241219]
	TIME [epoch: 5.99 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2747450660779352		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.2747450660779352 | validation: 0.33562039484344414]
	TIME [epoch: 6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853819169448493		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.3853819169448493 | validation: 0.3000536504410898]
	TIME [epoch: 5.99 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3254225203600825		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.3254225203600825 | validation: 0.3037188353109872]
	TIME [epoch: 6 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33898159152479646		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.33898159152479646 | validation: 0.5502109118882568]
	TIME [epoch: 6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061245056447244		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.4061245056447244 | validation: 0.24653872804175705]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3121651837539767		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3121651837539767 | validation: 0.236897023513899]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535705403447477		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.2535705403447477 | validation: 0.431625782566003]
	TIME [epoch: 5.98 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4696427180415877		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.4696427180415877 | validation: 0.2986425112762753]
	TIME [epoch: 5.99 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32783252117393075		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.32783252117393075 | validation: 0.28055295803283786]
	TIME [epoch: 5.98 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3353265403766918		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3353265403766918 | validation: 0.2843531855709419]
	TIME [epoch: 5.99 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305275225797203		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.305275225797203 | validation: 0.2154283406641106]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32448737026269664		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.32448737026269664 | validation: 0.2623895745471606]
	TIME [epoch: 6 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31827690236792344		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.31827690236792344 | validation: 0.31765208946814183]
	TIME [epoch: 5.99 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841463577617096		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.4841463577617096 | validation: 0.4476809633980288]
	TIME [epoch: 5.98 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904597775917583		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 0.3904597775917583 | validation: 0.2910632500249508]
	TIME [epoch: 5.98 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.271516314688768		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.271516314688768 | validation: 0.23960719102290878]
	TIME [epoch: 5.98 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3186101433121494		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.3186101433121494 | validation: 0.35679989851738575]
	TIME [epoch: 5.99 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3410398799397485		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.3410398799397485 | validation: 0.2598580301519223]
	TIME [epoch: 5.98 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32831187457602856		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.32831187457602856 | validation: 0.27888384669510274]
	TIME [epoch: 5.99 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2788366711493044		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.2788366711493044 | validation: 0.2748727423246347]
	TIME [epoch: 5.99 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31615981136889126		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.31615981136889126 | validation: 0.5274236357047272]
	TIME [epoch: 5.99 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37462960555242886		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.37462960555242886 | validation: 0.4249136703006432]
	TIME [epoch: 5.99 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33299870054508796		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.33299870054508796 | validation: 0.2744551076044348]
	TIME [epoch: 5.98 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3386879919790193		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.3386879919790193 | validation: 0.247726617034213]
	TIME [epoch: 5.98 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27822137764401117		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.27822137764401117 | validation: 0.236715312768332]
	TIME [epoch: 5.99 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2654460800628085		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.2654460800628085 | validation: 0.17705904329760336]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32966546021761295		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.32966546021761295 | validation: 0.36340724759469756]
	TIME [epoch: 6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264132981230511		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.264132981230511 | validation: 0.34039173310871923]
	TIME [epoch: 5.99 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35003701061207915		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.35003701061207915 | validation: 0.3048886088494236]
	TIME [epoch: 5.98 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2993273267470729		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.2993273267470729 | validation: 0.21666482844092305]
	TIME [epoch: 5.98 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27034358719685836		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.27034358719685836 | validation: 0.35492293312280004]
	TIME [epoch: 5.99 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32552560806618147		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.32552560806618147 | validation: 0.20505303047340903]
	TIME [epoch: 5.99 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25683633716243726		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.25683633716243726 | validation: 0.35722600836430474]
	TIME [epoch: 5.98 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2959134436699419		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.2959134436699419 | validation: 0.1951992394414342]
	TIME [epoch: 5.98 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263066004775302		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.263066004775302 | validation: 0.2090028170191496]
	TIME [epoch: 5.99 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3216454501840104		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.3216454501840104 | validation: 0.3418665378852507]
	TIME [epoch: 5.99 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27102176970217556		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.27102176970217556 | validation: 0.18617821739701831]
	TIME [epoch: 5.99 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891142773548076		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.2891142773548076 | validation: 0.16386541929461362]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20182953418079447		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.20182953418079447 | validation: 0.5181429864486831]
	TIME [epoch: 5.99 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338694091847118		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.3338694091847118 | validation: 0.33038947224306936]
	TIME [epoch: 436 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2850662525521488		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.2850662525521488 | validation: 0.2699035590047453]
	TIME [epoch: 11.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23004225379518362		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.23004225379518362 | validation: 0.2693531547641226]
	TIME [epoch: 11.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22988730313877903		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.22988730313877903 | validation: 0.2966632339617223]
	TIME [epoch: 11.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34524851519970085		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.34524851519970085 | validation: 0.2517722983353585]
	TIME [epoch: 11.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24485752689183132		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.24485752689183132 | validation: 0.20657816776315702]
	TIME [epoch: 11.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19582036587237156		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.19582036587237156 | validation: 0.25224717956075937]
	TIME [epoch: 11.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3316194118198085		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.3316194118198085 | validation: 0.25897325435042556]
	TIME [epoch: 11.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22343025783983558		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.22343025783983558 | validation: 0.21793434371425527]
	TIME [epoch: 11.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3220506441674373		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.3220506441674373 | validation: 0.25200545012763687]
	TIME [epoch: 11.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22375769370410895		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.22375769370410895 | validation: 0.19296046487895901]
	TIME [epoch: 11.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647007864466483		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.2647007864466483 | validation: 0.16441151474381227]
	TIME [epoch: 11.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21931743110437096		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.21931743110437096 | validation: 0.3225363995191549]
	TIME [epoch: 11.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25968659217076706		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.25968659217076706 | validation: 0.33948009084673875]
	TIME [epoch: 11.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25164439741740213		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.25164439741740213 | validation: 0.1874616544092003]
	TIME [epoch: 11.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29159131968800417		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.29159131968800417 | validation: 0.2426250525773022]
	TIME [epoch: 11.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22085224385901436		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.22085224385901436 | validation: 0.24786306950981238]
	TIME [epoch: 11.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25978912443197527		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.25978912443197527 | validation: 0.3028819538222266]
	TIME [epoch: 11.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21682542137310964		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.21682542137310964 | validation: 0.30806068991240254]
	TIME [epoch: 11.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588836241576052		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.2588836241576052 | validation: 0.3000089310761914]
	TIME [epoch: 11.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2106171045277125		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.2106171045277125 | validation: 0.17004103930304684]
	TIME [epoch: 11.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560118316384224		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.2560118316384224 | validation: 0.2687807998496589]
	TIME [epoch: 11.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24521521881423952		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.24521521881423952 | validation: 0.1995353235060084]
	TIME [epoch: 11.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19093958696475508		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.19093958696475508 | validation: 0.23583107869706627]
	TIME [epoch: 11.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30294510592078344		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.30294510592078344 | validation: 0.16618372616092336]
	TIME [epoch: 11.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20191465774474876		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.20191465774474876 | validation: 0.22509789661341195]
	TIME [epoch: 12.1 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799629672832661		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.2799629672832661 | validation: 0.3376443764514774]
	TIME [epoch: 11.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2348478672630133		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2348478672630133 | validation: 0.21930394088658633]
	TIME [epoch: 11.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2222963526834732		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.2222963526834732 | validation: 0.2657466587346345]
	TIME [epoch: 11.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24687414831002424		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.24687414831002424 | validation: 0.1663762005157225]
	TIME [epoch: 11.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18960893983341046		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.18960893983341046 | validation: 0.1653713080183173]
	TIME [epoch: 11.8 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23620984989030064		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.23620984989030064 | validation: 0.3694404167036537]
	TIME [epoch: 11.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.223425921475317		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.223425921475317 | validation: 0.20712658281431404]
	TIME [epoch: 11.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23140916099244585		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.23140916099244585 | validation: 0.29909753683433676]
	TIME [epoch: 11.8 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2212733506551317		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2212733506551317 | validation: 0.1570060587691962]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19659191252895608		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.19659191252895608 | validation: 0.2555132856507235]
	TIME [epoch: 11.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25191386126517856		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.25191386126517856 | validation: 0.3642749227271392]
	TIME [epoch: 11.8 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23230653235099455		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.23230653235099455 | validation: 0.2596470821288921]
	TIME [epoch: 11.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22241015162836425		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.22241015162836425 | validation: 0.27514242931199845]
	TIME [epoch: 11.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20267211821242168		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.20267211821242168 | validation: 0.23433877037511264]
	TIME [epoch: 11.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24032323569482164		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.24032323569482164 | validation: 0.21570691222098057]
	TIME [epoch: 11.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17007406619211926		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.17007406619211926 | validation: 0.22344508642837346]
	TIME [epoch: 11.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2388236812822505		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.2388236812822505 | validation: 0.26654485873785916]
	TIME [epoch: 11.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23151012422037007		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.23151012422037007 | validation: 0.213019339812926]
	TIME [epoch: 11.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2138762493604881		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.2138762493604881 | validation: 0.2786844017806122]
	TIME [epoch: 11.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20375035084179952		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.20375035084179952 | validation: 0.17907377297716293]
	TIME [epoch: 11.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20652556198432687		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.20652556198432687 | validation: 0.1209886241165372]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2361408822836496		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.2361408822836496 | validation: 0.13720044714385515]
	TIME [epoch: 11.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22015136766141505		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.22015136766141505 | validation: 0.18620340796274748]
	TIME [epoch: 11.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18893073318860854		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.18893073318860854 | validation: 0.20088408418904957]
	TIME [epoch: 11.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18299870075289978		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.18299870075289978 | validation: 0.24322438835683804]
	TIME [epoch: 11.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23226863207238185		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.23226863207238185 | validation: 0.17931137167429284]
	TIME [epoch: 11.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18070764236778042		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.18070764236778042 | validation: 0.2156186157730548]
	TIME [epoch: 11.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23899632305954238		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.23899632305954238 | validation: 0.20323172611043933]
	TIME [epoch: 11.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18640724832359348		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.18640724832359348 | validation: 0.30187705222989863]
	TIME [epoch: 11.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22155248522794607		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.22155248522794607 | validation: 0.21571310513508024]
	TIME [epoch: 11.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874128445341697		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.1874128445341697 | validation: 0.15135536872468186]
	TIME [epoch: 11.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22786254978992904		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.22786254978992904 | validation: 0.1442151959522397]
	TIME [epoch: 11.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19245251942441233		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.19245251942441233 | validation: 0.15164952126541276]
	TIME [epoch: 11.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17672537980661526		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.17672537980661526 | validation: 0.23073414278758547]
	TIME [epoch: 11.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21453900619185107		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.21453900619185107 | validation: 0.13153417214762606]
	TIME [epoch: 11.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19415395664151291		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.19415395664151291 | validation: 0.16875225157875992]
	TIME [epoch: 11.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018850398818577		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.2018850398818577 | validation: 0.10886377893753718]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14960280777055662		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.14960280777055662 | validation: 0.22590693281859187]
	TIME [epoch: 11.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523345454679682		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.2523345454679682 | validation: 0.20126771804422028]
	TIME [epoch: 11.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17377059684387372		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.17377059684387372 | validation: 0.17417570483771472]
	TIME [epoch: 11.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1989760764103205		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.1989760764103205 | validation: 0.35302462096094567]
	TIME [epoch: 11.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21498346143961689		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.21498346143961689 | validation: 0.17330391719678373]
	TIME [epoch: 11.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18140470302751338		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.18140470302751338 | validation: 0.17691069762697492]
	TIME [epoch: 11.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21217766225938428		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.21217766225938428 | validation: 0.176853731460978]
	TIME [epoch: 11.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19135971054425394		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.19135971054425394 | validation: 0.16571555617705963]
	TIME [epoch: 11.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570116396009409		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.1570116396009409 | validation: 0.31768244044524385]
	TIME [epoch: 11.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23089586975704096		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.23089586975704096 | validation: 0.1844191541812148]
	TIME [epoch: 11.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851977950371263		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.18851977950371263 | validation: 0.155540923509295]
	TIME [epoch: 11.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18033346269925501		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.18033346269925501 | validation: 0.13029969645343553]
	TIME [epoch: 11.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17357310040265544		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.17357310040265544 | validation: 0.1299374206908976]
	TIME [epoch: 11.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18849640181939822		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.18849640181939822 | validation: 0.16896714828552328]
	TIME [epoch: 11.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485559671768663		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.1485559671768663 | validation: 0.1665999707369651]
	TIME [epoch: 11.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718963608724185		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.1718963608724185 | validation: 0.1283193850042732]
	TIME [epoch: 11.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19525871119593555		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.19525871119593555 | validation: 0.1342577516877327]
	TIME [epoch: 11.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14667497398868354		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.14667497398868354 | validation: 0.13780666508180783]
	TIME [epoch: 11.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20016263342909807		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.20016263342909807 | validation: 0.12298132337890161]
	TIME [epoch: 11.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14253745663662137		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.14253745663662137 | validation: 0.19741816835745776]
	TIME [epoch: 11.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17841882262363676		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.17841882262363676 | validation: 0.2618778072962963]
	TIME [epoch: 11.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909527747333932		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.1909527747333932 | validation: 0.14253108425257782]
	TIME [epoch: 11.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13609180688210787		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.13609180688210787 | validation: 0.12007572018950118]
	TIME [epoch: 11.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15358331847105652		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.15358331847105652 | validation: 0.25544311803490644]
	TIME [epoch: 11.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19860237604345232		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.19860237604345232 | validation: 0.1365973807600867]
	TIME [epoch: 11.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15970645246841025		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.15970645246841025 | validation: 0.21545203594362744]
	TIME [epoch: 11.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172119957423208		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.172119957423208 | validation: 0.15967894954232004]
	TIME [epoch: 11.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456453775257723		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.13456453775257723 | validation: 0.18967374988093863]
	TIME [epoch: 11.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16100445286649348		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.16100445286649348 | validation: 0.15570772015577652]
	TIME [epoch: 11.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16573793221580227		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.16573793221580227 | validation: 0.21315452903966453]
	TIME [epoch: 11.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1949220553909567		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.1949220553909567 | validation: 0.12302133653396022]
	TIME [epoch: 11.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14861606376757697		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.14861606376757697 | validation: 0.13314576508126333]
	TIME [epoch: 11.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11805508857655554		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.11805508857655554 | validation: 0.14065362216317379]
	TIME [epoch: 11.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23648316717367182		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.23648316717367182 | validation: 0.1228359565014183]
	TIME [epoch: 11.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16523543003195543		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.16523543003195543 | validation: 0.14305098753426845]
	TIME [epoch: 11.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424711451095158		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.1424711451095158 | validation: 0.1194852582574716]
	TIME [epoch: 11.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1376626244534613		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.1376626244534613 | validation: 0.15179413486768709]
	TIME [epoch: 11.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21380196388967582		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.21380196388967582 | validation: 0.10756467860065229]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17057072961139308		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.17057072961139308 | validation: 0.10131422438969695]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09176435079730132		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.09176435079730132 | validation: 0.08920687742852795]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15141237031851895		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.15141237031851895 | validation: 0.2981062875282993]
	TIME [epoch: 11.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899668888776104		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.1899668888776104 | validation: 0.15571120926771223]
	TIME [epoch: 11.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455163511807413		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.12455163511807413 | validation: 0.10229777974996868]
	TIME [epoch: 11.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14326028689875203		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.14326028689875203 | validation: 0.09105163592867219]
	TIME [epoch: 11.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115636524295843		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.19115636524295843 | validation: 0.11149532655054908]
	TIME [epoch: 11.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13994918885898133		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.13994918885898133 | validation: 0.1751232833256252]
	TIME [epoch: 11.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522015037343057		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.12522015037343057 | validation: 0.1307852361663117]
	TIME [epoch: 11.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17040827141631162		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.17040827141631162 | validation: 0.15698338425545075]
	TIME [epoch: 11.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17176747505341416		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.17176747505341416 | validation: 0.1927768758105371]
	TIME [epoch: 11.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12350524750231201		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.12350524750231201 | validation: 0.14495699411417867]
	TIME [epoch: 11.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439811007209659		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.1439811007209659 | validation: 0.09271368580937389]
	TIME [epoch: 11.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2275981852266512		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.2275981852266512 | validation: 0.09609412078656632]
	TIME [epoch: 11.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13780896591511077		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.13780896591511077 | validation: 0.1518573226342146]
	TIME [epoch: 11.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169494782890237		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.16169494782890237 | validation: 0.11907761788969795]
	TIME [epoch: 11.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11982341989824166		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.11982341989824166 | validation: 0.1432427787668991]
	TIME [epoch: 11.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15370120217794422		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.15370120217794422 | validation: 0.10429656660302203]
	TIME [epoch: 11.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13247036139733323		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.13247036139733323 | validation: 0.11255832526390708]
	TIME [epoch: 11.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14370651479379776		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.14370651479379776 | validation: 0.07739002966499639]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619305009964552		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.11619305009964552 | validation: 0.08280208431176136]
	TIME [epoch: 11.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748342411091376		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.07748342411091376 | validation: 0.15230541573320108]
	TIME [epoch: 11.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16963210025382497		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.16963210025382497 | validation: 0.5913145954271652]
	TIME [epoch: 11.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851488012351565		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.2851488012351565 | validation: 0.10469848286964518]
	TIME [epoch: 11.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12624285981225983		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.12624285981225983 | validation: 0.10389798225987884]
	TIME [epoch: 11.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1731572126512398		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.1731572126512398 | validation: 0.106582816938635]
	TIME [epoch: 11.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10492790519447352		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.10492790519447352 | validation: 0.09967631936166335]
	TIME [epoch: 11.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274003769297922		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.1274003769297922 | validation: 0.17443178819361965]
	TIME [epoch: 11.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974871950531767		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.10974871950531767 | validation: 0.19219835781740363]
	TIME [epoch: 11.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14048687448036332		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.14048687448036332 | validation: 0.1223490784040539]
	TIME [epoch: 11.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12985719983838978		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.12985719983838978 | validation: 0.17317864652193946]
	TIME [epoch: 11.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17203287805745915		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.17203287805745915 | validation: 0.08794248633923482]
	TIME [epoch: 11.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12733757079431215		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.12733757079431215 | validation: 0.09467920973430674]
	TIME [epoch: 11.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087846761619871		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.1087846761619871 | validation: 0.33028520829368374]
	TIME [epoch: 11.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19753051091443755		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.19753051091443755 | validation: 0.13356010272593222]
	TIME [epoch: 11.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12413139210578096		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.12413139210578096 | validation: 0.0789161522890531]
	TIME [epoch: 11.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869431664481982		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.0869431664481982 | validation: 0.16227273983130985]
	TIME [epoch: 11.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18040477702454985		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.18040477702454985 | validation: 0.10229282151314449]
	TIME [epoch: 11.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09330255368269293		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.09330255368269293 | validation: 0.1153085904793365]
	TIME [epoch: 11.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09296035173508452		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.09296035173508452 | validation: 0.21499760270302543]
	TIME [epoch: 11.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21781214028400842		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.21781214028400842 | validation: 0.12963401667715707]
	TIME [epoch: 11.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09621812159018789		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.09621812159018789 | validation: 0.11306426255495591]
	TIME [epoch: 11.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13978032737299756		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.13978032737299756 | validation: 0.09335781300779261]
	TIME [epoch: 11.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11095111691178706		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.11095111691178706 | validation: 0.1588249162235092]
	TIME [epoch: 11.8 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12455989475295148		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.12455989475295148 | validation: 0.13050626362802514]
	TIME [epoch: 11.8 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257926929590727		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.13257926929590727 | validation: 0.07811646118214027]
	TIME [epoch: 11.8 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091031510124735		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.1091031510124735 | validation: 0.06844291358094823]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942913838064088		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.09942913838064088 | validation: 0.1843995288563255]
	TIME [epoch: 11.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15415226186936123		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.15415226186936123 | validation: 0.10143253798889212]
	TIME [epoch: 11.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979543359793186		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.0979543359793186 | validation: 0.2229796121007646]
	TIME [epoch: 11.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13342177447023199		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.13342177447023199 | validation: 0.1272977462299678]
	TIME [epoch: 11.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1453594334435924		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.1453594334435924 | validation: 0.08704030830086759]
	TIME [epoch: 11.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09195192014309293		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.09195192014309293 | validation: 0.08464746488563918]
	TIME [epoch: 11.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16481014663883603		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.16481014663883603 | validation: 0.13894322364792486]
	TIME [epoch: 11.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13847495912544655		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.13847495912544655 | validation: 0.09494713346639715]
	TIME [epoch: 11.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15724884988968718		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.15724884988968718 | validation: 0.11637672237377261]
	TIME [epoch: 11.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832869352106206		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.10832869352106206 | validation: 0.12702746890320704]
	TIME [epoch: 11.8 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546209894745087		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.1546209894745087 | validation: 0.152940465880874]
	TIME [epoch: 11.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07594563659777298		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.07594563659777298 | validation: 0.05764949571985475]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10030127345898471		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.10030127345898471 | validation: 0.20749186892977253]
	TIME [epoch: 11.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17284731357822064		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.17284731357822064 | validation: 0.09116218478346445]
	TIME [epoch: 11.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07724738955069949		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.07724738955069949 | validation: 0.09537558551727925]
	TIME [epoch: 11.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12271156679830185		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.12271156679830185 | validation: 0.10038609155803069]
	TIME [epoch: 11.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0954835461960923		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.0954835461960923 | validation: 0.11380199236485986]
	TIME [epoch: 11.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1024068294422398		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.1024068294422398 | validation: 0.17486416629804008]
	TIME [epoch: 11.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15850716932147446		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.15850716932147446 | validation: 0.08525413196097598]
	TIME [epoch: 11.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07357982242922712		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.07357982242922712 | validation: 0.13861572839225944]
	TIME [epoch: 11.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10426933872369759		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.10426933872369759 | validation: 0.14645696797373042]
	TIME [epoch: 11.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468206748546361		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.12468206748546361 | validation: 0.1748374136539274]
	TIME [epoch: 11.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08278462351225642		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.08278462351225642 | validation: 0.11229029536025997]
	TIME [epoch: 11.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.123715565371077		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.123715565371077 | validation: 0.06587034147115992]
	TIME [epoch: 11.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09232556865145838		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.09232556865145838 | validation: 0.08874043433651904]
	TIME [epoch: 11.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07637426575279704		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.07637426575279704 | validation: 0.29673257607433834]
	TIME [epoch: 11.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11893724822277119		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.11893724822277119 | validation: 0.12035359858699274]
	TIME [epoch: 11.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13814895051389467		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.13814895051389467 | validation: 0.06168073366907221]
	TIME [epoch: 11.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269347117661474		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.08269347117661474 | validation: 0.15825861817370956]
	TIME [epoch: 11.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1120835496969454		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.1120835496969454 | validation: 0.09068931675505097]
	TIME [epoch: 11.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414445904086288		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.06414445904086288 | validation: 0.11055332644808005]
	TIME [epoch: 11.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14429858824602698		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.14429858824602698 | validation: 0.17583037711302163]
	TIME [epoch: 11.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09491682979543557		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.09491682979543557 | validation: 0.08386079011585054]
	TIME [epoch: 11.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092443649744265		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.092443649744265 | validation: 0.07977167205586766]
	TIME [epoch: 11.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305126470211129		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.10305126470211129 | validation: 0.05724300116657642]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027072091173771		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.09027072091173771 | validation: 0.13229681580741812]
	TIME [epoch: 11.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.138675129821564		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.138675129821564 | validation: 0.06405969128858405]
	TIME [epoch: 11.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09177915069145556		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.09177915069145556 | validation: 0.06023302618132444]
	TIME [epoch: 11.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07583094608719922		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.07583094608719922 | validation: 0.1212899061192133]
	TIME [epoch: 11.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13012988209645285		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.13012988209645285 | validation: 0.07368146069645998]
	TIME [epoch: 11.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09861507149999803		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.09861507149999803 | validation: 0.09078120959410106]
	TIME [epoch: 11.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08357554353978591		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.08357554353978591 | validation: 0.06470102330497612]
	TIME [epoch: 11.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08086597567251885		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.08086597567251885 | validation: 0.07621031370435694]
	TIME [epoch: 11.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07781730205872893		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.07781730205872893 | validation: 0.1080527256449301]
	TIME [epoch: 11.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09547959124683142		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.09547959124683142 | validation: 0.10453423702247458]
	TIME [epoch: 11.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07090859309358805		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.07090859309358805 | validation: 0.19908242362236378]
	TIME [epoch: 11.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17040948445925555		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.17040948445925555 | validation: 0.10777539789396698]
	TIME [epoch: 11.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06722940725781501		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.06722940725781501 | validation: 0.0997405374768146]
	TIME [epoch: 11.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08054792511842714		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.08054792511842714 | validation: 0.06478771372854425]
	TIME [epoch: 11.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12298077071896465		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.12298077071896465 | validation: 0.09463793827996524]
	TIME [epoch: 11.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08469065876062992		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.08469065876062992 | validation: 0.06478944561518836]
	TIME [epoch: 11.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051660497963715316		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.051660497963715316 | validation: 0.06874925018307232]
	TIME [epoch: 11.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09227079483331356		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.09227079483331356 | validation: 0.13873312799696594]
	TIME [epoch: 11.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307148310963704		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.1307148310963704 | validation: 0.06886369789384254]
	TIME [epoch: 11.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305150598752707		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.06305150598752707 | validation: 0.05004320111828786]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11877015428988585		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.11877015428988585 | validation: 0.09892056819422176]
	TIME [epoch: 11.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07741979657121419		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.07741979657121419 | validation: 0.21962080091086322]
	TIME [epoch: 11.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219809690802254		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.1219809690802254 | validation: 0.06565662636560754]
	TIME [epoch: 11.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07054276022630514		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.07054276022630514 | validation: 0.12321444038130869]
	TIME [epoch: 11.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969339127822352		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.06969339127822352 | validation: 0.12876469377758848]
	TIME [epoch: 11.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0735682941177852		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.0735682941177852 | validation: 0.05148452679185003]
	TIME [epoch: 11.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08047158083819059		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.08047158083819059 | validation: 0.11317775130186691]
	TIME [epoch: 11.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714831814549385		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.07714831814549385 | validation: 0.11653742330894637]
	TIME [epoch: 11.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09615085017423584		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.09615085017423584 | validation: 0.06059609629312594]
	TIME [epoch: 11.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06793761850881387		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.06793761850881387 | validation: 0.04148788240051074]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_413.pth
	Model improved!!!
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08312927109132692		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.08312927109132692 | validation: 0.11236275830341796]
	TIME [epoch: 11.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08748197959798784		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.08748197959798784 | validation: 0.0988568995001002]
	TIME [epoch: 11.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04987885423867108		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.04987885423867108 | validation: 0.09512108806348255]
	TIME [epoch: 11.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11530891112472723		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.11530891112472723 | validation: 0.10656123788622168]
	TIME [epoch: 11.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07206178220094968		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.07206178220094968 | validation: 0.11423821553290098]
	TIME [epoch: 11.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09133104384035709		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.09133104384035709 | validation: 0.10123359600612415]
	TIME [epoch: 11.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863012053898145		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.0863012053898145 | validation: 0.07404482058288392]
	TIME [epoch: 11.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512194644710575		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.05512194644710575 | validation: 0.09922245407978841]
	TIME [epoch: 11.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06739577699371967		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.06739577699371967 | validation: 0.037584673683260475]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14565067204673401		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.14565067204673401 | validation: 0.1357061070603106]
	TIME [epoch: 11.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839598399119289		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.0839598399119289 | validation: 0.04867821434173143]
	TIME [epoch: 11.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07047236265446001		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.07047236265446001 | validation: 0.09495082546171135]
	TIME [epoch: 11.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486793569983309		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.0486793569983309 | validation: 0.050178602122586013]
	TIME [epoch: 11.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09096899749556993		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.09096899749556993 | validation: 0.040049375368540224]
	TIME [epoch: 11.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08307754399539818		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.08307754399539818 | validation: 0.06551270667237151]
	TIME [epoch: 11.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049513649480018074		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.049513649480018074 | validation: 0.08389528363789409]
	TIME [epoch: 11.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07930597818106408		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.07930597818106408 | validation: 0.0515726632635081]
	TIME [epoch: 11.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05712554779069476		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.05712554779069476 | validation: 0.13526216552872927]
	TIME [epoch: 11.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08507592126410679		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.08507592126410679 | validation: 0.047797379340083955]
	TIME [epoch: 11.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050301551036077516		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.050301551036077516 | validation: 0.09123635383096283]
	TIME [epoch: 11.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11959937785314086		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.11959937785314086 | validation: 0.08232211456155447]
	TIME [epoch: 11.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07271916365022564		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.07271916365022564 | validation: 0.03504578316676844]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656070087141789		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.04656070087141789 | validation: 0.08510680727214043]
	TIME [epoch: 11.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213492973625888		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.05213492973625888 | validation: 0.041133069565829294]
	TIME [epoch: 11.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0916917089892009		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.0916917089892009 | validation: 0.128360624271256]
	TIME [epoch: 11.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08533589101194966		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.08533589101194966 | validation: 0.04296690418574819]
	TIME [epoch: 11.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058398354493847476		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.058398354493847476 | validation: 0.0960741729448473]
	TIME [epoch: 11.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05654914142797905		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.05654914142797905 | validation: 0.03071551086064802]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05703990493056482		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.05703990493056482 | validation: 0.2322957729688389]
	TIME [epoch: 11.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11479715385597392		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.11479715385597392 | validation: 0.047872963384703794]
	TIME [epoch: 11.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037690727318600195		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.037690727318600195 | validation: 0.05773891275091277]
	TIME [epoch: 11.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470815752711606		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.05470815752711606 | validation: 0.0377537321651997]
	TIME [epoch: 11.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111890697953843		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.08111890697953843 | validation: 0.17079175305776542]
	TIME [epoch: 11.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08298005441722303		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.08298005441722303 | validation: 0.04835528053214995]
	TIME [epoch: 11.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04817299184275859		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.04817299184275859 | validation: 0.03379678007846643]
	TIME [epoch: 11.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390239453555125		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.04390239453555125 | validation: 0.13079260974791754]
	TIME [epoch: 11.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262493032832495		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.06262493032832495 | validation: 0.058061805222943505]
	TIME [epoch: 11.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.089116628744424		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.089116628744424 | validation: 0.09823145221011287]
	TIME [epoch: 11.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368980780756964		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.05368980780756964 | validation: 0.09493593735170112]
	TIME [epoch: 11.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07216077631062173		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.07216077631062173 | validation: 0.08975365219090667]
	TIME [epoch: 11.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602701857197927		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.07602701857197927 | validation: 0.08013993629014353]
	TIME [epoch: 11.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04843493252855331		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04843493252855331 | validation: 0.037320785156568156]
	TIME [epoch: 11.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08833724927576302		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.08833724927576302 | validation: 0.0418154518928684]
	TIME [epoch: 11.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0448878345098288		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.0448878345098288 | validation: 0.10052267701904466]
	TIME [epoch: 11.8 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981502872670321		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.07981502872670321 | validation: 0.20261670730918174]
	TIME [epoch: 11.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08496431321707211		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.08496431321707211 | validation: 0.04596414059292811]
	TIME [epoch: 11.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648226456662614		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.04648226456662614 | validation: 0.03180652715094078]
	TIME [epoch: 11.8 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03153465829417467		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.03153465829417467 | validation: 0.06991565337410102]
	TIME [epoch: 11.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994752503358976		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.0994752503358976 | validation: 0.050131235882936706]
	TIME [epoch: 11.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701017571279318		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.04701017571279318 | validation: 0.1575758009139931]
	TIME [epoch: 11.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06520876597104648		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.06520876597104648 | validation: 0.040043571222371246]
	TIME [epoch: 11.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345507145824029		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.04345507145824029 | validation: 0.10938023393412621]
	TIME [epoch: 11.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09094991456090352		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.09094991456090352 | validation: 0.04034687285244426]
	TIME [epoch: 11.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963288395511373		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.06963288395511373 | validation: 0.07172379224301872]
	TIME [epoch: 11.8 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06826003505368738		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.06826003505368738 | validation: 0.09775583073729409]
	TIME [epoch: 11.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06954022735251021		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.06954022735251021 | validation: 0.08148400356456192]
	TIME [epoch: 11.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03718449548551377		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.03718449548551377 | validation: 0.041790172842299106]
	TIME [epoch: 11.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05568312509411005		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.05568312509411005 | validation: 0.03447612637049747]
	TIME [epoch: 11.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03299846980628494		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.03299846980628494 | validation: 0.07433208015912728]
	TIME [epoch: 11.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0634257625971612		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.0634257625971612 | validation: 0.056460654698866686]
	TIME [epoch: 11.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08118795116817615		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.08118795116817615 | validation: 0.03436980787326553]
	TIME [epoch: 11.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064366742658294		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.08064366742658294 | validation: 0.0438121613157971]
	TIME [epoch: 11.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320110766745202		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.05320110766745202 | validation: 0.04842388615575968]
	TIME [epoch: 11.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039932729280923784		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.039932729280923784 | validation: 0.05761986274090242]
	TIME [epoch: 11.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049483634814378286		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.049483634814378286 | validation: 0.07850238848662731]
	TIME [epoch: 11.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07982670465759059		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.07982670465759059 | validation: 0.09916831373207899]
	TIME [epoch: 11.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646176910940865		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.0646176910940865 | validation: 0.05144381329158629]
	TIME [epoch: 11.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399041712420812		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.05399041712420812 | validation: 0.034941192121600184]
	TIME [epoch: 11.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099869724011574		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.03099869724011574 | validation: 0.04762365788471824]
	TIME [epoch: 11.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11600985262554425		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.11600985262554425 | validation: 0.10930993910564568]
	TIME [epoch: 11.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432012889946616		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.05432012889946616 | validation: 0.02882723766901664]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446483228058547		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.04446483228058547 | validation: 0.05304151569768198]
	TIME [epoch: 11.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034188689320646955		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.034188689320646955 | validation: 0.03375041634496286]
	TIME [epoch: 11.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06587970794221067		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.06587970794221067 | validation: 0.13924181576469713]
	TIME [epoch: 11.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985787735559063		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.07985787735559063 | validation: 0.024523455184741798]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_488.pth
	Model improved!!!
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03387736864124051		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.03387736864124051 | validation: 0.03393882028535025]
	TIME [epoch: 11.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02769539943868317		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.02769539943868317 | validation: 0.10982606795968936]
	TIME [epoch: 11.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753867323097372		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.08753867323097372 | validation: 0.033371098070844374]
	TIME [epoch: 11.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03634329006899835		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.03634329006899835 | validation: 0.04972205977922825]
	TIME [epoch: 11.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414195264299287		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.0414195264299287 | validation: 0.0676592968127844]
	TIME [epoch: 11.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06376637489397018		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.06376637489397018 | validation: 0.02694857946740971]
	TIME [epoch: 11.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02676943404210962		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.02676943404210962 | validation: 0.038669064964864955]
	TIME [epoch: 11.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04876463173904202		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.04876463173904202 | validation: 0.028958205190679927]
	TIME [epoch: 11.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13053199771201424		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.13053199771201424 | validation: 0.11536104134274003]
	TIME [epoch: 11.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05141161630781041		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.05141161630781041 | validation: 0.027250805795959523]
	TIME [epoch: 11.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02625781201253619		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.02625781201253619 | validation: 0.028534367135865435]
	TIME [epoch: 11.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02568376951663825		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.02568376951663825 | validation: 0.03240615253391976]
	TIME [epoch: 11.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05226020134292727		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.05226020134292727 | validation: 0.11948495388194302]
	TIME [epoch: 456 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06027537331239741		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.06027537331239741 | validation: 0.08657530435414726]
	TIME [epoch: 25.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038590793348535386		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.038590793348535386 | validation: 0.039046595144643266]
	TIME [epoch: 25.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05857004208682409		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.05857004208682409 | validation: 0.034546155271864096]
	TIME [epoch: 25.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04362701525498831		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.04362701525498831 | validation: 0.052317219385737204]
	TIME [epoch: 25.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035482978767611466		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.035482978767611466 | validation: 0.04070449915869611]
	TIME [epoch: 25.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050164128706757474		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.050164128706757474 | validation: 0.08502609181657494]
	TIME [epoch: 25.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04599447362593528		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.04599447362593528 | validation: 0.058497774595685406]
	TIME [epoch: 25.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297352053371928		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.07297352053371928 | validation: 0.03831328280068107]
	TIME [epoch: 25.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022753986167776182		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.022753986167776182 | validation: 0.02517967371450901]
	TIME [epoch: 25.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020727118013218693		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.020727118013218693 | validation: 0.038319173881957734]
	TIME [epoch: 25.5 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0864111300469784		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.0864111300469784 | validation: 0.035630902618759966]
	TIME [epoch: 25.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140736906360663		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.03140736906360663 | validation: 0.043817897688708404]
	TIME [epoch: 25.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0330772227155572		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.0330772227155572 | validation: 0.03848016766534601]
	TIME [epoch: 25.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05709441255661585		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.05709441255661585 | validation: 0.04975605954088579]
	TIME [epoch: 25.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037762969152780296		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.037762969152780296 | validation: 0.03000246660166416]
	TIME [epoch: 25.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678763891780248		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.04678763891780248 | validation: 0.07627203616280008]
	TIME [epoch: 25.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057365759318567286		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.057365759318567286 | validation: 0.033975525887498234]
	TIME [epoch: 25.5 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02891344241301769		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.02891344241301769 | validation: 0.04300065929274216]
	TIME [epoch: 25.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08747267660091573		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.08747267660091573 | validation: 0.05663171796281878]
	TIME [epoch: 25.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033368474518252936		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.033368474518252936 | validation: 0.024135393869490925]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664734976067181		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.03664734976067181 | validation: 0.03357448210495058]
	TIME [epoch: 25.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03703199267463013		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.03703199267463013 | validation: 0.10856814882627501]
	TIME [epoch: 25.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07256916447981862		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.07256916447981862 | validation: 0.039718711882860115]
	TIME [epoch: 25.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565986843826865		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.03565986843826865 | validation: 0.037444943955015075]
	TIME [epoch: 25.5 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030303391394752643		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.030303391394752643 | validation: 0.03443095838975957]
	TIME [epoch: 25.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029304512506765037		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.029304512506765037 | validation: 0.05137643341921984]
	TIME [epoch: 25.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809734359331126		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.0809734359331126 | validation: 0.0531601357018571]
	TIME [epoch: 25.5 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039274767266368485		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.039274767266368485 | validation: 0.03344923150684865]
	TIME [epoch: 25.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032775411043959785		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.032775411043959785 | validation: 0.0287594601076222]
	TIME [epoch: 25.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043458755547148606		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.043458755547148606 | validation: 0.031791375268754814]
	TIME [epoch: 25.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040251920341105585		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.040251920341105585 | validation: 0.07824188020583797]
	TIME [epoch: 25.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04386167528568968		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.04386167528568968 | validation: 0.02275823935601054]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020540502081348232		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.020540502081348232 | validation: 0.036443890315797596]
	TIME [epoch: 25.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512913355732087		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.08512913355732087 | validation: 0.05281080251376423]
	TIME [epoch: 25.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036210839271327865		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.036210839271327865 | validation: 0.02311549134191423]
	TIME [epoch: 25.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018783549265041864		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.018783549265041864 | validation: 0.03141135024132871]
	TIME [epoch: 25.5 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04082550093300946		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.04082550093300946 | validation: 0.03253123344610165]
	TIME [epoch: 25.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028983875749526735		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.028983875749526735 | validation: 0.0645396343159817]
	TIME [epoch: 25.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283377522712028		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.05283377522712028 | validation: 0.023918395907093097]
	TIME [epoch: 25.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021277813327118894		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.021277813327118894 | validation: 0.04879621340543544]
	TIME [epoch: 25.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047036286861657436		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.047036286861657436 | validation: 0.05843834132801962]
	TIME [epoch: 25.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560534431081877		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.03560534431081877 | validation: 0.027113278302762844]
	TIME [epoch: 25.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02828812123723757		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.02828812123723757 | validation: 0.059561127371493126]
	TIME [epoch: 25.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112506155864071		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.04112506155864071 | validation: 0.0333572932289455]
	TIME [epoch: 25.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340692317269921		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.0340692317269921 | validation: 0.038950717251630615]
	TIME [epoch: 25.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333007101994374		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.0333007101994374 | validation: 0.062397441136746876]
	TIME [epoch: 25.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05420352179790318		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.05420352179790318 | validation: 0.047878022825637134]
	TIME [epoch: 25.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901448220782735		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.06901448220782735 | validation: 0.053206466541360076]
	TIME [epoch: 25.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029119216509985665		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.029119216509985665 | validation: 0.02815973750928282]
	TIME [epoch: 25.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466262339255943		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.02466262339255943 | validation: 0.03469218335699371]
	TIME [epoch: 25.5 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569417944524004		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.03569417944524004 | validation: 0.03799386754367221]
	TIME [epoch: 25.5 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0367236561326856		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.0367236561326856 | validation: 0.019914979309007486]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756085135396228		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.04756085135396228 | validation: 0.029691494619520732]
	TIME [epoch: 25.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033624812812681		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.033624812812681 | validation: 0.02413221318041111]
	TIME [epoch: 25.5 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035868640824978884		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.035868640824978884 | validation: 0.021495913839310075]
	TIME [epoch: 25.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0441832330343382		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.0441832330343382 | validation: 0.03670214326889961]
	TIME [epoch: 25.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03650897620662519		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.03650897620662519 | validation: 0.02236570282462348]
	TIME [epoch: 25.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023341943194402505		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.023341943194402505 | validation: 0.07307548820576175]
	TIME [epoch: 25.5 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09572897088364289		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.09572897088364289 | validation: 0.032959900866772154]
	TIME [epoch: 25.5 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02202700151785711		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.02202700151785711 | validation: 0.0209325720215018]
	TIME [epoch: 25.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017104574070801		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.017104574070801 | validation: 0.02205010401218249]
	TIME [epoch: 25.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049633644394836834		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.049633644394836834 | validation: 0.026014275002669944]
	TIME [epoch: 25.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033793071974561106		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.033793071974561106 | validation: 0.09014060142511378]
	TIME [epoch: 25.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042490950710932084		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.042490950710932084 | validation: 0.04093407389802875]
	TIME [epoch: 25.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022327942241818867		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.022327942241818867 | validation: 0.02431542589871567]
	TIME [epoch: 25.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033535201026152796		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.033535201026152796 | validation: 0.0252917870702742]
	TIME [epoch: 25.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03771309327976874		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.03771309327976874 | validation: 0.029791560600297445]
	TIME [epoch: 25.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020530756896212546		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.020530756896212546 | validation: 0.04701106479521926]
	TIME [epoch: 25.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0326942203150221		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0326942203150221 | validation: 0.022682641025038752]
	TIME [epoch: 25.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022864234635226337		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.022864234635226337 | validation: 0.05378176239063613]
	TIME [epoch: 25.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059845068721760486		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.059845068721760486 | validation: 0.025713770038777485]
	TIME [epoch: 25.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08067774223400441		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.08067774223400441 | validation: 0.027573221921490535]
	TIME [epoch: 25.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020283081394444413		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.020283081394444413 | validation: 0.021758971905304236]
	TIME [epoch: 25.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014464838743006692		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.014464838743006692 | validation: 0.017727159532465817]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021180214302345537		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.021180214302345537 | validation: 0.039809036181928395]
	TIME [epoch: 25.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059283688562191864		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.059283688562191864 | validation: 0.03483766121191577]
	TIME [epoch: 25.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022535006753134048		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.022535006753134048 | validation: 0.01973076014952297]
	TIME [epoch: 25.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485579427013648		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.03485579427013648 | validation: 0.024200776598032686]
	TIME [epoch: 25.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026209393079426435		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.026209393079426435 | validation: 0.018967937819915303]
	TIME [epoch: 25.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021785580331605943		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.021785580331605943 | validation: 0.03828850634069386]
	TIME [epoch: 25.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02781046384916649		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.02781046384916649 | validation: 0.0383241362881192]
	TIME [epoch: 25.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929190558765534		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.05929190558765534 | validation: 0.03638795534844291]
	TIME [epoch: 25.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029799691420739658		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.029799691420739658 | validation: 0.022961929463684125]
	TIME [epoch: 25.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025290780223507524		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.025290780223507524 | validation: 0.027706364848605128]
	TIME [epoch: 25.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016549922611697323		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.016549922611697323 | validation: 0.021522760079989087]
	TIME [epoch: 25.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030015586151915023		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.030015586151915023 | validation: 0.07571460206193534]
	TIME [epoch: 25.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029078288907077837		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.029078288907077837 | validation: 0.03926459662334915]
	TIME [epoch: 25.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030857014887740036		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.030857014887740036 | validation: 0.056442131949172296]
	TIME [epoch: 25.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04614986829022273		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.04614986829022273 | validation: 0.015842420671213647]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022774691914830274		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.022774691914830274 | validation: 0.039382549827600574]
	TIME [epoch: 25.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02258290549291104		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.02258290549291104 | validation: 0.021098044983874745]
	TIME [epoch: 25.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04732579182295241		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.04732579182295241 | validation: 0.03750534379182678]
	TIME [epoch: 25.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03961012895489426		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.03961012895489426 | validation: 0.021019654596524877]
	TIME [epoch: 25.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017742229044966834		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.017742229044966834 | validation: 0.040625032929870394]
	TIME [epoch: 25.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02708104034575438		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.02708104034575438 | validation: 0.03555049695021]
	TIME [epoch: 25.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02104899415648992		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.02104899415648992 | validation: 0.02120053401733321]
	TIME [epoch: 25.5 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024199878775026277		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.024199878775026277 | validation: 0.08746229473817585]
	TIME [epoch: 25.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055318087534010116		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.055318087534010116 | validation: 0.024660233241665525]
	TIME [epoch: 25.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017551785146111235		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.017551785146111235 | validation: 0.030625497042604685]
	TIME [epoch: 25.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03229970581479312		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.03229970581479312 | validation: 0.02901088342280465]
	TIME [epoch: 25.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019987321746868226		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.019987321746868226 | validation: 0.017515179765702875]
	TIME [epoch: 25.5 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02724916996785063		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.02724916996785063 | validation: 0.06618741156398941]
	TIME [epoch: 25.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0294994411448289		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.0294994411448289 | validation: 0.029419119230422806]
	TIME [epoch: 25.5 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002280445321786		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.04002280445321786 | validation: 0.032158115548597044]
	TIME [epoch: 25.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020358268569708852		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.020358268569708852 | validation: 0.022230739690328703]
	TIME [epoch: 25.5 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025404476188682718		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.025404476188682718 | validation: 0.022776163888181176]
	TIME [epoch: 25.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021783177859593522		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.021783177859593522 | validation: 0.030381418478816993]
	TIME [epoch: 25.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045901650791476706		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.045901650791476706 | validation: 0.01712256441385387]
	TIME [epoch: 25.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017849250022502622		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.017849250022502622 | validation: 0.01691483161774028]
	TIME [epoch: 25.5 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013961845080004719		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.013961845080004719 | validation: 0.04099116882171917]
	TIME [epoch: 25.5 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03550686605240396		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.03550686605240396 | validation: 0.09337258894867206]
	TIME [epoch: 25.5 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03480151913380696		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.03480151913380696 | validation: 0.02361070282819991]
	TIME [epoch: 25.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019172842433852057		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.019172842433852057 | validation: 0.016686195479152087]
	TIME [epoch: 25.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02089665646057222		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.02089665646057222 | validation: 0.0635134787430841]
	TIME [epoch: 25.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049051189786494045		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.049051189786494045 | validation: 0.026865803230108974]
	TIME [epoch: 25.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019412084276940994		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.019412084276940994 | validation: 0.01682511971719282]
	TIME [epoch: 25.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012647761072047289		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.012647761072047289 | validation: 0.016343650931996415]
	TIME [epoch: 25.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02754103532943955		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.02754103532943955 | validation: 0.06806489221345888]
	TIME [epoch: 25.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044180412440791586		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.044180412440791586 | validation: 0.023443408152761046]
	TIME [epoch: 25.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735105284423523		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.01735105284423523 | validation: 0.022039657648644264]
	TIME [epoch: 25.5 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020852193488457633		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.020852193488457633 | validation: 0.03705251870396229]
	TIME [epoch: 25.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032617591438811794		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.032617591438811794 | validation: 0.042635718244047854]
	TIME [epoch: 25.5 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022756474390740012		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.022756474390740012 | validation: 0.01737511431964928]
	TIME [epoch: 25.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01398450107356719		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.01398450107356719 | validation: 0.018978575335944894]
	TIME [epoch: 25.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262507402287704		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.03262507402287704 | validation: 0.08298011483956558]
	TIME [epoch: 25.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048923386864917526		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.048923386864917526 | validation: 0.025937642133233553]
	TIME [epoch: 25.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016860246250909268		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.016860246250909268 | validation: 0.014349363769299319]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013574278549299323		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.013574278549299323 | validation: 0.02181196062569209]
	TIME [epoch: 25.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019386280360179076		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.019386280360179076 | validation: 0.03575501787174269]
	TIME [epoch: 25.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056586835471460456		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.056586835471460456 | validation: 0.029586021345715308]
	TIME [epoch: 25.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018228851251506605		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.018228851251506605 | validation: 0.01647591348319385]
	TIME [epoch: 25.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012268243630555346		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.012268243630555346 | validation: 0.0166554631979369]
	TIME [epoch: 25.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020386412200941336		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.020386412200941336 | validation: 0.015685304335378618]
	TIME [epoch: 25.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04085199634901735		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.04085199634901735 | validation: 0.07057691176666246]
	TIME [epoch: 25.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03223779024567829		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.03223779024567829 | validation: 0.016994833285027565]
	TIME [epoch: 25.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0127058247278336		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.0127058247278336 | validation: 0.017946001599409716]
	TIME [epoch: 25.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015678135289772188		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.015678135289772188 | validation: 0.04422997629449144]
	TIME [epoch: 25.5 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03525658333915457		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.03525658333915457 | validation: 0.02407163950844758]
	TIME [epoch: 25.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019981869554435323		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.019981869554435323 | validation: 0.03145507813876948]
	TIME [epoch: 25.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019914976108542707		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.019914976108542707 | validation: 0.015793796010535953]
	TIME [epoch: 25.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02412766338815388		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.02412766338815388 | validation: 0.042537458069530555]
	TIME [epoch: 25.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027007605261042143		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.027007605261042143 | validation: 0.018038535889083177]
	TIME [epoch: 25.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01948000630356958		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.01948000630356958 | validation: 0.04907672965715418]
	TIME [epoch: 25.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028973892840864587		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.028973892840864587 | validation: 0.03451286855384552]
	TIME [epoch: 25.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019050440693201064		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.019050440693201064 | validation: 0.023679380112112264]
	TIME [epoch: 25.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019333281452934826		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.019333281452934826 | validation: 0.015412443263540694]
	TIME [epoch: 25.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018978273991762207		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.018978273991762207 | validation: 0.05953916804453098]
	TIME [epoch: 25.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027095191696805184		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.027095191696805184 | validation: 0.018958645371227434]
	TIME [epoch: 25.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01555045167657837		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.01555045167657837 | validation: 0.04476609894143438]
	TIME [epoch: 25.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04500193904174776		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.04500193904174776 | validation: 0.031118902840980192]
	TIME [epoch: 25.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01722801848406387		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.01722801848406387 | validation: 0.020903111401330145]
	TIME [epoch: 25.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014206445229421057		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.014206445229421057 | validation: 0.02609397939840005]
	TIME [epoch: 25.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027794040109849313		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.027794040109849313 | validation: 0.02326104285358256]
	TIME [epoch: 25.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0159482190843596		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0159482190843596 | validation: 0.017726156557470354]
	TIME [epoch: 25.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392908010148006		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.02392908010148006 | validation: 0.09505985032274301]
	TIME [epoch: 25.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429668901931578		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.03429668901931578 | validation: 0.015445623684541984]
	TIME [epoch: 25.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013280240706214731		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.013280240706214731 | validation: 0.027153849061736138]
	TIME [epoch: 25.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025302022031020326		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.025302022031020326 | validation: 0.029842620558353655]
	TIME [epoch: 25.6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02058997907582386		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.02058997907582386 | validation: 0.017635690779047534]
	TIME [epoch: 25.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011664250788096764		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.011664250788096764 | validation: 0.01455886227838797]
	TIME [epoch: 25.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03717984948188643		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.03717984948188643 | validation: 0.06633997055343324]
	TIME [epoch: 25.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025992883382192668		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.025992883382192668 | validation: 0.012357782825739065]
	TIME [epoch: 25.6 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012061622630604809		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.012061622630604809 | validation: 0.016108519078976636]
	TIME [epoch: 25.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017680249074910927		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.017680249074910927 | validation: 0.016532753945849715]
	TIME [epoch: 25.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012231147084571195		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.012231147084571195 | validation: 0.023297331262837277]
	TIME [epoch: 25.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046465351310904325		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.046465351310904325 | validation: 0.03709036394632918]
	TIME [epoch: 25.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028138071312393865		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.028138071312393865 | validation: 0.020482597781310452]
	TIME [epoch: 25.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01467542679701654		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.01467542679701654 | validation: 0.015666242216822168]
	TIME [epoch: 25.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020788546287134353		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.020788546287134353 | validation: 0.014786885678847044]
	TIME [epoch: 25.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024906579304388433		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.024906579304388433 | validation: 0.02455324802545937]
	TIME [epoch: 25.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013539681336637112		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.013539681336637112 | validation: 0.016443858215986536]
	TIME [epoch: 25.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013821287879627279		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.013821287879627279 | validation: 0.019807080023012957]
	TIME [epoch: 25.5 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014941897496255288		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.014941897496255288 | validation: 0.0192803786249029]
	TIME [epoch: 25.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0386434457858979		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.0386434457858979 | validation: 0.03228420904541694]
	TIME [epoch: 25.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01800525536345008		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.01800525536345008 | validation: 0.01574462194594307]
	TIME [epoch: 25.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015475610818224482		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.015475610818224482 | validation: 0.04042936808798464]
	TIME [epoch: 25.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0357037737618746		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.0357037737618746 | validation: 0.020022736502728688]
	TIME [epoch: 25.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01598136115961283		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.01598136115961283 | validation: 0.012577256265400728]
	TIME [epoch: 25.5 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010943442536665971		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.010943442536665971 | validation: 0.013662173077209318]
	TIME [epoch: 25.4 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016783331062724352		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.016783331062724352 | validation: 0.036458712000427065]
	TIME [epoch: 25.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026977686641072095		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.026977686641072095 | validation: 0.014371986123117405]
	TIME [epoch: 25.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012492250086117528		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.012492250086117528 | validation: 0.026096197824334942]
	TIME [epoch: 25.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02313743347955843		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.02313743347955843 | validation: 0.017402879436813578]
	TIME [epoch: 25.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017029829893041984		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.017029829893041984 | validation: 0.0360003304407482]
	TIME [epoch: 25.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028207954773412973		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.028207954773412973 | validation: 0.018030101748956903]
	TIME [epoch: 25.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013090706237186207		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.013090706237186207 | validation: 0.013057351967400124]
	TIME [epoch: 25.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012494084986992598		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.012494084986992598 | validation: 0.05134022891704168]
	TIME [epoch: 25.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039970106630102635		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.039970106630102635 | validation: 0.04485864092875466]
	TIME [epoch: 25.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020284337072287557		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.020284337072287557 | validation: 0.014278426378225656]
	TIME [epoch: 25.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010978375766860055		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.010978375766860055 | validation: 0.01659526205222674]
	TIME [epoch: 25.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666721365150528		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.01666721365150528 | validation: 0.029259296469407656]
	TIME [epoch: 25.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025136270873340735		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.025136270873340735 | validation: 0.03544734086226231]
	TIME [epoch: 25.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016726907174575645		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.016726907174575645 | validation: 0.014735750459201571]
	TIME [epoch: 25.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014077604941566822		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.014077604941566822 | validation: 0.04336513328973396]
	TIME [epoch: 25.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025866503443782215		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.025866503443782215 | validation: 0.017969171163448677]
	TIME [epoch: 25.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016533215017234253		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.016533215017234253 | validation: 0.03730675159078551]
	TIME [epoch: 25.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036714141255449306		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.036714141255449306 | validation: 0.022911768219993522]
	TIME [epoch: 25.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013688085484907617		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.013688085484907617 | validation: 0.013227345375551976]
	TIME [epoch: 25.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010994677887821365		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.010994677887821365 | validation: 0.020259143983718954]
	TIME [epoch: 25.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017012497574971107		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.017012497574971107 | validation: 0.016573901751912347]
	TIME [epoch: 25.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028359044391216358		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.028359044391216358 | validation: 0.017594560725405023]
	TIME [epoch: 25.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016044906718683517		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.016044906718683517 | validation: 0.012955092191683249]
	TIME [epoch: 25.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013266106656095799		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.013266106656095799 | validation: 0.04950612522255607]
	TIME [epoch: 25.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027673741095066096		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.027673741095066096 | validation: 0.017203933075317056]
	TIME [epoch: 25.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011439757107639918		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.011439757107639918 | validation: 0.014364290667484583]
	TIME [epoch: 25.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012899499193529547		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.012899499193529547 | validation: 0.018627869538250467]
	TIME [epoch: 25.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015791780535079306		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.015791780535079306 | validation: 0.024064295507817635]
	TIME [epoch: 25.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04054378638372034		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.04054378638372034 | validation: 0.047263216903258104]
	TIME [epoch: 25.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023862967669146314		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.023862967669146314 | validation: 0.013099097931575883]
	TIME [epoch: 25.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011202614557105363		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.011202614557105363 | validation: 0.01254460308468465]
	TIME [epoch: 25.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009851385613760005		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.009851385613760005 | validation: 0.014795490443311238]
	TIME [epoch: 25.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012306385711036564		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.012306385711036564 | validation: 0.013660219780416566]
	TIME [epoch: 25.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016029911545754928		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.016029911545754928 | validation: 0.01982761074927509]
	TIME [epoch: 25.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017231112155808644		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.017231112155808644 | validation: 0.04468453437044917]
	TIME [epoch: 25.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020760197904085762		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.020760197904085762 | validation: 0.014954906693053244]
	TIME [epoch: 25.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011583369904304953		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.011583369904304953 | validation: 0.015248227840504405]
	TIME [epoch: 25.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04069342767205328		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.04069342767205328 | validation: 0.06044544830357243]
	TIME [epoch: 25.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041042187891737324		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.041042187891737324 | validation: 0.017996867509178924]
	TIME [epoch: 25.5 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011478456826913501		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.011478456826913501 | validation: 0.01308519625388932]
	TIME [epoch: 25.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011148805344503923		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.011148805344503923 | validation: 0.01428173522318986]
	TIME [epoch: 25.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015061392826686448		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.015061392826686448 | validation: 0.020999179246136035]
	TIME [epoch: 25.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01268931367684548		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.01268931367684548 | validation: 0.019183917928166802]
	TIME [epoch: 25.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02744507766154839		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.02744507766154839 | validation: 0.049791638378408554]
	TIME [epoch: 25.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024573109373819024		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.024573109373819024 | validation: 0.015758840445588583]
	TIME [epoch: 25.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011593834914649333		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.011593834914649333 | validation: 0.015115037036941274]
	TIME [epoch: 25.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012432181419739619		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.012432181419739619 | validation: 0.01723745150905392]
	TIME [epoch: 25.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011457795825466412		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.011457795825466412 | validation: 0.03809936955406877]
	TIME [epoch: 25.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265048763332144		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.03265048763332144 | validation: 0.018651023075340608]
	TIME [epoch: 25.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011464908368831163		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.011464908368831163 | validation: 0.012857010427873218]
	TIME [epoch: 25.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009751828938609562		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.009751828938609562 | validation: 0.012614083270775681]
	TIME [epoch: 25.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017814194672439308		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.017814194672439308 | validation: 0.05382596698231035]
	TIME [epoch: 25.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0213144953325278		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.0213144953325278 | validation: 0.013999372100619294]
	TIME [epoch: 25.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01076210091489255		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.01076210091489255 | validation: 0.02048332856583025]
	TIME [epoch: 25.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01864502376803205		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.01864502376803205 | validation: 0.026630911181233646]
	TIME [epoch: 25.4 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01634807965698631		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.01634807965698631 | validation: 0.02279989256796492]
	TIME [epoch: 25.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01583924090020261		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.01583924090020261 | validation: 0.013574392657467307]
	TIME [epoch: 25.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014196260780648565		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.014196260780648565 | validation: 0.01202924843181356]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019380246707126358		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.019380246707126358 | validation: 0.018721372102836503]
	TIME [epoch: 25.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013844989696560518		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.013844989696560518 | validation: 0.028990070058707303]
	TIME [epoch: 25.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698894152893164		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.01698894152893164 | validation: 0.028390243450560407]
	TIME [epoch: 25.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015818053384317503		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.015818053384317503 | validation: 0.02028631643101931]
	TIME [epoch: 25.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013446693719955716		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.013446693719955716 | validation: 0.012874009716568002]
	TIME [epoch: 25.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009529673584741768		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.009529673584741768 | validation: 0.022025068176513736]
	TIME [epoch: 25.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021800720911364372		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.021800720911364372 | validation: 0.0171720257506637]
	TIME [epoch: 25.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01606015477552548		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.01606015477552548 | validation: 0.018380510580794377]
	TIME [epoch: 25.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015515653381413433		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.015515653381413433 | validation: 0.013540849604632428]
	TIME [epoch: 25.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015719803209194343		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.015719803209194343 | validation: 0.011672525642903173]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_748.pth
	Model improved!!!
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01050057749139022		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.01050057749139022 | validation: 0.019523637278526892]
	TIME [epoch: 25.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742046900342272		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.01742046900342272 | validation: 0.014592086369016315]
	TIME [epoch: 25.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0140051909402281		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.0140051909402281 | validation: 0.012140290511384214]
	TIME [epoch: 25.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013301399199347322		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.013301399199347322 | validation: 0.012445588953207538]
	TIME [epoch: 25.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016033636668979567		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.016033636668979567 | validation: 0.02397113350768152]
	TIME [epoch: 25.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012575537666451028		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.012575537666451028 | validation: 0.013892741840214044]
	TIME [epoch: 25.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014269845392917837		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.014269845392917837 | validation: 0.026721367483980317]
	TIME [epoch: 25.5 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014242346273102186		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.014242346273102186 | validation: 0.026175777442412725]
	TIME [epoch: 25.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021406963864395247		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.021406963864395247 | validation: 0.013304541143964992]
	TIME [epoch: 25.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010440732573898057		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.010440732573898057 | validation: 0.012730360527712828]
	TIME [epoch: 25.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015123362555612942		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.015123362555612942 | validation: 0.013182023849066506]
	TIME [epoch: 25.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011102231798537813		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.011102231798537813 | validation: 0.02194988623824053]
	TIME [epoch: 25.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013944134468583176		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.013944134468583176 | validation: 0.01512937045416245]
	TIME [epoch: 25.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015873941381028406		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.015873941381028406 | validation: 0.02708531823162219]
	TIME [epoch: 25.5 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013168725202896		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.02013168725202896 | validation: 0.016389448160984775]
	TIME [epoch: 25.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01137607189967652		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.01137607189967652 | validation: 0.010969838234304759]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014707675275781026		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.014707675275781026 | validation: 0.024720003226002107]
	TIME [epoch: 25.4 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014664772085495773		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.014664772085495773 | validation: 0.012611641223953652]
	TIME [epoch: 25.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01117105978388895		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.01117105978388895 | validation: 0.015478835267896568]
	TIME [epoch: 25.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017181953234914577		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.017181953234914577 | validation: 0.013213488785953065]
	TIME [epoch: 25.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010084528644543012		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.010084528644543012 | validation: 0.015809693504993005]
	TIME [epoch: 25.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018239088415016418		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.018239088415016418 | validation: 0.013939115486473107]
	TIME [epoch: 25.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010093253627401669		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.010093253627401669 | validation: 0.014300441838972534]
	TIME [epoch: 25.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019798616263947175		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.019798616263947175 | validation: 0.02341564749111723]
	TIME [epoch: 25.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013972618201549894		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.013972618201549894 | validation: 0.012209416821225515]
	TIME [epoch: 25.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011128926462187407		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.011128926462187407 | validation: 0.011911897805130436]
	TIME [epoch: 25.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014066647165969932		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.014066647165969932 | validation: 0.0221865322982321]
	TIME [epoch: 25.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01224562446471627		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.01224562446471627 | validation: 0.016611093418648887]
	TIME [epoch: 25.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013804235421678496		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.013804235421678496 | validation: 0.013010440132386624]
	TIME [epoch: 25.5 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010645378530299229		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.010645378530299229 | validation: 0.019164419113582]
	TIME [epoch: 25.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015331870194726472		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.015331870194726472 | validation: 0.02727509241590407]
	TIME [epoch: 25.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025836904858378806		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.025836904858378806 | validation: 0.023364420309634842]
	TIME [epoch: 25.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025609941275373072		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.025609941275373072 | validation: 0.014741616979544663]
	TIME [epoch: 25.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00967272712871806		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.00967272712871806 | validation: 0.0112896832628059]
	TIME [epoch: 25.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009665096715093552		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.009665096715093552 | validation: 0.012536511887845457]
	TIME [epoch: 25.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008940577155623786		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.008940577155623786 | validation: 0.01138448259370228]
	TIME [epoch: 25.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00956893748170542		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.00956893748170542 | validation: 0.01253216953674731]
	TIME [epoch: 25.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013800210533951154		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.013800210533951154 | validation: 0.036841948609901254]
	TIME [epoch: 25.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016325043050183872		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.016325043050183872 | validation: 0.02270467109697913]
	TIME [epoch: 25.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01349423859264117		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.01349423859264117 | validation: 0.021038840416496306]
	TIME [epoch: 25.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013568444772450644		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.013568444772450644 | validation: 0.022046994862668083]
	TIME [epoch: 25.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01373413243952453		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.01373413243952453 | validation: 0.016168875603336245]
	TIME [epoch: 25.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012071119894311243		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.012071119894311243 | validation: 0.015638142527288124]
	TIME [epoch: 25.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011393682739403404		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.011393682739403404 | validation: 0.010361053037840101]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013298431952183299		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.013298431952183299 | validation: 0.012809590528846193]
	TIME [epoch: 25.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01894601525450585		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.01894601525450585 | validation: 0.014422610008257486]
	TIME [epoch: 25.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009194120647819229		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.009194120647819229 | validation: 0.011837593186563848]
	TIME [epoch: 25.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009206369683110983		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.009206369683110983 | validation: 0.020148449256314854]
	TIME [epoch: 25.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013807494134825439		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.013807494134825439 | validation: 0.02645110440866459]
	TIME [epoch: 25.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013815138919343706		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.013815138919343706 | validation: 0.012698489548810745]
	TIME [epoch: 25.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012731633302706283		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.012731633302706283 | validation: 0.019249963523783546]
	TIME [epoch: 25.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014329666513454655		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.014329666513454655 | validation: 0.014406099934275222]
	TIME [epoch: 25.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008714632189800599		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.008714632189800599 | validation: 0.02107049904059554]
	TIME [epoch: 25.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010693750482844688		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.010693750482844688 | validation: 0.012117104034347768]
	TIME [epoch: 25.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01565777937722913		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.01565777937722913 | validation: 0.028864874710921667]
	TIME [epoch: 25.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015374323800245579		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.015374323800245579 | validation: 0.01032171885346755]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_804.pth
	Model improved!!!
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009372005151799735		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.009372005151799735 | validation: 0.012775977267927837]
	TIME [epoch: 25.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011498457223772445		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.011498457223772445 | validation: 0.014508111694967258]
	TIME [epoch: 25.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293079773495681		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.07293079773495681 | validation: 0.14973145627194284]
	TIME [epoch: 25.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088391769221431		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.05088391769221431 | validation: 0.02573406499359939]
	TIME [epoch: 25.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01287149627143257		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.01287149627143257 | validation: 0.012961951814586693]
	TIME [epoch: 25.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008645007445179882		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.008645007445179882 | validation: 0.011231970628144985]
	TIME [epoch: 25.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00820758302499416		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.00820758302499416 | validation: 0.010131718147133113]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_811.pth
	Model improved!!!
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009702962183078374		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.009702962183078374 | validation: 0.012022528497598288]
	TIME [epoch: 25.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008319691884015597		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.008319691884015597 | validation: 0.011202064979307567]
	TIME [epoch: 25.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008396055855250379		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.008396055855250379 | validation: 0.011313823523140754]
	TIME [epoch: 25.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012241776584649852		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.012241776584649852 | validation: 0.010530062140574174]
	TIME [epoch: 25.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011995171133544046		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.011995171133544046 | validation: 0.013950934265784552]
	TIME [epoch: 25.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01168118828032896		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.01168118828032896 | validation: 0.02509415022916009]
	TIME [epoch: 25.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013280620426827434		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.013280620426827434 | validation: 0.01108199246181081]
	TIME [epoch: 25.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011008888752494568		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.011008888752494568 | validation: 0.011661677678926712]
	TIME [epoch: 25.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009706977860496676		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.009706977860496676 | validation: 0.016671120231523902]
	TIME [epoch: 25.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01186930447874555		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.01186930447874555 | validation: 0.012287665534178451]
	TIME [epoch: 25.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010621289695878588		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.010621289695878588 | validation: 0.023244283772741143]
	TIME [epoch: 25.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01144569879886859		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.01144569879886859 | validation: 0.012187694827795673]
	TIME [epoch: 25.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012255476454505579		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.012255476454505579 | validation: 0.018314890309020688]
	TIME [epoch: 25.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010360742458179414		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.010360742458179414 | validation: 0.020849296592447115]
	TIME [epoch: 25.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017373070571626056		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.017373070571626056 | validation: 0.012058834802090627]
	TIME [epoch: 25.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00795470156376733		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.00795470156376733 | validation: 0.012626144735507161]
	TIME [epoch: 25.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009015742174553303		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.009015742174553303 | validation: 0.015843447902171726]
	TIME [epoch: 25.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015068940341870122		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.015068940341870122 | validation: 0.025641607850409715]
	TIME [epoch: 25.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012030832523567753		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.012030832523567753 | validation: 0.013292456163939866]
	TIME [epoch: 25.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008537885937464927		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.008537885937464927 | validation: 0.024625690951142067]
	TIME [epoch: 25.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041118486285270775		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.041118486285270775 | validation: 0.02378408314860947]
	TIME [epoch: 25.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01403875739855001		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.01403875739855001 | validation: 0.011589342426409223]
	TIME [epoch: 25.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00905335127054712		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.00905335127054712 | validation: 0.011182331443247498]
	TIME [epoch: 25.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008567248517955994		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.008567248517955994 | validation: 0.010506932861426403]
	TIME [epoch: 25.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008347789874576003		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.008347789874576003 | validation: 0.009586626596127638]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074925116486710165		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0074925116486710165 | validation: 0.011227540930619173]
	TIME [epoch: 25.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012433908638532717		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.012433908638532717 | validation: 0.010183623001406565]
	TIME [epoch: 25.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007964982219572883		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.007964982219572883 | validation: 0.010754761349635754]
	TIME [epoch: 25.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011774016809836613		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.011774016809836613 | validation: 0.04074200493917984]
	TIME [epoch: 25.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333007880830998		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.0333007880830998 | validation: 0.017390080468268416]
	TIME [epoch: 25.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01176127502328128		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.01176127502328128 | validation: 0.009878360978726977]
	TIME [epoch: 25.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00842262971989796		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.00842262971989796 | validation: 0.009074315830995537]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_843.pth
	Model improved!!!
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007803777570998707		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.007803777570998707 | validation: 0.012225544841604]
	TIME [epoch: 25.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008830959088686328		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.008830959088686328 | validation: 0.010954498081072295]
	TIME [epoch: 25.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008357837583831415		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.008357837583831415 | validation: 0.01123065023382109]
	TIME [epoch: 25.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00992467064290522		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.00992467064290522 | validation: 0.01014533541741443]
	TIME [epoch: 25.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014613718125276627		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.014613718125276627 | validation: 0.018031587397362513]
	TIME [epoch: 25.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010791947301553187		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.010791947301553187 | validation: 0.014937023908691869]
	TIME [epoch: 25.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010356867339532555		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.010356867339532555 | validation: 0.013204364175912938]
	TIME [epoch: 25.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009115010249522437		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.009115010249522437 | validation: 0.013882138708900572]
	TIME [epoch: 25.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008707269531806701		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.008707269531806701 | validation: 0.010259022800105499]
	TIME [epoch: 25.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01388113794311489		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.01388113794311489 | validation: 0.016021968800015083]
	TIME [epoch: 25.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011765939920488454		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.011765939920488454 | validation: 0.013261215970803975]
	TIME [epoch: 25.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010498458339669076		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.010498458339669076 | validation: 0.011766412155722857]
	TIME [epoch: 25.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008757243408500849		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.008757243408500849 | validation: 0.011930628562100608]
	TIME [epoch: 25.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00961986343530647		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.00961986343530647 | validation: 0.01288423785881598]
	TIME [epoch: 25.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010692755787714635		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.010692755787714635 | validation: 0.009224440850292115]
	TIME [epoch: 25.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009294245689390492		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.009294245689390492 | validation: 0.012625716044168081]
	TIME [epoch: 25.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011002733355396612		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.011002733355396612 | validation: 0.01694904574105985]
	TIME [epoch: 25.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010940398486776541		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.010940398486776541 | validation: 0.013199143568793445]
	TIME [epoch: 25.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013059257661171183		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.013059257661171183 | validation: 0.010966213839128776]
	TIME [epoch: 25.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007952924163226877		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.007952924163226877 | validation: 0.011166529909291158]
	TIME [epoch: 25.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008002624293571922		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.008002624293571922 | validation: 0.009840533241843825]
	TIME [epoch: 25.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017638305141721457		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.017638305141721457 | validation: 0.02196867169854464]
	TIME [epoch: 25.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011403308075891051		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.011403308075891051 | validation: 0.014851191082622187]
	TIME [epoch: 25.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012159655876472759		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.012159655876472759 | validation: 0.013391976220926423]
	TIME [epoch: 25.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009690860630649797		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.009690860630649797 | validation: 0.010306441418736136]
	TIME [epoch: 25.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00922623927731035		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.00922623927731035 | validation: 0.012228292015814202]
	TIME [epoch: 25.5 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009792036965303463		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.009792036965303463 | validation: 0.008642106806399822]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_870.pth
	Model improved!!!
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008969039026209035		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.008969039026209035 | validation: 0.02382725324016997]
	TIME [epoch: 25.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011486854591537856		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.011486854591537856 | validation: 0.011493375397679112]
	TIME [epoch: 25.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00736177737321641		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.00736177737321641 | validation: 0.009683427130861691]
	TIME [epoch: 25.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014073156070655304		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.014073156070655304 | validation: 0.01233322153596859]
	TIME [epoch: 25.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009218500375868733		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.009218500375868733 | validation: 0.011905388358420725]
	TIME [epoch: 25.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010567017643983207		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.010567017643983207 | validation: 0.009359607204208892]
	TIME [epoch: 25.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009216314933540798		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.009216314933540798 | validation: 0.026674255744657156]
	TIME [epoch: 25.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01713953913403758		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.01713953913403758 | validation: 0.010789139358451003]
	TIME [epoch: 25.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008478197831377822		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.008478197831377822 | validation: 0.009826765880577282]
	TIME [epoch: 25.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007724364108836986		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.007724364108836986 | validation: 0.011037416450731738]
	TIME [epoch: 25.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00954687225566902		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.00954687225566902 | validation: 0.012058391501187097]
	TIME [epoch: 25.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007781420158699542		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.007781420158699542 | validation: 0.009586361145349769]
	TIME [epoch: 25.4 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007980009554584583		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.007980009554584583 | validation: 0.013975773382197944]
	TIME [epoch: 25.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013522277321470443		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.013522277321470443 | validation: 0.018681531688054906]
	TIME [epoch: 25.4 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010697845570524382		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.010697845570524382 | validation: 0.011273399612156947]
	TIME [epoch: 25.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009105112927080595		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.009105112927080595 | validation: 0.009898460785629143]
	TIME [epoch: 25.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007543567637841764		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.007543567637841764 | validation: 0.008825749125777955]
	TIME [epoch: 25.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009099188212045955		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.009099188212045955 | validation: 0.011207246391353533]
	TIME [epoch: 25.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0151286823434972		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0151286823434972 | validation: 0.01983766151270199]
	TIME [epoch: 25.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009977195195950769		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.009977195195950769 | validation: 0.009332901716287822]
	TIME [epoch: 25.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069938944723734395		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.0069938944723734395 | validation: 0.009749850399653426]
	TIME [epoch: 25.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010405812945038312		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.010405812945038312 | validation: 0.010414960238973061]
	TIME [epoch: 25.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009960573219983348		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.009960573219983348 | validation: 0.011893240837278]
	TIME [epoch: 25.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008106280517958128		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.008106280517958128 | validation: 0.016383244197594064]
	TIME [epoch: 25.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012546716243642493		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.012546716243642493 | validation: 0.011592038005136241]
	TIME [epoch: 25.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012055040101156236		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.012055040101156236 | validation: 0.012263145447851464]
	TIME [epoch: 25.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00891449490981153		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.00891449490981153 | validation: 0.009837990794609876]
	TIME [epoch: 25.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008185468801669572		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.008185468801669572 | validation: 0.009842772511805396]
	TIME [epoch: 25.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008629756619797823		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.008629756619797823 | validation: 0.019876233141786534]
	TIME [epoch: 25.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011340148045123129		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.011340148045123129 | validation: 0.009218915527498239]
	TIME [epoch: 25.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008987695742645678		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.008987695742645678 | validation: 0.009555793131169051]
	TIME [epoch: 25.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008152063361501623		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.008152063361501623 | validation: 0.009785546745773518]
	TIME [epoch: 25.4 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009915122103475227		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.009915122103475227 | validation: 0.008654742086497701]
	TIME [epoch: 25.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008179242895585357		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.008179242895585357 | validation: 0.012728116005352154]
	TIME [epoch: 25.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010480531454848455		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.010480531454848455 | validation: 0.015041179833966299]
	TIME [epoch: 25.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010253136853633913		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.010253136853633913 | validation: 0.010895530722609868]
	TIME [epoch: 25.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007592564411212423		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.007592564411212423 | validation: 0.018372118532128348]
	TIME [epoch: 25.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01070648523376316		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.01070648523376316 | validation: 0.01322847094518318]
	TIME [epoch: 25.4 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008003112666141444		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.008003112666141444 | validation: 0.00894707473808701]
	TIME [epoch: 25.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01105194402371273		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.01105194402371273 | validation: 0.025033224748998332]
	TIME [epoch: 25.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015546572715367801		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.015546572715367801 | validation: 0.011079908790050672]
	TIME [epoch: 25.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008765192085629769		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.008765192085629769 | validation: 0.010136732791418529]
	TIME [epoch: 25.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007040111476478755		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.007040111476478755 | validation: 0.009784602879758644]
	TIME [epoch: 25.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007852449396171163		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.007852449396171163 | validation: 0.010456119757755459]
	TIME [epoch: 25.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00859820839370602		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.00859820839370602 | validation: 0.01104769651508234]
	TIME [epoch: 25.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007710033502982683		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.007710033502982683 | validation: 0.01189803626611487]
	TIME [epoch: 25.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0110297840896145		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.0110297840896145 | validation: 0.009700420788039893]
	TIME [epoch: 25.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007390862350899134		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.007390862350899134 | validation: 0.011188966169746238]
	TIME [epoch: 25.4 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008122141820628138		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.008122141820628138 | validation: 0.013848621090413925]
	TIME [epoch: 25.4 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010527348258502114		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.010527348258502114 | validation: 0.009284332747509456]
	TIME [epoch: 25.4 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007863187089619476		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.007863187089619476 | validation: 0.009080239119780833]
	TIME [epoch: 25.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012705829151508894		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.012705829151508894 | validation: 0.012104170882862662]
	TIME [epoch: 25.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008696497647559977		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.008696497647559977 | validation: 0.009556084912474805]
	TIME [epoch: 25.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006847185881291422		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.006847185881291422 | validation: 0.009097238383665548]
	TIME [epoch: 25.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008230551482437398		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.008230551482437398 | validation: 0.010734325411068505]
	TIME [epoch: 25.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011053151124200635		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.011053151124200635 | validation: 0.010121546921938694]
	TIME [epoch: 25.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007654176032178801		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.007654176032178801 | validation: 0.00925655470442286]
	TIME [epoch: 25.4 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007888584967363317		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.007888584967363317 | validation: 0.010188930549078875]
	TIME [epoch: 25.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00956012180247036		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.00956012180247036 | validation: 0.009737768936069898]
	TIME [epoch: 25.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006857883849108466		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.006857883849108466 | validation: 0.010562715877067775]
	TIME [epoch: 25.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009844040434776073		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.009844040434776073 | validation: 0.012650351811237307]
	TIME [epoch: 25.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011022640279541808		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.011022640279541808 | validation: 0.01063686482750414]
	TIME [epoch: 25.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007352040220979928		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.007352040220979928 | validation: 0.008685741293103889]
	TIME [epoch: 25.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072653238168661465		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0072653238168661465 | validation: 0.011264198746127928]
	TIME [epoch: 25.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008792957378769384		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.008792957378769384 | validation: 0.013220119279546604]
	TIME [epoch: 25.4 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011945972958344		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.011945972958344 | validation: 0.027757451216850117]
	TIME [epoch: 25.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013497335502921532		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.013497335502921532 | validation: 0.008839555938173425]
	TIME [epoch: 25.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006962386312076296		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.006962386312076296 | validation: 0.009789557163984906]
	TIME [epoch: 25.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008929407110823608		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.008929407110823608 | validation: 0.010061041490619274]
	TIME [epoch: 25.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006941857881691864		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.006941857881691864 | validation: 0.009739802012397308]
	TIME [epoch: 25.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007098387909553258		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.007098387909553258 | validation: 0.011261344397700046]
	TIME [epoch: 25.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008981771428732542		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.008981771428732542 | validation: 0.009208388013233596]
	TIME [epoch: 25.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00797634485004263		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.00797634485004263 | validation: 0.010434495263613675]
	TIME [epoch: 25.4 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009341404314027838		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.009341404314027838 | validation: 0.009935242534124457]
	TIME [epoch: 25.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008789793665353356		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.008789793665353356 | validation: 0.012965522737950569]
	TIME [epoch: 25.4 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00855718057527086		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.00855718057527086 | validation: 0.009509047483042751]
	TIME [epoch: 25.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008337277945978822		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.008337277945978822 | validation: 0.017721335483791296]
	TIME [epoch: 25.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009116209068878438		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.009116209068878438 | validation: 0.010666357956752855]
	TIME [epoch: 25.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070486936598523516		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.0070486936598523516 | validation: 0.008701426237087194]
	TIME [epoch: 25.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0072313805959206695		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.0072313805959206695 | validation: 0.009568124054386961]
	TIME [epoch: 25.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009922597322742404		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.009922597322742404 | validation: 0.011218097074211075]
	TIME [epoch: 25.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008590674689229702		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.008590674689229702 | validation: 0.008395807672549806]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_952.pth
	Model improved!!!
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007076669040442808		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.007076669040442808 | validation: 0.01345023483256428]
	TIME [epoch: 25.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007568915315518983		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.007568915315518983 | validation: 0.013215925572032116]
	TIME [epoch: 25.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014078461694972313		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.014078461694972313 | validation: 0.012222317113467121]
	TIME [epoch: 25.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008991022949362017		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.008991022949362017 | validation: 0.010365225661956152]
	TIME [epoch: 25.4 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007389514400948761		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.007389514400948761 | validation: 0.00910687242896904]
	TIME [epoch: 25.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006750476665179235		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.006750476665179235 | validation: 0.01076389160161178]
	TIME [epoch: 25.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00881732430072084		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.00881732430072084 | validation: 0.008525325869757825]
	TIME [epoch: 25.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007648745157571637		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.007648745157571637 | validation: 0.011336644678110908]
	TIME [epoch: 25.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008484873568245059		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.008484873568245059 | validation: 0.010399922656720222]
	TIME [epoch: 25.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007799101327963253		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.007799101327963253 | validation: 0.011974488490764459]
	TIME [epoch: 25.4 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008140150363808604		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.008140150363808604 | validation: 0.015965495181177125]
	TIME [epoch: 25.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008934690894108692		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.008934690894108692 | validation: 0.00999639489458043]
	TIME [epoch: 25.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00678598893210141		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.00678598893210141 | validation: 0.009381950570170688]
	TIME [epoch: 25.4 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008923906509544648		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.008923906509544648 | validation: 0.01392257496913828]
	TIME [epoch: 25.4 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00898848650011847		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.00898848650011847 | validation: 0.010805381049042016]
	TIME [epoch: 25.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006399777046497032		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.006399777046497032 | validation: 0.008780572685552587]
	TIME [epoch: 25.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008059607093444755		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.008059607093444755 | validation: 0.010794524422209899]
	TIME [epoch: 25.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077421039202827365		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0077421039202827365 | validation: 0.010150488468652265]
	TIME [epoch: 25.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008932572686975341		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.008932572686975341 | validation: 0.012097371583491792]
	TIME [epoch: 25.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007997101527389234		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.007997101527389234 | validation: 0.010088372500627975]
	TIME [epoch: 25.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075846828312366105		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.0075846828312366105 | validation: 0.022613748993171548]
	TIME [epoch: 25.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011636398188609403		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.011636398188609403 | validation: 0.012355244833920085]
	TIME [epoch: 25.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008173346941122806		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.008173346941122806 | validation: 0.008973097790611796]
	TIME [epoch: 25.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007772624932875002		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.007772624932875002 | validation: 0.028455713112555348]
	TIME [epoch: 25.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011820503719224463		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.011820503719224463 | validation: 0.009522304766590241]
	TIME [epoch: 25.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007168383769308633		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.007168383769308633 | validation: 0.009296557587193395]
	TIME [epoch: 25.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006916026505386879		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.006916026505386879 | validation: 0.010161500639033878]
	TIME [epoch: 25.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006369534961950085		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.006369534961950085 | validation: 0.008115327027112405]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_980.pth
	Model improved!!!
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006739603967982923		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.006739603967982923 | validation: 0.012967446037769923]
	TIME [epoch: 25.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00928265370247441		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.00928265370247441 | validation: 0.01117575667821062]
	TIME [epoch: 25.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007157153717793071		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.007157153717793071 | validation: 0.010483816720065826]
	TIME [epoch: 25.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008674587977980572		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.008674587977980572 | validation: 0.01045038505031222]
	TIME [epoch: 25.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008622804930130897		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.008622804930130897 | validation: 0.009872158414934912]
	TIME [epoch: 25.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008036544029608303		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.008036544029608303 | validation: 0.009924097737046202]
	TIME [epoch: 25.4 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007026937703695134		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.007026937703695134 | validation: 0.009321273083183444]
	TIME [epoch: 25.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006994605609215491		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.006994605609215491 | validation: 0.009474883477015233]
	TIME [epoch: 25.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00912427802046219		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.00912427802046219 | validation: 0.007906784018452618]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006819807578878479		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.006819807578878479 | validation: 0.00796054952853438]
	TIME [epoch: 25.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007506546451197448		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.007506546451197448 | validation: 0.011168454176889202]
	TIME [epoch: 25.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008188124858882158		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.008188124858882158 | validation: 0.009510781205868644]
	TIME [epoch: 25.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007450998979693617		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.007450998979693617 | validation: 0.009470705721937667]
	TIME [epoch: 25.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008117060006678483		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.008117060006678483 | validation: 0.01814721713843538]
	TIME [epoch: 25.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009629943780987124		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.009629943780987124 | validation: 0.009140854758937052]
	TIME [epoch: 25.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006447831412531772		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.006447831412531772 | validation: 0.009020554349421306]
	TIME [epoch: 25.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006754470867913368		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.006754470867913368 | validation: 0.008965900617440225]
	TIME [epoch: 25.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008228259883143886		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.008228259883143886 | validation: 0.010973434083964785]
	TIME [epoch: 25.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008191448853965836		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.008191448853965836 | validation: 0.009079611627589464]
	TIME [epoch: 25.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007444185550440758		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.007444185550440758 | validation: 0.008959082637989401]
	TIME [epoch: 25.4 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00797493339348099		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.00797493339348099 | validation: 0.010372381578236674]
	TIME [epoch: 442 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006771388056863031		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.006771388056863031 | validation: 0.008804571605924025]
	TIME [epoch: 54.2 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007169922827060896		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.007169922827060896 | validation: 0.010099164552680121]
	TIME [epoch: 54.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010682945648794035		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.010682945648794035 | validation: 0.018516521666138992]
	TIME [epoch: 54.2 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009038575297879166		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.009038575297879166 | validation: 0.010497009210620856]
	TIME [epoch: 54.2 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007021928424015859		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.007021928424015859 | validation: 0.008249707028807503]
	TIME [epoch: 54.2 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007124472714515861		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.007124472714515861 | validation: 0.00955657663401498]
	TIME [epoch: 54.2 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006958362216363749		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.006958362216363749 | validation: 0.010416017162694146]
	TIME [epoch: 54.2 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007102310348798444		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.007102310348798444 | validation: 0.010040161384369129]
	TIME [epoch: 54.2 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007535795048535417		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.007535795048535417 | validation: 0.010797747384892295]
	TIME [epoch: 54.2 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007226831885970924		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.007226831885970924 | validation: 0.009125997310126331]
	TIME [epoch: 54.2 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00769707984862279		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.00769707984862279 | validation: 0.01103816446847495]
	TIME [epoch: 54.2 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006665492894257408		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.006665492894257408 | validation: 0.009902148231481998]
	TIME [epoch: 54.2 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009009312358124858		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.009009312358124858 | validation: 0.009837731890530329]
	TIME [epoch: 54.2 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00781241808535919		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.00781241808535919 | validation: 0.009900959664934648]
	TIME [epoch: 54.2 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0075536038359372655		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.0075536038359372655 | validation: 0.009099628848210022]
	TIME [epoch: 54.2 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006424395836917996		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.006424395836917996 | validation: 0.00797461661099067]
	TIME [epoch: 54.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007013247193423532		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.007013247193423532 | validation: 0.011328112087239607]
	TIME [epoch: 54.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00805201697016383		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.00805201697016383 | validation: 0.008077652244919992]
	TIME [epoch: 54.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007869887713190644		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.007869887713190644 | validation: 0.008439315776640486]
	TIME [epoch: 54.2 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008258849706471007		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.008258849706471007 | validation: 0.008317887470671163]
	TIME [epoch: 54.2 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00627248629279868		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.00627248629279868 | validation: 0.009749541215710677]
	TIME [epoch: 54.2 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007147575429960239		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.007147575429960239 | validation: 0.009715221413821501]
	TIME [epoch: 54.2 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007832733755897606		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.007832733755897606 | validation: 0.012891148599581525]
	TIME [epoch: 54.2 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009058336103432707		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.009058336103432707 | validation: 0.008742547177041697]
	TIME [epoch: 54.2 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065291430775783876		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.0065291430775783876 | validation: 0.007573895094118341]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1026.pth
	Model improved!!!
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005981746539362876		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.005981746539362876 | validation: 0.007680850445099495]
	TIME [epoch: 54.2 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005798844840630742		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.005798844840630742 | validation: 0.011000774788440994]
	TIME [epoch: 54.2 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006926300629626233		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.006926300629626233 | validation: 0.008677659006810775]
	TIME [epoch: 54.2 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009419977235089328		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.009419977235089328 | validation: 0.010440050074853588]
	TIME [epoch: 54.2 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00816387335872469		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.00816387335872469 | validation: 0.009681177363386743]
	TIME [epoch: 54.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007152941910227924		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.007152941910227924 | validation: 0.009759575317916042]
	TIME [epoch: 54.2 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006499015741665854		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.006499015741665854 | validation: 0.009403680544893447]
	TIME [epoch: 54.2 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00620193019692792		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.00620193019692792 | validation: 0.007899831079826813]
	TIME [epoch: 54.2 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006293849457207991		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.006293849457207991 | validation: 0.00781545080018618]
	TIME [epoch: 54.2 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006350928842423191		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.006350928842423191 | validation: 0.01676775293029983]
	TIME [epoch: 54.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009033180255160023		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.009033180255160023 | validation: 0.008753406885585784]
	TIME [epoch: 54.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007552402440873469		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.007552402440873469 | validation: 0.008469811802997189]
	TIME [epoch: 54.2 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006730802141785137		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.006730802141785137 | validation: 0.009462276628271456]
	TIME [epoch: 54.2 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006972690641906894		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.006972690641906894 | validation: 0.00863622025544409]
	TIME [epoch: 54.2 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006491568752923794		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.006491568752923794 | validation: 0.009693406215458089]
	TIME [epoch: 54.2 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007710114810725707		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.007710114810725707 | validation: 0.008564107960652106]
	TIME [epoch: 54.4 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066846025438460095		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.0066846025438460095 | validation: 0.008388160702281012]
	TIME [epoch: 54.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007245877660839881		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.007245877660839881 | validation: 0.00847129155927928]
	TIME [epoch: 54.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006499424791907264		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.006499424791907264 | validation: 0.015151509402029311]
	TIME [epoch: 54.2 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007952518406738567		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.007952518406738567 | validation: 0.009625456446449283]
	TIME [epoch: 54.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069095419311751265		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.0069095419311751265 | validation: 0.007994587363584042]
	TIME [epoch: 54.4 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006265665923780349		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.006265665923780349 | validation: 0.007917478238546735]
	TIME [epoch: 54.2 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006322153624700384		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.006322153624700384 | validation: 0.009232828456209303]
	TIME [epoch: 54.2 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00873636471336749		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.00873636471336749 | validation: 0.008221212549014048]
	TIME [epoch: 54.2 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069120220026751495		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0069120220026751495 | validation: 0.008366110529719386]
	TIME [epoch: 54.2 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006828374747446163		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.006828374747446163 | validation: 0.008397582841535313]
	TIME [epoch: 54.2 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007187438163902918		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.007187438163902918 | validation: 0.008438180939905351]
	TIME [epoch: 54.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006730197817603301		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.006730197817603301 | validation: 0.009630546182933937]
	TIME [epoch: 54.2 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006249310266727741		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.006249310266727741 | validation: 0.00990891011688831]
	TIME [epoch: 54.2 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008736165110303088		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.008736165110303088 | validation: 0.007958790813442113]
	TIME [epoch: 54.2 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006011397514575785		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.006011397514575785 | validation: 0.00795113807253956]
	TIME [epoch: 54.2 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006028836663791276		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.006028836663791276 | validation: 0.023880351272506484]
	TIME [epoch: 54.2 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011656807383477224		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.011656807383477224 | validation: 0.008714755127942262]
	TIME [epoch: 54.2 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007172917711144923		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.007172917711144923 | validation: 0.009392871056698724]
	TIME [epoch: 54.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006361114948753646		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.006361114948753646 | validation: 0.008264407903036794]
	TIME [epoch: 54.2 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006094148735286854		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.006094148735286854 | validation: 0.008097471312096484]
	TIME [epoch: 54.2 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009073154052430032		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.009073154052430032 | validation: 0.008870307223904295]
	TIME [epoch: 54.2 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006598461020867758		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.006598461020867758 | validation: 0.008342775912231756]
	TIME [epoch: 54.4 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005909707171695618		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.005909707171695618 | validation: 0.007883838133496817]
	TIME [epoch: 54.2 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006505682434504701		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.006505682434504701 | validation: 0.008553004048292515]
	TIME [epoch: 54.2 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065896597812765785		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0065896597812765785 | validation: 0.009932975677343284]
	TIME [epoch: 54.2 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006843586343484244		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.006843586343484244 | validation: 0.010421685136185386]
	TIME [epoch: 54.2 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007428876618369929		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.007428876618369929 | validation: 0.00787443286670749]
	TIME [epoch: 54.2 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066411640029057405		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0066411640029057405 | validation: 0.012740246766583715]
	TIME [epoch: 54.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076304968957353085		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.0076304968957353085 | validation: 0.008758866230225959]
	TIME [epoch: 54.2 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006920627255172622		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.006920627255172622 | validation: 0.008921628830820611]
	TIME [epoch: 54.2 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005990479354440972		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.005990479354440972 | validation: 0.009178521808930123]
	TIME [epoch: 54.2 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007350824738723652		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.007350824738723652 | validation: 0.008903029833244046]
	TIME [epoch: 54.2 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006334576748355768		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.006334576748355768 | validation: 0.007821117001809316]
	TIME [epoch: 54.2 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006317687814849906		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.006317687814849906 | validation: 0.007534219942092186]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1076.pth
	Model improved!!!
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069778098569484685		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.0069778098569484685 | validation: 0.010292189742999896]
	TIME [epoch: 54.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006376870004587329		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.006376870004587329 | validation: 0.0073231076739077045]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1078.pth
	Model improved!!!
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060138311798123975		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.0060138311798123975 | validation: 0.011683188495337627]
	TIME [epoch: 54.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007742625298787765		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.007742625298787765 | validation: 0.007062355927735335]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1080.pth
	Model improved!!!
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005953345375955724		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.005953345375955724 | validation: 0.00866485675866246]
	TIME [epoch: 54.2 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005969927194154078		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.005969927194154078 | validation: 0.008385779432615488]
	TIME [epoch: 54.2 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006438267906843376		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.006438267906843376 | validation: 0.009707595453102742]
	TIME [epoch: 54.2 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069974215238989		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.0069974215238989 | validation: 0.008742869708186253]
	TIME [epoch: 54.2 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006080649625783042		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.006080649625783042 | validation: 0.009181759109709777]
	TIME [epoch: 54.5 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006538420952635612		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.006538420952635612 | validation: 0.010478364731231172]
	TIME [epoch: 54.2 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007688479981505742		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.007688479981505742 | validation: 0.008811048995012966]
	TIME [epoch: 54.4 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006756566240605127		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.006756566240605127 | validation: 0.00982143780119129]
	TIME [epoch: 54.2 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007012182958534843		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.007012182958534843 | validation: 0.0085324629610465]
	TIME [epoch: 54.2 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005882489405122098		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.005882489405122098 | validation: 0.00803459497693123]
	TIME [epoch: 54.2 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00647911117089393		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.00647911117089393 | validation: 0.007608159067623868]
	TIME [epoch: 54.2 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006695752595198774		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.006695752595198774 | validation: 0.006852229027106678]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1092.pth
	Model improved!!!
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007982548919019198		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.007982548919019198 | validation: 0.008153757386407843]
	TIME [epoch: 54.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006073842132229435		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.006073842132229435 | validation: 0.007494278926462653]
	TIME [epoch: 54.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006714502067439435		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.006714502067439435 | validation: 0.008046715483101178]
	TIME [epoch: 54.2 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006621272392642079		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.006621272392642079 | validation: 0.008053315464220563]
	TIME [epoch: 54.2 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005832327684907685		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.005832327684907685 | validation: 0.008881583212972865]
	TIME [epoch: 54.2 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007269339846696876		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.007269339846696876 | validation: 0.008168466998158458]
	TIME [epoch: 54.2 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006485688893600312		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.006485688893600312 | validation: 0.010162632905889693]
	TIME [epoch: 54.2 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009927157585000849		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.009927157585000849 | validation: 0.00986346885046643]
	TIME [epoch: 54.2 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006574718876545061		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.006574718876545061 | validation: 0.00963713371182361]
	TIME [epoch: 54.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005939390713652915		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.005939390713652915 | validation: 0.012147931076193837]
	TIME [epoch: 54.2 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0067071760463560575		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0067071760463560575 | validation: 0.008170467413898035]
	TIME [epoch: 54.2 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006670184847600944		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.006670184847600944 | validation: 0.007840227465905418]
	TIME [epoch: 54.2 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006646838508549426		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.006646838508549426 | validation: 0.00800482080295041]
	TIME [epoch: 54.2 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006588926092107134		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.006588926092107134 | validation: 0.011022779837697602]
	TIME [epoch: 54.2 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00673867589947638		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.00673867589947638 | validation: 0.008068017993439112]
	TIME [epoch: 54.2 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006095328677123769		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.006095328677123769 | validation: 0.008193592090668392]
	TIME [epoch: 54.2 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006402036901036754		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.006402036901036754 | validation: 0.0089500446879348]
	TIME [epoch: 54.2 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007253876475999474		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.007253876475999474 | validation: 0.007591637586731441]
	TIME [epoch: 54.2 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006398202300519503		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.006398202300519503 | validation: 0.008937671048351347]
	TIME [epoch: 54.2 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005784262581968274		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.005784262581968274 | validation: 0.007559068251070404]
	TIME [epoch: 54.2 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005741127760738107		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.005741127760738107 | validation: 0.007969773008553114]
	TIME [epoch: 54.2 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00621448347224212		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.00621448347224212 | validation: 0.009032621969119515]
	TIME [epoch: 54.2 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007374664723677729		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.007374664723677729 | validation: 0.009919419960608342]
	TIME [epoch: 54.2 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063585865543018495		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.0063585865543018495 | validation: 0.008217185723517498]
	TIME [epoch: 54.2 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006046326672529781		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.006046326672529781 | validation: 0.011096247072834955]
	TIME [epoch: 54.2 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070616754990075895		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.0070616754990075895 | validation: 0.00855948799683786]
	TIME [epoch: 54.2 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005796588892221406		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.005796588892221406 | validation: 0.008058942514024395]
	TIME [epoch: 54.2 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006731290626435376		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.006731290626435376 | validation: 0.007069146143949158]
	TIME [epoch: 54.2 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00704590029885767		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.00704590029885767 | validation: 0.0075611603457651725]
	TIME [epoch: 54.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006068686744641603		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.006068686744641603 | validation: 0.007678972640847147]
	TIME [epoch: 54.2 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006183659102406498		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.006183659102406498 | validation: 0.008613915360397899]
	TIME [epoch: 54.2 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0066081572879259165		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.0066081572879259165 | validation: 0.00790110000598732]
	TIME [epoch: 54.2 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005897354338269531		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.005897354338269531 | validation: 0.00849311329689165]
	TIME [epoch: 54.2 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059642550138145995		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.0059642550138145995 | validation: 0.007549667713586308]
	TIME [epoch: 54.2 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006637345474952319		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.006637345474952319 | validation: 0.008272585209443465]
	TIME [epoch: 54.2 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008529584505960981		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.008529584505960981 | validation: 0.010886689541190334]
	TIME [epoch: 54.2 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006937992231946648		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.006937992231946648 | validation: 0.007511468280825219]
	TIME [epoch: 54.2 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005979327026900413		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.005979327026900413 | validation: 0.007935281283826211]
	TIME [epoch: 54.2 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005780704497485963		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.005780704497485963 | validation: 0.007305746761940825]
	TIME [epoch: 54.2 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006366607714860037		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.006366607714860037 | validation: 0.007487746871299241]
	TIME [epoch: 54.2 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005891155576879908		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.005891155576879908 | validation: 0.007423562733265228]
	TIME [epoch: 54.2 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061482427356715896		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.0061482427356715896 | validation: 0.007786275710892273]
	TIME [epoch: 54.2 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006012124581474635		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.006012124581474635 | validation: 0.007916194636572048]
	TIME [epoch: 54.2 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005905333459515952		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.005905333459515952 | validation: 0.00836997486500297]
	TIME [epoch: 54.2 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007728442108190133		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.007728442108190133 | validation: 0.007784096922967952]
	TIME [epoch: 54.2 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008095447894320262		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.008095447894320262 | validation: 0.009317383844513215]
	TIME [epoch: 54.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0062846519316587645		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.0062846519316587645 | validation: 0.007543289734062673]
	TIME [epoch: 54.2 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005754914697100134		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.005754914697100134 | validation: 0.007947347672023309]
	TIME [epoch: 54.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006113664210533705		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.006113664210533705 | validation: 0.007476937501706669]
	TIME [epoch: 54.2 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006221293251023692		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.006221293251023692 | validation: 0.008916797667002218]
	TIME [epoch: 54.2 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006367811056390702		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.006367811056390702 | validation: 0.007000705392547931]
	TIME [epoch: 54.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005652721201072271		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.005652721201072271 | validation: 0.007826934339316673]
	TIME [epoch: 54.2 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00593426946491801		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.00593426946491801 | validation: 0.00770872684182271]
	TIME [epoch: 54.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006176472196401564		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.006176472196401564 | validation: 0.008101622482682893]
	TIME [epoch: 54.2 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006244018041586907		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.006244018041586907 | validation: 0.008088713440074394]
	TIME [epoch: 54.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058745829545095865		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.0058745829545095865 | validation: 0.008539981754308798]
	TIME [epoch: 54.2 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0061449284232438		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.0061449284232438 | validation: 0.009141805249129562]
	TIME [epoch: 54.2 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007795714058231129		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.007795714058231129 | validation: 0.007931887244179849]
	TIME [epoch: 54.2 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006271980837674376		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.006271980837674376 | validation: 0.00773086206657095]
	TIME [epoch: 54.2 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006102420455952762		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.006102420455952762 | validation: 0.007945670884856267]
	TIME [epoch: 54.2 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006821995077847905		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.006821995077847905 | validation: 0.00923541707613005]
	TIME [epoch: 54.2 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006156420720028799		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.006156420720028799 | validation: 0.008276437331758599]
	TIME [epoch: 54.2 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006236209670751659		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.006236209670751659 | validation: 0.00824242674373448]
	TIME [epoch: 54.2 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005833042113975716		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.005833042113975716 | validation: 0.006947829137654884]
	TIME [epoch: 54.2 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005404431017128125		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.005404431017128125 | validation: 0.008183355912196048]
	TIME [epoch: 54.2 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005535028915393264		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.005535028915393264 | validation: 0.01127362668911714]
	TIME [epoch: 54.2 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006461413067191604		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.006461413067191604 | validation: 0.00777942946653651]
	TIME [epoch: 54.2 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005704715085793399		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.005704715085793399 | validation: 0.007228595597477428]
	TIME [epoch: 54.2 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006271453613728705		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.006271453613728705 | validation: 0.013948143439412392]
	TIME [epoch: 54.2 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009146600062262042		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.009146600062262042 | validation: 0.00745891590112027]
	TIME [epoch: 54.2 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005859521760028366		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.005859521760028366 | validation: 0.007639860653316553]
	TIME [epoch: 54.2 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006001662448459472		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.006001662448459472 | validation: 0.007138513147595929]
	TIME [epoch: 54.2 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00586554845324951		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.00586554845324951 | validation: 0.007813916507771091]
	TIME [epoch: 54.2 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006186229930869973		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.006186229930869973 | validation: 0.007340333958920724]
	TIME [epoch: 54.2 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005943576492191766		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.005943576492191766 | validation: 0.008386119302663662]
	TIME [epoch: 54.2 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005960924548698937		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.005960924548698937 | validation: 0.007780436338144729]
	TIME [epoch: 54.2 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005871388695635926		[learning rate: 0.00019004]
	Learning Rate: 0.000190041
	LOSS [training: 0.005871388695635926 | validation: 0.0077671297364191715]
	TIME [epoch: 54.2 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0063922174645476915		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.0063922174645476915 | validation: 0.008567261205285991]
	TIME [epoch: 54.2 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007411556163863929		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.007411556163863929 | validation: 0.007617261314655311]
	TIME [epoch: 54.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055748453139603926		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.0055748453139603926 | validation: 0.00848089566920603]
	TIME [epoch: 54.2 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058408522245595364		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0058408522245595364 | validation: 0.006835907004182404]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1173.pth
	Model improved!!!
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006417855827296792		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.006417855827296792 | validation: 0.008166336905666371]
	TIME [epoch: 54.2 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057447224070118685		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.0057447224070118685 | validation: 0.007714888494817489]
	TIME [epoch: 54.2 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005941143166134531		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.005941143166134531 | validation: 0.007392129958261615]
	TIME [epoch: 54.2 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005879254882672854		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.005879254882672854 | validation: 0.00795742377258137]
	TIME [epoch: 54.2 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058776485463256116		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.0058776485463256116 | validation: 0.007189936570165861]
	TIME [epoch: 54.2 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005597499127183731		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.005597499127183731 | validation: 0.007839661296757193]
	TIME [epoch: 54.2 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059552488579790435		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.0059552488579790435 | validation: 0.011728571599852909]
	TIME [epoch: 54.2 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065955065534139806		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.0065955065534139806 | validation: 0.009110172080397013]
	TIME [epoch: 54.2 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00604404826325001		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.00604404826325001 | validation: 0.007863519702110827]
	TIME [epoch: 54.2 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005350779640166094		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.005350779640166094 | validation: 0.007186191232977617]
	TIME [epoch: 54.2 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006156569078729237		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.006156569078729237 | validation: 0.007570348604373696]
	TIME [epoch: 54.2 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057415942438653455		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.0057415942438653455 | validation: 0.008901560056428285]
	TIME [epoch: 54.2 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005508612977875112		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.005508612977875112 | validation: 0.007950304367776096]
	TIME [epoch: 54.2 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006219970650524249		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.006219970650524249 | validation: 0.006919884193565799]
	TIME [epoch: 54.2 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006418794232585082		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.006418794232585082 | validation: 0.009927450644633299]
	TIME [epoch: 54.2 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006808102548604916		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.006808102548604916 | validation: 0.00786636977090326]
	TIME [epoch: 54.2 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005851730715710933		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.005851730715710933 | validation: 0.008162406589356668]
	TIME [epoch: 54.2 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005619663178682621		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.005619663178682621 | validation: 0.007557978776801935]
	TIME [epoch: 54.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005908432916150776		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.005908432916150776 | validation: 0.007260497022784149]
	TIME [epoch: 54.2 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005872415530799303		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.005872415530799303 | validation: 0.009070108803518722]
	TIME [epoch: 54.2 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005859461577766625		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.005859461577766625 | validation: 0.008122586829008294]
	TIME [epoch: 54.2 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057583051834566535		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.0057583051834566535 | validation: 0.008133660851289167]
	TIME [epoch: 54.2 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00541238221865954		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.00541238221865954 | validation: 0.007762277875036888]
	TIME [epoch: 54.2 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0058710247803901985		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.0058710247803901985 | validation: 0.006409085501705478]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1197.pth
	Model improved!!!
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005532970565215811		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.005532970565215811 | validation: 0.012321015642884747]
	TIME [epoch: 54.2 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006591721188892419		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.006591721188892419 | validation: 0.0081000164013867]
	TIME [epoch: 54.2 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005851573104883609		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.005851573104883609 | validation: 0.008290673126227405]
	TIME [epoch: 54.2 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005328356863961556		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.005328356863961556 | validation: 0.0070920427052425985]
	TIME [epoch: 54.2 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00587352556606021		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.00587352556606021 | validation: 0.008559386298604412]
	TIME [epoch: 54.4 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006559170069335574		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.006559170069335574 | validation: 0.00939262861190011]
	TIME [epoch: 54.4 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006023768838425884		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.006023768838425884 | validation: 0.0079032077898333]
	TIME [epoch: 54.4 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005373628955829492		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.005373628955829492 | validation: 0.007654083512557256]
	TIME [epoch: 54.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005473797130243917		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.005473797130243917 | validation: 0.007500031994797904]
	TIME [epoch: 54.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005601046532377514		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.005601046532377514 | validation: 0.007978814316832419]
	TIME [epoch: 54.2 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005256578912672822		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.005256578912672822 | validation: 0.00801643512452388]
	TIME [epoch: 54.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005936450945697168		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.005936450945697168 | validation: 0.00744482185385798]
	TIME [epoch: 54.2 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005484076758308204		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.005484076758308204 | validation: 0.009892177168289357]
	TIME [epoch: 54.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006119791964261423		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.006119791964261423 | validation: 0.008224160534940683]
	TIME [epoch: 54.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006548197368081386		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.006548197368081386 | validation: 0.008583214137448714]
	TIME [epoch: 54.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008424323967792519		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.008424323967792519 | validation: 0.008162198855391108]
	TIME [epoch: 54.2 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005873495168647382		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.005873495168647382 | validation: 0.008201597536509316]
	TIME [epoch: 54.2 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005526108150456582		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.005526108150456582 | validation: 0.007319853462229749]
	TIME [epoch: 54.2 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005479405933259324		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.005479405933259324 | validation: 0.007884130895190307]
	TIME [epoch: 54.2 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006124734868276403		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.006124734868276403 | validation: 0.007312125857737821]
	TIME [epoch: 54.2 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005258733500894356		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.005258733500894356 | validation: 0.007905129582507584]
	TIME [epoch: 54.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00580773042709482		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.00580773042709482 | validation: 0.009251267030439722]
	TIME [epoch: 54.2 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060942772860107745		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.0060942772860107745 | validation: 0.007567509981337034]
	TIME [epoch: 54.2 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005778351303520673		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.005778351303520673 | validation: 0.00958990247195083]
	TIME [epoch: 54.2 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006076343700619511		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.006076343700619511 | validation: 0.007211373955718758]
	TIME [epoch: 54.2 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055466682819318375		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0055466682819318375 | validation: 0.007173525407267934]
	TIME [epoch: 54.2 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005766619614921586		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.005766619614921586 | validation: 0.007636324510056247]
	TIME [epoch: 54.2 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00549300413691748		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.00549300413691748 | validation: 0.008310484720055659]
	TIME [epoch: 54.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005796041182342151		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.005796041182342151 | validation: 0.006782473060675313]
	TIME [epoch: 54.2 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005434091902768534		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.005434091902768534 | validation: 0.007006524477825996]
	TIME [epoch: 54.2 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005526668929420288		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.005526668929420288 | validation: 0.00771258972190271]
	TIME [epoch: 54.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065353295288644395		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.0065353295288644395 | validation: 0.006594536258227068]
	TIME [epoch: 54.2 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005365018402472391		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.005365018402472391 | validation: 0.007283539124258906]
	TIME [epoch: 54.2 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005565437470190128		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.005565437470190128 | validation: 0.007424418586552103]
	TIME [epoch: 54.2 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005429654284979141		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.005429654284979141 | validation: 0.0073967144476944705]
	TIME [epoch: 54.2 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006048096742336092		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.006048096742336092 | validation: 0.0070493587016272515]
	TIME [epoch: 54.2 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0057521355301542385		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.0057521355301542385 | validation: 0.007021636781275179]
	TIME [epoch: 54.2 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005196270270234411		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.005196270270234411 | validation: 0.00731000733578472]
	TIME [epoch: 54.2 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00516610795495178		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.00516610795495178 | validation: 0.00750560295533248]
	TIME [epoch: 54.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005322150574138592		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.005322150574138592 | validation: 0.006740332731353877]
	TIME [epoch: 54.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00562826265397027		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.00562826265397027 | validation: 0.006648335540137615]
	TIME [epoch: 54.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005531265560710581		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.005531265560710581 | validation: 0.009296389419133268]
	TIME [epoch: 54.2 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0059033723952744655		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.0059033723952744655 | validation: 0.008065841455465749]
	TIME [epoch: 54.4 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005560937110847954		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.005560937110847954 | validation: 0.008252338744170832]
	TIME [epoch: 54.4 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005571782637583706		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.005571782637583706 | validation: 0.007637286023027004]
	TIME [epoch: 54.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005004585961327455		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.005004585961327455 | validation: 0.008066167035092817]
	TIME [epoch: 54.4 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053027737885035005		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.0053027737885035005 | validation: 0.007712769912797367]
	TIME [epoch: 54.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00489158197537557		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.00489158197537557 | validation: 0.008109930970820748]
	TIME [epoch: 54.4 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0060506828362130415		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.0060506828362130415 | validation: 0.008320164722711782]
	TIME [epoch: 54.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005467576859517648		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.005467576859517648 | validation: 0.006664255413981522]
	TIME [epoch: 54.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055610512222619216		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.0055610512222619216 | validation: 0.006715527095449699]
	TIME [epoch: 54.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056226670590766034		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0056226670590766034 | validation: 0.008027633963944838]
	TIME [epoch: 54.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00514401707866412		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.00514401707866412 | validation: 0.008267148851851706]
	TIME [epoch: 54.2 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005883057693808679		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.005883057693808679 | validation: 0.007728783437635393]
	TIME [epoch: 54.4 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005531130926899037		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.005531130926899037 | validation: 0.007841099157813928]
	TIME [epoch: 54.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005500094820281586		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.005500094820281586 | validation: 0.006696555023855433]
	TIME [epoch: 54.2 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005439950847562798		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.005439950847562798 | validation: 0.00876464867251854]
	TIME [epoch: 54.2 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006202068407700516		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.006202068407700516 | validation: 0.007969525740193521]
	TIME [epoch: 54.2 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005239001929173151		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.005239001929173151 | validation: 0.006903823387625568]
	TIME [epoch: 54.2 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005530668849276387		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.005530668849276387 | validation: 0.0071864223617696]
	TIME [epoch: 54.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006171301344314321		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.006171301344314321 | validation: 0.007390738972786262]
	TIME [epoch: 54.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005370198914130781		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.005370198914130781 | validation: 0.007275442949718475]
	TIME [epoch: 54.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005416662204417875		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.005416662204417875 | validation: 0.007898821486189225]
	TIME [epoch: 54.2 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056282701382268496		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.0056282701382268496 | validation: 0.0063802983767767135]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1261.pth
	Model improved!!!
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005953748013219751		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.005953748013219751 | validation: 0.007386703145985003]
	TIME [epoch: 54.2 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005426581665818655		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.005426581665818655 | validation: 0.007225411063550511]
	TIME [epoch: 54.2 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005899741938533983		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.005899741938533983 | validation: 0.008333419519962628]
	TIME [epoch: 54.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005914575400827874		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.005914575400827874 | validation: 0.008153674543227768]
	TIME [epoch: 54.2 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055684450820585926		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.0055684450820585926 | validation: 0.007389518908287309]
	TIME [epoch: 54.2 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005393941994038746		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.005393941994038746 | validation: 0.007164124767742726]
	TIME [epoch: 54.2 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005181182868262467		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.005181182868262467 | validation: 0.007864453883879578]
	TIME [epoch: 54.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005480126023418446		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.005480126023418446 | validation: 0.007435773929065439]
	TIME [epoch: 54.2 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00532219652310177		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.00532219652310177 | validation: 0.007401669449386568]
	TIME [epoch: 54.4 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005280304961806967		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.005280304961806967 | validation: 0.007763206147739128]
	TIME [epoch: 54.2 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005547277545786644		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.005547277545786644 | validation: 0.007330929540383016]
	TIME [epoch: 54.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005428851862312841		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.005428851862312841 | validation: 0.007227935537515975]
	TIME [epoch: 54.2 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005248881115345502		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.005248881115345502 | validation: 0.006637845022634624]
	TIME [epoch: 54.2 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005419843236136609		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.005419843236136609 | validation: 0.006660712939844098]
	TIME [epoch: 54.2 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005577452594066396		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.005577452594066396 | validation: 0.0076910786017115335]
	TIME [epoch: 54.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005084219110638006		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.005084219110638006 | validation: 0.007879949539428714]
	TIME [epoch: 54.3 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005836474325340834		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.005836474325340834 | validation: 0.007174724576437428]
	TIME [epoch: 54.2 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052207909069644206		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.0052207909069644206 | validation: 0.00802646382400049]
	TIME [epoch: 54.2 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005283634347149884		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.005283634347149884 | validation: 0.0075156147513004866]
	TIME [epoch: 54.2 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005212773250211402		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.005212773250211402 | validation: 0.0070951078142338486]
	TIME [epoch: 54.2 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005365989703064868		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.005365989703064868 | validation: 0.007226887317804963]
	TIME [epoch: 54.2 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00611013943725749		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.00611013943725749 | validation: 0.007779716925822111]
	TIME [epoch: 54.2 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005365181836782658		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.005365181836782658 | validation: 0.006425483308677085]
	TIME [epoch: 54.2 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005428132563205528		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.005428132563205528 | validation: 0.008358458685900336]
	TIME [epoch: 54.2 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005862779460282747		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.005862779460282747 | validation: 0.0076286933363385575]
	TIME [epoch: 54.2 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005524983648000616		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.005524983648000616 | validation: 0.00772837763470645]
	TIME [epoch: 54.2 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005272748725171706		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.005272748725171706 | validation: 0.007413973771641236]
	TIME [epoch: 54.2 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00513104907959548		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.00513104907959548 | validation: 0.006712766021348429]
	TIME [epoch: 54.2 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005571843619845		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.005571843619845 | validation: 0.008087714162034944]
	TIME [epoch: 54.2 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005364526608518403		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.005364526608518403 | validation: 0.008396133294561084]
	TIME [epoch: 54.2 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005101146875013553		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.005101146875013553 | validation: 0.007261063457364853]
	TIME [epoch: 54.2 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005667894513215159		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.005667894513215159 | validation: 0.008118686075280218]
	TIME [epoch: 54.2 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005936155796950942		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.005936155796950942 | validation: 0.007600203440008578]
	TIME [epoch: 54.2 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005807486660857459		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.005807486660857459 | validation: 0.0065188571407759415]
	TIME [epoch: 54.2 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005054100721736634		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.005054100721736634 | validation: 0.007821107840148084]
	TIME [epoch: 54.2 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005300241300144606		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.005300241300144606 | validation: 0.007452099337071895]
	TIME [epoch: 54.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005251823256245068		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.005251823256245068 | validation: 0.007859812925304119]
	TIME [epoch: 54.2 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005171241760099014		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.005171241760099014 | validation: 0.007380334112422662]
	TIME [epoch: 54.2 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005323994044621225		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.005323994044621225 | validation: 0.007542205554177662]
	TIME [epoch: 54.2 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005540003530793586		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.005540003530793586 | validation: 0.007537130178437647]
	TIME [epoch: 54.2 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005145035951196368		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.005145035951196368 | validation: 0.007335629335047955]
	TIME [epoch: 54.2 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005254017837607578		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.005254017837607578 | validation: 0.006817020108369538]
	TIME [epoch: 54.2 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004999133295951117		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.004999133295951117 | validation: 0.007661505884526265]
	TIME [epoch: 54.2 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006075434746886818		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.006075434746886818 | validation: 0.006705948594537197]
	TIME [epoch: 54.2 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005098069922041261		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.005098069922041261 | validation: 0.007320564031990551]
	TIME [epoch: 54.2 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005469042817495234		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.005469042817495234 | validation: 0.006869375292028877]
	TIME [epoch: 54.2 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005141670945582977		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.005141670945582977 | validation: 0.00716178445873052]
	TIME [epoch: 54.2 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005142207823432718		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.005142207823432718 | validation: 0.0066898887273461605]
	TIME [epoch: 54.2 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00511053987182194		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.00511053987182194 | validation: 0.00647158642945603]
	TIME [epoch: 54.2 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006561509695862		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.006561509695862 | validation: 0.006817125367555915]
	TIME [epoch: 54.2 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005516536479166155		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.005516536479166155 | validation: 0.007228703263490437]
	TIME [epoch: 54.2 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005211567774333308		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.005211567774333308 | validation: 0.007222256248270864]
	TIME [epoch: 54.2 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005156994082032879		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.005156994082032879 | validation: 0.007227430553467419]
	TIME [epoch: 54.2 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005076505319659865		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.005076505319659865 | validation: 0.007083907446567863]
	TIME [epoch: 54.2 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005303562821571072		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.005303562821571072 | validation: 0.0076638212120522554]
	TIME [epoch: 54.2 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005439278820931316		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.005439278820931316 | validation: 0.007048718486330957]
	TIME [epoch: 54.2 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005308183541704891		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.005308183541704891 | validation: 0.007719652817450264]
	TIME [epoch: 54.2 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052846901394910245		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.0052846901394910245 | validation: 0.00801635465789116]
	TIME [epoch: 54.2 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005607378734840459		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.005607378734840459 | validation: 0.00809182565177408]
	TIME [epoch: 54.2 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005318762127266054		[learning rate: 0.00011092]
	Learning Rate: 0.000110917
	LOSS [training: 0.005318762127266054 | validation: 0.007570653538730818]
	TIME [epoch: 54.2 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005110178778112354		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.005110178778112354 | validation: 0.007557222222119516]
	TIME [epoch: 54.2 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005476933204083337		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.005476933204083337 | validation: 0.007609139406289612]
	TIME [epoch: 54.2 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053726306592448364		[learning rate: 0.00010974]
	Learning Rate: 0.000109745
	LOSS [training: 0.0053726306592448364 | validation: 0.007055686161520986]
	TIME [epoch: 54.2 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004843067199834885		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.004843067199834885 | validation: 0.006266341900601747]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1325.pth
	Model improved!!!
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004942721121467686		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.004942721121467686 | validation: 0.007559735845417996]
	TIME [epoch: 54.2 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005565467993573579		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.005565467993573579 | validation: 0.007430949266397898]
	TIME [epoch: 54.2 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005253604536469911		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.005253604536469911 | validation: 0.007410471085676159]
	TIME [epoch: 54.2 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055634496955465525		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.0055634496955465525 | validation: 0.008623897845719097]
	TIME [epoch: 54.2 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005312227539808546		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.005312227539808546 | validation: 0.007180398836239492]
	TIME [epoch: 54.2 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005149981216588743		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.005149981216588743 | validation: 0.006828853763708233]
	TIME [epoch: 54.2 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005072949372354167		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.005072949372354167 | validation: 0.007596645249368686]
	TIME [epoch: 54.2 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005462861368255477		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.005462861368255477 | validation: 0.006733994547903259]
	TIME [epoch: 54.2 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005329549879213446		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.005329549879213446 | validation: 0.007094259880960702]
	TIME [epoch: 54.2 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004716711377540517		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.004716711377540517 | validation: 0.007224144023828898]
	TIME [epoch: 54.2 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053722918901412155		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.0053722918901412155 | validation: 0.007605743354311677]
	TIME [epoch: 54.2 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005105254815091594		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.005105254815091594 | validation: 0.006870866048679432]
	TIME [epoch: 54.2 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005453914471971752		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.005453914471971752 | validation: 0.006849710547847273]
	TIME [epoch: 54.2 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005127417997781209		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.005127417997781209 | validation: 0.008046356353511407]
	TIME [epoch: 54.2 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004991698873974414		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.004991698873974414 | validation: 0.007799503327759135]
	TIME [epoch: 54.2 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005742329235481168		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.005742329235481168 | validation: 0.008542033775609512]
	TIME [epoch: 54.2 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00514225841775369		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.00514225841775369 | validation: 0.006320586277879655]
	TIME [epoch: 54.2 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005135723809040519		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.005135723809040519 | validation: 0.00800518511026085]
	TIME [epoch: 54.2 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053450913522679906		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.0053450913522679906 | validation: 0.008024537012602473]
	TIME [epoch: 54.2 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005032787232971535		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.005032787232971535 | validation: 0.0064058137790725]
	TIME [epoch: 54.2 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004883680211509669		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.004883680211509669 | validation: 0.006994598145237911]
	TIME [epoch: 54.2 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005318824771709473		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.005318824771709473 | validation: 0.007311746482465521]
	TIME [epoch: 54.2 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0055608483508536545		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.0055608483508536545 | validation: 0.006749689161244266]
	TIME [epoch: 54.2 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005124225899161843		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.005124225899161843 | validation: 0.007799376594992989]
	TIME [epoch: 54.2 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005071035570805644		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.005071035570805644 | validation: 0.007543723792129114]
	TIME [epoch: 54.2 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005174169842386068		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.005174169842386068 | validation: 0.007979320940436232]
	TIME [epoch: 54.2 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005392788845802427		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.005392788845802427 | validation: 0.005811489805375226]
	TIME [epoch: 54.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_4_v_mmd1_20250602_170520/states/model_phi1_1a_distortion_v2r_4_v_mmd1_1352.pth
	Model improved!!!
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005500978751425032		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.005500978751425032 | validation: 0.0067858869777589126]
	TIME [epoch: 54.2 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005083697850291691		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.005083697850291691 | validation: 0.007301342935781347]
	TIME [epoch: 54.2 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005033711612239555		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.005033711612239555 | validation: 0.007107023191996461]
	TIME [epoch: 54.2 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051961627956897335		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0051961627956897335 | validation: 0.00654780627311036]
	TIME [epoch: 54.2 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0054485207178407635		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.0054485207178407635 | validation: 0.006191300025681103]
	TIME [epoch: 54.2 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005367436706278354		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.005367436706278354 | validation: 0.007832654851856528]
	TIME [epoch: 54.2 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005212940758095161		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.005212940758095161 | validation: 0.00889747438901955]
	TIME [epoch: 54.2 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005805059881094032		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.005805059881094032 | validation: 0.00796586877236558]
	TIME [epoch: 54.2 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050622395682888505		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.0050622395682888505 | validation: 0.0065840291493444005]
	TIME [epoch: 54.2 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006344294849889051		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.006344294849889051 | validation: 0.006807267738248208]
	TIME [epoch: 54.2 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005244223299551613		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.005244223299551613 | validation: 0.006870688130885989]
	TIME [epoch: 54.2 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005125215473120776		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.005125215473120776 | validation: 0.007939262139966378]
	TIME [epoch: 54.2 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004875769272123858		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.004875769272123858 | validation: 0.007353802512710759]
	TIME [epoch: 54.2 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005005479747278108		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.005005479747278108 | validation: 0.0069436461099266576]
	TIME [epoch: 54.2 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004944540669415172		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.004944540669415172 | validation: 0.006621060455368877]
	TIME [epoch: 54.2 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004816160432787618		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.004816160432787618 | validation: 0.007765245084888685]
	TIME [epoch: 54.2 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004770056203540405		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.004770056203540405 | validation: 0.006999114206170193]
	TIME [epoch: 54.2 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004937142847911879		[learning rate: 9.3243e-05]
	Learning Rate: 9.32429e-05
	LOSS [training: 0.004937142847911879 | validation: 0.007224210779411716]
	TIME [epoch: 54.2 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005230824468837641		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.005230824468837641 | validation: 0.007121060820822572]
	TIME [epoch: 54.2 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005315617266704867		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.005315617266704867 | validation: 0.007348838226370217]
	TIME [epoch: 54.2 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005576100258680555		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.005576100258680555 | validation: 0.00728926406510934]
	TIME [epoch: 54.2 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050368172478439345		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.0050368172478439345 | validation: 0.007784067606992533]
	TIME [epoch: 54.2 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00515625830298078		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.00515625830298078 | validation: 0.007113752746797333]
	TIME [epoch: 54.2 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00485047264239921		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.00485047264239921 | validation: 0.006386236556892954]
	TIME [epoch: 54.2 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004981770221549976		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.004981770221549976 | validation: 0.007278063081255101]
	TIME [epoch: 54.2 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005260787812436736		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.005260787812436736 | validation: 0.006961361922149264]
	TIME [epoch: 54.2 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005048757491146605		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.005048757491146605 | validation: 0.006722785526757957]
	TIME [epoch: 54.2 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004480527778688856		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.004480527778688856 | validation: 0.0063658962697815]
	TIME [epoch: 54.2 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005293628657832843		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.005293628657832843 | validation: 0.006622146413417525]
	TIME [epoch: 54.2 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005313120634451795		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.005313120634451795 | validation: 0.006409714555992945]
	TIME [epoch: 54.2 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0052362450766121355		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.0052362450766121355 | validation: 0.00654051770406207]
	TIME [epoch: 54.2 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005196840093517247		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.005196840093517247 | validation: 0.006811863591279612]
	TIME [epoch: 54.2 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004983429586425458		[learning rate: 8.8418e-05]
	Learning Rate: 8.84176e-05
	LOSS [training: 0.004983429586425458 | validation: 0.007462996843964735]
	TIME [epoch: 54.2 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050319275388787535		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.0050319275388787535 | validation: 0.006777412648627232]
	TIME [epoch: 54.2 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004778642242653279		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.004778642242653279 | validation: 0.006740738308897068]
	TIME [epoch: 54.2 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005023120938915024		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.005023120938915024 | validation: 0.006638434476822241]
	TIME [epoch: 54.2 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005542356356977243		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.005542356356977243 | validation: 0.007214292469977038]
	TIME [epoch: 54.2 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00504152889597732		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.00504152889597732 | validation: 0.0073107007071468895]
	TIME [epoch: 54.2 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005205295089848239		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.005205295089848239 | validation: 0.006807949999065869]
	TIME [epoch: 54.2 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004919044508650485		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.004919044508650485 | validation: 0.006122590928365764]
	TIME [epoch: 54.2 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004798612812388011		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.004798612812388011 | validation: 0.006940589154282936]
	TIME [epoch: 54.2 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005091002154943372		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.005091002154943372 | validation: 0.006817565055350049]
	TIME [epoch: 54.2 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004934935551085454		[learning rate: 8.534e-05]
	Learning Rate: 8.53403e-05
	LOSS [training: 0.004934935551085454 | validation: 0.007498437554273895]
	TIME [epoch: 54.2 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005310103374261902		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.005310103374261902 | validation: 0.00804329523138408]
	TIME [epoch: 54.2 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005070832962288185		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.005070832962288185 | validation: 0.007065643367647973]
	TIME [epoch: 54.2 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005110288678936925		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.005110288678936925 | validation: 0.007051498480853685]
	TIME [epoch: 54.2 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048997262211616		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.0048997262211616 | validation: 0.007849102191005146]
	TIME [epoch: 54.2 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005585461726298584		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.005585461726298584 | validation: 0.006698421354352587]
	TIME [epoch: 54.2 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004859354295013658		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.004859354295013658 | validation: 0.008269997292248952]
	TIME [epoch: 54.2 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004973652032897746		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.004973652032897746 | validation: 0.006824343922126143]
	TIME [epoch: 54.2 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050599004664267175		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.0050599004664267175 | validation: 0.007631299582289025]
	TIME [epoch: 54.2 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005021601062955108		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.005021601062955108 | validation: 0.007580410061139244]
	TIME [epoch: 54.2 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00482184262595017		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.00482184262595017 | validation: 0.006984617787831856]
	TIME [epoch: 54.2 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004758609164168172		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.004758609164168172 | validation: 0.007787767042512975]
	TIME [epoch: 54.2 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004700907882696816		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.004700907882696816 | validation: 0.006626857184579817]
	TIME [epoch: 54.2 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0049975126845628335		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.0049975126845628335 | validation: 0.006759299794393423]
	TIME [epoch: 54.2 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005073971527155992		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.005073971527155992 | validation: 0.007021638468298489]
	TIME [epoch: 54.2 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00468778871383386		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.00468778871383386 | validation: 0.007549318077380656]
	TIME [epoch: 54.2 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004853075261151075		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.004853075261151075 | validation: 0.007594916988629593]
	TIME [epoch: 54.2 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005049093308823687		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.005049093308823687 | validation: 0.007686245598127578]
	TIME [epoch: 54.2 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005184436754886517		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.005184436754886517 | validation: 0.007321023040402828]
	TIME [epoch: 54.2 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005017287593374282		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.005017287593374282 | validation: 0.006693815570464703]
	TIME [epoch: 54.2 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004807644672385679		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.004807644672385679 | validation: 0.007015302851809957]
	TIME [epoch: 54.2 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004988928448271323		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.004988928448271323 | validation: 0.006963694093380098]
	TIME [epoch: 54.2 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048842231471672055		[learning rate: 7.8942e-05]
	Learning Rate: 7.89419e-05
	LOSS [training: 0.0048842231471672055 | validation: 0.007119302206436201]
	TIME [epoch: 54.2 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005083027792433324		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.005083027792433324 | validation: 0.007226453675402342]
	TIME [epoch: 54.2 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004794870117202289		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.004794870117202289 | validation: 0.006500045823116439]
	TIME [epoch: 54.2 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004948626358541517		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.004948626358541517 | validation: 0.0068900507850739165]
	TIME [epoch: 54.2 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004982219815708087		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.004982219815708087 | validation: 0.006585506397221472]
	TIME [epoch: 54.2 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004855767144826526		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.004855767144826526 | validation: 0.006513054031460547]
	TIME [epoch: 54.2 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050255118810132084		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0050255118810132084 | validation: 0.006782049019194287]
	TIME [epoch: 54.2 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00479854893186463		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.00479854893186463 | validation: 0.006176715083420971]
	TIME [epoch: 54.2 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045741604994581474		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.0045741604994581474 | validation: 0.006122479760818224]
	TIME [epoch: 54.2 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005097374178507234		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.005097374178507234 | validation: 0.007570744838989009]
	TIME [epoch: 54.2 sec]
EPOCH 1427/2000:
	Training over batches...
