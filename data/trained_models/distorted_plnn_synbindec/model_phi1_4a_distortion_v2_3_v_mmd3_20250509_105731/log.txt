Args:
Namespace(name='model_phi1_4a_distortion_v2_3_v_mmd3', outdir='out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3', training_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_3/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_4a_distortion_v2_3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.020969864, 0.1, 1.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4122409703

Training model...

Saving initial model state to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.011528643072418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.011528643072418 | validation: 2.9615432035182536]
	TIME [epoch: 124 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7753322404926544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7753322404926544 | validation: 3.0082025145694864]
	TIME [epoch: 0.483 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.35069946010319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.35069946010319 | validation: 2.7391877433899765]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.876945282090471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.876945282090471 | validation: 2.7910910283523083]
	TIME [epoch: 0.477 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7799695296375186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7799695296375186 | validation: 2.662578566865284]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6852548526033626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6852548526033626 | validation: 2.6025880631187905]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5786192695890655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5786192695890655 | validation: 2.5254910264448944]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.435079850224747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.435079850224747 | validation: 2.447782602816642]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3838195434885865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3838195434885865 | validation: 2.4340733166432944]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3252491555724375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3252491555724375 | validation: 2.401815753081772]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2825072873912045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2825072873912045 | validation: 2.30192172161612]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2438815381540747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2438815381540747 | validation: 2.2711234313061053]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1966332093037817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1966332093037817 | validation: 2.2814604962078575]
	TIME [epoch: 0.475 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1672328340126383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1672328340126383 | validation: 2.1567966474892004]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.127119505012098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.127119505012098 | validation: 2.0705895157042926]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.09730556233224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.09730556233224 | validation: 2.1709909656797577]
	TIME [epoch: 0.474 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0669932833283213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0669932833283213 | validation: 2.0869317925976283]
	TIME [epoch: 0.473 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.02302365939881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.02302365939881 | validation: 2.038309056682362]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9813326368362305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9813326368362305 | validation: 1.9539742257253108]
	TIME [epoch: 0.477 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9394023553947828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9394023553947828 | validation: 1.841521958038065]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9220456800793495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9220456800793495 | validation: 2.0966763158024335]
	TIME [epoch: 0.475 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0218743295003274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0218743295003274 | validation: 2.0964431235637826]
	TIME [epoch: 0.474 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.0375486795869597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0375486795869597 | validation: 1.9041296125341163]
	TIME [epoch: 0.475 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8763482373589724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8763482373589724 | validation: 1.7512346227341054]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9090329250368925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9090329250368925 | validation: 1.8011018103160392]
	TIME [epoch: 0.475 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.8259609021919119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8259609021919119 | validation: 1.764791655214902]
	TIME [epoch: 0.475 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7759893238960291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7759893238960291 | validation: 1.759738213362918]
	TIME [epoch: 0.474 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7705668562374672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7705668562374672 | validation: 1.6381658815284663]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.71393005763318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.71393005763318 | validation: 1.5228264117286499]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.676188299714342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.676188299714342 | validation: 1.530938432871969]
	TIME [epoch: 0.474 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6625318977228116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6625318977228116 | validation: 1.5691854237305969]
	TIME [epoch: 0.473 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.674691987229449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.674691987229449 | validation: 1.572840263386948]
	TIME [epoch: 0.472 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6840642461474318		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6840642461474318 | validation: 1.6018310872592545]
	TIME [epoch: 0.473 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.659880461443407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.659880461443407 | validation: 1.4302502634593628]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5861617527948932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5861617527948932 | validation: 1.3352382496352364]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.584559652964137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.584559652964137 | validation: 1.5384586012748382]
	TIME [epoch: 0.475 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6240313647299325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6240313647299325 | validation: 1.441303453866729]
	TIME [epoch: 0.48 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5376349415266057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5376349415266057 | validation: 1.38442402963976]
	TIME [epoch: 0.474 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5396800309707193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5396800309707193 | validation: 1.505351603732759]
	TIME [epoch: 0.472 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5892278482341222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5892278482341222 | validation: 1.38348391766407]
	TIME [epoch: 0.472 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4998314097208236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4998314097208236 | validation: 1.4214145335652024]
	TIME [epoch: 0.473 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5515963651393703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5515963651393703 | validation: 1.5085244918827383]
	TIME [epoch: 0.473 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5704063465088427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5704063465088427 | validation: 1.3965635847620486]
	TIME [epoch: 0.472 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4971508053232037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4971508053232037 | validation: 1.408651372116951]
	TIME [epoch: 0.471 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4993077942298088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4993077942298088 | validation: 1.3944052606024475]
	TIME [epoch: 0.471 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.474947907803603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.474947907803603 | validation: 1.330321716852015]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4552432452687274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4552432452687274 | validation: 1.350119907860286]
	TIME [epoch: 0.475 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4465368337918074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4465368337918074 | validation: 1.3417723505067873]
	TIME [epoch: 0.473 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4425476996344737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4425476996344737 | validation: 1.3363856818883697]
	TIME [epoch: 0.474 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4428533642669887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4428533642669887 | validation: 1.3327604755589162]
	TIME [epoch: 0.473 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4406820851803823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4406820851803823 | validation: 1.3353145119154923]
	TIME [epoch: 0.472 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4334192963326626		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 1.4334192963326626 | validation: 1.3766917233978218]
	TIME [epoch: 0.474 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.440089304309836		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 1.440089304309836 | validation: 1.313026383924174]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.43592797850128		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 1.43592797850128 | validation: 1.3989299583528683]
	TIME [epoch: 0.476 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4472243924294643		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 1.4472243924294643 | validation: 1.2672275705699363]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.452043168110014		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 1.452043168110014 | validation: 1.4039125063232882]
	TIME [epoch: 0.474 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4502684793604488		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 1.4502684793604488 | validation: 1.3072348852243405]
	TIME [epoch: 0.476 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4205378060463256		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 1.4205378060463256 | validation: 1.343254400568776]
	TIME [epoch: 0.478 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.418548898008521		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 1.418548898008521 | validation: 1.3433498304494607]
	TIME [epoch: 0.475 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4187920640832163		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 1.4187920640832163 | validation: 1.2970449911738506]
	TIME [epoch: 0.473 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.418392865721869		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 1.418392865721869 | validation: 1.3802147612970126]
	TIME [epoch: 0.473 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4176585099791164		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 1.4176585099791164 | validation: 1.2579970531602225]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4294239432571385		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 1.4294239432571385 | validation: 1.3898701884070555]
	TIME [epoch: 0.475 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4215961569764806		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 1.4215961569764806 | validation: 1.301485547608138]
	TIME [epoch: 0.474 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4056320658388586		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 1.4056320658388586 | validation: 1.3517845219724771]
	TIME [epoch: 0.474 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3981747885766251		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 1.3981747885766251 | validation: 1.2983492898151259]
	TIME [epoch: 0.473 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.398479766971048		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 1.398479766971048 | validation: 1.387457392558622]
	TIME [epoch: 0.472 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.407705912902293		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 1.407705912902293 | validation: 1.2151208546296044]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.432129671150492		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 1.432129671150492 | validation: 1.442489954854644]
	TIME [epoch: 0.477 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.445780158381276		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 1.445780158381276 | validation: 1.318211802600501]
	TIME [epoch: 0.475 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3845148680890202		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 1.3845148680890202 | validation: 1.2685689587714943]
	TIME [epoch: 0.473 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4016423774160165		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 1.4016423774160165 | validation: 1.3995183865945902]
	TIME [epoch: 0.472 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4123983133132745		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 1.4123983133132745 | validation: 1.3105586000593927]
	TIME [epoch: 0.474 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.370920948987058		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 1.370920948987058 | validation: 1.2890032191375562]
	TIME [epoch: 0.473 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.377811690683854		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 1.377811690683854 | validation: 1.3862212733295536]
	TIME [epoch: 0.473 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3910028999999626		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 1.3910028999999626 | validation: 1.2470052957603652]
	TIME [epoch: 0.472 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.374795798217075		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 1.374795798217075 | validation: 1.381283277535358]
	TIME [epoch: 0.472 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3789795960412767		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 1.3789795960412767 | validation: 1.2408394386308523]
	TIME [epoch: 0.473 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3719537661192711		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 1.3719537661192711 | validation: 1.396880517487475]
	TIME [epoch: 0.474 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3732179588940152		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 1.3732179588940152 | validation: 1.2253806946081536]
	TIME [epoch: 0.473 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.374899120669811		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 1.374899120669811 | validation: 1.3986264165656352]
	TIME [epoch: 0.472 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.369370403697963		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 1.369370403697963 | validation: 1.2784088327200527]
	TIME [epoch: 0.472 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3387609435578491		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 1.3387609435578491 | validation: 1.3331106869846923]
	TIME [epoch: 0.472 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3207002142327053		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 1.3207002142327053 | validation: 1.2925843329657396]
	TIME [epoch: 0.473 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3115861109981768		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 1.3115861109981768 | validation: 1.3785347676251396]
	TIME [epoch: 0.472 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.31123375347069		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 1.31123375347069 | validation: 1.2222515134048484]
	TIME [epoch: 0.472 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4194845928986632		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 1.4194845928986632 | validation: 1.5268992272960018]
	TIME [epoch: 0.472 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4674926561239188		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 1.4674926561239188 | validation: 1.2703159138175792]
	TIME [epoch: 0.473 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3001326514338218		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 1.3001326514338218 | validation: 1.2084956948370824]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.312345672435512		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 1.312345672435512 | validation: 1.3500750947575815]
	TIME [epoch: 0.474 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3196586484447588		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 1.3196586484447588 | validation: 1.2643630493996405]
	TIME [epoch: 0.473 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2765078685631555		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 1.2765078685631555 | validation: 1.2411991052906755]
	TIME [epoch: 0.475 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2728907968492067		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 1.2728907968492067 | validation: 1.3335535298272938]
	TIME [epoch: 0.474 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.263195443542389		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 1.263195443542389 | validation: 1.1984214641056055]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3016312265396142		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 1.3016312265396142 | validation: 1.4123667527525363]
	TIME [epoch: 0.474 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3396311695320118		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 1.3396311695320118 | validation: 1.1757705086107835]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2890062541376908		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 1.2890062541376908 | validation: 1.2651287886642426]
	TIME [epoch: 0.476 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2319535220855158		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 1.2319535220855158 | validation: 1.2568112972710437]
	TIME [epoch: 0.475 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2186573927713205		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 1.2186573927713205 | validation: 1.1749645562930693]
	TIME [epoch: 0.474 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2208905470238214		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 1.2208905470238214 | validation: 1.361934458514632]
	TIME [epoch: 0.475 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2817873267184847		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 1.2817873267184847 | validation: 1.156676030136773]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3188199952155157		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 1.3188199952155157 | validation: 1.2523019017181047]
	TIME [epoch: 0.476 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.190374560500653		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 1.190374560500653 | validation: 1.2407468325042226]
	TIME [epoch: 0.475 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1783740095036224		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 1.1783740095036224 | validation: 1.150788436581737]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1998835612091285		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 1.1998835612091285 | validation: 1.3800313043288177]
	TIME [epoch: 0.474 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3221158519360585		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 1.3221158519360585 | validation: 1.14566893573639]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2710862950454977		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 1.2710862950454977 | validation: 1.2131725673885303]
	TIME [epoch: 0.474 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1601726658248817		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 1.1601726658248817 | validation: 1.2271188969367701]
	TIME [epoch: 0.473 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1530785467151714		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 1.1530785467151714 | validation: 1.1284058202470697]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1684427137823998		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 1.1684427137823998 | validation: 1.303658620627536]
	TIME [epoch: 0.476 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2139745927158534		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 1.2139745927158534 | validation: 1.1326358852658807]
	TIME [epoch: 0.474 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2386309664258426		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 1.2386309664258426 | validation: 1.2266963261789048]
	TIME [epoch: 0.473 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1369895338946947		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 1.1369895338946947 | validation: 1.1309124765042267]
	TIME [epoch: 0.472 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1091387198754157		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 1.1091387198754157 | validation: 1.1703063847074782]
	TIME [epoch: 0.473 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0932441798115016		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 1.0932441798115016 | validation: 1.1290401147936358]
	TIME [epoch: 0.474 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0854483185581463		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 1.0854483185581463 | validation: 1.2484592537604045]
	TIME [epoch: 0.474 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1431745186882203		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 1.1431745186882203 | validation: 1.2029079299212886]
	TIME [epoch: 0.473 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4022244790636833		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 1.4022244790636833 | validation: 1.1138403609317071]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0966345317739836		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 1.0966345317739836 | validation: 1.4085861448200143]
	TIME [epoch: 0.475 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4231526454501		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 1.4231526454501 | validation: 1.1540450654165657]
	TIME [epoch: 0.474 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0724924919215224		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 1.0724924919215224 | validation: 1.1143903333442053]
	TIME [epoch: 0.474 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2242948031762781		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 1.2242948031762781 | validation: 1.1618448409325757]
	TIME [epoch: 0.473 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.089559260298179		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 1.089559260298179 | validation: 1.1386227530080963]
	TIME [epoch: 0.473 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0594583845511871		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 1.0594583845511871 | validation: 1.082862982856236]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0779384842841448		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 1.0779384842841448 | validation: 1.2194966055615282]
	TIME [epoch: 0.474 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1344069615269952		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 1.1344069615269952 | validation: 1.0943848383002264]
	TIME [epoch: 0.474 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1714929159926464		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 1.1714929159926464 | validation: 1.1694833396474973]
	TIME [epoch: 0.475 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0610097156170188		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 1.0610097156170188 | validation: 1.0800699669826233]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0395444576471637		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 1.0395444576471637 | validation: 1.1635057595153389]
	TIME [epoch: 0.474 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.047776318516704		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 1.047776318516704 | validation: 1.0756877994362517]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1339972774525668		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 1.1339972774525668 | validation: 1.2112451540378573]
	TIME [epoch: 0.475 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.129375934234775		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 1.129375934234775 | validation: 1.0517363846117058]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.088560432324218		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 1.088560432324218 | validation: 1.1346392394119909]
	TIME [epoch: 0.475 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0363176869160236		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 1.0363176869160236 | validation: 1.0479715982544373]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_134.pth
	Model improved!!!
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0288496485307268		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 1.0288496485307268 | validation: 1.1702369917728574]
	TIME [epoch: 0.473 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0595534938113225		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 1.0595534938113225 | validation: 1.0637779765297357]
	TIME [epoch: 0.473 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1118259728774351		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 1.1118259728774351 | validation: 1.1667972744655566]
	TIME [epoch: 0.472 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0579014087059122		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 1.0579014087059122 | validation: 1.0385167152563288]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0315600368892015		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 1.0315600368892015 | validation: 1.1381036375461]
	TIME [epoch: 0.473 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0193531868908583		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 1.0193531868908583 | validation: 1.001570804764852]
	TIME [epoch: 0.472 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0637091200424627		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 1.0637091200424627 | validation: 1.1663258197145878]
	TIME [epoch: 0.473 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0585330099352441		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 1.0585330099352441 | validation: 1.0454557441548782]
	TIME [epoch: 0.472 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.039579128225143		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 1.039579128225143 | validation: 1.1169058050952185]
	TIME [epoch: 0.478 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0044140111057613		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 1.0044140111057613 | validation: 1.0076624173083049]
	TIME [epoch: 0.472 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.01546380305258		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 1.01546380305258 | validation: 1.1410040312414897]
	TIME [epoch: 0.475 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.041067778986089		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 1.041067778986089 | validation: 1.008089215280039]
	TIME [epoch: 0.472 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0511319382468975		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 1.0511319382468975 | validation: 1.088821919878301]
	TIME [epoch: 0.472 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9869269436310792		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.9869269436310792 | validation: 1.004692075040752]
	TIME [epoch: 0.472 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9732929994564975		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.9732929994564975 | validation: 1.0969329858920964]
	TIME [epoch: 0.472 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.989991647274146		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.989991647274146 | validation: 0.9898612270035798]
	TIME [epoch: 0.473 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0711432063952544		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 1.0711432063952544 | validation: 1.1290651866099493]
	TIME [epoch: 0.475 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.024702518022804		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 1.024702518022804 | validation: 1.0145532362013328]
	TIME [epoch: 0.476 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9836212842678507		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.9836212842678507 | validation: 1.0473914924346441]
	TIME [epoch: 0.475 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9464303426431808		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.9464303426431808 | validation: 0.9678609884223426]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9906223720056785		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.9906223720056785 | validation: 1.1395238567567991]
	TIME [epoch: 0.476 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0553566957536362		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 1.0553566957536362 | validation: 0.9904021364723822]
	TIME [epoch: 0.475 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0193296040620734		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 1.0193296040620734 | validation: 1.0337588183894437]
	TIME [epoch: 0.474 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9250473210432094		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.9250473210432094 | validation: 0.9623655454597944]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9042720400812829		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.9042720400812829 | validation: 1.0199262718727486]
	TIME [epoch: 0.477 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9083234012033574		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.9083234012033574 | validation: 0.9410343977349727]
	TIME [epoch: 0.477 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9931977039794947		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.9931977039794947 | validation: 1.2042549630787136]
	TIME [epoch: 0.478 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1391833993220386		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 1.1391833993220386 | validation: 1.0047509153437824]
	TIME [epoch: 0.481 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9542649319875462		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.9542649319875462 | validation: 1.0102364642816346]
	TIME [epoch: 0.476 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8899260281625414		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.8899260281625414 | validation: 0.9604155023517174]
	TIME [epoch: 0.475 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8944973435502505		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.8944973435502505 | validation: 0.9729415652885373]
	TIME [epoch: 0.476 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8812490209518903		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.8812490209518903 | validation: 0.8991064665472885]
	TIME [epoch: 0.475 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9240103046023171		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.9240103046023171 | validation: 1.240700321129027]
	TIME [epoch: 0.476 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2061477844494277		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 1.2061477844494277 | validation: 0.9762295976490609]
	TIME [epoch: 0.476 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9173197822398163		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.9173197822398163 | validation: 0.9840394311081071]
	TIME [epoch: 0.478 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8690393338774842		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.8690393338774842 | validation: 0.9858946538339457]
	TIME [epoch: 0.476 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8896392246469853		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.8896392246469853 | validation: 0.9335072353608066]
	TIME [epoch: 0.477 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1621787368254761		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 1.1621787368254761 | validation: 1.1722578282074487]
	TIME [epoch: 0.477 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0674474138024106		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 1.0674474138024106 | validation: 0.9937266286897648]
	TIME [epoch: 0.477 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9655659159334957		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.9655659159334957 | validation: 0.9475976633301649]
	TIME [epoch: 0.477 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.872024898368781		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.872024898368781 | validation: 0.9392362983682198]
	TIME [epoch: 0.477 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8720808389132474		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.8720808389132474 | validation: 0.9665000591600947]
	TIME [epoch: 0.476 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8654118736668565		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.8654118736668565 | validation: 0.9092693308716226]
	TIME [epoch: 0.477 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9925860504394929		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.9925860504394929 | validation: 1.1494838922117174]
	TIME [epoch: 0.477 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1213127490583255		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 1.1213127490583255 | validation: 0.9480496803413591]
	TIME [epoch: 0.475 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9024657572535756		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.9024657572535756 | validation: 0.9232789807781869]
	TIME [epoch: 0.476 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8527866909699882		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.8527866909699882 | validation: 1.0019008409904675]
	TIME [epoch: 0.476 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8875918447899126		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.8875918447899126 | validation: 0.8882543719171745]
	TIME [epoch: 0.477 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.083619900532428		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 1.083619900532428 | validation: 1.086183960143928]
	TIME [epoch: 0.478 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9882794315315746		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.9882794315315746 | validation: 0.9403034110311883]
	TIME [epoch: 0.476 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.901435938497334		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.901435938497334 | validation: 0.9423530276640101]
	TIME [epoch: 0.477 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469415348272437		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.8469415348272437 | validation: 0.8608480227133779]
	TIME [epoch: 0.477 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8757829039078857		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.8757829039078857 | validation: 1.041921494393474]
	TIME [epoch: 0.476 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9656077698654099		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 0.9656077698654099 | validation: 0.9079293727969482]
	TIME [epoch: 0.475 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0065233047083542		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 1.0065233047083542 | validation: 0.992471229447618]
	TIME [epoch: 0.475 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8970898889738078		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.8970898889738078 | validation: 0.8953960747846929]
	TIME [epoch: 0.475 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8496967029135951		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.8496967029135951 | validation: 0.9351285772379744]
	TIME [epoch: 0.476 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8388769195915045		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.8388769195915045 | validation: 0.8491057956696081]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8610775413147937		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.8610775413147937 | validation: 1.039130650655579]
	TIME [epoch: 0.476 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9778099246010115		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.9778099246010115 | validation: 0.9223835208262529]
	TIME [epoch: 0.476 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0103129587702808		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 1.0103129587702808 | validation: 0.9717402627351164]
	TIME [epoch: 0.476 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.873215767947197		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.873215767947197 | validation: 0.9165382987471088]
	TIME [epoch: 0.475 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8393351524716138		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.8393351524716138 | validation: 0.8636709550379731]
	TIME [epoch: 0.475 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.822231851568335		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.822231851568335 | validation: 0.8977655371123036]
	TIME [epoch: 0.48 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8175861379641086		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.8175861379641086 | validation: 0.8238906707710107]
	TIME [epoch: 0.476 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_199.pth
	Model improved!!!
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9004718833595547		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.9004718833595547 | validation: 1.2165227412065005]
	TIME [epoch: 0.475 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1695221776009554		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 1.1695221776009554 | validation: 1.008525404858086]
	TIME [epoch: 131 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8953785937699124		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.8953785937699124 | validation: 0.8567244521346933]
	TIME [epoch: 0.938 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8499307025254925		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.8499307025254925 | validation: 0.9830912864584047]
	TIME [epoch: 0.928 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9027282870972644		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.9027282870972644 | validation: 0.8640966713418301]
	TIME [epoch: 0.927 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0782244395935956		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 1.0782244395935956 | validation: 1.0131839426589468]
	TIME [epoch: 0.929 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9277920661402804		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.9277920661402804 | validation: 0.845555902749858]
	TIME [epoch: 0.93 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8398691970615173		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.8398691970615173 | validation: 0.87599779372636]
	TIME [epoch: 0.929 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8094720387827016		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.8094720387827016 | validation: 0.8249588598677499]
	TIME [epoch: 0.928 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7987347518371462		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.7987347518371462 | validation: 0.8948987202326406]
	TIME [epoch: 0.928 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8127623836183862		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.8127623836183862 | validation: 0.8290636974939783]
	TIME [epoch: 0.929 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9190441670202225		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.9190441670202225 | validation: 1.122467736902486]
	TIME [epoch: 0.929 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0804209243959475		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 1.0804209243959475 | validation: 0.8821791836148098]
	TIME [epoch: 0.935 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.843753874821582		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.843753874821582 | validation: 0.8234179492458781]
	TIME [epoch: 0.929 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7951597307729397		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.7951597307729397 | validation: 0.9389300249671128]
	TIME [epoch: 0.931 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8591911454819778		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.8591911454819778 | validation: 0.8199647440668403]
	TIME [epoch: 0.929 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0096106162341034		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 1.0096106162341034 | validation: 0.9803005103845432]
	TIME [epoch: 0.928 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9107881836975902		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.9107881836975902 | validation: 0.8431642390710306]
	TIME [epoch: 0.928 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8212180809530228		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.8212180809530228 | validation: 0.8573027043141084]
	TIME [epoch: 0.927 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7918676320245345		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.7918676320245345 | validation: 0.8316424882537827]
	TIME [epoch: 0.932 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7934921822527257		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.7934921822527257 | validation: 0.9032489969407721]
	TIME [epoch: 0.927 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8273944377722943		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.8273944377722943 | validation: 0.8855362840900558]
	TIME [epoch: 0.927 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9930509691146203		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.9930509691146203 | validation: 1.0402606536955117]
	TIME [epoch: 0.927 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9608483715873489		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 0.9608483715873489 | validation: 0.8301565635700247]
	TIME [epoch: 0.927 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8182228625946149		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.8182228625946149 | validation: 0.8366421778318014]
	TIME [epoch: 0.927 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7745703538779517		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.7745703538779517 | validation: 0.8464496022380268]
	TIME [epoch: 0.927 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.800706902015701		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.800706902015701 | validation: 0.7965927697984103]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8444903687802828		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.8444903687802828 | validation: 1.0568664405175765]
	TIME [epoch: 0.928 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9976918098935835		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.9976918098935835 | validation: 0.839084615539877]
	TIME [epoch: 0.928 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8482195060827646		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.8482195060827646 | validation: 0.830687441678667]
	TIME [epoch: 0.929 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7713422333315758		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.7713422333315758 | validation: 0.8330204136148046]
	TIME [epoch: 0.929 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7783972626718905		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.7783972626718905 | validation: 0.768393251334335]
	TIME [epoch: 0.928 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8238811928460748		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.8238811928460748 | validation: 1.067004410073753]
	TIME [epoch: 0.928 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0160442545494859		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 1.0160442545494859 | validation: 0.8861245480625328]
	TIME [epoch: 0.927 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8691790984115082		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.8691790984115082 | validation: 0.8305943896436067]
	TIME [epoch: 0.926 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7906098322096975		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.7906098322096975 | validation: 0.8917837066558054]
	TIME [epoch: 0.926 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8070037248040461		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.8070037248040461 | validation: 0.7861451019391746]
	TIME [epoch: 0.925 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7701193599775046		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.7701193599775046 | validation: 0.8003812502199829]
	TIME [epoch: 0.925 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7540568319362588		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.7540568319362588 | validation: 0.7787247541740103]
	TIME [epoch: 0.925 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7436616385414377		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.7436616385414377 | validation: 0.7617350069305061]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7398437515009717		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.7398437515009717 | validation: 0.8164081977100459]
	TIME [epoch: 0.93 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7484062804080659		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.7484062804080659 | validation: 0.7715991007735893]
	TIME [epoch: 0.93 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9955349383602282		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.9955349383602282 | validation: 1.361270932106418]
	TIME [epoch: 0.926 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2759002953809437		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 1.2759002953809437 | validation: 0.9807531102984424]
	TIME [epoch: 0.926 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8742198653003055		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.8742198653003055 | validation: 0.8298050421263445]
	TIME [epoch: 0.926 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9865122868888946		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.9865122868888946 | validation: 0.8252783787252476]
	TIME [epoch: 0.925 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8605817089115247		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.8605817089115247 | validation: 0.963258393359746]
	TIME [epoch: 0.927 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8777517609774934		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.8777517609774934 | validation: 0.7990753067234263]
	TIME [epoch: 0.925 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.892965834658913		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.892965834658913 | validation: 0.9998052018353502]
	TIME [epoch: 0.927 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.932522579593875		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.932522579593875 | validation: 0.7821832906173323]
	TIME [epoch: 0.926 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8091142885028696		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.8091142885028696 | validation: 0.8009266096064049]
	TIME [epoch: 0.931 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.753424010826468		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.753424010826468 | validation: 0.7646566715163555]
	TIME [epoch: 0.926 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7524729799184935		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.7524729799184935 | validation: 0.7613763715707258]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_252.pth
	Model improved!!!
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7415748000709143		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.7415748000709143 | validation: 0.8294015679216943]
	TIME [epoch: 0.929 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7641515407263247		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.7641515407263247 | validation: 0.7441310761817199]
	TIME [epoch: 0.928 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8445354445219877		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.8445354445219877 | validation: 1.0795416850852275]
	TIME [epoch: 0.928 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0102589231523504		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 1.0102589231523504 | validation: 0.8544890099000786]
	TIME [epoch: 0.927 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8062271263471634		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.8062271263471634 | validation: 0.7352615975015356]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7460745959332848		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.7460745959332848 | validation: 0.82547015661488]
	TIME [epoch: 0.927 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7700251332914216		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.7700251332914216 | validation: 0.7458221587789186]
	TIME [epoch: 0.927 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8557444012204439		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.8557444012204439 | validation: 1.0211541503401258]
	TIME [epoch: 0.927 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.964989834256267		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.964989834256267 | validation: 0.8248949030105355]
	TIME [epoch: 0.927 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.783787040956217		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.783787040956217 | validation: 0.7389349400926938]
	TIME [epoch: 0.928 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7369164980622003		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.7369164980622003 | validation: 0.805197542419254]
	TIME [epoch: 0.926 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7592347290540222		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.7592347290540222 | validation: 0.714615836154957]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8131710847467918		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.8131710847467918 | validation: 0.9447231084081965]
	TIME [epoch: 0.927 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9103116618249343		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.9103116618249343 | validation: 0.7733254000154369]
	TIME [epoch: 0.927 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7884523357382102		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.7884523357382102 | validation: 0.7440011559157143]
	TIME [epoch: 0.926 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7297930863543298		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.7297930863543298 | validation: 0.7782958710350677]
	TIME [epoch: 0.927 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.737752171731799		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.737752171731799 | validation: 0.6964631688758663]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7399214328108542		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.7399214328108542 | validation: 0.8539796512773279]
	TIME [epoch: 0.93 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.798033207465962		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.798033207465962 | validation: 0.7043445385772407]
	TIME [epoch: 0.927 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8469983279431564		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.8469983279431564 | validation: 0.9954319723815502]
	TIME [epoch: 0.926 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9218671521818635		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.9218671521818635 | validation: 0.9081511284219115]
	TIME [epoch: 0.926 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8483977758132842		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.8483977758132842 | validation: 0.7608953254238617]
	TIME [epoch: 0.926 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7222264574733186		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.7222264574733186 | validation: 0.7393469480927861]
	TIME [epoch: 0.925 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.734684966694658		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.734684966694658 | validation: 0.7705927616600488]
	TIME [epoch: 0.926 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7316207315517052		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.7316207315517052 | validation: 0.7394285608478022]
	TIME [epoch: 0.925 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.718046339159402		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.718046339159402 | validation: 0.7141588758724252]
	TIME [epoch: 0.925 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7431437574958594		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.7431437574958594 | validation: 0.9723108919247916]
	TIME [epoch: 0.925 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9314020652398682		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.9314020652398682 | validation: 0.7913573857695234]
	TIME [epoch: 0.93 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9415548452131763		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.9415548452131763 | validation: 0.8350867481749704]
	TIME [epoch: 0.926 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7966210943552829		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.7966210943552829 | validation: 0.7105969457097597]
	TIME [epoch: 0.927 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7273845646475942		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.7273845646475942 | validation: 0.714612810540129]
	TIME [epoch: 0.926 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7031136146771547		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.7031136146771547 | validation: 0.7071155070578936]
	TIME [epoch: 0.926 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.704327516835929		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.704327516835929 | validation: 0.6942440132616156]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7015208570006394		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.7015208570006394 | validation: 0.7631723213031395]
	TIME [epoch: 0.927 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7290943007856661		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.7290943007856661 | validation: 0.7386788329330516]
	TIME [epoch: 0.927 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8696689779990212		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.8696689779990212 | validation: 1.075036908627476]
	TIME [epoch: 0.927 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0213624960411862		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 1.0213624960411862 | validation: 0.7775403190536778]
	TIME [epoch: 0.928 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7447965850475098		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.7447965850475098 | validation: 0.6744692915728777]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.738077433648833		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.738077433648833 | validation: 0.8879772847799139]
	TIME [epoch: 0.927 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8527325375357568		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.8527325375357568 | validation: 0.6901089509573777]
	TIME [epoch: 0.926 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7948863496699968		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.7948863496699968 | validation: 0.8062551258990296]
	TIME [epoch: 0.927 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7776622443731549		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.7776622443731549 | validation: 0.7092129182600568]
	TIME [epoch: 0.926 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7441433209156219		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.7441433209156219 | validation: 0.7400808571228303]
	TIME [epoch: 0.926 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7263116201271801		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.7263116201271801 | validation: 0.7431116569730075]
	TIME [epoch: 0.927 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7365179691987026		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.7365179691987026 | validation: 0.7718686041534218]
	TIME [epoch: 0.925 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7425913841339127		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.7425913841339127 | validation: 0.700489882065152]
	TIME [epoch: 0.934 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7750181575571355		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.7750181575571355 | validation: 0.8325486100552286]
	TIME [epoch: 0.925 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8104629292363678		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.8104629292363678 | validation: 0.6554474202074027]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.769678542913678		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.769678542913678 | validation: 0.7747618481703897]
	TIME [epoch: 0.927 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7532766954071659		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.7532766954071659 | validation: 0.6916923362913053]
	TIME [epoch: 0.927 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7195889665997445		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.7195889665997445 | validation: 0.7174794287870229]
	TIME [epoch: 0.926 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7023523381937529		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.7023523381937529 | validation: 0.7185901992651429]
	TIME [epoch: 0.925 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7156146539222972		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.7156146539222972 | validation: 0.82085684390198]
	TIME [epoch: 0.926 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7946038666237308		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.7946038666237308 | validation: 0.746387574305033]
	TIME [epoch: 0.928 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8251928217785962		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.8251928217785962 | validation: 0.8523499523231663]
	TIME [epoch: 0.926 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8182664659513702		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.8182664659513702 | validation: 0.6447394701775051]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7371314709274412		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.7371314709274412 | validation: 0.7198536149639543]
	TIME [epoch: 0.927 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.692169965220019		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.692169965220019 | validation: 0.6473668290742245]
	TIME [epoch: 0.931 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.689059617360776		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.689059617360776 | validation: 0.7409735748712654]
	TIME [epoch: 0.926 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7052920490087041		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.7052920490087041 | validation: 0.6096603431834001]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7186436002227815		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.7186436002227815 | validation: 0.8053940450227594]
	TIME [epoch: 0.926 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7892690449480773		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.7892690449480773 | validation: 0.6384039459093183]
	TIME [epoch: 0.926 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7801369911814451		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.7801369911814451 | validation: 0.8701384212357888]
	TIME [epoch: 0.926 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8162124309828781		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.8162124309828781 | validation: 0.8012372075591507]
	TIME [epoch: 0.925 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7962916186813785		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.7962916186813785 | validation: 0.7237702617913507]
	TIME [epoch: 0.925 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7127651716934722		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.7127651716934722 | validation: 0.62262534348638]
	TIME [epoch: 0.925 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7036859363316049		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.7036859363316049 | validation: 0.7845983901383558]
	TIME [epoch: 0.924 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7611301098966974		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.7611301098966974 | validation: 0.6440621390859924]
	TIME [epoch: 0.925 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7932972648488773		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.7932972648488773 | validation: 0.8192987581928677]
	TIME [epoch: 0.925 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7773510349999418		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.7773510349999418 | validation: 0.703086289149523]
	TIME [epoch: 0.925 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7318828652584763		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.7318828652584763 | validation: 0.679734776182319]
	TIME [epoch: 0.924 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6780535444205424		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.6780535444205424 | validation: 0.6304600748634647]
	TIME [epoch: 0.924 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.670534893574301		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.670534893574301 | validation: 0.6947490551896456]
	TIME [epoch: 0.924 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6754436028569881		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.6754436028569881 | validation: 0.5971979502707963]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7018934151665898		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.7018934151665898 | validation: 0.7932204262097434]
	TIME [epoch: 0.926 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.779388615649837		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.779388615649837 | validation: 0.6488235731298921]
	TIME [epoch: 0.926 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8094659580671941		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.8094659580671941 | validation: 0.8431379495681711]
	TIME [epoch: 0.925 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8002822818994428		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.8002822818994428 | validation: 0.6946402060556846]
	TIME [epoch: 0.926 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7152324057903136		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.7152324057903136 | validation: 0.6671247632903216]
	TIME [epoch: 0.925 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6766191236007848		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.6766191236007848 | validation: 0.6452666106517406]
	TIME [epoch: 0.924 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6654188559781545		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.6654188559781545 | validation: 0.6676733075466522]
	TIME [epoch: 0.926 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.668233847919598		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.668233847919598 | validation: 0.6148335682326552]
	TIME [epoch: 0.924 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7170943058839737		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.7170943058839737 | validation: 0.8675821152872729]
	TIME [epoch: 0.925 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8472646656487842		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.8472646656487842 | validation: 0.6478414921948336]
	TIME [epoch: 0.924 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7283151013255045		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.7283151013255045 | validation: 0.6709544201188217]
	TIME [epoch: 0.927 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6752764854005028		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.6752764854005028 | validation: 0.6528368336469988]
	TIME [epoch: 0.929 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6619137631404215		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.6619137631404215 | validation: 0.6882216666016188]
	TIME [epoch: 0.926 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6827396078459498		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.6827396078459498 | validation: 0.6675910503450568]
	TIME [epoch: 0.925 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7731166398940212		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.7731166398940212 | validation: 0.8776164910589203]
	TIME [epoch: 0.925 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8622372492340028		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.8622372492340028 | validation: 0.6271321526537297]
	TIME [epoch: 0.931 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7080938505760241		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.7080938505760241 | validation: 0.6539370229280318]
	TIME [epoch: 0.925 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6576381836968198		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.6576381836968198 | validation: 0.6505233901965813]
	TIME [epoch: 0.926 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6663160457279607		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.6663160457279607 | validation: 0.6502238382334803]
	TIME [epoch: 0.927 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6931131404587981		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.6931131404587981 | validation: 0.7768739956433066]
	TIME [epoch: 0.925 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7634411283445285		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.7634411283445285 | validation: 0.5899083698487576]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_347.pth
	Model improved!!!
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7651028173367199		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.7651028173367199 | validation: 0.7452878080074123]
	TIME [epoch: 0.928 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7248674938644248		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.7248674938644248 | validation: 0.6002197812131942]
	TIME [epoch: 0.927 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6584259702061458		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.6584259702061458 | validation: 0.5935571813392875]
	TIME [epoch: 0.928 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.635417933676422		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.635417933676422 | validation: 0.6561286976277696]
	TIME [epoch: 0.925 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6558277961320096		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.6558277961320096 | validation: 0.54348924140145]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6996059236978625		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.6996059236978625 | validation: 0.8030248685234004]
	TIME [epoch: 0.926 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7956157186292444		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.7956157186292444 | validation: 0.5847699105715783]
	TIME [epoch: 0.926 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7103689535551732		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.7103689535551732 | validation: 0.7424390967267787]
	TIME [epoch: 0.925 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.713094727236644		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.713094727236644 | validation: 0.6883564458709842]
	TIME [epoch: 0.926 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7167722604924195		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.7167722604924195 | validation: 0.7092653154993864]
	TIME [epoch: 0.926 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7075907586303546		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.7075907586303546 | validation: 0.5867589275874201]
	TIME [epoch: 0.928 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7034356126580872		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.7034356126580872 | validation: 0.7406316745871079]
	TIME [epoch: 0.926 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7315342002771087		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.7315342002771087 | validation: 0.5770205437414381]
	TIME [epoch: 0.925 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6779130529530321		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.6779130529530321 | validation: 0.6595917947044407]
	TIME [epoch: 0.925 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.667643517098183		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.667643517098183 | validation: 0.5966611325920665]
	TIME [epoch: 0.926 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6675562060699944		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.6675562060699944 | validation: 0.7205524815583071]
	TIME [epoch: 0.925 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7130706819504292		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.7130706819504292 | validation: 0.6206952345176122]
	TIME [epoch: 0.925 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.738670476161931		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.738670476161931 | validation: 0.731733830651335]
	TIME [epoch: 0.925 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7187532514678953		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.7187532514678953 | validation: 0.5878111793300027]
	TIME [epoch: 0.925 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6561261298871037		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.6561261298871037 | validation: 0.6139187517759602]
	TIME [epoch: 0.925 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6342497374033975		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.6342497374033975 | validation: 0.5739708483967538]
	TIME [epoch: 0.924 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6389408151568958		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.6389408151568958 | validation: 0.6508718372895583]
	TIME [epoch: 0.924 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6689271283481466		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.6689271283481466 | validation: 0.5985532116651338]
	TIME [epoch: 0.924 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7347135532026876		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.7347135532026876 | validation: 0.8036645800911952]
	TIME [epoch: 0.925 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7830557996539096		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.7830557996539096 | validation: 0.576660432041472]
	TIME [epoch: 0.925 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6751529470897281		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.6751529470897281 | validation: 0.6285629240735688]
	TIME [epoch: 0.93 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6403013149602318		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.6403013149602318 | validation: 0.5492730248636987]
	TIME [epoch: 0.925 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6445699719486551		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.6445699719486551 | validation: 0.6975658125962809]
	TIME [epoch: 0.927 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6756211556880538		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.6756211556880538 | validation: 0.5762155283092111]
	TIME [epoch: 0.926 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6872580454025985		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.6872580454025985 | validation: 0.6534967730759361]
	TIME [epoch: 0.925 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6463734246147472		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.6463734246147472 | validation: 0.5376999925930193]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6353860492501144		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.6353860492501144 | validation: 0.7164977550418938]
	TIME [epoch: 0.927 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7163645550516183		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.7163645550516183 | validation: 0.6613065816749455]
	TIME [epoch: 0.927 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8118297999539691		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.8118297999539691 | validation: 0.7447280072974641]
	TIME [epoch: 0.926 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7404390320835694		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.7404390320835694 | validation: 0.5761814755890813]
	TIME [epoch: 0.926 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6328977623005548		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.6328977623005548 | validation: 0.587478823503936]
	TIME [epoch: 0.926 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6136723711119306		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.6136723711119306 | validation: 0.6130552743301302]
	TIME [epoch: 0.926 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.624931298290819		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.624931298290819 | validation: 0.5378249809813385]
	TIME [epoch: 0.927 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6464572012263416		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.6464572012263416 | validation: 0.7679649092999243]
	TIME [epoch: 0.926 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7448259865652243		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.7448259865652243 | validation: 0.5851722439633505]
	TIME [epoch: 0.926 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7216765986540792		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.7216765986540792 | validation: 0.6673443064487571]
	TIME [epoch: 0.925 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.675434217737466		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.675434217737466 | validation: 0.5458462784692415]
	TIME [epoch: 0.926 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6341456321848311		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.6341456321848311 | validation: 0.6305396987420254]
	TIME [epoch: 0.925 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6323671936935858		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.6323671936935858 | validation: 0.5320054968495141]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6517599112939647		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.6517599112939647 | validation: 0.7178272078592987]
	TIME [epoch: 0.928 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7193282346598702		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.7193282346598702 | validation: 0.5350140090758151]
	TIME [epoch: 0.926 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6703940649893394		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.6703940649893394 | validation: 0.6177670374820796]
	TIME [epoch: 0.925 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6250679454996327		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.6250679454996327 | validation: 0.5410329746843259]
	TIME [epoch: 0.925 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6202157321381694		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.6202157321381694 | validation: 0.669146055674958]
	TIME [epoch: 0.924 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6797758032756476		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.6797758032756476 | validation: 0.5416849286685529]
	TIME [epoch: 0.925 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6982490159499891		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.6982490159499891 | validation: 0.6778445530819077]
	TIME [epoch: 0.926 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6846909647744351		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.6846909647744351 | validation: 0.5651222832900565]
	TIME [epoch: 0.926 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6395058454456717		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.6395058454456717 | validation: 0.6047898286991644]
	TIME [epoch: 0.925 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6320211306333992		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.6320211306333992 | validation: 0.6243422643701504]
	TIME [epoch: 0.93 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6434854886025889		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.6434854886025889 | validation: 0.630808776144298]
	TIME [epoch: 0.929 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6487980779029314		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.6487980779029314 | validation: 0.5937926603304812]
	TIME [epoch: 0.93 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6418321604099063		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.6418321604099063 | validation: 0.6174325400912184]
	TIME [epoch: 0.931 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6346622138578436		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.6346622138578436 | validation: 0.5128159978215214]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6670256028959517		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.6670256028959517 | validation: 0.7466680519389617]
	TIME [epoch: 0.926 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7658917464145987		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.7658917464145987 | validation: 0.5161480691265011]
	TIME [epoch: 0.926 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6396039019180926		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.6396039019180926 | validation: 0.5365282804917048]
	TIME [epoch: 0.924 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5993970382159023		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.5993970382159023 | validation: 0.5636770181822719]
	TIME [epoch: 0.927 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6044553970225133		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.6044553970225133 | validation: 0.5287604134118772]
	TIME [epoch: 0.925 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6117292396519565		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.6117292396519565 | validation: 0.6221875663418142]
	TIME [epoch: 0.927 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6226595115684822		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.6226595115684822 | validation: 0.49849400943464883]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6344519558732952		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.6344519558732952 | validation: 0.6626048606039276]
	TIME [epoch: 0.928 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6837643107617334		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.6837643107617334 | validation: 0.5299594158032708]
	TIME [epoch: 0.926 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7294048911018822		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.7294048911018822 | validation: 0.7739135461278933]
	TIME [epoch: 0.926 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7489390585168983		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.7489390585168983 | validation: 0.5661277980681877]
	TIME [epoch: 0.926 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6294710030625296		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.6294710030625296 | validation: 0.5353526935229079]
	TIME [epoch: 0.925 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5878797809163823		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.5878797809163823 | validation: 0.553056319688641]
	TIME [epoch: 0.924 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5925362085643424		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.5925362085643424 | validation: 0.5068315424932618]
	TIME [epoch: 0.925 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6195686324462953		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.6195686324462953 | validation: 0.6928308626752764]
	TIME [epoch: 0.927 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7137187097973146		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.7137187097973146 | validation: 0.5379989484880359]
	TIME [epoch: 0.925 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7214598623502181		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.7214598623502181 | validation: 0.6681122296885023]
	TIME [epoch: 0.927 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6805323295476506		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.6805323295476506 | validation: 0.5197703265633716]
	TIME [epoch: 0.924 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6063310026238744		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.6063310026238744 | validation: 0.5250168700072927]
	TIME [epoch: 0.927 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5855491902722892		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.5855491902722892 | validation: 0.5744116423227852]
	TIME [epoch: 0.925 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6092995411500113		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.6092995411500113 | validation: 0.4760061926809831]
	TIME [epoch: 0.925 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_426.pth
	Model improved!!!
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6621465800278341		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.6621465800278341 | validation: 0.6924624387821178]
	TIME [epoch: 0.928 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7259519014779832		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.7259519014779832 | validation: 0.5347187566938174]
	TIME [epoch: 0.928 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6325087413746916		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.6325087413746916 | validation: 0.5354461837853164]
	TIME [epoch: 0.927 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5902718749092815		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.5902718749092815 | validation: 0.5600121347541899]
	TIME [epoch: 0.927 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5978372201664364		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.5978372201664364 | validation: 0.5466687316511804]
	TIME [epoch: 0.928 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.608866349048287		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.608866349048287 | validation: 0.5796387870245976]
	TIME [epoch: 0.927 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6106251899874221		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.6106251899874221 | validation: 0.5574883924679827]
	TIME [epoch: 0.929 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5977412933928445		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.5977412933928445 | validation: 0.5154352849439151]
	TIME [epoch: 0.931 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6210880752740914		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.6210880752740914 | validation: 0.7038215901859706]
	TIME [epoch: 0.926 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7414420662297329		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.7414420662297329 | validation: 0.508882447890608]
	TIME [epoch: 0.926 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.69188868546671		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.69188868546671 | validation: 0.6219659490544844]
	TIME [epoch: 0.926 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6286124755272582		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.6286124755272582 | validation: 0.5054216631606122]
	TIME [epoch: 0.926 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5915413317300032		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.5915413317300032 | validation: 0.5335759593876367]
	TIME [epoch: 0.927 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5796560762975551		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.5796560762975551 | validation: 0.5261093619064291]
	TIME [epoch: 0.926 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5889754416857548		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.5889754416857548 | validation: 0.5550959078044418]
	TIME [epoch: 0.926 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5972099223987989		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.5972099223987989 | validation: 0.5255220550012657]
	TIME [epoch: 0.926 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6249601000004644		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.6249601000004644 | validation: 0.6804147701217631]
	TIME [epoch: 0.926 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6984533204943		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.6984533204943 | validation: 0.5061351871233291]
	TIME [epoch: 0.926 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6975927969536914		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.6975927969536914 | validation: 0.6478698163599614]
	TIME [epoch: 0.926 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6728437147978513		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.6728437147978513 | validation: 0.48745690830474886]
	TIME [epoch: 0.926 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5931832179115996		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.5931832179115996 | validation: 0.4992224271405463]
	TIME [epoch: 0.927 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5723006045071054		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.5723006045071054 | validation: 0.5354684945318912]
	TIME [epoch: 0.926 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5778923667059412		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.5778923667059412 | validation: 0.4636207309047864]
	TIME [epoch: 0.926 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5916655275519714		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.5916655275519714 | validation: 0.6147133057527645]
	TIME [epoch: 0.928 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6323399379485122		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.6323399379485122 | validation: 0.46874331955142123]
	TIME [epoch: 0.927 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6702736501064507		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.6702736501064507 | validation: 0.6503017038207202]
	TIME [epoch: 0.926 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6696529082804326		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.6696529082804326 | validation: 0.5489475928420186]
	TIME [epoch: 0.927 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6233531873052636		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.6233531873052636 | validation: 0.5215341288848411]
	TIME [epoch: 0.927 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5808799884343515		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.5808799884343515 | validation: 0.5187740694179498]
	TIME [epoch: 0.927 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5803726314479907		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.5803726314479907 | validation: 0.5514720675559309]
	TIME [epoch: 0.927 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5894298220535473		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.5894298220535473 | validation: 0.5017638893458333]
	TIME [epoch: 0.927 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6138887875526394		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.6138887875526394 | validation: 0.66004420358486]
	TIME [epoch: 0.926 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6820615563334185		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.6820615563334185 | validation: 0.4851011894523401]
	TIME [epoch: 0.927 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6414647741040017		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.6414647741040017 | validation: 0.5912555393202044]
	TIME [epoch: 0.927 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6143851239706826		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.6143851239706826 | validation: 0.4593619488649335]
	TIME [epoch: 0.927 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5992676934572676		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.5992676934572676 | validation: 0.5570783432461263]
	TIME [epoch: 0.929 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5947340691948133		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.5947340691948133 | validation: 0.46548493998045015]
	TIME [epoch: 0.927 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6107678873910694		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.6107678873910694 | validation: 0.6296275408094522]
	TIME [epoch: 0.927 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.663073151143053		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.663073151143053 | validation: 0.501921028604419]
	TIME [epoch: 0.931 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6383265960885164		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.6383265960885164 | validation: 0.5719177536698782]
	TIME [epoch: 0.926 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.600336839568056		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.600336839568056 | validation: 0.48402258689895866]
	TIME [epoch: 0.925 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5801552953335584		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.5801552953335584 | validation: 0.5243621918798912]
	TIME [epoch: 0.927 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5743435072192574		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.5743435072192574 | validation: 0.4759995531174328]
	TIME [epoch: 0.926 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5815864216413483		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.5815864216413483 | validation: 0.5462963189175362]
	TIME [epoch: 0.925 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5882801357103964		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.5882801357103964 | validation: 0.4671181581327888]
	TIME [epoch: 0.928 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6101589380638842		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.6101589380638842 | validation: 0.6229511768446377]
	TIME [epoch: 0.925 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.655328562523056		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.655328562523056 | validation: 0.4657376753512086]
	TIME [epoch: 0.926 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6379249968348001		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.6379249968348001 | validation: 0.5808199522841095]
	TIME [epoch: 0.927 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6044720039666643		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.6044720039666643 | validation: 0.4665543671554604]
	TIME [epoch: 0.931 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5741584080542244		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.5741584080542244 | validation: 0.522853457942022]
	TIME [epoch: 0.929 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.569246121661334		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.569246121661334 | validation: 0.4678655931874416]
	TIME [epoch: 0.93 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5862839008023337		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.5862839008023337 | validation: 0.6006503809952451]
	TIME [epoch: 0.929 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6314274643213651		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.6314274643213651 | validation: 0.4909899777326368]
	TIME [epoch: 0.929 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6498610041118615		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.6498610041118615 | validation: 0.6019815046975053]
	TIME [epoch: 0.93 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6292189461720316		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.6292189461720316 | validation: 0.4760062634621135]
	TIME [epoch: 0.931 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5742055384656911		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.5742055384656911 | validation: 0.49582428811618906]
	TIME [epoch: 0.931 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5564767741514274		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.5564767741514274 | validation: 0.47299963519699717]
	TIME [epoch: 0.931 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.550078746518895		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.550078746518895 | validation: 0.49949028486616415]
	TIME [epoch: 0.93 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.557315562234219		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.557315562234219 | validation: 0.448485627197064]
	TIME [epoch: 0.929 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5820667373357419		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.5820667373357419 | validation: 0.6192590946584003]
	TIME [epoch: 0.93 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6463407558572063		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.6463407558572063 | validation: 0.4300044802743438]
	TIME [epoch: 0.93 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_487.pth
	Model improved!!!
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6438367890827332		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.6438367890827332 | validation: 0.591859868864732]
	TIME [epoch: 0.931 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6322265703285771		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.6322265703285771 | validation: 0.5427383848083628]
	TIME [epoch: 0.931 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6101855455046341		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.6101855455046341 | validation: 0.5411493470683306]
	TIME [epoch: 0.93 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5834269967517576		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.5834269967517576 | validation: 0.4931406442443684]
	TIME [epoch: 0.93 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5662825158896609		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.5662825158896609 | validation: 0.5138628105722134]
	TIME [epoch: 0.93 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5578175061516331		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.5578175061516331 | validation: 0.4403794617798064]
	TIME [epoch: 0.931 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5776194655109007		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.5776194655109007 | validation: 0.5544425847320221]
	TIME [epoch: 0.93 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6104954239042264		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.6104954239042264 | validation: 0.46406719294762466]
	TIME [epoch: 0.931 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.630427879368462		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.630427879368462 | validation: 0.6105546010282235]
	TIME [epoch: 0.935 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6408363770387646		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.6408363770387646 | validation: 0.47941357021979325]
	TIME [epoch: 0.93 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5854609119111612		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.5854609119111612 | validation: 0.5148161807810384]
	TIME [epoch: 0.929 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5626107054778615		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.5626107054778615 | validation: 0.4723747689055493]
	TIME [epoch: 0.93 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5582305430006284		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.5582305430006284 | validation: 0.5234552899292421]
	TIME [epoch: 0.932 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5709111947204875		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.5709111947204875 | validation: 0.46586298628301653]
	TIME [epoch: 134 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5933920878041309		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.5933920878041309 | validation: 0.6117350057028502]
	TIME [epoch: 1.84 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6382635397112464		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.6382635397112464 | validation: 0.45214773969284466]
	TIME [epoch: 1.83 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6076314138673518		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.6076314138673518 | validation: 0.5400823590228117]
	TIME [epoch: 1.83 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5784930617627118		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.5784930617627118 | validation: 0.4384738377026389]
	TIME [epoch: 1.83 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.571186742751355		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.571186742751355 | validation: 0.5348000473504803]
	TIME [epoch: 1.83 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5713703291911552		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.5713703291911552 | validation: 0.4447330014108129]
	TIME [epoch: 1.83 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5791017536212915		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.5791017536212915 | validation: 0.5571822206823643]
	TIME [epoch: 1.84 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6028901594406608		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.6028901594406608 | validation: 0.4640245368556084]
	TIME [epoch: 1.83 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6035559650095675		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.6035559650095675 | validation: 0.5768446039163388]
	TIME [epoch: 1.83 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6035618282047919		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.6035618282047919 | validation: 0.4638836355845304]
	TIME [epoch: 1.83 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5711256198164152		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.5711256198164152 | validation: 0.5160401469540981]
	TIME [epoch: 1.83 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5634700279221738		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.5634700279221738 | validation: 0.44323420071828634]
	TIME [epoch: 1.83 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5594300740707272		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.5594300740707272 | validation: 0.5428024433754891]
	TIME [epoch: 1.83 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5867070897602976		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.5867070897602976 | validation: 0.4382360931117664]
	TIME [epoch: 1.83 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6013186310322244		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.6013186310322244 | validation: 0.5572852590982015]
	TIME [epoch: 1.83 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6002214391082906		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.6002214391082906 | validation: 0.43589367751889274]
	TIME [epoch: 1.83 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5747349010059185		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.5747349010059185 | validation: 0.5351787936161826]
	TIME [epoch: 1.83 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5677147612587634		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.5677147612587634 | validation: 0.4384720145074836]
	TIME [epoch: 1.83 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5658341131000058		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.5658341131000058 | validation: 0.5078937474406051]
	TIME [epoch: 1.83 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5613444623595728		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.5613444623595728 | validation: 0.41521160416636493]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5803507982279102		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.5803507982279102 | validation: 0.5765819693846569]
	TIME [epoch: 1.83 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6278131268252245		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.6278131268252245 | validation: 0.47002006399460383]
	TIME [epoch: 1.83 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5932955382536853		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.5932955382536853 | validation: 0.5265079444674193]
	TIME [epoch: 1.84 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5656300531151591		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.5656300531151591 | validation: 0.4691476500368869]
	TIME [epoch: 1.83 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5494227032538104		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.5494227032538104 | validation: 0.4726227131399676]
	TIME [epoch: 1.83 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5456818307592022		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.5456818307592022 | validation: 0.45716369604257817]
	TIME [epoch: 1.83 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5461532986533834		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.5461532986533834 | validation: 0.4817006744224679]
	TIME [epoch: 1.84 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5635310672995781		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.5635310672995781 | validation: 0.5007176731200041]
	TIME [epoch: 1.83 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.579104343305555		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.579104343305555 | validation: 0.5135318477279951]
	TIME [epoch: 1.83 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5722872796076818		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.5722872796076818 | validation: 0.4293720654707949]
	TIME [epoch: 1.83 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5673830021757472		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.5673830021757472 | validation: 0.5551962856177631]
	TIME [epoch: 1.83 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.602697716711567		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.602697716711567 | validation: 0.42267010288767737]
	TIME [epoch: 1.83 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6297167235032584		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.6297167235032584 | validation: 0.570207737694751]
	TIME [epoch: 1.83 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.617027526185625		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.617027526185625 | validation: 0.4532255732194468]
	TIME [epoch: 1.83 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5612617253409777		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.5612617253409777 | validation: 0.4604173900508302]
	TIME [epoch: 1.83 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5390947775575518		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.5390947775575518 | validation: 0.4871829696328311]
	TIME [epoch: 1.83 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5404162349706242		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.5404162349706242 | validation: 0.430764812480653]
	TIME [epoch: 1.83 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5436961988507005		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.5436961988507005 | validation: 0.5136027593810689]
	TIME [epoch: 1.83 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5628631203780858		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.5628631203780858 | validation: 0.442768639383576]
	TIME [epoch: 1.84 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5990284584839456		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.5990284584839456 | validation: 0.5963218182281919]
	TIME [epoch: 1.83 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6381276182498465		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.6381276182498465 | validation: 0.44419082088880296]
	TIME [epoch: 1.83 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5700422089262667		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.5700422089262667 | validation: 0.46077634862362804]
	TIME [epoch: 1.83 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5378043656898471		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.5378043656898471 | validation: 0.45913340791647506]
	TIME [epoch: 1.83 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5295673276605629		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.5295673276605629 | validation: 0.4474580332073041]
	TIME [epoch: 1.83 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5322039318738364		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.5322039318738364 | validation: 0.43463954190917387]
	TIME [epoch: 1.83 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5363635269801306		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.5363635269801306 | validation: 0.4642502619797636]
	TIME [epoch: 1.83 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5392550648829468		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.5392550648829468 | validation: 0.42492721635448905]
	TIME [epoch: 1.83 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5743033398838792		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.5743033398838792 | validation: 0.6447470484130466]
	TIME [epoch: 1.83 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6883149410862504		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.6883149410862504 | validation: 0.43747402364000365]
	TIME [epoch: 1.83 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6000755560490235		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.6000755560490235 | validation: 0.47205177560031103]
	TIME [epoch: 1.83 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5406567860501653		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.5406567860501653 | validation: 0.45063483393611553]
	TIME [epoch: 1.83 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5341428096338582		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.5341428096338582 | validation: 0.4442675369045597]
	TIME [epoch: 1.84 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5365325621863183		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.5365325621863183 | validation: 0.4541449370311389]
	TIME [epoch: 1.83 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5409628839086222		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.5409628839086222 | validation: 0.4552227501209027]
	TIME [epoch: 1.83 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.555842105253482		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.555842105253482 | validation: 0.4894288982694122]
	TIME [epoch: 1.84 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5542287777346389		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.5542287777346389 | validation: 0.4209694901696159]
	TIME [epoch: 1.83 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5462559409430662		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.5462559409430662 | validation: 0.4923378748042881]
	TIME [epoch: 1.83 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5607692956711146		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.5607692956711146 | validation: 0.4162811043447285]
	TIME [epoch: 1.83 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6205582593146143		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.6205582593146143 | validation: 0.6305891195293539]
	TIME [epoch: 1.83 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6846748077510154		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.6846748077510154 | validation: 0.4437416819843247]
	TIME [epoch: 1.83 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5568641163736524		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.5568641163736524 | validation: 0.4378864410749069]
	TIME [epoch: 1.83 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5322618045959131		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.5322618045959131 | validation: 0.4932998096006247]
	TIME [epoch: 1.83 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5514255370632596		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.5514255370632596 | validation: 0.42160800809370597]
	TIME [epoch: 1.83 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5781814962243284		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.5781814962243284 | validation: 0.5258995145378829]
	TIME [epoch: 1.83 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5817225780203379		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.5817225780203379 | validation: 0.4230355037669229]
	TIME [epoch: 1.83 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5501484479781867		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.5501484479781867 | validation: 0.4508645863601013]
	TIME [epoch: 1.83 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5330077741652935		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.5330077741652935 | validation: 0.4120125874311514]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.532836661568429		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.532836661568429 | validation: 0.47053940824226176]
	TIME [epoch: 1.84 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5381433281027794		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.5381433281027794 | validation: 0.408975117741768]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5580018023713179		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.5580018023713179 | validation: 0.5554858099102448]
	TIME [epoch: 1.83 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6053709882806098		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.6053709882806098 | validation: 0.422032267516782]
	TIME [epoch: 1.84 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5705749461460894		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.5705749461460894 | validation: 0.4780711042857501]
	TIME [epoch: 1.83 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5429860246990977		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.5429860246990977 | validation: 0.44708233868641534]
	TIME [epoch: 1.83 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5349489950069247		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.5349489950069247 | validation: 0.4508413816375527]
	TIME [epoch: 1.83 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5366624366292914		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.5366624366292914 | validation: 0.45022484920542366]
	TIME [epoch: 1.83 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5464131454297457		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.5464131454297457 | validation: 0.4832193220360724]
	TIME [epoch: 1.83 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5575468493008527		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.5575468493008527 | validation: 0.4328226042082284]
	TIME [epoch: 1.83 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5463208095474856		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.5463208095474856 | validation: 0.5154900081183346]
	TIME [epoch: 1.83 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5680574287839661		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.5680574287839661 | validation: 0.4098552247146298]
	TIME [epoch: 1.84 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5904869159264335		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.5904869159264335 | validation: 0.5371117386029088]
	TIME [epoch: 1.83 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5752053612687683		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.5752053612687683 | validation: 0.40910739316885913]
	TIME [epoch: 1.83 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.550610777586532		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.550610777586532 | validation: 0.4934559465322094]
	TIME [epoch: 1.83 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5583323643348175		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.5583323643348175 | validation: 0.4455086609224232]
	TIME [epoch: 1.83 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.549646385804482		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.549646385804482 | validation: 0.47764824704709946]
	TIME [epoch: 1.83 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5469155310108526		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.5469155310108526 | validation: 0.4178823765574977]
	TIME [epoch: 1.84 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5380550454939524		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.5380550454939524 | validation: 0.46668035583541123]
	TIME [epoch: 1.84 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5310412754521677		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.5310412754521677 | validation: 0.40688940678712404]
	TIME [epoch: 1.84 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_588.pth
	Model improved!!!
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5397800494116362		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.5397800494116362 | validation: 0.4855796168715073]
	TIME [epoch: 1.83 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5485990558129497		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.5485990558129497 | validation: 0.4011531748915161]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5721729221557953		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.5721729221557953 | validation: 0.5375808519210677]
	TIME [epoch: 1.83 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5937896897784389		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.5937896897784389 | validation: 0.4099691844990023]
	TIME [epoch: 1.83 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5502813814435779		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.5502813814435779 | validation: 0.4581736877920479]
	TIME [epoch: 1.83 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5320804457501553		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.5320804457501553 | validation: 0.43328207905682226]
	TIME [epoch: 1.83 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.528105697832497		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.528105697832497 | validation: 0.44488849597504193]
	TIME [epoch: 1.83 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5326185314748477		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.5326185314748477 | validation: 0.4134245978965432]
	TIME [epoch: 1.83 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5330017787675156		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.5330017787675156 | validation: 0.48671564592424127]
	TIME [epoch: 1.83 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5457253511656298		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.5457253511656298 | validation: 0.40583033501684923]
	TIME [epoch: 1.83 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5614665562771165		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.5614665562771165 | validation: 0.5225317363921885]
	TIME [epoch: 1.83 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5808327433021812		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.5808327433021812 | validation: 0.40698904977898903]
	TIME [epoch: 1.83 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5437647715885312		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.5437647715885312 | validation: 0.46553117827881974]
	TIME [epoch: 1.83 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5329505703938843		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.5329505703938843 | validation: 0.42140617344730114]
	TIME [epoch: 1.83 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5310649551437899		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.5310649551437899 | validation: 0.45734017305402086]
	TIME [epoch: 1.83 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5295676801301421		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.5295676801301421 | validation: 0.40353502376899747]
	TIME [epoch: 1.84 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5288057857330426		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.5288057857330426 | validation: 0.47567851483553963]
	TIME [epoch: 1.83 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5395888590426445		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.5395888590426445 | validation: 0.40668904398769484]
	TIME [epoch: 1.83 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5951725038345694		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.5951725038345694 | validation: 0.5808852383577573]
	TIME [epoch: 1.83 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6256172904837444		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.6256172904837444 | validation: 0.4224190160928756]
	TIME [epoch: 1.83 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5407660531990635		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.5407660531990635 | validation: 0.41594182680399466]
	TIME [epoch: 1.83 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5243701445521172		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.5243701445521172 | validation: 0.47038295533587127]
	TIME [epoch: 1.83 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5381808251510145		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.5381808251510145 | validation: 0.39991809657323907]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_611.pth
	Model improved!!!
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5501291047337217		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.5501291047337217 | validation: 0.49600356764819536]
	TIME [epoch: 1.83 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5580205587490391		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.5580205587490391 | validation: 0.3947846515772424]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5352353370652245		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.5352353370652245 | validation: 0.4548690974578997]
	TIME [epoch: 1.83 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5276286451631831		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.5276286451631831 | validation: 0.41499787864077736]
	TIME [epoch: 1.83 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.525725318875051		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.525725318875051 | validation: 0.45210695787294863]
	TIME [epoch: 1.83 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5253297813453954		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.5253297813453954 | validation: 0.40976428428662537]
	TIME [epoch: 1.83 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5407671838076593		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.5407671838076593 | validation: 0.5100188551405636]
	TIME [epoch: 1.83 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5725766739474929		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.5725766739474929 | validation: 0.41152910007401494]
	TIME [epoch: 1.84 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5595858745636788		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.5595858745636788 | validation: 0.48180540484393747]
	TIME [epoch: 1.83 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5437584301052364		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.5437584301052364 | validation: 0.4121422096902329]
	TIME [epoch: 1.83 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5281507751657637		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.5281507751657637 | validation: 0.46089184463010596]
	TIME [epoch: 1.83 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5260615419439065		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.5260615419439065 | validation: 0.4357469516826191]
	TIME [epoch: 1.83 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5370503396582863		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.5370503396582863 | validation: 0.4582238257382841]
	TIME [epoch: 1.83 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5260773767964031		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.5260773767964031 | validation: 0.4134768744007957]
	TIME [epoch: 1.83 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.51906313315186		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.51906313315186 | validation: 0.4462488591818217]
	TIME [epoch: 1.83 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5235797188080893		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.5235797188080893 | validation: 0.3847888995253764]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_627.pth
	Model improved!!!
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5431238867886334		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.5431238867886334 | validation: 0.5388190458985769]
	TIME [epoch: 1.83 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6057258707628664		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.6057258707628664 | validation: 0.4111637909975917]
	TIME [epoch: 1.83 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.564736668915148		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.564736668915148 | validation: 0.4704116023225039]
	TIME [epoch: 1.83 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.532657436740323		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.532657436740323 | validation: 0.4292230843177214]
	TIME [epoch: 1.83 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5192944463631632		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.5192944463631632 | validation: 0.4357350533576426]
	TIME [epoch: 1.83 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5178220226567861		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.5178220226567861 | validation: 0.43201925526222795]
	TIME [epoch: 1.83 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5164781692074432		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.5164781692074432 | validation: 0.41150362110597105]
	TIME [epoch: 1.83 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5178794335450351		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.5178794335450351 | validation: 0.43125969880052506]
	TIME [epoch: 1.83 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5174530345788506		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.5174530345788506 | validation: 0.40927571095523496]
	TIME [epoch: 1.84 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5132332172923886		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.5132332172923886 | validation: 0.4248975093888871]
	TIME [epoch: 1.83 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.516622535343928		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.516622535343928 | validation: 0.3985851823605948]
	TIME [epoch: 1.83 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.522155964017181		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.522155964017181 | validation: 0.5246962889647876]
	TIME [epoch: 1.83 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5751562167913776		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.5751562167913776 | validation: 0.4129321848190721]
	TIME [epoch: 1.83 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6560600007100907		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.6560600007100907 | validation: 0.519662324087481]
	TIME [epoch: 1.83 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5728832705062396		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.5728832705062396 | validation: 0.4381011550929376]
	TIME [epoch: 1.83 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5229710080367557		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.5229710080367557 | validation: 0.3905371515525805]
	TIME [epoch: 1.83 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5320642880868712		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.5320642880868712 | validation: 0.48310932317817595]
	TIME [epoch: 1.83 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5375823251686378		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.5375823251686378 | validation: 0.38600988297688127]
	TIME [epoch: 1.83 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5299014114265923		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.5299014114265923 | validation: 0.4344109827346884]
	TIME [epoch: 1.83 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5235054493982318		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.5235054493982318 | validation: 0.40168927386616]
	TIME [epoch: 1.83 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5226190039338542		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.5226190039338542 | validation: 0.43066327956578654]
	TIME [epoch: 1.83 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206638888397431		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.5206638888397431 | validation: 0.39627017975064405]
	TIME [epoch: 1.83 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5299271758610591		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.5299271758610591 | validation: 0.48173431745738926]
	TIME [epoch: 1.83 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5461594848804423		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.5461594848804423 | validation: 0.409268541709112]
	TIME [epoch: 1.83 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5432617601474913		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.5432617601474913 | validation: 0.4728561554285386]
	TIME [epoch: 1.84 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5342949949924429		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.5342949949924429 | validation: 0.4016968343546179]
	TIME [epoch: 1.83 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5298068641262772		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.5298068641262772 | validation: 0.47456659937832396]
	TIME [epoch: 1.83 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5361963946584624		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.5361963946584624 | validation: 0.39465507921181864]
	TIME [epoch: 1.83 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5278778851045491		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.5278778851045491 | validation: 0.45206109203749567]
	TIME [epoch: 1.83 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5205555064999469		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.5205555064999469 | validation: 0.3889374440508662]
	TIME [epoch: 1.83 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5247479140488599		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.5247479140488599 | validation: 0.46162151822246167]
	TIME [epoch: 1.83 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5290675507802649		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.5290675507802649 | validation: 0.3974463892223176]
	TIME [epoch: 1.83 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5334895283010951		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.5334895283010951 | validation: 0.4752801315302459]
	TIME [epoch: 1.83 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5380367585575531		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.5380367585575531 | validation: 0.40599300980350495]
	TIME [epoch: 1.83 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5272989537178032		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.5272989537178032 | validation: 0.4342233456955105]
	TIME [epoch: 1.83 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5167888239994719		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.5167888239994719 | validation: 0.4042355733271563]
	TIME [epoch: 1.83 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5129578585996325		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.5129578585996325 | validation: 0.4196342400991759]
	TIME [epoch: 1.83 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5129707718154927		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.5129707718154927 | validation: 0.4014872928416134]
	TIME [epoch: 1.83 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5108068455974807		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.5108068455974807 | validation: 0.4461082961670375]
	TIME [epoch: 1.83 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.520233229713844		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.520233229713844 | validation: 0.39659602746001593]
	TIME [epoch: 1.83 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5429962684711819		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.5429962684711819 | validation: 0.5267381409992238]
	TIME [epoch: 1.84 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5934566854805475		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.5934566854805475 | validation: 0.3992352168368215]
	TIME [epoch: 1.83 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5555774568833798		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.5555774568833798 | validation: 0.4485475351394474]
	TIME [epoch: 1.83 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5245835926865936		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.5245835926865936 | validation: 0.3967499848089985]
	TIME [epoch: 1.83 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5150557410462483		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.5150557410462483 | validation: 0.4184543313795147]
	TIME [epoch: 1.83 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5100085890475515		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.5100085890475515 | validation: 0.41246091976089994]
	TIME [epoch: 1.83 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5074548781023421		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.5074548781023421 | validation: 0.41439606438507737]
	TIME [epoch: 1.83 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5123129975387147		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.5123129975387147 | validation: 0.4332045361759777]
	TIME [epoch: 1.83 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5187641485829441		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.5187641485829441 | validation: 0.4469283713177717]
	TIME [epoch: 1.83 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5266581779056102		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.5266581779056102 | validation: 0.4546032764011164]
	TIME [epoch: 1.83 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5256445434745668		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.5256445434745668 | validation: 0.4008165270062236]
	TIME [epoch: 1.83 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.518090780847335		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.518090780847335 | validation: 0.45016388104541055]
	TIME [epoch: 1.83 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5246104693713515		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.5246104693713515 | validation: 0.368178748023406]
	TIME [epoch: 1.83 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5563507515498561		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.5563507515498561 | validation: 0.5234603031896182]
	TIME [epoch: 1.83 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5891449076442661		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.5891449076442661 | validation: 0.3881060737307121]
	TIME [epoch: 1.84 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5254397866422513		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.5254397866422513 | validation: 0.4030860563930867]
	TIME [epoch: 1.83 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5087282950387423		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.5087282950387423 | validation: 0.42007040800004286]
	TIME [epoch: 1.84 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5160005909223184		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.5160005909223184 | validation: 0.39728887530651325]
	TIME [epoch: 1.83 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5123724348965725		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.5123724348965725 | validation: 0.42498097605347285]
	TIME [epoch: 1.83 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5106674452922091		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.5106674452922091 | validation: 0.392214500213771]
	TIME [epoch: 1.83 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5129407145202443		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.5129407145202443 | validation: 0.4470933028584749]
	TIME [epoch: 1.83 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5172423590737469		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.5172423590737469 | validation: 0.39095801021165316]
	TIME [epoch: 1.83 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5262869187420776		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.5262869187420776 | validation: 0.4806894901260467]
	TIME [epoch: 1.83 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5443367991050425		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.5443367991050425 | validation: 0.39744863264186603]
	TIME [epoch: 1.83 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5400200107306818		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.5400200107306818 | validation: 0.4577736112501878]
	TIME [epoch: 1.83 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5245050480028778		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.5245050480028778 | validation: 0.39157176428679413]
	TIME [epoch: 1.83 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5156575693698707		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.5156575693698707 | validation: 0.43217324109315475]
	TIME [epoch: 1.83 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5081601395497897		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.5081601395497897 | validation: 0.39523524795042475]
	TIME [epoch: 1.83 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5078972802630126		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.5078972802630126 | validation: 0.41319309156813644]
	TIME [epoch: 1.83 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.508254073702161		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.508254073702161 | validation: 0.40653559938524686]
	TIME [epoch: 1.83 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5147534730367882		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.5147534730367882 | validation: 0.46483040406569076]
	TIME [epoch: 1.83 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5276081956989591		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.5276081956989591 | validation: 0.38830777407492123]
	TIME [epoch: 1.83 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5211032388863386		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.5211032388863386 | validation: 0.44616525071895713]
	TIME [epoch: 1.84 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5195579790486494		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.5195579790486494 | validation: 0.3876213683003962]
	TIME [epoch: 1.83 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.52852274438365		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.52852274438365 | validation: 0.47668493727422234]
	TIME [epoch: 1.83 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5489273409648273		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.5489273409648273 | validation: 0.3800363220586729]
	TIME [epoch: 1.83 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5453367873792901		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.5453367873792901 | validation: 0.4589634978668878]
	TIME [epoch: 1.83 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5282724878388028		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.5282724878388028 | validation: 0.3977619363151246]
	TIME [epoch: 1.83 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.51141065712424		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.51141065712424 | validation: 0.39830472845440373]
	TIME [epoch: 1.83 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5111653331578416		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.5111653331578416 | validation: 0.44388453930921995]
	TIME [epoch: 1.83 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5112661200557631		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.5112661200557631 | validation: 0.3911163260435583]
	TIME [epoch: 1.83 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5163939423680558		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.5163939423680558 | validation: 0.45333726146897435]
	TIME [epoch: 1.83 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5261420035115433		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.5261420035115433 | validation: 0.37634244462055316]
	TIME [epoch: 1.83 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5347827219507104		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.5347827219507104 | validation: 0.44842630546371043]
	TIME [epoch: 1.83 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5232188876455068		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.5232188876455068 | validation: 0.37760857634705025]
	TIME [epoch: 1.83 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5149888377338891		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.5149888377338891 | validation: 0.41385968032021325]
	TIME [epoch: 1.83 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5076568575030106		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.5076568575030106 | validation: 0.3908066205468795]
	TIME [epoch: 1.83 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5059852589996249		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.5059852589996249 | validation: 0.4269962636615108]
	TIME [epoch: 1.83 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5071709412438723		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.5071709412438723 | validation: 0.3859214577634016]
	TIME [epoch: 1.83 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5121535231820411		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.5121535231820411 | validation: 0.4478806623148177]
	TIME [epoch: 1.83 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5231855349579861		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.5231855349579861 | validation: 0.36901044717222575]
	TIME [epoch: 1.83 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5316717508333919		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.5316717508333919 | validation: 0.4617159984885607]
	TIME [epoch: 1.83 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5281783696122576		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.5281783696122576 | validation: 0.38641396184571597]
	TIME [epoch: 1.83 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5156316463133355		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.5156316463133355 | validation: 0.42772548220742124]
	TIME [epoch: 1.83 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5105230325697432		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.5105230325697432 | validation: 0.41559044425361835]
	TIME [epoch: 1.83 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5105723969612618		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.5105723969612618 | validation: 0.4421096335780441]
	TIME [epoch: 1.83 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5228189235558868		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.5228189235558868 | validation: 0.41057971435007334]
	TIME [epoch: 1.83 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5131528507458574		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.5131528507458574 | validation: 0.424148737024386]
	TIME [epoch: 1.83 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5067884867280692		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.5067884867280692 | validation: 0.38218526216385174]
	TIME [epoch: 1.83 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5120839256543692		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.5120839256543692 | validation: 0.4430951389123296]
	TIME [epoch: 1.83 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5188441765106949		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.5188441765106949 | validation: 0.3707251946996562]
	TIME [epoch: 1.83 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5240409451600726		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.5240409451600726 | validation: 0.46416313159265815]
	TIME [epoch: 1.83 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5335894522745405		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.5335894522745405 | validation: 0.3924315719107117]
	TIME [epoch: 1.83 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5236896838001932		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.5236896838001932 | validation: 0.45052242166339873]
	TIME [epoch: 1.83 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5183971754636777		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.5183971754636777 | validation: 0.3962434121628414]
	TIME [epoch: 1.84 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5083711700424767		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.5083711700424767 | validation: 0.4106602725311603]
	TIME [epoch: 1.83 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5033617357106575		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.5033617357106575 | validation: 0.4020003393712214]
	TIME [epoch: 1.83 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5033430121132754		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.5033430121132754 | validation: 0.3968102762543166]
	TIME [epoch: 1.83 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5025678145187866		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.5025678145187866 | validation: 0.3962964854338739]
	TIME [epoch: 1.83 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5020635190191608		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.5020635190191608 | validation: 0.4204409298505845]
	TIME [epoch: 1.83 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5128989521117234		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.5128989521117234 | validation: 0.4136315130940833]
	TIME [epoch: 1.83 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5111354433665903		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.5111354433665903 | validation: 0.42446225868110404]
	TIME [epoch: 1.83 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5022323263159555		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.5022323263159555 | validation: 0.39206974316590815]
	TIME [epoch: 1.83 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5012636633346002		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.5012636633346002 | validation: 0.436508813504354]
	TIME [epoch: 1.83 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5130958479474698		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.5130958479474698 | validation: 0.372291076654265]
	TIME [epoch: 1.83 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5471385052503431		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.5471385052503431 | validation: 0.5076378936633439]
	TIME [epoch: 1.83 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5714758305474862		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.5714758305474862 | validation: 0.3838415307928706]
	TIME [epoch: 1.83 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5127203408279362		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.5127203408279362 | validation: 0.39326201543531064]
	TIME [epoch: 1.83 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4990974862791936		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.4990974862791936 | validation: 0.41776845224277576]
	TIME [epoch: 1.83 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5087691894509848		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.5087691894509848 | validation: 0.38678031888005426]
	TIME [epoch: 1.83 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5093714437148112		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.5093714437148112 | validation: 0.42067657513540635]
	TIME [epoch: 1.84 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5071339416942469		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.5071339416942469 | validation: 0.3875161261773219]
	TIME [epoch: 1.83 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5022802823688097		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.5022802823688097 | validation: 0.41292175693690575]
	TIME [epoch: 1.83 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5055366867323206		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.5055366867323206 | validation: 0.37676672894866714]
	TIME [epoch: 1.83 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.504104401248761		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.504104401248761 | validation: 0.45109802138587346]
	TIME [epoch: 1.83 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5215868403342323		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.5215868403342323 | validation: 0.37464859029045017]
	TIME [epoch: 1.83 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5220696226149754		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.5220696226149754 | validation: 0.43720443081013766]
	TIME [epoch: 1.83 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.511676117934571		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.511676117934571 | validation: 0.3802877600063459]
	TIME [epoch: 1.83 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5034644472045668		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.5034644472045668 | validation: 0.4111072936779156]
	TIME [epoch: 1.83 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49934212091939734		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.49934212091939734 | validation: 0.4052490733486844]
	TIME [epoch: 1.84 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5049016961356777		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.5049016961356777 | validation: 0.4212774949742862]
	TIME [epoch: 1.83 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5141752142807411		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.5141752142807411 | validation: 0.3924243553088591]
	TIME [epoch: 1.83 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5113956123110113		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.5113956123110113 | validation: 0.427196598986087]
	TIME [epoch: 1.83 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5040328551030072		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.5040328551030072 | validation: 0.37032155225620866]
	TIME [epoch: 1.83 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.512500226194861		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.512500226194861 | validation: 0.45933004837649155]
	TIME [epoch: 1.83 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5289322253891039		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.5289322253891039 | validation: 0.3696036070669978]
	TIME [epoch: 1.83 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5110322026506221		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.5110322026506221 | validation: 0.42309430682795457]
	TIME [epoch: 1.83 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5027256930989877		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.5027256930989877 | validation: 0.39420450443412924]
	TIME [epoch: 1.84 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49757606151324496		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.49757606151324496 | validation: 0.3957170126180598]
	TIME [epoch: 1.83 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49486706682124876		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.49486706682124876 | validation: 0.38938830800112995]
	TIME [epoch: 1.83 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4965138662088512		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.4965138662088512 | validation: 0.39997061396047084]
	TIME [epoch: 1.83 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49437352899435655		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.49437352899435655 | validation: 0.40033149203261226]
	TIME [epoch: 1.83 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5010629152251793		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.5010629152251793 | validation: 0.42470311499435137]
	TIME [epoch: 1.83 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5027070190344192		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.5027070190344192 | validation: 0.39902606082531733]
	TIME [epoch: 1.83 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5100993457585574		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.5100993457585574 | validation: 0.4410063285808703]
	TIME [epoch: 1.83 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5158128277976508		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.5158128277976508 | validation: 0.3785703093855964]
	TIME [epoch: 1.83 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5174385149843899		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.5174385149843899 | validation: 0.4710868715855184]
	TIME [epoch: 1.83 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5327102512770165		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.5327102512770165 | validation: 0.3774650908580558]
	TIME [epoch: 1.84 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5124110715567152		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.5124110715567152 | validation: 0.4159903041442646]
	TIME [epoch: 1.83 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5031071997047226		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.5031071997047226 | validation: 0.39786948059920246]
	TIME [epoch: 1.83 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4969286044271533		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.4969286044271533 | validation: 0.3880726775797929]
	TIME [epoch: 1.83 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5004358756201972		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.5004358756201972 | validation: 0.41707038886078895]
	TIME [epoch: 1.83 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5002230088502243		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.5002230088502243 | validation: 0.37007597867893677]
	TIME [epoch: 1.83 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.504694918572693		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.504694918572693 | validation: 0.43158413559751785]
	TIME [epoch: 1.84 sec]
	Saving model to: out/model_training/model_phi1_4a_distortion_v2_3_v_mmd3_20250509_105731/states/model_phi1_4a_distortion_v2_3_v_mmd3_781.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 1321.350 seconds.
