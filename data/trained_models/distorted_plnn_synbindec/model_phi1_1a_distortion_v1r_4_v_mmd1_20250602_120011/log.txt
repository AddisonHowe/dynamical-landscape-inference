Args:
Namespace(name='model_phi1_1a_distortion_v1r_4_v_mmd1', outdir='out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1', training_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v1r_4/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v1r_4/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.052380685, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4255324623

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.001914169894096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.001914169894096 | validation: 5.94655800592002]
	TIME [epoch: 372 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.126213980977422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.126213980977422 | validation: 5.153575082133809]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.41457226022313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.41457226022313 | validation: 5.29896077884786]
	TIME [epoch: 5.94 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.095334321475777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.095334321475777 | validation: 4.707613639254557]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.749068899099853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.749068899099853 | validation: 4.194063998176993]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.501804676414297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.501804676414297 | validation: 4.351892195288471]
	TIME [epoch: 5.95 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.281619599703604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.281619599703604 | validation: 3.977311757708571]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.146960771171228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.146960771171228 | validation: 4.441035903550638]
	TIME [epoch: 5.94 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.210599773726178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.210599773726178 | validation: 5.077903991498876]
	TIME [epoch: 5.93 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6734888046403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6734888046403 | validation: 4.869063720222627]
	TIME [epoch: 5.93 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.343851850060882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.343851850060882 | validation: 3.4264516698839396]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.785400516575973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.785400516575973 | validation: 3.5641402589234583]
	TIME [epoch: 5.94 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6159906948302796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6159906948302796 | validation: 3.4597376786149634]
	TIME [epoch: 6.04 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.540127146015953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.540127146015953 | validation: 3.4555369799496933]
	TIME [epoch: 5.92 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5278213176641566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5278213176641566 | validation: 3.367235480625154]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4435906076230154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4435906076230154 | validation: 3.431747953273663]
	TIME [epoch: 5.94 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.417609529520876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.417609529520876 | validation: 3.3681633801947375]
	TIME [epoch: 5.94 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4026847720783837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4026847720783837 | validation: 3.3635328239775206]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3723761804088634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3723761804088634 | validation: 3.373793956797811]
	TIME [epoch: 5.95 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328106096592429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.328106096592429 | validation: 3.404223735323564]
	TIME [epoch: 6.43 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342961366739334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342961366739334 | validation: 3.233836071329608]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302419387086155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.302419387086155 | validation: 3.3363892389858023]
	TIME [epoch: 5.95 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.289601529575014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.289601529575014 | validation: 3.212547600424995]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.271707310287795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.271707310287795 | validation: 3.1924838152699677]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.257584292375366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.257584292375366 | validation: 3.285587324424125]
	TIME [epoch: 5.93 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244550346295344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.244550346295344 | validation: 3.1682439628229657]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2061242614289025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2061242614289025 | validation: 3.1494754212553104]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1717938904622756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1717938904622756 | validation: 3.147116175242453]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1791011733123242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1791011733123242 | validation: 3.196183569163656]
	TIME [epoch: 6.01 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222025569943021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.222025569943021 | validation: 3.0997000935989343]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1250894512090985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1250894512090985 | validation: 3.0681868418906846]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1037156646065625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1037156646065625 | validation: 3.0713327535224333]
	TIME [epoch: 5.94 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1213341329587694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1213341329587694 | validation: 3.14505317656418]
	TIME [epoch: 5.94 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1072591246483223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1072591246483223 | validation: 3.0177299517660945]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.055745064257178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.055745064257178 | validation: 2.9852029052914]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.046196148609185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.046196148609185 | validation: 3.0092114574879067]
	TIME [epoch: 5.94 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0282202944013896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0282202944013896 | validation: 3.0067937340868856]
	TIME [epoch: 5.94 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0705931979535097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0705931979535097 | validation: 2.9105751473174424]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9786664320967917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9786664320967917 | validation: 3.0025190833289166]
	TIME [epoch: 6.19 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9789320074426233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9789320074426233 | validation: 2.817326886315274]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.953771355776154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.953771355776154 | validation: 2.780916446794583]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.885781068193025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.885781068193025 | validation: 2.850524762072692]
	TIME [epoch: 5.94 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8391425473771483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8391425473771483 | validation: 3.5442272634452676]
	TIME [epoch: 5.93 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1559585871143008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1559585871143008 | validation: 2.8583072600175337]
	TIME [epoch: 5.95 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.823201468498789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.823201468498789 | validation: 2.547837686114027]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9048073928713007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9048073928713007 | validation: 3.2308621532728496]
	TIME [epoch: 5.94 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9806308194248703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9806308194248703 | validation: 2.7506036870213713]
	TIME [epoch: 5.94 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.750488831123712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.750488831123712 | validation: 2.4556032553370857]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7787639403121447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7787639403121447 | validation: 3.090578270355502]
	TIME [epoch: 5.95 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7784656936495282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7784656936495282 | validation: 2.2788477120918227]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5335633616142554		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.5335633616142554 | validation: 3.343765037548838]
	TIME [epoch: 5.94 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.102550863457239		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.102550863457239 | validation: 2.5829983615704553]
	TIME [epoch: 5.94 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5425408454226432		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.5425408454226432 | validation: 2.1074092412698824]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.452295099773165		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.452295099773165 | validation: 2.30039466833699]
	TIME [epoch: 5.93 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8319818419724148		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.8319818419724148 | validation: 2.555781984494313]
	TIME [epoch: 6.32 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3631850984752596		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.3631850984752596 | validation: 1.9567126496718414]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1574640927327007		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.1574640927327007 | validation: 2.6881171240062]
	TIME [epoch: 5.95 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2202855886258996		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.2202855886258996 | validation: 1.9305572955458934]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.762546112107124		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.762546112107124 | validation: 2.2509658473216545]
	TIME [epoch: 5.95 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.92817082478839		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.92817082478839 | validation: 2.036345698707289]
	TIME [epoch: 5.94 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.805550747208926		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.805550747208926 | validation: 3.5855107289048354]
	TIME [epoch: 5.94 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.358593346838684		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.358593346838684 | validation: 3.242347005270445]
	TIME [epoch: 5.96 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.027977173282268		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.027977173282268 | validation: 2.6673729759591502]
	TIME [epoch: 5.94 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3465228992138822		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.3465228992138822 | validation: 2.1133293456730597]
	TIME [epoch: 5.94 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8606088476035147		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.8606088476035147 | validation: 1.7021367877463018]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.674179831161256		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 1.674179831161256 | validation: 1.9581925824732522]
	TIME [epoch: 5.95 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9546121278196498		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.9546121278196498 | validation: 2.7168050818112093]
	TIME [epoch: 5.95 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0076497861163283		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.0076497861163283 | validation: 1.7644634484141197]
	TIME [epoch: 5.94 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.49820536559488		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.49820536559488 | validation: 1.8005999354367692]
	TIME [epoch: 5.96 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.202596408700318		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.202596408700318 | validation: 6.840172237632477]
	TIME [epoch: 5.94 sec]
EPOCH 71/2000:
	Training over batches...
	Encountered nan in loss. Reverting update and performing model surgery (1/4).
		New model confinement_factor: 0.010000000000000002
		[batch 4/4] avg loss: 6.728261118862433		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 6.728261118862433 | validation: 6.983299270049282]
	TIME [epoch: 380 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.937537110638314		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 6.937537110638314 | validation: 6.756679845561444]
	TIME [epoch: 6.14 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.681368631132376		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 6.681368631132376 | validation: 6.4704388251101665]
	TIME [epoch: 5.94 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.301479362389774		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 6.301479362389774 | validation: 6.264308347079793]
	TIME [epoch: 5.94 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.077879461880174		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 6.077879461880174 | validation: 5.555003752748945]
	TIME [epoch: 5.94 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.376870194745528		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.376870194745528 | validation: 5.122930806633833]
	TIME [epoch: 5.94 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.031216754117748		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.031216754117748 | validation: 4.814447783622379]
	TIME [epoch: 5.95 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9292137205659747		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.9292137205659747 | validation: 2.746893603359776]
	TIME [epoch: 5.97 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3944194697404444		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.3944194697404444 | validation: 2.21993382064322]
	TIME [epoch: 6.61 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.083105523573303		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.083105523573303 | validation: 2.1194839005646395]
	TIME [epoch: 5.96 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.992419775622515		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.992419775622515 | validation: 2.06909898862287]
	TIME [epoch: 5.94 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9357038908827378		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9357038908827378 | validation: 2.0212325222303678]
	TIME [epoch: 6.31 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9080643951652567		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.9080643951652567 | validation: 2.0010514578803327]
	TIME [epoch: 5.95 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8653533228138148		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.8653533228138148 | validation: 1.9848862883562983]
	TIME [epoch: 5.95 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8137999071918378		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.8137999071918378 | validation: 1.916264073967057]
	TIME [epoch: 5.96 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7804630134592794		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.7804630134592794 | validation: 2.008210614582064]
	TIME [epoch: 6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7358097259957042		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.7358097259957042 | validation: 1.8842187512710549]
	TIME [epoch: 5.96 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7013737758021343		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.7013737758021343 | validation: 1.8493209068981185]
	TIME [epoch: 5.96 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.660335057095604		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.660335057095604 | validation: 1.8336837121559306]
	TIME [epoch: 5.95 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6437890536575333		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.6437890536575333 | validation: 1.8092675395174247]
	TIME [epoch: 5.94 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5675566786521955		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5675566786521955 | validation: 1.8833764324014317]
	TIME [epoch: 5.94 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6184939988938565		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.6184939988938565 | validation: 1.6812597275155254]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2500510312219526		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.2500510312219526 | validation: 3.752371056402832]
	TIME [epoch: 5.95 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.350247117144177		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.350247117144177 | validation: 6.135540665802888]
	TIME [epoch: 6.05 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.171511614869501		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 6.171511614869501 | validation: 5.955241544539829]
	TIME [epoch: 5.96 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.884326833786618		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 5.884326833786618 | validation: 5.7523956640067695]
	TIME [epoch: 6.54 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733272044893558		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 5.733272044893558 | validation: 5.585535416673784]
	TIME [epoch: 5.94 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.63403189686249		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 5.63403189686249 | validation: 5.483142285478405]
	TIME [epoch: 5.94 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5314186291702265		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 5.5314186291702265 | validation: 5.371571151443325]
	TIME [epoch: 5.94 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.396368365283488		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 5.396368365283488 | validation: 5.605679201900156]
	TIME [epoch: 5.94 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.303131711933481		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.303131711933481 | validation: 5.057045031238214]
	TIME [epoch: 5.94 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.588637479636424		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.588637479636424 | validation: 3.9988394433273236]
	TIME [epoch: 5.96 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8498136751785195		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.8498136751785195 | validation: 3.645552960284962]
	TIME [epoch: 5.95 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6848161512037647		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 3.6848161512037647 | validation: 4.088418688299375]
	TIME [epoch: 5.94 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8163291489688107		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.8163291489688107 | validation: 3.4782665372114447]
	TIME [epoch: 5.94 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2811640807281033		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.2811640807281033 | validation: 3.2317497412769254]
	TIME [epoch: 5.94 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1253031933792825		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.1253031933792825 | validation: 3.233743448624]
	TIME [epoch: 5.94 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1612598434405115		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.1612598434405115 | validation: 3.22186101637475]
	TIME [epoch: 5.95 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.13556478807147		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.13556478807147 | validation: 3.2044341636396947]
	TIME [epoch: 5.94 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.161245352436788		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.161245352436788 | validation: 3.4791755876200474]
	TIME [epoch: 5.94 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3537788530584622		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.3537788530584622 | validation: 3.415995674773849]
	TIME [epoch: 5.94 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.257512401125798		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.257512401125798 | validation: 3.4361322985792104]
	TIME [epoch: 5.94 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2383705456610503		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.2383705456610503 | validation: 3.3820790351826906]
	TIME [epoch: 5.94 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2653254047244		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.2653254047244 | validation: 3.5460556817372604]
	TIME [epoch: 5.95 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2637851328361727		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.2637851328361727 | validation: 3.157277613994953]
	TIME [epoch: 5.93 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0174251932659595		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.0174251932659595 | validation: 3.081813017267719]
	TIME [epoch: 5.94 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0137910747789887		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.0137910747789887 | validation: 3.1142186206557954]
	TIME [epoch: 5.94 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.02595348874796		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.02595348874796 | validation: 3.150739553225993]
	TIME [epoch: 5.95 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135723570421299		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.135723570421299 | validation: 3.2449402831647136]
	TIME [epoch: 5.94 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2282899913244503		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.2282899913244503 | validation: 3.068301122127952]
	TIME [epoch: 5.94 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.119745319724079		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.119745319724079 | validation: 3.145379361944558]
	TIME [epoch: 5.93 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.364606299710664		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.364606299710664 | validation: 3.60217182425286]
	TIME [epoch: 5.93 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.671459440281419		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.671459440281419 | validation: 3.476748757696429]
	TIME [epoch: 5.94 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.380269836727075		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.380269836727075 | validation: 3.3165463928895056]
	TIME [epoch: 5.94 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.28968285766026		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.28968285766026 | validation: 3.5414542421602677]
	TIME [epoch: 5.94 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.493856167855691		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.493856167855691 | validation: 3.769380517040883]
	TIME [epoch: 5.94 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.782268998224582		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.782268998224582 | validation: 4.082777650887595]
	TIME [epoch: 5.96 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.075814946790937		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 4.075814946790937 | validation: 4.099215594686726]
	TIME [epoch: 5.96 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.968326178618769		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.968326178618769 | validation: 3.8194256617508118]
	TIME [epoch: 6.35 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6638689835295035		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.6638689835295035 | validation: 3.521659625779272]
	TIME [epoch: 5.95 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.353471317522846		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 3.353471317522846 | validation: 3.24984784013351]
	TIME [epoch: 5.95 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.103624857479403		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.103624857479403 | validation: 3.0364594446795605]
	TIME [epoch: 5.96 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.927992396461201		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.927992396461201 | validation: 2.904353219680666]
	TIME [epoch: 5.95 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.790971674531174		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.790971674531174 | validation: 2.7653405049880555]
	TIME [epoch: 5.96 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6519517907295933		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 2.6519517907295933 | validation: 2.614144151280629]
	TIME [epoch: 5.95 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.517873733936798		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 2.517873733936798 | validation: 2.493357218059514]
	TIME [epoch: 5.94 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3775358970434177		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.3775358970434177 | validation: 2.3847562673336844]
	TIME [epoch: 5.95 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243053469281056		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 2.243053469281056 | validation: 2.2763756913709905]
	TIME [epoch: 5.95 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142332872708118		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 2.142332872708118 | validation: 2.1928879192353996]
	TIME [epoch: 5.95 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0486767532174457		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.0486767532174457 | validation: 2.1029700511008467]
	TIME [epoch: 5.95 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9672459367644253		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.9672459367644253 | validation: 2.035866451179616]
	TIME [epoch: 5.97 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9067286444137044		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.9067286444137044 | validation: 1.9870803394504204]
	TIME [epoch: 5.97 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8622073492204898		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.8622073492204898 | validation: 1.9313846080307675]
	TIME [epoch: 5.95 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8124951907284959		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.8124951907284959 | validation: 1.918334262346598]
	TIME [epoch: 5.95 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7760621058555377		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7760621058555377 | validation: 1.885740928096359]
	TIME [epoch: 5.96 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7134976027669895		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.7134976027669895 | validation: 1.8250849268838292]
	TIME [epoch: 5.95 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6684869439278331		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.6684869439278331 | validation: 1.7421790421565277]
	TIME [epoch: 5.96 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5973159317635126		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.5973159317635126 | validation: 1.660980164100477]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5208510263037538		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.5208510263037538 | validation: 1.604814525502726]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.451986001827079		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.451986001827079 | validation: 1.552902403253639]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3613334554457848		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3613334554457848 | validation: 1.4640338698299749]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269767014094342		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.269767014094342 | validation: 1.474150595701191]
	TIME [epoch: 5.94 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1595753082626108		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.1595753082626108 | validation: 1.1844564255536418]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0179273986590884		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0179273986590884 | validation: 1.1171256825561016]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1298073375520281		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.1298073375520281 | validation: 1.200151972178222]
	TIME [epoch: 5.95 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0816752630758777		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.0816752630758777 | validation: 1.0983204873825492]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.745412202661046		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.745412202661046 | validation: 3.3342694206510046]
	TIME [epoch: 5.96 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.891311580385158		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.891311580385158 | validation: 5.031283417131945]
	TIME [epoch: 5.96 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.792483613285886		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 5.792483613285886 | validation: 5.623476313477149]
	TIME [epoch: 6.05 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3906778932750825		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 6.3906778932750825 | validation: 6.793620964599482]
	TIME [epoch: 5.95 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.667512521189307		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 6.667512521189307 | validation: 5.643329940963359]
	TIME [epoch: 5.95 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.967478929077444		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 4.967478929077444 | validation: 3.765784158436448]
	TIME [epoch: 6.18 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9903413161526338		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.9903413161526338 | validation: 4.89917334085224]
	TIME [epoch: 5.96 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.624274968549182		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 4.624274968549182 | validation: 3.953364034025503]
	TIME [epoch: 5.96 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5771544781638696		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 4.5771544781638696 | validation: 4.194199238486798]
	TIME [epoch: 5.96 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.234032940883215		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 4.234032940883215 | validation: 4.206865781920786]
	TIME [epoch: 5.96 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.15483088020613		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 4.15483088020613 | validation: 3.8229882466413363]
	TIME [epoch: 5.96 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5621437195527816		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.5621437195527816 | validation: 3.660599798377791]
	TIME [epoch: 5.95 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2635443798474295		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.2635443798474295 | validation: 3.4691050065845292]
	TIME [epoch: 5.98 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.209090379545358		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.209090379545358 | validation: 3.567289230050007]
	TIME [epoch: 5.96 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3107439881085803		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.3107439881085803 | validation: 3.5904708166005874]
	TIME [epoch: 6.01 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3618150742538537		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.3618150742538537 | validation: 3.606815112083107]
	TIME [epoch: 5.96 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4898305614272442		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 3.4898305614272442 | validation: 3.6492405945291413]
	TIME [epoch: 5.96 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3199099050709773		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 3.3199099050709773 | validation: 3.4153706230127145]
	TIME [epoch: 5.96 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2722038994794285		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 3.2722038994794285 | validation: 3.427946496049284]
	TIME [epoch: 6.33 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.426307474529811		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 4.426307474529811 | validation: 5.231403779917049]
	TIME [epoch: 5.96 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.237605749692513		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.237605749692513 | validation: 3.742471660107811]
	TIME [epoch: 5.95 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3387089454490093		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 3.3387089454490093 | validation: 3.3871536952849253]
	TIME [epoch: 5.96 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.220958107272181		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.220958107272181 | validation: 3.317022016569202]
	TIME [epoch: 5.96 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1429603789775538		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.1429603789775538 | validation: 3.42300374320582]
	TIME [epoch: 5.96 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.188965688002012		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.188965688002012 | validation: 3.532743587908606]
	TIME [epoch: 5.96 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2514953912077997		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.2514953912077997 | validation: 3.4752430186306498]
	TIME [epoch: 5.96 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2434759836547844		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.2434759836547844 | validation: 3.390125762991127]
	TIME [epoch: 5.96 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6118405870479173		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.6118405870479173 | validation: 4.2610943893157245]
	TIME [epoch: 5.96 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.079800799617848		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 4.079800799617848 | validation: 3.6798378425460916]
	TIME [epoch: 5.96 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4924267780555422		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.4924267780555422 | validation: 3.2802949371355727]
	TIME [epoch: 5.96 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221666000891762		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.221666000891762 | validation: 3.123075231303745]
	TIME [epoch: 5.94 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5143553139222052		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.5143553139222052 | validation: 3.6389650976118264]
	TIME [epoch: 5.94 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6424483955567672		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.6424483955567672 | validation: 4.245796256039647]
	TIME [epoch: 5.95 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.099871287604827		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 4.099871287604827 | validation: 3.5088908468914544]
	TIME [epoch: 6.28 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.662026721212125		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.662026721212125 | validation: 3.7332222938913366]
	TIME [epoch: 5.95 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9623346739676717		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.9623346739676717 | validation: 3.6150295883533934]
	TIME [epoch: 5.93 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.47864176280892		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.47864176280892 | validation: 3.217712247975948]
	TIME [epoch: 5.95 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.40312659962494		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.40312659962494 | validation: 3.445665723149694]
	TIME [epoch: 5.96 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4966948435658898		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.4966948435658898 | validation: 3.6135806823658028]
	TIME [epoch: 5.96 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.308844794512027		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.308844794512027 | validation: 4.124418262301411]
	TIME [epoch: 5.95 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.878719900275138		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.878719900275138 | validation: 3.401712721891964]
	TIME [epoch: 5.96 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5555479442063516		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.5555479442063516 | validation: 3.937238889378235]
	TIME [epoch: 5.96 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552580345450993		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 4.552580345450993 | validation: 4.386933578309396]
	TIME [epoch: 5.96 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.530346279241592		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 4.530346279241592 | validation: 4.599163089462939]
	TIME [epoch: 5.95 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.343657604413298		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 5.343657604413298 | validation: 5.172475156113856]
	TIME [epoch: 395 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0250217883971295		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 5.0250217883971295 | validation: 4.786450824392249]
	TIME [epoch: 11.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.535527185922499		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 4.535527185922499 | validation: 4.1379328383807295]
	TIME [epoch: 11.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.682005825970825		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 3.682005825970825 | validation: 3.147582721363868]
	TIME [epoch: 11.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7982490660770227		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 2.7982490660770227 | validation: 2.438399208694193]
	TIME [epoch: 11.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2825159939934565		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.2825159939934565 | validation: 2.20328902836515]
	TIME [epoch: 11.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.123558182142761		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.123558182142761 | validation: 2.0953790841359567]
	TIME [epoch: 11.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0095847475097126		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 2.0095847475097126 | validation: 2.0026091548011746]
	TIME [epoch: 11.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8917495983226171		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.8917495983226171 | validation: 1.914484582039421]
	TIME [epoch: 11.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7696133096774886		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.7696133096774886 | validation: 1.8593437384573097]
	TIME [epoch: 11.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6696924429262319		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.6696924429262319 | validation: 1.7260315583038257]
	TIME [epoch: 11.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5647046548363224		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.5647046548363224 | validation: 1.5899128247949212]
	TIME [epoch: 11.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4458330454658395		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.4458330454658395 | validation: 1.424658806432022]
	TIME [epoch: 11.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2859938223367657		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2859938223367657 | validation: 1.2105140095941547]
	TIME [epoch: 11.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0941512308503136		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0941512308503136 | validation: 1.1251900754039923]
	TIME [epoch: 11.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.102895867420573		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.102895867420573 | validation: 0.9971001357755856]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9293066584213499		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.9293066584213499 | validation: 1.120677575194728]
	TIME [epoch: 11.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6774085979068025		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 2.6774085979068025 | validation: 2.4838374660361717]
	TIME [epoch: 11.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5382621627908322		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.5382621627908322 | validation: 1.241252385774937]
	TIME [epoch: 11.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0095030891718995		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.0095030891718995 | validation: 1.0135468219266834]
	TIME [epoch: 11.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8855429033879703		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8855429033879703 | validation: 0.8584388311022657]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7786127580111774		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.7786127580111774 | validation: 0.8745200821483485]
	TIME [epoch: 11.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1258143978318675		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.1258143978318675 | validation: 0.7975733472038533]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8432811790405539		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.8432811790405539 | validation: 0.7855401362931219]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272806296971548		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7272806296971548 | validation: 0.8632258098020849]
	TIME [epoch: 11.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7641540807759559		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7641540807759559 | validation: 0.8408371405337074]
	TIME [epoch: 11.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663293355228187		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.663293355228187 | validation: 0.5875034538418293]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342506646253301		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.7342506646253301 | validation: 0.671339563090664]
	TIME [epoch: 11.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419306550390658		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.6419306550390658 | validation: 0.6433821894422505]
	TIME [epoch: 11.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0816874506666765		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0816874506666765 | validation: 1.508314192150015]
	TIME [epoch: 11.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0702249209128027		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.0702249209128027 | validation: 1.6891202122384201]
	TIME [epoch: 11.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5908654220937346		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.5908654220937346 | validation: 2.7808773212335614]
	TIME [epoch: 11.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4841815692702136		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.4841815692702136 | validation: 2.963595444302406]
	TIME [epoch: 11.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.884372011363061		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 4.884372011363061 | validation: 5.490437226711048]
	TIME [epoch: 11.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590874840824809		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 5.590874840824809 | validation: 4.5580108896204745]
	TIME [epoch: 11.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5528987103441025		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 4.5528987103441025 | validation: 4.570604025092019]
	TIME [epoch: 11.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.566270872411281		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 4.566270872411281 | validation: 5.376684894919263]
	TIME [epoch: 11.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.828425179287232		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 5.828425179287232 | validation: 5.828725075712677]
	TIME [epoch: 11.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.830458039223352		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 5.830458039223352 | validation: 5.391569089276807]
	TIME [epoch: 11.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.075547437694651		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 5.075547437694651 | validation: 5.0690652395972045]
	TIME [epoch: 11.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736220293127976		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 4.736220293127976 | validation: 5.068771529622936]
	TIME [epoch: 11.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.978491211273825		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 4.978491211273825 | validation: 5.0743027741165045]
	TIME [epoch: 11.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.940027452889427		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 4.940027452889427 | validation: 4.64382753067132]
	TIME [epoch: 11.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5360203147932845		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 4.5360203147932845 | validation: 4.56480873966424]
	TIME [epoch: 11.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.622100889692239		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 4.622100889692239 | validation: 4.785834369769238]
	TIME [epoch: 11.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.800262709847368		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 4.800262709847368 | validation: 4.4123036013277295]
	TIME [epoch: 12 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1167490669348465		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 4.1167490669348465 | validation: 4.322270409210839]
	TIME [epoch: 11.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8278834085536566		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 3.8278834085536566 | validation: 4.24407604107676]
	TIME [epoch: 11.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.207969584568328		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 4.207969584568328 | validation: 4.389249439823544]
	TIME [epoch: 11.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.230109305769418		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 4.230109305769418 | validation: 3.9977925602957924]
	TIME [epoch: 11.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5381953380010045		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.5381953380010045 | validation: 4.573872296622941]
	TIME [epoch: 11.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.8027899320570775		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 4.8027899320570775 | validation: 5.205878782837134]
	TIME [epoch: 11.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6929375676164495		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 4.6929375676164495 | validation: 5.156538672727735]
	TIME [epoch: 11.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0450517061821945		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 5.0450517061821945 | validation: 5.497823445323212]
	TIME [epoch: 11.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.416627316032745		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 5.416627316032745 | validation: 4.964411859124549]
	TIME [epoch: 11.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.58171644960726		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 4.58171644960726 | validation: 4.29896901773]
	TIME [epoch: 11.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2657730660078155		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 4.2657730660078155 | validation: 5.142869473456727]
	TIME [epoch: 11.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.589982212862153		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 4.589982212862153 | validation: 3.919423729587277]
	TIME [epoch: 11.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.290437121564251		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 4.290437121564251 | validation: 3.9418976958028975]
	TIME [epoch: 11.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.151637925968046		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 4.151637925968046 | validation: 3.799267073720637]
	TIME [epoch: 11.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9982326829831103		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.9982326829831103 | validation: 3.6624069229100957]
	TIME [epoch: 11.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.831617128191767		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.831617128191767 | validation: 3.5608814566729983]
	TIME [epoch: 11.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.826718835649019		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.826718835649019 | validation: 3.6432408636916938]
	TIME [epoch: 11.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.714828051144348		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.714828051144348 | validation: 3.4824645297125043]
	TIME [epoch: 11.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.52262457497553		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.52262457497553 | validation: 3.386737286837505]
	TIME [epoch: 11.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.407657563655794		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 3.407657563655794 | validation: 3.3496112156430824]
	TIME [epoch: 11.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302052357876811		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.302052357876811 | validation: 3.182304387249595]
	TIME [epoch: 11.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1743379781102283		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 3.1743379781102283 | validation: 3.0275615790083763]
	TIME [epoch: 11.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.035461152903874		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.035461152903874 | validation: 3.217010783040009]
	TIME [epoch: 11.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.877632549059902		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 2.877632549059902 | validation: 2.5340815746148158]
	TIME [epoch: 11.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4071491886687273		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 2.4071491886687273 | validation: 2.071109261439359]
	TIME [epoch: 11.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9268298233297476		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.9268298233297476 | validation: 1.7930654538509503]
	TIME [epoch: 11.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6766315893648651		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.6766315893648651 | validation: 1.555169967609069]
	TIME [epoch: 11.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.534104085953162		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.534104085953162 | validation: 1.493846750978641]
	TIME [epoch: 11.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4504718171664286		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.4504718171664286 | validation: 1.4046241911696593]
	TIME [epoch: 11.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4459945562832943		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.4459945562832943 | validation: 1.3866704835418808]
	TIME [epoch: 11.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3483677980315125		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.3483677980315125 | validation: 1.4290221695479968]
	TIME [epoch: 11.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2941811148556344		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.2941811148556344 | validation: 1.3356355024825666]
	TIME [epoch: 11.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.232954105520299		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.232954105520299 | validation: 1.347543020813423]
	TIME [epoch: 11.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2193822285663072		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.2193822285663072 | validation: 1.2625159949374067]
	TIME [epoch: 11.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1245803373899896		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.1245803373899896 | validation: 1.1815746743225481]
	TIME [epoch: 11.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0791357615492152		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.0791357615492152 | validation: 1.2421598320748966]
	TIME [epoch: 11.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1058173451700286		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.1058173451700286 | validation: 1.0785647479502716]
	TIME [epoch: 11.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217119482406694		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.0217119482406694 | validation: 0.9743526809591847]
	TIME [epoch: 11.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9074836949426117		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.9074836949426117 | validation: 1.0014515288456334]
	TIME [epoch: 11.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790812839793721		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.8790812839793721 | validation: 0.9343902634198111]
	TIME [epoch: 11.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9919229787846295		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.9919229787846295 | validation: 0.9014495577223638]
	TIME [epoch: 11.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9180843787665446		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.9180843787665446 | validation: 0.9183703928767877]
	TIME [epoch: 11.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840948431340949		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.840948431340949 | validation: 0.9724248145124526]
	TIME [epoch: 11.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8302014028821572		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.8302014028821572 | validation: 0.8198538657029544]
	TIME [epoch: 11.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8348156038005421		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.8348156038005421 | validation: 0.7713418945794246]
	TIME [epoch: 11.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953209503012373		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7953209503012373 | validation: 0.8119841703876354]
	TIME [epoch: 11.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7512803670514484		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7512803670514484 | validation: 0.8307769737361947]
	TIME [epoch: 11.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7746060150936549		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.7746060150936549 | validation: 1.3163227302298832]
	TIME [epoch: 11.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.947712554087023		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.947712554087023 | validation: 0.8192400216581633]
	TIME [epoch: 11.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7094361476884268		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7094361476884268 | validation: 0.7014610641655072]
	TIME [epoch: 11.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.649595016883347		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.649595016883347 | validation: 0.7211257246141309]
	TIME [epoch: 11.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.773030950535609		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.773030950535609 | validation: 0.6748949067866896]
	TIME [epoch: 11.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7363232728217894		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.7363232728217894 | validation: 0.6482923002767393]
	TIME [epoch: 11.9 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563432561199186		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6563432561199186 | validation: 0.6034047526055306]
	TIME [epoch: 11.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7519532737502468		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7519532737502468 | validation: 0.6594170799733066]
	TIME [epoch: 11.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203819913096646		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6203819913096646 | validation: 0.5667314270151118]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.901671053367137		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.901671053367137 | validation: 1.7119472139217409]
	TIME [epoch: 11.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.007701443381456		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.007701443381456 | validation: 0.8022793317449806]
	TIME [epoch: 11.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443775259263842		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.6443775259263842 | validation: 0.5775329992443934]
	TIME [epoch: 11.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109915626559066		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6109915626559066 | validation: 0.6507793143315583]
	TIME [epoch: 11.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6333463266476433		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6333463266476433 | validation: 0.6410197289974908]
	TIME [epoch: 11.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319888912239326		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6319888912239326 | validation: 0.8717687409498325]
	TIME [epoch: 11.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6613164707601933		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.6613164707601933 | validation: 0.5890426780049945]
	TIME [epoch: 11.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5883105593036649		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5883105593036649 | validation: 0.8494826603171797]
	TIME [epoch: 11.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6193681623941372		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6193681623941372 | validation: 0.5523371114067509]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757509641616723		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5757509641616723 | validation: 0.7592354423887003]
	TIME [epoch: 11.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6418210725582199		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6418210725582199 | validation: 0.7799476447042909]
	TIME [epoch: 11.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431132456734057		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5431132456734057 | validation: 0.7246654219421237]
	TIME [epoch: 11.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853427729929082		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5853427729929082 | validation: 0.43954754710619975]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493019947384354		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.493019947384354 | validation: 0.46615025181585545]
	TIME [epoch: 11.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7148601732491776		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.7148601732491776 | validation: 0.42173033520697795]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4277891371171727		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.4277891371171727 | validation: 0.5255200033290492]
	TIME [epoch: 11.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6045413546870116		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6045413546870116 | validation: 0.7564131300704411]
	TIME [epoch: 11.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6206900312672268		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6206900312672268 | validation: 0.7957010412731111]
	TIME [epoch: 11.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5593317620308031		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5593317620308031 | validation: 0.8978971045676484]
	TIME [epoch: 11.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428356733934135		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5428356733934135 | validation: 0.5730335939216176]
	TIME [epoch: 11.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6003486412079149		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6003486412079149 | validation: 0.4608519819401212]
	TIME [epoch: 11.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839409504847741		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.4839409504847741 | validation: 1.234727403541016]
	TIME [epoch: 11.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9365699834006762		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.9365699834006762 | validation: 0.9102792383128109]
	TIME [epoch: 11.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190315439499144		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6190315439499144 | validation: 0.4082276634657215]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42976062734641485		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.42976062734641485 | validation: 0.631461416328444]
	TIME [epoch: 11.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5420466367537969		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5420466367537969 | validation: 0.45129662430701356]
	TIME [epoch: 11.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4696029493020044		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.4696029493020044 | validation: 0.4566996560136103]
	TIME [epoch: 11.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394756213553674		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5394756213553674 | validation: 0.3947522980637089]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675604094006842		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5675604094006842 | validation: 0.35554338923935547]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48460778286878814		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.48460778286878814 | validation: 0.34500810215289884]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932234701548042		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3932234701548042 | validation: 0.6003322777202634]
	TIME [epoch: 11.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574476973760233		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5574476973760233 | validation: 0.4342093913984868]
	TIME [epoch: 11.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48301086090875045		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.48301086090875045 | validation: 0.6292879203674453]
	TIME [epoch: 11.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4838783960977321		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.4838783960977321 | validation: 0.4940474855205185]
	TIME [epoch: 11.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4888202225364635		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.4888202225364635 | validation: 0.4838821263006175]
	TIME [epoch: 11.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41368226746773495		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.41368226746773495 | validation: 0.6534931082042643]
	TIME [epoch: 11.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44070563396784973		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.44070563396784973 | validation: 0.5021567914819334]
	TIME [epoch: 11.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4544095902516464		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.4544095902516464 | validation: 0.5414839802831027]
	TIME [epoch: 11.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42135201406558564		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.42135201406558564 | validation: 0.3894158346084052]
	TIME [epoch: 11.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41679773369936773		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.41679773369936773 | validation: 0.7138949113588919]
	TIME [epoch: 11.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48402618985502077		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.48402618985502077 | validation: 0.5885881461807909]
	TIME [epoch: 11.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45209723762825477		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.45209723762825477 | validation: 0.4817591587331707]
	TIME [epoch: 11.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43990223389918853		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.43990223389918853 | validation: 0.36080001001283507]
	TIME [epoch: 11.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4826467762142759		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4826467762142759 | validation: 0.3059307881328549]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40267882050004217		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.40267882050004217 | validation: 0.4577709136771464]
	TIME [epoch: 11.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662652166911177		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.4662652166911177 | validation: 0.2905072501882828]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4166441376827247		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4166441376827247 | validation: 0.2897595727283888]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777073260285897		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.3777073260285897 | validation: 0.5409421239431169]
	TIME [epoch: 11.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43176711927549577		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.43176711927549577 | validation: 0.3277342703368651]
	TIME [epoch: 11.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415581656281911		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4415581656281911 | validation: 0.3108464812104149]
	TIME [epoch: 11.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40952430984736765		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.40952430984736765 | validation: 0.31316748479413237]
	TIME [epoch: 11.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34543659326765763		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.34543659326765763 | validation: 0.45632649346739185]
	TIME [epoch: 11.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37063189350734116		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.37063189350734116 | validation: 0.3108777657347025]
	TIME [epoch: 11.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4736292285246434		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.4736292285246434 | validation: 0.2950792442072171]
	TIME [epoch: 11.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43115490969488135		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.43115490969488135 | validation: 0.3242404119795971]
	TIME [epoch: 11.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47177176646653135		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.47177176646653135 | validation: 0.621613110070892]
	TIME [epoch: 11.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157435672184911		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4157435672184911 | validation: 0.6515877379580479]
	TIME [epoch: 11.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41812508186311265		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.41812508186311265 | validation: 0.4373113224082995]
	TIME [epoch: 11.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395304358351145		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.395304358351145 | validation: 0.44579420397193187]
	TIME [epoch: 11.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740090457912125		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.3740090457912125 | validation: 0.3868043055569139]
	TIME [epoch: 11.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3974766998455423		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.3974766998455423 | validation: 0.5317561674155411]
	TIME [epoch: 11.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3777280759349634		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3777280759349634 | validation: 0.47850479822675585]
	TIME [epoch: 11.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721096655754188		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.3721096655754188 | validation: 0.3106326710807805]
	TIME [epoch: 11.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4235442952431462		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.4235442952431462 | validation: 0.26757049187511356]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3324805578610598		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.3324805578610598 | validation: 0.4469638324194495]
	TIME [epoch: 11.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37707741537864653		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.37707741537864653 | validation: 0.28977514036453644]
	TIME [epoch: 11.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37391525060170505		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.37391525060170505 | validation: 0.323353864337785]
	TIME [epoch: 11.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46465792166199593		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.46465792166199593 | validation: 0.2426668913020308]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_370.pth
	Model improved!!!
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040601057296733		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.3040601057296733 | validation: 0.5762787033655088]
	TIME [epoch: 11.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45163832656118114		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.45163832656118114 | validation: 0.5577745667816153]
	TIME [epoch: 11.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256920210452277		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.3256920210452277 | validation: 0.3269343059329218]
	TIME [epoch: 11.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40393393709218345		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.40393393709218345 | validation: 0.60831352842814]
	TIME [epoch: 11.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3830891957940715		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.3830891957940715 | validation: 0.4063522522458851]
	TIME [epoch: 11.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759524313579028		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.3759524313579028 | validation: 0.4746881422745744]
	TIME [epoch: 11.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31812564288995726		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.31812564288995726 | validation: 0.320350042678612]
	TIME [epoch: 11.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45529318840892213		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.45529318840892213 | validation: 0.33262000483920034]
	TIME [epoch: 11.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32552876830638955		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.32552876830638955 | validation: 0.30390999043000155]
	TIME [epoch: 11.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3684900331263562		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.3684900331263562 | validation: 0.2054445271896243]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26488705904873505		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.26488705904873505 | validation: 0.6481141819178333]
	TIME [epoch: 11.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34781020042543315		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.34781020042543315 | validation: 0.19659246295071856]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340697770048538		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.3340697770048538 | validation: 0.4748921383709459]
	TIME [epoch: 11.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36257569738151746		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.36257569738151746 | validation: 0.48245782550426686]
	TIME [epoch: 11.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3713432224364968		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.3713432224364968 | validation: 0.25492623535926145]
	TIME [epoch: 11.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064027040298287		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3064027040298287 | validation: 0.318375040429217]
	TIME [epoch: 11.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479947568052582		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.3479947568052582 | validation: 0.1821312794356824]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301422553194565		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3301422553194565 | validation: 0.18883990191082714]
	TIME [epoch: 11.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038137969721374		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3038137969721374 | validation: 0.2406848365369078]
	TIME [epoch: 11.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23429980068743636		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.23429980068743636 | validation: 0.4912877995625802]
	TIME [epoch: 11.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955474562491738		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.3955474562491738 | validation: 0.595010584606507]
	TIME [epoch: 11.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4466516946026725		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.4466516946026725 | validation: 0.26002275986557793]
	TIME [epoch: 11.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3315314711303083		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3315314711303083 | validation: 0.1962603779565842]
	TIME [epoch: 11.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.318849968205312		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.318849968205312 | validation: 0.21485902869322016]
	TIME [epoch: 11.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913986885412526		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2913986885412526 | validation: 0.18218046214249467]
	TIME [epoch: 11.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30786783459604605		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.30786783459604605 | validation: 0.2121305210978451]
	TIME [epoch: 11.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31207388698743693		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.31207388698743693 | validation: 0.24311101177275468]
	TIME [epoch: 11.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305200997127596		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.305200997127596 | validation: 0.20775177405245576]
	TIME [epoch: 11.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24325006189872267		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.24325006189872267 | validation: 0.3223291778194073]
	TIME [epoch: 11.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30137792221411236		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.30137792221411236 | validation: 0.4018706122440644]
	TIME [epoch: 11.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28615864247634437		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.28615864247634437 | validation: 0.5531572434763206]
	TIME [epoch: 11.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33093425233699536		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.33093425233699536 | validation: 0.31398302995055044]
	TIME [epoch: 11.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29252897060579014		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.29252897060579014 | validation: 0.277431359089232]
	TIME [epoch: 11.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457375046116317		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.3457375046116317 | validation: 0.4869922481964368]
	TIME [epoch: 11.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35075572632666885		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.35075572632666885 | validation: 0.251238077330344]
	TIME [epoch: 11.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19690662374539905		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.19690662374539905 | validation: 0.7700121077199712]
	TIME [epoch: 11.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3747711767649952		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.3747711767649952 | validation: 0.4586376739817314]
	TIME [epoch: 11.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32423555857075276		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.32423555857075276 | validation: 0.3002500178177228]
	TIME [epoch: 11.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31184416274862514		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.31184416274862514 | validation: 0.3207488318120252]
	TIME [epoch: 11.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29456248878584124		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.29456248878584124 | validation: 0.26511533517362934]
	TIME [epoch: 11.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2853239842892821		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2853239842892821 | validation: 0.27346919851872376]
	TIME [epoch: 11.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2366132263730988		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.2366132263730988 | validation: 0.408997313781044]
	TIME [epoch: 11.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26883187382067325		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.26883187382067325 | validation: 0.26795271883379373]
	TIME [epoch: 11.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2647469053397808		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.2647469053397808 | validation: 0.2121829698588173]
	TIME [epoch: 11.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2859012725577641		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2859012725577641 | validation: 0.6415280702317437]
	TIME [epoch: 11.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3604064753417944		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3604064753417944 | validation: 0.2540421621750328]
	TIME [epoch: 11.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24225783837005557		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.24225783837005557 | validation: 0.21941534543814678]
	TIME [epoch: 11.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2614336263288135		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.2614336263288135 | validation: 0.24055579880314443]
	TIME [epoch: 11.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25069302276742467		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.25069302276742467 | validation: 0.22196582871484521]
	TIME [epoch: 11.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2418053136941752		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.2418053136941752 | validation: 0.13550321918717295]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17222181778243809		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.17222181778243809 | validation: 0.4085242787093973]
	TIME [epoch: 11.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33136378790350557		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.33136378790350557 | validation: 0.44675940101388856]
	TIME [epoch: 11.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3136339889350603		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.3136339889350603 | validation: 0.48667933593432133]
	TIME [epoch: 11.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29846918974228115		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.29846918974228115 | validation: 0.2148837003934536]
	TIME [epoch: 11.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2492117633005913		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2492117633005913 | validation: 0.2499085029338847]
	TIME [epoch: 11.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413636525508201		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.2413636525508201 | validation: 0.22798829956804262]
	TIME [epoch: 11.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25084929653581833		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.25084929653581833 | validation: 0.14530771147384702]
	TIME [epoch: 11.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.198715046565836		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.198715046565836 | validation: 0.3864698954480035]
	TIME [epoch: 11.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24654554486003114		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.24654554486003114 | validation: 0.24071741280400244]
	TIME [epoch: 11.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3221203743184883		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3221203743184883 | validation: 0.31015098704573213]
	TIME [epoch: 11.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2724994710210792		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2724994710210792 | validation: 0.19091185020089493]
	TIME [epoch: 11.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27653692661881213		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.27653692661881213 | validation: 0.262779310041068]
	TIME [epoch: 11.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23529408880498964		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.23529408880498964 | validation: 0.33006070112053787]
	TIME [epoch: 11.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18861797139787018		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.18861797139787018 | validation: 0.20851731621854575]
	TIME [epoch: 11.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434139703435932		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2434139703435932 | validation: 0.22751608851304506]
	TIME [epoch: 11.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21195793431020676		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.21195793431020676 | validation: 0.3245953096702239]
	TIME [epoch: 11.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25864864396150644		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.25864864396150644 | validation: 0.271996707691729]
	TIME [epoch: 11.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29366285395830644		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.29366285395830644 | validation: 0.14986422174590813]
	TIME [epoch: 11.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2350041642231654		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2350041642231654 | validation: 0.21548211122715916]
	TIME [epoch: 11.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21706088296492382		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.21706088296492382 | validation: 0.1360181053272606]
	TIME [epoch: 11.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3022610444333629		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.3022610444333629 | validation: 0.18226675032780865]
	TIME [epoch: 11.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24414051186118774		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.24414051186118774 | validation: 0.14296998976015035]
	TIME [epoch: 11.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20444356232500985		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.20444356232500985 | validation: 0.18918436743022327]
	TIME [epoch: 11.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20799756430889194		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.20799756430889194 | validation: 0.15634355110423664]
	TIME [epoch: 11.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18911014397890208		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.18911014397890208 | validation: 0.1789486437595566]
	TIME [epoch: 11.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23776578862237432		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.23776578862237432 | validation: 0.15836346013830455]
	TIME [epoch: 11.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19217830825714977		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.19217830825714977 | validation: 0.2937928952021405]
	TIME [epoch: 11.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24527971623710812		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.24527971623710812 | validation: 0.23769305510078356]
	TIME [epoch: 11.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22709743060167856		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.22709743060167856 | validation: 0.23447632370772548]
	TIME [epoch: 11.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20006059556283098		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.20006059556283098 | validation: 0.2505402940810644]
	TIME [epoch: 11.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23148045706792297		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.23148045706792297 | validation: 0.14335915000554122]
	TIME [epoch: 11.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19269722790990962		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.19269722790990962 | validation: 0.13848801416037743]
	TIME [epoch: 11.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23246260174578012		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.23246260174578012 | validation: 0.11160687201548466]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24787816147495642		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.24787816147495642 | validation: 0.13231065212768758]
	TIME [epoch: 11.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918690708964371		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.1918690708964371 | validation: 0.18895700850272057]
	TIME [epoch: 11.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19210602806698346		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.19210602806698346 | validation: 0.24814589568101783]
	TIME [epoch: 11.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19393934178481861		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.19393934178481861 | validation: 0.1807890060365976]
	TIME [epoch: 11.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21511370722652146		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.21511370722652146 | validation: 0.24868913930136322]
	TIME [epoch: 11.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18052383194374347		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.18052383194374347 | validation: 0.19871261784370375]
	TIME [epoch: 11.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21223039147274925		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.21223039147274925 | validation: 0.27853540132497856]
	TIME [epoch: 11.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18946362019904606		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.18946362019904606 | validation: 0.1746290392073953]
	TIME [epoch: 11.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1847056525209022		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.1847056525209022 | validation: 0.2712588193720628]
	TIME [epoch: 11.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20630843416763384		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.20630843416763384 | validation: 0.26857404678176283]
	TIME [epoch: 11.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18085064547788782		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.18085064547788782 | validation: 0.3026999825806094]
	TIME [epoch: 11.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47911931007319497		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.47911931007319497 | validation: 1.1180820564496976]
	TIME [epoch: 11.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5982995920271192		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5982995920271192 | validation: 0.21515465064915967]
	TIME [epoch: 11.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2391512766817906		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.2391512766817906 | validation: 0.1773800578329712]
	TIME [epoch: 11.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20152408619649886		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.20152408619649886 | validation: 0.11376618280915596]
	TIME [epoch: 11.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13998381930633774		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.13998381930633774 | validation: 0.3068450374560816]
	TIME [epoch: 11.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19283390369611939		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.19283390369611939 | validation: 0.3695774640168288]
	TIME [epoch: 11.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20841833721317266		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.20841833721317266 | validation: 0.19541622755946397]
	TIME [epoch: 11.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18913074179337244		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.18913074179337244 | validation: 0.09643662216020003]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18578086326543805		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.18578086326543805 | validation: 0.11496702274548827]
	TIME [epoch: 11.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2131525651601554		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2131525651601554 | validation: 0.12772250739105034]
	TIME [epoch: 11.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14031947769829745		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.14031947769829745 | validation: 0.28255515759457406]
	TIME [epoch: 11.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21073943252491056		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.21073943252491056 | validation: 0.15982087541744217]
	TIME [epoch: 11.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18934138082115465		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.18934138082115465 | validation: 0.13761268821652023]
	TIME [epoch: 11.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1832230349110935		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.1832230349110935 | validation: 0.1570481964705768]
	TIME [epoch: 11.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1865013909546388		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1865013909546388 | validation: 0.14239079241138494]
	TIME [epoch: 11.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14688718415025762		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.14688718415025762 | validation: 0.17875955438807684]
	TIME [epoch: 11.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31876137662446796		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.31876137662446796 | validation: 0.11518785457229569]
	TIME [epoch: 11.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2549107344770031		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.2549107344770031 | validation: 0.08222662378118942]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14678290210739203		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.14678290210739203 | validation: 0.27699152008281946]
	TIME [epoch: 11.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16480571949339912		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.16480571949339912 | validation: 0.17131616532411315]
	TIME [epoch: 11.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18628200298670153		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.18628200298670153 | validation: 0.11958773750683313]
	TIME [epoch: 11.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18409369356932737		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.18409369356932737 | validation: 0.10146924787420092]
	TIME [epoch: 11.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15114344429888757		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.15114344429888757 | validation: 0.3354103199614988]
	TIME [epoch: 11.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1679604278195194		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1679604278195194 | validation: 0.30340661461911195]
	TIME [epoch: 11.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18622990319074734		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.18622990319074734 | validation: 0.2157006631184866]
	TIME [epoch: 11.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18402932329391086		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.18402932329391086 | validation: 0.25879178033795774]
	TIME [epoch: 11.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17869347865738447		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.17869347865738447 | validation: 0.16482474218546744]
	TIME [epoch: 11.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868803462700303		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.14868803462700303 | validation: 0.1015429314933407]
	TIME [epoch: 11.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871394727691556		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.17871394727691556 | validation: 0.09305169803623145]
	TIME [epoch: 11.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150836667046397		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.150836667046397 | validation: 0.2519499417441998]
	TIME [epoch: 11.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15397171985727526		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.15397171985727526 | validation: 0.15559865458192498]
	TIME [epoch: 11.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21096653561007284		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.21096653561007284 | validation: 0.13320634650241528]
	TIME [epoch: 11.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13731338620720693		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.13731338620720693 | validation: 0.20854749329456676]
	TIME [epoch: 11.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16389177959373297		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.16389177959373297 | validation: 0.21425437378709605]
	TIME [epoch: 11.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1289424934254244		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1289424934254244 | validation: 0.1722867669229407]
	TIME [epoch: 11.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1573616917257898		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.1573616917257898 | validation: 0.24744562794285624]
	TIME [epoch: 11.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665107145774302		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.1665107145774302 | validation: 0.22663532275904563]
	TIME [epoch: 407 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621559350435014		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.1621559350435014 | validation: 0.18641392129800421]
	TIME [epoch: 25.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15738608138307192		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.15738608138307192 | validation: 0.10239735815786963]
	TIME [epoch: 25.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816649698717927		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.1816649698717927 | validation: 0.1382506146146417]
	TIME [epoch: 25.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17032863417544558		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.17032863417544558 | validation: 0.24339449247359127]
	TIME [epoch: 25.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20306606190979543		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.20306606190979543 | validation: 0.05696021575024719]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861317795482438		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.12861317795482438 | validation: 0.16861628591309108]
	TIME [epoch: 25.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12612114498241753		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.12612114498241753 | validation: 0.17340773648350316]
	TIME [epoch: 25.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347541145710316		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.14347541145710316 | validation: 0.1940520896973011]
	TIME [epoch: 25.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956678492108897		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.12956678492108897 | validation: 0.18647005860006527]
	TIME [epoch: 25.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378955150344359		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.12378955150344359 | validation: 0.22470906630043064]
	TIME [epoch: 25.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16921447249874794		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.16921447249874794 | validation: 0.06705624074414474]
	TIME [epoch: 25.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13463261521031675		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.13463261521031675 | validation: 0.20371086711413788]
	TIME [epoch: 25.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18205693912804652		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.18205693912804652 | validation: 0.17225083947459588]
	TIME [epoch: 25.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18659037898077901		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.18659037898077901 | validation: 0.08987587365280691]
	TIME [epoch: 25.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1379832641016238		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.1379832641016238 | validation: 0.1031372529686049]
	TIME [epoch: 25.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12994163966257705		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.12994163966257705 | validation: 0.11490801054176328]
	TIME [epoch: 25.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390711030439262		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.1390711030439262 | validation: 0.0748945670686913]
	TIME [epoch: 25.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10215775667259983		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.10215775667259983 | validation: 0.29913901297392487]
	TIME [epoch: 25.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15774917435254915		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.15774917435254915 | validation: 0.190268147312183]
	TIME [epoch: 25.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11639274956415253		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.11639274956415253 | validation: 0.17716431215455591]
	TIME [epoch: 25.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17487238683625445		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.17487238683625445 | validation: 0.20487593650412483]
	TIME [epoch: 25.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13854732555073912		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.13854732555073912 | validation: 0.21267705827038935]
	TIME [epoch: 25.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668195681549617		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.17668195681549617 | validation: 0.05725700831390583]
	TIME [epoch: 25.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09347613215111547		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.09347613215111547 | validation: 0.23525564463779955]
	TIME [epoch: 25.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14630205150856126		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.14630205150856126 | validation: 0.1414957206579517]
	TIME [epoch: 25.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12891245682254862		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.12891245682254862 | validation: 0.17446014172266677]
	TIME [epoch: 25.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1356027726949484		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.1356027726949484 | validation: 0.10891961195003809]
	TIME [epoch: 25.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12340157818147854		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.12340157818147854 | validation: 0.11718741026885002]
	TIME [epoch: 25.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10212596448223492		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.10212596448223492 | validation: 0.274110990918118]
	TIME [epoch: 25.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17921049012757923		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.17921049012757923 | validation: 0.12746169958363296]
	TIME [epoch: 25.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498217935943814		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.1498217935943814 | validation: 0.10811868244545089]
	TIME [epoch: 25.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508347152836023		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.1508347152836023 | validation: 0.13024835874037968]
	TIME [epoch: 25.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13165923700538953		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.13165923700538953 | validation: 0.2584899156443602]
	TIME [epoch: 25.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22696397841344731		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.22696397841344731 | validation: 0.11856942384437613]
	TIME [epoch: 25.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08999480856175353		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.08999480856175353 | validation: 0.19764750880161736]
	TIME [epoch: 25.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17767140968703377		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.17767140968703377 | validation: 0.05184740816503319]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13526290648422193		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.13526290648422193 | validation: 0.10511721010000531]
	TIME [epoch: 25.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12965792959805478		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.12965792959805478 | validation: 0.05198199272399065]
	TIME [epoch: 25.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15444940398936438		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.15444940398936438 | validation: 0.08181916695557077]
	TIME [epoch: 25.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11803531576851586		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11803531576851586 | validation: 0.17906191566505847]
	TIME [epoch: 25.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11829938273861235		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.11829938273861235 | validation: 0.09732809643735957]
	TIME [epoch: 25.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14953726233053205		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.14953726233053205 | validation: 0.1344355358674174]
	TIME [epoch: 25.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14248813347054307		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.14248813347054307 | validation: 0.07171156720511654]
	TIME [epoch: 25.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258989176463519		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.11258989176463519 | validation: 0.06342783893756584]
	TIME [epoch: 25.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12757969084292092		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.12757969084292092 | validation: 0.1562316379264085]
	TIME [epoch: 25.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103814007508396		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.103814007508396 | validation: 0.14197662159985652]
	TIME [epoch: 25.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10026298512182585		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.10026298512182585 | validation: 0.23205043540631778]
	TIME [epoch: 25.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390441611077316		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.1390441611077316 | validation: 0.15723781892717106]
	TIME [epoch: 25.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12296395032606347		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.12296395032606347 | validation: 0.1636622047122464]
	TIME [epoch: 25.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10608668687583891		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.10608668687583891 | validation: 0.1567053609229747]
	TIME [epoch: 25.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16411145034605126		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.16411145034605126 | validation: 0.15684071894320725]
	TIME [epoch: 25.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024831308360362		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.12024831308360362 | validation: 0.043236908087912126]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_553.pth
	Model improved!!!
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11032598133716023		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.11032598133716023 | validation: 0.07430503846649242]
	TIME [epoch: 25.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12601686524307196		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.12601686524307196 | validation: 0.05452750793500837]
	TIME [epoch: 25.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131267494212337		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.10131267494212337 | validation: 0.07600359616255768]
	TIME [epoch: 25.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10977945165825256		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.10977945165825256 | validation: 0.16162595808639113]
	TIME [epoch: 25.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325671841046313		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.1325671841046313 | validation: 0.10689514502291425]
	TIME [epoch: 25.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19283125532310594		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.19283125532310594 | validation: 0.10339633613209408]
	TIME [epoch: 25.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042783835001255		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.1042783835001255 | validation: 0.17922202061440604]
	TIME [epoch: 25.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12230802618856815		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.12230802618856815 | validation: 0.09221725032860886]
	TIME [epoch: 25.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1022011727189121		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1022011727189121 | validation: 0.07532519590601414]
	TIME [epoch: 25.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09194117271542775		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.09194117271542775 | validation: 0.06558814591439549]
	TIME [epoch: 25.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14005780648038024		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.14005780648038024 | validation: 0.125845122687478]
	TIME [epoch: 25.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0821694893673325		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.0821694893673325 | validation: 0.11114843849537809]
	TIME [epoch: 25.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13251937792074286		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.13251937792074286 | validation: 0.040066667662008636]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11574780239434075		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.11574780239434075 | validation: 0.09891505808551732]
	TIME [epoch: 25.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07251000412769416		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.07251000412769416 | validation: 0.1426407618226777]
	TIME [epoch: 25.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13511675914624016		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.13511675914624016 | validation: 0.09025448702596091]
	TIME [epoch: 25.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1396944239966763		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.1396944239966763 | validation: 0.1275020753745309]
	TIME [epoch: 25.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12928096662424596		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.12928096662424596 | validation: 0.13863184070442497]
	TIME [epoch: 25.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416433797163223		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.10416433797163223 | validation: 0.06848495304941105]
	TIME [epoch: 25.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054050943079076		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.11054050943079076 | validation: 0.06678226920711013]
	TIME [epoch: 25.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243899807213957		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.1243899807213957 | validation: 0.1328105238219237]
	TIME [epoch: 25.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12192866671254166		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.12192866671254166 | validation: 0.06907560886601341]
	TIME [epoch: 25.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10523256746929074		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.10523256746929074 | validation: 0.10800983695662025]
	TIME [epoch: 25.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08247923618257358		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.08247923618257358 | validation: 0.19352856988088005]
	TIME [epoch: 25.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13484921165186411		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.13484921165186411 | validation: 0.07996741792548827]
	TIME [epoch: 25.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10437008599867661		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.10437008599867661 | validation: 0.08488684984213504]
	TIME [epoch: 25.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10218768553089164		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.10218768553089164 | validation: 0.0697591692088538]
	TIME [epoch: 25.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09382603241939536		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.09382603241939536 | validation: 0.10389495682865467]
	TIME [epoch: 25.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09573997036936688		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09573997036936688 | validation: 0.16637727696905485]
	TIME [epoch: 25.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12176542667476825		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.12176542667476825 | validation: 0.09319265916720501]
	TIME [epoch: 25.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11716224488319715		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.11716224488319715 | validation: 0.06015056194143658]
	TIME [epoch: 25.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12135023443250409		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12135023443250409 | validation: 0.10413462967489737]
	TIME [epoch: 25.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142224663524647		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.08142224663524647 | validation: 0.10929655163944063]
	TIME [epoch: 25.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875691345117867		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.09875691345117867 | validation: 0.0574775642642676]
	TIME [epoch: 25.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09987320212854048		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.09987320212854048 | validation: 0.1275638671038306]
	TIME [epoch: 25.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883622657745094		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.0883622657745094 | validation: 0.06762723603665506]
	TIME [epoch: 25.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12778684266488355		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.12778684266488355 | validation: 0.0939820124394653]
	TIME [epoch: 25.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0619161171332753		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.0619161171332753 | validation: 0.09194106801052684]
	TIME [epoch: 25.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15925275539006623		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.15925275539006623 | validation: 0.06638941298082156]
	TIME [epoch: 25.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08925527728895061		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08925527728895061 | validation: 0.06835278138955031]
	TIME [epoch: 25.2 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08304572407972652		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.08304572407972652 | validation: 0.12402135802081626]
	TIME [epoch: 25.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11484979644308974		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.11484979644308974 | validation: 0.06445843621316893]
	TIME [epoch: 25.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515689719114753		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.09515689719114753 | validation: 0.04348673976624205]
	TIME [epoch: 25.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564944471416872		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.09564944471416872 | validation: 0.18424506994220496]
	TIME [epoch: 25.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230245106781005		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.11230245106781005 | validation: 0.04910351496040379]
	TIME [epoch: 25.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11770667074079415		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.11770667074079415 | validation: 0.03660036169887927]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_599.pth
	Model improved!!!
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10255070254908531		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.10255070254908531 | validation: 0.17703376317825842]
	TIME [epoch: 25.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16347988140701092		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.16347988140701092 | validation: 0.03844432140542983]
	TIME [epoch: 25.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05290998527962997		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.05290998527962997 | validation: 0.04835079622721114]
	TIME [epoch: 25.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11216150599780814		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.11216150599780814 | validation: 0.049527619872807356]
	TIME [epoch: 25.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09871831016804464		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.09871831016804464 | validation: 0.08458826643071124]
	TIME [epoch: 25.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09611037842264476		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.09611037842264476 | validation: 0.1319408047220076]
	TIME [epoch: 25.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08860219748956369		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.08860219748956369 | validation: 0.04809958679053046]
	TIME [epoch: 25.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11651388512813168		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.11651388512813168 | validation: 0.0669251978106813]
	TIME [epoch: 25.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990432857823067		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.0990432857823067 | validation: 0.06562274470333004]
	TIME [epoch: 25.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09963083087816299		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.09963083087816299 | validation: 0.03858003158413438]
	TIME [epoch: 25.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08433221273415062		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.08433221273415062 | validation: 0.08426638667568137]
	TIME [epoch: 25.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150935072779895		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.09150935072779895 | validation: 0.2136097121006122]
	TIME [epoch: 25.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1139812361250816		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1139812361250816 | validation: 0.06440831658205398]
	TIME [epoch: 25.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11975906122621714		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.11975906122621714 | validation: 0.15649383509594678]
	TIME [epoch: 25.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11872645577920639		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.11872645577920639 | validation: 0.043824672952810007]
	TIME [epoch: 25.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157396114158203		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.09157396114158203 | validation: 0.12837391329065317]
	TIME [epoch: 25.2 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20565006799942226		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.20565006799942226 | validation: 0.14603872621239714]
	TIME [epoch: 25.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11966147063276701		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.11966147063276701 | validation: 0.044846925546363076]
	TIME [epoch: 25.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193249517273266		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.09193249517273266 | validation: 0.08273915103681906]
	TIME [epoch: 25.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829505340986885		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.08829505340986885 | validation: 0.0775598803183234]
	TIME [epoch: 25.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08003601793481507		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08003601793481507 | validation: 0.12023932399712]
	TIME [epoch: 25.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789413567266109		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.09789413567266109 | validation: 0.05100838897516804]
	TIME [epoch: 25.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033927777690259		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.07033927777690259 | validation: 0.15067673773626755]
	TIME [epoch: 25.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0880696973155633		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.0880696973155633 | validation: 0.08812884969001478]
	TIME [epoch: 25.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08346300155604437		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.08346300155604437 | validation: 0.09745830350522834]
	TIME [epoch: 25.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09556988911447538		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.09556988911447538 | validation: 0.0697422731893885]
	TIME [epoch: 25.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06288177110316481		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.06288177110316481 | validation: 0.10173595073095451]
	TIME [epoch: 25.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602070951338176		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.07602070951338176 | validation: 0.047321126687343756]
	TIME [epoch: 25.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10489822469026111		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.10489822469026111 | validation: 0.10897792123505107]
	TIME [epoch: 25.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06285526828252865		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.06285526828252865 | validation: 0.04072545375159141]
	TIME [epoch: 25.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08726781645514864		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.08726781645514864 | validation: 0.0886034870570854]
	TIME [epoch: 25.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772393176119023		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.0772393176119023 | validation: 0.062126525296919685]
	TIME [epoch: 25.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08169538395502704		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.08169538395502704 | validation: 0.1681222328141509]
	TIME [epoch: 25.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475084809945091		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.08475084809945091 | validation: 0.08076276467807486]
	TIME [epoch: 25.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11340758598992742		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.11340758598992742 | validation: 0.06484544291959458]
	TIME [epoch: 25.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04681326191537121		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.04681326191537121 | validation: 0.051512547719677865]
	TIME [epoch: 25.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09638680436712489		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.09638680436712489 | validation: 0.10813976332279479]
	TIME [epoch: 25.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07254425168903225		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.07254425168903225 | validation: 0.09447366676075705]
	TIME [epoch: 25.2 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08607034445951743		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.08607034445951743 | validation: 0.09063933636849025]
	TIME [epoch: 25.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08123996699057418		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.08123996699057418 | validation: 0.055989973179842153]
	TIME [epoch: 25.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06752861871730947		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.06752861871730947 | validation: 0.04002414972844989]
	TIME [epoch: 25.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09406157630828307		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.09406157630828307 | validation: 0.057388698984482525]
	TIME [epoch: 25.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006736338490615		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.08006736338490615 | validation: 0.03536971763648167]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_642.pth
	Model improved!!!
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09768445135181231		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.09768445135181231 | validation: 0.05335658742391537]
	TIME [epoch: 25.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199515761088863		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.10199515761088863 | validation: 0.04692475260194221]
	TIME [epoch: 25.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06812831407878583		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.06812831407878583 | validation: 0.1319859999223248]
	TIME [epoch: 25.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563824898084467		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.08563824898084467 | validation: 0.047475376590162446]
	TIME [epoch: 25.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07127303388647485		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.07127303388647485 | validation: 0.059326509142714375]
	TIME [epoch: 25.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0622241538101571		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.0622241538101571 | validation: 0.09363362134244801]
	TIME [epoch: 25.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092993516972831		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.092993516972831 | validation: 0.044166308458836095]
	TIME [epoch: 25.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05029970096569064		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.05029970096569064 | validation: 0.07409122445663056]
	TIME [epoch: 25.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611069228137401		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.08611069228137401 | validation: 0.08350983400149356]
	TIME [epoch: 25.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439504318861287		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.09439504318861287 | validation: 0.07437172569162356]
	TIME [epoch: 25.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0937364665537582		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0937364665537582 | validation: 0.10327348179808613]
	TIME [epoch: 25.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06636408328484086		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.06636408328484086 | validation: 0.05073556341863113]
	TIME [epoch: 25.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07238778725110342		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.07238778725110342 | validation: 0.04012691989738009]
	TIME [epoch: 25.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06589459985267795		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.06589459985267795 | validation: 0.06768586328935064]
	TIME [epoch: 25.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835225984443378		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.07835225984443378 | validation: 0.03026029945375513]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_657.pth
	Model improved!!!
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059116025468214435		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.059116025468214435 | validation: 0.10221124721345004]
	TIME [epoch: 25.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09146049063200747		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.09146049063200747 | validation: 0.02813047066201218]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042022047433503476		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.042022047433503476 | validation: 0.07663274470833753]
	TIME [epoch: 25.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883185011350306		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.10883185011350306 | validation: 0.047918563320385174]
	TIME [epoch: 25.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09263910921254402		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.09263910921254402 | validation: 0.07373627297472032]
	TIME [epoch: 25.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11274085938496159		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.11274085938496159 | validation: 0.05922520019862107]
	TIME [epoch: 25.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06600176595523027		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.06600176595523027 | validation: 0.06146194351240003]
	TIME [epoch: 25.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2597939245573802		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2597939245573802 | validation: 0.09747428900669965]
	TIME [epoch: 25.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06571734650689175		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.06571734650689175 | validation: 0.05107481801858671]
	TIME [epoch: 25.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0503187037458248		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.0503187037458248 | validation: 0.03844042224213759]
	TIME [epoch: 25.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059971632260608504		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.059971632260608504 | validation: 0.058131861993624905]
	TIME [epoch: 25.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07074055561172993		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.07074055561172993 | validation: 0.05096417893936327]
	TIME [epoch: 25.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139946218010588		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.06139946218010588 | validation: 0.07036873889388606]
	TIME [epoch: 25.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06332257465127024		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06332257465127024 | validation: 0.054028065914668494]
	TIME [epoch: 25.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07273831490544318		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.07273831490544318 | validation: 0.02385416651493976]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_672.pth
	Model improved!!!
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756161946454429		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.04756161946454429 | validation: 0.04561082515304167]
	TIME [epoch: 25.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05557710598848359		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.05557710598848359 | validation: 0.0636678938952444]
	TIME [epoch: 25.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1167021618536243		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.1167021618536243 | validation: 0.2320421529470063]
	TIME [epoch: 25.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825341643175002		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10825341643175002 | validation: 0.046197972194763806]
	TIME [epoch: 25.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801908748093275		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.05801908748093275 | validation: 0.041022294013858]
	TIME [epoch: 25.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05749587601985587		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.05749587601985587 | validation: 0.09374960937827838]
	TIME [epoch: 25.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06076454971948099		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.06076454971948099 | validation: 0.05450688128327983]
	TIME [epoch: 25.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06159755125409469		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06159755125409469 | validation: 0.046156571554102854]
	TIME [epoch: 25.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07347535386247832		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.07347535386247832 | validation: 0.02999703867535227]
	TIME [epoch: 25.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041842159262464824		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.041842159262464824 | validation: 0.04041158413345851]
	TIME [epoch: 25.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08201822389248795		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.08201822389248795 | validation: 0.024995711773907185]
	TIME [epoch: 25.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08130526137594932		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.08130526137594932 | validation: 0.03880471079502058]
	TIME [epoch: 25.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07191151412902477		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.07191151412902477 | validation: 0.044882026232044986]
	TIME [epoch: 25.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05283742474544077		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.05283742474544077 | validation: 0.06560940432048844]
	TIME [epoch: 25.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07000975278875213		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.07000975278875213 | validation: 0.07085832212006275]
	TIME [epoch: 25.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05754419544781218		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.05754419544781218 | validation: 0.028037603405196787]
	TIME [epoch: 25.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06946738567450034		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.06946738567450034 | validation: 0.0956669171541165]
	TIME [epoch: 25.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05430863797251104		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.05430863797251104 | validation: 0.06191988229721816]
	TIME [epoch: 25.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581486757093415		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.06581486757093415 | validation: 0.025484486110660218]
	TIME [epoch: 25.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164103996788247		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.07164103996788247 | validation: 0.040847868595943845]
	TIME [epoch: 25.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060271795675682575		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.060271795675682575 | validation: 0.040154726669732924]
	TIME [epoch: 25.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055352402769687614		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.055352402769687614 | validation: 0.03445378529592614]
	TIME [epoch: 25.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07051077227364991		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.07051077227364991 | validation: 0.032038663758822666]
	TIME [epoch: 25.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860545618512909		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.03860545618512909 | validation: 0.044697253389865896]
	TIME [epoch: 25.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061072647200498424		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.061072647200498424 | validation: 0.0301006830795468]
	TIME [epoch: 25.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08225913605053525		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.08225913605053525 | validation: 0.02960471462652561]
	TIME [epoch: 25.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05756732278334839		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.05756732278334839 | validation: 0.0489426511426566]
	TIME [epoch: 25.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578241692495283		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.05578241692495283 | validation: 0.06905995817117777]
	TIME [epoch: 25.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809925264669701		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.06809925264669701 | validation: 0.04293746747270212]
	TIME [epoch: 25.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06176414412772936		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.06176414412772936 | validation: 0.0683943004501197]
	TIME [epoch: 25.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053353229226363916		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.053353229226363916 | validation: 0.028724141323708076]
	TIME [epoch: 25.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05811397795659672		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.05811397795659672 | validation: 0.05649948775612067]
	TIME [epoch: 25.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596054650954863		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.05596054650954863 | validation: 0.057208828872817134]
	TIME [epoch: 25.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06152527188128782		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.06152527188128782 | validation: 0.03882775915144172]
	TIME [epoch: 25.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05527506489501857		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.05527506489501857 | validation: 0.02641856858954792]
	TIME [epoch: 25.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918521178779329		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.05918521178779329 | validation: 0.045605987991767606]
	TIME [epoch: 25.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12627271950945634		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.12627271950945634 | validation: 0.24651106923410177]
	TIME [epoch: 25.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09916538588401229		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.09916538588401229 | validation: 0.02501591333156935]
	TIME [epoch: 25.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03352562743624331		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.03352562743624331 | validation: 0.02871936919807539]
	TIME [epoch: 25.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255710623361548		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.05255710623361548 | validation: 0.06409629029380944]
	TIME [epoch: 25.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843517068586246		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.08843517068586246 | validation: 0.04737126231879523]
	TIME [epoch: 25.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06183924020771335		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.06183924020771335 | validation: 0.035306573363876076]
	TIME [epoch: 25.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051828229473419495		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.051828229473419495 | validation: 0.025005814632151627]
	TIME [epoch: 25.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997533285173213		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.04997533285173213 | validation: 0.04111760667419958]
	TIME [epoch: 25.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050955377164416386		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.050955377164416386 | validation: 0.06544263329881718]
	TIME [epoch: 25.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06184643674653038		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.06184643674653038 | validation: 0.031209518460264662]
	TIME [epoch: 25.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05772601914173882		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.05772601914173882 | validation: 0.023039743633662763]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08768565042057003		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.08768565042057003 | validation: 0.03577517695731491]
	TIME [epoch: 25.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04601706015062961		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.04601706015062961 | validation: 0.03692402605749117]
	TIME [epoch: 25.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038994628582561336		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.038994628582561336 | validation: 0.038900154272236816]
	TIME [epoch: 25.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06466905185033417		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.06466905185033417 | validation: 0.03364559844558519]
	TIME [epoch: 25.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593280807781716		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07593280807781716 | validation: 0.08308300184472228]
	TIME [epoch: 25.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06086533911932168		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.06086533911932168 | validation: 0.040456320518613254]
	TIME [epoch: 25.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039996695764929		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.04039996695764929 | validation: 0.01968907925125096]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737739142085245		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.0737739142085245 | validation: 0.04593110702155593]
	TIME [epoch: 25.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05153549132638731		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.05153549132638731 | validation: 0.060030665406600556]
	TIME [epoch: 25.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041245048796588385		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.041245048796588385 | validation: 0.03292693837259788]
	TIME [epoch: 25.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05856298758036005		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05856298758036005 | validation: 0.12666801809049913]
	TIME [epoch: 25.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07451586864992202		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.07451586864992202 | validation: 0.030914463147362153]
	TIME [epoch: 25.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041504895183607435		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.041504895183607435 | validation: 0.08000077212894319]
	TIME [epoch: 25.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230388891347359		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.06230388891347359 | validation: 0.06526072529885026]
	TIME [epoch: 25.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046217330423988436		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.046217330423988436 | validation: 0.01943492447531755]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832733146604947		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.05832733146604947 | validation: 0.037642189521923365]
	TIME [epoch: 25.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05433700063123083		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.05433700063123083 | validation: 0.08589375510206554]
	TIME [epoch: 25.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914969286365569		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.04914969286365569 | validation: 0.020753202924633975]
	TIME [epoch: 25.2 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051932498483449746		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.051932498483449746 | validation: 0.053628762731207785]
	TIME [epoch: 25.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04251510112900265		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.04251510112900265 | validation: 0.0802121153997092]
	TIME [epoch: 25.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06045324567145262		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.06045324567145262 | validation: 0.03876189461264898]
	TIME [epoch: 25.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447698254001172		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.04447698254001172 | validation: 0.03437646152528118]
	TIME [epoch: 25.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03988955580985771		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.03988955580985771 | validation: 0.04789500508330219]
	TIME [epoch: 25.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05799289815322958		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.05799289815322958 | validation: 0.026391927148085647]
	TIME [epoch: 25.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06749095264268681		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.06749095264268681 | validation: 0.02319917213245397]
	TIME [epoch: 25.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036935993075924274		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.036935993075924274 | validation: 0.06550616439048411]
	TIME [epoch: 25.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371568476193328		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.05371568476193328 | validation: 0.019573082513253466]
	TIME [epoch: 25.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033609744999488295		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.033609744999488295 | validation: 0.0569387890550814]
	TIME [epoch: 25.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2031996221346712		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.2031996221346712 | validation: 0.127463679947702]
	TIME [epoch: 25.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566610157190886		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.06566610157190886 | validation: 0.02335568729535999]
	TIME [epoch: 25.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08408584579923062		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.08408584579923062 | validation: 0.05051598111543243]
	TIME [epoch: 25.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04135655050873742		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.04135655050873742 | validation: 0.052876384994837426]
	TIME [epoch: 25.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612679456926763		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.04612679456926763 | validation: 0.032442679338293576]
	TIME [epoch: 25.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047061927446380845		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.047061927446380845 | validation: 0.027296470868724554]
	TIME [epoch: 25.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03822080493544952		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.03822080493544952 | validation: 0.08382526055355052]
	TIME [epoch: 25.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009272180009807		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.05009272180009807 | validation: 0.031094956900380034]
	TIME [epoch: 25.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045952305223675466		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.045952305223675466 | validation: 0.07347084458706454]
	TIME [epoch: 25.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054206465774070595		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.054206465774070595 | validation: 0.03114594080469895]
	TIME [epoch: 25.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043898003823336515		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.043898003823336515 | validation: 0.0683839872430039]
	TIME [epoch: 25.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20222584406568994		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.20222584406568994 | validation: 0.15217807487550872]
	TIME [epoch: 25.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09326311920107745		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.09326311920107745 | validation: 0.03401406484619828]
	TIME [epoch: 25.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153760839094317		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.04153760839094317 | validation: 0.0195295181251227]
	TIME [epoch: 25.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040770716855992165		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.040770716855992165 | validation: 0.033523179584936266]
	TIME [epoch: 25.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042553456934088074		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.042553456934088074 | validation: 0.061627620032581765]
	TIME [epoch: 25.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03947879564709025		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.03947879564709025 | validation: 0.02882860511888123]
	TIME [epoch: 25.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04506425496687435		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.04506425496687435 | validation: 0.02135868974173937]
	TIME [epoch: 25.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769685992746172		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.03769685992746172 | validation: 0.03970077504298103]
	TIME [epoch: 25.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974213357895981		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.03974213357895981 | validation: 0.04308019837743013]
	TIME [epoch: 25.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04073122762277845		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.04073122762277845 | validation: 0.02239805827693793]
	TIME [epoch: 25.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999267994288119		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.04999267994288119 | validation: 0.06511736586315432]
	TIME [epoch: 25.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637556473091374		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.0637556473091374 | validation: 0.022934694599077144]
	TIME [epoch: 25.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048712820880892724		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.048712820880892724 | validation: 0.027699839743960404]
	TIME [epoch: 25.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02851290381060246		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.02851290381060246 | validation: 0.0233117330764515]
	TIME [epoch: 25.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258726012751653		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.06258726012751653 | validation: 0.03671126580454363]
	TIME [epoch: 25.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062496391255047426		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.062496391255047426 | validation: 0.019200501391913625]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_774.pth
	Model improved!!!
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343156837669802		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.0343156837669802 | validation: 0.05393645850533604]
	TIME [epoch: 25.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048247502514665176		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.048247502514665176 | validation: 0.03077185049294095]
	TIME [epoch: 25.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03758091646368056		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.03758091646368056 | validation: 0.046184231742206525]
	TIME [epoch: 25.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619020749030376		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.04619020749030376 | validation: 0.057915503055354076]
	TIME [epoch: 25.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03643955906414162		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.03643955906414162 | validation: 0.01965588224147336]
	TIME [epoch: 25.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764162816563766		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.02764162816563766 | validation: 0.020745080889192354]
	TIME [epoch: 25.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036862179203331506		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.036862179203331506 | validation: 0.02681809310787826]
	TIME [epoch: 25.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06305174662339229		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.06305174662339229 | validation: 0.026552249764285996]
	TIME [epoch: 25.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0327534230472693		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0327534230472693 | validation: 0.032016527511805074]
	TIME [epoch: 25.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03610842533748079		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.03610842533748079 | validation: 0.03459267937900804]
	TIME [epoch: 25.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06568196058416677		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06568196058416677 | validation: 0.0577524503508812]
	TIME [epoch: 25.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047160641489526055		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.047160641489526055 | validation: 0.049018860835105454]
	TIME [epoch: 25.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034525091255058156		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.034525091255058156 | validation: 0.01664990783497096]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04456883410060031		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.04456883410060031 | validation: 0.034804552587896394]
	TIME [epoch: 25.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03530473909658889		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.03530473909658889 | validation: 0.04095224995958428]
	TIME [epoch: 25.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596041053552648		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.03596041053552648 | validation: 0.07944271535645513]
	TIME [epoch: 25.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04404147164037896		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.04404147164037896 | validation: 0.049163753758100254]
	TIME [epoch: 25.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04238967618673583		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.04238967618673583 | validation: 0.02562492003876199]
	TIME [epoch: 25.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924298935277831		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.03924298935277831 | validation: 0.02101142361008713]
	TIME [epoch: 25.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0489301243836232		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.0489301243836232 | validation: 0.028827377000418222]
	TIME [epoch: 25.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031480103650149915		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.031480103650149915 | validation: 0.03783060396937725]
	TIME [epoch: 25.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0425294763849896		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.0425294763849896 | validation: 0.08117988670105411]
	TIME [epoch: 25.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04916374308821481		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.04916374308821481 | validation: 0.021720076528671115]
	TIME [epoch: 25.2 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481581651916214		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.04481581651916214 | validation: 0.06167092743829845]
	TIME [epoch: 25.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06840541066024157		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.06840541066024157 | validation: 0.040062815335023205]
	TIME [epoch: 25.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03124703854741969		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.03124703854741969 | validation: 0.022593213696682303]
	TIME [epoch: 25.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048448537936893965		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.048448537936893965 | validation: 0.030613493403281677]
	TIME [epoch: 25.2 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263178643690589		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.03263178643690589 | validation: 0.028327166493236203]
	TIME [epoch: 25.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753502183887029		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.04753502183887029 | validation: 0.018027193318924724]
	TIME [epoch: 25.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025646569021215045		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.025646569021215045 | validation: 0.21894471246573027]
	TIME [epoch: 25.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11924544038169825		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.11924544038169825 | validation: 0.055033815509269085]
	TIME [epoch: 25.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096892767144908		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.04096892767144908 | validation: 0.022570330889634657]
	TIME [epoch: 25.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036566620792857545		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.036566620792857545 | validation: 0.03371767133041205]
	TIME [epoch: 25.2 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029373522264052168		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.029373522264052168 | validation: 0.23368697031112523]
	TIME [epoch: 25.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376190989680635		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.15376190989680635 | validation: 0.03199653239870647]
	TIME [epoch: 25.2 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032672436836822555		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.032672436836822555 | validation: 0.021703315009929773]
	TIME [epoch: 25.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304602755237641		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.03304602755237641 | validation: 0.01928057365580721]
	TIME [epoch: 25.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998395711542312		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.02998395711542312 | validation: 0.044315484514972144]
	TIME [epoch: 25.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04048891668357447		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.04048891668357447 | validation: 0.03405681958493179]
	TIME [epoch: 25.2 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045825209438746864		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.045825209438746864 | validation: 0.0306056257945009]
	TIME [epoch: 25.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026770309678862347		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.026770309678862347 | validation: 0.018270329599185543]
	TIME [epoch: 25.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03814755443621422		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.03814755443621422 | validation: 0.08810711648475186]
	TIME [epoch: 25.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434632381008737		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.04434632381008737 | validation: 0.01894124752180016]
	TIME [epoch: 25.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04003787235759182		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.04003787235759182 | validation: 0.025212916232735427]
	TIME [epoch: 25.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026276718182097012		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.026276718182097012 | validation: 0.016734728009143378]
	TIME [epoch: 25.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029261972317536612		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.029261972317536612 | validation: 0.08867348747984621]
	TIME [epoch: 25.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06455002316610209		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06455002316610209 | validation: 0.027278216172608817]
	TIME [epoch: 25.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028052177773815593		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.028052177773815593 | validation: 0.019827808970682856]
	TIME [epoch: 25.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592722960507634		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03592722960507634 | validation: 0.040949447500759656]
	TIME [epoch: 25.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165807295542063		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03165807295542063 | validation: 0.04745828222058536]
	TIME [epoch: 25.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622317326541539		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.03622317326541539 | validation: 0.05247623318761841]
	TIME [epoch: 25.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04457512367525584		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.04457512367525584 | validation: 0.023344281374888323]
	TIME [epoch: 25.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03402079230210413		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.03402079230210413 | validation: 0.01915687380158408]
	TIME [epoch: 25.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030180997892912703		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.030180997892912703 | validation: 0.06447631450245496]
	TIME [epoch: 25.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05264516297309114		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.05264516297309114 | validation: 0.026367158184774413]
	TIME [epoch: 25.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031936161096122684		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.031936161096122684 | validation: 0.017474014670250594]
	TIME [epoch: 25.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02883245264087626		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.02883245264087626 | validation: 0.03239990317811743]
	TIME [epoch: 25.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322308232084506		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0322308232084506 | validation: 0.03752888128356688]
	TIME [epoch: 25.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549773257316423		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04549773257316423 | validation: 0.05156422613179723]
	TIME [epoch: 25.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03489046670991366		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.03489046670991366 | validation: 0.028714602657178498]
	TIME [epoch: 25.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0358013045260332		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.0358013045260332 | validation: 0.014340636732887657]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027927062011964793		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.027927062011964793 | validation: 0.08606395004898124]
	TIME [epoch: 25.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056385613738811534		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.056385613738811534 | validation: 0.0313136588377502]
	TIME [epoch: 25.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029321211234532192		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.029321211234532192 | validation: 0.015215763748189212]
	TIME [epoch: 25.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0310592639716213		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0310592639716213 | validation: 0.049144746463599766]
	TIME [epoch: 25.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485764150247909		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03485764150247909 | validation: 0.021142658202831253]
	TIME [epoch: 25.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951193829621426		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.03951193829621426 | validation: 0.0161809932249252]
	TIME [epoch: 25.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031508722981683085		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.031508722981683085 | validation: 0.025083760972528776]
	TIME [epoch: 25.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165902803225407		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.03165902803225407 | validation: 0.018488342694090717]
	TIME [epoch: 25.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025560765999855857		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.025560765999855857 | validation: 0.025060432309934023]
	TIME [epoch: 25.2 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05364706149700567		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.05364706149700567 | validation: 0.04012241373145004]
	TIME [epoch: 25.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038326942472509146		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.038326942472509146 | validation: 0.028681632414122048]
	TIME [epoch: 25.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045036695105649116		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.045036695105649116 | validation: 0.03220137011246696]
	TIME [epoch: 25.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027703034853296553		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.027703034853296553 | validation: 0.01846754144765745]
	TIME [epoch: 25.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028612321870898558		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.028612321870898558 | validation: 0.02267755296800847]
	TIME [epoch: 25.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388818028178454		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.03388818028178454 | validation: 0.015002693079043602]
	TIME [epoch: 25.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036868561350439054		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.036868561350439054 | validation: 0.03695004978680219]
	TIME [epoch: 25.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03252073810267351		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.03252073810267351 | validation: 0.026710213825616627]
	TIME [epoch: 25.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352103244758776		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.04352103244758776 | validation: 0.023419079110220616]
	TIME [epoch: 25.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028306230739938376		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.028306230739938376 | validation: 0.029623036298645912]
	TIME [epoch: 25.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03303084156727309		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.03303084156727309 | validation: 0.02442769011900531]
	TIME [epoch: 25.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036320758287641405		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.036320758287641405 | validation: 0.015996209310030846]
	TIME [epoch: 25.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04633291717171325		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.04633291717171325 | validation: 0.031047150314609476]
	TIME [epoch: 25.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027644185451680715		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.027644185451680715 | validation: 0.02586851373454443]
	TIME [epoch: 25.2 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029597351060485482		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.029597351060485482 | validation: 0.01829350001358481]
	TIME [epoch: 25.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024427820484003028		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.024427820484003028 | validation: 0.01721866733527657]
	TIME [epoch: 25.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033947639578958855		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.033947639578958855 | validation: 0.05032929282603875]
	TIME [epoch: 25.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03788814390556671		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.03788814390556671 | validation: 0.017860923838526305]
	TIME [epoch: 25.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025447106061665323		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.025447106061665323 | validation: 0.02899201128488874]
	TIME [epoch: 25.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496737653506872		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.03496737653506872 | validation: 0.04179577876211236]
	TIME [epoch: 25.2 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933642890359469		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.02933642890359469 | validation: 0.014157402378149171]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03412221660237087		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.03412221660237087 | validation: 0.030788371014537505]
	TIME [epoch: 25.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04353736243708125		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.04353736243708125 | validation: 0.022615702751335544]
	TIME [epoch: 25.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028593341300131		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.028593341300131 | validation: 0.016420172410827136]
	TIME [epoch: 25.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026661152133098005		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.026661152133098005 | validation: 0.033352694481686235]
	TIME [epoch: 25.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027410895742737904		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.027410895742737904 | validation: 0.05565825187291139]
	TIME [epoch: 25.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039092903853194985		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.039092903853194985 | validation: 0.10031703433619651]
	TIME [epoch: 25.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061117508923757		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.06061117508923757 | validation: 0.022547905727976464]
	TIME [epoch: 25.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030263437087708553		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.030263437087708553 | validation: 0.018433236469506984]
	TIME [epoch: 25.2 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025717354093322403		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.025717354093322403 | validation: 0.0218984585298585]
	TIME [epoch: 25.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379906763093478		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.03379906763093478 | validation: 0.059399496802873014]
	TIME [epoch: 25.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035903157191531504		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.035903157191531504 | validation: 0.031509072983180925]
	TIME [epoch: 25.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04207886008704424		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.04207886008704424 | validation: 0.019142409746958414]
	TIME [epoch: 25.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028937720551857574		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.028937720551857574 | validation: 0.02293141275154237]
	TIME [epoch: 25.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027908088747555435		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.027908088747555435 | validation: 0.01841010434642555]
	TIME [epoch: 25.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029393664552041884		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.029393664552041884 | validation: 0.01709978497566514]
	TIME [epoch: 25.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02360956328159377		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.02360956328159377 | validation: 0.030733764267511135]
	TIME [epoch: 25.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044368472134973684		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.044368472134973684 | validation: 0.018228060487681406]
	TIME [epoch: 25.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022621901197040065		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.022621901197040065 | validation: 0.019556395210525643]
	TIME [epoch: 25.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027544046142000254		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.027544046142000254 | validation: 0.01964588667472897]
	TIME [epoch: 25.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023049085862895908		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.023049085862895908 | validation: 0.025175471483314157]
	TIME [epoch: 25.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03850558544233559		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.03850558544233559 | validation: 0.014398281600901758]
	TIME [epoch: 25.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029504438589243398		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.029504438589243398 | validation: 0.016959576822735134]
	TIME [epoch: 25.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023716748979909625		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.023716748979909625 | validation: 0.025051796603448556]
	TIME [epoch: 25.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779437203761578		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.03779437203761578 | validation: 0.0358370540417814]
	TIME [epoch: 25.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028427973899981203		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.028427973899981203 | validation: 0.06656985655852032]
	TIME [epoch: 25.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040719761863445544		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.040719761863445544 | validation: 0.0339235691730254]
	TIME [epoch: 25.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030158782912402364		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.030158782912402364 | validation: 0.02196308430965066]
	TIME [epoch: 25.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02723460957543644		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.02723460957543644 | validation: 0.04067808272691696]
	TIME [epoch: 25.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147643864213749		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.03147643864213749 | validation: 0.01514019463853452]
	TIME [epoch: 25.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033323833500625274		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.033323833500625274 | validation: 0.01876291064878224]
	TIME [epoch: 25.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024674967612220794		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.024674967612220794 | validation: 0.023256934076557153]
	TIME [epoch: 25.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027334102310455854		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.027334102310455854 | validation: 0.023461939915628453]
	TIME [epoch: 25.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030754933215962788		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.030754933215962788 | validation: 0.023385262337737727]
	TIME [epoch: 25.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976129212716014		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.03976129212716014 | validation: 0.04101437247435226]
	TIME [epoch: 25.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136972565823108		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.03136972565823108 | validation: 0.02091116414498654]
	TIME [epoch: 25.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023067589432485505		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.023067589432485505 | validation: 0.1415090102407805]
	TIME [epoch: 25.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08135899381840098		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.08135899381840098 | validation: 0.019016525774342256]
	TIME [epoch: 25.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025213032617912703		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.025213032617912703 | validation: 0.025585851773963827]
	TIME [epoch: 25.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024768864106506853		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.024768864106506853 | validation: 0.01975112787740735]
	TIME [epoch: 25.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04441051198982547		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.04441051198982547 | validation: 0.022532624672810874]
	TIME [epoch: 25.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03045457893490819		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.03045457893490819 | validation: 0.017751477311340805]
	TIME [epoch: 25.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508758070957088		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.03508758070957088 | validation: 0.01901848334616056]
	TIME [epoch: 25.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020473094076973106		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.020473094076973106 | validation: 0.015774987017944615]
	TIME [epoch: 25.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02858616619224484		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.02858616619224484 | validation: 0.023870313275740733]
	TIME [epoch: 25.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02496497568067787		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.02496497568067787 | validation: 0.014198880668525048]
	TIME [epoch: 25.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020665282862485933		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.020665282862485933 | validation: 0.10250855558991198]
	TIME [epoch: 25.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06136690290224032		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.06136690290224032 | validation: 0.016159378590843765]
	TIME [epoch: 25.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359900951189385		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.02359900951189385 | validation: 0.0180069978225396]
	TIME [epoch: 25.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030190474811811405		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.030190474811811405 | validation: 0.017841238394933512]
	TIME [epoch: 25.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02154825954872911		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.02154825954872911 | validation: 0.021685256252323835]
	TIME [epoch: 25.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025443128452452335		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.025443128452452335 | validation: 0.017506810409114386]
	TIME [epoch: 25.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03171623387386404		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.03171623387386404 | validation: 0.027984586197696552]
	TIME [epoch: 25.2 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052531066203667265		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.052531066203667265 | validation: 0.1436612253197515]
	TIME [epoch: 25.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06903325613725694		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.06903325613725694 | validation: 0.043495441602556695]
	TIME [epoch: 25.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03024509299163681		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.03024509299163681 | validation: 0.01421298250296891]
	TIME [epoch: 25.2 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021290771062212676		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.021290771062212676 | validation: 0.013633458604275167]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025998436069501085		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.025998436069501085 | validation: 0.021606043619151225]
	TIME [epoch: 25.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04160245648234681		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.04160245648234681 | validation: 0.02032650101881547]
	TIME [epoch: 25.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02478345204393559		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.02478345204393559 | validation: 0.027975312482628245]
	TIME [epoch: 25.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023036817728591036		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.023036817728591036 | validation: 0.02022843845425752]
	TIME [epoch: 25.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02474181051966583		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.02474181051966583 | validation: 0.017174397086195396]
	TIME [epoch: 25.2 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03140985253937194		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.03140985253937194 | validation: 0.01605076520747186]
	TIME [epoch: 25.2 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02084930604078595		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.02084930604078595 | validation: 0.015757483991583113]
	TIME [epoch: 25.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024693397518430173		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.024693397518430173 | validation: 0.012574815125338439]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_929.pth
	Model improved!!!
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02003690324741722		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.02003690324741722 | validation: 0.026142896201125372]
	TIME [epoch: 25.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045749174342022664		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.045749174342022664 | validation: 0.015822383708592465]
	TIME [epoch: 25.2 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02318335808065184		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.02318335808065184 | validation: 0.017107192784827058]
	TIME [epoch: 25.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022972111914111748		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.022972111914111748 | validation: 0.027732561148705502]
	TIME [epoch: 25.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024376731735335784		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.024376731735335784 | validation: 0.033163484133265586]
	TIME [epoch: 25.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02924601291448247		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.02924601291448247 | validation: 0.01934284115349196]
	TIME [epoch: 25.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025218929385892937		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.025218929385892937 | validation: 0.020408412287570822]
	TIME [epoch: 25.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639333052397582		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.02639333052397582 | validation: 0.017834093353715545]
	TIME [epoch: 25.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0223619728236512		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.0223619728236512 | validation: 0.015282484063227283]
	TIME [epoch: 25.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042004880219121014		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.042004880219121014 | validation: 0.04101325619259311]
	TIME [epoch: 25.2 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453540551925431		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.03453540551925431 | validation: 0.021228607800311265]
	TIME [epoch: 25.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022784170959837556		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.022784170959837556 | validation: 0.015513268906948409]
	TIME [epoch: 25.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02361658987268557		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.02361658987268557 | validation: 0.019713121814827476]
	TIME [epoch: 25.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022514966738416742		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.022514966738416742 | validation: 0.016068622196345465]
	TIME [epoch: 25.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02205310918212003		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.02205310918212003 | validation: 0.023920749115512358]
	TIME [epoch: 25.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02493607241139001		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.02493607241139001 | validation: 0.029805901327481794]
	TIME [epoch: 25.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032373882706565216		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.032373882706565216 | validation: 0.02701720214443078]
	TIME [epoch: 25.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022910704115548082		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.022910704115548082 | validation: 0.017635224596365337]
	TIME [epoch: 25.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030721588439188645		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.030721588439188645 | validation: 0.01458132565062231]
	TIME [epoch: 25.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02219261060872255		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.02219261060872255 | validation: 0.014866041985923735]
	TIME [epoch: 25.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021954005044104812		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.021954005044104812 | validation: 0.039652117666730935]
	TIME [epoch: 25.2 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027010257554011635		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.027010257554011635 | validation: 0.01434672753805453]
	TIME [epoch: 25.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024957020419109934		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.024957020419109934 | validation: 0.020744164523055313]
	TIME [epoch: 25.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02223066810496988		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.02223066810496988 | validation: 0.01938818781248006]
	TIME [epoch: 25.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03143499446892606		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.03143499446892606 | validation: 0.014117406570823308]
	TIME [epoch: 25.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021708414205132753		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.021708414205132753 | validation: 0.013772535863397405]
	TIME [epoch: 25.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02280123874825616		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.02280123874825616 | validation: 0.036991406606112553]
	TIME [epoch: 25.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02449682206202785		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.02449682206202785 | validation: 0.021664901575193664]
	TIME [epoch: 25.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02313926004306667		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.02313926004306667 | validation: 0.01621666258816789]
	TIME [epoch: 25.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026570116079566455		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.026570116079566455 | validation: 0.01803596978970664]
	TIME [epoch: 25.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024202043305470582		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.024202043305470582 | validation: 0.024121329918587762]
	TIME [epoch: 25.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020395214845275032		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.020395214845275032 | validation: 0.045516827929892104]
	TIME [epoch: 25.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03096963790496201		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.03096963790496201 | validation: 0.026472810666462974]
	TIME [epoch: 25.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027089888255036776		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.027089888255036776 | validation: 0.027019413620029714]
	TIME [epoch: 25.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076764815638327		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04076764815638327 | validation: 0.07445370533335259]
	TIME [epoch: 25.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04484427080440227		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04484427080440227 | validation: 0.022270190946593493]
	TIME [epoch: 25.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023696894182123878		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.023696894182123878 | validation: 0.019268625507440254]
	TIME [epoch: 25.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0234136236228839		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.0234136236228839 | validation: 0.04049934729920127]
	TIME [epoch: 25.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027126786103920813		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.027126786103920813 | validation: 0.013332503082974064]
	TIME [epoch: 25.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020043498237712683		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.020043498237712683 | validation: 0.017806216908502055]
	TIME [epoch: 25.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02353019018041528		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.02353019018041528 | validation: 0.020252776595691906]
	TIME [epoch: 25.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024181662840863493		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.024181662840863493 | validation: 0.018248005005894137]
	TIME [epoch: 25.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021633624715154016		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.021633624715154016 | validation: 0.020695462604327863]
	TIME [epoch: 25.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03379140055356493		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.03379140055356493 | validation: 0.02591613029029701]
	TIME [epoch: 25.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02596757254595378		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.02596757254595378 | validation: 0.013682727096550683]
	TIME [epoch: 25.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023194916506540392		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.023194916506540392 | validation: 0.016336752467194415]
	TIME [epoch: 25.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023085799868040668		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.023085799868040668 | validation: 0.013927372969204453]
	TIME [epoch: 25.2 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021979851325823065		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.021979851325823065 | validation: 0.01786227828522867]
	TIME [epoch: 25.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019818454029796165		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.019818454029796165 | validation: 0.012321796552729886]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_978.pth
	Model improved!!!
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020765069607371525		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.020765069607371525 | validation: 0.014921489835758027]
	TIME [epoch: 25.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02030559907895718		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.02030559907895718 | validation: 0.014382116421972301]
	TIME [epoch: 25.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026248757326279733		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.026248757326279733 | validation: 0.026109260211310555]
	TIME [epoch: 25.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022271082867073327		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.022271082867073327 | validation: 0.022784134211729323]
	TIME [epoch: 25.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023055693257965415		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.023055693257965415 | validation: 0.012814283353249644]
	TIME [epoch: 25.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01865990260369398		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.01865990260369398 | validation: 0.020200451423853988]
	TIME [epoch: 25.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025366367778598388		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.025366367778598388 | validation: 0.018637880746687055]
	TIME [epoch: 25.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08153842396451721		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.08153842396451721 | validation: 0.054072002226689196]
	TIME [epoch: 25.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640255830316886		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.03640255830316886 | validation: 0.02306819013225307]
	TIME [epoch: 25.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022046880398628465		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.022046880398628465 | validation: 0.012555018838628834]
	TIME [epoch: 25.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0183126977588994		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.0183126977588994 | validation: 0.012353380679066392]
	TIME [epoch: 25.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01931294626554989		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.01931294626554989 | validation: 0.013738115572423496]
	TIME [epoch: 25.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01887259670602546		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.01887259670602546 | validation: 0.01418222554936247]
	TIME [epoch: 25.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024013256813882326		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.024013256813882326 | validation: 0.013873223622625136]
	TIME [epoch: 25.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020014963685460983		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.020014963685460983 | validation: 0.018770146059523977]
	TIME [epoch: 25.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365267908606068		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.02365267908606068 | validation: 0.028841457280551534]
	TIME [epoch: 25.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023682893135400375		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.023682893135400375 | validation: 0.0123456629164521]
	TIME [epoch: 25.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018127455311441998		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.018127455311441998 | validation: 0.018791263827156866]
	TIME [epoch: 25.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024848045583205417		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.024848045583205417 | validation: 0.013341571843158175]
	TIME [epoch: 25.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021339077101737408		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.021339077101737408 | validation: 0.014787720304969776]
	TIME [epoch: 25.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022534737130478325		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.022534737130478325 | validation: 0.011936501196567105]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_999.pth
	Model improved!!!
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244739780893916		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.0244739780893916 | validation: 0.014947252648485763]
	TIME [epoch: 25.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01906493186419647		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.01906493186419647 | validation: 0.0212778233765746]
	TIME [epoch: 426 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022730596373000005		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.022730596373000005 | validation: 0.023493398746619303]
	TIME [epoch: 53.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018846764520219494		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.018846764520219494 | validation: 0.013242033067420549]
	TIME [epoch: 53.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01817703454859025		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.01817703454859025 | validation: 0.02352043014931174]
	TIME [epoch: 53.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025959352788106602		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.025959352788106602 | validation: 0.014121849437269433]
	TIME [epoch: 53.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017757786829108183		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.017757786829108183 | validation: 0.018005084746356106]
	TIME [epoch: 53.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023493820150021504		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.023493820150021504 | validation: 0.022097529801434]
	TIME [epoch: 53.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022116622380902656		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.022116622380902656 | validation: 0.01438661215496088]
	TIME [epoch: 53.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018397216634630367		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.018397216634630367 | validation: 0.015401249833345048]
	TIME [epoch: 53.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024891994602183165		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.024891994602183165 | validation: 0.021447595625732653]
	TIME [epoch: 53.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022779186885524386		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.022779186885524386 | validation: 0.02026294821279637]
	TIME [epoch: 53.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01803557372601285		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.01803557372601285 | validation: 0.013411389547483757]
	TIME [epoch: 53.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01948956057612359		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.01948956057612359 | validation: 0.016498844246054925]
	TIME [epoch: 53.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02950214596711799		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.02950214596711799 | validation: 0.017546432293931123]
	TIME [epoch: 53.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02425619115681487		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.02425619115681487 | validation: 0.016677651642514973]
	TIME [epoch: 53.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021624990817432254		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.021624990817432254 | validation: 0.011635844409268615]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_1016.pth
	Model improved!!!
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018637940278081737		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.018637940278081737 | validation: 0.014316992403735202]
	TIME [epoch: 53.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01740150541933136		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.01740150541933136 | validation: 0.015329684517332905]
	TIME [epoch: 53.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020577165820457162		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.020577165820457162 | validation: 0.026102068517889022]
	TIME [epoch: 53.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019759617991324765		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.019759617991324765 | validation: 0.01446549467668777]
	TIME [epoch: 53.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02572792806690206		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.02572792806690206 | validation: 0.012329892188051684]
	TIME [epoch: 53.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018104772724722742		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.018104772724722742 | validation: 0.013024171673347702]
	TIME [epoch: 53.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01984169685392123		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.01984169685392123 | validation: 0.026782108780584724]
	TIME [epoch: 53.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023942758050090433		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.023942758050090433 | validation: 0.012820170359137427]
	TIME [epoch: 53.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01749689798409625		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.01749689798409625 | validation: 0.042023508656180195]
	TIME [epoch: 53.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023463883705457784		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.023463883705457784 | validation: 0.012937801454818825]
	TIME [epoch: 53.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733325111908839		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.01733325111908839 | validation: 0.0167581882197968]
	TIME [epoch: 53.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876404820356214		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.01876404820356214 | validation: 0.012856822403519104]
	TIME [epoch: 53.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022868686512048902		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.022868686512048902 | validation: 0.018435690124491488]
	TIME [epoch: 53.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967172976136563		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.01967172976136563 | validation: 0.015076808167981844]
	TIME [epoch: 53.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01982610805628324		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.01982610805628324 | validation: 0.02397422237405209]
	TIME [epoch: 53.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019788355998950076		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.019788355998950076 | validation: 0.017048078591835263]
	TIME [epoch: 53.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018608962120212263		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.018608962120212263 | validation: 0.017925527495702545]
	TIME [epoch: 53.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018109919874513908		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.018109919874513908 | validation: 0.02217150698498517]
	TIME [epoch: 53.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021488700364865755		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.021488700364865755 | validation: 0.02364412425363066]
	TIME [epoch: 53.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020907399761331765		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.020907399761331765 | validation: 0.025829729568989032]
	TIME [epoch: 53.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0262610738820154		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.0262610738820154 | validation: 0.01804130587307966]
	TIME [epoch: 53.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020915296851389382		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.020915296851389382 | validation: 0.011180246171505686]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_1038.pth
	Model improved!!!
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018455926890192258		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.018455926890192258 | validation: 0.013781521941263069]
	TIME [epoch: 53.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018744238545933337		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.018744238545933337 | validation: 0.012545395991478088]
	TIME [epoch: 53.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019492692377888043		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.019492692377888043 | validation: 0.019317625426978017]
	TIME [epoch: 53.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021308934484420963		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.021308934484420963 | validation: 0.016099557968937694]
	TIME [epoch: 53.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017699644052270133		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.017699644052270133 | validation: 0.012928087399218986]
	TIME [epoch: 53.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018057441992638763		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.018057441992638763 | validation: 0.01769253684755432]
	TIME [epoch: 53.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02016966494679922		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.02016966494679922 | validation: 0.016412443658668487]
	TIME [epoch: 53.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019290705314078123		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.019290705314078123 | validation: 0.01496084949994779]
	TIME [epoch: 53.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712095561172959		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.01712095561172959 | validation: 0.018913194548047116]
	TIME [epoch: 53.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021600906639561053		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.021600906639561053 | validation: 0.012339234446582758]
	TIME [epoch: 53.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02035985384843024		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.02035985384843024 | validation: 0.013934444921761806]
	TIME [epoch: 53.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017501839306952188		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.017501839306952188 | validation: 0.016827474092636616]
	TIME [epoch: 53.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020530509039750268		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.020530509039750268 | validation: 0.024327689867527855]
	TIME [epoch: 53.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024515339615481937		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.024515339615481937 | validation: 0.013646332102438551]
	TIME [epoch: 53.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018185232419127638		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.018185232419127638 | validation: 0.013182082812945198]
	TIME [epoch: 53.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017062270441110673		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.017062270441110673 | validation: 0.012862078918585852]
	TIME [epoch: 53.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01962831859365955		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.01962831859365955 | validation: 0.028842132627315643]
	TIME [epoch: 53.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021901309412283583		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.021901309412283583 | validation: 0.014259682888928994]
	TIME [epoch: 53.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02326221305475942		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.02326221305475942 | validation: 0.014535449669689756]
	TIME [epoch: 53.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020229216616630782		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.020229216616630782 | validation: 0.023598353551075504]
	TIME [epoch: 53.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020147335391020628		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.020147335391020628 | validation: 0.01448311195740775]
	TIME [epoch: 53.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016305076188712953		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.016305076188712953 | validation: 0.012517422587233297]
	TIME [epoch: 53.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018603860132458745		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.018603860132458745 | validation: 0.02857903427488053]
	TIME [epoch: 53.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023020719981314507		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.023020719981314507 | validation: 0.013758164655524922]
	TIME [epoch: 53.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01872033849719909		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.01872033849719909 | validation: 0.02350092067673468]
	TIME [epoch: 53.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211126244523377		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.0211126244523377 | validation: 0.013150186770202214]
	TIME [epoch: 53.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01715339037769458		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.01715339037769458 | validation: 0.017927442164869776]
	TIME [epoch: 53.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01678259601750139		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.01678259601750139 | validation: 0.012645336821674099]
	TIME [epoch: 53.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020523100040918524		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.020523100040918524 | validation: 0.014134848177202525]
	TIME [epoch: 53.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017083905023467526		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.017083905023467526 | validation: 0.01559418222303011]
	TIME [epoch: 53.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0182750336259482		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.0182750336259482 | validation: 0.011626870614907941]
	TIME [epoch: 53.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02589629556309597		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.02589629556309597 | validation: 0.02378292492514274]
	TIME [epoch: 53.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020906354469027805		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.020906354469027805 | validation: 0.011316771014568777]
	TIME [epoch: 53.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016945796227984124		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.016945796227984124 | validation: 0.014160695714334134]
	TIME [epoch: 53.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016473827576344885		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.016473827576344885 | validation: 0.01536521423047879]
	TIME [epoch: 53.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01911815213207358		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.01911815213207358 | validation: 0.012972670961027062]
	TIME [epoch: 53.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016689097485121256		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.016689097485121256 | validation: 0.020867750754291203]
	TIME [epoch: 53.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01784789055583777		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.01784789055583777 | validation: 0.015266273076762302]
	TIME [epoch: 53.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016834054996486693		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.016834054996486693 | validation: 0.01331295383902149]
	TIME [epoch: 53.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01659442521882595		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.01659442521882595 | validation: 0.017041832875431817]
	TIME [epoch: 53.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02668479611795324		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.02668479611795324 | validation: 0.01356784398080223]
	TIME [epoch: 53.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01648875690109487		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.01648875690109487 | validation: 0.013256774049668223]
	TIME [epoch: 53.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016726301124162936		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.016726301124162936 | validation: 0.01856901226104555]
	TIME [epoch: 53.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01758455471090065		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.01758455471090065 | validation: 0.01600637070136699]
	TIME [epoch: 53.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017900562869095738		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.017900562869095738 | validation: 0.014535032560692456]
	TIME [epoch: 53.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01661015792635647		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.01661015792635647 | validation: 0.01150442412647289]
	TIME [epoch: 53.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020094114178308455		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.020094114178308455 | validation: 0.019920553450733885]
	TIME [epoch: 53.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0189181228949517		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.0189181228949517 | validation: 0.023237931679504237]
	TIME [epoch: 53.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020845613014787198		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.020845613014787198 | validation: 0.014683658970191305]
	TIME [epoch: 53.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016671161822434652		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.016671161822434652 | validation: 0.042382685306319334]
	TIME [epoch: 53.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023941201032059142		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.023941201032059142 | validation: 0.012878942787372193]
	TIME [epoch: 53.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01655297493031762		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.01655297493031762 | validation: 0.01305566210507818]
	TIME [epoch: 53.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015793725921350775		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.015793725921350775 | validation: 0.011754805818930214]
	TIME [epoch: 53.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014847709366369706		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.014847709366369706 | validation: 0.012536337108752314]
	TIME [epoch: 53.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02642313118838902		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.02642313118838902 | validation: 0.015082299932515399]
	TIME [epoch: 53.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018711358324727985		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.018711358324727985 | validation: 0.01173778653981868]
	TIME [epoch: 53.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015314877693798343		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.015314877693798343 | validation: 0.011738765082837076]
	TIME [epoch: 53.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019961185959671127		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.019961185959671127 | validation: 0.013087336979192222]
	TIME [epoch: 53.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017099836752493103		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.017099836752493103 | validation: 0.012160300293782383]
	TIME [epoch: 53.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015831088887781057		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.015831088887781057 | validation: 0.01339728852197795]
	TIME [epoch: 53.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021159042262391226		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.021159042262391226 | validation: 0.015270809560463155]
	TIME [epoch: 53.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016628640185014303		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.016628640185014303 | validation: 0.01552757619596961]
	TIME [epoch: 53.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01830244843725374		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.01830244843725374 | validation: 0.014072523172674928]
	TIME [epoch: 53.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01757392244002775		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.01757392244002775 | validation: 0.016799769960450118]
	TIME [epoch: 53.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016476408308780707		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.016476408308780707 | validation: 0.012669312745345709]
	TIME [epoch: 53.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016978301854915175		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.016978301854915175 | validation: 0.01222073708585486]
	TIME [epoch: 53.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015841585612918888		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.015841585612918888 | validation: 0.015704201296935102]
	TIME [epoch: 53.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018671704467605556		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.018671704467605556 | validation: 0.028023268763843402]
	TIME [epoch: 53.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021332765143857294		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.021332765143857294 | validation: 0.011546120724428847]
	TIME [epoch: 53.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01798548926779472		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.01798548926779472 | validation: 0.014954336705402693]
	TIME [epoch: 53.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016249418626620653		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.016249418626620653 | validation: 0.011247778534724511]
	TIME [epoch: 53.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01628359221834142		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.01628359221834142 | validation: 0.014021437901454731]
	TIME [epoch: 53.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01785296147505426		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.01785296147505426 | validation: 0.021351522864319114]
	TIME [epoch: 53.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812193642637898		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.01812193642637898 | validation: 0.011755336048292615]
	TIME [epoch: 53.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015222337557178355		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.015222337557178355 | validation: 0.014545262560630708]
	TIME [epoch: 53.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015638474976449185		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.015638474976449185 | validation: 0.012403237215572224]
	TIME [epoch: 53.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018689307620115718		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.018689307620115718 | validation: 0.014110762448423068]
	TIME [epoch: 53.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01588930500526146		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.01588930500526146 | validation: 0.014428274479627154]
	TIME [epoch: 53.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02011269014266968		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.02011269014266968 | validation: 0.017839380489043367]
	TIME [epoch: 53.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018352528458676336		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.018352528458676336 | validation: 0.014746637510431593]
	TIME [epoch: 53.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01643503318233301		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.01643503318233301 | validation: 0.011399878509058173]
	TIME [epoch: 53.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015963033783029542		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.015963033783029542 | validation: 0.014735061319002131]
	TIME [epoch: 53.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019132265874574297		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.019132265874574297 | validation: 0.018656362104771312]
	TIME [epoch: 53.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018992596828987976		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.018992596828987976 | validation: 0.013205003904573992]
	TIME [epoch: 53.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016848427508252904		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.016848427508252904 | validation: 0.011741725820678046]
	TIME [epoch: 53.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016030197337531995		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.016030197337531995 | validation: 0.016975163798228506]
	TIME [epoch: 53.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018586406079443184		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.018586406079443184 | validation: 0.01228612235080645]
	TIME [epoch: 53.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016200536941742328		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.016200536941742328 | validation: 0.020332860336382062]
	TIME [epoch: 53.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017025563931943107		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.017025563931943107 | validation: 0.01509286255477697]
	TIME [epoch: 53.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015919083965954088		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.015919083965954088 | validation: 0.013879586943400855]
	TIME [epoch: 53.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0263189340796075		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.0263189340796075 | validation: 0.026000626495082356]
	TIME [epoch: 53.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879328515322669		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.01879328515322669 | validation: 0.013601941558214255]
	TIME [epoch: 53.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594282076112395		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.015594282076112395 | validation: 0.01597029978161666]
	TIME [epoch: 53.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018490521610229262		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.018490521610229262 | validation: 0.011656370473033537]
	TIME [epoch: 53.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014637463760275235		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.014637463760275235 | validation: 0.013267811642288515]
	TIME [epoch: 53.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015385058613986945		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.015385058613986945 | validation: 0.013607194206407144]
	TIME [epoch: 53.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021145864096433944		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.021145864096433944 | validation: 0.014421214764924877]
	TIME [epoch: 53.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017261537434091104		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.017261537434091104 | validation: 0.012663462764075147]
	TIME [epoch: 53.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01570212714165575		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.01570212714165575 | validation: 0.012351466039997545]
	TIME [epoch: 53.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016769711667061333		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.016769711667061333 | validation: 0.018970104077318722]
	TIME [epoch: 53.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022056281588446188		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.022056281588446188 | validation: 0.018632593926636503]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_4_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_4_v_mmd1_1139.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 27635.788 seconds.
