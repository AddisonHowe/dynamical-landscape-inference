Args:
Namespace(name='model_phi1_1a_distortion_v2r_2_v_mmd1', outdir='out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1', training_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v2r_2/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v2r_2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.034137025, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 856071899

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.515172315406168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.515172315406168 | validation: 5.830015975306155]
	TIME [epoch: 358 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.908108588784858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.908108588784858 | validation: 5.41768326707202]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.21453413687714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.21453413687714 | validation: 4.481555814315302]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.736955506669352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.736955506669352 | validation: 5.23217143568927]
	TIME [epoch: 5.92 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.7533765841717806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7533765841717806 | validation: 4.092510662548902]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9212811021955574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9212811021955574 | validation: 3.757342451096643]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8152027344660002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8152027344660002 | validation: 3.552112089874396]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5674509929796825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5674509929796825 | validation: 3.313577736764181]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.555008586495047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.555008586495047 | validation: 3.3213481552448543]
	TIME [epoch: 5.93 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.442024276273891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.442024276273891 | validation: 3.3120860447441958]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3619894551514036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3619894551514036 | validation: 3.4184236585263568]
	TIME [epoch: 5.92 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3200300198501838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3200300198501838 | validation: 3.0517734713423295]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2676677743862728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2676677743862728 | validation: 2.9910552751985326]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135009799035958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.135009799035958 | validation: 3.0217442808829746]
	TIME [epoch: 5.92 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2118749720733017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2118749720733017 | validation: 3.020998489923282]
	TIME [epoch: 5.92 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.089711459474076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.089711459474076 | validation: 2.9867280154388185]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1041907027705524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1041907027705524 | validation: 2.9413094450294923]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.036184135704107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.036184135704107 | validation: 2.8733041702599733]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0050346695623924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0050346695623924 | validation: 2.899141641698802]
	TIME [epoch: 5.92 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.952601989037431		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.952601989037431 | validation: 2.777715331953864]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.006765982597959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.006765982597959 | validation: 2.903292718522498]
	TIME [epoch: 5.95 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9149059007736833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9149059007736833 | validation: 2.671178021797092]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8783145467284745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8783145467284745 | validation: 2.731495850207352]
	TIME [epoch: 5.93 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.885210908668577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.885210908668577 | validation: 2.635340366729377]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7848852549956327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7848852549956327 | validation: 2.491205103628949]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7454002916406983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7454002916406983 | validation: 2.5422733002071913]
	TIME [epoch: 5.92 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.735189536302214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.735189536302214 | validation: 2.477950581191452]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7519709367213747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7519709367213747 | validation: 2.408836354011605]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.672584786572303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.672584786572303 | validation: 2.3001298154145937]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.609827233040332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.609827233040332 | validation: 2.198904576009466]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.540714283545526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.540714283545526 | validation: 2.154724647678467]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.558065322738206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.558065322738206 | validation: 2.3160036068360266]
	TIME [epoch: 5.93 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536902590272181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.536902590272181 | validation: 2.0878174515642476]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5007286022700224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5007286022700224 | validation: 2.103776902049053]
	TIME [epoch: 5.92 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.449764467230382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.449764467230382 | validation: 2.001797230793004]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4065881956819335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4065881956819335 | validation: 2.512777964748511]
	TIME [epoch: 5.94 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.527347595254539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.527347595254539 | validation: 1.9929346759629731]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3562782417813253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3562782417813253 | validation: 2.0011733929969973]
	TIME [epoch: 5.93 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4035847542145543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4035847542145543 | validation: 1.9403996493649895]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3355536401399317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3355536401399317 | validation: 1.8965241593987727]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.346022837651998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.346022837651998 | validation: 1.8202544367600788]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.30991855974544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.30991855974544 | validation: 2.0347467191173845]
	TIME [epoch: 5.94 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.261037463095369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.261037463095369 | validation: 1.729157735470377]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1495827729294685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1495827729294685 | validation: 1.94307011653924]
	TIME [epoch: 5.95 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2273918948588545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2273918948588545 | validation: 1.8265199270496197]
	TIME [epoch: 5.93 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1942571083241327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1942571083241327 | validation: 1.763095265837538]
	TIME [epoch: 5.94 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.142482641824845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.142482641824845 | validation: 1.8017518823271683]
	TIME [epoch: 5.93 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170499620472212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.170499620472212 | validation: 1.6747364293060665]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.132966577855501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.132966577855501 | validation: 1.8746636971486614]
	TIME [epoch: 5.93 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.179215140883783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.179215140883783 | validation: 1.6628980008233083]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066551652768081		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.066551652768081 | validation: 1.6414815450927953]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1814031885959864		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.1814031885959864 | validation: 1.6882411592750035]
	TIME [epoch: 5.93 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1412634628047114		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.1412634628047114 | validation: 1.6379095102435839]
	TIME [epoch: 5.92 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0422659080428276		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.0422659080428276 | validation: 1.5659641447996688]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0193578721563332		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.0193578721563332 | validation: 1.6511482662450176]
	TIME [epoch: 5.93 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.090686184391779		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.090686184391779 | validation: 2.047201556065408]
	TIME [epoch: 5.93 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.173618130252927		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.173618130252927 | validation: 1.6087668728563465]
	TIME [epoch: 5.92 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0207895077651		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.0207895077651 | validation: 1.549670015700137]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.031338265932434		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.031338265932434 | validation: 1.8032933097316315]
	TIME [epoch: 5.94 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0911912976452607		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.0911912976452607 | validation: 1.5917111733131502]
	TIME [epoch: 5.93 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9855897387520032		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.9855897387520032 | validation: 1.6379986052431699]
	TIME [epoch: 6.06 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.016622334299479		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.016622334299479 | validation: 1.5455739103691366]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9632017850153471		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.9632017850153471 | validation: 1.8259374494881615]
	TIME [epoch: 5.94 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.111671690233935		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.111671690233935 | validation: 1.5948658369073185]
	TIME [epoch: 5.92 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9516729460838125		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.9516729460838125 | validation: 1.6018497085864136]
	TIME [epoch: 5.93 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9784037633425993		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 1.9784037633425993 | validation: 1.607350286218359]
	TIME [epoch: 5.93 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9591692727635726		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.9591692727635726 | validation: 1.6750468141257082]
	TIME [epoch: 5.95 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9409805074734812		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.9409805074734812 | validation: 1.5712512014174296]
	TIME [epoch: 5.93 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8842042630583713		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.8842042630583713 | validation: 1.741201907561337]
	TIME [epoch: 5.93 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8990051261101195		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.8990051261101195 | validation: 1.9037709091908397]
	TIME [epoch: 5.94 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8796990785809367		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.8796990785809367 | validation: 1.6344688179059348]
	TIME [epoch: 5.93 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6995554447338415		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.6995554447338415 | validation: 1.641361388410513]
	TIME [epoch: 5.93 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5993695892354132		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.5993695892354132 | validation: 1.6531755624623323]
	TIME [epoch: 5.96 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7949164130014594		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.7949164130014594 | validation: 1.6969489449994155]
	TIME [epoch: 6.05 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.624455295368842		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.624455295368842 | validation: 2.1569891972831625]
	TIME [epoch: 5.95 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4195601171702474		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.4195601171702474 | validation: 5.006945212957646]
	TIME [epoch: 5.94 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.76762457828715		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.76762457828715 | validation: 3.5859662732817057]
	TIME [epoch: 5.93 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.421167511718559		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.421167511718559 | validation: 4.491726558787847]
	TIME [epoch: 5.93 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.594880313537424		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 5.594880313537424 | validation: 5.538525652884619]
	TIME [epoch: 5.94 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.410182241609376		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.410182241609376 | validation: 5.117851759141388]
	TIME [epoch: 5.93 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.973608020558592		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.973608020558592 | validation: 4.635333148814414]
	TIME [epoch: 5.92 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.443177512161403		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.443177512161403 | validation: 3.6339485307669808]
	TIME [epoch: 5.93 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.616748201857787		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.616748201857787 | validation: 3.5372191593624036]
	TIME [epoch: 5.95 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3458006283985853		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.3458006283985853 | validation: 3.2502537756288934]
	TIME [epoch: 5.92 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5339770005827162		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.5339770005827162 | validation: 3.1115234946616477]
	TIME [epoch: 5.93 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5993817204399146		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.5993817204399146 | validation: 3.7305156999062996]
	TIME [epoch: 5.94 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7174349477756414		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.7174349477756414 | validation: 3.616730841862971]
	TIME [epoch: 5.93 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.995368908733745		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.995368908733745 | validation: 3.7076224103732276]
	TIME [epoch: 5.93 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000786067672784		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.000786067672784 | validation: 3.835647631600136]
	TIME [epoch: 5.92 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.906707348171677		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.906707348171677 | validation: 3.805258098504833]
	TIME [epoch: 5.93 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9109646307180874		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.9109646307180874 | validation: 3.6636594641298004]
	TIME [epoch: 5.93 sec]
EPOCH 92/2000:
	Training over batches...
	Encountered nan in loss. Reverting update and performing model surgery (1/4).
		New model confinement_factor: 0.010000000000000002
		[batch 4/4] avg loss: 3.820161422128402		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.820161422128402 | validation: 3.7768857764178274]
	TIME [epoch: 377 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4623221391007566		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.4623221391007566 | validation: 2.888561889826459]
	TIME [epoch: 5.97 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6462831924057193		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.6462831924057193 | validation: 4.297181510381506]
	TIME [epoch: 5.92 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9390847643626987		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.9390847643626987 | validation: 2.7135863408160805]
	TIME [epoch: 5.92 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275695520579033		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.275695520579033 | validation: 4.896359721825462]
	TIME [epoch: 5.92 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4900395631637404		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 3.4900395631637404 | validation: 3.0211242674235255]
	TIME [epoch: 5.94 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2739110964602185		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 3.2739110964602185 | validation: 3.5480599334748906]
	TIME [epoch: 5.95 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7420853447663824		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.7420853447663824 | validation: 3.6883134634206067]
	TIME [epoch: 5.92 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.533794671027658		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.533794671027658 | validation: 3.5295327567961463]
	TIME [epoch: 5.92 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.525411634204103		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 3.525411634204103 | validation: 3.3452465917735967]
	TIME [epoch: 5.94 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.354425660187615		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 3.354425660187615 | validation: 2.816051169253143]
	TIME [epoch: 5.94 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9427945349422457		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.9427945349422457 | validation: 2.736658570602823]
	TIME [epoch: 5.93 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9142917469124745		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.9142917469124745 | validation: 2.7230110782018797]
	TIME [epoch: 5.92 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.063737113615138		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.063737113615138 | validation: 2.906011792909346]
	TIME [epoch: 5.92 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208388658388309		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.208388658388309 | validation: 3.2303270542701368]
	TIME [epoch: 5.93 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.208118959927253		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.208118959927253 | validation: 3.0637002574361545]
	TIME [epoch: 5.94 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9890796550662393		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.9890796550662393 | validation: 3.219691457927584]
	TIME [epoch: 5.94 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8352515947193515		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.8352515947193515 | validation: 4.415035319623694]
	TIME [epoch: 5.93 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.280697181493666		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 5.280697181493666 | validation: 5.603504191768529]
	TIME [epoch: 5.93 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.646568752263386		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 5.646568752263386 | validation: 5.806592939181963]
	TIME [epoch: 5.92 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838281201769757		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 5.838281201769757 | validation: 5.510131391789079]
	TIME [epoch: 5.92 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.590410101263361		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 5.590410101263361 | validation: 5.785199361853595]
	TIME [epoch: 5.93 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.932272500407384		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.932272500407384 | validation: 3.445953412264952]
	TIME [epoch: 5.93 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3259196199005086		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 3.3259196199005086 | validation: 2.894514246902009]
	TIME [epoch: 5.93 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2150256672443507		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 3.2150256672443507 | validation: 3.0980105669007028]
	TIME [epoch: 5.93 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.161258641020077		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.161258641020077 | validation: 3.400118300139435]
	TIME [epoch: 6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.048613677812765		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.048613677812765 | validation: 3.111499350890328]
	TIME [epoch: 5.95 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.770304988905017		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.770304988905017 | validation: 2.6395585601651765]
	TIME [epoch: 5.92 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2566406372624352		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.2566406372624352 | validation: 2.011233844301462]
	TIME [epoch: 5.92 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9143318956734925		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.9143318956734925 | validation: 1.87157233939578]
	TIME [epoch: 5.92 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8819978631075278		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.8819978631075278 | validation: 1.8558606014993746]
	TIME [epoch: 6.12 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8654234850390234		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8654234850390234 | validation: 1.846809333029533]
	TIME [epoch: 5.95 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8664760436020424		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.8664760436020424 | validation: 1.8318081224326581]
	TIME [epoch: 5.94 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8553058810468848		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.8553058810468848 | validation: 1.839835189341172]
	TIME [epoch: 5.93 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.846555637474871		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.846555637474871 | validation: 1.8391530881854756]
	TIME [epoch: 5.95 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8355971601488368		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.8355971601488368 | validation: 1.8337341406147714]
	TIME [epoch: 6 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8214008145472518		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.8214008145472518 | validation: 1.8483031854964636]
	TIME [epoch: 5.95 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8192124573662833		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.8192124573662833 | validation: 1.8448039678488724]
	TIME [epoch: 5.92 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7862621117459734		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.7862621117459734 | validation: 1.844200368989398]
	TIME [epoch: 5.94 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7781802624315364		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.7781802624315364 | validation: 1.8679578077976045]
	TIME [epoch: 5.94 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7549215146522903		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.7549215146522903 | validation: 1.92316831797439]
	TIME [epoch: 5.96 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.753934662396976		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.753934662396976 | validation: 1.8525931980474577]
	TIME [epoch: 5.93 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7219612666087372		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7219612666087372 | validation: 1.8303379082770355]
	TIME [epoch: 5.95 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6492584478820427		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6492584478820427 | validation: 1.9325482533601754]
	TIME [epoch: 5.93 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281271613826055		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.7281271613826055 | validation: 1.8327435650259272]
	TIME [epoch: 5.95 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6232647372368887		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.6232647372368887 | validation: 1.8220477677701847]
	TIME [epoch: 5.94 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.597567932092551		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 1.597567932092551 | validation: 1.7959644783757884]
	TIME [epoch: 5.93 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5614452987330403		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.5614452987330403 | validation: 1.8475296058083102]
	TIME [epoch: 5.95 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6229123117782795		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.6229123117782795 | validation: 1.7913972566600185]
	TIME [epoch: 5.95 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5213390615445554		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.5213390615445554 | validation: 1.7502794849137975]
	TIME [epoch: 5.95 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.451899809416605		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.451899809416605 | validation: 1.7916485478193032]
	TIME [epoch: 5.94 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5754435798243043		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.5754435798243043 | validation: 1.7777240935685739]
	TIME [epoch: 5.95 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5750798517847093		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.5750798517847093 | validation: 1.980294530584232]
	TIME [epoch: 5.95 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6241764372323158		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6241764372323158 | validation: 1.93002099210032]
	TIME [epoch: 5.93 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.570210361886406		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.570210361886406 | validation: 1.8450751872927402]
	TIME [epoch: 5.95 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5187489806742265		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.5187489806742265 | validation: 1.756748581307869]
	TIME [epoch: 5.96 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480048283322436		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.480048283322436 | validation: 1.801957037020137]
	TIME [epoch: 5.95 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4643780506895392		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.4643780506895392 | validation: 1.7111445895633353]
	TIME [epoch: 5.95 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4898762257037585		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.4898762257037585 | validation: 1.8234176693397997]
	TIME [epoch: 5.95 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3970926357344562		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3970926357344562 | validation: 1.7757689837907253]
	TIME [epoch: 5.95 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4781064299581794		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.4781064299581794 | validation: 1.7172079958566746]
	TIME [epoch: 5.95 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3830268269389854		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.3830268269389854 | validation: 1.6835398922867202]
	TIME [epoch: 5.94 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2505541736844843		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.2505541736844843 | validation: 1.704065136119017]
	TIME [epoch: 5.95 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5270933013468142		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.5270933013468142 | validation: 1.9113115354958814]
	TIME [epoch: 5.95 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.370698025788976		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.370698025788976 | validation: 1.8806422047681042]
	TIME [epoch: 5.96 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3315022307051056		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.3315022307051056 | validation: 4.183067569496327]
	TIME [epoch: 5.95 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3863520986544735		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 3.3863520986544735 | validation: 2.9707709261570523]
	TIME [epoch: 5.95 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.31655609338598		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.31655609338598 | validation: 2.2297347787692954]
	TIME [epoch: 5.95 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6968096111310176		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.6968096111310176 | validation: 1.9389361444955795]
	TIME [epoch: 5.94 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4927882815669289		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 1.4927882815669289 | validation: 1.796291413922761]
	TIME [epoch: 5.94 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.399939057912324		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.399939057912324 | validation: 1.6926035791395857]
	TIME [epoch: 5.94 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3540398574712182		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.3540398574712182 | validation: 1.6657084029204854]
	TIME [epoch: 5.95 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3203500995764834		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.3203500995764834 | validation: 1.5796574060143378]
	TIME [epoch: 5.95 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.308235911533004		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.308235911533004 | validation: 1.6746226473644403]
	TIME [epoch: 5.95 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3914951686129333		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 1.3914951686129333 | validation: 1.6934011803826328]
	TIME [epoch: 5.95 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2456590995498156		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.2456590995498156 | validation: 1.7167792732665816]
	TIME [epoch: 5.95 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.295892047372033		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.295892047372033 | validation: 1.682966216169569]
	TIME [epoch: 5.95 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2047494308452347		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.2047494308452347 | validation: 1.4098798725296275]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1132232593239557		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.1132232593239557 | validation: 1.6094964269662473]
	TIME [epoch: 5.94 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0906989854829527		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0906989854829527 | validation: 1.2983206625439268]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0986367025830388		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.0986367025830388 | validation: 1.3364104540623145]
	TIME [epoch: 5.94 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1322862714339168		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.1322862714339168 | validation: 1.3147118217687024]
	TIME [epoch: 5.95 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554234633813987		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.1554234633813987 | validation: 1.7351152713378601]
	TIME [epoch: 5.94 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2642351595054142		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 1.2642351595054142 | validation: 1.4911148262080056]
	TIME [epoch: 5.95 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1433205016636387		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 1.1433205016636387 | validation: 1.3695263969256597]
	TIME [epoch: 5.94 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0726562591764133		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0726562591764133 | validation: 1.2644041856157358]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.931006971408514		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.931006971408514 | validation: 1.0962012804311954]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9367987298900342		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9367987298900342 | validation: 1.1714822708859898]
	TIME [epoch: 5.95 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833948112137733		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.8833948112137733 | validation: 1.0838289063688116]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9332365190446404		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9332365190446404 | validation: 1.4514198248002943]
	TIME [epoch: 5.94 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1360380968525134		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1360380968525134 | validation: 1.1104280639661286]
	TIME [epoch: 5.95 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8591169453324454		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8591169453324454 | validation: 1.0318323463269334]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.824008682611856		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.824008682611856 | validation: 1.0073146887660605]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7868551013041891		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.7868551013041891 | validation: 0.9192831177513305]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8615554208331002		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.8615554208331002 | validation: 1.124663313397254]
	TIME [epoch: 5.93 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.805246812760834		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.805246812760834 | validation: 1.2207738911091393]
	TIME [epoch: 5.95 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9910789972796099		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.9910789972796099 | validation: 1.346486506014016]
	TIME [epoch: 5.95 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.04438248282251		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.04438248282251 | validation: 1.021677371437855]
	TIME [epoch: 5.95 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8109915154920297		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8109915154920297 | validation: 0.9069025552846308]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7450180036985566		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7450180036985566 | validation: 0.7338297161730386]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033251961974205		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.6033251961974205 | validation: 0.9263495305142306]
	TIME [epoch: 5.93 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9399198794873955		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9399198794873955 | validation: 1.1411035832896903]
	TIME [epoch: 5.94 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8654638000497833		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.8654638000497833 | validation: 0.8565428350323675]
	TIME [epoch: 5.95 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948049545832742		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6948049545832742 | validation: 0.9841048121090294]
	TIME [epoch: 5.95 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8420792522118505		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8420792522118505 | validation: 1.4771636317584738]
	TIME [epoch: 5.97 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.380029749175754		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.380029749175754 | validation: 2.9999947130414424]
	TIME [epoch: 5.96 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.83535785524733		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.83535785524733 | validation: 2.863067124641635]
	TIME [epoch: 5.97 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7261538275600907		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.7261538275600907 | validation: 2.7250889040921917]
	TIME [epoch: 5.96 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.734613033665142		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 2.734613033665142 | validation: 2.9171697167345636]
	TIME [epoch: 5.96 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.487588728891545		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.487588728891545 | validation: 2.825223135122206]
	TIME [epoch: 387 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.247787322573762		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 4.247787322573762 | validation: 6.222392152582248]
	TIME [epoch: 11.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.844456238720923		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 5.844456238720923 | validation: 5.890766816911881]
	TIME [epoch: 11.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.778308293458942		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.778308293458942 | validation: 4.9572777092725335]
	TIME [epoch: 11.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076677674307422		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 4.076677674307422 | validation: 3.887085314180702]
	TIME [epoch: 11.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.218598524019242		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 4.218598524019242 | validation: 5.128801521290456]
	TIME [epoch: 11.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.399672665284604		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 4.399672665284604 | validation: 4.940349520457867]
	TIME [epoch: 11.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094666957575911		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 4.094666957575911 | validation: 4.71101042182144]
	TIME [epoch: 11.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03068446532608		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 4.03068446532608 | validation: 4.532788969729069]
	TIME [epoch: 11.7 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9468888369262185		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.9468888369262185 | validation: 4.479424440056038]
	TIME [epoch: 11.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.881214692328999		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.881214692328999 | validation: 4.4148506955552556]
	TIME [epoch: 11.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.695402709021625		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.695402709021625 | validation: 4.424929568687618]
	TIME [epoch: 11.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.663963621089702		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.663963621089702 | validation: 4.253291497519475]
	TIME [epoch: 11.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.329931415732285		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 4.329931415732285 | validation: 4.482654117905469]
	TIME [epoch: 11.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.532993517118372		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 4.532993517118372 | validation: 4.274383832007794]
	TIME [epoch: 11.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.000416404319791		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 4.000416404319791 | validation: 3.80298723393743]
	TIME [epoch: 11.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.401685099919097		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.401685099919097 | validation: 3.464143999335878]
	TIME [epoch: 11.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.388574704036663		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.388574704036663 | validation: 3.8606681700315484]
	TIME [epoch: 11.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.070320165012676		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 4.070320165012676 | validation: 3.9376074881549368]
	TIME [epoch: 11.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7865179326489153		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.7865179326489153 | validation: 3.2911804510874645]
	TIME [epoch: 11.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3132910398713187		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.3132910398713187 | validation: 2.542205766363891]
	TIME [epoch: 11.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7641500923930002		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 2.7641500923930002 | validation: 2.1336095638345327]
	TIME [epoch: 11.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.48840906123799		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 2.48840906123799 | validation: 1.9757941864934976]
	TIME [epoch: 11.7 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.331091108166029		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 2.331091108166029 | validation: 1.8687681000326894]
	TIME [epoch: 11.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.098632264548927		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 2.098632264548927 | validation: 1.8350392954577106]
	TIME [epoch: 11.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0246034913251245		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 2.0246034913251245 | validation: 1.735667789733954]
	TIME [epoch: 11.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8610711508937006		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.8610711508937006 | validation: 1.69134569178963]
	TIME [epoch: 11.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.791430993389727		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.791430993389727 | validation: 1.6897539373313148]
	TIME [epoch: 11.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7822686503641871		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 1.7822686503641871 | validation: 1.670582845540981]
	TIME [epoch: 11.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6855847508394213		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.6855847508394213 | validation: 1.642529655290544]
	TIME [epoch: 11.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6841772184275468		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.6841772184275468 | validation: 1.6242467034921835]
	TIME [epoch: 11.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5700348889156377		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.5700348889156377 | validation: 1.5805426967111038]
	TIME [epoch: 11.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6753391268792535		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.6753391268792535 | validation: 1.6021101093995846]
	TIME [epoch: 11.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5259914457756711		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.5259914457756711 | validation: 1.5976680313698706]
	TIME [epoch: 11.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.467513916182453		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.467513916182453 | validation: 1.7145227419445441]
	TIME [epoch: 11.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4798829721665858		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.4798829721665858 | validation: 1.4762193457109891]
	TIME [epoch: 11.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4038675462340553		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.4038675462340553 | validation: 1.39133863641473]
	TIME [epoch: 11.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3256262855238363		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.3256262855238363 | validation: 1.4030730600667534]
	TIME [epoch: 11.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2486142137094733		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2486142137094733 | validation: 1.3301283812479316]
	TIME [epoch: 11.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1804674556057035		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 1.1804674556057035 | validation: 1.3829948574951856]
	TIME [epoch: 11.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1659414996565103		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1659414996565103 | validation: 1.3588566762316936]
	TIME [epoch: 11.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0977139531555204		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.0977139531555204 | validation: 1.206567818330962]
	TIME [epoch: 11.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0481279963483723		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.0481279963483723 | validation: 1.0692857508948699]
	TIME [epoch: 11.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9998237996776049		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.9998237996776049 | validation: 0.9247094892936203]
	TIME [epoch: 11.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.914826812432856		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.914826812432856 | validation: 0.832657313811396]
	TIME [epoch: 11.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9176898968915796		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.9176898968915796 | validation: 0.8338502599805424]
	TIME [epoch: 11.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7969609312819662		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7969609312819662 | validation: 0.9171324168140033]
	TIME [epoch: 11.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8239890460669539		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8239890460669539 | validation: 0.7578892118497158]
	TIME [epoch: 11.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7267319626925897		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7267319626925897 | validation: 0.7397009051891122]
	TIME [epoch: 11.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7462924707710658		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.7462924707710658 | validation: 0.7007284337947914]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7219602218816863		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7219602218816863 | validation: 0.6971715109118574]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738307721830845		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6738307721830845 | validation: 0.7386030960672413]
	TIME [epoch: 11.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7126487228209446		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7126487228209446 | validation: 0.6702446436548968]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6516075391592149		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6516075391592149 | validation: 0.65516999029897]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810464102321321		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6810464102321321 | validation: 0.5610930696892577]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092059981289604		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6092059981289604 | validation: 0.6257625113302296]
	TIME [epoch: 11.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258315940844761		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6258315940844761 | validation: 0.4943253508859468]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7879992186500491		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7879992186500491 | validation: 0.8738745717330381]
	TIME [epoch: 11.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7594428884600077		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7594428884600077 | validation: 0.6527686854504372]
	TIME [epoch: 11.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5498848044518039		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5498848044518039 | validation: 0.571213939481529]
	TIME [epoch: 11.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5699403974700711		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5699403974700711 | validation: 0.5435258679313211]
	TIME [epoch: 11.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664987115747586		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.5664987115747586 | validation: 0.5153084170627666]
	TIME [epoch: 11.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5646931595920988		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5646931595920988 | validation: 0.4666836577984001]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_263.pth
	Model improved!!!
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.498853514732235		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.498853514732235 | validation: 0.5171450804965727]
	TIME [epoch: 11.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586892924930198		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5586892924930198 | validation: 0.4496532833574587]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5873840219339985		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.5873840219339985 | validation: 0.5487152745380572]
	TIME [epoch: 11.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696096297590768		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5696096297590768 | validation: 0.5318222457686472]
	TIME [epoch: 11.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4971522580077722		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.4971522580077722 | validation: 0.49331861959711576]
	TIME [epoch: 11.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135316742481272		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5135316742481272 | validation: 0.4268396249252138]
	TIME [epoch: 11.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49068945535675246		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.49068945535675246 | validation: 0.3865146573478704]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5149443368002193		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5149443368002193 | validation: 0.449266474063616]
	TIME [epoch: 11.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4641847747710055		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.4641847747710055 | validation: 0.6459559438193414]
	TIME [epoch: 11.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4789526415311037		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.4789526415311037 | validation: 0.39022638065334675]
	TIME [epoch: 11.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214472341415384		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.5214472341415384 | validation: 0.35756684892235924]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5290297345319357		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.5290297345319357 | validation: 0.3340549064772919]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42440220822512276		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.42440220822512276 | validation: 0.5761965573756388]
	TIME [epoch: 11.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5013001774113442		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5013001774113442 | validation: 0.3291585042105377]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6158837602097188		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6158837602097188 | validation: 0.47412248019646697]
	TIME [epoch: 11.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039853402222735		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.5039853402222735 | validation: 0.3533414475889931]
	TIME [epoch: 11.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303373574648362		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.4303373574648362 | validation: 0.47671173645649967]
	TIME [epoch: 11.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47921894341033583		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.47921894341033583 | validation: 0.45307030971330586]
	TIME [epoch: 11.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4436287150595878		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.4436287150595878 | validation: 0.30497993918366767]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5435975711688469		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5435975711688469 | validation: 0.3477973659023326]
	TIME [epoch: 11.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43334678757183115		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.43334678757183115 | validation: 0.3075835614937624]
	TIME [epoch: 11.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40205567118118063		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.40205567118118063 | validation: 0.44457368206048814]
	TIME [epoch: 11.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483310117808451		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.4483310117808451 | validation: 0.354713960814557]
	TIME [epoch: 11.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49242395885915247		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.49242395885915247 | validation: 0.26026310234627575]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044378818578532		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4044378818578532 | validation: 0.3227301672267031]
	TIME [epoch: 11.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43372320858187674		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.43372320858187674 | validation: 0.3178493215236826]
	TIME [epoch: 11.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38361931563750673		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.38361931563750673 | validation: 0.3604597706827918]
	TIME [epoch: 11.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40731098488227846		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.40731098488227846 | validation: 0.2901446617425262]
	TIME [epoch: 11.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38417432793590445		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.38417432793590445 | validation: 0.2687140095980347]
	TIME [epoch: 11.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41658840978296563		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.41658840978296563 | validation: 0.2568519787472951]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36774186442116014		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.36774186442116014 | validation: 0.2689256500306893]
	TIME [epoch: 11.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183381131701888		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.4183381131701888 | validation: 0.28364853500739295]
	TIME [epoch: 11.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4109992796224845		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.4109992796224845 | validation: 0.29898866636945953]
	TIME [epoch: 11.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.396693090921597		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.396693090921597 | validation: 0.33681165404223945]
	TIME [epoch: 11.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.386105198083826		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.386105198083826 | validation: 0.3323612810996737]
	TIME [epoch: 11.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39449805456602416		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.39449805456602416 | validation: 0.31100228385979467]
	TIME [epoch: 11.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076879544022284		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8076879544022284 | validation: 0.35187702262745657]
	TIME [epoch: 11.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839653901223493		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5839653901223493 | validation: 0.27955557138435566]
	TIME [epoch: 11.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571554640177009		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.571554640177009 | validation: 0.32432248726981117]
	TIME [epoch: 11.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5581289513286182		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5581289513286182 | validation: 0.23174700529208453]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384570489239067		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.3384570489239067 | validation: 0.34999916552685184]
	TIME [epoch: 11.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3909127387513504		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.3909127387513504 | validation: 0.23618944358892946]
	TIME [epoch: 11.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3705853321645627		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.3705853321645627 | validation: 0.2917451352469811]
	TIME [epoch: 11.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38394563558662875		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.38394563558662875 | validation: 0.2455953586819004]
	TIME [epoch: 11.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.368188083891748		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.368188083891748 | validation: 0.2484897016433093]
	TIME [epoch: 11.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35612428212695957		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.35612428212695957 | validation: 0.3098671144737085]
	TIME [epoch: 11.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35318580089972434		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.35318580089972434 | validation: 0.2664202956487486]
	TIME [epoch: 11.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401818408853777		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.3401818408853777 | validation: 0.28761433936191977]
	TIME [epoch: 11.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479243357711852		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.3479243357711852 | validation: 0.31357339577374155]
	TIME [epoch: 11.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36317638373067085		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.36317638373067085 | validation: 0.23004552140860932]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33244595671223504		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.33244595671223504 | validation: 0.1979180859119597]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_314.pth
	Model improved!!!
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38191589769690226		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.38191589769690226 | validation: 0.21964295141049256]
	TIME [epoch: 11.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33376199069064755		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.33376199069064755 | validation: 0.3594607152288678]
	TIME [epoch: 11.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37939211683224294		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.37939211683224294 | validation: 0.24297923771711744]
	TIME [epoch: 11.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32455816644891405		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.32455816644891405 | validation: 0.2812181561263411]
	TIME [epoch: 11.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35581033453840644		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.35581033453840644 | validation: 0.2816550846317633]
	TIME [epoch: 11.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3455188380942239		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.3455188380942239 | validation: 0.18651777470757971]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32064589805586796		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.32064589805586796 | validation: 0.2654970505131781]
	TIME [epoch: 11.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36085298547124045		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.36085298547124045 | validation: 0.24068278471447851]
	TIME [epoch: 11.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36760598542532286		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.36760598542532286 | validation: 0.17185680463335498]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30705429514988525		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.30705429514988525 | validation: 0.24117716635391498]
	TIME [epoch: 11.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33489351774233056		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.33489351774233056 | validation: 0.3029245681881413]
	TIME [epoch: 11.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230268791017492		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3230268791017492 | validation: 0.34844785624225844]
	TIME [epoch: 11.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510860006308455		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.3510860006308455 | validation: 0.21079413456058166]
	TIME [epoch: 11.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33453510783575585		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.33453510783575585 | validation: 0.23808095800934043]
	TIME [epoch: 11.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3097131288719286		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3097131288719286 | validation: 0.19855794102206709]
	TIME [epoch: 11.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30844511169248195		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.30844511169248195 | validation: 0.21384568468814247]
	TIME [epoch: 11.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3349356109597754		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.3349356109597754 | validation: 0.18731747516888225]
	TIME [epoch: 11.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29189396860744343		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.29189396860744343 | validation: 0.2896092277404443]
	TIME [epoch: 11.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123763662743835		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.3123763662743835 | validation: 0.3674126539764818]
	TIME [epoch: 11.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3341923163423888		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.3341923163423888 | validation: 0.2922703214894786]
	TIME [epoch: 11.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344640079928747		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.3344640079928747 | validation: 0.269633626616397]
	TIME [epoch: 11.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3229301842464053		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.3229301842464053 | validation: 0.353745301225207]
	TIME [epoch: 11.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38445861837411066		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.38445861837411066 | validation: 0.346502150231085]
	TIME [epoch: 11.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3560714206499621		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.3560714206499621 | validation: 0.2834659909372506]
	TIME [epoch: 11.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3137533130882817		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.3137533130882817 | validation: 0.19199724706197854]
	TIME [epoch: 11.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29559387337518406		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.29559387337518406 | validation: 0.2441097211087905]
	TIME [epoch: 11.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31206425199149335		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.31206425199149335 | validation: 0.20995144184912803]
	TIME [epoch: 11.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29362424646797364		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.29362424646797364 | validation: 0.17654977124401708]
	TIME [epoch: 11.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315935919614841		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.315935919614841 | validation: 0.22146246488605176]
	TIME [epoch: 11.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30665858276674574		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.30665858276674574 | validation: 0.23970183842811343]
	TIME [epoch: 11.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29767732976004907		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.29767732976004907 | validation: 0.17884407900067387]
	TIME [epoch: 11.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31233631737968603		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.31233631737968603 | validation: 0.2342683675827552]
	TIME [epoch: 11.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845242856204053		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2845242856204053 | validation: 0.22306916186537853]
	TIME [epoch: 11.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2824129957386615		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2824129957386615 | validation: 0.28081968299677773]
	TIME [epoch: 11.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30051669409552073		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.30051669409552073 | validation: 0.18919309935992612]
	TIME [epoch: 11.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26814226555500165		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.26814226555500165 | validation: 0.2191493148296132]
	TIME [epoch: 11.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29795489853983537		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.29795489853983537 | validation: 0.17638680992865693]
	TIME [epoch: 11.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2762412294460187		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2762412294460187 | validation: 0.18549385846430594]
	TIME [epoch: 11.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25707914683069966		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.25707914683069966 | validation: 0.27263993626500377]
	TIME [epoch: 11.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956002454634147		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2956002454634147 | validation: 0.22361823866820701]
	TIME [epoch: 11.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2936189530497348		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2936189530497348 | validation: 0.26130767918090386]
	TIME [epoch: 11.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2882781422458067		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.2882781422458067 | validation: 0.18236156854377383]
	TIME [epoch: 11.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25293421393214915		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.25293421393214915 | validation: 0.2593180340309107]
	TIME [epoch: 11.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29925570847373734		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.29925570847373734 | validation: 0.18464029123294834]
	TIME [epoch: 11.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2772669369571342		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2772669369571342 | validation: 0.2321517949343926]
	TIME [epoch: 11.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.272312721976403		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.272312721976403 | validation: 0.1835639160755341]
	TIME [epoch: 11.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842467775426123		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.2842467775426123 | validation: 0.16614824171520715]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2752861488853073		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.2752861488853073 | validation: 0.189499773403961]
	TIME [epoch: 11.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27356397337881966		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.27356397337881966 | validation: 0.173620037650336]
	TIME [epoch: 11.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26867589423979876		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.26867589423979876 | validation: 0.26760767661738905]
	TIME [epoch: 11.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813165782125422		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.2813165782125422 | validation: 0.16908057742636617]
	TIME [epoch: 11.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622742450971121		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2622742450971121 | validation: 0.15330669837216224]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25064006869717925		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.25064006869717925 | validation: 0.26364563825103404]
	TIME [epoch: 11.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26391173700430093		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.26391173700430093 | validation: 0.2281282938896736]
	TIME [epoch: 11.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26467540745528945		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.26467540745528945 | validation: 0.18518940196092537]
	TIME [epoch: 11.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2750263589288075		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2750263589288075 | validation: 0.20068354270129182]
	TIME [epoch: 11.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25697818947843065		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.25697818947843065 | validation: 0.18666191676677468]
	TIME [epoch: 11.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25013564215785333		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.25013564215785333 | validation: 0.17993607401354228]
	TIME [epoch: 11.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23620560371041593		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.23620560371041593 | validation: 0.2199410827718628]
	TIME [epoch: 11.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25395852421646986		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.25395852421646986 | validation: 0.2034233149720163]
	TIME [epoch: 11.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576851391045023		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.2576851391045023 | validation: 0.19051258357470996]
	TIME [epoch: 11.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24076148193896377		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.24076148193896377 | validation: 0.24476807924574384]
	TIME [epoch: 11.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2656394801115857		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.2656394801115857 | validation: 0.20921151401716315]
	TIME [epoch: 11.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27519521926919854		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.27519521926919854 | validation: 0.18546603116993327]
	TIME [epoch: 11.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247525915269392		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.247525915269392 | validation: 0.20273680992066406]
	TIME [epoch: 11.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2531517396233385		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.2531517396233385 | validation: 0.18169824676702284]
	TIME [epoch: 11.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438739942564693		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.2438739942564693 | validation: 0.19535559997261487]
	TIME [epoch: 11.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24022801936054328		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.24022801936054328 | validation: 0.17751771153376492]
	TIME [epoch: 11.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23299027489472715		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.23299027489472715 | validation: 0.1672760822930503]
	TIME [epoch: 11.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24222245275521653		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.24222245275521653 | validation: 0.18421340174679585]
	TIME [epoch: 11.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2377381254667031		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2377381254667031 | validation: 0.21506364806422165]
	TIME [epoch: 11.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2342225836303622		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2342225836303622 | validation: 0.20959612956934992]
	TIME [epoch: 11.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21920555904578465		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.21920555904578465 | validation: 0.20284538177186534]
	TIME [epoch: 11.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25813423147461856		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.25813423147461856 | validation: 0.20774345473224837]
	TIME [epoch: 11.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22626041384809806		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.22626041384809806 | validation: 0.19256738885275504]
	TIME [epoch: 11.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2560125160769464		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2560125160769464 | validation: 0.23388921172687108]
	TIME [epoch: 11.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21857070718769353		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.21857070718769353 | validation: 0.2044176743343517]
	TIME [epoch: 11.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24157095692203262		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.24157095692203262 | validation: 0.22401705130838354]
	TIME [epoch: 11.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22161134486604298		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.22161134486604298 | validation: 0.1285889288779039]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2362219015274653		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2362219015274653 | validation: 0.20573957690331268]
	TIME [epoch: 11.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229269249821129		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.2229269249821129 | validation: 0.18862182014312773]
	TIME [epoch: 11.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564120900742435		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.2564120900742435 | validation: 0.2011154525090399]
	TIME [epoch: 11.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23371686379573875		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.23371686379573875 | validation: 0.20873792856068502]
	TIME [epoch: 11.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22905135680734423		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.22905135680734423 | validation: 0.1429511097891572]
	TIME [epoch: 11.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21796846682572257		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.21796846682572257 | validation: 0.15557845873492715]
	TIME [epoch: 11.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21898502046733223		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.21898502046733223 | validation: 0.15435831276618095]
	TIME [epoch: 11.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21333588512678697		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.21333588512678697 | validation: 0.17581792675617858]
	TIME [epoch: 11.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2286557517943569		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.2286557517943569 | validation: 0.21092484830632197]
	TIME [epoch: 11.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21157157910731847		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.21157157910731847 | validation: 0.15108903680534325]
	TIME [epoch: 11.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23754653282144783		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.23754653282144783 | validation: 0.18609593137578723]
	TIME [epoch: 11.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21998002974051542		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.21998002974051542 | validation: 0.4055016996069659]
	TIME [epoch: 11.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771753505046447		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2771753505046447 | validation: 0.17330032325904016]
	TIME [epoch: 11.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20829168846800844		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.20829168846800844 | validation: 0.13055464969966069]
	TIME [epoch: 11.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023268747312278		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.2023268747312278 | validation: 0.12844828893303756]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19782540762717732		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.19782540762717732 | validation: 0.1969392375745111]
	TIME [epoch: 11.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2173545259756751		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.2173545259756751 | validation: 0.18801287341442688]
	TIME [epoch: 11.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443874204926994		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.21443874204926994 | validation: 0.16511815874348773]
	TIME [epoch: 11.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21990581878171106		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.21990581878171106 | validation: 0.14344408246971185]
	TIME [epoch: 11.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19861738259571052		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.19861738259571052 | validation: 0.19177200357208007]
	TIME [epoch: 11.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21811810347835722		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.21811810347835722 | validation: 0.1661225765714484]
	TIME [epoch: 11.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2028663405117151		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2028663405117151 | validation: 0.1641636354548786]
	TIME [epoch: 11.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.226182761368725		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.226182761368725 | validation: 0.17686613880883467]
	TIME [epoch: 11.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2574305244937967		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.2574305244937967 | validation: 0.22462706506368474]
	TIME [epoch: 11.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22681373040608543		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.22681373040608543 | validation: 0.13960889192844556]
	TIME [epoch: 11.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20736658839511174		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.20736658839511174 | validation: 0.17507435893907747]
	TIME [epoch: 11.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19535589815502596		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.19535589815502596 | validation: 0.1360143357110637]
	TIME [epoch: 11.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20747577277553378		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.20747577277553378 | validation: 0.16846191543924594]
	TIME [epoch: 11.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20925101065433807		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.20925101065433807 | validation: 0.11612353758041752]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18705829593880327		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.18705829593880327 | validation: 0.15179460501141423]
	TIME [epoch: 11.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19414732265436038		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.19414732265436038 | validation: 0.14401714358077944]
	TIME [epoch: 11.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1890571851936791		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.1890571851936791 | validation: 0.45589557173782247]
	TIME [epoch: 11.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808791719530487		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.2808791719530487 | validation: 0.17577571188188082]
	TIME [epoch: 11.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19183481624577475		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.19183481624577475 | validation: 0.1362407248095647]
	TIME [epoch: 11.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18715024759879664		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.18715024759879664 | validation: 0.1896089511736326]
	TIME [epoch: 11.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2034656934669587		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.2034656934669587 | validation: 0.22501087128416614]
	TIME [epoch: 11.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3332020075549864		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3332020075549864 | validation: 0.2306444872960966]
	TIME [epoch: 11.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22677021298083205		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.22677021298083205 | validation: 0.18810067672461817]
	TIME [epoch: 11.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19400083864520473		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.19400083864520473 | validation: 0.150186216923078]
	TIME [epoch: 11.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1826314300140419		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.1826314300140419 | validation: 0.15657974607356517]
	TIME [epoch: 11.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18423210392243825		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.18423210392243825 | validation: 0.18996204317396925]
	TIME [epoch: 11.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18701229158141483		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.18701229158141483 | validation: 0.15516908394201562]
	TIME [epoch: 11.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18959341493139178		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.18959341493139178 | validation: 0.1907044084453008]
	TIME [epoch: 11.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2387348874908679		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.2387348874908679 | validation: 0.250685018336393]
	TIME [epoch: 11.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22805959381031501		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.22805959381031501 | validation: 0.1651376300410693]
	TIME [epoch: 11.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1747126694130783		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.1747126694130783 | validation: 0.1627944124374149]
	TIME [epoch: 11.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1861358621897689		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.1861358621897689 | validation: 0.1424393703880762]
	TIME [epoch: 11.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19297948283707367		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.19297948283707367 | validation: 0.18797291569813762]
	TIME [epoch: 11.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17602939978783375		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.17602939978783375 | validation: 0.18946574595751114]
	TIME [epoch: 11.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913269454412429		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.1913269454412429 | validation: 0.1489291378390078]
	TIME [epoch: 11.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19045995532289065		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.19045995532289065 | validation: 0.18745296178565488]
	TIME [epoch: 11.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18216694277000445		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.18216694277000445 | validation: 0.16153586885101656]
	TIME [epoch: 11.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19261074558463465		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.19261074558463465 | validation: 0.20168896000874448]
	TIME [epoch: 11.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17073595308990783		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.17073595308990783 | validation: 0.1277442121297528]
	TIME [epoch: 11.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16826073346482534		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.16826073346482534 | validation: 0.14510682252421717]
	TIME [epoch: 11.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1717458564001469		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.1717458564001469 | validation: 0.13992283616995843]
	TIME [epoch: 11.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19314911807125268		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.19314911807125268 | validation: 0.19685061887108268]
	TIME [epoch: 11.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19044524578266986		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.19044524578266986 | validation: 0.11120489766233328]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_451.pth
	Model improved!!!
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17292986411435765		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.17292986411435765 | validation: 0.16650444415727894]
	TIME [epoch: 11.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1757356785437329		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.1757356785437329 | validation: 0.17822345004003623]
	TIME [epoch: 11.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18578448506786271		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.18578448506786271 | validation: 0.13850263036475477]
	TIME [epoch: 11.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475428225328735		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.14475428225328735 | validation: 0.18868822491135406]
	TIME [epoch: 11.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18154689551133144		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.18154689551133144 | validation: 0.10858725887892448]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18031709414680425		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.18031709414680425 | validation: 0.11223244987864299]
	TIME [epoch: 11.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.181763969279065		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.181763969279065 | validation: 0.13368564757931095]
	TIME [epoch: 11.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16721570105028213		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.16721570105028213 | validation: 0.13800612737709655]
	TIME [epoch: 11.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17396044055097062		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.17396044055097062 | validation: 0.12118467281014433]
	TIME [epoch: 11.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569592462258043		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.17569592462258043 | validation: 0.2054142753215873]
	TIME [epoch: 11.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16947290133080542		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.16947290133080542 | validation: 0.11721072349891241]
	TIME [epoch: 11.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16490837489670496		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.16490837489670496 | validation: 0.1808813044536715]
	TIME [epoch: 11.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16980477832874266		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.16980477832874266 | validation: 0.11419577160413916]
	TIME [epoch: 11.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16006056857492565		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.16006056857492565 | validation: 0.12980022032095415]
	TIME [epoch: 11.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17155724192577076		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.17155724192577076 | validation: 0.15608539631656848]
	TIME [epoch: 11.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726969015249956		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.1726969015249956 | validation: 0.11394121000292524]
	TIME [epoch: 11.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546275547114941		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.1546275547114941 | validation: 0.14279872173871222]
	TIME [epoch: 11.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621015087151792		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1621015087151792 | validation: 0.11521345979639774]
	TIME [epoch: 11.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17150609176557607		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.17150609176557607 | validation: 0.17535415686061306]
	TIME [epoch: 11.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18940202610563223		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.18940202610563223 | validation: 0.17678963805833342]
	TIME [epoch: 11.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15369527943506248		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.15369527943506248 | validation: 0.1448581060365809]
	TIME [epoch: 11.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16507979270104067		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.16507979270104067 | validation: 0.11700707536459971]
	TIME [epoch: 11.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15946643078713815		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.15946643078713815 | validation: 0.17520392336801827]
	TIME [epoch: 11.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534286941745242		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.1534286941745242 | validation: 0.1739853461679669]
	TIME [epoch: 11.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17164120337663427		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.17164120337663427 | validation: 0.12094488639031092]
	TIME [epoch: 11.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14939625213426208		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.14939625213426208 | validation: 0.1584402979713982]
	TIME [epoch: 11.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361650577872826		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.15361650577872826 | validation: 0.17825974917947612]
	TIME [epoch: 11.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14707364868699238		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.14707364868699238 | validation: 0.14835614877092707]
	TIME [epoch: 11.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14871451242341532		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.14871451242341532 | validation: 0.1167756897564519]
	TIME [epoch: 11.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16868072773398413		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.16868072773398413 | validation: 0.14011069671676585]
	TIME [epoch: 11.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18291972323989103		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.18291972323989103 | validation: 0.15140770766980366]
	TIME [epoch: 11.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549296408365372		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.1549296408365372 | validation: 0.13971357163241194]
	TIME [epoch: 11.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13657538009934017		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.13657538009934017 | validation: 0.1225472973740998]
	TIME [epoch: 11.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049597205563076		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.15049597205563076 | validation: 0.17626871163360489]
	TIME [epoch: 11.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15006301285155005		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.15006301285155005 | validation: 0.20586527045622288]
	TIME [epoch: 11.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16099934289477236		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.16099934289477236 | validation: 0.17298327848281192]
	TIME [epoch: 11.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558514813705444		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.1558514813705444 | validation: 0.15384695164239567]
	TIME [epoch: 11.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15299880725668333		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.15299880725668333 | validation: 0.08833397232353564]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348857510585623		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.1348857510585623 | validation: 0.1506554382484374]
	TIME [epoch: 11.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14282096722166987		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.14282096722166987 | validation: 0.16509804701823066]
	TIME [epoch: 11.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14470307427092985		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.14470307427092985 | validation: 0.18074875622790215]
	TIME [epoch: 11.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121497542674409		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.15121497542674409 | validation: 0.1335069921255802]
	TIME [epoch: 11.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126645872244015		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.14126645872244015 | validation: 0.1276945854280519]
	TIME [epoch: 11.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746196122904293		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.14746196122904293 | validation: 0.12297822571599579]
	TIME [epoch: 11.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15699797880101657		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.15699797880101657 | validation: 0.13148426297153099]
	TIME [epoch: 11.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512663264781569		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.1512663264781569 | validation: 0.10590372924223265]
	TIME [epoch: 11.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12581121114547994		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.12581121114547994 | validation: 0.12734810547255732]
	TIME [epoch: 11.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1402974079489195		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.1402974079489195 | validation: 0.15194823570123978]
	TIME [epoch: 11.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14110214315519512		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.14110214315519512 | validation: 0.13798197541508467]
	TIME [epoch: 11.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13651043246655256		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.13651043246655256 | validation: 0.14693660974623318]
	TIME [epoch: 404 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13122307601159788		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.13122307601159788 | validation: 0.14986317518900627]
	TIME [epoch: 25.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13769018209821715		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.13769018209821715 | validation: 0.1535466213444448]
	TIME [epoch: 25.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274464984515322		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.1274464984515322 | validation: 0.12060030604884914]
	TIME [epoch: 25.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13628700566978638		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.13628700566978638 | validation: 0.14062984861127226]
	TIME [epoch: 25.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13064008874928296		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.13064008874928296 | validation: 0.12953578377680025]
	TIME [epoch: 25.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13997468823093784		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.13997468823093784 | validation: 0.12720748870708845]
	TIME [epoch: 25.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900636185985822		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.11900636185985822 | validation: 0.1456396267054343]
	TIME [epoch: 25.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15171148194619183		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.15171148194619183 | validation: 0.16460467078313787]
	TIME [epoch: 25.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14197923836212994		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.14197923836212994 | validation: 0.14666121883550676]
	TIME [epoch: 25.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1171045869834292		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.1171045869834292 | validation: 0.1271747632846064]
	TIME [epoch: 25.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13758185983416985		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.13758185983416985 | validation: 0.11993292378706408]
	TIME [epoch: 25.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12622740104093508		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.12622740104093508 | validation: 0.1483981472644302]
	TIME [epoch: 25.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12835254310403565		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.12835254310403565 | validation: 0.1365750503103656]
	TIME [epoch: 25.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17850987376206623		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.17850987376206623 | validation: 0.14171324577175187]
	TIME [epoch: 25.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15535104181624584		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.15535104181624584 | validation: 0.19399635723620715]
	TIME [epoch: 25.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490927220139687		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.13490927220139687 | validation: 0.13446762389004965]
	TIME [epoch: 25.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14756565873728167		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.14756565873728167 | validation: 0.1879660937511741]
	TIME [epoch: 25.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524147110289363		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.12524147110289363 | validation: 0.12567512074985968]
	TIME [epoch: 25.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11616654729283486		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.11616654729283486 | validation: 0.6007001081890363]
	TIME [epoch: 25.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33468379083976085		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.33468379083976085 | validation: 0.1417685671631269]
	TIME [epoch: 25.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581856691518591		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.11581856691518591 | validation: 0.12116634502044157]
	TIME [epoch: 25.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11100227353397404		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.11100227353397404 | validation: 0.1382349142151074]
	TIME [epoch: 25.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094273039830086		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.12094273039830086 | validation: 0.13436469950655833]
	TIME [epoch: 25.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246338067524334		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.12246338067524334 | validation: 0.12605429234711413]
	TIME [epoch: 25.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12422195926004198		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.12422195926004198 | validation: 0.134394219102516]
	TIME [epoch: 25.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13173772529168568		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.13173772529168568 | validation: 0.11612223315618897]
	TIME [epoch: 25.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433122323392503		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.11433122323392503 | validation: 0.14881946346391034]
	TIME [epoch: 25.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12065313079192966		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.12065313079192966 | validation: 0.1026087349301683]
	TIME [epoch: 25.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12040664417505756		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.12040664417505756 | validation: 0.20624752559393905]
	TIME [epoch: 25.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586265806311453		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.1586265806311453 | validation: 0.13504577860301448]
	TIME [epoch: 25.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11349274485075705		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.11349274485075705 | validation: 0.19323359684267138]
	TIME [epoch: 25.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12707609135781317		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.12707609135781317 | validation: 0.1009840258611713]
	TIME [epoch: 25.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10845860258977055		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.10845860258977055 | validation: 0.11901478629899459]
	TIME [epoch: 25.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10786218786307931		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.10786218786307931 | validation: 0.1702240327617824]
	TIME [epoch: 25.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13006062546065944		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.13006062546065944 | validation: 0.11278237117136077]
	TIME [epoch: 25.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11255646584003952		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.11255646584003952 | validation: 0.10953322493976361]
	TIME [epoch: 25.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12508827201225714		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.12508827201225714 | validation: 0.10383229020238453]
	TIME [epoch: 25.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10383952370350616		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.10383952370350616 | validation: 0.11272971705328216]
	TIME [epoch: 25.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11362221483326483		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.11362221483326483 | validation: 0.1123657711862347]
	TIME [epoch: 25.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11266373203673646		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.11266373203673646 | validation: 0.14492418319423594]
	TIME [epoch: 25.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11357541523838023		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.11357541523838023 | validation: 0.12593291757680647]
	TIME [epoch: 25.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1207805993258537		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.1207805993258537 | validation: 0.11154402009308693]
	TIME [epoch: 25.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126786501738675		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.11126786501738675 | validation: 0.11793959482321661]
	TIME [epoch: 25.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378399858753521		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.12378399858753521 | validation: 0.12338134118015805]
	TIME [epoch: 25.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898275066411305		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.10898275066411305 | validation: 0.10917537011725914]
	TIME [epoch: 25.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1125180206714512		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.1125180206714512 | validation: 0.11021131871619616]
	TIME [epoch: 25.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11702623121859695		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.11702623121859695 | validation: 0.07347188645939615]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_548.pth
	Model improved!!!
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16233092616310046		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16233092616310046 | validation: 0.14863153855929345]
	TIME [epoch: 25.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12619658965917055		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.12619658965917055 | validation: 0.11849019240653258]
	TIME [epoch: 25.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10138788517789071		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.10138788517789071 | validation: 0.14212454625893817]
	TIME [epoch: 25.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10594791268295861		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.10594791268295861 | validation: 0.11687946316712623]
	TIME [epoch: 25.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10369295494283653		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.10369295494283653 | validation: 0.15524948865963464]
	TIME [epoch: 25.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11287587612653778		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.11287587612653778 | validation: 0.12329751536165046]
	TIME [epoch: 25.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11707494968207721		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.11707494968207721 | validation: 0.10034204778812723]
	TIME [epoch: 25.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09852394304714852		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.09852394304714852 | validation: 0.13206972670662473]
	TIME [epoch: 25.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312001007441213		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.09312001007441213 | validation: 0.11079237631800579]
	TIME [epoch: 25.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11244207942993707		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.11244207942993707 | validation: 0.08744189299227309]
	TIME [epoch: 25.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1121541123626748		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.1121541123626748 | validation: 0.0851495673122281]
	TIME [epoch: 25.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098571926598522		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.11098571926598522 | validation: 0.12980023987663217]
	TIME [epoch: 25.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981493937342032		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.10981493937342032 | validation: 0.1404114768994534]
	TIME [epoch: 25.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11762669194240855		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.11762669194240855 | validation: 0.11435428064460815]
	TIME [epoch: 25.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09662864423067946		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.09662864423067946 | validation: 0.097019492041887]
	TIME [epoch: 25.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12022230287556118		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.12022230287556118 | validation: 0.0810780083738738]
	TIME [epoch: 25.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10700001502894578		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.10700001502894578 | validation: 0.08881793349387604]
	TIME [epoch: 25.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12110679467777133		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.12110679467777133 | validation: 0.10725335488923997]
	TIME [epoch: 25.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991331205116336		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.08991331205116336 | validation: 0.10361980512089816]
	TIME [epoch: 25.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591964348077129		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.10591964348077129 | validation: 0.10443912521884066]
	TIME [epoch: 25.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09934654040418324		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.09934654040418324 | validation: 0.16614486035124415]
	TIME [epoch: 25.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12203135886936409		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.12203135886936409 | validation: 0.07248227934586104]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_570.pth
	Model improved!!!
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09221681925042148		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.09221681925042148 | validation: 0.13294435487099807]
	TIME [epoch: 25.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1023965528042525		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.1023965528042525 | validation: 0.13037485729415182]
	TIME [epoch: 25.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10488301648726989		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.10488301648726989 | validation: 0.089500199836207]
	TIME [epoch: 25.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08393077713814606		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.08393077713814606 | validation: 0.10474877377072514]
	TIME [epoch: 25.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10064860116000832		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.10064860116000832 | validation: 0.0761726126031663]
	TIME [epoch: 25.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700738717365649		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.09700738717365649 | validation: 0.10441611327218811]
	TIME [epoch: 25.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09779611828744542		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.09779611828744542 | validation: 0.12940783040105572]
	TIME [epoch: 25.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1184503152974372		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.1184503152974372 | validation: 0.11553625949169209]
	TIME [epoch: 25.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426555594594083		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.09426555594594083 | validation: 0.21908707449981668]
	TIME [epoch: 25.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.141438670794208		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.141438670794208 | validation: 0.1333436010542638]
	TIME [epoch: 25.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09386363543211848		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.09386363543211848 | validation: 0.09335508940019444]
	TIME [epoch: 25.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320433476103252		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.10320433476103252 | validation: 0.10547620021547671]
	TIME [epoch: 25.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08820531567385426		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.08820531567385426 | validation: 0.11144004505590599]
	TIME [epoch: 25.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09716508096590659		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.09716508096590659 | validation: 0.07515483918373948]
	TIME [epoch: 25.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08185772932450625		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.08185772932450625 | validation: 0.09121351355463217]
	TIME [epoch: 25.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09953876385701493		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.09953876385701493 | validation: 0.0710598806340805]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_586.pth
	Model improved!!!
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043362850893819		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.09043362850893819 | validation: 0.12309411451630978]
	TIME [epoch: 25.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08629858577222133		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.08629858577222133 | validation: 0.1081631937648472]
	TIME [epoch: 25.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1029371839451776		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.1029371839451776 | validation: 0.07698066442595794]
	TIME [epoch: 25.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09336001126671056		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.09336001126671056 | validation: 0.13270573453791276]
	TIME [epoch: 25.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08764483868869682		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.08764483868869682 | validation: 0.14161889127458108]
	TIME [epoch: 25.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09297654974171794		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.09297654974171794 | validation: 0.11421332018767744]
	TIME [epoch: 25.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829121583446992		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.08829121583446992 | validation: 0.053273223927505484]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09151148108762408		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.09151148108762408 | validation: 0.07220543628393217]
	TIME [epoch: 25.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262389573631504		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.10262389573631504 | validation: 0.08015628928540508]
	TIME [epoch: 25.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154403365902103		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.08154403365902103 | validation: 0.0992630657842006]
	TIME [epoch: 25.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07577028646024359		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.07577028646024359 | validation: 0.11207712273360262]
	TIME [epoch: 25.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08296128267342803		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.08296128267342803 | validation: 0.09909762489249396]
	TIME [epoch: 25.2 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08641503402559678		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.08641503402559678 | validation: 0.09460139222782371]
	TIME [epoch: 25.2 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0902535974975288		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0902535974975288 | validation: 0.09262605954870681]
	TIME [epoch: 25.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08474849481679905		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.08474849481679905 | validation: 0.13613493986938296]
	TIME [epoch: 25.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09325182791221787		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.09325182791221787 | validation: 0.13299004056730276]
	TIME [epoch: 25.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0958181474176065		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.0958181474176065 | validation: 0.08301103021663932]
	TIME [epoch: 25.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07825413085453836		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.07825413085453836 | validation: 0.07753461047054673]
	TIME [epoch: 25.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08536585358668972		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.08536585358668972 | validation: 0.09874439671251661]
	TIME [epoch: 25.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912761247596152		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.0912761247596152 | validation: 0.06791185278108405]
	TIME [epoch: 25.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598565255125362		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.08598565255125362 | validation: 0.0613032699008259]
	TIME [epoch: 25.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08589218963609627		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.08589218963609627 | validation: 0.05347712380440502]
	TIME [epoch: 25.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07112491089045628		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.07112491089045628 | validation: 0.10932020984288249]
	TIME [epoch: 25.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09577140636544715		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.09577140636544715 | validation: 0.08643142173930315]
	TIME [epoch: 25.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046209393774857		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.09046209393774857 | validation: 0.06521769449140927]
	TIME [epoch: 25.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08163874194013522		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.08163874194013522 | validation: 0.08366213416379445]
	TIME [epoch: 25.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08731634121711596		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.08731634121711596 | validation: 0.055863970029395485]
	TIME [epoch: 25.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07524360385646063		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.07524360385646063 | validation: 0.05720298625384722]
	TIME [epoch: 25.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09128603157676209		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.09128603157676209 | validation: 0.06461446001476578]
	TIME [epoch: 25.2 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872478219544521		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.07872478219544521 | validation: 0.06608485997473484]
	TIME [epoch: 25.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174026601719629		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.08174026601719629 | validation: 0.06704953041220402]
	TIME [epoch: 25.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07441174404427862		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.07441174404427862 | validation: 0.07091412983499652]
	TIME [epoch: 25.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07998086047865478		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.07998086047865478 | validation: 0.06946188408936374]
	TIME [epoch: 25.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073973148702457		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.08073973148702457 | validation: 0.0648300578079452]
	TIME [epoch: 25.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605620612913369		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.07605620612913369 | validation: 0.08116741006322661]
	TIME [epoch: 25.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0834509268404009		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.0834509268404009 | validation: 0.059796891003850605]
	TIME [epoch: 25.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08159622713577652		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.08159622713577652 | validation: 0.05770040133561018]
	TIME [epoch: 25.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0737963808607475		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0737963808607475 | validation: 0.11410520757396589]
	TIME [epoch: 25.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13829078898505445		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.13829078898505445 | validation: 0.06611379689723954]
	TIME [epoch: 25.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253757860064551		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.07253757860064551 | validation: 0.05207759954604578]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0621948802120434		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.0621948802120434 | validation: 0.06285548402372716]
	TIME [epoch: 25.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833302641280382		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.0833302641280382 | validation: 0.07195956388928966]
	TIME [epoch: 25.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06698608163634227		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.06698608163634227 | validation: 0.09004729383353874]
	TIME [epoch: 25.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749081336964198		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.07749081336964198 | validation: 0.05086461996968064]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07003186900753865		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.07003186900753865 | validation: 0.061371906001544185]
	TIME [epoch: 25.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0794196184557463		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0794196184557463 | validation: 0.06238416837420949]
	TIME [epoch: 25.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346905163058233		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.07346905163058233 | validation: 0.05877245872824529]
	TIME [epoch: 25.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450710905863485		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.07450710905863485 | validation: 0.06779222854341188]
	TIME [epoch: 25.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07385154862781329		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.07385154862781329 | validation: 0.08621093216931082]
	TIME [epoch: 25.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747861146222657		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.07747861146222657 | validation: 0.09426001244922141]
	TIME [epoch: 25.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478847348419933		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.07478847348419933 | validation: 0.09808357704264566]
	TIME [epoch: 25.2 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07301684808068022		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.07301684808068022 | validation: 0.06052654732659067]
	TIME [epoch: 25.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671127411011238		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0671127411011238 | validation: 0.11674523261634653]
	TIME [epoch: 25.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07038447556320766		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.07038447556320766 | validation: 0.09614012188557536]
	TIME [epoch: 25.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07327164983728562		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.07327164983728562 | validation: 0.10618144581647013]
	TIME [epoch: 25.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10968297008377645		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.10968297008377645 | validation: 0.1580642809714341]
	TIME [epoch: 25.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786757025953954		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.0786757025953954 | validation: 0.0806818059728828]
	TIME [epoch: 25.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07572312954297547		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.07572312954297547 | validation: 0.07173042980550991]
	TIME [epoch: 25.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07459233012196935		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.07459233012196935 | validation: 0.061314029579550004]
	TIME [epoch: 25.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07114195660553155		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.07114195660553155 | validation: 0.07361442398502455]
	TIME [epoch: 25.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06938341453615769		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.06938341453615769 | validation: 0.07116169987891219]
	TIME [epoch: 25.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06787680650187548		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.06787680650187548 | validation: 0.07792608964482932]
	TIME [epoch: 25.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06928870591355725		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.06928870591355725 | validation: 0.06961649620592959]
	TIME [epoch: 25.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901538081948824		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.06901538081948824 | validation: 0.08438304971165639]
	TIME [epoch: 25.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06729609652787184		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.06729609652787184 | validation: 0.07999069672554343]
	TIME [epoch: 25.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06272979259908537		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.06272979259908537 | validation: 0.09699360276502073]
	TIME [epoch: 25.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667020176906003		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0667020176906003 | validation: 0.06523404167440454]
	TIME [epoch: 25.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07286686294143736		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.07286686294143736 | validation: 0.049767613293339]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_654.pth
	Model improved!!!
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217582396285183		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.06217582396285183 | validation: 0.0726478398840717]
	TIME [epoch: 25.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062331889556657596		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.062331889556657596 | validation: 0.0715028885199758]
	TIME [epoch: 25.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06970869074645775		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.06970869074645775 | validation: 0.06222143791161807]
	TIME [epoch: 25.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887080591849898		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.06887080591849898 | validation: 0.06145057424588543]
	TIME [epoch: 25.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06438969032028732		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.06438969032028732 | validation: 0.054684593722947455]
	TIME [epoch: 25.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05964003201069017		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.05964003201069017 | validation: 0.08494259597167678]
	TIME [epoch: 25.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.066235799655773		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.066235799655773 | validation: 0.05070408776161111]
	TIME [epoch: 25.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06370502006221325		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.06370502006221325 | validation: 0.05576714858164002]
	TIME [epoch: 25.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07945117594628187		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.07945117594628187 | validation: 0.04860087863606516]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0727937481258337		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.0727937481258337 | validation: 0.06050949254384212]
	TIME [epoch: 25.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07195626125778057		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.07195626125778057 | validation: 0.06100990999029644]
	TIME [epoch: 25.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0650334245634866		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.0650334245634866 | validation: 0.08700598869404697]
	TIME [epoch: 25.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961471913582773		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.05961471913582773 | validation: 0.05103890622191794]
	TIME [epoch: 25.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799716364960529		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.06799716364960529 | validation: 0.07421596321166299]
	TIME [epoch: 25.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608934830316818		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.06608934830316818 | validation: 0.06161502697829585]
	TIME [epoch: 25.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646223112241714		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.06646223112241714 | validation: 0.07517653164033612]
	TIME [epoch: 25.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06503952691265472		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.06503952691265472 | validation: 0.061232129607739993]
	TIME [epoch: 25.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056896693581110235		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.056896693581110235 | validation: 0.09229673718220226]
	TIME [epoch: 25.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06352629353507216		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.06352629353507216 | validation: 0.060072569152481346]
	TIME [epoch: 25.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06826216834709686		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.06826216834709686 | validation: 0.09886357684633074]
	TIME [epoch: 25.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053591510260279696		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.053591510260279696 | validation: 0.06660926913959536]
	TIME [epoch: 25.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07234884631983879		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.07234884631983879 | validation: 0.05645608900112266]
	TIME [epoch: 25.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059170850258895236		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.059170850258895236 | validation: 0.09397226715989815]
	TIME [epoch: 25.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07421757618263004		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.07421757618263004 | validation: 0.05992490446418769]
	TIME [epoch: 25.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055128496418143935		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.055128496418143935 | validation: 0.0602588627279882]
	TIME [epoch: 25.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06284901910243348		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.06284901910243348 | validation: 0.03964135497984461]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057901061955769564		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.057901061955769564 | validation: 0.03147651091447476]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_681.pth
	Model improved!!!
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053703673515781584		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.053703673515781584 | validation: 0.0954541290107207]
	TIME [epoch: 25.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06543148492584905		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.06543148492584905 | validation: 0.0656599333611564]
	TIME [epoch: 25.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863277752443249		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.05863277752443249 | validation: 0.1096415122106886]
	TIME [epoch: 25.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361312691509845		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.06361312691509845 | validation: 0.10749164334844051]
	TIME [epoch: 25.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720045921531618		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.07720045921531618 | validation: 0.07457809174082024]
	TIME [epoch: 25.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05374428789172761		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.05374428789172761 | validation: 0.060159078331949986]
	TIME [epoch: 25.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05237819984080058		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.05237819984080058 | validation: 0.0631015828034671]
	TIME [epoch: 25.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05957677419971009		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.05957677419971009 | validation: 0.08552380374200003]
	TIME [epoch: 25.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608934753016772		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.06608934753016772 | validation: 0.06314562962661846]
	TIME [epoch: 25.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056454599660296374		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.056454599660296374 | validation: 0.04275000507962031]
	TIME [epoch: 25.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05612876765848225		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.05612876765848225 | validation: 0.08983738858790886]
	TIME [epoch: 25.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060110880198902365		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.060110880198902365 | validation: 0.06700142429520375]
	TIME [epoch: 25.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05545989291211345		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.05545989291211345 | validation: 0.04513411065055825]
	TIME [epoch: 25.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06017464046985653		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.06017464046985653 | validation: 0.04626151117292571]
	TIME [epoch: 25.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639788431683134		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.05639788431683134 | validation: 0.04278622388724613]
	TIME [epoch: 25.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279548715954708		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.06279548715954708 | validation: 0.052497003804320895]
	TIME [epoch: 25.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568155864731006		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.0568155864731006 | validation: 0.05558394183149238]
	TIME [epoch: 25.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053720899811116385		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.053720899811116385 | validation: 0.1758453815140122]
	TIME [epoch: 25.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324088647346828		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.08324088647346828 | validation: 0.0520804433083399]
	TIME [epoch: 25.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603949474152394		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.05603949474152394 | validation: 0.03994586621366759]
	TIME [epoch: 25.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049090176642707734		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.049090176642707734 | validation: 0.05869635090740931]
	TIME [epoch: 25.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05212752534005677		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.05212752534005677 | validation: 0.03561925600312792]
	TIME [epoch: 25.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05112526129353023		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.05112526129353023 | validation: 0.04132103721168827]
	TIME [epoch: 25.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06646519307533652		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.06646519307533652 | validation: 0.04696160569873222]
	TIME [epoch: 25.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05859597639867328		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.05859597639867328 | validation: 0.042321955049863386]
	TIME [epoch: 25.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05359236964264573		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.05359236964264573 | validation: 0.033654623319528905]
	TIME [epoch: 25.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0426872386125748		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.0426872386125748 | validation: 0.08092420280850435]
	TIME [epoch: 25.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05650626169260158		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.05650626169260158 | validation: 0.05523402364731559]
	TIME [epoch: 25.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058160151602580284		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.058160151602580284 | validation: 0.07163198206878799]
	TIME [epoch: 25.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052014627349697605		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.052014627349697605 | validation: 0.058219714477538584]
	TIME [epoch: 25.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07575247558078113		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.07575247558078113 | validation: 0.16839006291254194]
	TIME [epoch: 25.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12426660748373398		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.12426660748373398 | validation: 0.09425479514575577]
	TIME [epoch: 25.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05421324403124158		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.05421324403124158 | validation: 0.041238118850649715]
	TIME [epoch: 25.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048540623490691756		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.048540623490691756 | validation: 0.04379415605236299]
	TIME [epoch: 25.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088569226212405		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.05088569226212405 | validation: 0.04370920171332689]
	TIME [epoch: 25.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420139706644255		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0420139706644255 | validation: 0.03450338292921826]
	TIME [epoch: 25.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743085591262457		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.04743085591262457 | validation: 0.11468473672236207]
	TIME [epoch: 25.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055224305387594215		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.055224305387594215 | validation: 0.04993399868038036]
	TIME [epoch: 25.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543664843999517		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.05543664843999517 | validation: 0.03786645219462691]
	TIME [epoch: 25.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04934470157019495		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.04934470157019495 | validation: 0.07405969579721633]
	TIME [epoch: 25.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049586140708044533		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.049586140708044533 | validation: 0.06318497799874884]
	TIME [epoch: 25.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06488556764833017		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.06488556764833017 | validation: 0.06550561650899539]
	TIME [epoch: 25.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051355983273100446		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.051355983273100446 | validation: 0.04455216217071293]
	TIME [epoch: 25.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461327510370535		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.05461327510370535 | validation: 0.04634653609455272]
	TIME [epoch: 25.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491619223058716		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.05491619223058716 | validation: 0.047363885097415244]
	TIME [epoch: 25.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04459748813455165		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.04459748813455165 | validation: 0.05884561012921752]
	TIME [epoch: 25.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04663223520652169		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.04663223520652169 | validation: 0.054504563789963656]
	TIME [epoch: 25.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049560623466369844		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.049560623466369844 | validation: 0.03930783159727218]
	TIME [epoch: 25.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478514735677277		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.05478514735677277 | validation: 0.0961437756007154]
	TIME [epoch: 25.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06423235996421905		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.06423235996421905 | validation: 0.062138598291059895]
	TIME [epoch: 25.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049181292117015975		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.049181292117015975 | validation: 0.04857543290439947]
	TIME [epoch: 25.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05289080769440341		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.05289080769440341 | validation: 0.04381200934517577]
	TIME [epoch: 25.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049404891352930455		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.049404891352930455 | validation: 0.041150813340698755]
	TIME [epoch: 25.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04207851289472002		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.04207851289472002 | validation: 0.09691849468789163]
	TIME [epoch: 25.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05011232814161204		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.05011232814161204 | validation: 0.04181580434361917]
	TIME [epoch: 25.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691632154662326		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.05691632154662326 | validation: 0.030380837195082454]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_737.pth
	Model improved!!!
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054337385520072314		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.054337385520072314 | validation: 0.02669265605620033]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0473822553476204		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0473822553476204 | validation: 0.07920733668837283]
	TIME [epoch: 25.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050651624474837564		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.050651624474837564 | validation: 0.08055594993551918]
	TIME [epoch: 25.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046860604136452995		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.046860604136452995 | validation: 0.06492910341890594]
	TIME [epoch: 25.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04649338928589873		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.04649338928589873 | validation: 0.0609524631638642]
	TIME [epoch: 25.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042082052509490375		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.042082052509490375 | validation: 0.08106130523888014]
	TIME [epoch: 25.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045096620966152266		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.045096620966152266 | validation: 0.039266053648161756]
	TIME [epoch: 25.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05127106671398312		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.05127106671398312 | validation: 0.08955593863566738]
	TIME [epoch: 25.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045493724907113404		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.045493724907113404 | validation: 0.06206338507820973]
	TIME [epoch: 25.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05344248349157804		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.05344248349157804 | validation: 0.04916323127980761]
	TIME [epoch: 25.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0477115775130159		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0477115775130159 | validation: 0.07212056319027804]
	TIME [epoch: 25.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05396969359193407		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.05396969359193407 | validation: 0.05715900663955549]
	TIME [epoch: 25.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042294656802492114		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.042294656802492114 | validation: 0.03955656874578945]
	TIME [epoch: 25.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032332371987217265		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.032332371987217265 | validation: 0.057406496297590114]
	TIME [epoch: 25.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046258405214217806		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.046258405214217806 | validation: 0.049195549739388486]
	TIME [epoch: 25.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403366003328206		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.04403366003328206 | validation: 0.0747879971690284]
	TIME [epoch: 25.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04946202425895923		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.04946202425895923 | validation: 0.026749861035702496]
	TIME [epoch: 25.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385998441519097		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.04385998441519097 | validation: 0.0758936275056164]
	TIME [epoch: 25.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04438310539780438		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.04438310539780438 | validation: 0.06314313686547804]
	TIME [epoch: 25.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442972144851744		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0442972144851744 | validation: 0.04146159664885722]
	TIME [epoch: 25.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046827201177678794		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.046827201177678794 | validation: 0.03270317672390864]
	TIME [epoch: 25.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309374429300202		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.04309374429300202 | validation: 0.0342315901505669]
	TIME [epoch: 25.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055842112221633995		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.055842112221633995 | validation: 0.03229964443901541]
	TIME [epoch: 25.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047352283369754986		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.047352283369754986 | validation: 0.0519394264781776]
	TIME [epoch: 25.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03712987831379135		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.03712987831379135 | validation: 0.0777571213977609]
	TIME [epoch: 25.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04479018328242768		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.04479018328242768 | validation: 0.08429481591645202]
	TIME [epoch: 25.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0421422074724962		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0421422074724962 | validation: 0.056068085065247596]
	TIME [epoch: 25.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420161542162349		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0420161542162349 | validation: 0.044932221226105316]
	TIME [epoch: 25.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042593849512163294		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.042593849512163294 | validation: 0.06274801257328391]
	TIME [epoch: 25.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718147690921181		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.04718147690921181 | validation: 0.06672125895933466]
	TIME [epoch: 25.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048806813127390825		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.048806813127390825 | validation: 0.05812628960691325]
	TIME [epoch: 25.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04142032127787672		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.04142032127787672 | validation: 0.051984924718227264]
	TIME [epoch: 25.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03664091445001363		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.03664091445001363 | validation: 0.0757402916221264]
	TIME [epoch: 25.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03751555117681696		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.03751555117681696 | validation: 0.05791148387643531]
	TIME [epoch: 25.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049745825526894674		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.049745825526894674 | validation: 0.03094884575218216]
	TIME [epoch: 25.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035452535063011936		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.035452535063011936 | validation: 0.06510805857390661]
	TIME [epoch: 25.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04156420142100309		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.04156420142100309 | validation: 0.09141206683026404]
	TIME [epoch: 25.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06444345601972845		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.06444345601972845 | validation: 0.10598372678692058]
	TIME [epoch: 25.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06262982343878433		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.06262982343878433 | validation: 0.046864831488953776]
	TIME [epoch: 25.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038724836117605355		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.038724836117605355 | validation: 0.04143183918345211]
	TIME [epoch: 25.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595099926699771		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.03595099926699771 | validation: 0.05070543685497304]
	TIME [epoch: 25.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042594680900350526		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.042594680900350526 | validation: 0.040605900111779364]
	TIME [epoch: 25.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03667318186825797		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.03667318186825797 | validation: 0.02679451860254659]
	TIME [epoch: 25.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03201060991247245		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.03201060991247245 | validation: 0.040273810207756465]
	TIME [epoch: 25.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0673592161033169		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0673592161033169 | validation: 0.038491600492029945]
	TIME [epoch: 25.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036787003396795		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.036787003396795 | validation: 0.021268342415685128]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_783.pth
	Model improved!!!
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260415184864282		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.04260415184864282 | validation: 0.03296892552976051]
	TIME [epoch: 25.1 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04812758087641858		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.04812758087641858 | validation: 0.028408469918870548]
	TIME [epoch: 25.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0370248261670879		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0370248261670879 | validation: 0.029149835474288795]
	TIME [epoch: 25.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03680155731539165		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.03680155731539165 | validation: 0.030560632716130357]
	TIME [epoch: 25.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03666970556223766		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.03666970556223766 | validation: 0.03661562135177468]
	TIME [epoch: 25.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467796252711015		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.04467796252711015 | validation: 0.035164920587270734]
	TIME [epoch: 25.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03759411233615375		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.03759411233615375 | validation: 0.034845290395129146]
	TIME [epoch: 25.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032458807206978614		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.032458807206978614 | validation: 0.029538462112422968]
	TIME [epoch: 25.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876679117156822		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.03876679117156822 | validation: 0.036706086927875914]
	TIME [epoch: 25.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004349253094609		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.04004349253094609 | validation: 0.035351167166252695]
	TIME [epoch: 25.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540737732437042		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.04540737732437042 | validation: 0.03403182457946231]
	TIME [epoch: 25.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035653244347413134		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.035653244347413134 | validation: 0.025235746613125956]
	TIME [epoch: 25.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035764780495180976		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.035764780495180976 | validation: 0.03504504518009793]
	TIME [epoch: 25.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037725649433845654		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.037725649433845654 | validation: 0.03187966705191904]
	TIME [epoch: 25.2 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017176607745563		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.04017176607745563 | validation: 0.024156601592500448]
	TIME [epoch: 25.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04706652784234465		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.04706652784234465 | validation: 0.02788297380349783]
	TIME [epoch: 25.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030810466623752038		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.030810466623752038 | validation: 0.0959628997920558]
	TIME [epoch: 25.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04171764272564966		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.04171764272564966 | validation: 0.041492592263736944]
	TIME [epoch: 25.2 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044039792875032985		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.044039792875032985 | validation: 0.022004593741080047]
	TIME [epoch: 25.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03062280363227049		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.03062280363227049 | validation: 0.03015976015967889]
	TIME [epoch: 25.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037176210823917755		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.037176210823917755 | validation: 0.03134440424947031]
	TIME [epoch: 25.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04222126470171325		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.04222126470171325 | validation: 0.027428714745412044]
	TIME [epoch: 25.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0385161981496928		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0385161981496928 | validation: 0.024883240390602065]
	TIME [epoch: 25.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09594150082292123		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.09594150082292123 | validation: 0.030294356641246217]
	TIME [epoch: 25.2 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045542790926697815		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.045542790926697815 | validation: 0.03995530907465797]
	TIME [epoch: 25.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031004905493763807		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.031004905493763807 | validation: 0.03391802858840363]
	TIME [epoch: 25.2 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030648603741154384		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.030648603741154384 | validation: 0.04171055156427935]
	TIME [epoch: 25.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029653570950597515		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.029653570950597515 | validation: 0.06049572694121583]
	TIME [epoch: 25.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297105110898451		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.03297105110898451 | validation: 0.043088541609599934]
	TIME [epoch: 25.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03331654654664897		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.03331654654664897 | validation: 0.025459416297936376]
	TIME [epoch: 25.2 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032612884988788685		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.032612884988788685 | validation: 0.04410627035019207]
	TIME [epoch: 25.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03514491990576748		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.03514491990576748 | validation: 0.03687231022237761]
	TIME [epoch: 25.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595878360539964		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.03595878360539964 | validation: 0.030541393741150585]
	TIME [epoch: 25.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030895201715292732		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.030895201715292732 | validation: 0.02157990656025186]
	TIME [epoch: 25.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03448137897716702		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.03448137897716702 | validation: 0.07737149457339346]
	TIME [epoch: 25.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372602514964412		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.03372602514964412 | validation: 0.04396529320488378]
	TIME [epoch: 25.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03372444761159882		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.03372444761159882 | validation: 0.04410845438511429]
	TIME [epoch: 25.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03559699973915431		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.03559699973915431 | validation: 0.08769192507350446]
	TIME [epoch: 25.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04234275421404415		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.04234275421404415 | validation: 0.041622983249900956]
	TIME [epoch: 25.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03853082385921253		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.03853082385921253 | validation: 0.030457196870704993]
	TIME [epoch: 25.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03569900609111225		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.03569900609111225 | validation: 0.04101078267764846]
	TIME [epoch: 25.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024976584275734945		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.024976584275734945 | validation: 0.029366328748170363]
	TIME [epoch: 25.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03233481636833677		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.03233481636833677 | validation: 0.02359895108841959]
	TIME [epoch: 25.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196907366009309		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.04196907366009309 | validation: 0.03544207873917072]
	TIME [epoch: 25.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027126809529475587		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.027126809529475587 | validation: 0.027329883970071592]
	TIME [epoch: 25.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034613538107277304		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.034613538107277304 | validation: 0.026338222327347224]
	TIME [epoch: 25.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032127142853047526		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.032127142853047526 | validation: 0.030430829931839494]
	TIME [epoch: 25.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035920727866735974		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.035920727866735974 | validation: 0.03096273133607579]
	TIME [epoch: 25.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03143161411681118		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.03143161411681118 | validation: 0.029481813664796262]
	TIME [epoch: 25.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030829837736531487		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.030829837736531487 | validation: 0.020884620878803058]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03470016144188741		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.03470016144188741 | validation: 0.02788863984058783]
	TIME [epoch: 25.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03765551460490705		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.03765551460490705 | validation: 0.027098571584810792]
	TIME [epoch: 25.2 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02869908446816023		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.02869908446816023 | validation: 0.034231418452849896]
	TIME [epoch: 25.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032561044179127197		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.032561044179127197 | validation: 0.03847711422900757]
	TIME [epoch: 25.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03963691943024366		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.03963691943024366 | validation: 0.020456664541151914]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_838.pth
	Model improved!!!
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471351709628481		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.03471351709628481 | validation: 0.05401760443496028]
	TIME [epoch: 25.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03592487168658816		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.03592487168658816 | validation: 0.02415491004024157]
	TIME [epoch: 25.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032792934044101774		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.032792934044101774 | validation: 0.024001699476700833]
	TIME [epoch: 25.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026776359767259048		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.026776359767259048 | validation: 0.031916161619684226]
	TIME [epoch: 25.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03511226035416044		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.03511226035416044 | validation: 0.022896919071875157]
	TIME [epoch: 25.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02087996163623		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.02087996163623 | validation: 0.022131904458406564]
	TIME [epoch: 25.2 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335732647800893		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.03335732647800893 | validation: 0.02295519518565356]
	TIME [epoch: 25.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030727487127722546		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.030727487127722546 | validation: 0.031019365515670173]
	TIME [epoch: 25.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03716496646900281		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.03716496646900281 | validation: 0.020152079042507095]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_847.pth
	Model improved!!!
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0312010182334875		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0312010182334875 | validation: 0.02288430555726876]
	TIME [epoch: 25.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038219644855181326		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.038219644855181326 | validation: 0.03063737616948349]
	TIME [epoch: 25.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02727686657941714		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.02727686657941714 | validation: 0.036302832835482045]
	TIME [epoch: 25.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028420418049123156		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.028420418049123156 | validation: 0.022414923802329866]
	TIME [epoch: 25.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026849770897234396		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.026849770897234396 | validation: 0.026737873001730233]
	TIME [epoch: 25.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03304866514524316		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.03304866514524316 | validation: 0.09521016280497882]
	TIME [epoch: 25.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03466954573901966		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.03466954573901966 | validation: 0.018535264817573976]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_854.pth
	Model improved!!!
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029549241891881933		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.029549241891881933 | validation: 0.025732792116200137]
	TIME [epoch: 25.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03299005793843019		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.03299005793843019 | validation: 0.023924192968945084]
	TIME [epoch: 25.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028805893603407944		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.028805893603407944 | validation: 0.02782560392322575]
	TIME [epoch: 25.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029582579118048347		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.029582579118048347 | validation: 0.0368870874400938]
	TIME [epoch: 25.2 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03092275925471447		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.03092275925471447 | validation: 0.03982078960100577]
	TIME [epoch: 25.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02517428537237948		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.02517428537237948 | validation: 0.022712242339272194]
	TIME [epoch: 25.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030401692934868788		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.030401692934868788 | validation: 0.022925804919183355]
	TIME [epoch: 25.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029850573381766		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.029850573381766 | validation: 0.044312835789684]
	TIME [epoch: 25.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029714431451356257		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.029714431451356257 | validation: 0.017423605409515253]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_863.pth
	Model improved!!!
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027329628170984884		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.027329628170984884 | validation: 0.04568451391805258]
	TIME [epoch: 25.1 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03487525248437995		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.03487525248437995 | validation: 0.02207193314903387]
	TIME [epoch: 25.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028574530352059046		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.028574530352059046 | validation: 0.01961701577433829]
	TIME [epoch: 25.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02846989774745775		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.02846989774745775 | validation: 0.022323348630157926]
	TIME [epoch: 25.1 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026860410678831194		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.026860410678831194 | validation: 0.022407114011593034]
	TIME [epoch: 25.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0316937252459136		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0316937252459136 | validation: 0.025610747290152548]
	TIME [epoch: 25.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027647839440482533		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.027647839440482533 | validation: 0.021151696306477383]
	TIME [epoch: 25.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026288457943492233		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.026288457943492233 | validation: 0.021098618504124263]
	TIME [epoch: 25.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025243648148118678		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.025243648148118678 | validation: 0.020022713173257]
	TIME [epoch: 25.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031970676810352906		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.031970676810352906 | validation: 0.023542593849764572]
	TIME [epoch: 25.2 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0275363073152404		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.0275363073152404 | validation: 0.027380069298193456]
	TIME [epoch: 25.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02687442714665655		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.02687442714665655 | validation: 0.02575496049794468]
	TIME [epoch: 25.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029308825839177318		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.029308825839177318 | validation: 0.03536924058415137]
	TIME [epoch: 25.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033588842962744454		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.033588842962744454 | validation: 0.03002651389322543]
	TIME [epoch: 25.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02190790655776705		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.02190790655776705 | validation: 0.025931696216824923]
	TIME [epoch: 25.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445378827851271		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.03445378827851271 | validation: 0.02175842131370554]
	TIME [epoch: 25.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127321760224434		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.03127321760224434 | validation: 0.01702867704559622]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_880.pth
	Model improved!!!
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026565909204830082		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.026565909204830082 | validation: 0.029960322828344408]
	TIME [epoch: 25.2 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026772092721743492		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.026772092721743492 | validation: 0.018684427795693966]
	TIME [epoch: 25.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03169909310877757		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.03169909310877757 | validation: 0.026062088037230254]
	TIME [epoch: 25.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030311936844161422		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.030311936844161422 | validation: 0.02515854394415747]
	TIME [epoch: 25.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07226385525863163		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07226385525863163 | validation: 0.0361420621238591]
	TIME [epoch: 25.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024361030296962963		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.024361030296962963 | validation: 0.02057723329894468]
	TIME [epoch: 25.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018170246149591174		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.018170246149591174 | validation: 0.02322122056792611]
	TIME [epoch: 25.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02900372641017232		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.02900372641017232 | validation: 0.027443656759200477]
	TIME [epoch: 25.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027464851687367297		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.027464851687367297 | validation: 0.01753776618863214]
	TIME [epoch: 25.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024518604450150777		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.024518604450150777 | validation: 0.023062758657302795]
	TIME [epoch: 25.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02078663936512857		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.02078663936512857 | validation: 0.02541803386654624]
	TIME [epoch: 25.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030382064097526775		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.030382064097526775 | validation: 0.037621498495691706]
	TIME [epoch: 25.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028052371217918533		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.028052371217918533 | validation: 0.021622914407648873]
	TIME [epoch: 25.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02630726526105969		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.02630726526105969 | validation: 0.02273040000443443]
	TIME [epoch: 25.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027293241615409875		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.027293241615409875 | validation: 0.019561591358931475]
	TIME [epoch: 25.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02206000703176735		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.02206000703176735 | validation: 0.022284263962031522]
	TIME [epoch: 25.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026518898630095468		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.026518898630095468 | validation: 0.017139297002436577]
	TIME [epoch: 25.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02487506321644098		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.02487506321644098 | validation: 0.020156389245204548]
	TIME [epoch: 25.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223588403309899		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.04223588403309899 | validation: 0.0177863094354628]
	TIME [epoch: 25.1 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024016109708242823		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.024016109708242823 | validation: 0.017968393065450748]
	TIME [epoch: 25.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020205851768207057		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.020205851768207057 | validation: 0.023366952395265074]
	TIME [epoch: 25.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026617089520597267		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.026617089520597267 | validation: 0.020104678954688426]
	TIME [epoch: 25.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024067495406609275		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.024067495406609275 | validation: 0.018831796681232908]
	TIME [epoch: 25.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0260487477048063		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.0260487477048063 | validation: 0.02064224022148313]
	TIME [epoch: 25.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023570880191515486		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.023570880191515486 | validation: 0.022296421347406385]
	TIME [epoch: 25.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02035475828568259		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.02035475828568259 | validation: 0.01967850809524372]
	TIME [epoch: 25.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025528892312211313		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.025528892312211313 | validation: 0.01855271028278617]
	TIME [epoch: 25.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025472588556106394		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.025472588556106394 | validation: 0.01565420237276346]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02601537463811374		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.02601537463811374 | validation: 0.01932869751084335]
	TIME [epoch: 25.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02213827403439041		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.02213827403439041 | validation: 0.02277404682945456]
	TIME [epoch: 25.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023846283136149657		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.023846283136149657 | validation: 0.019711437984705746]
	TIME [epoch: 25.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022576607699057557		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.022576607699057557 | validation: 0.020694856921860474]
	TIME [epoch: 25.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02416849519270301		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.02416849519270301 | validation: 0.031250047601435266]
	TIME [epoch: 25.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049471050943557		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.03049471050943557 | validation: 0.01567189686317605]
	TIME [epoch: 25.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02089827528682892		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.02089827528682892 | validation: 0.033089481685482154]
	TIME [epoch: 25.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030070731617315483		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.030070731617315483 | validation: 0.02239522067376149]
	TIME [epoch: 25.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01985799676025241		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.01985799676025241 | validation: 0.039220041978865056]
	TIME [epoch: 25.2 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028059419543546876		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.028059419543546876 | validation: 0.015160286395164545]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_918.pth
	Model improved!!!
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016313827004111492		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.016313827004111492 | validation: 0.02939623147204238]
	TIME [epoch: 25.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02907559731899008		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.02907559731899008 | validation: 0.016401939476820157]
	TIME [epoch: 25.2 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022851675325102794		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.022851675325102794 | validation: 0.01814132502089049]
	TIME [epoch: 25.2 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021747998514281865		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.021747998514281865 | validation: 0.02062782634534215]
	TIME [epoch: 25.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025128109713566354		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.025128109713566354 | validation: 0.024417269086317694]
	TIME [epoch: 25.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027124061196088668		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.027124061196088668 | validation: 0.016484188718656163]
	TIME [epoch: 25.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02327376600478459		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.02327376600478459 | validation: 0.027398674722706864]
	TIME [epoch: 25.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026216011052181312		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.026216011052181312 | validation: 0.025776845628572534]
	TIME [epoch: 25.2 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0223609731763919		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.0223609731763919 | validation: 0.02679696151486197]
	TIME [epoch: 25.2 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02403309176826701		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.02403309176826701 | validation: 0.016254535023540566]
	TIME [epoch: 25.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02268266401714343		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.02268266401714343 | validation: 0.017110652753002078]
	TIME [epoch: 25.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017031602511488983		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.017031602511488983 | validation: 0.019150073101026035]
	TIME [epoch: 25.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027609267923494815		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.027609267923494815 | validation: 0.015069213833941796]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_931.pth
	Model improved!!!
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024628782902747934		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.024628782902747934 | validation: 0.018304086169083814]
	TIME [epoch: 25.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021441109392787358		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.021441109392787358 | validation: 0.022857683056802882]
	TIME [epoch: 25.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025222975384950212		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.025222975384950212 | validation: 0.03519400820200998]
	TIME [epoch: 25.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02138655613361161		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.02138655613361161 | validation: 0.024717378247559936]
	TIME [epoch: 25.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02217393323291427		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.02217393323291427 | validation: 0.037926949549566005]
	TIME [epoch: 25.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021658784003394622		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.021658784003394622 | validation: 0.01845726257546766]
	TIME [epoch: 25.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022532088107050378		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.022532088107050378 | validation: 0.021366791983407102]
	TIME [epoch: 25.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021799451696127396		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.021799451696127396 | validation: 0.02147562543688637]
	TIME [epoch: 25.2 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022998000436105497		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.022998000436105497 | validation: 0.016730953473561176]
	TIME [epoch: 25.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016412508586541037		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.016412508586541037 | validation: 0.02214971592109566]
	TIME [epoch: 25.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02779209888710191		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.02779209888710191 | validation: 0.017210481619976806]
	TIME [epoch: 25.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845618310286055		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.01845618310286055 | validation: 0.020483219769075352]
	TIME [epoch: 25.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0225951799309186		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0225951799309186 | validation: 0.022424119211419673]
	TIME [epoch: 25.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02530729852810966		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.02530729852810966 | validation: 0.015783661531149143]
	TIME [epoch: 25.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019711317726171483		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.019711317726171483 | validation: 0.013359315921003388]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022552178602020738		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.022552178602020738 | validation: 0.02005256444048461]
	TIME [epoch: 25.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020050575468062493		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.020050575468062493 | validation: 0.01522429033275278]
	TIME [epoch: 25.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021465475553342408		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.021465475553342408 | validation: 0.02501159451372043]
	TIME [epoch: 25.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01981296465943511		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.01981296465943511 | validation: 0.014411821232410617]
	TIME [epoch: 25.2 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023106653576202913		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.023106653576202913 | validation: 0.023418808897608168]
	TIME [epoch: 25.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015896532988852897		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.015896532988852897 | validation: 0.01640798122534926]
	TIME [epoch: 25.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02431361676795743		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.02431361676795743 | validation: 0.015740237328350073]
	TIME [epoch: 25.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020109132207536518		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.020109132207536518 | validation: 0.018689912671615495]
	TIME [epoch: 25.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02409005801962869		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.02409005801962869 | validation: 0.01681791353742987]
	TIME [epoch: 25.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018208217735458724		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.018208217735458724 | validation: 0.020011844628463168]
	TIME [epoch: 25.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021692054792568027		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.021692054792568027 | validation: 0.02369682693523667]
	TIME [epoch: 25.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023858197046803108		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.023858197046803108 | validation: 0.01713798226102767]
	TIME [epoch: 25.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019403742510490703		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.019403742510490703 | validation: 0.024335396508534283]
	TIME [epoch: 25.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022149440505763274		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.022149440505763274 | validation: 0.013538888245982686]
	TIME [epoch: 25.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018153933980323445		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.018153933980323445 | validation: 0.01549716995049481]
	TIME [epoch: 25.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021436538052770016		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.021436538052770016 | validation: 0.016203817519361792]
	TIME [epoch: 25.1 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028525828774133254		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.028525828774133254 | validation: 0.021236580705008123]
	TIME [epoch: 25.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019330071579703005		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.019330071579703005 | validation: 0.016244030017822153]
	TIME [epoch: 25.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015595565279232192		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.015595565279232192 | validation: 0.011849921908610214]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_965.pth
	Model improved!!!
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01950093358198377		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.01950093358198377 | validation: 0.017550702459967555]
	TIME [epoch: 25.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022659910404514098		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.022659910404514098 | validation: 0.016311093331253405]
	TIME [epoch: 25.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01951779199013711		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.01951779199013711 | validation: 0.023721609740534923]
	TIME [epoch: 25.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020740214999263703		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.020740214999263703 | validation: 0.01424946713825724]
	TIME [epoch: 25.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018138788285079338		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.018138788285079338 | validation: 0.013447134002780331]
	TIME [epoch: 25.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016481240992466735		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.016481240992466735 | validation: 0.04097415963480462]
	TIME [epoch: 25.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03161455525020218		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.03161455525020218 | validation: 0.021214678656104845]
	TIME [epoch: 25.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018744205936367143		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.018744205936367143 | validation: 0.022368302117364038]
	TIME [epoch: 25.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01741988498229366		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.01741988498229366 | validation: 0.016587731160137717]
	TIME [epoch: 25.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977794776975023		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.01977794776975023 | validation: 0.019422300297019447]
	TIME [epoch: 25.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015310403021448992		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.015310403021448992 | validation: 0.015528561452123234]
	TIME [epoch: 25.1 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02513256368570454		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.02513256368570454 | validation: 0.01244982877776095]
	TIME [epoch: 25.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791116354113263		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.01791116354113263 | validation: 0.016753021309013665]
	TIME [epoch: 25.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018991483290087218		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.018991483290087218 | validation: 0.01782912119557767]
	TIME [epoch: 25.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016255619031251133		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.016255619031251133 | validation: 0.022250231182475738]
	TIME [epoch: 25.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023048142446644267		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.023048142446644267 | validation: 0.012465792134869695]
	TIME [epoch: 25.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019382662611530807		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.019382662611530807 | validation: 0.026304075104637503]
	TIME [epoch: 25.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0184760527531766		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0184760527531766 | validation: 0.0121541747611917]
	TIME [epoch: 25.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02099769747806816		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.02099769747806816 | validation: 0.022069091608857803]
	TIME [epoch: 25.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016480424172699903		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.016480424172699903 | validation: 0.014820848227306224]
	TIME [epoch: 25.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02159218123471706		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.02159218123471706 | validation: 0.015302759253024548]
	TIME [epoch: 25.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014557157235478395		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.014557157235478395 | validation: 0.023191436801708668]
	TIME [epoch: 25.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023126025778412735		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.023126025778412735 | validation: 0.016803224218861483]
	TIME [epoch: 25.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01955149826673932		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.01955149826673932 | validation: 0.03084422523263094]
	TIME [epoch: 25.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019111963279014654		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.019111963279014654 | validation: 0.019269877787452257]
	TIME [epoch: 25.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016747971950689423		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.016747971950689423 | validation: 0.013097561053759385]
	TIME [epoch: 25.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421437685815532		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.02421437685815532 | validation: 0.01572758915518721]
	TIME [epoch: 25.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014477054925716607		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.014477054925716607 | validation: 0.012424349976116866]
	TIME [epoch: 25.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018378828665263414		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.018378828665263414 | validation: 0.012793488714681127]
	TIME [epoch: 25.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01427508447348338		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.01427508447348338 | validation: 0.018966178162194418]
	TIME [epoch: 25.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021793512063399537		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.021793512063399537 | validation: 0.02112124910796967]
	TIME [epoch: 25.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017363328139157395		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.017363328139157395 | validation: 0.014089275653277894]
	TIME [epoch: 25.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932372013092132		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.01932372013092132 | validation: 0.014834315989626892]
	TIME [epoch: 25.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01995626683711296		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.01995626683711296 | validation: 0.01294286799004208]
	TIME [epoch: 25.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01539997098549344		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.01539997098549344 | validation: 0.013977665374266294]
	TIME [epoch: 25.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01874301274084632		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.01874301274084632 | validation: 0.013713764444748915]
	TIME [epoch: 398 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01655896501896414		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.01655896501896414 | validation: 0.02375151610994889]
	TIME [epoch: 53.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021378633038223325		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.021378633038223325 | validation: 0.014869876538798487]
	TIME [epoch: 53.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013658394551058965		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.013658394551058965 | validation: 0.019082268988545762]
	TIME [epoch: 53.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020291140665223514		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.020291140665223514 | validation: 0.011575381656901541]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1005.pth
	Model improved!!!
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671304580465752		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.01671304580465752 | validation: 0.020089965582817004]
	TIME [epoch: 53.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018109763775176875		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.018109763775176875 | validation: 0.015326263911828151]
	TIME [epoch: 53.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020364417219730334		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.020364417219730334 | validation: 0.013725716099280794]
	TIME [epoch: 53.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0178106301570727		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.0178106301570727 | validation: 0.017879068977003493]
	TIME [epoch: 53.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014759940799207252		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.014759940799207252 | validation: 0.030675950483380558]
	TIME [epoch: 53.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02128969126988061		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.02128969126988061 | validation: 0.011968197460232598]
	TIME [epoch: 53.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01384001834937391		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.01384001834937391 | validation: 0.01851059136588013]
	TIME [epoch: 53.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020850220142856417		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.020850220142856417 | validation: 0.014749299569342764]
	TIME [epoch: 53.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017532502938010633		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.017532502938010633 | validation: 0.015401569386318488]
	TIME [epoch: 53.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01651837676145416		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.01651837676145416 | validation: 0.010991955585058059]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1015.pth
	Model improved!!!
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015096081068799463		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.015096081068799463 | validation: 0.023946207458007334]
	TIME [epoch: 53.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04329709793926151		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.04329709793926151 | validation: 0.07558734971071254]
	TIME [epoch: 53.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043935078263160975		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.043935078263160975 | validation: 0.013193685427078406]
	TIME [epoch: 53.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01430406975608425		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.01430406975608425 | validation: 0.012166796905382353]
	TIME [epoch: 53.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013551901601954424		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.013551901601954424 | validation: 0.012282815607843663]
	TIME [epoch: 53.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015050892805203463		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.015050892805203463 | validation: 0.01918772011256549]
	TIME [epoch: 53.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016412174287084205		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.016412174287084205 | validation: 0.014308446273106588]
	TIME [epoch: 53.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01667126308916205		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.01667126308916205 | validation: 0.011094907539426345]
	TIME [epoch: 53.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019735035728067618		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.019735035728067618 | validation: 0.013926779230021516]
	TIME [epoch: 53.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013458865883518235		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.013458865883518235 | validation: 0.012861431984804052]
	TIME [epoch: 53.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01790754575657513		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.01790754575657513 | validation: 0.012756931950750942]
	TIME [epoch: 53.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015610384203924743		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.015610384203924743 | validation: 0.013608002899103987]
	TIME [epoch: 53.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017746444520928426		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.017746444520928426 | validation: 0.015681205447223144]
	TIME [epoch: 53.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01352813811582196		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.01352813811582196 | validation: 0.011659631105773213]
	TIME [epoch: 53.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021392274985641342		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.021392274985641342 | validation: 0.017732024767744093]
	TIME [epoch: 53.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01988794296846425		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.01988794296846425 | validation: 0.014080152126059302]
	TIME [epoch: 53.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013621972617694218		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.013621972617694218 | validation: 0.016264760367503416]
	TIME [epoch: 53.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017129773948877703		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.017129773948877703 | validation: 0.014295984923954265]
	TIME [epoch: 53.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014838468096493397		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.014838468096493397 | validation: 0.010060303829049898]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172131956367827		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0172131956367827 | validation: 0.013038122789497713]
	TIME [epoch: 53.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016083460818476815		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.016083460818476815 | validation: 0.028059106270502177]
	TIME [epoch: 53.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016222962783513574		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.016222962783513574 | validation: 0.018396796574533313]
	TIME [epoch: 53.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01537565293341643		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.01537565293341643 | validation: 0.01684952656313395]
	TIME [epoch: 53.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016955568661431584		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.016955568661431584 | validation: 0.01364537892841754]
	TIME [epoch: 53.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01451125991012504		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.01451125991012504 | validation: 0.018099010181919957]
	TIME [epoch: 53.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01662455738437273		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.01662455738437273 | validation: 0.02361183494719201]
	TIME [epoch: 53.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016771455879294975		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.016771455879294975 | validation: 0.018398023641953497]
	TIME [epoch: 53.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014246790966730642		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.014246790966730642 | validation: 0.019287443696254354]
	TIME [epoch: 53.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698927186689184		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.01698927186689184 | validation: 0.01608695004901625]
	TIME [epoch: 53.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013282676728284136		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.013282676728284136 | validation: 0.011608554390237521]
	TIME [epoch: 53.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015897596787971365		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.015897596787971365 | validation: 0.015121511239544028]
	TIME [epoch: 53.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015081391365545933		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.015081391365545933 | validation: 0.013174194912272608]
	TIME [epoch: 53.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013739200656554455		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.013739200656554455 | validation: 0.0133017926963839]
	TIME [epoch: 53.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01741137920568236		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.01741137920568236 | validation: 0.015063035030896165]
	TIME [epoch: 53.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014445047230414529		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.014445047230414529 | validation: 0.01824628306726974]
	TIME [epoch: 53.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022137603882770494		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.022137603882770494 | validation: 0.016185468401073443]
	TIME [epoch: 53.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01369088838903355		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.01369088838903355 | validation: 0.014454763120806468]
	TIME [epoch: 53.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016895868176920844		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.016895868176920844 | validation: 0.014821382617250582]
	TIME [epoch: 53.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015147896387333016		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.015147896387333016 | validation: 0.011675936354704226]
	TIME [epoch: 53.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01490610929015589		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.01490610929015589 | validation: 0.010791853893588641]
	TIME [epoch: 53.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013684780116712748		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.013684780116712748 | validation: 0.017983164932354224]
	TIME [epoch: 53.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016064941566180605		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.016064941566180605 | validation: 0.013114386980568393]
	TIME [epoch: 53.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013390434404432057		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.013390434404432057 | validation: 0.013541863722322474]
	TIME [epoch: 53.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015482679079753352		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.015482679079753352 | validation: 0.016426987770793967]
	TIME [epoch: 53.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013154155165842495		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.013154155165842495 | validation: 0.010214707766969347]
	TIME [epoch: 53.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013306071649232181		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.013306071649232181 | validation: 0.024597521381205724]
	TIME [epoch: 53.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014877188888286152		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.014877188888286152 | validation: 0.012510413181241267]
	TIME [epoch: 53.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018544784338944187		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.018544784338944187 | validation: 0.012053681433050249]
	TIME [epoch: 53.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012663408258885994		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.012663408258885994 | validation: 0.0444254979475035]
	TIME [epoch: 53.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021389475756373268		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.021389475756373268 | validation: 0.015858653169767103]
	TIME [epoch: 53.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0174190066947929		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0174190066947929 | validation: 0.012023608664983258]
	TIME [epoch: 53.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016660930441781026		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.016660930441781026 | validation: 0.010686654353624522]
	TIME [epoch: 53.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011834402277940748		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.011834402277940748 | validation: 0.011090318858651927]
	TIME [epoch: 53.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012736259525610383		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.012736259525610383 | validation: 0.01739854989766529]
	TIME [epoch: 53.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016468806496286677		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.016468806496286677 | validation: 0.01645971325158713]
	TIME [epoch: 53.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013736872213266317		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.013736872213266317 | validation: 0.010451568578636132]
	TIME [epoch: 53.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017014215795658986		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.017014215795658986 | validation: 0.012315443310056805]
	TIME [epoch: 53.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012340113068202811		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.012340113068202811 | validation: 0.013870832038464698]
	TIME [epoch: 53.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01801260355327662		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.01801260355327662 | validation: 0.010492635582295195]
	TIME [epoch: 53.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014127966627666647		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.014127966627666647 | validation: 0.015326589000935274]
	TIME [epoch: 53.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01454299208070265		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.01454299208070265 | validation: 0.010436400192743653]
	TIME [epoch: 53.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014764771564856428		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.014764771564856428 | validation: 0.010611873956357773]
	TIME [epoch: 53.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01394593555850962		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.01394593555850962 | validation: 0.020150168240477495]
	TIME [epoch: 53.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014930798284917243		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.014930798284917243 | validation: 0.013026112158120034]
	TIME [epoch: 53.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01547474386659408		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.01547474386659408 | validation: 0.011689397003861585]
	TIME [epoch: 54.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01380987146262009		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.01380987146262009 | validation: 0.01723505467828438]
	TIME [epoch: 53.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015489927760033223		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.015489927760033223 | validation: 0.011368434385399006]
	TIME [epoch: 53.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011220092676897022		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.011220092676897022 | validation: 0.0110395482283561]
	TIME [epoch: 53.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01386571808029657		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.01386571808029657 | validation: 0.0157033952575863]
	TIME [epoch: 53.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01516642606912107		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.01516642606912107 | validation: 0.009927053927175807]
	TIME [epoch: 53.9 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1085.pth
	Model improved!!!
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01423026076774587		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.01423026076774587 | validation: 0.010377371319210352]
	TIME [epoch: 54.1 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01052243511721117		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.01052243511721117 | validation: 0.009527037587363544]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1087.pth
	Model improved!!!
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019927080554906728		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.019927080554906728 | validation: 0.00974594332988641]
	TIME [epoch: 53.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011228559354203528		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.011228559354203528 | validation: 0.012592133332706115]
	TIME [epoch: 53.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016622764489833818		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.016622764489833818 | validation: 0.01317945745655866]
	TIME [epoch: 53.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014245005068993868		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.014245005068993868 | validation: 0.00906745942433368]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1091.pth
	Model improved!!!
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011295277068258247		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.011295277068258247 | validation: 0.016683326596809513]
	TIME [epoch: 53.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015487750613222138		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.015487750613222138 | validation: 0.011823046644901084]
	TIME [epoch: 53.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010676656995616932		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.010676656995616932 | validation: 0.012134899277131034]
	TIME [epoch: 54.1 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01655396544553053		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.01655396544553053 | validation: 0.01609617651726255]
	TIME [epoch: 53.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01301048656775396		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.01301048656775396 | validation: 0.010892796144151205]
	TIME [epoch: 53.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011706687537568664		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.011706687537568664 | validation: 0.010301982425590508]
	TIME [epoch: 53.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013250022098804815		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.013250022098804815 | validation: 0.009953600106838628]
	TIME [epoch: 53.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012079955503149241		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.012079955503149241 | validation: 0.01202388505546425]
	TIME [epoch: 53.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016309900984854856		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.016309900984854856 | validation: 0.011278981319527467]
	TIME [epoch: 53.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011387687898815215		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.011387687898815215 | validation: 0.012834812100985526]
	TIME [epoch: 53.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016172836055346005		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.016172836055346005 | validation: 0.010914125461087502]
	TIME [epoch: 53.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014564659465427364		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.014564659465427364 | validation: 0.014405134757718381]
	TIME [epoch: 53.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011766232857171537		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.011766232857171537 | validation: 0.010653375147325398]
	TIME [epoch: 53.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013847764398390305		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.013847764398390305 | validation: 0.012862395411312021]
	TIME [epoch: 53.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013675765849369127		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.013675765849369127 | validation: 0.01179235594090017]
	TIME [epoch: 53.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01044945876942916		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.01044945876942916 | validation: 0.010493723634848526]
	TIME [epoch: 53.8 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002927994724883		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.017002927994724883 | validation: 0.009742999691032341]
	TIME [epoch: 53.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018692415856417025		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.018692415856417025 | validation: 0.010667696311613802]
	TIME [epoch: 54.1 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010000671614532082		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.010000671614532082 | validation: 0.008802458737732633]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1110.pth
	Model improved!!!
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011372155395583106		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.011372155395583106 | validation: 0.011261615790571944]
	TIME [epoch: 53.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013608534097571089		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.013608534097571089 | validation: 0.014440964499227962]
	TIME [epoch: 53.8 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013591334817807957		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.013591334817807957 | validation: 0.011759748011220837]
	TIME [epoch: 54 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011433384482326498		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.011433384482326498 | validation: 0.011473234873688882]
	TIME [epoch: 53.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015899368640906485		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.015899368640906485 | validation: 0.013183360225544548]
	TIME [epoch: 53.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01504071061638446		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.01504071061638446 | validation: 0.01102071124742111]
	TIME [epoch: 53.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01210051985976418		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.01210051985976418 | validation: 0.009674915356930068]
	TIME [epoch: 53.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013266834579261392		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.013266834579261392 | validation: 0.010881394035986898]
	TIME [epoch: 53.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013411102799461842		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.013411102799461842 | validation: 0.011951405015197005]
	TIME [epoch: 53.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011030825730039391		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.011030825730039391 | validation: 0.02093613051220224]
	TIME [epoch: 53.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01489421111859822		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.01489421111859822 | validation: 0.008462157317021194]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1121.pth
	Model improved!!!
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012328955456582254		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.012328955456582254 | validation: 0.024436814456802413]
	TIME [epoch: 53.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014718144112881741		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.014718144112881741 | validation: 0.010089884770380732]
	TIME [epoch: 53.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011506124518402936		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.011506124518402936 | validation: 0.00872650003938177]
	TIME [epoch: 54 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01182509685874984		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.01182509685874984 | validation: 0.01124362081644284]
	TIME [epoch: 53.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011997880619779563		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.011997880619779563 | validation: 0.008625131481397109]
	TIME [epoch: 53.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013094709257868636		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.013094709257868636 | validation: 0.012003479908759964]
	TIME [epoch: 53.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014734485886722081		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.014734485886722081 | validation: 0.010757270565655142]
	TIME [epoch: 53.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010083593190859094		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.010083593190859094 | validation: 0.009065701356032744]
	TIME [epoch: 53.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011802809559204874		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.011802809559204874 | validation: 0.009965807566057456]
	TIME [epoch: 53.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011264603954324916		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.011264603954324916 | validation: 0.011037245240724379]
	TIME [epoch: 54.1 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01167475850355976		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.01167475850355976 | validation: 0.024118878224687244]
	TIME [epoch: 53.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014250094829665983		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.014250094829665983 | validation: 0.009822188113228596]
	TIME [epoch: 53.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01264673741307514		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.01264673741307514 | validation: 0.014817730801758435]
	TIME [epoch: 53.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012098622589033756		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.012098622589033756 | validation: 0.007318617579101017]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1135.pth
	Model improved!!!
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013199926117091549		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.013199926117091549 | validation: 0.014284094767248057]
	TIME [epoch: 53.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012842044266612639		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.012842044266612639 | validation: 0.01243811101725625]
	TIME [epoch: 53.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012088837440999152		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.012088837440999152 | validation: 0.011769012156546773]
	TIME [epoch: 53.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01597659724868816		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.01597659724868816 | validation: 0.008884762670398845]
	TIME [epoch: 53.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010372652431034919		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.010372652431034919 | validation: 0.0077344094854817635]
	TIME [epoch: 53.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010792680114168398		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.010792680114168398 | validation: 0.0102213223025268]
	TIME [epoch: 53.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011371953424963228		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.011371953424963228 | validation: 0.023533635164180427]
	TIME [epoch: 53.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012699849362962555		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.012699849362962555 | validation: 0.013846839436711725]
	TIME [epoch: 53.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015113177904879042		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.015113177904879042 | validation: 0.010361642631019581]
	TIME [epoch: 53.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010733990358107223		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.010733990358107223 | validation: 0.010842164606305292]
	TIME [epoch: 53.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010602929761416333		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.010602929761416333 | validation: 0.01716543321055599]
	TIME [epoch: 53.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011678149138302979		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.011678149138302979 | validation: 0.010528662356944211]
	TIME [epoch: 53.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016002529054036034		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.016002529054036034 | validation: 0.012515047599281603]
	TIME [epoch: 53.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011095558362781517		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.011095558362781517 | validation: 0.008591755189865062]
	TIME [epoch: 53.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012821721124538355		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.012821721124538355 | validation: 0.010113767545196398]
	TIME [epoch: 53.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009848416814566632		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.009848416814566632 | validation: 0.008244851568029822]
	TIME [epoch: 53.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01353097827456061		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.01353097827456061 | validation: 0.008133425488072825]
	TIME [epoch: 53.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010614989761088234		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.010614989761088234 | validation: 0.014597135864562693]
	TIME [epoch: 53.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01403460231491678		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.01403460231491678 | validation: 0.01585085087160082]
	TIME [epoch: 53.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011776493610285446		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.011776493610285446 | validation: 0.010274844152032371]
	TIME [epoch: 53.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011952366811278156		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.011952366811278156 | validation: 0.00876369126324221]
	TIME [epoch: 53.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009997665713397996		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.009997665713397996 | validation: 0.009697371453760187]
	TIME [epoch: 53.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010488371934250838		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.010488371934250838 | validation: 0.010256467046482674]
	TIME [epoch: 53.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013148950936546885		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.013148950936546885 | validation: 0.009605767582952552]
	TIME [epoch: 53.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01166784840286959		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.01166784840286959 | validation: 0.011248437662301138]
	TIME [epoch: 53.8 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012826734223748549		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.012826734223748549 | validation: 0.009309022257856396]
	TIME [epoch: 53.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010953265575950503		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.010953265575950503 | validation: 0.00967431577140419]
	TIME [epoch: 53.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012673846034253488		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.012673846034253488 | validation: 0.015819835466287055]
	TIME [epoch: 53.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011914182572038811		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.011914182572038811 | validation: 0.011788082893790438]
	TIME [epoch: 53.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010415158277061121		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.010415158277061121 | validation: 0.008972278344440619]
	TIME [epoch: 53.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010562075204875477		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.010562075204875477 | validation: 0.01201012707531767]
	TIME [epoch: 53.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010932200348506674		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.010932200348506674 | validation: 0.018867865170336742]
	TIME [epoch: 53.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013067729610958138		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.013067729610958138 | validation: 0.009848611686733219]
	TIME [epoch: 53.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01230338841412864		[learning rate: 0.00019004]
	Learning Rate: 0.000190041
	LOSS [training: 0.01230338841412864 | validation: 0.008988377194782564]
	TIME [epoch: 53.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00957795084822042		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.00957795084822042 | validation: 0.010400680294825593]
	TIME [epoch: 53.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012324845903367954		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.012324845903367954 | validation: 0.009249964310807712]
	TIME [epoch: 53.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009786396190405128		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.009786396190405128 | validation: 0.011220369426976441]
	TIME [epoch: 53.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013872901077076614		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.013872901077076614 | validation: 0.009306379905194263]
	TIME [epoch: 53.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012689417084221864		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.012689417084221864 | validation: 0.01043517811555887]
	TIME [epoch: 53.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009873050408300627		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.009873050408300627 | validation: 0.011377803392697027]
	TIME [epoch: 53.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010914765513365343		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.010914765513365343 | validation: 0.015982252515501227]
	TIME [epoch: 53.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01172100810127068		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.01172100810127068 | validation: 0.008506037955784796]
	TIME [epoch: 53.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010923629368707345		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.010923629368707345 | validation: 0.009791492555596863]
	TIME [epoch: 53.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011655575352734005		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.011655575352734005 | validation: 0.011544375374001728]
	TIME [epoch: 53.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011050555765922947		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.011050555765922947 | validation: 0.007753245561739947]
	TIME [epoch: 53.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010726098795556431		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.010726098795556431 | validation: 0.16380284521421623]
	TIME [epoch: 53.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04290475906221512		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.04290475906221512 | validation: 0.015998233578172934]
	TIME [epoch: 53.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011427214959131134		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.011427214959131134 | validation: 0.008690413985853108]
	TIME [epoch: 53.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009643443439747323		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.009643443439747323 | validation: 0.008429908018027968]
	TIME [epoch: 53.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00927816910660135		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.00927816910660135 | validation: 0.008879011811976718]
	TIME [epoch: 53.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009642870264496662		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.009642870264496662 | validation: 0.008216494179113524]
	TIME [epoch: 53.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011681125044985675		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.011681125044985675 | validation: 0.009128769444297892]
	TIME [epoch: 53.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009115849493284877		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.009115849493284877 | validation: 0.007810440306463289]
	TIME [epoch: 53.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011253350514627681		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.011253350514627681 | validation: 0.011142243875646569]
	TIME [epoch: 53.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011313618225488906		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.011313618225488906 | validation: 0.01012390344798128]
	TIME [epoch: 53.8 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010236239992077192		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.010236239992077192 | validation: 0.008240703937582108]
	TIME [epoch: 53.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010620595440823406		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.010620595440823406 | validation: 0.012776093430293546]
	TIME [epoch: 53.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01171547691988182		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.01171547691988182 | validation: 0.008993379897001223]
	TIME [epoch: 53.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010497852611466763		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.010497852611466763 | validation: 0.013076175849189176]
	TIME [epoch: 53.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012421272775105406		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.012421272775105406 | validation: 0.007855564563549114]
	TIME [epoch: 53.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009222102746142623		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.009222102746142623 | validation: 0.008435682926060617]
	TIME [epoch: 53.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009827242810142564		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.009827242810142564 | validation: 0.008247310052771148]
	TIME [epoch: 53.8 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010361624006398857		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.010361624006398857 | validation: 0.00847819564793707]
	TIME [epoch: 53.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009638605867838382		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.009638605867838382 | validation: 0.010916812970554642]
	TIME [epoch: 53.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011767188478961674		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.011767188478961674 | validation: 0.010687087339184956]
	TIME [epoch: 53.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01149099044931425		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.01149099044931425 | validation: 0.010997013152629142]
	TIME [epoch: 53.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010679680282380467		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.010679680282380467 | validation: 0.006399651585912649]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1202.pth
	Model improved!!!
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01250384055651046		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.01250384055651046 | validation: 0.0071475962801475015]
	TIME [epoch: 53.7 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009117188786203715		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.009117188786203715 | validation: 0.008573306300383486]
	TIME [epoch: 53.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012495171185150662		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.012495171185150662 | validation: 0.007630009991222259]
	TIME [epoch: 53.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009789377594001985		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.009789377594001985 | validation: 0.009535010121185752]
	TIME [epoch: 53.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011083407835428861		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.011083407835428861 | validation: 0.009866710065505368]
	TIME [epoch: 53.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008822436086547885		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.008822436086547885 | validation: 0.009627156752482281]
	TIME [epoch: 53.8 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010630809135542013		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.010630809135542013 | validation: 0.010974747193544701]
	TIME [epoch: 53.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011196770049900943		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.011196770049900943 | validation: 0.008891181780523885]
	TIME [epoch: 53.8 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009178775193906993		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.009178775193906993 | validation: 0.008356278251687065]
	TIME [epoch: 53.8 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010407530774778309		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.010407530774778309 | validation: 0.011463395088262761]
	TIME [epoch: 53.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010874004457893697		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.010874004457893697 | validation: 0.01779275746314362]
	TIME [epoch: 53.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013541648764174774		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.013541648764174774 | validation: 0.00936674094885182]
	TIME [epoch: 53.8 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008850845846838245		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.008850845846838245 | validation: 0.00685444753014759]
	TIME [epoch: 53.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009500008889425829		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.009500008889425829 | validation: 0.009175646137127862]
	TIME [epoch: 53.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012748233329232198		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.012748233329232198 | validation: 0.010985292005911473]
	TIME [epoch: 53.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010298702801775354		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.010298702801775354 | validation: 0.008619603085973461]
	TIME [epoch: 53.8 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010975580776784502		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.010975580776784502 | validation: 0.009842796820113959]
	TIME [epoch: 53.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00911577514395194		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.00911577514395194 | validation: 0.007416310143713443]
	TIME [epoch: 53.8 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010699256538706787		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.010699256538706787 | validation: 0.008228174766277581]
	TIME [epoch: 53.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010005958735777096		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.010005958735777096 | validation: 0.007108373165688804]
	TIME [epoch: 53.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010634326074808822		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.010634326074808822 | validation: 0.009243598146471011]
	TIME [epoch: 53.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009439395239926119		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.009439395239926119 | validation: 0.008407822895498651]
	TIME [epoch: 53.8 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00930301892409182		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.00930301892409182 | validation: 0.008456286693820153]
	TIME [epoch: 53.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010710516583465593		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.010710516583465593 | validation: 0.013230834746780173]
	TIME [epoch: 53.8 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010658886962969846		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.010658886962969846 | validation: 0.008190321991136604]
	TIME [epoch: 53.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009616697418329063		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.009616697418329063 | validation: 0.008981460366369962]
	TIME [epoch: 53.8 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011219144888340277		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.011219144888340277 | validation: 0.01008637295773357]
	TIME [epoch: 53.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00931728626397043		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.00931728626397043 | validation: 0.00973705275800704]
	TIME [epoch: 53.8 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010087879454732772		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.010087879454732772 | validation: 0.008512870014798304]
	TIME [epoch: 53.8 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009044838124437295		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.009044838124437295 | validation: 0.022388292514436352]
	TIME [epoch: 53.8 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011997610416724069		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.011997610416724069 | validation: 0.008557074296781389]
	TIME [epoch: 53.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008992940222840352		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.008992940222840352 | validation: 0.00967741667817657]
	TIME [epoch: 53.8 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010155169135402512		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.010155169135402512 | validation: 0.006847235464635332]
	TIME [epoch: 53.8 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009436255905534301		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.009436255905534301 | validation: 0.007858968774311968]
	TIME [epoch: 53.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01118632622673158		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.01118632622673158 | validation: 0.008972272297763192]
	TIME [epoch: 53.8 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00844739121522506		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.00844739121522506 | validation: 0.00909717868326613]
	TIME [epoch: 53.8 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00959497891331601		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.00959497891331601 | validation: 0.007361100687202171]
	TIME [epoch: 53.8 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009602853346504597		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.009602853346504597 | validation: 0.009060275962223814]
	TIME [epoch: 53.8 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011077391713694323		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.011077391713694323 | validation: 0.007559879693885021]
	TIME [epoch: 53.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00880159504730017		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.00880159504730017 | validation: 0.009993232957462957]
	TIME [epoch: 53.8 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009211017617037688		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.009211017617037688 | validation: 0.008075287454146683]
	TIME [epoch: 53.8 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010275473692757362		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.010275473692757362 | validation: 0.009903641283389294]
	TIME [epoch: 53.8 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00917322632628233		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.00917322632628233 | validation: 0.008697622722731755]
	TIME [epoch: 53.8 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010900668328758311		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.010900668328758311 | validation: 0.008203266955654348]
	TIME [epoch: 53.8 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008276767604791544		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.008276767604791544 | validation: 0.008343389622825924]
	TIME [epoch: 53.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009524477320297969		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.009524477320297969 | validation: 0.009139378239598029]
	TIME [epoch: 53.8 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0110479288029708		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.0110479288029708 | validation: 0.010303198548404354]
	TIME [epoch: 53.8 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010290929406909096		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.010290929406909096 | validation: 0.008231791600563709]
	TIME [epoch: 53.8 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008842690474997018		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.008842690474997018 | validation: 0.008534891986081147]
	TIME [epoch: 53.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008893006625538272		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.008893006625538272 | validation: 0.013025649638740614]
	TIME [epoch: 53.8 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011401794546204637		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.011401794546204637 | validation: 0.007846336559265596]
	TIME [epoch: 53.8 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008537571437056097		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.008537571437056097 | validation: 0.009476289410461424]
	TIME [epoch: 53.8 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0114222690951063		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.0114222690951063 | validation: 0.008306260837887842]
	TIME [epoch: 53.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008853748573059794		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.008853748573059794 | validation: 0.00882611875331368]
	TIME [epoch: 53.8 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00838660430358789		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.00838660430358789 | validation: 0.007963533024441007]
	TIME [epoch: 53.8 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00851950284886724		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.00851950284886724 | validation: 0.014040141215933923]
	TIME [epoch: 53.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010746023400243356		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.010746023400243356 | validation: 0.009579106771084502]
	TIME [epoch: 53.8 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010702926432212902		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.010702926432212902 | validation: 0.009568006579519214]
	TIME [epoch: 53.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008908677463604851		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.008908677463604851 | validation: 0.007042116393837095]
	TIME [epoch: 53.8 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008958452934430058		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.008958452934430058 | validation: 0.011533523670104032]
	TIME [epoch: 53.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013097219882600174		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.013097219882600174 | validation: 0.01786148149339006]
	TIME [epoch: 53.8 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011456171796369726		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.011456171796369726 | validation: 0.00796047228865664]
	TIME [epoch: 53.8 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008610103963749737		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.008610103963749737 | validation: 0.007002548037927604]
	TIME [epoch: 53.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008666229603746377		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.008666229603746377 | validation: 0.006016960784146916]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1266.pth
	Model improved!!!
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012012638500013864		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.012012638500013864 | validation: 0.009778816459135461]
	TIME [epoch: 53.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009498637012541654		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.009498637012541654 | validation: 0.009681305523587109]
	TIME [epoch: 53.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00890380048150696		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.00890380048150696 | validation: 0.006797219676831917]
	TIME [epoch: 53.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010163168520958527		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.010163168520958527 | validation: 0.009135695626688081]
	TIME [epoch: 53.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009366743732158407		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.009366743732158407 | validation: 0.006817209751322616]
	TIME [epoch: 53.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008190957174593515		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.008190957174593515 | validation: 0.007445461259233093]
	TIME [epoch: 53.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010692006801764544		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.010692006801764544 | validation: 0.01458436391952604]
	TIME [epoch: 53.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009513201981020097		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.009513201981020097 | validation: 0.007489664084646509]
	TIME [epoch: 53.8 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009690824363827122		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.009690824363827122 | validation: 0.007937932312224925]
	TIME [epoch: 53.8 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009235762106511728		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.009235762106511728 | validation: 0.008756467562762688]
	TIME [epoch: 53.8 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00946802894113462		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.00946802894113462 | validation: 0.009875220346453266]
	TIME [epoch: 53.8 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008503454113756893		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.008503454113756893 | validation: 0.007736417096142385]
	TIME [epoch: 53.8 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008722434449480345		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.008722434449480345 | validation: 0.007963804974612429]
	TIME [epoch: 53.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614057278627908		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.03614057278627908 | validation: 0.01813246096524189]
	TIME [epoch: 53.8 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012375196119825752		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.012375196119825752 | validation: 0.007701407348516391]
	TIME [epoch: 53.8 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008497054793177729		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.008497054793177729 | validation: 0.006861433437513565]
	TIME [epoch: 53.8 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007522207908974696		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.007522207908974696 | validation: 0.007221406722501449]
	TIME [epoch: 53.8 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007881941945342417		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.007881941945342417 | validation: 0.00790157292209754]
	TIME [epoch: 53.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008338277577893148		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.008338277577893148 | validation: 0.008176772895286632]
	TIME [epoch: 53.8 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00870499228066439		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.00870499228066439 | validation: 0.009699357872322293]
	TIME [epoch: 53.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011875735515789753		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.011875735515789753 | validation: 0.008298504285086833]
	TIME [epoch: 53.8 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010069764101166062		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.010069764101166062 | validation: 0.0073937681039027035]
	TIME [epoch: 53.8 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008563120264526396		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.008563120264526396 | validation: 0.0069793457855157216]
	TIME [epoch: 53.8 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008313960573946297		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.008313960573946297 | validation: 0.007196367599717454]
	TIME [epoch: 53.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009403158759440446		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.009403158759440446 | validation: 0.006808670034242937]
	TIME [epoch: 53.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009379256686450298		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.009379256686450298 | validation: 0.007428423414625513]
	TIME [epoch: 53.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008560326387421154		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.008560326387421154 | validation: 0.0075325595380541285]
	TIME [epoch: 53.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008375268590127658		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.008375268590127658 | validation: 0.007117596896269762]
	TIME [epoch: 53.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009048760344062125		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.009048760344062125 | validation: 0.007534111901457509]
	TIME [epoch: 53.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009399294204847704		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.009399294204847704 | validation: 0.009335441059572638]
	TIME [epoch: 53.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009254433810864578		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.009254433810864578 | validation: 0.00773241673929425]
	TIME [epoch: 53.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009996604882996247		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.009996604882996247 | validation: 0.007940161412910988]
	TIME [epoch: 53.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009675561745083529		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.009675561745083529 | validation: 0.0069783692153374205]
	TIME [epoch: 53.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008199117134742197		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.008199117134742197 | validation: 0.006905838935070387]
	TIME [epoch: 53.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008469189943698996		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.008469189943698996 | validation: 0.009973857306189424]
	TIME [epoch: 53.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01143025462467632		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.01143025462467632 | validation: 0.008529814829062569]
	TIME [epoch: 53.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008393472412413287		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.008393472412413287 | validation: 0.007598341797951003]
	TIME [epoch: 53.8 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00792165094745216		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.00792165094745216 | validation: 0.006138494405282063]
	TIME [epoch: 53.8 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009175012241643105		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.009175012241643105 | validation: 0.006993196020375011]
	TIME [epoch: 53.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008355932509401687		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.008355932509401687 | validation: 0.006216353479433515]
	TIME [epoch: 53.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00981899427447115		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.00981899427447115 | validation: 0.007977126650016972]
	TIME [epoch: 53.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008748495737604504		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.008748495737604504 | validation: 0.01213619887886417]
	TIME [epoch: 53.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009679628209507983		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.009679628209507983 | validation: 0.007516045782151104]
	TIME [epoch: 53.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00791759078405958		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.00791759078405958 | validation: 0.009674296739938418]
	TIME [epoch: 53.8 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009565866695663252		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.009565866695663252 | validation: 0.006629943533463557]
	TIME [epoch: 53.8 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008983917149351796		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.008983917149351796 | validation: 0.006514064707619402]
	TIME [epoch: 53.8 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00867931620174043		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.00867931620174043 | validation: 0.0071965518506726285]
	TIME [epoch: 53.8 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008093070837798056		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.008093070837798056 | validation: 0.007811202491815103]
	TIME [epoch: 53.8 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009132681822110347		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.009132681822110347 | validation: 0.010045086588525636]
	TIME [epoch: 53.8 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007977219152245365		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.007977219152245365 | validation: 0.009324651833817504]
	TIME [epoch: 53.7 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010587464964015858		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.010587464964015858 | validation: 0.008322924445631943]
	TIME [epoch: 53.8 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009656580606687054		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.009656580606687054 | validation: 0.010504974958252429]
	TIME [epoch: 53.7 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00901070194843492		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.00901070194843492 | validation: 0.007141320662293126]
	TIME [epoch: 53.7 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010174396022618456		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.010174396022618456 | validation: 0.008028322482955617]
	TIME [epoch: 53.8 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007591734292275798		[learning rate: 0.00011092]
	Learning Rate: 0.000110917
	LOSS [training: 0.007591734292275798 | validation: 0.007648464240468014]
	TIME [epoch: 53.8 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02214909714261986		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.02214909714261986 | validation: 0.017950772565383973]
	TIME [epoch: 53.7 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011925074413008116		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.011925074413008116 | validation: 0.007553115440987459]
	TIME [epoch: 53.7 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00805740198038546		[learning rate: 0.00010974]
	Learning Rate: 0.000109745
	LOSS [training: 0.00805740198038546 | validation: 0.007509288945421534]
	TIME [epoch: 53.7 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007649081164427625		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.007649081164427625 | validation: 0.006971659868123051]
	TIME [epoch: 53.8 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008133303435173295		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.008133303435173295 | validation: 0.006589644935399809]
	TIME [epoch: 53.7 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076755106356176505		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.0076755106356176505 | validation: 0.007171356753130825]
	TIME [epoch: 53.8 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0087322801060309		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.0087322801060309 | validation: 0.009550848408752588]
	TIME [epoch: 53.8 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009057080595471148		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.009057080595471148 | validation: 0.006785280292904625]
	TIME [epoch: 53.7 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007892792600718193		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.007892792600718193 | validation: 0.009147519278387709]
	TIME [epoch: 53.8 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00847869949133691		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.00847869949133691 | validation: 0.006855185869042641]
	TIME [epoch: 53.8 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009717149211813342		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.009717149211813342 | validation: 0.006750197568744356]
	TIME [epoch: 53.7 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008270781216286197		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.008270781216286197 | validation: 0.008149471873209024]
	TIME [epoch: 53.8 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009392233314868211		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.009392233314868211 | validation: 0.007882963303542545]
	TIME [epoch: 53.8 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008082850778380658		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.008082850778380658 | validation: 0.007024682240344437]
	TIME [epoch: 53.8 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008170580217218226		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.008170580217218226 | validation: 0.007534767448616345]
	TIME [epoch: 53.8 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008743348609144164		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.008743348609144164 | validation: 0.0072771156317051715]
	TIME [epoch: 53.8 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008598408506726312		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.008598408506726312 | validation: 0.008581802892754028]
	TIME [epoch: 53.8 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00833632026671257		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.00833632026671257 | validation: 0.008074213663867498]
	TIME [epoch: 53.8 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008227005870001226		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.008227005870001226 | validation: 0.007998663678407177]
	TIME [epoch: 53.8 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009345429848652595		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.009345429848652595 | validation: 0.0062942083858260126]
	TIME [epoch: 53.7 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00881445918602799		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.00881445918602799 | validation: 0.006922066180763865]
	TIME [epoch: 53.7 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00905685348039521		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.00905685348039521 | validation: 0.0069406272118340655]
	TIME [epoch: 53.7 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008241998281454168		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.008241998281454168 | validation: 0.006500166774127889]
	TIME [epoch: 53.8 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008594487195291073		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.008594487195291073 | validation: 0.008468169991082106]
	TIME [epoch: 53.8 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007701258177000642		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.007701258177000642 | validation: 0.006560766491436715]
	TIME [epoch: 53.7 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008829816127524474		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.008829816127524474 | validation: 0.006660213196098608]
	TIME [epoch: 53.7 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008337404416563266		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.008337404416563266 | validation: 0.007589478416827799]
	TIME [epoch: 53.8 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008308391544064184		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.008308391544064184 | validation: 0.009098756898608744]
	TIME [epoch: 53.7 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010864512456037326		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.010864512456037326 | validation: 0.007609745237885485]
	TIME [epoch: 53.8 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008166507244836932		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.008166507244836932 | validation: 0.0073569140376136995]
	TIME [epoch: 53.7 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007742301548785626		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.007742301548785626 | validation: 0.006265490519355512]
	TIME [epoch: 53.7 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007485862056844227		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.007485862056844227 | validation: 0.007542725080729875]
	TIME [epoch: 53.7 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008532973036748588		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.008532973036748588 | validation: 0.011706807942143394]
	TIME [epoch: 53.7 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00896040986161992		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.00896040986161992 | validation: 0.007807016905589914]
	TIME [epoch: 53.7 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007864434486493755		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.007864434486493755 | validation: 0.006893790087494094]
	TIME [epoch: 53.7 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008232436950451463		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.008232436950451463 | validation: 0.007649780614381257]
	TIME [epoch: 53.7 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008078032923659387		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.008078032923659387 | validation: 0.006522733208253065]
	TIME [epoch: 53.7 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007942099828258145		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.007942099828258145 | validation: 0.006659058539415567]
	TIME [epoch: 53.7 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009519549696031172		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.009519549696031172 | validation: 0.01582448408352538]
	TIME [epoch: 53.7 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011402126892409237		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.011402126892409237 | validation: 0.006669110303970632]
	TIME [epoch: 53.7 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009427465344242495		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.009427465344242495 | validation: 0.008317271452666745]
	TIME [epoch: 53.7 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00821899976134222		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.00821899976134222 | validation: 0.008289617626259398]
	TIME [epoch: 53.7 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008212158051259832		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.008212158051259832 | validation: 0.007911554677036626]
	TIME [epoch: 53.7 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008216832831727855		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.008216832831727855 | validation: 0.005975124335859613]
	TIME [epoch: 53.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v2r_2_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v2r_2_v_mmd1_1365.pth
	Model improved!!!
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008126097962486917		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.008126097962486917 | validation: 0.0067935640884316745]
	TIME [epoch: 53.7 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010048598433887062		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.010048598433887062 | validation: 0.0071331533609431345]
	TIME [epoch: 53.7 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008722137175176985		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.008722137175176985 | validation: 0.007335125481742101]
	TIME [epoch: 53.7 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007818420143090997		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.007818420143090997 | validation: 0.008771637712812693]
	TIME [epoch: 53.8 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008155285611643992		[learning rate: 9.3243e-05]
	Learning Rate: 9.32429e-05
	LOSS [training: 0.008155285611643992 | validation: 0.006881260497792016]
	TIME [epoch: 53.7 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076947753765519555		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.0076947753765519555 | validation: 0.010094302890206554]
	TIME [epoch: 53.7 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007785422011301211		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.007785422011301211 | validation: 0.007046663338664985]
	TIME [epoch: 53.7 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0077566468681153		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.0077566468681153 | validation: 0.011048974257076362]
	TIME [epoch: 53.7 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008442418228104279		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.008442418228104279 | validation: 0.0069959533867064525]
	TIME [epoch: 53.8 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00859151092846087		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.00859151092846087 | validation: 0.008104246610815392]
	TIME [epoch: 53.7 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008451308775786166		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.008451308775786166 | validation: 0.00702334804445099]
	TIME [epoch: 53.7 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008072294660964199		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.008072294660964199 | validation: 0.007293193308279335]
	TIME [epoch: 53.7 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007500164137815731		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.007500164137815731 | validation: 0.006862090382256936]
	TIME [epoch: 53.7 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007709777198865985		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.007709777198865985 | validation: 0.006836090370558812]
	TIME [epoch: 53.7 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010186940988095802		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.010186940988095802 | validation: 0.006593198979611181]
	TIME [epoch: 53.7 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007720783693232749		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.007720783693232749 | validation: 0.008977855265178792]
	TIME [epoch: 53.7 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007215750588477013		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.007215750588477013 | validation: 0.006746005731424274]
	TIME [epoch: 53.7 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007750259063399098		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.007750259063399098 | validation: 0.006742342368625968]
	TIME [epoch: 53.7 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008877606449489737		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.008877606449489737 | validation: 0.006224723728941451]
	TIME [epoch: 53.7 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007976276155130555		[learning rate: 8.8418e-05]
	Learning Rate: 8.84176e-05
	LOSS [training: 0.007976276155130555 | validation: 0.009515379376315327]
	TIME [epoch: 53.7 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007823898319841276		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.007823898319841276 | validation: 0.01222092306898643]
	TIME [epoch: 53.7 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009681878058190346		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.009681878058190346 | validation: 0.006270792709332892]
	TIME [epoch: 53.7 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007567897971652505		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.007567897971652505 | validation: 0.007090164275543269]
	TIME [epoch: 53.7 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007654738758217658		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.007654738758217658 | validation: 0.006090187941409895]
	TIME [epoch: 53.7 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007826981755051022		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.007826981755051022 | validation: 0.0061675880503867095]
	TIME [epoch: 53.7 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007842056807276659		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.007842056807276659 | validation: 0.00917482504534883]
	TIME [epoch: 53.7 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008127127734463477		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.008127127734463477 | validation: 0.008222681217109432]
	TIME [epoch: 53.7 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008016938061592002		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.008016938061592002 | validation: 0.010347442031754441]
	TIME [epoch: 53.7 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076662988096876045		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.0076662988096876045 | validation: 0.006833503308551028]
	TIME [epoch: 53.7 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007534538890234905		[learning rate: 8.534e-05]
	Learning Rate: 8.53403e-05
	LOSS [training: 0.007534538890234905 | validation: 0.007379530683883565]
	TIME [epoch: 53.7 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008413514675807492		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.008413514675807492 | validation: 0.006479222636714555]
	TIME [epoch: 53.7 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007643860261022677		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.007643860261022677 | validation: 0.006306046994509763]
	TIME [epoch: 53.7 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007739175888329727		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.007739175888329727 | validation: 0.00636963183070814]
	TIME [epoch: 53.8 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007202715725896808		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.007202715725896808 | validation: 0.006901421427297707]
	TIME [epoch: 53.6 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008032835732258213		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.008032835732258213 | validation: 0.011720760268486534]
	TIME [epoch: 53.7 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009025729293098524		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.009025729293098524 | validation: 0.007633390760175021]
	TIME [epoch: 53.8 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00772620350536792		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.00772620350536792 | validation: 0.009115740487063949]
	TIME [epoch: 53.7 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007752451732241504		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.007752451732241504 | validation: 0.006136813540603458]
	TIME [epoch: 53.7 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008078929323206934		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.008078929323206934 | validation: 0.0069796546379098405]
	TIME [epoch: 53.7 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007555928509603833		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.007555928509603833 | validation: 0.007306729908426575]
	TIME [epoch: 53.8 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007386788452842326		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.007386788452842326 | validation: 0.0069510007215390825]
	TIME [epoch: 53.7 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008114359006500049		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.008114359006500049 | validation: 0.00810021394138664]
	TIME [epoch: 53.7 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00860071070324088		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.00860071070324088 | validation: 0.006570228537997635]
	TIME [epoch: 53.7 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007826448959901845		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.007826448959901845 | validation: 0.006498518142223967]
	TIME [epoch: 53.8 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008412614464711081		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.008412614464711081 | validation: 0.008700111332256396]
	TIME [epoch: 53.7 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007353809257022949		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.007353809257022949 | validation: 0.007167739052492925]
	TIME [epoch: 53.7 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008183514128688155		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.008183514128688155 | validation: 0.007281720171616056]
	TIME [epoch: 53.7 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007248491261348788		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.007248491261348788 | validation: 0.007556211048027172]
	TIME [epoch: 53.6 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007649447132499898		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.007649447132499898 | validation: 0.007081171442838267]
	TIME [epoch: 53.7 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007834386002038831		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.007834386002038831 | validation: 0.006335439242210181]
	TIME [epoch: 53.7 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008082942503458642		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.008082942503458642 | validation: 0.008159544450347193]
	TIME [epoch: 53.7 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076244706093913355		[learning rate: 7.8942e-05]
	Learning Rate: 7.89419e-05
	LOSS [training: 0.0076244706093913355 | validation: 0.006820556575666091]
	TIME [epoch: 53.7 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007438172600174165		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.007438172600174165 | validation: 0.0068017224152048545]
	TIME [epoch: 53.7 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00869053680400243		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.00869053680400243 | validation: 0.00738983066309609]
	TIME [epoch: 53.7 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007359497539086851		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.007359497539086851 | validation: 0.007212781408826729]
	TIME [epoch: 53.7 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007191885987779194		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.007191885987779194 | validation: 0.009012309344836192]
	TIME [epoch: 53.7 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009074790637434863		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.009074790637434863 | validation: 0.008469632366744702]
	TIME [epoch: 53.7 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00887712186267258		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.00887712186267258 | validation: 0.0068615912951664896]
	TIME [epoch: 53.7 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0076541942600793925		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.0076541942600793925 | validation: 0.006819604531530885]
	TIME [epoch: 53.7 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007231324145633113		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.007231324145633113 | validation: 0.007202239924548435]
	TIME [epoch: 53.7 sec]
EPOCH 1426/2000:
	Training over batches...
