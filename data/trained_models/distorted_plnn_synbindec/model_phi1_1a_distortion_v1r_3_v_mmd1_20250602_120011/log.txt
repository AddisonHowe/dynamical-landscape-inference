Args:
Namespace(name='model_phi1_1a_distortion_v1r_3_v_mmd1', outdir='out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1', training_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v1r_3/training', validation_data='data/training_data/distortions/paraboloids/data_phi1_1a_distortion_v1r_3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.060471818, 0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3133609540

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.8324911570224165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8324911570224165 | validation: 5.959281008068105]
	TIME [epoch: 373 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.153244978864881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153244978864881 | validation: 5.543187979371306]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.360957616124781		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.360957616124781 | validation: 5.040018807060564]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.880255354478453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.880255354478453 | validation: 4.794673281642113]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.511897540600087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.511897540600087 | validation: 3.7455892022340236]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.082109729490619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.082109729490619 | validation: 3.5518431649683033]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.673987732400733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.673987732400733 | validation: 3.5068781933023714]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5542079869219867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5542079869219867 | validation: 3.6445189794249764]
	TIME [epoch: 5.94 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5704235239873707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5704235239873707 | validation: 3.5725236452963554]
	TIME [epoch: 5.95 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5286472601617236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5286472601617236 | validation: 3.522894641817291]
	TIME [epoch: 5.95 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5051752780876266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5051752780876266 | validation: 3.4742295565392585]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4591789572988496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4591789572988496 | validation: 3.49298601833062]
	TIME [epoch: 5.95 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4516269223230256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4516269223230256 | validation: 3.4987121451748315]
	TIME [epoch: 5.94 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4469309567674618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4469309567674618 | validation: 3.457253180137278]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.432851544728044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.432851544728044 | validation: 3.581519170920396]
	TIME [epoch: 6.19 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4772793045147776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4772793045147776 | validation: 3.47905699715798]
	TIME [epoch: 5.94 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.410311297788937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.410311297788937 | validation: 3.4410846900038257]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39154478126938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.39154478126938 | validation: 3.3912081277933446]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3676894453696695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3676894453696695 | validation: 3.369377546854264]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.355933979453574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.355933979453574 | validation: 3.382805456625341]
	TIME [epoch: 5.96 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4171311616806603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4171311616806603 | validation: 3.3465537317330076]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.355161272273306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.355161272273306 | validation: 3.3709921210881553]
	TIME [epoch: 5.94 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3288656795427745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3288656795427745 | validation: 3.3296542724083076]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.307842462946976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.307842462946976 | validation: 3.3228027056869376]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3166027293479337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3166027293479337 | validation: 3.3786172092919085]
	TIME [epoch: 5.95 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.31668395954501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.31668395954501 | validation: 3.312353574643101]
	TIME [epoch: 6.35 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2832462918721332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2832462918721332 | validation: 3.3026201170953255]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302921734903591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.302921734903591 | validation: 3.3341687996466014]
	TIME [epoch: 5.95 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2886379476949297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2886379476949297 | validation: 3.2799412152791274]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.267954663977111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.267954663977111 | validation: 3.268816055603514]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2493392472605676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2493392472605676 | validation: 3.2910660576042887]
	TIME [epoch: 5.94 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.284713078231466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.284713078231466 | validation: 3.2663500739013727]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2329231481440246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2329231481440246 | validation: 3.2475271879059404]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221547816350364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.221547816350364 | validation: 3.2493245157487625]
	TIME [epoch: 5.94 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2577283961300485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2577283961300485 | validation: 3.2440068846465517]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2094635040398845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2094635040398845 | validation: 3.2197996544615366]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.194171493228846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.194171493228846 | validation: 3.2074315908700317]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2355053847970123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2355053847970123 | validation: 3.1856857033144625]
	TIME [epoch: 5.93 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1611667050623358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1611667050623358 | validation: 3.1734556643396963]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1324607066148893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1324607066148893 | validation: 3.185953875342972]
	TIME [epoch: 5.94 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2637971547551325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2637971547551325 | validation: 3.14106084866931]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.108742825208372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.108742825208372 | validation: 3.109614037151702]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1101529475970735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1101529475970735 | validation: 3.1207416586779013]
	TIME [epoch: 5.94 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0260438869878463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0260438869878463 | validation: 3.083219379698077]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.937355393758605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.937355393758605 | validation: 3.5613959151285224]
	TIME [epoch: 6.18 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3314741033381097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3314741033381097 | validation: 3.224908288722016]
	TIME [epoch: 5.96 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.160626668083543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.160626668083543 | validation: 3.15604471147485]
	TIME [epoch: 5.94 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0851500138055523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0851500138055523 | validation: 3.083942119876093]
	TIME [epoch: 5.94 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.042381225517727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.042381225517727 | validation: 3.0496995272840115]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.122861068357565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.122861068357565 | validation: 3.5617313921100084]
	TIME [epoch: 5.95 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0199115601738966		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.0199115601738966 | validation: 4.046960663094045]
	TIME [epoch: 5.95 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677661297899613		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.6677661297899613 | validation: 2.620117214955547]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8765821208134614		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 1.8765821208134614 | validation: 2.51981147178208]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9454914325578532		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.9454914325578532 | validation: 2.5387144849471146]
	TIME [epoch: 5.95 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8053548818932221		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 1.8053548818932221 | validation: 2.496461685342978]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7788011614549304		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 1.7788011614549304 | validation: 3.05371428741785]
	TIME [epoch: 5.95 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.229001484065782		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.229001484065782 | validation: 2.628658229832139]
	TIME [epoch: 5.95 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8464789904043126		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.8464789904043126 | validation: 2.56158927355046]
	TIME [epoch: 5.94 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7442719032460492		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.7442719032460492 | validation: 2.4401517238639334]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6037010203799662		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.6037010203799662 | validation: 2.435938967531691]
	TIME [epoch: 5.96 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6867825308923348		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.6867825308923348 | validation: 3.502235416971894]
	TIME [epoch: 6.06 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9486286071755274		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.9486286071755274 | validation: 2.4790177390976886]
	TIME [epoch: 6.23 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6297057152545564		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.6297057152545564 | validation: 2.423374709745957]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6225272318896096		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.6225272318896096 | validation: 2.416884273145688]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5334001861998112		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.5334001861998112 | validation: 2.4553727695667757]
	TIME [epoch: 5.94 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.814732772099681		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 1.814732772099681 | validation: 2.428044986533533]
	TIME [epoch: 5.94 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5264671666345848		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.5264671666345848 | validation: 4.03697709579478]
	TIME [epoch: 5.93 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.067256222200379		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.067256222200379 | validation: 2.3960067493917414]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5462879860907655		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.5462879860907655 | validation: 3.051779737392547]
	TIME [epoch: 5.95 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9262319034371307		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.9262319034371307 | validation: 2.443319889488881]
	TIME [epoch: 5.95 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.480482060682555		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.480482060682555 | validation: 2.3611665883437967]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4760847467521307		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.4760847467521307 | validation: 2.5896603719991473]
	TIME [epoch: 5.95 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5994591096396542		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.5994591096396542 | validation: 2.435633402988471]
	TIME [epoch: 5.94 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.513282578491225		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.513282578491225 | validation: 2.5098851164820335]
	TIME [epoch: 5.94 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5789268122737337		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.5789268122737337 | validation: 2.4094111341618505]
	TIME [epoch: 5.93 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.500140891063833		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.500140891063833 | validation: 2.4264955290342325]
	TIME [epoch: 5.94 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5567503654189117		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.5567503654189117 | validation: 2.429592874219554]
	TIME [epoch: 5.93 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.582339011589844		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.582339011589844 | validation: 2.382997138099038]
	TIME [epoch: 5.93 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4525536993560328		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.4525536993560328 | validation: 2.4310918593037276]
	TIME [epoch: 5.94 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.492236796116537		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.492236796116537 | validation: 2.421803673335239]
	TIME [epoch: 5.94 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5475432431136515		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.5475432431136515 | validation: 2.46204621449588]
	TIME [epoch: 5.94 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4905918409056946		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.4905918409056946 | validation: 2.299686078653954]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5534569927665005		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.5534569927665005 | validation: 2.4277136292687898]
	TIME [epoch: 5.95 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9641039921292456		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9641039921292456 | validation: 3.0423339318267626]
	TIME [epoch: 5.94 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8185149050586897		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.8185149050586897 | validation: 2.3765739207043985]
	TIME [epoch: 5.94 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4265495293240356		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.4265495293240356 | validation: 2.332017915854395]
	TIME [epoch: 5.94 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3951547295685751		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.3951547295685751 | validation: 2.301735503719304]
	TIME [epoch: 5.94 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4494075578104333		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.4494075578104333 | validation: 2.273186550550938]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3660473793904853		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.3660473793904853 | validation: 2.337053538100757]
	TIME [epoch: 5.94 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3982977052260197		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.3982977052260197 | validation: 2.4843735417390675]
	TIME [epoch: 5.94 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4711683086582932		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.4711683086582932 | validation: 2.2752376192029287]
	TIME [epoch: 6.26 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4334567745691158		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.4334567745691158 | validation: 2.2094813714786583]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4676938538126336		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.4676938538126336 | validation: 2.276843185857049]
	TIME [epoch: 5.96 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3520262158803402		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.3520262158803402 | validation: 2.0696897954707554]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3841675376032208		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.3841675376032208 | validation: 2.0988329042237543]
	TIME [epoch: 5.95 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3757913539157829		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.3757913539157829 | validation: 1.9439795932740407]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2468834199725163		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.2468834199725163 | validation: 1.7999729175173287]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2498467294380142		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.2498467294380142 | validation: 1.1563662831304975]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4227886541003163		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.4227886541003163 | validation: 0.8923756914512937]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240265615128115		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.0240265615128115 | validation: 0.46596472474655193]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5083948807317167		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.5083948807317167 | validation: 0.4285068114159684]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39304589554765934		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.39304589554765934 | validation: 0.7662380295771918]
	TIME [epoch: 5.95 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6323690036966955		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.6323690036966955 | validation: 0.7939711732907889]
	TIME [epoch: 5.94 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509571563146067		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.509571563146067 | validation: 0.32202664835127925]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3263081000026191		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.3263081000026191 | validation: 0.41896608784319256]
	TIME [epoch: 5.96 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3004818066229555		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.3004818066229555 | validation: 0.2882463862401252]
	TIME [epoch: 6.4 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29836180457741107		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.29836180457741107 | validation: 0.5114970808872088]
	TIME [epoch: 5.95 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34942561468841427		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.34942561468841427 | validation: 0.31902184368048764]
	TIME [epoch: 5.94 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713588436614323		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.2713588436614323 | validation: 0.2838667689580291]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37055009427181		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.37055009427181 | validation: 0.32306817481043737]
	TIME [epoch: 5.96 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28020803269808003		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.28020803269808003 | validation: 0.7357390367341214]
	TIME [epoch: 5.94 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49820983680578823		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.49820983680578823 | validation: 0.2060181242376937]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595872887091756		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.2595872887091756 | validation: 0.2459217380848699]
	TIME [epoch: 6.15 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973085592604586		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.2973085592604586 | validation: 0.3692446366764348]
	TIME [epoch: 5.95 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308302711996827		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.308302711996827 | validation: 0.2907289076078793]
	TIME [epoch: 5.94 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23439811077203454		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.23439811077203454 | validation: 0.2549218694465349]
	TIME [epoch: 5.94 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21158806901120725		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.21158806901120725 | validation: 0.2844576996375591]
	TIME [epoch: 5.96 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27126485373793147		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.27126485373793147 | validation: 0.40548315326034123]
	TIME [epoch: 5.94 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22810625923626754		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.22810625923626754 | validation: 0.31224342540813566]
	TIME [epoch: 5.95 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24505741395244038		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.24505741395244038 | validation: 0.21811893011395656]
	TIME [epoch: 5.94 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2995076926658473		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.2995076926658473 | validation: 0.3669492762620062]
	TIME [epoch: 6.26 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34734928947097166		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.34734928947097166 | validation: 0.38559399267273686]
	TIME [epoch: 5.96 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23973914406511804		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.23973914406511804 | validation: 0.16892339068717044]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32810197365501864		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.32810197365501864 | validation: 0.5766039874210259]
	TIME [epoch: 5.95 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375970019052058		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.375970019052058 | validation: 0.17925731300411685]
	TIME [epoch: 5.96 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16323877354416869		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.16323877354416869 | validation: 0.23041384060190007]
	TIME [epoch: 5.95 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27853408195476526		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.27853408195476526 | validation: 0.3196302449771109]
	TIME [epoch: 5.96 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783919158608032		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.2783919158608032 | validation: 0.21372265408101804]
	TIME [epoch: 5.96 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059281387303997		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.2059281387303997 | validation: 0.16493018160917866]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17777326934455104		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.17777326934455104 | validation: 0.22718318499680495]
	TIME [epoch: 5.94 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22281395214533709		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.22281395214533709 | validation: 0.12544916792691732]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16407592939997315		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.16407592939997315 | validation: 0.29613327287781993]
	TIME [epoch: 5.95 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4685255649380647		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.4685255649380647 | validation: 0.25053530152739595]
	TIME [epoch: 6.16 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538995966089566		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.2538995966089566 | validation: 0.20986632903587973]
	TIME [epoch: 5.94 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683115440511504		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.1683115440511504 | validation: 0.14603372702003176]
	TIME [epoch: 5.95 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16672769395453246		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.16672769395453246 | validation: 0.26903860824913195]
	TIME [epoch: 5.95 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22582721097889885		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.22582721097889885 | validation: 0.37619482937745197]
	TIME [epoch: 5.96 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509272071613225		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 0.2509272071613225 | validation: 0.5626624743928901]
	TIME [epoch: 6.14 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3015404318178437		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3015404318178437 | validation: 0.15230060118343125]
	TIME [epoch: 5.95 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20895430333808487		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.20895430333808487 | validation: 0.2621696262766091]
	TIME [epoch: 5.95 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19111228095509264		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.19111228095509264 | validation: 0.15692205187186886]
	TIME [epoch: 5.95 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23346252920489802		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.23346252920489802 | validation: 0.1758657498235939]
	TIME [epoch: 6.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15412904159153723		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.15412904159153723 | validation: 0.19886208202825673]
	TIME [epoch: 5.95 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23338282807796543		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.23338282807796543 | validation: 0.21406431770410347]
	TIME [epoch: 5.95 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17105797903173775		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.17105797903173775 | validation: 0.15367301333539618]
	TIME [epoch: 5.95 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20000768372708577		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.20000768372708577 | validation: 0.23769881693263328]
	TIME [epoch: 5.96 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22167527723964195		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.22167527723964195 | validation: 0.14787835734394755]
	TIME [epoch: 6.24 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14211915946902062		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.14211915946902062 | validation: 0.16248734040882706]
	TIME [epoch: 6.08 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18633913838491267		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.18633913838491267 | validation: 0.11902639325495452]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14912845159063245		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.14912845159063245 | validation: 0.13907664074950235]
	TIME [epoch: 5.94 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19675004206328014		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.19675004206328014 | validation: 0.19252039827765222]
	TIME [epoch: 5.95 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20421109130121495		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.20421109130121495 | validation: 0.22825171286354098]
	TIME [epoch: 6.15 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958057157323155		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.1958057157323155 | validation: 0.22356099635076615]
	TIME [epoch: 5.95 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.174768549434438		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.174768549434438 | validation: 0.12373041084275319]
	TIME [epoch: 5.95 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17656337600264185		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.17656337600264185 | validation: 0.1998843109010152]
	TIME [epoch: 5.95 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18088380624697786		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.18088380624697786 | validation: 0.2915243665963031]
	TIME [epoch: 5.94 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14638184177861305		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.14638184177861305 | validation: 0.13782598133562415]
	TIME [epoch: 5.95 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17312355939313906		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.17312355939313906 | validation: 0.11763461300207853]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_158.pth
	Model improved!!!
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.133516305065648		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.133516305065648 | validation: 0.3216695176732485]
	TIME [epoch: 5.95 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3272336406017177		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.3272336406017177 | validation: 0.27610466711719994]
	TIME [epoch: 5.95 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18175670754105439		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 0.18175670754105439 | validation: 0.27653283667705597]
	TIME [epoch: 5.95 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20397758259346072		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.20397758259346072 | validation: 0.1771987560825946]
	TIME [epoch: 5.94 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588831813702471		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.1588831813702471 | validation: 0.15028820665444187]
	TIME [epoch: 5.94 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12466249624181439		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.12466249624181439 | validation: 0.13982354836776278]
	TIME [epoch: 5.95 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901872544419412		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.14901872544419412 | validation: 0.18498262329214857]
	TIME [epoch: 5.95 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21314105662618338		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.21314105662618338 | validation: 0.3184247155723334]
	TIME [epoch: 5.94 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444908141847396		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.3444908141847396 | validation: 0.37355556062091766]
	TIME [epoch: 5.95 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25787445193820185		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.25787445193820185 | validation: 0.22155503753618322]
	TIME [epoch: 5.94 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620152020846284		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.1620152020846284 | validation: 0.18963136394800495]
	TIME [epoch: 5.95 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14545259175689743		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.14545259175689743 | validation: 0.1844515216876985]
	TIME [epoch: 5.94 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16439260378265752		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.16439260378265752 | validation: 0.24073341073630772]
	TIME [epoch: 5.94 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1790146441984093		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.1790146441984093 | validation: 0.20168334263719745]
	TIME [epoch: 5.95 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20360823381374024		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.20360823381374024 | validation: 0.14448165184404382]
	TIME [epoch: 5.95 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10602031642497668		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.10602031642497668 | validation: 0.12027392897642458]
	TIME [epoch: 5.95 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14465351377140703		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.14465351377140703 | validation: 0.2552679164985622]
	TIME [epoch: 5.94 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22531381530461297		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 0.22531381530461297 | validation: 0.15113243165296336]
	TIME [epoch: 5.95 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11727154973091083		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.11727154973091083 | validation: 0.11523739697183634]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22449037925085663		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.22449037925085663 | validation: 0.27021745725155877]
	TIME [epoch: 5.94 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1474880562129821		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.1474880562129821 | validation: 0.23000852001388705]
	TIME [epoch: 5.95 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15915788280739046		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.15915788280739046 | validation: 0.43536963494273917]
	TIME [epoch: 5.95 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2974254591497058		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.2974254591497058 | validation: 0.18202740120817917]
	TIME [epoch: 5.97 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.999588811991109		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.999588811991109 | validation: 0.42883181840350254]
	TIME [epoch: 5.95 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31936799881446837		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.31936799881446837 | validation: 0.1125224110181213]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13999313539166036		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.13999313539166036 | validation: 0.1360585527348408]
	TIME [epoch: 5.94 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089717181782858		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.4089717181782858 | validation: 0.279483060084586]
	TIME [epoch: 5.96 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1834711692583165		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.1834711692583165 | validation: 0.14860596291559322]
	TIME [epoch: 5.98 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081225174451554		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.12081225174451554 | validation: 0.1062376331100754]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11267274748593394		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.11267274748593394 | validation: 0.1448383092821938]
	TIME [epoch: 5.95 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1033573412090515		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.1033573412090515 | validation: 0.11907087829787433]
	TIME [epoch: 5.96 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12590071790736834		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.12590071790736834 | validation: 0.2968276571673703]
	TIME [epoch: 5.96 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22250520071927557		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.22250520071927557 | validation: 0.14918837748506344]
	TIME [epoch: 5.95 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.120879049198889		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.120879049198889 | validation: 0.09924558433798006]
	TIME [epoch: 5.94 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1394182048994465		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.1394182048994465 | validation: 1.0349340646646812]
	TIME [epoch: 5.94 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3673195877022154		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.3673195877022154 | validation: 0.09482354049478378]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14068771944219774		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.14068771944219774 | validation: 0.14457610835057735]
	TIME [epoch: 5.97 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713555741343913		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.1713555741343913 | validation: 0.2170988615237458]
	TIME [epoch: 5.95 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14916342772475555		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.14916342772475555 | validation: 0.2617326398756685]
	TIME [epoch: 5.95 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16025201475540626		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.16025201475540626 | validation: 0.15761580007454928]
	TIME [epoch: 6.13 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11260255447725633		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.11260255447725633 | validation: 0.09586897786657245]
	TIME [epoch: 5.95 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10551333781204156		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.10551333781204156 | validation: 0.1681886804023702]
	TIME [epoch: 5.94 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901363836507064		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.14901363836507064 | validation: 0.11304713025992066]
	TIME [epoch: 386 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16891729457365862		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.16891729457365862 | validation: 0.15767873733608195]
	TIME [epoch: 11.8 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10838390880530693		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.10838390880530693 | validation: 0.13348751670017794]
	TIME [epoch: 11.7 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11262142274821269		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.11262142274821269 | validation: 0.2420402332392219]
	TIME [epoch: 11.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585787550027294		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.1585787550027294 | validation: 0.3320419348549411]
	TIME [epoch: 11.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2054448126382822		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.2054448126382822 | validation: 0.19755536636667687]
	TIME [epoch: 11.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12589618740326353		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.12589618740326353 | validation: 0.12473658496705478]
	TIME [epoch: 11.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617811711007039		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.1617811711007039 | validation: 0.18852771951913933]
	TIME [epoch: 11.7 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14889805240324577		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.14889805240324577 | validation: 0.08881104645355345]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11773444315958967		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.11773444315958967 | validation: 0.13248646657573993]
	TIME [epoch: 11.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08326831874359872		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.08326831874359872 | validation: 0.1235364558956634]
	TIME [epoch: 11.7 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17009934345630162		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.17009934345630162 | validation: 0.29556054354014216]
	TIME [epoch: 11.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581414400924579		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.2581414400924579 | validation: 0.13761440873423444]
	TIME [epoch: 11.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740447289425194		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.12740447289425194 | validation: 0.08976596728057308]
	TIME [epoch: 11.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1312133836891993		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.1312133836891993 | validation: 0.12972363133064108]
	TIME [epoch: 11.7 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14062631563357467		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.14062631563357467 | validation: 0.10414371623647908]
	TIME [epoch: 11.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12435385320785297		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.12435385320785297 | validation: 0.13582263353639898]
	TIME [epoch: 11.7 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11207049833503115		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.11207049833503115 | validation: 0.136112187800646]
	TIME [epoch: 11.7 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11884054074518452		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.11884054074518452 | validation: 0.14398009861336025]
	TIME [epoch: 11.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168447608698823		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.11168447608698823 | validation: 0.12487074664968212]
	TIME [epoch: 11.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13680472399429425		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.13680472399429425 | validation: 0.20417992013311329]
	TIME [epoch: 11.7 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16613758519003935		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.16613758519003935 | validation: 0.12889224935318355]
	TIME [epoch: 11.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10757960111928579		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.10757960111928579 | validation: 0.07092409885934686]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07161002903021654		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.07161002903021654 | validation: 0.12168516431957176]
	TIME [epoch: 11.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14310801224752395		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.14310801224752395 | validation: 0.08780538263452664]
	TIME [epoch: 11.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1105399533906015		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.1105399533906015 | validation: 0.07630399361313911]
	TIME [epoch: 11.7 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925433811000475		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.09925433811000475 | validation: 0.21050271954142885]
	TIME [epoch: 11.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458117033342606		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.13458117033342606 | validation: 0.178442163776367]
	TIME [epoch: 11.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13859242212036252		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.13859242212036252 | validation: 0.12035399540219724]
	TIME [epoch: 11.7 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650380607372311		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.08650380607372311 | validation: 0.11284787648272226]
	TIME [epoch: 11.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11318625825061907		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.11318625825061907 | validation: 0.18285495111471145]
	TIME [epoch: 11.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12698692559425298		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.12698692559425298 | validation: 0.11028329806407802]
	TIME [epoch: 11.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855791272430064		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.09855791272430064 | validation: 0.15188023932121325]
	TIME [epoch: 11.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274062945540334		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.1274062945540334 | validation: 0.113609378359081]
	TIME [epoch: 11.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147067167121616		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.1147067167121616 | validation: 0.1681768925582674]
	TIME [epoch: 11.7 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13574528697581392		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.13574528697581392 | validation: 0.15990890885920025]
	TIME [epoch: 11.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14615270160184793		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.14615270160184793 | validation: 0.13813951118173984]
	TIME [epoch: 11.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110274255805276		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.110274255805276 | validation: 0.07623263710080543]
	TIME [epoch: 11.7 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1115498090807434		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.1115498090807434 | validation: 0.09299336514049844]
	TIME [epoch: 11.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08630664876989061		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.08630664876989061 | validation: 0.14839739867367974]
	TIME [epoch: 11.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950282995682367		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.10950282995682367 | validation: 0.08176030656407667]
	TIME [epoch: 11.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09043391870741915		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.09043391870741915 | validation: 0.1482566966645063]
	TIME [epoch: 11.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11793044459740606		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.11793044459740606 | validation: 0.12487387335704796]
	TIME [epoch: 11.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.093112704156443		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.093112704156443 | validation: 0.08639881548867837]
	TIME [epoch: 11.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19350769890983294		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.19350769890983294 | validation: 0.2400053996211191]
	TIME [epoch: 11.7 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25078608924724133		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.25078608924724133 | validation: 0.0952029920617781]
	TIME [epoch: 11.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09802940485558767		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.09802940485558767 | validation: 0.0827760314847387]
	TIME [epoch: 11.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07734190503469433		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.07734190503469433 | validation: 0.07480912559511607]
	TIME [epoch: 11.7 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07360643857354954		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.07360643857354954 | validation: 0.08570315322581402]
	TIME [epoch: 11.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12372917823974255		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.12372917823974255 | validation: 0.11743833302649365]
	TIME [epoch: 11.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883807081342042		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.0883807081342042 | validation: 0.09090817399358428]
	TIME [epoch: 11.7 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07927085444125984		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.07927085444125984 | validation: 0.16864374439571134]
	TIME [epoch: 11.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10633040733541671		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.10633040733541671 | validation: 0.12431398909362326]
	TIME [epoch: 11.7 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13026264886549305		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.13026264886549305 | validation: 0.10163782805400964]
	TIME [epoch: 11.7 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07806247865939064		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.07806247865939064 | validation: 0.06201351366545937]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07836933598988444		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.07836933598988444 | validation: 0.12560732257061796]
	TIME [epoch: 11.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513956791642814		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.1513956791642814 | validation: 0.14436716408995726]
	TIME [epoch: 11.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831284648000022		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.0831284648000022 | validation: 0.07199061566132609]
	TIME [epoch: 11.7 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566754891882984		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.06566754891882984 | validation: 0.07815238631935328]
	TIME [epoch: 11.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09471857661518182		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.09471857661518182 | validation: 0.2919483879361568]
	TIME [epoch: 11.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19993446298224496		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.19993446298224496 | validation: 0.12542225935904747]
	TIME [epoch: 11.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851347646604377		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.08851347646604377 | validation: 0.08463368434403831]
	TIME [epoch: 11.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09914351650217441		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.09914351650217441 | validation: 0.06355976400109253]
	TIME [epoch: 11.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08746582429369956		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.08746582429369956 | validation: 0.08033719925800845]
	TIME [epoch: 11.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09449081520185168		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.09449081520185168 | validation: 0.08643552347334627]
	TIME [epoch: 11.7 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222238732075618		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.08222238732075618 | validation: 0.08593979043443703]
	TIME [epoch: 11.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099534987797296		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.099534987797296 | validation: 0.08997224396203357]
	TIME [epoch: 11.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20175781328517		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.20175781328517 | validation: 0.2551141738207757]
	TIME [epoch: 11.7 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12421562686482067		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.12421562686482067 | validation: 0.08373918058879008]
	TIME [epoch: 11.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07543112604084035		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.07543112604084035 | validation: 0.08343685613301993]
	TIME [epoch: 11.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08922903283540096		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.08922903283540096 | validation: 0.12124470169218977]
	TIME [epoch: 11.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09822571468567187		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.09822571468567187 | validation: 0.06827179790907809]
	TIME [epoch: 11.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05938275332096685		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.05938275332096685 | validation: 0.09211989677622467]
	TIME [epoch: 11.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08267990579846711		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.08267990579846711 | validation: 0.06875976982194164]
	TIME [epoch: 11.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09452856569927529		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.09452856569927529 | validation: 0.11699750449243135]
	TIME [epoch: 11.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09129562326573074		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.09129562326573074 | validation: 0.07678763171280309]
	TIME [epoch: 11.7 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08931357432147097		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.08931357432147097 | validation: 0.07902374343568005]
	TIME [epoch: 11.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07527433883989927		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.07527433883989927 | validation: 0.13461149880746498]
	TIME [epoch: 11.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249413472262459		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.10249413472262459 | validation: 0.06400306232233573]
	TIME [epoch: 11.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07200252654193699		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.07200252654193699 | validation: 0.11829108236332439]
	TIME [epoch: 11.7 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11104505400058323		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.11104505400058323 | validation: 0.06103724850229637]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_281.pth
	Model improved!!!
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059433276942567295		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.059433276942567295 | validation: 0.06657404264293673]
	TIME [epoch: 11.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08277177563904552		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.08277177563904552 | validation: 0.15179614187514118]
	TIME [epoch: 11.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11525903022462756		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.11525903022462756 | validation: 0.04648713485599271]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061036470038429214		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.061036470038429214 | validation: 0.08429911005445259]
	TIME [epoch: 11.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10920149431479485		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.10920149431479485 | validation: 0.12625346087910855]
	TIME [epoch: 11.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910819678053745		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.08910819678053745 | validation: 0.1119280360523923]
	TIME [epoch: 11.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09820350473830554		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.09820350473830554 | validation: 0.059055599815242485]
	TIME [epoch: 11.7 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06662108726580707		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.06662108726580707 | validation: 0.12548679035575142]
	TIME [epoch: 11.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119197847112564		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.08119197847112564 | validation: 0.07271311977732696]
	TIME [epoch: 11.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09471487127830688		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.09471487127830688 | validation: 0.1252353258719691]
	TIME [epoch: 11.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484520269002974		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.08484520269002974 | validation: 0.07183703948414683]
	TIME [epoch: 11.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08853031553486637		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.08853031553486637 | validation: 0.1322361207203843]
	TIME [epoch: 11.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07887290835720334		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.07887290835720334 | validation: 0.058749160270032505]
	TIME [epoch: 11.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051088490534784		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.09051088490534784 | validation: 0.0879448588225106]
	TIME [epoch: 11.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08196210653537883		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.08196210653537883 | validation: 0.07352274777108214]
	TIME [epoch: 11.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061421370919901276		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.061421370919901276 | validation: 0.08935633234061052]
	TIME [epoch: 11.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07733527524175757		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.07733527524175757 | validation: 0.11770750272005204]
	TIME [epoch: 11.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09555457402244871		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.09555457402244871 | validation: 0.05648286440199979]
	TIME [epoch: 11.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949929861225799		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.10949929861225799 | validation: 0.06942752088926929]
	TIME [epoch: 11.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570430384003327		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.05570430384003327 | validation: 0.05298348070830004]
	TIME [epoch: 11.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08143659958926278		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.08143659958926278 | validation: 0.10021798120297729]
	TIME [epoch: 11.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07681810181725926		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.07681810181725926 | validation: 0.08284083313917098]
	TIME [epoch: 11.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22530881847161996		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.22530881847161996 | validation: 0.5660007448220492]
	TIME [epoch: 11.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24248293813776267		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.24248293813776267 | validation: 0.07767389935569127]
	TIME [epoch: 11.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979158605825159		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.06979158605825159 | validation: 0.07481610068476417]
	TIME [epoch: 11.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06605485639788894		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.06605485639788894 | validation: 0.081401610042633]
	TIME [epoch: 11.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08060301583759469		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.08060301583759469 | validation: 0.10128059942914161]
	TIME [epoch: 11.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948514635758932		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.05948514635758932 | validation: 0.05078164486438416]
	TIME [epoch: 11.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0537888821752515		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.0537888821752515 | validation: 0.061735943310540484]
	TIME [epoch: 11.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08668994892864162		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.08668994892864162 | validation: 0.058627704437137884]
	TIME [epoch: 11.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979981457860971		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.0979981457860971 | validation: 0.12813609257478575]
	TIME [epoch: 11.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0760633837594804		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.0760633837594804 | validation: 0.047801375738802054]
	TIME [epoch: 11.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048058507230755325		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.048058507230755325 | validation: 0.09593328546132844]
	TIME [epoch: 11.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10052854840423112		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.10052854840423112 | validation: 0.04506595666757797]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06881485804031759		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.06881485804031759 | validation: 0.09910548415554288]
	TIME [epoch: 11.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07880306052995943		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.07880306052995943 | validation: 0.0762171832816978]
	TIME [epoch: 12.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07164149821614701		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.07164149821614701 | validation: 0.09172817170724645]
	TIME [epoch: 11.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07380096849684985		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.07380096849684985 | validation: 0.07934025603989964]
	TIME [epoch: 11.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07275208069910788		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.07275208069910788 | validation: 0.08821763764254761]
	TIME [epoch: 11.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0615039391538161		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.0615039391538161 | validation: 0.08167634738402269]
	TIME [epoch: 11.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091123082344068		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.1091123082344068 | validation: 0.0884747218607719]
	TIME [epoch: 11.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353088838298247		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.06353088838298247 | validation: 0.06257344159845714]
	TIME [epoch: 11.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536923064784914		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.06536923064784914 | validation: 0.057945527141742725]
	TIME [epoch: 11.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06304599643258288		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.06304599643258288 | validation: 0.09013173341929015]
	TIME [epoch: 11.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10215876008582404		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.10215876008582404 | validation: 0.12931076269817007]
	TIME [epoch: 11.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126863853198316		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.07126863853198316 | validation: 0.038724943089316816]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538628911212186		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.04538628911212186 | validation: 0.062458288525890984]
	TIME [epoch: 11.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0842723524582551		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.0842723524582551 | validation: 0.1160897729865393]
	TIME [epoch: 11.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07376330234508009		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.07376330234508009 | validation: 0.09315252048848434]
	TIME [epoch: 11.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06095303910983147		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.06095303910983147 | validation: 0.17973278361155054]
	TIME [epoch: 11.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902401522181145		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.10902401522181145 | validation: 0.06599974235825404]
	TIME [epoch: 11.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04715751458529549		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.04715751458529549 | validation: 0.07436688893543114]
	TIME [epoch: 11.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06676181998133829		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.06676181998133829 | validation: 0.13568436159422093]
	TIME [epoch: 11.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07968932631444527		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.07968932631444527 | validation: 0.05943769966635201]
	TIME [epoch: 11.7 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07139083980088554		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.07139083980088554 | validation: 0.07990929527101913]
	TIME [epoch: 11.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667551207555008		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.0667551207555008 | validation: 0.05184103304474881]
	TIME [epoch: 11.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055453390318454365		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.055453390318454365 | validation: 0.07360523871783345]
	TIME [epoch: 11.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085636001908038		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.07085636001908038 | validation: 0.1501879648678966]
	TIME [epoch: 11.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10102137234564405		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.10102137234564405 | validation: 0.03964487691351128]
	TIME [epoch: 11.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04736724950353511		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.04736724950353511 | validation: 0.04988956608771925]
	TIME [epoch: 11.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06675422669743672		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.06675422669743672 | validation: 0.049558782830739695]
	TIME [epoch: 11.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351728409983968		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.07351728409983968 | validation: 0.07277139847575512]
	TIME [epoch: 11.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662857807525307		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.05662857807525307 | validation: 0.05341919808376898]
	TIME [epoch: 11.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046742946412739794		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.046742946412739794 | validation: 0.08346726646296389]
	TIME [epoch: 11.7 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06738996848006999		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.06738996848006999 | validation: 0.05756835795050706]
	TIME [epoch: 11.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08598733675615824		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.08598733675615824 | validation: 0.046355928712940496]
	TIME [epoch: 11.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08382445768823223		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.08382445768823223 | validation: 0.059032061467059346]
	TIME [epoch: 11.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060156903305505785		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.060156903305505785 | validation: 0.046205339483378835]
	TIME [epoch: 11.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715315843760011		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.06715315843760011 | validation: 0.04582769103075386]
	TIME [epoch: 11.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054249604596393		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.06054249604596393 | validation: 0.09318459105767193]
	TIME [epoch: 11.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06124299499690418		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.06124299499690418 | validation: 0.07450789159416452]
	TIME [epoch: 11.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318843700037621		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.06318843700037621 | validation: 0.0575700087777141]
	TIME [epoch: 11.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914174054469497		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.07914174054469497 | validation: 0.09670508032659189]
	TIME [epoch: 11.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06091961357951825		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.06091961357951825 | validation: 0.061072207688648524]
	TIME [epoch: 11.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06311605614763545		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.06311605614763545 | validation: 0.06118695035211149]
	TIME [epoch: 11.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05438082640709026		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.05438082640709026 | validation: 0.12078923431101103]
	TIME [epoch: 11.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156249703872741		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.08156249703872741 | validation: 0.06789963984135837]
	TIME [epoch: 11.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055415360083406896		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.055415360083406896 | validation: 0.039472083115317774]
	TIME [epoch: 11.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050727873232111684		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.050727873232111684 | validation: 0.1155265437466211]
	TIME [epoch: 11.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07894386619146372		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.07894386619146372 | validation: 0.08247526191173538]
	TIME [epoch: 11.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644474505676985		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.0644474505676985 | validation: 0.06498903336182552]
	TIME [epoch: 11.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320781001252679		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.05320781001252679 | validation: 0.0454775657189036]
	TIME [epoch: 11.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07544929651521184		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.07544929651521184 | validation: 0.08455935874743084]
	TIME [epoch: 11.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056557255002890536		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.056557255002890536 | validation: 0.05522529868032626]
	TIME [epoch: 11.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501690060650667		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.06501690060650667 | validation: 0.05369363081477502]
	TIME [epoch: 11.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06110018511268639		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.06110018511268639 | validation: 0.04090814673467777]
	TIME [epoch: 11.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05535501930731556		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.05535501930731556 | validation: 0.04331129640192119]
	TIME [epoch: 11.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225712478214821		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.07225712478214821 | validation: 0.04859480440574534]
	TIME [epoch: 11.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054911646795879156		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.054911646795879156 | validation: 0.06320935216033746]
	TIME [epoch: 11.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06200944816909217		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.06200944816909217 | validation: 0.056497813457127614]
	TIME [epoch: 11.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07444934873421798		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.07444934873421798 | validation: 0.06623836249275458]
	TIME [epoch: 11.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06361741920389022		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.06361741920389022 | validation: 0.04448070267062683]
	TIME [epoch: 11.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04713401025309905		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.04713401025309905 | validation: 0.04268039202769014]
	TIME [epoch: 11.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05452186817917462		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.05452186817917462 | validation: 0.06076972909367158]
	TIME [epoch: 11.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006538859357456		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.06006538859357456 | validation: 0.06722225802244751]
	TIME [epoch: 11.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05566279307938797		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.05566279307938797 | validation: 0.0430367680554858]
	TIME [epoch: 11.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05291842100894874		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.05291842100894874 | validation: 0.11044407275992606]
	TIME [epoch: 11.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08636827052084434		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.08636827052084434 | validation: 0.04523259983570252]
	TIME [epoch: 11.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06129568618643649		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.06129568618643649 | validation: 0.07867846787191574]
	TIME [epoch: 11.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053571225760321126		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.053571225760321126 | validation: 0.04427711412296376]
	TIME [epoch: 11.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06401906671128352		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.06401906671128352 | validation: 0.05449781581642105]
	TIME [epoch: 11.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058274366300615305		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.058274366300615305 | validation: 0.06716673003688245]
	TIME [epoch: 11.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05470293688067959		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.05470293688067959 | validation: 0.09689839647397638]
	TIME [epoch: 11.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07059880428040272		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.07059880428040272 | validation: 0.06556724562878082]
	TIME [epoch: 11.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05307140419088972		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.05307140419088972 | validation: 0.04192251275606587]
	TIME [epoch: 11.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512922170875746		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.05512922170875746 | validation: 0.057948561356823365]
	TIME [epoch: 11.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04838011587655404		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.04838011587655404 | validation: 0.043400748009586695]
	TIME [epoch: 11.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07415093438522968		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.07415093438522968 | validation: 0.05548965822627512]
	TIME [epoch: 11.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055542808095637594		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.055542808095637594 | validation: 0.07796638839640384]
	TIME [epoch: 11.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05411501029442151		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.05411501029442151 | validation: 0.04506593255613536]
	TIME [epoch: 11.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059452166477297064		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.059452166477297064 | validation: 0.05225552294080593]
	TIME [epoch: 11.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045719930262005826		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.045719930262005826 | validation: 0.04594307786322449]
	TIME [epoch: 11.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08694896886148498		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.08694896886148498 | validation: 0.05967716810260721]
	TIME [epoch: 11.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925535739310134		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.05925535739310134 | validation: 0.052445939220398086]
	TIME [epoch: 11.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046294881944230745		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.046294881944230745 | validation: 0.04730497462588765]
	TIME [epoch: 11.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05042971446338773		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.05042971446338773 | validation: 0.09177322934661905]
	TIME [epoch: 12 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05161993425844147		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.05161993425844147 | validation: 0.061431107047084085]
	TIME [epoch: 11.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06085545883227761		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.06085545883227761 | validation: 0.039383907597874745]
	TIME [epoch: 11.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053629549119885996		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.053629549119885996 | validation: 0.056886331691954437]
	TIME [epoch: 11.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05171714507966659		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.05171714507966659 | validation: 0.037441863716194096]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727542078785874		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.04727542078785874 | validation: 0.07457314498543915]
	TIME [epoch: 11.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06918887295935269		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.06918887295935269 | validation: 0.04315760068084412]
	TIME [epoch: 11.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05148578320653125		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.05148578320653125 | validation: 0.04610290971444184]
	TIME [epoch: 11.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051872869070634986		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.051872869070634986 | validation: 0.05604462456672761]
	TIME [epoch: 11.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662532688023099		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.05662532688023099 | validation: 0.04194293058419431]
	TIME [epoch: 11.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044924547719572855		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.044924547719572855 | validation: 0.03596268874307937]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_407.pth
	Model improved!!!
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802884672592611		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.06802884672592611 | validation: 0.053150445326436174]
	TIME [epoch: 11.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05665826393570744		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.05665826393570744 | validation: 0.04147392422082269]
	TIME [epoch: 11.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043185047742982575		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.043185047742982575 | validation: 0.06916655372491685]
	TIME [epoch: 11.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993078454259028		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.04993078454259028 | validation: 0.07545330831295746]
	TIME [epoch: 11.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06828778733120644		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.06828778733120644 | validation: 0.03448757686323012]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037816734990348655		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.037816734990348655 | validation: 0.05817200995025093]
	TIME [epoch: 11.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06629509844305301		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.06629509844305301 | validation: 0.09165968703508115]
	TIME [epoch: 11.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05387175560160587		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.05387175560160587 | validation: 0.03515953350558251]
	TIME [epoch: 11.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04000975771283127		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.04000975771283127 | validation: 0.07034963414202507]
	TIME [epoch: 11.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05624822305554		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.05624822305554 | validation: 0.06833237565998629]
	TIME [epoch: 11.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06447502126314311		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.06447502126314311 | validation: 0.09762569402064679]
	TIME [epoch: 11.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05521640904715052		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.05521640904715052 | validation: 0.04565541063049851]
	TIME [epoch: 11.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660590577850809		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.04660590577850809 | validation: 0.033783365674255134]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05844974913949775		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.05844974913949775 | validation: 0.05211540194696876]
	TIME [epoch: 11.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05267338316623593		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.05267338316623593 | validation: 0.06747674400059385]
	TIME [epoch: 11.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04978394713262193		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.04978394713262193 | validation: 0.048599926957235376]
	TIME [epoch: 11.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449804364106094		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.0449804364106094 | validation: 0.046618893935992785]
	TIME [epoch: 11.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051794350727313615		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.051794350727313615 | validation: 0.03914091165018978]
	TIME [epoch: 11.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04295848942122559		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.04295848942122559 | validation: 0.07913631552920179]
	TIME [epoch: 11.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05666962202417885		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.05666962202417885 | validation: 0.0511469267868196]
	TIME [epoch: 11.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0552204526420426		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.0552204526420426 | validation: 0.05739963138050455]
	TIME [epoch: 11.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051892236972481076		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.051892236972481076 | validation: 0.03588238821707002]
	TIME [epoch: 11.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04633480978285946		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.04633480978285946 | validation: 0.07892720333468996]
	TIME [epoch: 11.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05765705209942822		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.05765705209942822 | validation: 0.03986989209109816]
	TIME [epoch: 11.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046508912762221154		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.046508912762221154 | validation: 0.040647972359701454]
	TIME [epoch: 11.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667304438592847		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.04667304438592847 | validation: 0.03681934788369258]
	TIME [epoch: 11.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054822377770239905		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.054822377770239905 | validation: 0.058685892315232496]
	TIME [epoch: 11.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05458545498667096		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.05458545498667096 | validation: 0.06868462187117552]
	TIME [epoch: 11.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04619747558120076		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.04619747558120076 | validation: 0.04869589121855855]
	TIME [epoch: 11.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827054355443041		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.04827054355443041 | validation: 0.03661262594871813]
	TIME [epoch: 11.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05573734941379145		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.05573734941379145 | validation: 0.05656512038113959]
	TIME [epoch: 11.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724354348731857		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.05724354348731857 | validation: 0.036530726319935425]
	TIME [epoch: 11.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052656735074205784		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.052656735074205784 | validation: 0.05287770198138325]
	TIME [epoch: 11.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053309054687665135		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.053309054687665135 | validation: 0.04790443592995926]
	TIME [epoch: 11.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05179868576797642		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.05179868576797642 | validation: 0.044215832851253585]
	TIME [epoch: 11.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052491575438811514		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.052491575438811514 | validation: 0.03904891864712185]
	TIME [epoch: 11.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04245373841243359		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.04245373841243359 | validation: 0.04183081088831466]
	TIME [epoch: 11.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039872414536976084		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.039872414536976084 | validation: 0.04262430341997418]
	TIME [epoch: 11.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044426458400428886		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.044426458400428886 | validation: 0.03491719564619174]
	TIME [epoch: 11.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047452869406741476		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.047452869406741476 | validation: 0.040160871968326906]
	TIME [epoch: 11.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04785669054002179		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.04785669054002179 | validation: 0.05524243048856822]
	TIME [epoch: 11.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03895927717787666		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.03895927717787666 | validation: 0.0695018526692133]
	TIME [epoch: 11.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045803235981414		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.045803235981414 | validation: 0.03582178765530049]
	TIME [epoch: 11.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836633676005593		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.05836633676005593 | validation: 0.04315847786117462]
	TIME [epoch: 11.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03923378698497284		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.03923378698497284 | validation: 0.04103115312601825]
	TIME [epoch: 11.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05066725619773743		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.05066725619773743 | validation: 0.07587367819717214]
	TIME [epoch: 11.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657252396951271		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.04657252396951271 | validation: 0.057116345285460265]
	TIME [epoch: 11.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04421724301224046		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.04421724301224046 | validation: 0.02817256805962513]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_455.pth
	Model improved!!!
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040294920558018144		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.040294920558018144 | validation: 0.0385578455954291]
	TIME [epoch: 11.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045943572790512796		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.045943572790512796 | validation: 0.040899142918700976]
	TIME [epoch: 11.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048858401240607224		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.048858401240607224 | validation: 0.05483041523315339]
	TIME [epoch: 11.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040223380501158264		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.040223380501158264 | validation: 0.03989484164310671]
	TIME [epoch: 11.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414108758701261		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.0414108758701261 | validation: 0.0395035489517051]
	TIME [epoch: 11.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04615366001293891		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.04615366001293891 | validation: 0.07721678424911657]
	TIME [epoch: 11.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772724107720133		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.04772724107720133 | validation: 0.04580911190677706]
	TIME [epoch: 11.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04748297326032904		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.04748297326032904 | validation: 0.04552215473995734]
	TIME [epoch: 11.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04143654799599165		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.04143654799599165 | validation: 0.03793081034527332]
	TIME [epoch: 11.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433329594471851		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.0433329594471851 | validation: 0.028676860673890227]
	TIME [epoch: 11.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862251253865323		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.03862251253865323 | validation: 0.06038985381553087]
	TIME [epoch: 11.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056464056806819915		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.056464056806819915 | validation: 0.03692923639542321]
	TIME [epoch: 11.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03712791206205854		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.03712791206205854 | validation: 0.0656786451346312]
	TIME [epoch: 11.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239229342411273		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.04239229342411273 | validation: 0.038558643068825206]
	TIME [epoch: 11.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995700333446345		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.03995700333446345 | validation: 0.06712272487398985]
	TIME [epoch: 11.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419580021597204		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.04419580021597204 | validation: 0.04847757604236821]
	TIME [epoch: 11.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044781254474406354		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.044781254474406354 | validation: 0.040473014059362475]
	TIME [epoch: 11.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228756886762616		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.04228756886762616 | validation: 0.05154198609439864]
	TIME [epoch: 11.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050923887657911004		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.050923887657911004 | validation: 0.026086312375365954]
	TIME [epoch: 11.7 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03950688119711465		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.03950688119711465 | validation: 0.049604732319081364]
	TIME [epoch: 11.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047026719038768344		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.047026719038768344 | validation: 0.03557294396868037]
	TIME [epoch: 11.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03807380134941145		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.03807380134941145 | validation: 0.029444984789411502]
	TIME [epoch: 11.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654486909060361		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.04654486909060361 | validation: 0.035169167596843964]
	TIME [epoch: 11.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03873910150201821		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.03873910150201821 | validation: 0.04282696477182686]
	TIME [epoch: 11.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037456550326345435		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.037456550326345435 | validation: 0.055760771862601075]
	TIME [epoch: 11.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274111040653268		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.04274111040653268 | validation: 0.04697997581103386]
	TIME [epoch: 11.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046402347501683074		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.046402347501683074 | validation: 0.03943967917496734]
	TIME [epoch: 11.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04074651146082593		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.04074651146082593 | validation: 0.05202060210313285]
	TIME [epoch: 11.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04227102187054981		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.04227102187054981 | validation: 0.041322215942889276]
	TIME [epoch: 11.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884796434051399		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.03884796434051399 | validation: 0.04267013533758404]
	TIME [epoch: 11.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04143028950419736		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.04143028950419736 | validation: 0.03589814483031159]
	TIME [epoch: 11.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03625354222400595		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.03625354222400595 | validation: 0.03134570617986639]
	TIME [epoch: 11.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036618050566794215		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.036618050566794215 | validation: 0.03227646112962114]
	TIME [epoch: 11.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056476978618161214		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.056476978618161214 | validation: 0.05163088714560149]
	TIME [epoch: 11.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445489775848798		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.04445489775848798 | validation: 0.0281333153680732]
	TIME [epoch: 11.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03371841359276659		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.03371841359276659 | validation: 0.034213914382186315]
	TIME [epoch: 11.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03892305534082993		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.03892305534082993 | validation: 0.03844287648027403]
	TIME [epoch: 11.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03513624617094077		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.03513624617094077 | validation: 0.04542744350415046]
	TIME [epoch: 11.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244051679101142		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.04244051679101142 | validation: 0.05374340895165933]
	TIME [epoch: 11.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039198270986745054		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.039198270986745054 | validation: 0.06305664108714905]
	TIME [epoch: 11.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05135269265348291		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.05135269265348291 | validation: 0.030038610043810494]
	TIME [epoch: 11.7 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464395018390225		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.03464395018390225 | validation: 0.04058141492955114]
	TIME [epoch: 11.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034319457409905905		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.034319457409905905 | validation: 0.030929132875398703]
	TIME [epoch: 11.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482607587780074		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.04482607587780074 | validation: 0.12462196137217081]
	TIME [epoch: 11.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06754499792309705		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.06754499792309705 | validation: 0.032055409261361426]
	TIME [epoch: 11.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493027740048691		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.03493027740048691 | validation: 0.02952717231419872]
	TIME [epoch: 405 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03646863457193715		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.03646863457193715 | validation: 0.0995323057621942]
	TIME [epoch: 25.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16436089736923598		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.16436089736923598 | validation: 0.10872558527948328]
	TIME [epoch: 25.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782619715158943		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.0782619715158943 | validation: 0.04332934365791456]
	TIME [epoch: 25.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029734493158825107		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.029734493158825107 | validation: 0.029385408505903057]
	TIME [epoch: 25.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027589040030681907		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.027589040030681907 | validation: 0.02429346085005247]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02992034102811497		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.02992034102811497 | validation: 0.03497533428141347]
	TIME [epoch: 25.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318802915529645		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.03318802915529645 | validation: 0.026549101338524304]
	TIME [epoch: 25.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035741002377744115		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.035741002377744115 | validation: 0.0324437434733273]
	TIME [epoch: 25.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508520510294649		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.03508520510294649 | validation: 0.030567709023864166]
	TIME [epoch: 25.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595993347702773		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.03595993347702773 | validation: 0.03199616909535817]
	TIME [epoch: 25.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04100952212506764		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.04100952212506764 | validation: 0.035220964939718234]
	TIME [epoch: 25.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037207954523476076		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.037207954523476076 | validation: 0.03176446771959164]
	TIME [epoch: 25.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03424623888813618		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.03424623888813618 | validation: 0.025931400234496006]
	TIME [epoch: 25.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034554615073404994		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.034554615073404994 | validation: 0.04478412831547955]
	TIME [epoch: 25.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03974739641704053		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.03974739641704053 | validation: 0.03198599029551866]
	TIME [epoch: 25.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03437972680502556		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.03437972680502556 | validation: 0.034933295721042534]
	TIME [epoch: 25.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033892414876547615		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.033892414876547615 | validation: 0.05537548645046179]
	TIME [epoch: 25.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042813850935280624		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.042813850935280624 | validation: 0.046919828725499546]
	TIME [epoch: 25.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630161176671155		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.03630161176671155 | validation: 0.027181492938431848]
	TIME [epoch: 25.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035621597886834284		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.035621597886834284 | validation: 0.027435498316171734]
	TIME [epoch: 25.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02888530657117048		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.02888530657117048 | validation: 0.026236226802390926]
	TIME [epoch: 25.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033446766543298256		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.033446766543298256 | validation: 0.03469836342435127]
	TIME [epoch: 25.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04903269971502075		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.04903269971502075 | validation: 0.03357948312116909]
	TIME [epoch: 25.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034547225373445394		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.034547225373445394 | validation: 0.028129012345517842]
	TIME [epoch: 25.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035824866922201055		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.035824866922201055 | validation: 0.03096346457043722]
	TIME [epoch: 25.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037191547486403555		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.037191547486403555 | validation: 0.031183141264807444]
	TIME [epoch: 25.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02776687897256882		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.02776687897256882 | validation: 0.025365230703066538]
	TIME [epoch: 25.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033527562284355834		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.033527562284355834 | validation: 0.045061342585238494]
	TIME [epoch: 25.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383504904299936		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.0383504904299936 | validation: 0.03207157271939495]
	TIME [epoch: 25.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02679323674377476		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.02679323674377476 | validation: 0.025418923867806448]
	TIME [epoch: 25.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03441435757341943		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.03441435757341943 | validation: 0.023729451144930268]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03100699481056826		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.03100699481056826 | validation: 0.0566366595553207]
	TIME [epoch: 25.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04382387157220653		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.04382387157220653 | validation: 0.0626698733792383]
	TIME [epoch: 25.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767034775307392		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.04767034775307392 | validation: 0.03503186070419669]
	TIME [epoch: 25.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031502325354277765		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.031502325354277765 | validation: 0.023694152661719724]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_536.pth
	Model improved!!!
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029740867956693826		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.029740867956693826 | validation: 0.0329341126377443]
	TIME [epoch: 25.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02988698998422916		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.02988698998422916 | validation: 0.03506608628092871]
	TIME [epoch: 25.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03395759395756239		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.03395759395756239 | validation: 0.030903978299873465]
	TIME [epoch: 25.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03469147566238131		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.03469147566238131 | validation: 0.036512384207628215]
	TIME [epoch: 25.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035198899528463654		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.035198899528463654 | validation: 0.049922144937941025]
	TIME [epoch: 25.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03368082491001633		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.03368082491001633 | validation: 0.026663337326407174]
	TIME [epoch: 25.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028005158197764266		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.028005158197764266 | validation: 0.039993657654149826]
	TIME [epoch: 25.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039508979819130687		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.039508979819130687 | validation: 0.03642845993061068]
	TIME [epoch: 25.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035985416362355784		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.035985416362355784 | validation: 0.032796509697539056]
	TIME [epoch: 25.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029437891142242434		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.029437891142242434 | validation: 0.03168392810260204]
	TIME [epoch: 25.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03301916575650466		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.03301916575650466 | validation: 0.035266773992754734]
	TIME [epoch: 25.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035631841536690786		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.035631841536690786 | validation: 0.02950424765405697]
	TIME [epoch: 25.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03633034313308835		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.03633034313308835 | validation: 0.02626824387186627]
	TIME [epoch: 25.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02821233114929168		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.02821233114929168 | validation: 0.025178665494545324]
	TIME [epoch: 25.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0482436218112455		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.0482436218112455 | validation: 0.04236960437971918]
	TIME [epoch: 25.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032150892573793145		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.032150892573793145 | validation: 0.022385861802777178]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026868683634896744		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.026868683634896744 | validation: 0.032649256134036894]
	TIME [epoch: 25.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337582642914637		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.0337582642914637 | validation: 0.03252876806454286]
	TIME [epoch: 25.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02845635934672939		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.02845635934672939 | validation: 0.024618175791205787]
	TIME [epoch: 25.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03607841086848744		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.03607841086848744 | validation: 0.04723127648494797]
	TIME [epoch: 25.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039469663666563314		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.039469663666563314 | validation: 0.0335696560680708]
	TIME [epoch: 25.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025432709959556855		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.025432709959556855 | validation: 0.027730491615928027]
	TIME [epoch: 25.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986665030993503		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.02986665030993503 | validation: 0.029979608113652356]
	TIME [epoch: 25.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028332234513588163		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.028332234513588163 | validation: 0.07743996076265168]
	TIME [epoch: 25.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04913449411148119		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.04913449411148119 | validation: 0.024081903527626538]
	TIME [epoch: 25.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678831424351317		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.04678831424351317 | validation: 0.02925652002079708]
	TIME [epoch: 25.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03257087055824389		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.03257087055824389 | validation: 0.0305486535598349]
	TIME [epoch: 25.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02616474172568977		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.02616474172568977 | validation: 0.02132321547602467]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_564.pth
	Model improved!!!
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02604245935359888		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.02604245935359888 | validation: 0.025952978373113174]
	TIME [epoch: 25.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029017126641269955		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.029017126641269955 | validation: 0.04451443857837055]
	TIME [epoch: 25.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031300766574726656		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.031300766574726656 | validation: 0.02859109066121005]
	TIME [epoch: 25.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147096337257978		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.03147096337257978 | validation: 0.04367030696536396]
	TIME [epoch: 25.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391330151337483		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.0391330151337483 | validation: 0.023867618225909396]
	TIME [epoch: 25.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03049503883619297		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.03049503883619297 | validation: 0.027320701198661958]
	TIME [epoch: 25.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032205465682141866		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.032205465682141866 | validation: 0.021814057057627977]
	TIME [epoch: 25.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03099209500783185		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.03099209500783185 | validation: 0.04251466372772886]
	TIME [epoch: 25.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03253477979340631		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.03253477979340631 | validation: 0.022532954555084993]
	TIME [epoch: 25.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026434314872065847		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.026434314872065847 | validation: 0.03632393951686623]
	TIME [epoch: 25.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03073271940199949		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.03073271940199949 | validation: 0.05851425594939465]
	TIME [epoch: 25.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03875271189562185		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.03875271189562185 | validation: 0.03082067036414476]
	TIME [epoch: 25.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029937308787058522		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.029937308787058522 | validation: 0.02251651310297701]
	TIME [epoch: 25.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026616534476147855		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.026616534476147855 | validation: 0.028122432283701582]
	TIME [epoch: 25.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026756947980716046		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.026756947980716046 | validation: 0.03293979047989962]
	TIME [epoch: 25.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033183178957426014		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.033183178957426014 | validation: 0.02201751546286808]
	TIME [epoch: 25.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244475924021437		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.03244475924021437 | validation: 0.034495564177342876]
	TIME [epoch: 25.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026208549343448406		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.026208549343448406 | validation: 0.022723927371057714]
	TIME [epoch: 25.2 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029601670167623502		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.029601670167623502 | validation: 0.031075675447292728]
	TIME [epoch: 25.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028739963162012223		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.028739963162012223 | validation: 0.02632975071927579]
	TIME [epoch: 25.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028787292417801785		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.028787292417801785 | validation: 0.03149740959086319]
	TIME [epoch: 25.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029515052233874434		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.029515052233874434 | validation: 0.02308787581621899]
	TIME [epoch: 25.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881569901704458		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.03881569901704458 | validation: 0.033806199107668106]
	TIME [epoch: 25.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731390154347016		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.03731390154347016 | validation: 0.029021860637438744]
	TIME [epoch: 25.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026583473182297694		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.026583473182297694 | validation: 0.022146792854931215]
	TIME [epoch: 25.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905550467982939		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.02905550467982939 | validation: 0.03673139343709805]
	TIME [epoch: 25.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028939761280554546		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.028939761280554546 | validation: 0.03590230556260661]
	TIME [epoch: 25.2 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03311089488302822		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.03311089488302822 | validation: 0.026777919408964276]
	TIME [epoch: 25.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026204472538359353		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.026204472538359353 | validation: 0.024035296857581864]
	TIME [epoch: 25.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030159370671430704		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.030159370671430704 | validation: 0.022009713257848652]
	TIME [epoch: 25.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02737625197074732		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.02737625197074732 | validation: 0.024001186116269328]
	TIME [epoch: 25.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03165916335738364		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.03165916335738364 | validation: 0.02697363501721442]
	TIME [epoch: 25.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027968201881051452		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.027968201881051452 | validation: 0.03020798292724861]
	TIME [epoch: 25.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030014849046478935		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.030014849046478935 | validation: 0.029666098714696172]
	TIME [epoch: 25.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0260143670643546		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0260143670643546 | validation: 0.03457304343085651]
	TIME [epoch: 25.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030119329147752984		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.030119329147752984 | validation: 0.03905040363734541]
	TIME [epoch: 25.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028183231994052618		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.028183231994052618 | validation: 0.03654369505364654]
	TIME [epoch: 25.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0332403427722326		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.0332403427722326 | validation: 0.022783304254164905]
	TIME [epoch: 25.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029616731975153965		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.029616731975153965 | validation: 0.024489590653346157]
	TIME [epoch: 25.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02894512105697412		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.02894512105697412 | validation: 0.029386132048828145]
	TIME [epoch: 25.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02995386435514306		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.02995386435514306 | validation: 0.02541381575086068]
	TIME [epoch: 25.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0312771739007785		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.0312771739007785 | validation: 0.025296637630678485]
	TIME [epoch: 25.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02708350564790654		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.02708350564790654 | validation: 0.0372618216025276]
	TIME [epoch: 25.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865195068756235		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.02865195068756235 | validation: 0.02747411477420391]
	TIME [epoch: 25.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02962894320592638		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.02962894320592638 | validation: 0.037465708308240364]
	TIME [epoch: 25.2 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03113851736188955		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.03113851736188955 | validation: 0.0331878648851298]
	TIME [epoch: 25.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026349260689129402		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.026349260689129402 | validation: 0.022305034534026574]
	TIME [epoch: 25.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028474498293899416		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.028474498293899416 | validation: 0.02420345699481148]
	TIME [epoch: 25.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027841576566103265		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.027841576566103265 | validation: 0.025313958124105612]
	TIME [epoch: 25.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029408303058926204		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.029408303058926204 | validation: 0.021987488799100202]
	TIME [epoch: 25.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028304978750004255		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.028304978750004255 | validation: 0.026020438277677145]
	TIME [epoch: 25.2 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024828447906655365		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.024828447906655365 | validation: 0.029003925694599683]
	TIME [epoch: 25.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228146084267967		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.03228146084267967 | validation: 0.03233312266962861]
	TIME [epoch: 25.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02741484054230144		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.02741484054230144 | validation: 0.024973138534641524]
	TIME [epoch: 25.2 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02858285416515212		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.02858285416515212 | validation: 0.038078545533263744]
	TIME [epoch: 25.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709151586934358		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.02709151586934358 | validation: 0.019746067528995097]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031079799566440337		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.031079799566440337 | validation: 0.03120190704606749]
	TIME [epoch: 25.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031565619812638876		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.031565619812638876 | validation: 0.01945310063283502]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_622.pth
	Model improved!!!
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02528173625547816		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.02528173625547816 | validation: 0.025753010941707243]
	TIME [epoch: 25.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025577716165809183		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.025577716165809183 | validation: 0.052796987431687384]
	TIME [epoch: 25.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029395352272667135		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.029395352272667135 | validation: 0.024129297956543724]
	TIME [epoch: 25.2 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02887210530758872		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.02887210530758872 | validation: 0.022113051868153245]
	TIME [epoch: 25.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02249165933560651		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.02249165933560651 | validation: 0.02387764835044407]
	TIME [epoch: 25.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029859015683372264		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.029859015683372264 | validation: 0.02966779822495184]
	TIME [epoch: 25.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031054301444004534		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.031054301444004534 | validation: 0.03653142451286041]
	TIME [epoch: 25.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028835311911813766		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.028835311911813766 | validation: 0.019134929820081557]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_630.pth
	Model improved!!!
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02479914049042636		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.02479914049042636 | validation: 0.025240411961364468]
	TIME [epoch: 25.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025739820835508433		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.025739820835508433 | validation: 0.01875299675761271]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025006218628858982		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.025006218628858982 | validation: 0.02031441584264301]
	TIME [epoch: 25.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030148227808789493		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.030148227808789493 | validation: 0.019520671438021796]
	TIME [epoch: 25.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025383909206251474		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.025383909206251474 | validation: 0.028335481703464442]
	TIME [epoch: 25.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0258945260193266		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.0258945260193266 | validation: 0.02931959125376539]
	TIME [epoch: 25.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02685579124832278		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.02685579124832278 | validation: 0.02297664572744445]
	TIME [epoch: 25.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026574169491633968		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.026574169491633968 | validation: 0.02348034363976114]
	TIME [epoch: 25.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303495054969717		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0303495054969717 | validation: 0.023631254931677864]
	TIME [epoch: 25.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026315797201389848		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.026315797201389848 | validation: 0.023543300302114524]
	TIME [epoch: 25.2 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02839539119826363		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.02839539119826363 | validation: 0.033718501224581754]
	TIME [epoch: 25.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03162226820311028		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.03162226820311028 | validation: 0.021888458068597932]
	TIME [epoch: 25.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026743299441437284		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.026743299441437284 | validation: 0.027010017498225965]
	TIME [epoch: 25.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05250464661196211		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.05250464661196211 | validation: 0.06263499311262925]
	TIME [epoch: 25.2 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797362973348954		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.03797362973348954 | validation: 0.028438284754551388]
	TIME [epoch: 25.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023135733067742293		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.023135733067742293 | validation: 0.021766898927379458]
	TIME [epoch: 25.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02406453804017273		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.02406453804017273 | validation: 0.02276766643619965]
	TIME [epoch: 25.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022192186324542694		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.022192186324542694 | validation: 0.02161045603260678]
	TIME [epoch: 25.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023093825936804608		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.023093825936804608 | validation: 0.01983993628315423]
	TIME [epoch: 25.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024280190091382898		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.024280190091382898 | validation: 0.031120165432812284]
	TIME [epoch: 25.2 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283120118997871		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.0283120118997871 | validation: 0.03514538282417201]
	TIME [epoch: 25.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028925693391563256		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.028925693391563256 | validation: 0.034553961324718226]
	TIME [epoch: 25.2 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02397047916934849		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.02397047916934849 | validation: 0.01861717492844249]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_653.pth
	Model improved!!!
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022656400550409954		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.022656400550409954 | validation: 0.02621965366207108]
	TIME [epoch: 25.2 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027468846642991582		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.027468846642991582 | validation: 0.02823477367582961]
	TIME [epoch: 25.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027652342095749592		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.027652342095749592 | validation: 0.02384925804437114]
	TIME [epoch: 25.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03184123377509891		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.03184123377509891 | validation: 0.03070406228624835]
	TIME [epoch: 25.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025377626271999867		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.025377626271999867 | validation: 0.023166663759319688]
	TIME [epoch: 25.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024220083937639067		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.024220083937639067 | validation: 0.032620361787891704]
	TIME [epoch: 25.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025160603464842706		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.025160603464842706 | validation: 0.019130750708718523]
	TIME [epoch: 25.6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022511632613525113		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.022511632613525113 | validation: 0.026962874961179877]
	TIME [epoch: 25.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03156145423315931		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.03156145423315931 | validation: 0.023175089544557152]
	TIME [epoch: 25.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022810669424469566		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.022810669424469566 | validation: 0.02232427328793267]
	TIME [epoch: 25.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02340326124637903		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.02340326124637903 | validation: 0.027051839888722208]
	TIME [epoch: 25.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026785449125318165		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.026785449125318165 | validation: 0.020616501867920623]
	TIME [epoch: 25.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02234534720014847		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.02234534720014847 | validation: 0.0210099313051036]
	TIME [epoch: 25.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02795680125592756		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.02795680125592756 | validation: 0.029239351356795035]
	TIME [epoch: 25.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027795485515268593		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.027795485515268593 | validation: 0.023866115447261495]
	TIME [epoch: 25.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027701963503054296		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.027701963503054296 | validation: 0.022101979192016723]
	TIME [epoch: 25.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022384754897664578		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.022384754897664578 | validation: 0.02038547132321343]
	TIME [epoch: 25.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023818569920384655		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.023818569920384655 | validation: 0.021006559214992927]
	TIME [epoch: 25.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030131565712786877		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.030131565712786877 | validation: 0.021236742227338203]
	TIME [epoch: 25.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026940788076566066		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.026940788076566066 | validation: 0.021735980829475456]
	TIME [epoch: 25.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313730135396032		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.03313730135396032 | validation: 0.019727469403946474]
	TIME [epoch: 25.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022857436261997384		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.022857436261997384 | validation: 0.028363650888941355]
	TIME [epoch: 25.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026794565980871758		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.026794565980871758 | validation: 0.026009702641074214]
	TIME [epoch: 25.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0242452907871787		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.0242452907871787 | validation: 0.0220703105728068]
	TIME [epoch: 25.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022515010337551964		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.022515010337551964 | validation: 0.024867454036753948]
	TIME [epoch: 25.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026209398551916327		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.026209398551916327 | validation: 0.021909756679659293]
	TIME [epoch: 25.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026466383774410636		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.026466383774410636 | validation: 0.028744624777798496]
	TIME [epoch: 25.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025163907409285133		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.025163907409285133 | validation: 0.023526838708998417]
	TIME [epoch: 25.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024856683486153455		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.024856683486153455 | validation: 0.037233360105667336]
	TIME [epoch: 25.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024807045252759424		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.024807045252759424 | validation: 0.01851886223710547]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02040885651964775		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.02040885651964775 | validation: 0.023069551129812106]
	TIME [epoch: 25.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022135868538526955		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.022135868538526955 | validation: 0.020356628321890176]
	TIME [epoch: 25.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026281709516821357		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.026281709516821357 | validation: 0.027081237778686606]
	TIME [epoch: 25.2 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026128852124440854		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.026128852124440854 | validation: 0.027548271073277973]
	TIME [epoch: 25.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029509456996477945		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.029509456996477945 | validation: 0.019548278873534178]
	TIME [epoch: 25.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022839179092738696		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.022839179092738696 | validation: 0.019273679153404777]
	TIME [epoch: 25.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023181154005660135		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.023181154005660135 | validation: 0.021481557862223402]
	TIME [epoch: 25.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029722850056122883		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.029722850056122883 | validation: 0.04249433795760044]
	TIME [epoch: 25.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028766238520978607		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.028766238520978607 | validation: 0.024529875030307687]
	TIME [epoch: 25.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023342140310072396		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.023342140310072396 | validation: 0.02230892637688278]
	TIME [epoch: 25.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0239734718007123		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0239734718007123 | validation: 0.024177048743724207]
	TIME [epoch: 25.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026251565970491872		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.026251565970491872 | validation: 0.018851458797881027]
	TIME [epoch: 25.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030664555424776686		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.030664555424776686 | validation: 0.024219359911967844]
	TIME [epoch: 25.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022855568680910775		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.022855568680910775 | validation: 0.018648827070307697]
	TIME [epoch: 25.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021936683066659045		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.021936683066659045 | validation: 0.026957638682173476]
	TIME [epoch: 25.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02564260689907872		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.02564260689907872 | validation: 0.02297503885728954]
	TIME [epoch: 25.2 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022553471013872985		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.022553471013872985 | validation: 0.030973741286335753]
	TIME [epoch: 25.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027108540678521198		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.027108540678521198 | validation: 0.01836108009267659]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_701.pth
	Model improved!!!
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021879328464004127		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.021879328464004127 | validation: 0.020085390382335803]
	TIME [epoch: 25.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022669353045880847		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.022669353045880847 | validation: 0.03493932613594092]
	TIME [epoch: 25.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331268227640042		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.0331268227640042 | validation: 0.02274964706052003]
	TIME [epoch: 25.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02387217654204643		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.02387217654204643 | validation: 0.020507512716299577]
	TIME [epoch: 25.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023125673442122387		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.023125673442122387 | validation: 0.019278966726061678]
	TIME [epoch: 25.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022763910330608247		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.022763910330608247 | validation: 0.019290472220664358]
	TIME [epoch: 25.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024122486357359252		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.024122486357359252 | validation: 0.022040272957229892]
	TIME [epoch: 25.2 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02145465851982279		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.02145465851982279 | validation: 0.016426984885665148]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_709.pth
	Model improved!!!
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024550331291283273		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.024550331291283273 | validation: 0.022896719255036106]
	TIME [epoch: 25.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025958482362077262		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.025958482362077262 | validation: 0.023987662869465347]
	TIME [epoch: 25.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02410373812032454		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.02410373812032454 | validation: 0.02403185842731977]
	TIME [epoch: 26 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02361079537820955		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.02361079537820955 | validation: 0.022990793989000214]
	TIME [epoch: 25.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021283850087811564		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.021283850087811564 | validation: 0.019697246611154087]
	TIME [epoch: 25.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022067267513453864		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.022067267513453864 | validation: 0.029183382599202404]
	TIME [epoch: 25.2 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02865074350538368		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.02865074350538368 | validation: 0.020298008376062777]
	TIME [epoch: 25.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02240554014859729		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.02240554014859729 | validation: 0.019327912500567267]
	TIME [epoch: 25.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021071308153784933		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.021071308153784933 | validation: 0.020815988891334215]
	TIME [epoch: 25.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022392562303820016		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.022392562303820016 | validation: 0.020924552898257134]
	TIME [epoch: 25.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025642048622397974		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.025642048622397974 | validation: 0.0285293298150679]
	TIME [epoch: 25.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02708985409683299		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.02708985409683299 | validation: 0.02081214870933587]
	TIME [epoch: 25.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02136095655404296		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.02136095655404296 | validation: 0.019091591413362877]
	TIME [epoch: 25.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312485151480066		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.02312485151480066 | validation: 0.01773031684425]
	TIME [epoch: 25.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022740087667603017		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.022740087667603017 | validation: 0.020551906374619525]
	TIME [epoch: 25.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021444257925942095		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.021444257925942095 | validation: 0.023497734310025997]
	TIME [epoch: 25.2 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02341667698164996		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.02341667698164996 | validation: 0.026754913336666235]
	TIME [epoch: 25.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022767406872278084		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.022767406872278084 | validation: 0.020376653464710855]
	TIME [epoch: 25.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023846836641409574		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.023846836641409574 | validation: 0.018845765474804103]
	TIME [epoch: 25.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02382033402427501		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.02382033402427501 | validation: 0.029707106318459055]
	TIME [epoch: 25.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02390145304529384		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.02390145304529384 | validation: 0.018795627786061392]
	TIME [epoch: 25.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023755384254847235		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.023755384254847235 | validation: 0.038483204260250856]
	TIME [epoch: 25.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025188989632666796		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.025188989632666796 | validation: 0.02208273830230217]
	TIME [epoch: 25.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023003979323267896		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.023003979323267896 | validation: 0.016394854530171157]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_733.pth
	Model improved!!!
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020191290593924764		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.020191290593924764 | validation: 0.02393381323146372]
	TIME [epoch: 25.2 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023098704434335558		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.023098704434335558 | validation: 0.02261918322597448]
	TIME [epoch: 25.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021543779988170766		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.021543779988170766 | validation: 0.022689957391562064]
	TIME [epoch: 25.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022537722516942846		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.022537722516942846 | validation: 0.024454277924096726]
	TIME [epoch: 25.2 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02183652560489186		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.02183652560489186 | validation: 0.023064084593447904]
	TIME [epoch: 25.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246651952238383		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.02246651952238383 | validation: 0.025844928111153114]
	TIME [epoch: 25.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02200839513445481		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.02200839513445481 | validation: 0.017127881864639434]
	TIME [epoch: 25.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021291182026929686		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.021291182026929686 | validation: 0.021769546779588752]
	TIME [epoch: 25.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026158109850911104		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.026158109850911104 | validation: 0.01974873726076209]
	TIME [epoch: 25.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024120002778281947		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.024120002778281947 | validation: 0.018031638500548747]
	TIME [epoch: 25.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02137249327274941		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.02137249327274941 | validation: 0.019948067839803012]
	TIME [epoch: 25.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021625940211114202		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.021625940211114202 | validation: 0.0185104371309308]
	TIME [epoch: 25.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02266926547376397		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.02266926547376397 | validation: 0.02774279320793551]
	TIME [epoch: 25.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025716751419144902		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.025716751419144902 | validation: 0.01784138937221926]
	TIME [epoch: 25.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02339729257675839		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.02339729257675839 | validation: 0.021402732595195442]
	TIME [epoch: 25.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019816326161712375		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.019816326161712375 | validation: 0.017782926651202933]
	TIME [epoch: 25.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026435174665075514		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.026435174665075514 | validation: 0.023012730055005027]
	TIME [epoch: 25.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023777541673009855		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.023777541673009855 | validation: 0.023161199939636286]
	TIME [epoch: 25.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021021374253230397		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.021021374253230397 | validation: 0.0205146844789149]
	TIME [epoch: 25.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02108885057234612		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.02108885057234612 | validation: 0.02822603277818417]
	TIME [epoch: 25.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027696173338741126		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.027696173338741126 | validation: 0.019500523625569893]
	TIME [epoch: 25.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020871146379714434		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.020871146379714434 | validation: 0.0218542649981266]
	TIME [epoch: 25.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022531992730064072		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.022531992730064072 | validation: 0.02110323518025554]
	TIME [epoch: 25.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022052163609527414		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.022052163609527414 | validation: 0.01825712185899336]
	TIME [epoch: 25.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024577100242675447		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.024577100242675447 | validation: 0.02228709157060356]
	TIME [epoch: 25.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021112385325181896		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.021112385325181896 | validation: 0.022300281150620528]
	TIME [epoch: 25.2 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021002673621066552		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.021002673621066552 | validation: 0.021847171132075273]
	TIME [epoch: 25.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02305744257268794		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.02305744257268794 | validation: 0.01723396588883175]
	TIME [epoch: 25.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023575437575354234		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.023575437575354234 | validation: 0.0164124099145998]
	TIME [epoch: 25.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021462590340161024		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.021462590340161024 | validation: 0.01730601784650925]
	TIME [epoch: 25.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024840876770214005		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.024840876770214005 | validation: 0.02124979367068915]
	TIME [epoch: 25.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024496832635153988		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.024496832635153988 | validation: 0.026365325713663224]
	TIME [epoch: 25.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023746568948511904		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.023746568948511904 | validation: 0.018507585513057655]
	TIME [epoch: 25.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244009445010561		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.0244009445010561 | validation: 0.02044742956778664]
	TIME [epoch: 25.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021208854315899424		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.021208854315899424 | validation: 0.02057948846074866]
	TIME [epoch: 25.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020533729091987477		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.020533729091987477 | validation: 0.017442162174013436]
	TIME [epoch: 25.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05408344634404648		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.05408344634404648 | validation: 0.03426331427255057]
	TIME [epoch: 25.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02565251406699933		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.02565251406699933 | validation: 0.01853084142863856]
	TIME [epoch: 25.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018952960611256293		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.018952960611256293 | validation: 0.018127364015161875]
	TIME [epoch: 25.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01918235920030384		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.01918235920030384 | validation: 0.020395587523789057]
	TIME [epoch: 25.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020275569239212594		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.020275569239212594 | validation: 0.019267151057471905]
	TIME [epoch: 25.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020216389315697685		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.020216389315697685 | validation: 0.017682854297999782]
	TIME [epoch: 25.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022447040976965107		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.022447040976965107 | validation: 0.016720391726008678]
	TIME [epoch: 25.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01991008706243208		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.01991008706243208 | validation: 0.02178379269784808]
	TIME [epoch: 25.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02299874601146711		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.02299874601146711 | validation: 0.020295697400744463]
	TIME [epoch: 25.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02086136702661714		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.02086136702661714 | validation: 0.021038323571547342]
	TIME [epoch: 25.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020021520131772698		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.020021520131772698 | validation: 0.019692161263130694]
	TIME [epoch: 25.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02246789542208949		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.02246789542208949 | validation: 0.017797437482640715]
	TIME [epoch: 25.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023805448957770863		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.023805448957770863 | validation: 0.02128345835030842]
	TIME [epoch: 25.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02000758599386052		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.02000758599386052 | validation: 0.017768952532491465]
	TIME [epoch: 25.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019909386308137357		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.019909386308137357 | validation: 0.022852413827763766]
	TIME [epoch: 25.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0216845831597865		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.0216845831597865 | validation: 0.0180423833240329]
	TIME [epoch: 25.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020902585624524114		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.020902585624524114 | validation: 0.016798164862163664]
	TIME [epoch: 25.2 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024997538395819658		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.024997538395819658 | validation: 0.026533258898538088]
	TIME [epoch: 25.2 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023995367842490012		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.023995367842490012 | validation: 0.021384184059208965]
	TIME [epoch: 25.2 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02029202160753336		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.02029202160753336 | validation: 0.016930988033985406]
	TIME [epoch: 25.2 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022475829754927096		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.022475829754927096 | validation: 0.022693220502945307]
	TIME [epoch: 25.2 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021550781150367567		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.021550781150367567 | validation: 0.017560061898206088]
	TIME [epoch: 25.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019113414575731916		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.019113414575731916 | validation: 0.019148036885869746]
	TIME [epoch: 25.2 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020202753207209153		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.020202753207209153 | validation: 0.01772462820659424]
	TIME [epoch: 25.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020633560996226562		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.020633560996226562 | validation: 0.023969893316568763]
	TIME [epoch: 25.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023530040701361055		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.023530040701361055 | validation: 0.022709729261203696]
	TIME [epoch: 25.2 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022522838953878722		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.022522838953878722 | validation: 0.02434498332998925]
	TIME [epoch: 25.2 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023565279871135804		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.023565279871135804 | validation: 0.015495164861991317]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_797.pth
	Model improved!!!
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02061631901857083		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.02061631901857083 | validation: 0.017865013640908728]
	TIME [epoch: 25.2 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020303010422437234		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.020303010422437234 | validation: 0.01615722516745433]
	TIME [epoch: 25.2 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020634252997056974		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.020634252997056974 | validation: 0.019212580192550198]
	TIME [epoch: 25.2 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021688155377886716		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.021688155377886716 | validation: 0.01671331916528442]
	TIME [epoch: 25.2 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020970491428555362		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.020970491428555362 | validation: 0.02296002194133038]
	TIME [epoch: 25.2 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021388923025967375		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.021388923025967375 | validation: 0.0198724829450002]
	TIME [epoch: 25.2 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02072684463482736		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.02072684463482736 | validation: 0.018588535802822482]
	TIME [epoch: 25.2 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020163697602100596		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.020163697602100596 | validation: 0.01859163400973042]
	TIME [epoch: 25.2 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020179704944667688		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.020179704944667688 | validation: 0.017289953959772418]
	TIME [epoch: 25.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01931635995498354		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.01931635995498354 | validation: 0.03192214754876838]
	TIME [epoch: 25.2 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02177979628515034		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.02177979628515034 | validation: 0.02212501637641659]
	TIME [epoch: 25.2 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02052748652420965		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.02052748652420965 | validation: 0.017253366222679523]
	TIME [epoch: 25.2 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021489195886089572		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.021489195886089572 | validation: 0.017052668613447525]
	TIME [epoch: 25.2 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0221171502805677		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0221171502805677 | validation: 0.016163663418419884]
	TIME [epoch: 25.2 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022566399920324717		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.022566399920324717 | validation: 0.020782511134350756]
	TIME [epoch: 25.2 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02123908933884584		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.02123908933884584 | validation: 0.01940887337085605]
	TIME [epoch: 25.2 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020476103560252777		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.020476103560252777 | validation: 0.019775453611828198]
	TIME [epoch: 25.2 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019617233774887746		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.019617233774887746 | validation: 0.01635572766385803]
	TIME [epoch: 25.2 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020137531480666646		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.020137531480666646 | validation: 0.026597639573071173]
	TIME [epoch: 25.2 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02106139551943747		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.02106139551943747 | validation: 0.01866682291410692]
	TIME [epoch: 25.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020444477725473312		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.020444477725473312 | validation: 0.018276058046330597]
	TIME [epoch: 25.2 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026704324471663193		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.026704324471663193 | validation: 0.02610022703067011]
	TIME [epoch: 25.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02183110544524417		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.02183110544524417 | validation: 0.02018589946734256]
	TIME [epoch: 25.2 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02292106769719571		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.02292106769719571 | validation: 0.020820276180782082]
	TIME [epoch: 25.2 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021291943752255304		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.021291943752255304 | validation: 0.016653593297597007]
	TIME [epoch: 25.2 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018841004796554022		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.018841004796554022 | validation: 0.01861662533171859]
	TIME [epoch: 25.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019782237937102175		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.019782237937102175 | validation: 0.017969162580747156]
	TIME [epoch: 25.2 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02111084443922053		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.02111084443922053 | validation: 0.017395665641069875]
	TIME [epoch: 25.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019830164484849366		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.019830164484849366 | validation: 0.020945595037091595]
	TIME [epoch: 25.2 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019976710802144755		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.019976710802144755 | validation: 0.017062324035237764]
	TIME [epoch: 25.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020146343779954043		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.020146343779954043 | validation: 0.021754244345977093]
	TIME [epoch: 25.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019846452626780055		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.019846452626780055 | validation: 0.01858597178364034]
	TIME [epoch: 25.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02224668756222806		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.02224668756222806 | validation: 0.01862690028460284]
	TIME [epoch: 25.2 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019737840637791777		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.019737840637791777 | validation: 0.01888137936328569]
	TIME [epoch: 25.2 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021055724284959332		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.021055724284959332 | validation: 0.027545594469830605]
	TIME [epoch: 25.2 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020471405575795083		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.020471405575795083 | validation: 0.020723728538420347]
	TIME [epoch: 25.2 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02025876961737967		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.02025876961737967 | validation: 0.020652332716098704]
	TIME [epoch: 25.2 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02245925202783362		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.02245925202783362 | validation: 0.01811572775066595]
	TIME [epoch: 25.2 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01871120085686107		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.01871120085686107 | validation: 0.018170329409675754]
	TIME [epoch: 25.2 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019573935686391854		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.019573935686391854 | validation: 0.01865165310765524]
	TIME [epoch: 25.2 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02071049460200941		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.02071049460200941 | validation: 0.016786066499903968]
	TIME [epoch: 25.2 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884536461696874		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.01884536461696874 | validation: 0.017815781881658763]
	TIME [epoch: 25.2 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020404531761342094		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.020404531761342094 | validation: 0.029236289497912665]
	TIME [epoch: 25.2 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02315000420928167		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.02315000420928167 | validation: 0.019200331635907168]
	TIME [epoch: 25.2 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021308606631617884		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.021308606631617884 | validation: 0.019539815107922243]
	TIME [epoch: 25.2 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02139350599314528		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.02139350599314528 | validation: 0.01635745910408883]
	TIME [epoch: 25.2 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0195601519725016		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.0195601519725016 | validation: 0.018566086984392584]
	TIME [epoch: 25.2 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01904865923447198		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.01904865923447198 | validation: 0.017498332593666586]
	TIME [epoch: 25.2 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019947777614496297		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.019947777614496297 | validation: 0.02558848475943737]
	TIME [epoch: 25.2 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02018134287601072		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.02018134287601072 | validation: 0.01719984581758687]
	TIME [epoch: 25.2 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01996667668570531		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.01996667668570531 | validation: 0.020434850824357226]
	TIME [epoch: 25.2 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020421105132661918		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.020421105132661918 | validation: 0.017147327546566532]
	TIME [epoch: 25.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021365824079418564		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.021365824079418564 | validation: 0.023636645632552807]
	TIME [epoch: 25.2 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020619166365929375		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.020619166365929375 | validation: 0.016898958816468204]
	TIME [epoch: 25.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018251010683086308		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.018251010683086308 | validation: 0.019004408038277222]
	TIME [epoch: 25.2 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001729782298847		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.02001729782298847 | validation: 0.01897234599502623]
	TIME [epoch: 25.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022434767828070894		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.022434767828070894 | validation: 0.021059358555346765]
	TIME [epoch: 25.2 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019722445520310293		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.019722445520310293 | validation: 0.01947927356392877]
	TIME [epoch: 25.2 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020290998849853744		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.020290998849853744 | validation: 0.0231925556089772]
	TIME [epoch: 25.2 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01992290731306542		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.01992290731306542 | validation: 0.016718714793339588]
	TIME [epoch: 25.2 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01867066427499863		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.01867066427499863 | validation: 0.017540840371002755]
	TIME [epoch: 25.2 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019136298426294985		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.019136298426294985 | validation: 0.017508328375450057]
	TIME [epoch: 25.2 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019998375935905116		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.019998375935905116 | validation: 0.016666779325959127]
	TIME [epoch: 25.2 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02036027795528585		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.02036027795528585 | validation: 0.01767764244707054]
	TIME [epoch: 25.2 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019843260726665056		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.019843260726665056 | validation: 0.01878598545068165]
	TIME [epoch: 25.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019833847854983724		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.019833847854983724 | validation: 0.017648611521687882]
	TIME [epoch: 25.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019304459074575262		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.019304459074575262 | validation: 0.019590390123176434]
	TIME [epoch: 25.2 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020910055510561958		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.020910055510561958 | validation: 0.025680556865472243]
	TIME [epoch: 25.2 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019440815915023786		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.019440815915023786 | validation: 0.016507696781868718]
	TIME [epoch: 25.2 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01927779281756556		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.01927779281756556 | validation: 0.020266086569246874]
	TIME [epoch: 25.2 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01980732260892624		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.01980732260892624 | validation: 0.017221072728507696]
	TIME [epoch: 25.2 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01926353781098153		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.01926353781098153 | validation: 0.019337146161347067]
	TIME [epoch: 25.2 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01933672037168873		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.01933672037168873 | validation: 0.019924336096004205]
	TIME [epoch: 25.2 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02049155738042327		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.02049155738042327 | validation: 0.017055698183506454]
	TIME [epoch: 25.2 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022460002050267606		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.022460002050267606 | validation: 0.015568515787735712]
	TIME [epoch: 25.2 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845599511806642		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.01845599511806642 | validation: 0.015267168030945872]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018954374465178614		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.018954374465178614 | validation: 0.01739234671813854]
	TIME [epoch: 25.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018962070130280263		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.018962070130280263 | validation: 0.018794559864826213]
	TIME [epoch: 25.2 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02130722133971929		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.02130722133971929 | validation: 0.01888803531643264]
	TIME [epoch: 25.2 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020583994653988153		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.020583994653988153 | validation: 0.016255522539239283]
	TIME [epoch: 25.2 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01834304207664801		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.01834304207664801 | validation: 0.02166622452210496]
	TIME [epoch: 25.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019865716810018186		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.019865716810018186 | validation: 0.017424205715923537]
	TIME [epoch: 25.2 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019149650460313014		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.019149650460313014 | validation: 0.02247794876040648]
	TIME [epoch: 25.2 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018403534595703926		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.018403534595703926 | validation: 0.0149352855807243]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_881.pth
	Model improved!!!
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021018772776052144		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.021018772776052144 | validation: 0.0228539593043039]
	TIME [epoch: 25.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019307241322506784		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.019307241322506784 | validation: 0.01642971642707077]
	TIME [epoch: 25.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020995453317594576		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.020995453317594576 | validation: 0.01696163676725576]
	TIME [epoch: 25.2 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02006149291193038		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.02006149291193038 | validation: 0.017153399124226927]
	TIME [epoch: 25.2 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01820530340021667		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.01820530340021667 | validation: 0.01711469399006875]
	TIME [epoch: 25.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019670353193405855		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.019670353193405855 | validation: 0.022332933967239305]
	TIME [epoch: 25.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01981248696946894		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.01981248696946894 | validation: 0.0167210190109042]
	TIME [epoch: 25.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019413756268435414		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.019413756268435414 | validation: 0.019361814339792033]
	TIME [epoch: 25.2 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019213351904096863		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.019213351904096863 | validation: 0.01858196200216481]
	TIME [epoch: 25.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017845797659906737		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.017845797659906737 | validation: 0.01654912707550915]
	TIME [epoch: 25.2 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019092325923342902		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.019092325923342902 | validation: 0.016652309167114375]
	TIME [epoch: 25.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01936267509828756		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.01936267509828756 | validation: 0.021362744473733396]
	TIME [epoch: 25.2 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019725394259124646		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.019725394259124646 | validation: 0.018743582172094764]
	TIME [epoch: 25.2 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01852002219073114		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.01852002219073114 | validation: 0.016591110823913083]
	TIME [epoch: 25.2 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045836547263087		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.02045836547263087 | validation: 0.016612810734114733]
	TIME [epoch: 25.2 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019678462386452128		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.019678462386452128 | validation: 0.016538881958549155]
	TIME [epoch: 25.2 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019453971103999115		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.019453971103999115 | validation: 0.01662440341334845]
	TIME [epoch: 25.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018252531640748443		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.018252531640748443 | validation: 0.016884035915736097]
	TIME [epoch: 25.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01934859626457084		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.01934859626457084 | validation: 0.015958247393703794]
	TIME [epoch: 25.2 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018321791989123842		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.018321791989123842 | validation: 0.018164397731207677]
	TIME [epoch: 25.2 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019172546107014528		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.019172546107014528 | validation: 0.022928584541389622]
	TIME [epoch: 25.2 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021105543262068028		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.021105543262068028 | validation: 0.018940887827626138]
	TIME [epoch: 25.2 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018481302312262436		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.018481302312262436 | validation: 0.018900398222064456]
	TIME [epoch: 25.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019100471556142255		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.019100471556142255 | validation: 0.01674960440573679]
	TIME [epoch: 25.2 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018020288180513877		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.018020288180513877 | validation: 0.0168058119910929]
	TIME [epoch: 25.2 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019432933642564886		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.019432933642564886 | validation: 0.01936154061575249]
	TIME [epoch: 25.2 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021241641262901532		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.021241641262901532 | validation: 0.0244577810254053]
	TIME [epoch: 25.2 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019276983534322716		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.019276983534322716 | validation: 0.020258923677408388]
	TIME [epoch: 25.2 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017781076526325504		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.017781076526325504 | validation: 0.017488554826948374]
	TIME [epoch: 25.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02079085672329247		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.02079085672329247 | validation: 0.01646409737327938]
	TIME [epoch: 25.2 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018047814107275493		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.018047814107275493 | validation: 0.01618375016523551]
	TIME [epoch: 25.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018482173184365423		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.018482173184365423 | validation: 0.016732253515515674]
	TIME [epoch: 25.2 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01764910679508388		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.01764910679508388 | validation: 0.015312399648301042]
	TIME [epoch: 25.2 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02069902299861538		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.02069902299861538 | validation: 0.025046186221443625]
	TIME [epoch: 25.2 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019062237395349815		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.019062237395349815 | validation: 0.019070800427065025]
	TIME [epoch: 25.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018546091578374287		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.018546091578374287 | validation: 0.015513679996579308]
	TIME [epoch: 25.2 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018476497727653658		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.018476497727653658 | validation: 0.01834241545553096]
	TIME [epoch: 25.2 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01992689661966461		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.01992689661966461 | validation: 0.01506646019863592]
	TIME [epoch: 25.2 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018142861074888154		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.018142861074888154 | validation: 0.01543005654732994]
	TIME [epoch: 25.2 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017857737253740274		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.017857737253740274 | validation: 0.01778047722557384]
	TIME [epoch: 25.2 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018663928936807087		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.018663928936807087 | validation: 0.01873577347371383]
	TIME [epoch: 25.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020811152233006166		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.020811152233006166 | validation: 0.021934015260952778]
	TIME [epoch: 25.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0190103666435846		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.0190103666435846 | validation: 0.01967879236273379]
	TIME [epoch: 25.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01921474343489305		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.01921474343489305 | validation: 0.01742763634473759]
	TIME [epoch: 25.2 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01790302439045293		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.01790302439045293 | validation: 0.020502422642220963]
	TIME [epoch: 25.2 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018577400823256634		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.018577400823256634 | validation: 0.01586135877145812]
	TIME [epoch: 25.2 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0195559232511845		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.0195559232511845 | validation: 0.019134417528881703]
	TIME [epoch: 25.2 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021846926738739083		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.021846926738739083 | validation: 0.017915445391224687]
	TIME [epoch: 25.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018906767919112857		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.018906767919112857 | validation: 0.01920720882364896]
	TIME [epoch: 25.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019388843835104613		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.019388843835104613 | validation: 0.016805497991253367]
	TIME [epoch: 25.2 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018864713280891107		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.018864713280891107 | validation: 0.015960561633206582]
	TIME [epoch: 25.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017507721448160478		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.017507721448160478 | validation: 0.01782537310134378]
	TIME [epoch: 25.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0194429218812276		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.0194429218812276 | validation: 0.016435231116042063]
	TIME [epoch: 25.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019407217212443845		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.019407217212443845 | validation: 0.016684633499348928]
	TIME [epoch: 25.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018976774804820348		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.018976774804820348 | validation: 0.017030058514324504]
	TIME [epoch: 25.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018033330117969683		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.018033330117969683 | validation: 0.016543554666409718]
	TIME [epoch: 25.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018646879252369252		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.018646879252369252 | validation: 0.017989859559230593]
	TIME [epoch: 25.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017546594048689104		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.017546594048689104 | validation: 0.019445516585319518]
	TIME [epoch: 25.2 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018409881886806624		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.018409881886806624 | validation: 0.017651896844335158]
	TIME [epoch: 25.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01923361311377493		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.01923361311377493 | validation: 0.0169403814225036]
	TIME [epoch: 25.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018700294492300644		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.018700294492300644 | validation: 0.018085643707463593]
	TIME [epoch: 25.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017983594027458222		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.017983594027458222 | validation: 0.01784593457929278]
	TIME [epoch: 25.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01962802351620421		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.01962802351620421 | validation: 0.024639068837956614]
	TIME [epoch: 25.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01858264823151999		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.01858264823151999 | validation: 0.018359063940863764]
	TIME [epoch: 25.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01719337582230515		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.01719337582230515 | validation: 0.014913873736318632]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_946.pth
	Model improved!!!
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018343136222865153		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.018343136222865153 | validation: 0.01711660603778157]
	TIME [epoch: 25.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018306740191359434		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.018306740191359434 | validation: 0.016461669047197588]
	TIME [epoch: 25.2 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017431605274517432		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.017431605274517432 | validation: 0.019317898165804537]
	TIME [epoch: 25.2 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019212009948207702		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.019212009948207702 | validation: 0.01919928949903404]
	TIME [epoch: 25.2 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01760712352598342		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.01760712352598342 | validation: 0.02066765740257115]
	TIME [epoch: 25.2 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01821685221284257		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.01821685221284257 | validation: 0.01808718965460092]
	TIME [epoch: 25.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018457375453072467		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.018457375453072467 | validation: 0.01971323133480686]
	TIME [epoch: 25.2 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018093673944947694		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.018093673944947694 | validation: 0.021127391582613283]
	TIME [epoch: 25.2 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018557970209264037		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.018557970209264037 | validation: 0.018237154856276146]
	TIME [epoch: 25.2 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017659923695741216		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.017659923695741216 | validation: 0.01760450291234831]
	TIME [epoch: 25.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01886254915901013		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.01886254915901013 | validation: 0.017707649846223514]
	TIME [epoch: 25.2 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017917896134355682		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.017917896134355682 | validation: 0.021322839504016717]
	TIME [epoch: 25.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017892453714629324		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.017892453714629324 | validation: 0.01593613765349834]
	TIME [epoch: 25.2 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847575647858631		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.01847575647858631 | validation: 0.016419829144445487]
	TIME [epoch: 25.2 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017899332163275015		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.017899332163275015 | validation: 0.015171283056693453]
	TIME [epoch: 25.2 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017343290125780043		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.017343290125780043 | validation: 0.03219416698853246]
	TIME [epoch: 25.2 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01998970350488008		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.01998970350488008 | validation: 0.016581500446629073]
	TIME [epoch: 25.2 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016957986567095584		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.016957986567095584 | validation: 0.01800800358183923]
	TIME [epoch: 25.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01953824951540633		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.01953824951540633 | validation: 0.015460693675289863]
	TIME [epoch: 25.2 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018279274473696185		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.018279274473696185 | validation: 0.018566241917410645]
	TIME [epoch: 25.2 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01930356309229921		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.01930356309229921 | validation: 0.01671748783327736]
	TIME [epoch: 25.2 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017734769628630444		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.017734769628630444 | validation: 0.017639426953228496]
	TIME [epoch: 25.2 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855059820348747		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.01855059820348747 | validation: 0.01804164617156608]
	TIME [epoch: 25.2 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020689390097969496		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.020689390097969496 | validation: 0.022027071107983652]
	TIME [epoch: 25.2 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020187637954571895		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.020187637954571895 | validation: 0.017133186847769936]
	TIME [epoch: 25.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017603288267634486		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.017603288267634486 | validation: 0.016387685970447635]
	TIME [epoch: 25.2 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018059565750157148		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.018059565750157148 | validation: 0.016058821130325803]
	TIME [epoch: 25.2 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01730674941386979		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.01730674941386979 | validation: 0.016688854752360684]
	TIME [epoch: 25.2 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017728442675377515		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.017728442675377515 | validation: 0.0183860362222384]
	TIME [epoch: 25.2 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017530362953224528		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.017530362953224528 | validation: 0.01367661748450443]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_976.pth
	Model improved!!!
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017957227716826715		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.017957227716826715 | validation: 0.016307665666527305]
	TIME [epoch: 25.2 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017757163413444212		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.017757163413444212 | validation: 0.01674420214726146]
	TIME [epoch: 25.2 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018984375471032225		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.018984375471032225 | validation: 0.018815867239163925]
	TIME [epoch: 25.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017686851829718967		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.017686851829718967 | validation: 0.019240854890030516]
	TIME [epoch: 25.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01787750790429611		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.01787750790429611 | validation: 0.014479489011574302]
	TIME [epoch: 25.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181550420657293		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0181550420657293 | validation: 0.016960373455371856]
	TIME [epoch: 25.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778701929470549		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.01778701929470549 | validation: 0.01623228845148804]
	TIME [epoch: 25.2 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017898345191838555		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.017898345191838555 | validation: 0.014404327339913502]
	TIME [epoch: 25.2 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020267916259720502		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.020267916259720502 | validation: 0.01567452650141153]
	TIME [epoch: 25.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016957109483055607		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.016957109483055607 | validation: 0.019113482537052487]
	TIME [epoch: 25.2 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017493404537142095		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.017493404537142095 | validation: 0.016287834148175667]
	TIME [epoch: 25.2 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745182795514868		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.01745182795514868 | validation: 0.014715333758563893]
	TIME [epoch: 25.2 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018687283656557193		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.018687283656557193 | validation: 0.015689592438480567]
	TIME [epoch: 25.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01772079199142948		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.01772079199142948 | validation: 0.015661916680138017]
	TIME [epoch: 25.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018912764263506424		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.018912764263506424 | validation: 0.01537941823021886]
	TIME [epoch: 25.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018485931358215982		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.018485931358215982 | validation: 0.020779928772056026]
	TIME [epoch: 25.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017208359191236533		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.017208359191236533 | validation: 0.019556474737522048]
	TIME [epoch: 25.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01732935661666095		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.01732935661666095 | validation: 0.019546410801474706]
	TIME [epoch: 25.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01755978666585261		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.01755978666585261 | validation: 0.017531747882751296]
	TIME [epoch: 25.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017710003746086236		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.017710003746086236 | validation: 0.019606866620418644]
	TIME [epoch: 25.2 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018780420186184275		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.018780420186184275 | validation: 0.021622930669049117]
	TIME [epoch: 25.2 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018749353709023874		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.018749353709023874 | validation: 0.015870822579797904]
	TIME [epoch: 25.2 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017051894305185014		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.017051894305185014 | validation: 0.01548036520147112]
	TIME [epoch: 25.2 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017164341283465997		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.017164341283465997 | validation: 0.016029328289044357]
	TIME [epoch: 25.2 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018808377317457683		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.018808377317457683 | validation: 0.018194929681799525]
	TIME [epoch: 393 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01713815877384607		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.01713815877384607 | validation: 0.016007797673599396]
	TIME [epoch: 53.8 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01885826928800025		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.01885826928800025 | validation: 0.016972483773711817]
	TIME [epoch: 53.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016693742071000196		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.016693742071000196 | validation: 0.019408484238997374]
	TIME [epoch: 53.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016826913841913843		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.016826913841913843 | validation: 0.015278388531599796]
	TIME [epoch: 53.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018290228405753995		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.018290228405753995 | validation: 0.01564562772510005]
	TIME [epoch: 53.8 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016218320186378372		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.016218320186378372 | validation: 0.016524932467644117]
	TIME [epoch: 53.8 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016394876962408215		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.016394876962408215 | validation: 0.020443533714278667]
	TIME [epoch: 53.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859085864578207		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.01859085864578207 | validation: 0.01831316461747435]
	TIME [epoch: 53.8 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017290504002252047		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.017290504002252047 | validation: 0.015138297236360279]
	TIME [epoch: 53.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016517733552335292		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.016517733552335292 | validation: 0.015631590087145257]
	TIME [epoch: 53.8 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01721916564049699		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.01721916564049699 | validation: 0.019911235771351402]
	TIME [epoch: 53.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01693055432656782		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.01693055432656782 | validation: 0.01564399449766883]
	TIME [epoch: 53.8 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01768106300525823		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.01768106300525823 | validation: 0.01564576414720999]
	TIME [epoch: 53.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016838787695650444		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.016838787695650444 | validation: 0.014512135046873728]
	TIME [epoch: 53.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01690956058975448		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.01690956058975448 | validation: 0.014347826843180082]
	TIME [epoch: 53.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018354160320543152		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.018354160320543152 | validation: 0.01747781821078548]
	TIME [epoch: 53.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017400330690128737		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.017400330690128737 | validation: 0.018482392276486896]
	TIME [epoch: 53.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017879547789609877		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.017879547789609877 | validation: 0.017069323026340802]
	TIME [epoch: 53.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016192803341407		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.016192803341407 | validation: 0.01729308358025753]
	TIME [epoch: 53.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017217497934229137		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.017217497934229137 | validation: 0.014426077074264783]
	TIME [epoch: 53.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016612804687240194		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.016612804687240194 | validation: 0.017318805266013003]
	TIME [epoch: 53.8 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016567435762762147		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.016567435762762147 | validation: 0.015569613371157972]
	TIME [epoch: 53.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016919103523281565		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.016919103523281565 | validation: 0.021836519419260774]
	TIME [epoch: 53.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01665443102786371		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.01665443102786371 | validation: 0.01641953837974623]
	TIME [epoch: 53.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016706070624734858		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.016706070624734858 | validation: 0.01496624692236186]
	TIME [epoch: 53.8 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016860781733243523		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.016860781733243523 | validation: 0.01481059654601387]
	TIME [epoch: 53.8 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016933964992786654		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.016933964992786654 | validation: 0.015470964473139222]
	TIME [epoch: 53.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01730769781963423		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.01730769781963423 | validation: 0.015220268880878633]
	TIME [epoch: 53.8 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016734106994107628		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.016734106994107628 | validation: 0.014727264032909883]
	TIME [epoch: 53.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791655795442276		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.01791655795442276 | validation: 0.016542032865567984]
	TIME [epoch: 53.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01736819665575841		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.01736819665575841 | validation: 0.016445408546454626]
	TIME [epoch: 53.8 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01705671162104855		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.01705671162104855 | validation: 0.014295137534122253]
	TIME [epoch: 53.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01820569906850103		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.01820569906850103 | validation: 0.015207064820910877]
	TIME [epoch: 53.8 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0166993496955373		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.0166993496955373 | validation: 0.015115868787114912]
	TIME [epoch: 53.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017290977631239365		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.017290977631239365 | validation: 0.014431826974600421]
	TIME [epoch: 53.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756379030335906		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.01756379030335906 | validation: 0.01826698338828244]
	TIME [epoch: 53.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01671303025313436		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.01671303025313436 | validation: 0.01579611206153335]
	TIME [epoch: 53.8 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016104563714828303		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.016104563714828303 | validation: 0.020541699974007926]
	TIME [epoch: 53.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017339764246501806		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.017339764246501806 | validation: 0.018143122438033545]
	TIME [epoch: 53.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165918108317377		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.0165918108317377 | validation: 0.017772257120585992]
	TIME [epoch: 53.8 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01640656436644904		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.01640656436644904 | validation: 0.015830214001050197]
	TIME [epoch: 53.8 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01713397616913086		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.01713397616913086 | validation: 0.015432638083275043]
	TIME [epoch: 53.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016109710127741816		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.016109710127741816 | validation: 0.01896120727789448]
	TIME [epoch: 53.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01645027498071013		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.01645027498071013 | validation: 0.014623577236646413]
	TIME [epoch: 53.8 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756607113438171		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.01756607113438171 | validation: 0.020203874498410296]
	TIME [epoch: 53.8 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01773107012920454		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.01773107012920454 | validation: 0.018472189057728256]
	TIME [epoch: 53.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017284093736601138		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.017284093736601138 | validation: 0.014291694680103648]
	TIME [epoch: 53.8 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016708704374091318		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.016708704374091318 | validation: 0.016992015705649646]
	TIME [epoch: 53.8 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016043919208714626		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.016043919208714626 | validation: 0.01591674958580406]
	TIME [epoch: 53.8 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016923149776707152		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.016923149776707152 | validation: 0.017730076516605353]
	TIME [epoch: 53.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017437836001049985		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.017437836001049985 | validation: 0.01544397604574564]
	TIME [epoch: 53.8 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016999204140884686		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.016999204140884686 | validation: 0.015002705223448874]
	TIME [epoch: 53.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016477398221932157		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.016477398221932157 | validation: 0.016128063448278766]
	TIME [epoch: 53.8 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016323200508131026		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.016323200508131026 | validation: 0.015074070770932405]
	TIME [epoch: 53.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016907704805722814		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.016907704805722814 | validation: 0.01655762809243577]
	TIME [epoch: 53.8 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016941866822824454		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.016941866822824454 | validation: 0.016961315869599564]
	TIME [epoch: 53.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018060860190509998		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.018060860190509998 | validation: 0.015973172876417998]
	TIME [epoch: 53.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01632877033721974		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.01632877033721974 | validation: 0.01675934811102809]
	TIME [epoch: 53.8 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016395113117506886		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.016395113117506886 | validation: 0.0143566852963368]
	TIME [epoch: 53.8 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017462914057183018		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.017462914057183018 | validation: 0.015213140880634423]
	TIME [epoch: 53.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01682182488490398		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.01682182488490398 | validation: 0.0157204475590235]
	TIME [epoch: 53.8 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017510567597091402		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.017510567597091402 | validation: 0.015161425846615858]
	TIME [epoch: 53.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015911618356714362		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.015911618356714362 | validation: 0.018020362614049074]
	TIME [epoch: 53.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0169347447122484		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.0169347447122484 | validation: 0.014804348700210752]
	TIME [epoch: 53.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165738725825294		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.0165738725825294 | validation: 0.017071482866731692]
	TIME [epoch: 53.8 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0172293842499007		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0172293842499007 | validation: 0.0154883156770878]
	TIME [epoch: 53.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016317644877036904		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.016317644877036904 | validation: 0.014918407779109591]
	TIME [epoch: 53.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01643066929558731		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.01643066929558731 | validation: 0.014413856240005761]
	TIME [epoch: 53.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016927519148517086		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.016927519148517086 | validation: 0.017996323157132225]
	TIME [epoch: 53.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016679079411245634		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.016679079411245634 | validation: 0.016394928776763344]
	TIME [epoch: 53.8 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0165370251485586		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.0165370251485586 | validation: 0.015680365947667]
	TIME [epoch: 53.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016527824970328772		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.016527824970328772 | validation: 0.016922232869839814]
	TIME [epoch: 53.8 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01641261766124909		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.01641261766124909 | validation: 0.014647115965823207]
	TIME [epoch: 53.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016971186295903815		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.016971186295903815 | validation: 0.015288378199934432]
	TIME [epoch: 53.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015985281243106615		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.015985281243106615 | validation: 0.015183716213218828]
	TIME [epoch: 53.8 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015959960201859278		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.015959960201859278 | validation: 0.01727573326417]
	TIME [epoch: 53.8 sec]
	Saving model to: out/model_training/model_phi1_1a_distortion_v1r_3_v_mmd1_20250602_120011/states/model_phi1_1a_distortion_v1r_3_v_mmd1_1077.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 23849.157 seconds.
