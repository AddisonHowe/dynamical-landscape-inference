Args:
Namespace(name='model_facs_dec2_v1_argset3', outdir='out/model_training/model_facs_dec2_v1_argset3', training_data='data/facs/facs_dec2_v1/training', validation_data='data/facs/facs_dec2_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[100, 300, 500, 700], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.275067687034607], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2325032535

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19561788295667862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19561788295667862 | validation: 0.17154733822239177]
	TIME [epoch: 51.1 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.14636192985878027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14636192985878027 | validation: 0.1368738842019954]
	TIME [epoch: 4.62 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10399630575658696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10399630575658696 | validation: 0.12779713350748803]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1021446644911505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1021446644911505 | validation: 0.12283859560842053]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558768250946409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09558768250946409 | validation: 0.11961797268938762]
	TIME [epoch: 4.6 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08674175421776711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08674175421776711 | validation: 0.11025958066298991]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07705805425713197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07705805425713197 | validation: 0.10910558343214916]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06964878092067597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06964878092067597 | validation: 0.09581037115397918]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0999142678899575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0999142678899575 | validation: 0.10289293541194441]
	TIME [epoch: 4.57 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981824938490507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07981824938490507 | validation: 0.09231399583328753]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06720191817925694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06720191817925694 | validation: 0.09337882870866068]
	TIME [epoch: 4.58 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06651895738191776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06651895738191776 | validation: 0.10007623651436136]
	TIME [epoch: 4.58 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501194034789977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06501194034789977 | validation: 0.08430253053363865]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.056963639240716485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056963639240716485 | validation: 0.08193129175999311]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05513018867735081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05513018867735081 | validation: 0.08660519094553387]
	TIME [epoch: 4.59 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.059562290296038614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.059562290296038614 | validation: 0.07672690069736929]
	TIME [epoch: 4.59 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05860103691303088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05860103691303088 | validation: 0.07118775395992644]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07322198364920217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07322198364920217 | validation: 0.11785778700212052]
	TIME [epoch: 4.56 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469963421264686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05469963421264686 | validation: 0.07366572745835702]
	TIME [epoch: 4.57 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04444734846183763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04444734846183763 | validation: 0.08150922240825212]
	TIME [epoch: 4.57 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283667642516499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04283667642516499 | validation: 0.08534017610718284]
	TIME [epoch: 4.57 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0438592550143624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0438592550143624 | validation: 0.06441098832733567]
	TIME [epoch: 4.57 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04541628117462954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04541628117462954 | validation: 0.0646909222157982]
	TIME [epoch: 4.59 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05088756817080235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05088756817080235 | validation: 0.07928223527660115]
	TIME [epoch: 4.58 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04522304296940402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04522304296940402 | validation: 0.06474055947483637]
	TIME [epoch: 4.57 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04220447009544908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04220447009544908 | validation: 0.0714271131549149]
	TIME [epoch: 4.59 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045423065392424744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.045423065392424744 | validation: 0.0605408463032654]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036321139228585216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036321139228585216 | validation: 0.07140644723198128]
	TIME [epoch: 4.59 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138193031494486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04138193031494486 | validation: 0.07445116424872672]
	TIME [epoch: 4.58 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043601232685439265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043601232685439265 | validation: 0.06015483606882743]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041063591484738024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.041063591484738024 | validation: 0.06989725444399983]
	TIME [epoch: 4.58 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04230401334519374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04230401334519374 | validation: 0.0591441822121742]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04101021601040761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04101021601040761 | validation: 0.06121383839887122]
	TIME [epoch: 4.58 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03545208091585018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03545208091585018 | validation: 0.065074947284213]
	TIME [epoch: 4.59 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04477283692949664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04477283692949664 | validation: 0.06181154963011813]
	TIME [epoch: 4.58 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035445173749297704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.035445173749297704 | validation: 0.07634330668769812]
	TIME [epoch: 4.58 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970374575312417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03970374575312417 | validation: 0.06650000425248614]
	TIME [epoch: 4.58 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042680090882261996		[learning rate: 0.0099839]
	Learning Rate: 0.00998385
	LOSS [training: 0.042680090882261996 | validation: 0.06462150313792554]
	TIME [epoch: 4.58 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155305966725451		[learning rate: 0.0099195]
	Learning Rate: 0.00991953
	LOSS [training: 0.04155305966725451 | validation: 0.06494854926165002]
	TIME [epoch: 4.58 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661858579953767		[learning rate: 0.0098556]
	Learning Rate: 0.00985563
	LOSS [training: 0.03661858579953767 | validation: 0.05773940559023319]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03335094607769974		[learning rate: 0.0097921]
	Learning Rate: 0.00979213
	LOSS [training: 0.03335094607769974 | validation: 0.07579848806586854]
	TIME [epoch: 4.58 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045479385467308675		[learning rate: 0.009729]
	Learning Rate: 0.00972904
	LOSS [training: 0.045479385467308675 | validation: 0.05887293927426916]
	TIME [epoch: 4.58 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04118676119879873		[learning rate: 0.0096664]
	Learning Rate: 0.00966636
	LOSS [training: 0.04118676119879873 | validation: 0.058204229884526386]
	TIME [epoch: 4.58 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517380395975738		[learning rate: 0.0096041]
	Learning Rate: 0.00960409
	LOSS [training: 0.03517380395975738 | validation: 0.061961454807297714]
	TIME [epoch: 4.58 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03657758667463717		[learning rate: 0.0095422]
	Learning Rate: 0.00954221
	LOSS [training: 0.03657758667463717 | validation: 0.057125406686862654]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.038286744757836805		[learning rate: 0.0094807]
	Learning Rate: 0.00948074
	LOSS [training: 0.038286744757836805 | validation: 0.0571750280936144]
	TIME [epoch: 4.59 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483241381580161		[learning rate: 0.0094197]
	Learning Rate: 0.00941966
	LOSS [training: 0.03483241381580161 | validation: 0.05970886788833399]
	TIME [epoch: 4.58 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327894937554412		[learning rate: 0.009359]
	Learning Rate: 0.00935897
	LOSS [training: 0.03327894937554412 | validation: 0.06768866628061726]
	TIME [epoch: 4.58 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03439467451663102		[learning rate: 0.0092987]
	Learning Rate: 0.00929867
	LOSS [training: 0.03439467451663102 | validation: 0.06483004988039415]
	TIME [epoch: 4.58 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03439289039413772		[learning rate: 0.0092388]
	Learning Rate: 0.00923877
	LOSS [training: 0.03439289039413772 | validation: 0.05531368891145654]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04316275010043952		[learning rate: 0.0091792]
	Learning Rate: 0.00917925
	LOSS [training: 0.04316275010043952 | validation: 0.07378669377448951]
	TIME [epoch: 4.59 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032262044242913006		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.032262044242913006 | validation: 0.0741659879559063]
	TIME [epoch: 4.58 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235466451196142		[learning rate: 0.0090614]
	Learning Rate: 0.00906135
	LOSS [training: 0.04235466451196142 | validation: 0.06365752153130486]
	TIME [epoch: 4.58 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03714713786973831		[learning rate: 0.009003]
	Learning Rate: 0.00900297
	LOSS [training: 0.03714713786973831 | validation: 0.06377618613792345]
	TIME [epoch: 4.58 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03472222509405278		[learning rate: 0.008945]
	Learning Rate: 0.00894497
	LOSS [training: 0.03472222509405278 | validation: 0.0645851079814082]
	TIME [epoch: 4.58 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.038749407526311445		[learning rate: 0.0088873]
	Learning Rate: 0.00888734
	LOSS [training: 0.038749407526311445 | validation: 0.06198533671973237]
	TIME [epoch: 4.58 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885216940411717		[learning rate: 0.0088301]
	Learning Rate: 0.00883009
	LOSS [training: 0.03885216940411717 | validation: 0.057598396505363136]
	TIME [epoch: 4.57 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03330534119748102		[learning rate: 0.0087732]
	Learning Rate: 0.0087732
	LOSS [training: 0.03330534119748102 | validation: 0.07031206814441264]
	TIME [epoch: 4.57 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036159447621688504		[learning rate: 0.0087167]
	Learning Rate: 0.00871668
	LOSS [training: 0.036159447621688504 | validation: 0.06917727237985774]
	TIME [epoch: 4.58 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03408170568870856		[learning rate: 0.0086605]
	Learning Rate: 0.00866052
	LOSS [training: 0.03408170568870856 | validation: 0.054125082743383894]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032301585507818746		[learning rate: 0.0086047]
	Learning Rate: 0.00860472
	LOSS [training: 0.032301585507818746 | validation: 0.0639206848280924]
	TIME [epoch: 4.59 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.038509691562406426		[learning rate: 0.0085493]
	Learning Rate: 0.00854929
	LOSS [training: 0.038509691562406426 | validation: 0.06248710963890374]
	TIME [epoch: 4.58 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033659686724694486		[learning rate: 0.0084942]
	Learning Rate: 0.00849421
	LOSS [training: 0.033659686724694486 | validation: 0.05610585034415659]
	TIME [epoch: 4.57 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03918244227072038		[learning rate: 0.0084395]
	Learning Rate: 0.00843948
	LOSS [training: 0.03918244227072038 | validation: 0.06623232050298694]
	TIME [epoch: 4.58 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03754825563517715		[learning rate: 0.0083851]
	Learning Rate: 0.00838511
	LOSS [training: 0.03754825563517715 | validation: 0.05450593226972142]
	TIME [epoch: 4.58 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02953846107308598		[learning rate: 0.0083311]
	Learning Rate: 0.00833109
	LOSS [training: 0.02953846107308598 | validation: 0.06316397834198358]
	TIME [epoch: 4.58 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.034586688631732664		[learning rate: 0.0082774]
	Learning Rate: 0.00827742
	LOSS [training: 0.034586688631732664 | validation: 0.06509744156840927]
	TIME [epoch: 4.58 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035622405984943865		[learning rate: 0.0082241]
	Learning Rate: 0.00822409
	LOSS [training: 0.035622405984943865 | validation: 0.057205657842893776]
	TIME [epoch: 4.58 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033397313520247496		[learning rate: 0.0081711]
	Learning Rate: 0.0081711
	LOSS [training: 0.033397313520247496 | validation: 0.05575832950692062]
	TIME [epoch: 4.58 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030713959570476644		[learning rate: 0.0081185]
	Learning Rate: 0.00811846
	LOSS [training: 0.030713959570476644 | validation: 0.05497198591429878]
	TIME [epoch: 4.59 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03663595127649249		[learning rate: 0.0080662]
	Learning Rate: 0.00806616
	LOSS [training: 0.03663595127649249 | validation: 0.07924373388267231]
	TIME [epoch: 4.58 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032443731771888966		[learning rate: 0.0080142]
	Learning Rate: 0.00801419
	LOSS [training: 0.032443731771888966 | validation: 0.05659256870237865]
	TIME [epoch: 4.58 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028989673038965106		[learning rate: 0.0079626]
	Learning Rate: 0.00796256
	LOSS [training: 0.028989673038965106 | validation: 0.054846548623279937]
	TIME [epoch: 4.57 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035914756291277494		[learning rate: 0.0079113]
	Learning Rate: 0.00791126
	LOSS [training: 0.035914756291277494 | validation: 0.05912220216509621]
	TIME [epoch: 4.58 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03317052044432997		[learning rate: 0.0078603]
	Learning Rate: 0.00786029
	LOSS [training: 0.03317052044432997 | validation: 0.05632423530481331]
	TIME [epoch: 4.58 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02920940693520466		[learning rate: 0.0078097]
	Learning Rate: 0.00780965
	LOSS [training: 0.02920940693520466 | validation: 0.07253493460048505]
	TIME [epoch: 4.57 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03531151103926731		[learning rate: 0.0077593]
	Learning Rate: 0.00775934
	LOSS [training: 0.03531151103926731 | validation: 0.05320520503128381]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03162514075893709		[learning rate: 0.0077093]
	Learning Rate: 0.00770935
	LOSS [training: 0.03162514075893709 | validation: 0.06449197635256373]
	TIME [epoch: 4.58 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442161597268597		[learning rate: 0.0076597]
	Learning Rate: 0.00765968
	LOSS [training: 0.03442161597268597 | validation: 0.05496531855342325]
	TIME [epoch: 4.58 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03396412560885877		[learning rate: 0.0076103]
	Learning Rate: 0.00761033
	LOSS [training: 0.03396412560885877 | validation: 0.05687671544549139]
	TIME [epoch: 4.58 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033249837302919756		[learning rate: 0.0075613]
	Learning Rate: 0.0075613
	LOSS [training: 0.033249837302919756 | validation: 0.06477362899369135]
	TIME [epoch: 4.58 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030755951112662997		[learning rate: 0.0075126]
	Learning Rate: 0.00751259
	LOSS [training: 0.030755951112662997 | validation: 0.057262086297926604]
	TIME [epoch: 4.58 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0322700081083026		[learning rate: 0.0074642]
	Learning Rate: 0.00746419
	LOSS [training: 0.0322700081083026 | validation: 0.0541923651226258]
	TIME [epoch: 4.58 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438777201883722		[learning rate: 0.0074161]
	Learning Rate: 0.0074161
	LOSS [training: 0.03438777201883722 | validation: 0.06181663032400887]
	TIME [epoch: 4.58 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026801995085491144		[learning rate: 0.0073683]
	Learning Rate: 0.00736832
	LOSS [training: 0.026801995085491144 | validation: 0.061296831138621444]
	TIME [epoch: 4.58 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029036527515893792		[learning rate: 0.0073208]
	Learning Rate: 0.00732085
	LOSS [training: 0.029036527515893792 | validation: 0.06927610298025429]
	TIME [epoch: 4.58 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03545924894637088		[learning rate: 0.0072737]
	Learning Rate: 0.00727368
	LOSS [training: 0.03545924894637088 | validation: 0.061364179727862574]
	TIME [epoch: 4.58 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041303254809161		[learning rate: 0.0072268]
	Learning Rate: 0.00722682
	LOSS [training: 0.04041303254809161 | validation: 0.05507809009486029]
	TIME [epoch: 4.58 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02969053751169002		[learning rate: 0.0071803]
	Learning Rate: 0.00718026
	LOSS [training: 0.02969053751169002 | validation: 0.05422845255069019]
	TIME [epoch: 4.58 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02638583703217678		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.02638583703217678 | validation: 0.05535948806741031]
	TIME [epoch: 4.59 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028046042410673135		[learning rate: 0.007088]
	Learning Rate: 0.00708804
	LOSS [training: 0.028046042410673135 | validation: 0.06478871510706703]
	TIME [epoch: 4.59 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942322997907008		[learning rate: 0.0070424]
	Learning Rate: 0.00704238
	LOSS [training: 0.02942322997907008 | validation: 0.05227936055886408]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025531847985094128		[learning rate: 0.006997]
	Learning Rate: 0.00699701
	LOSS [training: 0.025531847985094128 | validation: 0.05690534603557551]
	TIME [epoch: 4.58 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029768419276455682		[learning rate: 0.0069519]
	Learning Rate: 0.00695193
	LOSS [training: 0.029768419276455682 | validation: 0.05174721736984698]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764697485554119		[learning rate: 0.0069071]
	Learning Rate: 0.00690714
	LOSS [training: 0.02764697485554119 | validation: 0.06906968525195621]
	TIME [epoch: 4.59 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035686338687186764		[learning rate: 0.0068626]
	Learning Rate: 0.00686264
	LOSS [training: 0.035686338687186764 | validation: 0.07892164264609217]
	TIME [epoch: 4.58 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03064609653935846		[learning rate: 0.0068184]
	Learning Rate: 0.00681843
	LOSS [training: 0.03064609653935846 | validation: 0.059863094052005295]
	TIME [epoch: 4.59 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028933411210094274		[learning rate: 0.0067745]
	Learning Rate: 0.0067745
	LOSS [training: 0.028933411210094274 | validation: 0.051665434651167706]
	TIME [epoch: 4.58 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02720418441962097		[learning rate: 0.0067309]
	Learning Rate: 0.00673085
	LOSS [training: 0.02720418441962097 | validation: 0.058656111423533594]
	TIME [epoch: 4.58 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0313371992735139		[learning rate: 0.0066875]
	Learning Rate: 0.00668749
	LOSS [training: 0.0313371992735139 | validation: 0.06655138048200082]
	TIME [epoch: 4.59 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030348311408857694		[learning rate: 0.0066444]
	Learning Rate: 0.00664441
	LOSS [training: 0.030348311408857694 | validation: 0.07405396311968339]
	TIME [epoch: 53.9 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033421871621011734		[learning rate: 0.0066016]
	Learning Rate: 0.0066016
	LOSS [training: 0.033421871621011734 | validation: 0.062249843187973566]
	TIME [epoch: 8.84 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02819980919171889		[learning rate: 0.0065591]
	Learning Rate: 0.00655907
	LOSS [training: 0.02819980919171889 | validation: 0.05032367920063049]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_103.pth
	Model improved!!!
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026893361116117107		[learning rate: 0.0065168]
	Learning Rate: 0.00651681
	LOSS [training: 0.026893361116117107 | validation: 0.05727625512703756]
	TIME [epoch: 8.82 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024434762199914067		[learning rate: 0.0064748]
	Learning Rate: 0.00647483
	LOSS [training: 0.024434762199914067 | validation: 0.059311538489253114]
	TIME [epoch: 8.82 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027919843280518004		[learning rate: 0.0064331]
	Learning Rate: 0.00643311
	LOSS [training: 0.027919843280518004 | validation: 0.059663923980990505]
	TIME [epoch: 8.83 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025504569673065726		[learning rate: 0.0063917]
	Learning Rate: 0.00639166
	LOSS [training: 0.025504569673065726 | validation: 0.05233577944931096]
	TIME [epoch: 8.82 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027924103725164753		[learning rate: 0.0063505]
	Learning Rate: 0.00635049
	LOSS [training: 0.027924103725164753 | validation: 0.06368127927264043]
	TIME [epoch: 8.82 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028312811326538522		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.028312811326538522 | validation: 0.05798061192557867]
	TIME [epoch: 8.82 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027888081760270515		[learning rate: 0.0062689]
	Learning Rate: 0.00626892
	LOSS [training: 0.027888081760270515 | validation: 0.052916383064549474]
	TIME [epoch: 8.83 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025387855334716273		[learning rate: 0.0062285]
	Learning Rate: 0.00622854
	LOSS [training: 0.025387855334716273 | validation: 0.06310272574819416]
	TIME [epoch: 8.81 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02811231735070284		[learning rate: 0.0061884]
	Learning Rate: 0.00618841
	LOSS [training: 0.02811231735070284 | validation: 0.049592961427294274]
	TIME [epoch: 8.81 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029630615037112784		[learning rate: 0.0061485]
	Learning Rate: 0.00614854
	LOSS [training: 0.029630615037112784 | validation: 0.0567636609977318]
	TIME [epoch: 8.82 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02872876220233473		[learning rate: 0.0061089]
	Learning Rate: 0.00610893
	LOSS [training: 0.02872876220233473 | validation: 0.060994766131708525]
	TIME [epoch: 8.81 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0335391473380842		[learning rate: 0.0060696]
	Learning Rate: 0.00606957
	LOSS [training: 0.0335391473380842 | validation: 0.05272033124488499]
	TIME [epoch: 8.81 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027648025857022224		[learning rate: 0.0060305]
	Learning Rate: 0.00603047
	LOSS [training: 0.027648025857022224 | validation: 0.0758929955572543]
	TIME [epoch: 8.82 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321230265183631		[learning rate: 0.0059916]
	Learning Rate: 0.00599161
	LOSS [training: 0.0321230265183631 | validation: 0.05053771626852627]
	TIME [epoch: 8.82 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025347045710561282		[learning rate: 0.005953]
	Learning Rate: 0.00595301
	LOSS [training: 0.025347045710561282 | validation: 0.06305271593790855]
	TIME [epoch: 8.83 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026095196465336933		[learning rate: 0.0059147]
	Learning Rate: 0.00591466
	LOSS [training: 0.026095196465336933 | validation: 0.0651125528244712]
	TIME [epoch: 8.81 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027824174850842234		[learning rate: 0.0058766]
	Learning Rate: 0.00587655
	LOSS [training: 0.027824174850842234 | validation: 0.12382331347666273]
	TIME [epoch: 8.82 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04840086760116377		[learning rate: 0.0058387]
	Learning Rate: 0.00583869
	LOSS [training: 0.04840086760116377 | validation: 0.06045094335093308]
	TIME [epoch: 8.82 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026533366553968218		[learning rate: 0.0058011]
	Learning Rate: 0.00580108
	LOSS [training: 0.026533366553968218 | validation: 0.05531585799505759]
	TIME [epoch: 8.81 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022829333824160348		[learning rate: 0.0057637]
	Learning Rate: 0.0057637
	LOSS [training: 0.022829333824160348 | validation: 0.05808611120111969]
	TIME [epoch: 8.82 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023743889422139987		[learning rate: 0.0057266]
	Learning Rate: 0.00572657
	LOSS [training: 0.023743889422139987 | validation: 0.05265907019680623]
	TIME [epoch: 8.83 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023562581484009717		[learning rate: 0.0056897]
	Learning Rate: 0.00568968
	LOSS [training: 0.023562581484009717 | validation: 0.06400672482679583]
	TIME [epoch: 8.81 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025225058428661486		[learning rate: 0.005653]
	Learning Rate: 0.00565302
	LOSS [training: 0.025225058428661486 | validation: 0.05599407452935118]
	TIME [epoch: 8.81 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028233631963664		[learning rate: 0.0056166]
	Learning Rate: 0.0056166
	LOSS [training: 0.028233631963664 | validation: 0.04990056098168073]
	TIME [epoch: 8.82 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028832671120851062		[learning rate: 0.0055804]
	Learning Rate: 0.00558042
	LOSS [training: 0.028832671120851062 | validation: 0.06039292700255429]
	TIME [epoch: 8.81 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030902659281401543		[learning rate: 0.0055445]
	Learning Rate: 0.00554447
	LOSS [training: 0.030902659281401543 | validation: 0.052087710710271545]
	TIME [epoch: 8.82 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029014559722832813		[learning rate: 0.0055087]
	Learning Rate: 0.00550874
	LOSS [training: 0.029014559722832813 | validation: 0.051154135513502036]
	TIME [epoch: 8.83 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024233808757214953		[learning rate: 0.0054733]
	Learning Rate: 0.00547325
	LOSS [training: 0.024233808757214953 | validation: 0.05300895809104398]
	TIME [epoch: 8.81 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026116841064249		[learning rate: 0.005438]
	Learning Rate: 0.00543799
	LOSS [training: 0.026116841064249 | validation: 0.052605665997162286]
	TIME [epoch: 8.82 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026868106677581636		[learning rate: 0.005403]
	Learning Rate: 0.00540296
	LOSS [training: 0.026868106677581636 | validation: 0.06538801049201276]
	TIME [epoch: 8.83 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026133961911281575		[learning rate: 0.0053681]
	Learning Rate: 0.00536815
	LOSS [training: 0.026133961911281575 | validation: 0.049338953446029614]
	TIME [epoch: 8.82 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_134.pth
	Model improved!!!
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661840875701644		[learning rate: 0.0053336]
	Learning Rate: 0.00533356
	LOSS [training: 0.02661840875701644 | validation: 0.04858499772854661]
	TIME [epoch: 8.83 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02796482155257754		[learning rate: 0.0052992]
	Learning Rate: 0.0052992
	LOSS [training: 0.02796482155257754 | validation: 0.06153760759670616]
	TIME [epoch: 8.82 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026187364151189215		[learning rate: 0.0052651]
	Learning Rate: 0.00526506
	LOSS [training: 0.026187364151189215 | validation: 0.0562029666794087]
	TIME [epoch: 8.81 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02387715166744049		[learning rate: 0.0052311]
	Learning Rate: 0.00523114
	LOSS [training: 0.02387715166744049 | validation: 0.08606170720785004]
	TIME [epoch: 8.82 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030088756266927447		[learning rate: 0.0051974]
	Learning Rate: 0.00519744
	LOSS [training: 0.030088756266927447 | validation: 0.055045693449763775]
	TIME [epoch: 8.82 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024116077727182293		[learning rate: 0.005164]
	Learning Rate: 0.00516396
	LOSS [training: 0.024116077727182293 | validation: 0.056900525135902186]
	TIME [epoch: 8.81 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027214761631297175		[learning rate: 0.0051307]
	Learning Rate: 0.00513069
	LOSS [training: 0.027214761631297175 | validation: 0.0541532905245816]
	TIME [epoch: 8.82 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025338913194148733		[learning rate: 0.0050976]
	Learning Rate: 0.00509763
	LOSS [training: 0.025338913194148733 | validation: 0.05816283289063252]
	TIME [epoch: 8.82 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0246014765167879		[learning rate: 0.0050648]
	Learning Rate: 0.00506479
	LOSS [training: 0.0246014765167879 | validation: 0.049347474737500396]
	TIME [epoch: 8.8 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025791996228182984		[learning rate: 0.0050322]
	Learning Rate: 0.00503216
	LOSS [training: 0.025791996228182984 | validation: 0.054269386426492476]
	TIME [epoch: 8.82 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022072037233239687		[learning rate: 0.0049997]
	Learning Rate: 0.00499974
	LOSS [training: 0.022072037233239687 | validation: 0.05506220015413636]
	TIME [epoch: 8.82 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02555675324777265		[learning rate: 0.0049675]
	Learning Rate: 0.00496753
	LOSS [training: 0.02555675324777265 | validation: 0.057690448519899365]
	TIME [epoch: 8.81 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02859557947405446		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.02859557947405446 | validation: 0.05644147325959936]
	TIME [epoch: 8.82 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024049251723483968		[learning rate: 0.0049037]
	Learning Rate: 0.00490373
	LOSS [training: 0.024049251723483968 | validation: 0.055225828698585964]
	TIME [epoch: 8.81 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02299825950048889		[learning rate: 0.0048721]
	Learning Rate: 0.00487213
	LOSS [training: 0.02299825950048889 | validation: 0.06397880314101131]
	TIME [epoch: 8.81 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024132708888111976		[learning rate: 0.0048407]
	Learning Rate: 0.00484075
	LOSS [training: 0.024132708888111976 | validation: 0.05423223717329762]
	TIME [epoch: 8.81 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02562307868305056		[learning rate: 0.0048096]
	Learning Rate: 0.00480956
	LOSS [training: 0.02562307868305056 | validation: 0.054297052096887344]
	TIME [epoch: 8.81 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025471221084241373		[learning rate: 0.0047786]
	Learning Rate: 0.00477857
	LOSS [training: 0.025471221084241373 | validation: 0.0627631598655159]
	TIME [epoch: 8.81 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029292177591426705		[learning rate: 0.0047478]
	Learning Rate: 0.00474779
	LOSS [training: 0.029292177591426705 | validation: 0.07404265932293715]
	TIME [epoch: 8.81 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02749357213743129		[learning rate: 0.0047172]
	Learning Rate: 0.0047172
	LOSS [training: 0.02749357213743129 | validation: 0.062187706443190646]
	TIME [epoch: 8.8 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373313073938233		[learning rate: 0.0046868]
	Learning Rate: 0.00468681
	LOSS [training: 0.02373313073938233 | validation: 0.056512360902489414]
	TIME [epoch: 8.8 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02786257460326621		[learning rate: 0.0046566]
	Learning Rate: 0.00465661
	LOSS [training: 0.02786257460326621 | validation: 0.04999253655062665]
	TIME [epoch: 8.8 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030312526827633		[learning rate: 0.0046266]
	Learning Rate: 0.00462661
	LOSS [training: 0.030312526827633 | validation: 0.05986471551962766]
	TIME [epoch: 8.81 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030744075720896352		[learning rate: 0.0045968]
	Learning Rate: 0.00459681
	LOSS [training: 0.030744075720896352 | validation: 0.04696106308213216]
	TIME [epoch: 8.8 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_158.pth
	Model improved!!!
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024309208534072077		[learning rate: 0.0045672]
	Learning Rate: 0.00456719
	LOSS [training: 0.024309208534072077 | validation: 0.05501943258872339]
	TIME [epoch: 8.82 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02155025924656232		[learning rate: 0.0045378]
	Learning Rate: 0.00453777
	LOSS [training: 0.02155025924656232 | validation: 0.05253954993934138]
	TIME [epoch: 8.81 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0244173093966924		[learning rate: 0.0045085]
	Learning Rate: 0.00450853
	LOSS [training: 0.0244173093966924 | validation: 0.0478094390511173]
	TIME [epoch: 8.82 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02435185261208536		[learning rate: 0.0044795]
	Learning Rate: 0.00447948
	LOSS [training: 0.02435185261208536 | validation: 0.04997675870821273]
	TIME [epoch: 8.81 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024531846402499394		[learning rate: 0.0044506]
	Learning Rate: 0.00445063
	LOSS [training: 0.024531846402499394 | validation: 0.05382385632339299]
	TIME [epoch: 8.81 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021379979102592074		[learning rate: 0.004422]
	Learning Rate: 0.00442195
	LOSS [training: 0.021379979102592074 | validation: 0.05968171177499779]
	TIME [epoch: 8.81 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02347108105941998		[learning rate: 0.0043935]
	Learning Rate: 0.00439346
	LOSS [training: 0.02347108105941998 | validation: 0.06773012884821286]
	TIME [epoch: 8.82 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02470657923192456		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.02470657923192456 | validation: 0.052237347329159335]
	TIME [epoch: 8.81 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022278243315077335		[learning rate: 0.004337]
	Learning Rate: 0.00433704
	LOSS [training: 0.022278243315077335 | validation: 0.051950502134773445]
	TIME [epoch: 8.81 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023173073113660972		[learning rate: 0.0043091]
	Learning Rate: 0.00430909
	LOSS [training: 0.023173073113660972 | validation: 0.05074395927930172]
	TIME [epoch: 8.81 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022430316271527972		[learning rate: 0.0042813]
	Learning Rate: 0.00428133
	LOSS [training: 0.022430316271527972 | validation: 0.05295232680962799]
	TIME [epoch: 8.81 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022961469110052396		[learning rate: 0.0042537]
	Learning Rate: 0.00425375
	LOSS [training: 0.022961469110052396 | validation: 0.049840195089458195]
	TIME [epoch: 8.8 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023337562618553118		[learning rate: 0.0042263]
	Learning Rate: 0.00422634
	LOSS [training: 0.023337562618553118 | validation: 0.07023915812431608]
	TIME [epoch: 8.82 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02999140578127621		[learning rate: 0.0041991]
	Learning Rate: 0.00419912
	LOSS [training: 0.02999140578127621 | validation: 0.05129821544866383]
	TIME [epoch: 8.81 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421150403447974		[learning rate: 0.0041721]
	Learning Rate: 0.00417206
	LOSS [training: 0.02421150403447974 | validation: 0.06124713898748724]
	TIME [epoch: 8.81 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02617587519557473		[learning rate: 0.0041452]
	Learning Rate: 0.00414518
	LOSS [training: 0.02617587519557473 | validation: 0.05692269880002567]
	TIME [epoch: 8.81 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021420596312153463		[learning rate: 0.0041185]
	Learning Rate: 0.00411848
	LOSS [training: 0.021420596312153463 | validation: 0.055445132696313]
	TIME [epoch: 8.81 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023985039320534328		[learning rate: 0.0040919]
	Learning Rate: 0.00409195
	LOSS [training: 0.023985039320534328 | validation: 0.05253311455793947]
	TIME [epoch: 8.81 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022832129883416652		[learning rate: 0.0040656]
	Learning Rate: 0.00406558
	LOSS [training: 0.022832129883416652 | validation: 0.0455109534500243]
	TIME [epoch: 8.81 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022111293428674808		[learning rate: 0.0040394]
	Learning Rate: 0.00403939
	LOSS [training: 0.022111293428674808 | validation: 0.05586438326554344]
	TIME [epoch: 8.81 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026895013197482047		[learning rate: 0.0040134]
	Learning Rate: 0.00401337
	LOSS [training: 0.026895013197482047 | validation: 0.051931385775763624]
	TIME [epoch: 8.81 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025917685395298387		[learning rate: 0.0039875]
	Learning Rate: 0.00398751
	LOSS [training: 0.025917685395298387 | validation: 0.0516484241838224]
	TIME [epoch: 8.83 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026104789621132087		[learning rate: 0.0039618]
	Learning Rate: 0.00396182
	LOSS [training: 0.026104789621132087 | validation: 0.04864394309232232]
	TIME [epoch: 8.81 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022057229439422177		[learning rate: 0.0039363]
	Learning Rate: 0.0039363
	LOSS [training: 0.022057229439422177 | validation: 0.05134718184985398]
	TIME [epoch: 8.82 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02150459224487893		[learning rate: 0.0039109]
	Learning Rate: 0.00391094
	LOSS [training: 0.02150459224487893 | validation: 0.054712529371059894]
	TIME [epoch: 8.82 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023316898056211094		[learning rate: 0.0038857]
	Learning Rate: 0.00388574
	LOSS [training: 0.023316898056211094 | validation: 0.049743171617396414]
	TIME [epoch: 8.82 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024906698694476054		[learning rate: 0.0038607]
	Learning Rate: 0.00386071
	LOSS [training: 0.024906698694476054 | validation: 0.04970359492416556]
	TIME [epoch: 8.81 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02013185034018488		[learning rate: 0.0038358]
	Learning Rate: 0.00383583
	LOSS [training: 0.02013185034018488 | validation: 0.062313261130105616]
	TIME [epoch: 8.82 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024159084757610833		[learning rate: 0.0038111]
	Learning Rate: 0.00381112
	LOSS [training: 0.024159084757610833 | validation: 0.05046005345702593]
	TIME [epoch: 8.81 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021824853885451974		[learning rate: 0.0037866]
	Learning Rate: 0.00378657
	LOSS [training: 0.021824853885451974 | validation: 0.051431293246274094]
	TIME [epoch: 8.81 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02405981721140913		[learning rate: 0.0037622]
	Learning Rate: 0.00376217
	LOSS [training: 0.02405981721140913 | validation: 0.05692134121865079]
	TIME [epoch: 8.81 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03052848927739087		[learning rate: 0.0037379]
	Learning Rate: 0.00373793
	LOSS [training: 0.03052848927739087 | validation: 0.059685144552275284]
	TIME [epoch: 8.8 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03067319684022198		[learning rate: 0.0037139]
	Learning Rate: 0.00371385
	LOSS [training: 0.03067319684022198 | validation: 0.054169032265364424]
	TIME [epoch: 8.82 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021904294977154008		[learning rate: 0.0036899]
	Learning Rate: 0.00368992
	LOSS [training: 0.021904294977154008 | validation: 0.0552975589808356]
	TIME [epoch: 8.82 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024585086884160078		[learning rate: 0.0036662]
	Learning Rate: 0.00366615
	LOSS [training: 0.024585086884160078 | validation: 0.055962681615013395]
	TIME [epoch: 8.81 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02602744311361061		[learning rate: 0.0036425]
	Learning Rate: 0.00364253
	LOSS [training: 0.02602744311361061 | validation: 0.060546697277003264]
	TIME [epoch: 8.81 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01985364076594958		[learning rate: 0.0036191]
	Learning Rate: 0.00361907
	LOSS [training: 0.01985364076594958 | validation: 0.04943258365307613]
	TIME [epoch: 8.82 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020943070166484404		[learning rate: 0.0035957]
	Learning Rate: 0.00359575
	LOSS [training: 0.020943070166484404 | validation: 0.053778913733303624]
	TIME [epoch: 8.81 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022026364162419963		[learning rate: 0.0035726]
	Learning Rate: 0.00357258
	LOSS [training: 0.022026364162419963 | validation: 0.05056659251254056]
	TIME [epoch: 8.82 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021052586510365668		[learning rate: 0.0035496]
	Learning Rate: 0.00354957
	LOSS [training: 0.021052586510365668 | validation: 0.0525449427257307]
	TIME [epoch: 8.82 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022203499760567562		[learning rate: 0.0035267]
	Learning Rate: 0.0035267
	LOSS [training: 0.022203499760567562 | validation: 0.048006309956592774]
	TIME [epoch: 8.82 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02100964548507299		[learning rate: 0.003504]
	Learning Rate: 0.00350398
	LOSS [training: 0.02100964548507299 | validation: 0.057839051435154935]
	TIME [epoch: 8.82 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02116945908622024		[learning rate: 0.0034814]
	Learning Rate: 0.0034814
	LOSS [training: 0.02116945908622024 | validation: 0.05201056254602086]
	TIME [epoch: 8.83 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02091769303570653		[learning rate: 0.003459]
	Learning Rate: 0.00345897
	LOSS [training: 0.02091769303570653 | validation: 0.05248160747065837]
	TIME [epoch: 8.81 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02076781033348144		[learning rate: 0.0034367]
	Learning Rate: 0.00343669
	LOSS [training: 0.02076781033348144 | validation: 0.05962367377901192]
	TIME [epoch: 8.82 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021938208327004882		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.021938208327004882 | validation: 0.05545979541834709]
	TIME [epoch: 8.81 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019619625790586823		[learning rate: 0.0033926]
	Learning Rate: 0.00339255
	LOSS [training: 0.019619625790586823 | validation: 0.053267678823854595]
	TIME [epoch: 8.81 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02243949238400979		[learning rate: 0.0033707]
	Learning Rate: 0.00337069
	LOSS [training: 0.02243949238400979 | validation: 0.054390220257213136]
	TIME [epoch: 8.82 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020155511814282597		[learning rate: 0.003349]
	Learning Rate: 0.00334898
	LOSS [training: 0.020155511814282597 | validation: 0.05764265216102464]
	TIME [epoch: 8.81 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022709012682016475		[learning rate: 0.0033274]
	Learning Rate: 0.0033274
	LOSS [training: 0.022709012682016475 | validation: 0.04968660695818623]
	TIME [epoch: 8.81 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0204546747753358		[learning rate: 0.003306]
	Learning Rate: 0.00330596
	LOSS [training: 0.0204546747753358 | validation: 0.04899051344309394]
	TIME [epoch: 8.81 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020894351887767545		[learning rate: 0.0032847]
	Learning Rate: 0.00328467
	LOSS [training: 0.020894351887767545 | validation: 0.054397073011307785]
	TIME [epoch: 8.82 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021775156383931668		[learning rate: 0.0032635]
	Learning Rate: 0.0032635
	LOSS [training: 0.021775156383931668 | validation: 0.04969317083566769]
	TIME [epoch: 8.8 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022084901497245936		[learning rate: 0.0032425]
	Learning Rate: 0.00324248
	LOSS [training: 0.022084901497245936 | validation: 0.049722768754600695]
	TIME [epoch: 8.82 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02151214130459476		[learning rate: 0.0032216]
	Learning Rate: 0.00322159
	LOSS [training: 0.02151214130459476 | validation: 0.06661925440365712]
	TIME [epoch: 8.82 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023726592735783918		[learning rate: 0.0032008]
	Learning Rate: 0.00320083
	LOSS [training: 0.023726592735783918 | validation: 0.05692140157718315]
	TIME [epoch: 8.81 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02582837817849003		[learning rate: 0.0031802]
	Learning Rate: 0.00318021
	LOSS [training: 0.02582837817849003 | validation: 0.05729750592272824]
	TIME [epoch: 8.82 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024131848869585592		[learning rate: 0.0031597]
	Learning Rate: 0.00315972
	LOSS [training: 0.024131848869585592 | validation: 0.05122420519202707]
	TIME [epoch: 8.82 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021012400439564233		[learning rate: 0.0031394]
	Learning Rate: 0.00313937
	LOSS [training: 0.021012400439564233 | validation: 0.04662671637682712]
	TIME [epoch: 8.81 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02067585289591664		[learning rate: 0.0031191]
	Learning Rate: 0.00311914
	LOSS [training: 0.02067585289591664 | validation: 0.047140789264153625]
	TIME [epoch: 8.82 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02239885962837835		[learning rate: 0.003099]
	Learning Rate: 0.00309905
	LOSS [training: 0.02239885962837835 | validation: 0.04920574575315474]
	TIME [epoch: 8.81 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02031002919488966		[learning rate: 0.0030791]
	Learning Rate: 0.00307908
	LOSS [training: 0.02031002919488966 | validation: 0.05047750080015953]
	TIME [epoch: 8.81 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021509697555260145		[learning rate: 0.0030592]
	Learning Rate: 0.00305924
	LOSS [training: 0.021509697555260145 | validation: 0.05010401417487271]
	TIME [epoch: 8.82 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020678297258889592		[learning rate: 0.0030395]
	Learning Rate: 0.00303953
	LOSS [training: 0.020678297258889592 | validation: 0.05734184857318819]
	TIME [epoch: 8.82 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021103975312137573		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.021103975312137573 | validation: 0.051330322459601875]
	TIME [epoch: 8.81 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020623358860348707		[learning rate: 0.0030005]
	Learning Rate: 0.0030005
	LOSS [training: 0.020623358860348707 | validation: 0.048257722441649505]
	TIME [epoch: 8.82 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022089773349526817		[learning rate: 0.0029812]
	Learning Rate: 0.00298116
	LOSS [training: 0.022089773349526817 | validation: 0.051323503449127277]
	TIME [epoch: 8.81 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02382819778789737		[learning rate: 0.002962]
	Learning Rate: 0.00296196
	LOSS [training: 0.02382819778789737 | validation: 0.05258992866472857]
	TIME [epoch: 8.82 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023513275622816222		[learning rate: 0.0029429]
	Learning Rate: 0.00294288
	LOSS [training: 0.023513275622816222 | validation: 0.051024764876529315]
	TIME [epoch: 8.82 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018998467552321274		[learning rate: 0.0029239]
	Learning Rate: 0.00292392
	LOSS [training: 0.018998467552321274 | validation: 0.05418886305192433]
	TIME [epoch: 8.82 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019396517256770846		[learning rate: 0.0029051]
	Learning Rate: 0.00290508
	LOSS [training: 0.019396517256770846 | validation: 0.053034572360306426]
	TIME [epoch: 8.82 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019999633783602505		[learning rate: 0.0028864]
	Learning Rate: 0.00288636
	LOSS [training: 0.019999633783602505 | validation: 0.05172742979864771]
	TIME [epoch: 8.83 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021180857158167008		[learning rate: 0.0028678]
	Learning Rate: 0.00286777
	LOSS [training: 0.021180857158167008 | validation: 0.05946746465688882]
	TIME [epoch: 8.82 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023725530138780412		[learning rate: 0.0028493]
	Learning Rate: 0.00284929
	LOSS [training: 0.023725530138780412 | validation: 0.05665759829982126]
	TIME [epoch: 8.82 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01979249174096155		[learning rate: 0.0028309]
	Learning Rate: 0.00283093
	LOSS [training: 0.01979249174096155 | validation: 0.06001917547589693]
	TIME [epoch: 8.84 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945072534067151		[learning rate: 0.0028127]
	Learning Rate: 0.0028127
	LOSS [training: 0.01945072534067151 | validation: 0.05207442794501821]
	TIME [epoch: 8.83 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022061755371253114		[learning rate: 0.0027946]
	Learning Rate: 0.00279457
	LOSS [training: 0.022061755371253114 | validation: 0.05364838901535986]
	TIME [epoch: 8.82 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020774621978759004		[learning rate: 0.0027766]
	Learning Rate: 0.00277657
	LOSS [training: 0.020774621978759004 | validation: 0.05463768897989564]
	TIME [epoch: 8.84 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021607862531650073		[learning rate: 0.0027587]
	Learning Rate: 0.00275868
	LOSS [training: 0.021607862531650073 | validation: 0.05301045496262291]
	TIME [epoch: 8.82 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02134140303714632		[learning rate: 0.0027409]
	Learning Rate: 0.00274091
	LOSS [training: 0.02134140303714632 | validation: 0.05422140781989737]
	TIME [epoch: 8.82 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0207768312006712		[learning rate: 0.0027233]
	Learning Rate: 0.00272325
	LOSS [training: 0.0207768312006712 | validation: 0.04614623849069368]
	TIME [epoch: 8.82 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0219213556008285		[learning rate: 0.0027057]
	Learning Rate: 0.00270571
	LOSS [training: 0.0219213556008285 | validation: 0.04958889070994216]
	TIME [epoch: 8.83 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118441595983621		[learning rate: 0.0026883]
	Learning Rate: 0.00268827
	LOSS [training: 0.02118441595983621 | validation: 0.05233343755690787]
	TIME [epoch: 8.82 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025467122661615216		[learning rate: 0.002671]
	Learning Rate: 0.00267096
	LOSS [training: 0.025467122661615216 | validation: 0.048084474035305025]
	TIME [epoch: 8.83 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01849663838009748		[learning rate: 0.0026537]
	Learning Rate: 0.00265375
	LOSS [training: 0.01849663838009748 | validation: 0.053560663499827264]
	TIME [epoch: 8.82 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020266996430768236		[learning rate: 0.0026367]
	Learning Rate: 0.00263665
	LOSS [training: 0.020266996430768236 | validation: 0.05311349882436232]
	TIME [epoch: 8.83 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02091124508490843		[learning rate: 0.0026197]
	Learning Rate: 0.00261966
	LOSS [training: 0.02091124508490843 | validation: 0.05509932212368435]
	TIME [epoch: 8.83 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018987300554481702		[learning rate: 0.0026028]
	Learning Rate: 0.00260279
	LOSS [training: 0.018987300554481702 | validation: 0.04910552953487684]
	TIME [epoch: 8.84 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02271823084393687		[learning rate: 0.002586]
	Learning Rate: 0.00258602
	LOSS [training: 0.02271823084393687 | validation: 0.050458073895745324]
	TIME [epoch: 8.82 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022216181500004026		[learning rate: 0.0025694]
	Learning Rate: 0.00256936
	LOSS [training: 0.022216181500004026 | validation: 0.06179307813815648]
	TIME [epoch: 8.82 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021179094268409623		[learning rate: 0.0025528]
	Learning Rate: 0.0025528
	LOSS [training: 0.021179094268409623 | validation: 0.05011073161362266]
	TIME [epoch: 8.82 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02147725604451204		[learning rate: 0.0025364]
	Learning Rate: 0.00253636
	LOSS [training: 0.02147725604451204 | validation: 0.04986755378791351]
	TIME [epoch: 8.82 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02274470309997141		[learning rate: 0.00252]
	Learning Rate: 0.00252002
	LOSS [training: 0.02274470309997141 | validation: 0.05919407029573107]
	TIME [epoch: 8.83 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020680870167126095		[learning rate: 0.0025038]
	Learning Rate: 0.00250378
	LOSS [training: 0.020680870167126095 | validation: 0.04880540879780505]
	TIME [epoch: 8.82 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884056537844436		[learning rate: 0.0024877]
	Learning Rate: 0.00248765
	LOSS [training: 0.01884056537844436 | validation: 0.06202355256216618]
	TIME [epoch: 8.81 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01910200824827275		[learning rate: 0.0024716]
	Learning Rate: 0.00247162
	LOSS [training: 0.01910200824827275 | validation: 0.05212048446813031]
	TIME [epoch: 8.82 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02082332098482278		[learning rate: 0.0024557]
	Learning Rate: 0.0024557
	LOSS [training: 0.02082332098482278 | validation: 0.054006359267857615]
	TIME [epoch: 8.83 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020522798932616514		[learning rate: 0.0024399]
	Learning Rate: 0.00243988
	LOSS [training: 0.020522798932616514 | validation: 0.04752323994772922]
	TIME [epoch: 8.82 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018987227426140944		[learning rate: 0.0024242]
	Learning Rate: 0.00242416
	LOSS [training: 0.018987227426140944 | validation: 0.05132359056760354]
	TIME [epoch: 8.83 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020118200403861933		[learning rate: 0.0024085]
	Learning Rate: 0.00240854
	LOSS [training: 0.020118200403861933 | validation: 0.054112726004440594]
	TIME [epoch: 8.82 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0213293928064031		[learning rate: 0.002393]
	Learning Rate: 0.00239303
	LOSS [training: 0.0213293928064031 | validation: 0.04729100350562103]
	TIME [epoch: 8.83 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019855380550668152		[learning rate: 0.0023776]
	Learning Rate: 0.00237761
	LOSS [training: 0.019855380550668152 | validation: 0.04735188572884451]
	TIME [epoch: 8.85 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021624994746434843		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.021624994746434843 | validation: 0.04662066885039223]
	TIME [epoch: 8.83 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019474862946275786		[learning rate: 0.0023471]
	Learning Rate: 0.00234707
	LOSS [training: 0.019474862946275786 | validation: 0.04938530511449513]
	TIME [epoch: 8.82 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02091879826255677		[learning rate: 0.002332]
	Learning Rate: 0.00233195
	LOSS [training: 0.02091879826255677 | validation: 0.04751104853414444]
	TIME [epoch: 8.83 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020240933293678706		[learning rate: 0.0023169]
	Learning Rate: 0.00231693
	LOSS [training: 0.020240933293678706 | validation: 0.05274157861199492]
	TIME [epoch: 8.81 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01910291242370262		[learning rate: 0.002302]
	Learning Rate: 0.002302
	LOSS [training: 0.01910291242370262 | validation: 0.05402838429626586]
	TIME [epoch: 8.82 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019885160984737978		[learning rate: 0.0022872]
	Learning Rate: 0.00228717
	LOSS [training: 0.019885160984737978 | validation: 0.05121784733188063]
	TIME [epoch: 8.83 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021884038118171082		[learning rate: 0.0022724]
	Learning Rate: 0.00227243
	LOSS [training: 0.021884038118171082 | validation: 0.04518844396039319]
	TIME [epoch: 8.82 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_267.pth
	Model improved!!!
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021217375762023302		[learning rate: 0.0022578]
	Learning Rate: 0.00225779
	LOSS [training: 0.021217375762023302 | validation: 0.048239810499781884]
	TIME [epoch: 8.82 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024321188596190337		[learning rate: 0.0022432]
	Learning Rate: 0.00224325
	LOSS [training: 0.024321188596190337 | validation: 0.048354147377099546]
	TIME [epoch: 8.83 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021035562766875876		[learning rate: 0.0022288]
	Learning Rate: 0.0022288
	LOSS [training: 0.021035562766875876 | validation: 0.049074180836252576]
	TIME [epoch: 8.81 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018121737108453516		[learning rate: 0.0022144]
	Learning Rate: 0.00221444
	LOSS [training: 0.018121737108453516 | validation: 0.05165202670147879]
	TIME [epoch: 8.83 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01972769624243592		[learning rate: 0.0022002]
	Learning Rate: 0.00220017
	LOSS [training: 0.01972769624243592 | validation: 0.05028453659496869]
	TIME [epoch: 8.82 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018984535896386417		[learning rate: 0.002186]
	Learning Rate: 0.00218599
	LOSS [training: 0.018984535896386417 | validation: 0.04966845864827118]
	TIME [epoch: 8.82 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01967693716007042		[learning rate: 0.0021719]
	Learning Rate: 0.00217191
	LOSS [training: 0.01967693716007042 | validation: 0.04962656581363048]
	TIME [epoch: 8.82 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02053314893771495		[learning rate: 0.0021579]
	Learning Rate: 0.00215792
	LOSS [training: 0.02053314893771495 | validation: 0.05240380054911292]
	TIME [epoch: 8.82 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020271530621997005		[learning rate: 0.002144]
	Learning Rate: 0.00214402
	LOSS [training: 0.020271530621997005 | validation: 0.04970309515729927]
	TIME [epoch: 8.82 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018269043914566706		[learning rate: 0.0021302]
	Learning Rate: 0.0021302
	LOSS [training: 0.018269043914566706 | validation: 0.050678090000184875]
	TIME [epoch: 8.81 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01960212061887276		[learning rate: 0.0021165]
	Learning Rate: 0.00211648
	LOSS [training: 0.01960212061887276 | validation: 0.04947005371647123]
	TIME [epoch: 8.81 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020804174249887845		[learning rate: 0.0021028]
	Learning Rate: 0.00210284
	LOSS [training: 0.020804174249887845 | validation: 0.0460282119391024]
	TIME [epoch: 8.81 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01912646427416982		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.01912646427416982 | validation: 0.05776295630847995]
	TIME [epoch: 8.81 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020709548733913553		[learning rate: 0.0020758]
	Learning Rate: 0.00207584
	LOSS [training: 0.020709548733913553 | validation: 0.049423153083738604]
	TIME [epoch: 8.82 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018205516778154986		[learning rate: 0.0020625]
	Learning Rate: 0.00206246
	LOSS [training: 0.018205516778154986 | validation: 0.0487333699294048]
	TIME [epoch: 8.81 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018661642940406252		[learning rate: 0.0020492]
	Learning Rate: 0.00204917
	LOSS [training: 0.018661642940406252 | validation: 0.050927723341240905]
	TIME [epoch: 8.82 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021914700009513708		[learning rate: 0.002036]
	Learning Rate: 0.00203597
	LOSS [training: 0.021914700009513708 | validation: 0.047419473463357245]
	TIME [epoch: 8.81 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018858664492728713		[learning rate: 0.0020229]
	Learning Rate: 0.00202286
	LOSS [training: 0.018858664492728713 | validation: 0.04771499531777763]
	TIME [epoch: 8.81 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020949712678960324		[learning rate: 0.0020098]
	Learning Rate: 0.00200982
	LOSS [training: 0.020949712678960324 | validation: 0.0543927817175406]
	TIME [epoch: 8.83 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018963619266560906		[learning rate: 0.0019969]
	Learning Rate: 0.00199687
	LOSS [training: 0.018963619266560906 | validation: 0.050233382276557034]
	TIME [epoch: 8.83 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018397233213321703		[learning rate: 0.001984]
	Learning Rate: 0.00198401
	LOSS [training: 0.018397233213321703 | validation: 0.04694525910006934]
	TIME [epoch: 8.82 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019123446777512453		[learning rate: 0.0019712]
	Learning Rate: 0.00197123
	LOSS [training: 0.019123446777512453 | validation: 0.05123330588810973]
	TIME [epoch: 8.84 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01735670593241065		[learning rate: 0.0019585]
	Learning Rate: 0.00195853
	LOSS [training: 0.01735670593241065 | validation: 0.050149059124006086]
	TIME [epoch: 8.84 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742213831260446		[learning rate: 0.0019459]
	Learning Rate: 0.00194591
	LOSS [training: 0.01742213831260446 | validation: 0.04998760980227872]
	TIME [epoch: 8.82 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020434708314621568		[learning rate: 0.0019334]
	Learning Rate: 0.00193337
	LOSS [training: 0.020434708314621568 | validation: 0.05173573977806298]
	TIME [epoch: 8.83 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018845627963480122		[learning rate: 0.0019209]
	Learning Rate: 0.00192092
	LOSS [training: 0.018845627963480122 | validation: 0.05985104196820229]
	TIME [epoch: 8.82 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018544104444340917		[learning rate: 0.0019085]
	Learning Rate: 0.00190854
	LOSS [training: 0.018544104444340917 | validation: 0.04704581481794021]
	TIME [epoch: 8.83 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02037743753374357		[learning rate: 0.0018962]
	Learning Rate: 0.00189625
	LOSS [training: 0.02037743753374357 | validation: 0.04714712528215417]
	TIME [epoch: 8.84 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017202816848849917		[learning rate: 0.001884]
	Learning Rate: 0.00188403
	LOSS [training: 0.017202816848849917 | validation: 0.05268916730550669]
	TIME [epoch: 8.83 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822538221940052		[learning rate: 0.0018719]
	Learning Rate: 0.00187189
	LOSS [training: 0.01822538221940052 | validation: 0.04577547774538827]
	TIME [epoch: 8.82 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01818133199139649		[learning rate: 0.0018598]
	Learning Rate: 0.00185983
	LOSS [training: 0.01818133199139649 | validation: 0.05071441290721268]
	TIME [epoch: 8.81 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02070140046065095		[learning rate: 0.0018478]
	Learning Rate: 0.00184785
	LOSS [training: 0.02070140046065095 | validation: 0.04823906469071611]
	TIME [epoch: 8.81 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018292537742592097		[learning rate: 0.0018359]
	Learning Rate: 0.00183594
	LOSS [training: 0.018292537742592097 | validation: 0.047400056174062274]
	TIME [epoch: 8.83 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01854605099623292		[learning rate: 0.0018241]
	Learning Rate: 0.00182412
	LOSS [training: 0.01854605099623292 | validation: 0.050301833236895604]
	TIME [epoch: 64.2 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017502077547812696		[learning rate: 0.0018124]
	Learning Rate: 0.00181236
	LOSS [training: 0.017502077547812696 | validation: 0.04854578019416105]
	TIME [epoch: 18.6 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018452671823932346		[learning rate: 0.0018007]
	Learning Rate: 0.00180069
	LOSS [training: 0.018452671823932346 | validation: 0.04594654241143723]
	TIME [epoch: 18.6 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020100505968086525		[learning rate: 0.0017891]
	Learning Rate: 0.00178909
	LOSS [training: 0.020100505968086525 | validation: 0.055475030619466105]
	TIME [epoch: 18.6 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02101173727869607		[learning rate: 0.0017776]
	Learning Rate: 0.00177756
	LOSS [training: 0.02101173727869607 | validation: 0.05112220313782848]
	TIME [epoch: 18.6 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859544978064594		[learning rate: 0.0017661]
	Learning Rate: 0.00176611
	LOSS [training: 0.01859544978064594 | validation: 0.05095307652046949]
	TIME [epoch: 18.6 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020822362296974484		[learning rate: 0.0017547]
	Learning Rate: 0.00175473
	LOSS [training: 0.020822362296974484 | validation: 0.05288906408017438]
	TIME [epoch: 18.6 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018752941333616883		[learning rate: 0.0017434]
	Learning Rate: 0.00174343
	LOSS [training: 0.018752941333616883 | validation: 0.04510954331428546]
	TIME [epoch: 18.6 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_308.pth
	Model improved!!!
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0228443966108355		[learning rate: 0.0017322]
	Learning Rate: 0.00173219
	LOSS [training: 0.0228443966108355 | validation: 0.049349161950418115]
	TIME [epoch: 18.6 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023140138345134856		[learning rate: 0.001721]
	Learning Rate: 0.00172103
	LOSS [training: 0.023140138345134856 | validation: 0.052238006440650755]
	TIME [epoch: 18.6 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018857744499170815		[learning rate: 0.0017099]
	Learning Rate: 0.00170995
	LOSS [training: 0.018857744499170815 | validation: 0.05443314261181408]
	TIME [epoch: 18.6 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019548561732757472		[learning rate: 0.0016989]
	Learning Rate: 0.00169893
	LOSS [training: 0.019548561732757472 | validation: 0.047968585361770434]
	TIME [epoch: 18.6 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020518135398132617		[learning rate: 0.001688]
	Learning Rate: 0.00168798
	LOSS [training: 0.020518135398132617 | validation: 0.05005365857406074]
	TIME [epoch: 18.6 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019858134212024703		[learning rate: 0.0016771]
	Learning Rate: 0.00167711
	LOSS [training: 0.019858134212024703 | validation: 0.053249089404578835]
	TIME [epoch: 18.6 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02326494914412119		[learning rate: 0.0016663]
	Learning Rate: 0.0016663
	LOSS [training: 0.02326494914412119 | validation: 0.052554255146497156]
	TIME [epoch: 18.6 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02222372670693041		[learning rate: 0.0016556]
	Learning Rate: 0.00165557
	LOSS [training: 0.02222372670693041 | validation: 0.05534128189324195]
	TIME [epoch: 18.6 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02023208537947737		[learning rate: 0.0016449]
	Learning Rate: 0.0016449
	LOSS [training: 0.02023208537947737 | validation: 0.04879245619441389]
	TIME [epoch: 18.6 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022006046246640064		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.022006046246640064 | validation: 0.05006771692080949]
	TIME [epoch: 18.6 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742071630001317		[learning rate: 0.0016238]
	Learning Rate: 0.00162378
	LOSS [training: 0.01742071630001317 | validation: 0.04983993513669613]
	TIME [epoch: 18.6 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019650707751463787		[learning rate: 0.0016133]
	Learning Rate: 0.00161332
	LOSS [training: 0.019650707751463787 | validation: 0.04865351760355302]
	TIME [epoch: 18.6 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01726315785393396		[learning rate: 0.0016029]
	Learning Rate: 0.00160292
	LOSS [training: 0.01726315785393396 | validation: 0.050404407822656955]
	TIME [epoch: 18.6 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01710733132263425		[learning rate: 0.0015926]
	Learning Rate: 0.00159259
	LOSS [training: 0.01710733132263425 | validation: 0.05299832665941684]
	TIME [epoch: 18.6 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018200647504979392		[learning rate: 0.0015823]
	Learning Rate: 0.00158233
	LOSS [training: 0.018200647504979392 | validation: 0.050511492760564755]
	TIME [epoch: 18.6 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01825893023926518		[learning rate: 0.0015721]
	Learning Rate: 0.00157214
	LOSS [training: 0.01825893023926518 | validation: 0.05290393748255693]
	TIME [epoch: 18.6 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802659728318836		[learning rate: 0.001562]
	Learning Rate: 0.00156201
	LOSS [training: 0.01802659728318836 | validation: 0.05108562640492282]
	TIME [epoch: 18.6 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021262020776532976		[learning rate: 0.0015519]
	Learning Rate: 0.00155195
	LOSS [training: 0.021262020776532976 | validation: 0.0488479713957892]
	TIME [epoch: 18.6 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017050574706401214		[learning rate: 0.0015419]
	Learning Rate: 0.00154195
	LOSS [training: 0.017050574706401214 | validation: 0.05213866871245195]
	TIME [epoch: 18.6 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018762903842908026		[learning rate: 0.001532]
	Learning Rate: 0.00153202
	LOSS [training: 0.018762903842908026 | validation: 0.04683694860364295]
	TIME [epoch: 18.6 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019344093536905842		[learning rate: 0.0015221]
	Learning Rate: 0.00152215
	LOSS [training: 0.019344093536905842 | validation: 0.04863173036951696]
	TIME [epoch: 18.6 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01697281831636339		[learning rate: 0.0015123]
	Learning Rate: 0.00151234
	LOSS [training: 0.01697281831636339 | validation: 0.05085252465637046]
	TIME [epoch: 18.6 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017732648360050486		[learning rate: 0.0015026]
	Learning Rate: 0.0015026
	LOSS [training: 0.017732648360050486 | validation: 0.050397935275637566]
	TIME [epoch: 18.6 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018988583897961344		[learning rate: 0.0014929]
	Learning Rate: 0.00149291
	LOSS [training: 0.018988583897961344 | validation: 0.04860664307436844]
	TIME [epoch: 18.6 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018103267879507716		[learning rate: 0.0014833]
	Learning Rate: 0.0014833
	LOSS [training: 0.018103267879507716 | validation: 0.05016278085536843]
	TIME [epoch: 18.6 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018215778250189264		[learning rate: 0.0014737]
	Learning Rate: 0.00147374
	LOSS [training: 0.018215778250189264 | validation: 0.049902762981417034]
	TIME [epoch: 18.6 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019795730445975705		[learning rate: 0.0014642]
	Learning Rate: 0.00146425
	LOSS [training: 0.019795730445975705 | validation: 0.046900045790862994]
	TIME [epoch: 18.6 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017053837956923844		[learning rate: 0.0014548]
	Learning Rate: 0.00145481
	LOSS [training: 0.017053837956923844 | validation: 0.0482888793358051]
	TIME [epoch: 18.6 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020409172364350255		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.020409172364350255 | validation: 0.05322896541402631]
	TIME [epoch: 18.6 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019702503092658655		[learning rate: 0.0014361]
	Learning Rate: 0.00143613
	LOSS [training: 0.019702503092658655 | validation: 0.048819125608838415]
	TIME [epoch: 18.6 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0187717242205435		[learning rate: 0.0014269]
	Learning Rate: 0.00142688
	LOSS [training: 0.0187717242205435 | validation: 0.05158234582227253]
	TIME [epoch: 18.6 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01841700020544039		[learning rate: 0.0014177]
	Learning Rate: 0.00141768
	LOSS [training: 0.01841700020544039 | validation: 0.04822453759038149]
	TIME [epoch: 18.6 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01897158459146087		[learning rate: 0.0014085]
	Learning Rate: 0.00140855
	LOSS [training: 0.01897158459146087 | validation: 0.046745832509133445]
	TIME [epoch: 18.6 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021969469379423547		[learning rate: 0.0013995]
	Learning Rate: 0.00139947
	LOSS [training: 0.021969469379423547 | validation: 0.052486890907898334]
	TIME [epoch: 18.6 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019232242626261782		[learning rate: 0.0013905]
	Learning Rate: 0.00139046
	LOSS [training: 0.019232242626261782 | validation: 0.04618291864855823]
	TIME [epoch: 18.6 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019159971164624735		[learning rate: 0.0013815]
	Learning Rate: 0.0013815
	LOSS [training: 0.019159971164624735 | validation: 0.050001443843759714]
	TIME [epoch: 18.6 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860270291561101		[learning rate: 0.0013726]
	Learning Rate: 0.0013726
	LOSS [training: 0.01860270291561101 | validation: 0.053140836772636015]
	TIME [epoch: 18.6 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018032121507071085		[learning rate: 0.0013638]
	Learning Rate: 0.00136376
	LOSS [training: 0.018032121507071085 | validation: 0.048038171603982764]
	TIME [epoch: 18.6 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017216368180911806		[learning rate: 0.001355]
	Learning Rate: 0.00135497
	LOSS [training: 0.017216368180911806 | validation: 0.04764259825055892]
	TIME [epoch: 18.6 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01885527980413082		[learning rate: 0.0013462]
	Learning Rate: 0.00134624
	LOSS [training: 0.01885527980413082 | validation: 0.050047027315170446]
	TIME [epoch: 18.6 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019528957647222216		[learning rate: 0.0013376]
	Learning Rate: 0.00133757
	LOSS [training: 0.019528957647222216 | validation: 0.04829730898619533]
	TIME [epoch: 18.6 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932668172584994		[learning rate: 0.001329]
	Learning Rate: 0.00132895
	LOSS [training: 0.01932668172584994 | validation: 0.05298714608087133]
	TIME [epoch: 18.6 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019398770161244652		[learning rate: 0.0013204]
	Learning Rate: 0.00132039
	LOSS [training: 0.019398770161244652 | validation: 0.05375313901370832]
	TIME [epoch: 18.6 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01793916631097031		[learning rate: 0.0013119]
	Learning Rate: 0.00131188
	LOSS [training: 0.01793916631097031 | validation: 0.049938941515627534]
	TIME [epoch: 18.6 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945860003293905		[learning rate: 0.0013034]
	Learning Rate: 0.00130343
	LOSS [training: 0.01945860003293905 | validation: 0.047710630318666174]
	TIME [epoch: 18.6 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017288565298166744		[learning rate: 0.001295]
	Learning Rate: 0.00129503
	LOSS [training: 0.017288565298166744 | validation: 0.054911312786216165]
	TIME [epoch: 18.6 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01945223952869957		[learning rate: 0.0012867]
	Learning Rate: 0.00128669
	LOSS [training: 0.01945223952869957 | validation: 0.049811440164182916]
	TIME [epoch: 18.6 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019792789822586983		[learning rate: 0.0012784]
	Learning Rate: 0.0012784
	LOSS [training: 0.019792789822586983 | validation: 0.049218320687864796]
	TIME [epoch: 18.6 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017581227853283823		[learning rate: 0.0012702]
	Learning Rate: 0.00127016
	LOSS [training: 0.017581227853283823 | validation: 0.050951454509963315]
	TIME [epoch: 18.6 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020246973981826503		[learning rate: 0.001262]
	Learning Rate: 0.00126198
	LOSS [training: 0.020246973981826503 | validation: 0.047946959594189695]
	TIME [epoch: 18.6 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017818066096786055		[learning rate: 0.0012538]
	Learning Rate: 0.00125385
	LOSS [training: 0.017818066096786055 | validation: 0.049262028209719644]
	TIME [epoch: 18.6 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019027886213118947		[learning rate: 0.0012458]
	Learning Rate: 0.00124577
	LOSS [training: 0.019027886213118947 | validation: 0.04723338737827601]
	TIME [epoch: 18.6 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017687766924223337		[learning rate: 0.0012377]
	Learning Rate: 0.00123775
	LOSS [training: 0.017687766924223337 | validation: 0.04874958471506185]
	TIME [epoch: 18.6 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01862711202839095		[learning rate: 0.0012298]
	Learning Rate: 0.00122977
	LOSS [training: 0.01862711202839095 | validation: 0.04756543736146032]
	TIME [epoch: 18.6 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018676725688272826		[learning rate: 0.0012218]
	Learning Rate: 0.00122185
	LOSS [training: 0.018676725688272826 | validation: 0.05214854999481245]
	TIME [epoch: 18.6 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018194995475599787		[learning rate: 0.001214]
	Learning Rate: 0.00121398
	LOSS [training: 0.018194995475599787 | validation: 0.051446669316632845]
	TIME [epoch: 18.6 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01775678771158614		[learning rate: 0.0012062]
	Learning Rate: 0.00120616
	LOSS [training: 0.01775678771158614 | validation: 0.048607883686364865]
	TIME [epoch: 18.6 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855136298943892		[learning rate: 0.0011984]
	Learning Rate: 0.00119839
	LOSS [training: 0.01855136298943892 | validation: 0.04767200751363719]
	TIME [epoch: 18.6 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020872810614639796		[learning rate: 0.0011907]
	Learning Rate: 0.00119066
	LOSS [training: 0.020872810614639796 | validation: 0.047244217070560104]
	TIME [epoch: 18.6 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017613511887648786		[learning rate: 0.001183]
	Learning Rate: 0.00118299
	LOSS [training: 0.017613511887648786 | validation: 0.05001514183447644]
	TIME [epoch: 18.6 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018515940248920504		[learning rate: 0.0011754]
	Learning Rate: 0.00117537
	LOSS [training: 0.018515940248920504 | validation: 0.04916770453102434]
	TIME [epoch: 18.6 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021716396441062977		[learning rate: 0.0011678]
	Learning Rate: 0.0011678
	LOSS [training: 0.021716396441062977 | validation: 0.05207118803495126]
	TIME [epoch: 18.6 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017416944645280385		[learning rate: 0.0011603]
	Learning Rate: 0.00116028
	LOSS [training: 0.017416944645280385 | validation: 0.051723054815813796]
	TIME [epoch: 18.6 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017766797187984976		[learning rate: 0.0011528]
	Learning Rate: 0.0011528
	LOSS [training: 0.017766797187984976 | validation: 0.0485675197773288]
	TIME [epoch: 18.6 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02061622524442267		[learning rate: 0.0011454]
	Learning Rate: 0.00114537
	LOSS [training: 0.02061622524442267 | validation: 0.04854080415317859]
	TIME [epoch: 18.6 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021968675535148186		[learning rate: 0.001138]
	Learning Rate: 0.00113799
	LOSS [training: 0.021968675535148186 | validation: 0.050335745293767074]
	TIME [epoch: 18.6 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017271315836393242		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.017271315836393242 | validation: 0.050017680485602845]
	TIME [epoch: 18.6 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017590923806188603		[learning rate: 0.0011234]
	Learning Rate: 0.00112338
	LOSS [training: 0.017590923806188603 | validation: 0.0498820703811174]
	TIME [epoch: 18.6 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017487949742155597		[learning rate: 0.0011161]
	Learning Rate: 0.00111614
	LOSS [training: 0.017487949742155597 | validation: 0.04763024015159496]
	TIME [epoch: 18.6 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016973736198574774		[learning rate: 0.001109]
	Learning Rate: 0.00110895
	LOSS [training: 0.016973736198574774 | validation: 0.05266574022685205]
	TIME [epoch: 18.6 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01929910052832692		[learning rate: 0.0011018]
	Learning Rate: 0.00110181
	LOSS [training: 0.01929910052832692 | validation: 0.049230255138351275]
	TIME [epoch: 18.6 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018072117290899137		[learning rate: 0.0010947]
	Learning Rate: 0.00109471
	LOSS [training: 0.018072117290899137 | validation: 0.04946689689670476]
	TIME [epoch: 18.6 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018852008834467526		[learning rate: 0.0010877]
	Learning Rate: 0.00108766
	LOSS [training: 0.018852008834467526 | validation: 0.04906404605912192]
	TIME [epoch: 18.6 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018605108453621483		[learning rate: 0.0010806]
	Learning Rate: 0.00108065
	LOSS [training: 0.018605108453621483 | validation: 0.048820942889863515]
	TIME [epoch: 18.6 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018699761832053574		[learning rate: 0.0010737]
	Learning Rate: 0.00107369
	LOSS [training: 0.018699761832053574 | validation: 0.048891287477251036]
	TIME [epoch: 18.6 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017065009186312527		[learning rate: 0.0010668]
	Learning Rate: 0.00106677
	LOSS [training: 0.017065009186312527 | validation: 0.05226136357419475]
	TIME [epoch: 18.6 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017864450392382242		[learning rate: 0.0010599]
	Learning Rate: 0.0010599
	LOSS [training: 0.017864450392382242 | validation: 0.04994572881365893]
	TIME [epoch: 18.6 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02158165101181428		[learning rate: 0.0010531]
	Learning Rate: 0.00105307
	LOSS [training: 0.02158165101181428 | validation: 0.04979110175307644]
	TIME [epoch: 18.6 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01847683250777032		[learning rate: 0.0010463]
	Learning Rate: 0.00104628
	LOSS [training: 0.01847683250777032 | validation: 0.04984305249615277]
	TIME [epoch: 18.6 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01885787298940661		[learning rate: 0.0010395]
	Learning Rate: 0.00103954
	LOSS [training: 0.01885787298940661 | validation: 0.04838574200385526]
	TIME [epoch: 18.6 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016566889800190363		[learning rate: 0.0010328]
	Learning Rate: 0.00103284
	LOSS [training: 0.016566889800190363 | validation: 0.048467303463779025]
	TIME [epoch: 18.6 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01897934630298563		[learning rate: 0.0010262]
	Learning Rate: 0.00102619
	LOSS [training: 0.01897934630298563 | validation: 0.05128436724648606]
	TIME [epoch: 18.6 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017088548119619133		[learning rate: 0.0010196]
	Learning Rate: 0.00101958
	LOSS [training: 0.017088548119619133 | validation: 0.054510488585167265]
	TIME [epoch: 18.6 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01755619297482359		[learning rate: 0.001013]
	Learning Rate: 0.00101301
	LOSS [training: 0.01755619297482359 | validation: 0.05017346138931209]
	TIME [epoch: 18.6 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017308422050396163		[learning rate: 0.0010065]
	Learning Rate: 0.00100648
	LOSS [training: 0.017308422050396163 | validation: 0.04960824179720409]
	TIME [epoch: 18.6 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019553634148828665		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.019553634148828665 | validation: 0.04789798304784066]
	TIME [epoch: 18.6 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017780832005541987		[learning rate: 0.00099356]
	Learning Rate: 0.000993557
	LOSS [training: 0.017780832005541987 | validation: 0.051978383929796215]
	TIME [epoch: 18.6 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016326595201331718		[learning rate: 0.00098716]
	Learning Rate: 0.000987156
	LOSS [training: 0.016326595201331718 | validation: 0.04711854883519749]
	TIME [epoch: 18.6 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01759211895379101		[learning rate: 0.0009808]
	Learning Rate: 0.000980797
	LOSS [training: 0.01759211895379101 | validation: 0.050722424108669326]
	TIME [epoch: 18.6 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017488179207892866		[learning rate: 0.00097448]
	Learning Rate: 0.000974478
	LOSS [training: 0.017488179207892866 | validation: 0.049340298591163775]
	TIME [epoch: 18.6 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017703581970443732		[learning rate: 0.0009682]
	Learning Rate: 0.0009682
	LOSS [training: 0.017703581970443732 | validation: 0.04764970307989585]
	TIME [epoch: 18.6 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016968811145028257		[learning rate: 0.00096196]
	Learning Rate: 0.000961962
	LOSS [training: 0.016968811145028257 | validation: 0.05005116309876022]
	TIME [epoch: 18.6 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01921383417515829		[learning rate: 0.00095576]
	Learning Rate: 0.000955764
	LOSS [training: 0.01921383417515829 | validation: 0.05047943602008941]
	TIME [epoch: 18.6 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01859997729695066		[learning rate: 0.00094961]
	Learning Rate: 0.000949607
	LOSS [training: 0.01859997729695066 | validation: 0.05014642602831176]
	TIME [epoch: 18.6 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01679840744844402		[learning rate: 0.00094349]
	Learning Rate: 0.000943489
	LOSS [training: 0.01679840744844402 | validation: 0.050629447958316906]
	TIME [epoch: 18.6 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016818024431833757		[learning rate: 0.00093741]
	Learning Rate: 0.00093741
	LOSS [training: 0.016818024431833757 | validation: 0.04865640088173419]
	TIME [epoch: 18.6 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02028511079629284		[learning rate: 0.00093137]
	Learning Rate: 0.000931371
	LOSS [training: 0.02028511079629284 | validation: 0.04669058395280318]
	TIME [epoch: 18.6 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01799501558448246		[learning rate: 0.00092537]
	Learning Rate: 0.000925371
	LOSS [training: 0.01799501558448246 | validation: 0.048735138132164235]
	TIME [epoch: 18.6 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01931964419065063		[learning rate: 0.00091941]
	Learning Rate: 0.000919409
	LOSS [training: 0.01931964419065063 | validation: 0.05121286052996906]
	TIME [epoch: 18.6 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876555491543818		[learning rate: 0.00091349]
	Learning Rate: 0.000913486
	LOSS [training: 0.01876555491543818 | validation: 0.04966530717777446]
	TIME [epoch: 18.6 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01765319037364368		[learning rate: 0.0009076]
	Learning Rate: 0.0009076
	LOSS [training: 0.01765319037364368 | validation: 0.05115112244269648]
	TIME [epoch: 18.6 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017933833869231808		[learning rate: 0.00090175]
	Learning Rate: 0.000901753
	LOSS [training: 0.017933833869231808 | validation: 0.051785994032344365]
	TIME [epoch: 18.6 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020544044325785573		[learning rate: 0.00089594]
	Learning Rate: 0.000895943
	LOSS [training: 0.020544044325785573 | validation: 0.04800767164778552]
	TIME [epoch: 18.6 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752807952469869		[learning rate: 0.00089017]
	Learning Rate: 0.000890171
	LOSS [training: 0.01752807952469869 | validation: 0.05090540841075891]
	TIME [epoch: 18.6 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018887547608681565		[learning rate: 0.00088444]
	Learning Rate: 0.000884436
	LOSS [training: 0.018887547608681565 | validation: 0.04765265621768186]
	TIME [epoch: 18.6 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017780314534215556		[learning rate: 0.00087874]
	Learning Rate: 0.000878738
	LOSS [training: 0.017780314534215556 | validation: 0.05536792927648777]
	TIME [epoch: 18.6 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016898103861370077		[learning rate: 0.00087308]
	Learning Rate: 0.000873077
	LOSS [training: 0.016898103861370077 | validation: 0.04752446074511223]
	TIME [epoch: 18.6 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118400910040702		[learning rate: 0.00086745]
	Learning Rate: 0.000867452
	LOSS [training: 0.02118400910040702 | validation: 0.048939014058386805]
	TIME [epoch: 18.6 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855045764046209		[learning rate: 0.00086186]
	Learning Rate: 0.000861864
	LOSS [training: 0.01855045764046209 | validation: 0.04977900098029386]
	TIME [epoch: 18.6 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019226485100368403		[learning rate: 0.00085631]
	Learning Rate: 0.000856311
	LOSS [training: 0.019226485100368403 | validation: 0.051049030484283504]
	TIME [epoch: 18.6 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016278031929956086		[learning rate: 0.00085079]
	Learning Rate: 0.000850794
	LOSS [training: 0.016278031929956086 | validation: 0.049285684649282124]
	TIME [epoch: 18.6 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016598529980866538		[learning rate: 0.00084531]
	Learning Rate: 0.000845313
	LOSS [training: 0.016598529980866538 | validation: 0.0485335629756375]
	TIME [epoch: 18.6 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01685445595107831		[learning rate: 0.00083987]
	Learning Rate: 0.000839867
	LOSS [training: 0.01685445595107831 | validation: 0.05125479959290352]
	TIME [epoch: 18.6 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733589194354079		[learning rate: 0.00083446]
	Learning Rate: 0.000834456
	LOSS [training: 0.01733589194354079 | validation: 0.048107020209730636]
	TIME [epoch: 18.6 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01770879152402437		[learning rate: 0.00082908]
	Learning Rate: 0.00082908
	LOSS [training: 0.01770879152402437 | validation: 0.04898753072260491]
	TIME [epoch: 18.6 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01841419638793397		[learning rate: 0.00082374]
	Learning Rate: 0.000823739
	LOSS [training: 0.01841419638793397 | validation: 0.051623950102761135]
	TIME [epoch: 18.6 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020058339276658014		[learning rate: 0.00081843]
	Learning Rate: 0.000818432
	LOSS [training: 0.020058339276658014 | validation: 0.04915255155942025]
	TIME [epoch: 18.6 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019812149967838172		[learning rate: 0.00081316]
	Learning Rate: 0.000813159
	LOSS [training: 0.019812149967838172 | validation: 0.04908208478096608]
	TIME [epoch: 18.6 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01738544562373285		[learning rate: 0.00080792]
	Learning Rate: 0.00080792
	LOSS [training: 0.01738544562373285 | validation: 0.04942847346601971]
	TIME [epoch: 18.6 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017336871019739027		[learning rate: 0.00080272]
	Learning Rate: 0.000802715
	LOSS [training: 0.017336871019739027 | validation: 0.05003431568430884]
	TIME [epoch: 18.6 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019544372983193795		[learning rate: 0.00079754]
	Learning Rate: 0.000797544
	LOSS [training: 0.019544372983193795 | validation: 0.049430020008300726]
	TIME [epoch: 18.6 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016160609896721082		[learning rate: 0.00079241]
	Learning Rate: 0.000792405
	LOSS [training: 0.016160609896721082 | validation: 0.05211532080626736]
	TIME [epoch: 18.6 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0173121213110489		[learning rate: 0.0007873]
	Learning Rate: 0.0007873
	LOSS [training: 0.0173121213110489 | validation: 0.04835380512404976]
	TIME [epoch: 18.6 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017141110310527525		[learning rate: 0.00078223]
	Learning Rate: 0.000782228
	LOSS [training: 0.017141110310527525 | validation: 0.04975869889180267]
	TIME [epoch: 18.6 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01685429413780241		[learning rate: 0.00077719]
	Learning Rate: 0.000777188
	LOSS [training: 0.01685429413780241 | validation: 0.04808769225571176]
	TIME [epoch: 18.6 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01561883471998247		[learning rate: 0.00077218]
	Learning Rate: 0.000772181
	LOSS [training: 0.01561883471998247 | validation: 0.05054006923578546]
	TIME [epoch: 18.6 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019014800546227843		[learning rate: 0.00076721]
	Learning Rate: 0.000767206
	LOSS [training: 0.019014800546227843 | validation: 0.051893498372279384]
	TIME [epoch: 18.6 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01738550538706501		[learning rate: 0.00076226]
	Learning Rate: 0.000762264
	LOSS [training: 0.01738550538706501 | validation: 0.048842787552803454]
	TIME [epoch: 18.6 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018386454742597542		[learning rate: 0.00075735]
	Learning Rate: 0.000757353
	LOSS [training: 0.018386454742597542 | validation: 0.050146077768874454]
	TIME [epoch: 18.6 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018993416560813416		[learning rate: 0.00075247]
	Learning Rate: 0.000752473
	LOSS [training: 0.018993416560813416 | validation: 0.04983247923972883]
	TIME [epoch: 18.6 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018385004705796154		[learning rate: 0.00074763]
	Learning Rate: 0.000747626
	LOSS [training: 0.018385004705796154 | validation: 0.04863630649127709]
	TIME [epoch: 18.6 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016958464821406997		[learning rate: 0.00074281]
	Learning Rate: 0.000742809
	LOSS [training: 0.016958464821406997 | validation: 0.051737031381271906]
	TIME [epoch: 18.6 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812290294778368		[learning rate: 0.00073802]
	Learning Rate: 0.000738023
	LOSS [training: 0.01812290294778368 | validation: 0.04954469482516104]
	TIME [epoch: 18.6 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0169285495892477		[learning rate: 0.00073327]
	Learning Rate: 0.000733269
	LOSS [training: 0.0169285495892477 | validation: 0.050869778865461825]
	TIME [epoch: 18.6 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01783322291051498		[learning rate: 0.00072854]
	Learning Rate: 0.000728544
	LOSS [training: 0.01783322291051498 | validation: 0.04903922988045776]
	TIME [epoch: 18.6 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019216467938709805		[learning rate: 0.00072385]
	Learning Rate: 0.000723851
	LOSS [training: 0.019216467938709805 | validation: 0.051444270512914066]
	TIME [epoch: 18.6 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018575823397406637		[learning rate: 0.00071919]
	Learning Rate: 0.000719187
	LOSS [training: 0.018575823397406637 | validation: 0.049972156480965986]
	TIME [epoch: 18.6 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017943526579175962		[learning rate: 0.00071455]
	Learning Rate: 0.000714554
	LOSS [training: 0.017943526579175962 | validation: 0.048821928576846446]
	TIME [epoch: 18.6 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742789076064738		[learning rate: 0.00070995]
	Learning Rate: 0.00070995
	LOSS [training: 0.01742789076064738 | validation: 0.04962977557290801]
	TIME [epoch: 18.6 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019286795955495435		[learning rate: 0.00070538]
	Learning Rate: 0.000705377
	LOSS [training: 0.019286795955495435 | validation: 0.0510934617873857]
	TIME [epoch: 18.6 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017095392146277068		[learning rate: 0.00070083]
	Learning Rate: 0.000700832
	LOSS [training: 0.017095392146277068 | validation: 0.049857677917201935]
	TIME [epoch: 18.6 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016797806142734614		[learning rate: 0.00069632]
	Learning Rate: 0.000696317
	LOSS [training: 0.016797806142734614 | validation: 0.04873988063801332]
	TIME [epoch: 18.6 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018655895347648298		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.018655895347648298 | validation: 0.04771629977849965]
	TIME [epoch: 18.6 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02004628105350326		[learning rate: 0.00068737]
	Learning Rate: 0.000687374
	LOSS [training: 0.02004628105350326 | validation: 0.053570988586451915]
	TIME [epoch: 18.6 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02032749564739884		[learning rate: 0.00068295]
	Learning Rate: 0.000682945
	LOSS [training: 0.02032749564739884 | validation: 0.04730478122302999]
	TIME [epoch: 18.6 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021959649041309433		[learning rate: 0.00067855]
	Learning Rate: 0.000678545
	LOSS [training: 0.021959649041309433 | validation: 0.05292086595361239]
	TIME [epoch: 18.6 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017196688358851443		[learning rate: 0.00067417]
	Learning Rate: 0.000674174
	LOSS [training: 0.017196688358851443 | validation: 0.04908483430019741]
	TIME [epoch: 18.6 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016798585325199733		[learning rate: 0.00066983]
	Learning Rate: 0.00066983
	LOSS [training: 0.016798585325199733 | validation: 0.05065201256910999]
	TIME [epoch: 18.6 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016274394340521674		[learning rate: 0.00066552]
	Learning Rate: 0.000665515
	LOSS [training: 0.016274394340521674 | validation: 0.04896587986707039]
	TIME [epoch: 18.6 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017471144609323856		[learning rate: 0.00066123]
	Learning Rate: 0.000661227
	LOSS [training: 0.017471144609323856 | validation: 0.04934120952751814]
	TIME [epoch: 18.6 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017219507597875047		[learning rate: 0.00065697]
	Learning Rate: 0.000656967
	LOSS [training: 0.017219507597875047 | validation: 0.05075036604112281]
	TIME [epoch: 18.6 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01822428519869384		[learning rate: 0.00065273]
	Learning Rate: 0.000652735
	LOSS [training: 0.01822428519869384 | validation: 0.05050280219198915]
	TIME [epoch: 18.6 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017329370599911652		[learning rate: 0.00064853]
	Learning Rate: 0.00064853
	LOSS [training: 0.017329370599911652 | validation: 0.04613434920165031]
	TIME [epoch: 18.6 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02033409345062745		[learning rate: 0.00064435]
	Learning Rate: 0.000644351
	LOSS [training: 0.02033409345062745 | validation: 0.05060466280723364]
	TIME [epoch: 18.6 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019627184328724102		[learning rate: 0.0006402]
	Learning Rate: 0.0006402
	LOSS [training: 0.019627184328724102 | validation: 0.0506515976800458]
	TIME [epoch: 18.6 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018084130448621682		[learning rate: 0.00063608]
	Learning Rate: 0.000636076
	LOSS [training: 0.018084130448621682 | validation: 0.0498762239071643]
	TIME [epoch: 18.6 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018939135242939414		[learning rate: 0.00063198]
	Learning Rate: 0.000631978
	LOSS [training: 0.018939135242939414 | validation: 0.04788883851970977]
	TIME [epoch: 18.6 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01714384191942603		[learning rate: 0.00062791]
	Learning Rate: 0.000627906
	LOSS [training: 0.01714384191942603 | validation: 0.04929210915637758]
	TIME [epoch: 18.6 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017190197219622873		[learning rate: 0.00062386]
	Learning Rate: 0.000623861
	LOSS [training: 0.017190197219622873 | validation: 0.04985895074964036]
	TIME [epoch: 18.6 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018052961021576597		[learning rate: 0.00061984]
	Learning Rate: 0.000619842
	LOSS [training: 0.018052961021576597 | validation: 0.05116235008237686]
	TIME [epoch: 18.6 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01789620507919587		[learning rate: 0.00061585]
	Learning Rate: 0.000615848
	LOSS [training: 0.01789620507919587 | validation: 0.05027924875649113]
	TIME [epoch: 18.6 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019022769742808105		[learning rate: 0.00061188]
	Learning Rate: 0.000611881
	LOSS [training: 0.019022769742808105 | validation: 0.047281078802717945]
	TIME [epoch: 18.6 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01780803481017809		[learning rate: 0.00060794]
	Learning Rate: 0.000607938
	LOSS [training: 0.01780803481017809 | validation: 0.04828274862967702]
	TIME [epoch: 18.6 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0182904172763576		[learning rate: 0.00060402]
	Learning Rate: 0.000604022
	LOSS [training: 0.0182904172763576 | validation: 0.04950995145542426]
	TIME [epoch: 18.6 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015927031821940385		[learning rate: 0.00060013]
	Learning Rate: 0.00060013
	LOSS [training: 0.015927031821940385 | validation: 0.048977212108478774]
	TIME [epoch: 18.6 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018995956934103234		[learning rate: 0.00059626]
	Learning Rate: 0.000596264
	LOSS [training: 0.018995956934103234 | validation: 0.048426145396784116]
	TIME [epoch: 18.6 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017837053217289716		[learning rate: 0.00059242]
	Learning Rate: 0.000592422
	LOSS [training: 0.017837053217289716 | validation: 0.049107800221033275]
	TIME [epoch: 18.6 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019403369814278974		[learning rate: 0.00058861]
	Learning Rate: 0.000588606
	LOSS [training: 0.019403369814278974 | validation: 0.05026365579764893]
	TIME [epoch: 18.6 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018472350395793567		[learning rate: 0.00058481]
	Learning Rate: 0.000584814
	LOSS [training: 0.018472350395793567 | validation: 0.04976136028923979]
	TIME [epoch: 18.6 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017032981303034888		[learning rate: 0.00058105]
	Learning Rate: 0.000581046
	LOSS [training: 0.017032981303034888 | validation: 0.04971177678921464]
	TIME [epoch: 18.6 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017982576483124207		[learning rate: 0.0005773]
	Learning Rate: 0.000577302
	LOSS [training: 0.017982576483124207 | validation: 0.047842096213976476]
	TIME [epoch: 18.6 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01688556926175891		[learning rate: 0.00057358]
	Learning Rate: 0.000573583
	LOSS [training: 0.01688556926175891 | validation: 0.048785557111987586]
	TIME [epoch: 18.6 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01974469790631224		[learning rate: 0.00056989]
	Learning Rate: 0.000569888
	LOSS [training: 0.01974469790631224 | validation: 0.04785097702784344]
	TIME [epoch: 18.6 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017090501212874115		[learning rate: 0.00056622]
	Learning Rate: 0.000566216
	LOSS [training: 0.017090501212874115 | validation: 0.05187917627470729]
	TIME [epoch: 18.6 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017972100073656433		[learning rate: 0.00056257]
	Learning Rate: 0.000562568
	LOSS [training: 0.017972100073656433 | validation: 0.04805921774669557]
	TIME [epoch: 18.6 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017421036343014052		[learning rate: 0.00055894]
	Learning Rate: 0.000558944
	LOSS [training: 0.017421036343014052 | validation: 0.05120225883862306]
	TIME [epoch: 18.6 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01598401149757103		[learning rate: 0.00055534]
	Learning Rate: 0.000555343
	LOSS [training: 0.01598401149757103 | validation: 0.05018453140045592]
	TIME [epoch: 18.6 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019436648644283464		[learning rate: 0.00055177]
	Learning Rate: 0.000551765
	LOSS [training: 0.019436648644283464 | validation: 0.04972548293466064]
	TIME [epoch: 18.6 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018032278641493652		[learning rate: 0.00054821]
	Learning Rate: 0.00054821
	LOSS [training: 0.018032278641493652 | validation: 0.04883292933594048]
	TIME [epoch: 18.6 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017156178247443036		[learning rate: 0.00054468]
	Learning Rate: 0.000544679
	LOSS [training: 0.017156178247443036 | validation: 0.05092000957083369]
	TIME [epoch: 18.6 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01835678267659978		[learning rate: 0.00054117]
	Learning Rate: 0.000541169
	LOSS [training: 0.01835678267659978 | validation: 0.04774584597979305]
	TIME [epoch: 18.6 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01664596304087616		[learning rate: 0.00053768]
	Learning Rate: 0.000537683
	LOSS [training: 0.01664596304087616 | validation: 0.04966065912389478]
	TIME [epoch: 18.6 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017235688285685148		[learning rate: 0.00053422]
	Learning Rate: 0.000534219
	LOSS [training: 0.017235688285685148 | validation: 0.049734888648605244]
	TIME [epoch: 18.6 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01897763399014032		[learning rate: 0.00053078]
	Learning Rate: 0.000530777
	LOSS [training: 0.01897763399014032 | validation: 0.04869951555820593]
	TIME [epoch: 18.6 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017449840723418146		[learning rate: 0.00052736]
	Learning Rate: 0.000527358
	LOSS [training: 0.017449840723418146 | validation: 0.048407446632558145]
	TIME [epoch: 18.6 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016324424289525043		[learning rate: 0.00052396]
	Learning Rate: 0.00052396
	LOSS [training: 0.016324424289525043 | validation: 0.05235487909855971]
	TIME [epoch: 18.6 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016116347943235854		[learning rate: 0.00052058]
	Learning Rate: 0.000520584
	LOSS [training: 0.016116347943235854 | validation: 0.04893822117764569]
	TIME [epoch: 18.6 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02094178534411339		[learning rate: 0.00051723]
	Learning Rate: 0.000517231
	LOSS [training: 0.02094178534411339 | validation: 0.05056000164991236]
	TIME [epoch: 18.6 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0159661604948805		[learning rate: 0.0005139]
	Learning Rate: 0.000513898
	LOSS [training: 0.0159661604948805 | validation: 0.048253995238396415]
	TIME [epoch: 18.6 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016272167761699072		[learning rate: 0.00051059]
	Learning Rate: 0.000510587
	LOSS [training: 0.016272167761699072 | validation: 0.05177861165367766]
	TIME [epoch: 18.6 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017788212636358162		[learning rate: 0.0005073]
	Learning Rate: 0.000507298
	LOSS [training: 0.017788212636358162 | validation: 0.049367589423054296]
	TIME [epoch: 18.6 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01680982468763081		[learning rate: 0.00050403]
	Learning Rate: 0.00050403
	LOSS [training: 0.01680982468763081 | validation: 0.04923301306218883]
	TIME [epoch: 18.6 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020550177233479426		[learning rate: 0.00050078]
	Learning Rate: 0.000500782
	LOSS [training: 0.020550177233479426 | validation: 0.04817570542365283]
	TIME [epoch: 84.2 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01943088146397056		[learning rate: 0.00049756]
	Learning Rate: 0.000497556
	LOSS [training: 0.01943088146397056 | validation: 0.05054991535196208]
	TIME [epoch: 39.2 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01751173072776548		[learning rate: 0.00049435]
	Learning Rate: 0.000494351
	LOSS [training: 0.01751173072776548 | validation: 0.050731694693922094]
	TIME [epoch: 39.2 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018027043317451655		[learning rate: 0.00049117]
	Learning Rate: 0.000491166
	LOSS [training: 0.018027043317451655 | validation: 0.048015195443845436]
	TIME [epoch: 39.2 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018302521587474495		[learning rate: 0.000488]
	Learning Rate: 0.000488001
	LOSS [training: 0.018302521587474495 | validation: 0.049170159512567056]
	TIME [epoch: 39.2 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017935510895310362		[learning rate: 0.00048486]
	Learning Rate: 0.000484857
	LOSS [training: 0.017935510895310362 | validation: 0.04977716313555202]
	TIME [epoch: 39.2 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018919067834663104		[learning rate: 0.00048173]
	Learning Rate: 0.000481734
	LOSS [training: 0.018919067834663104 | validation: 0.048801636450941134]
	TIME [epoch: 39.2 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0166765905185825		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.0166765905185825 | validation: 0.050222827265367344]
	TIME [epoch: 39.2 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01964187351364304		[learning rate: 0.00047555]
	Learning Rate: 0.000475546
	LOSS [training: 0.01964187351364304 | validation: 0.05018559953114129]
	TIME [epoch: 39.2 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_151954/states/model_facs_dec2_v1_argset3_509.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 6510.313 seconds.
