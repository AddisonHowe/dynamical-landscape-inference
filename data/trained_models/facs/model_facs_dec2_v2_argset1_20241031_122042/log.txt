Args:
Namespace(name='model_facs_dec2_v2_argset1', outdir='out/model_training/model_facs_dec2_v2_argset1', training_data='data/training_data/facs/facs_dec2_v2/training', validation_data='data/training_data/facs/facs_dec2_v2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 467355111

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8485926721901387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8485926721901387 | validation: 1.4728672742062343]
	TIME [epoch: 46.7 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1818852924891043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1818852924891043 | validation: 1.1214911788463016]
	TIME [epoch: 5.07 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7881912004257771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7881912004257771 | validation: 1.0106221346276667]
	TIME [epoch: 5.02 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7500998117716859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7500998117716859 | validation: 0.8005918720143824]
	TIME [epoch: 5 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.561300964195697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.561300964195697 | validation: 0.7283232206044158]
	TIME [epoch: 5.02 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5500274155014383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5500274155014383 | validation: 0.48056431075919687]
	TIME [epoch: 5.02 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.40451323226901426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40451323226901426 | validation: 0.37116251511774956]
	TIME [epoch: 5 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.30972680993937207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30972680993937207 | validation: 0.3133700645170395]
	TIME [epoch: 5.02 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.23843989597963403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23843989597963403 | validation: 0.25846433142192]
	TIME [epoch: 5.02 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2023903135443809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2023903135443809 | validation: 0.2676193991182923]
	TIME [epoch: 5 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.19891109014603128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19891109014603128 | validation: 0.1852620879038401]
	TIME [epoch: 5 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13101389976386324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13101389976386324 | validation: 0.19633752688443995]
	TIME [epoch: 5 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13465286279109379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13465286279109379 | validation: 0.17844813002145182]
	TIME [epoch: 5 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067108411454695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1067108411454695 | validation: 0.17324401809757584]
	TIME [epoch: 4.99 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687738123647412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08687738123647412 | validation: 0.17923908010060188]
	TIME [epoch: 5.01 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243477753471258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08243477753471258 | validation: 0.20597449838353762]
	TIME [epoch: 4.98 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846527594816306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08846527594816306 | validation: 0.2640052510513304]
	TIME [epoch: 4.99 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017430867747632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11017430867747632 | validation: 0.19826946364626866]
	TIME [epoch: 4.99 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07828699064453015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07828699064453015 | validation: 0.1936130801579089]
	TIME [epoch: 5 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07583704791411888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07583704791411888 | validation: 0.19496882241892974]
	TIME [epoch: 4.99 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714961827016622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09714961827016622 | validation: 0.24870596586970434]
	TIME [epoch: 4.99 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1254413578854242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1254413578854242 | validation: 0.20510105487655733]
	TIME [epoch: 4.99 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09722950942577673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09722950942577673 | validation: 0.18860990282008652]
	TIME [epoch: 4.99 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08871898266307852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08871898266307852 | validation: 0.20880821511851255]
	TIME [epoch: 4.98 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08064205787772112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08064205787772112 | validation: 0.18990487151551053]
	TIME [epoch: 4.98 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09027037052806212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09027037052806212 | validation: 0.19618819687771272]
	TIME [epoch: 4.98 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022174336579583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09022174336579583 | validation: 0.19481943592344245]
	TIME [epoch: 5 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.084979476516485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.084979476516485 | validation: 0.2214744831480079]
	TIME [epoch: 5.01 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846938663501201		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08846938663501201 | validation: 0.21539492314627945]
	TIME [epoch: 5.01 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671826356636527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10671826356636527 | validation: 0.20973073546537785]
	TIME [epoch: 5 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08291388658597003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08291388658597003 | validation: 0.19992908835208661]
	TIME [epoch: 4.99 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0743883028226391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0743883028226391 | validation: 0.1907143908264304]
	TIME [epoch: 4.98 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08125542318818389		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08125542318818389 | validation: 0.20299194389232833]
	TIME [epoch: 5 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09203161934875835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09203161934875835 | validation: 0.20113613265960417]
	TIME [epoch: 5.01 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08670369566835527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08670369566835527 | validation: 0.20283102957800644]
	TIME [epoch: 5 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0876920981283088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0876920981283088 | validation: 0.20891242814132965]
	TIME [epoch: 5 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08389451251100855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08389451251100855 | validation: 0.23778433838455781]
	TIME [epoch: 5 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09458701853080262		[learning rate: 0.0099758]
	Learning Rate: 0.00997579
	LOSS [training: 0.09458701853080262 | validation: 0.2009480797126082]
	TIME [epoch: 5 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07296671551054436		[learning rate: 0.0098795]
	Learning Rate: 0.00987954
	LOSS [training: 0.07296671551054436 | validation: 0.2192760554260662]
	TIME [epoch: 5 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623173226116354		[learning rate: 0.0097842]
	Learning Rate: 0.00978422
	LOSS [training: 0.08623173226116354 | validation: 0.20921697202773648]
	TIME [epoch: 5.02 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061752257275379		[learning rate: 0.0096898]
	Learning Rate: 0.00968982
	LOSS [training: 0.08061752257275379 | validation: 0.19378445457014426]
	TIME [epoch: 5.02 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07742946575123094		[learning rate: 0.0095963]
	Learning Rate: 0.00959633
	LOSS [training: 0.07742946575123094 | validation: 0.1938093313608273]
	TIME [epoch: 5.02 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348034919347776		[learning rate: 0.0095037]
	Learning Rate: 0.00950374
	LOSS [training: 0.08348034919347776 | validation: 0.20924532226090925]
	TIME [epoch: 5.01 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09985198136657622		[learning rate: 0.009412]
	Learning Rate: 0.00941205
	LOSS [training: 0.09985198136657622 | validation: 0.18926318726516297]
	TIME [epoch: 5.01 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08087043917199624		[learning rate: 0.0093212]
	Learning Rate: 0.00932124
	LOSS [training: 0.08087043917199624 | validation: 0.19562316328834636]
	TIME [epoch: 5 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08537472302547103		[learning rate: 0.0092313]
	Learning Rate: 0.00923131
	LOSS [training: 0.08537472302547103 | validation: 0.2310086564288415]
	TIME [epoch: 5.01 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111018945935061		[learning rate: 0.0091422]
	Learning Rate: 0.00914224
	LOSS [training: 0.08111018945935061 | validation: 0.2152825425438187]
	TIME [epoch: 5 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093508430503135		[learning rate: 0.009054]
	Learning Rate: 0.00905403
	LOSS [training: 0.09093508430503135 | validation: 0.19941553679105653]
	TIME [epoch: 5.03 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0783394279103103		[learning rate: 0.0089667]
	Learning Rate: 0.00896668
	LOSS [training: 0.0783394279103103 | validation: 0.1915268525579709]
	TIME [epoch: 5 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09657355951263663		[learning rate: 0.0088802]
	Learning Rate: 0.00888017
	LOSS [training: 0.09657355951263663 | validation: 0.2041716150967989]
	TIME [epoch: 5 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07616964945228652		[learning rate: 0.0087945]
	Learning Rate: 0.00879449
	LOSS [training: 0.07616964945228652 | validation: 0.21160182494240498]
	TIME [epoch: 49.4 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785497470169659		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.0785497470169659 | validation: 0.19300665307279588]
	TIME [epoch: 9.53 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08927313582358383		[learning rate: 0.0086256]
	Learning Rate: 0.0086256
	LOSS [training: 0.08927313582358383 | validation: 0.2072603767953197]
	TIME [epoch: 9.51 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08757268256643541		[learning rate: 0.0085424]
	Learning Rate: 0.00854238
	LOSS [training: 0.08757268256643541 | validation: 0.19808254649950294]
	TIME [epoch: 9.52 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08563608451648078		[learning rate: 0.00846]
	Learning Rate: 0.00845996
	LOSS [training: 0.08563608451648078 | validation: 0.2179269903103504]
	TIME [epoch: 9.51 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08774439817030187		[learning rate: 0.0083783]
	Learning Rate: 0.00837834
	LOSS [training: 0.08774439817030187 | validation: 0.21908701266235622]
	TIME [epoch: 9.53 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0784136307241194		[learning rate: 0.0082975]
	Learning Rate: 0.0082975
	LOSS [training: 0.0784136307241194 | validation: 0.2059250426550476]
	TIME [epoch: 9.51 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08235257167020021		[learning rate: 0.0082174]
	Learning Rate: 0.00821745
	LOSS [training: 0.08235257167020021 | validation: 0.1943926414289464]
	TIME [epoch: 9.51 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08207893481632807		[learning rate: 0.0081382]
	Learning Rate: 0.00813816
	LOSS [training: 0.08207893481632807 | validation: 0.20114144420990443]
	TIME [epoch: 9.51 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799304839743561		[learning rate: 0.0080596]
	Learning Rate: 0.00805964
	LOSS [training: 0.06799304839743561 | validation: 0.20180585909917287]
	TIME [epoch: 9.5 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07442459265552304		[learning rate: 0.0079819]
	Learning Rate: 0.00798188
	LOSS [training: 0.07442459265552304 | validation: 0.19776116439395708]
	TIME [epoch: 9.52 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08016326384585479		[learning rate: 0.0079049]
	Learning Rate: 0.00790487
	LOSS [training: 0.08016326384585479 | validation: 0.20835825816858583]
	TIME [epoch: 9.53 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07992519229949037		[learning rate: 0.0078286]
	Learning Rate: 0.0078286
	LOSS [training: 0.07992519229949037 | validation: 0.19042459060105285]
	TIME [epoch: 9.54 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08571054796357586		[learning rate: 0.0077531]
	Learning Rate: 0.00775307
	LOSS [training: 0.08571054796357586 | validation: 0.21085142163057458]
	TIME [epoch: 9.51 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260158062598282		[learning rate: 0.0076783]
	Learning Rate: 0.00767827
	LOSS [training: 0.10260158062598282 | validation: 0.18852358007872877]
	TIME [epoch: 9.52 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540337225291864		[learning rate: 0.0076042]
	Learning Rate: 0.00760418
	LOSS [training: 0.07540337225291864 | validation: 0.22339315063428516]
	TIME [epoch: 9.55 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08067088116189808		[learning rate: 0.0075308]
	Learning Rate: 0.00753082
	LOSS [training: 0.08067088116189808 | validation: 0.20183866713347814]
	TIME [epoch: 9.52 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09047547820477386		[learning rate: 0.0074582]
	Learning Rate: 0.00745816
	LOSS [training: 0.09047547820477386 | validation: 0.20011069234376072]
	TIME [epoch: 9.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07304985407819706		[learning rate: 0.0073862]
	Learning Rate: 0.0073862
	LOSS [training: 0.07304985407819706 | validation: 0.20449683005529287]
	TIME [epoch: 9.5 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07854342195429537		[learning rate: 0.0073149]
	Learning Rate: 0.00731494
	LOSS [training: 0.07854342195429537 | validation: 0.19249723357944684]
	TIME [epoch: 9.52 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07523442979475382		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.07523442979475382 | validation: 0.19595639340492413]
	TIME [epoch: 9.51 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08844548159222225		[learning rate: 0.0071745]
	Learning Rate: 0.00717446
	LOSS [training: 0.08844548159222225 | validation: 0.18757248483665726]
	TIME [epoch: 9.5 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07876951607401336		[learning rate: 0.0071052]
	Learning Rate: 0.00710524
	LOSS [training: 0.07876951607401336 | validation: 0.23473679279123533]
	TIME [epoch: 9.5 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693536882519769		[learning rate: 0.0070367]
	Learning Rate: 0.00703669
	LOSS [training: 0.08693536882519769 | validation: 0.2017512454807771]
	TIME [epoch: 9.52 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07437041712979875		[learning rate: 0.0069688]
	Learning Rate: 0.0069688
	LOSS [training: 0.07437041712979875 | validation: 0.2124786131914939]
	TIME [epoch: 9.5 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09213783825856914		[learning rate: 0.0069016]
	Learning Rate: 0.00690156
	LOSS [training: 0.09213783825856914 | validation: 0.20021002796470552]
	TIME [epoch: 9.5 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07606184719396511		[learning rate: 0.006835]
	Learning Rate: 0.00683497
	LOSS [training: 0.07606184719396511 | validation: 0.20811378493361238]
	TIME [epoch: 9.51 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07615835903290699		[learning rate: 0.006769]
	Learning Rate: 0.00676903
	LOSS [training: 0.07615835903290699 | validation: 0.2093129360299201]
	TIME [epoch: 9.51 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252997109178999		[learning rate: 0.0067037]
	Learning Rate: 0.00670372
	LOSS [training: 0.08252997109178999 | validation: 0.1998666227497394]
	TIME [epoch: 9.51 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0752163315307636		[learning rate: 0.006639]
	Learning Rate: 0.00663904
	LOSS [training: 0.0752163315307636 | validation: 0.2091843607255151]
	TIME [epoch: 9.52 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966529295041919		[learning rate: 0.006575]
	Learning Rate: 0.00657498
	LOSS [training: 0.07966529295041919 | validation: 0.21901483427676738]
	TIME [epoch: 9.52 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994614113898743		[learning rate: 0.0065115]
	Learning Rate: 0.00651155
	LOSS [training: 0.08994614113898743 | validation: 0.19333722815825932]
	TIME [epoch: 9.53 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0736486305783539		[learning rate: 0.0064487]
	Learning Rate: 0.00644872
	LOSS [training: 0.0736486305783539 | validation: 0.2064687014697049]
	TIME [epoch: 9.51 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810130245007304		[learning rate: 0.0063865]
	Learning Rate: 0.0063865
	LOSS [training: 0.0810130245007304 | validation: 0.19754201757064233]
	TIME [epoch: 9.53 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222233953838641		[learning rate: 0.0063249]
	Learning Rate: 0.00632488
	LOSS [training: 0.08222233953838641 | validation: 0.19799473602492015]
	TIME [epoch: 9.54 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07488527863085229		[learning rate: 0.0062639]
	Learning Rate: 0.00626386
	LOSS [training: 0.07488527863085229 | validation: 0.18741636395103928]
	TIME [epoch: 9.52 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820261037900223		[learning rate: 0.0062034]
	Learning Rate: 0.00620343
	LOSS [training: 0.0820261037900223 | validation: 0.1896782806022264]
	TIME [epoch: 9.52 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869247561267577		[learning rate: 0.0061436]
	Learning Rate: 0.00614357
	LOSS [training: 0.06869247561267577 | validation: 0.2171545654612284]
	TIME [epoch: 9.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09548606347178781		[learning rate: 0.0060843]
	Learning Rate: 0.0060843
	LOSS [training: 0.09548606347178781 | validation: 0.19312462234878233]
	TIME [epoch: 9.53 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919438944704231		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.07919438944704231 | validation: 0.1954439217454626]
	TIME [epoch: 9.52 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805208570240091		[learning rate: 0.0059675]
	Learning Rate: 0.00596746
	LOSS [training: 0.07805208570240091 | validation: 0.2093467754327663]
	TIME [epoch: 9.51 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07369575326258034		[learning rate: 0.0059099]
	Learning Rate: 0.00590988
	LOSS [training: 0.07369575326258034 | validation: 0.18885625430681724]
	TIME [epoch: 9.49 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06887148469560793		[learning rate: 0.0058529]
	Learning Rate: 0.00585286
	LOSS [training: 0.06887148469560793 | validation: 0.1970726243791129]
	TIME [epoch: 9.53 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.077991463878201		[learning rate: 0.0057964]
	Learning Rate: 0.00579639
	LOSS [training: 0.077991463878201 | validation: 0.19144289643494647]
	TIME [epoch: 9.53 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07814177066928032		[learning rate: 0.0057405]
	Learning Rate: 0.00574047
	LOSS [training: 0.07814177066928032 | validation: 0.19063898927431902]
	TIME [epoch: 9.5 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08088539460042257		[learning rate: 0.0056851]
	Learning Rate: 0.00568508
	LOSS [training: 0.08088539460042257 | validation: 0.1933217584689002]
	TIME [epoch: 9.49 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07378731750726965		[learning rate: 0.0056302]
	Learning Rate: 0.00563023
	LOSS [training: 0.07378731750726965 | validation: 0.22685510667478623]
	TIME [epoch: 9.52 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08684359414912696		[learning rate: 0.0055759]
	Learning Rate: 0.00557591
	LOSS [training: 0.08684359414912696 | validation: 0.20006959365754026]
	TIME [epoch: 9.53 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07210470032541116		[learning rate: 0.0055221]
	Learning Rate: 0.00552211
	LOSS [training: 0.07210470032541116 | validation: 0.19664515804197544]
	TIME [epoch: 9.51 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0772330246438811		[learning rate: 0.0054688]
	Learning Rate: 0.00546883
	LOSS [training: 0.0772330246438811 | validation: 0.1937295749876457]
	TIME [epoch: 9.52 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819345041715637		[learning rate: 0.0054161]
	Learning Rate: 0.00541607
	LOSS [training: 0.0819345041715637 | validation: 0.1842120420937549]
	TIME [epoch: 59.8 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07707906988201998		[learning rate: 0.0053638]
	Learning Rate: 0.00536381
	LOSS [training: 0.07707906988201998 | validation: 0.19110719068573023]
	TIME [epoch: 20 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08105979218187813		[learning rate: 0.0053121]
	Learning Rate: 0.00531206
	LOSS [training: 0.08105979218187813 | validation: 0.1943068627632596]
	TIME [epoch: 19.9 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868783805263697		[learning rate: 0.0052608]
	Learning Rate: 0.00526081
	LOSS [training: 0.0868783805263697 | validation: 0.210055114911006]
	TIME [epoch: 20 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07664784639792346		[learning rate: 0.0052101]
	Learning Rate: 0.00521005
	LOSS [training: 0.07664784639792346 | validation: 0.19612344308751864]
	TIME [epoch: 19.9 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07333249212450338		[learning rate: 0.0051598]
	Learning Rate: 0.00515978
	LOSS [training: 0.07333249212450338 | validation: 0.2063782273406455]
	TIME [epoch: 19.9 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988603102152252		[learning rate: 0.00511]
	Learning Rate: 0.00511
	LOSS [training: 0.07988603102152252 | validation: 0.1905477467962321]
	TIME [epoch: 20 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168090563360187		[learning rate: 0.0050607]
	Learning Rate: 0.0050607
	LOSS [training: 0.07168090563360187 | validation: 0.20700627155820361]
	TIME [epoch: 19.9 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0771493686762118		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.0771493686762118 | validation: 0.1921233920789807]
	TIME [epoch: 19.9 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975063225677205		[learning rate: 0.0049635]
	Learning Rate: 0.00496352
	LOSS [training: 0.07975063225677205 | validation: 0.1910632496175724]
	TIME [epoch: 20 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08474558750356728		[learning rate: 0.0049156]
	Learning Rate: 0.00491563
	LOSS [training: 0.08474558750356728 | validation: 0.19062334046368806]
	TIME [epoch: 19.9 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07447090745669613		[learning rate: 0.0048682]
	Learning Rate: 0.0048682
	LOSS [training: 0.07447090745669613 | validation: 0.19571541755100524]
	TIME [epoch: 19.9 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757833089928365		[learning rate: 0.0048212]
	Learning Rate: 0.00482123
	LOSS [training: 0.07757833089928365 | validation: 0.19751877660004943]
	TIME [epoch: 19.9 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209407288716763		[learning rate: 0.0047747]
	Learning Rate: 0.00477471
	LOSS [training: 0.07209407288716763 | validation: 0.18786686070570371]
	TIME [epoch: 19.9 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789282487168353		[learning rate: 0.0047286]
	Learning Rate: 0.00472865
	LOSS [training: 0.0789282487168353 | validation: 0.19110682308325128]
	TIME [epoch: 19.9 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243766571351396		[learning rate: 0.004683]
	Learning Rate: 0.00468302
	LOSS [training: 0.08243766571351396 | validation: 0.18946965449093822]
	TIME [epoch: 19.9 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431871276742466		[learning rate: 0.0046378]
	Learning Rate: 0.00463784
	LOSS [training: 0.07431871276742466 | validation: 0.19331223590706798]
	TIME [epoch: 19.9 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07604224205711291		[learning rate: 0.0045931]
	Learning Rate: 0.00459309
	LOSS [training: 0.07604224205711291 | validation: 0.18596051284973425]
	TIME [epoch: 20 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07404433422230647		[learning rate: 0.0045488]
	Learning Rate: 0.00454878
	LOSS [training: 0.07404433422230647 | validation: 0.1836661392099392]
	TIME [epoch: 20 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07433639494483282		[learning rate: 0.0045049]
	Learning Rate: 0.00450489
	LOSS [training: 0.07433639494483282 | validation: 0.1834732772528131]
	TIME [epoch: 20 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08569192048536373		[learning rate: 0.0044614]
	Learning Rate: 0.00446143
	LOSS [training: 0.08569192048536373 | validation: 0.184725877948679]
	TIME [epoch: 19.9 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818992177511523		[learning rate: 0.0044184]
	Learning Rate: 0.00441838
	LOSS [training: 0.07818992177511523 | validation: 0.2267558099059191]
	TIME [epoch: 19.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09209881199357411		[learning rate: 0.0043758]
	Learning Rate: 0.00437575
	LOSS [training: 0.09209881199357411 | validation: 0.1902047466040236]
	TIME [epoch: 20 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532907370238424		[learning rate: 0.0043335]
	Learning Rate: 0.00433353
	LOSS [training: 0.07532907370238424 | validation: 0.18898092999946692]
	TIME [epoch: 19.9 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07757913032280696		[learning rate: 0.0042917]
	Learning Rate: 0.00429172
	LOSS [training: 0.07757913032280696 | validation: 0.1840437301625263]
	TIME [epoch: 19.9 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07709828104112218		[learning rate: 0.0042503]
	Learning Rate: 0.00425031
	LOSS [training: 0.07709828104112218 | validation: 0.19354858992526774]
	TIME [epoch: 19.9 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08315229908979993		[learning rate: 0.0042093]
	Learning Rate: 0.00420931
	LOSS [training: 0.08315229908979993 | validation: 0.19143936484669505]
	TIME [epoch: 20 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09206353175794915		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.09206353175794915 | validation: 0.1864908573487119]
	TIME [epoch: 20 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08536916056360563		[learning rate: 0.0041285]
	Learning Rate: 0.00412847
	LOSS [training: 0.08536916056360563 | validation: 0.18842009826615289]
	TIME [epoch: 20 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08172827565098104		[learning rate: 0.0040886]
	Learning Rate: 0.00408864
	LOSS [training: 0.08172827565098104 | validation: 0.18722271250763872]
	TIME [epoch: 19.9 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694795863070435		[learning rate: 0.0040492]
	Learning Rate: 0.00404919
	LOSS [training: 0.07694795863070435 | validation: 0.18573113923385257]
	TIME [epoch: 19.9 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678669752130446		[learning rate: 0.0040101]
	Learning Rate: 0.00401012
	LOSS [training: 0.07678669752130446 | validation: 0.18904823691952152]
	TIME [epoch: 20 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749583730622289		[learning rate: 0.0039714]
	Learning Rate: 0.00397143
	LOSS [training: 0.07749583730622289 | validation: 0.21421721170345778]
	TIME [epoch: 20 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07981440017788033		[learning rate: 0.0039331]
	Learning Rate: 0.00393312
	LOSS [training: 0.07981440017788033 | validation: 0.19576976855419895]
	TIME [epoch: 19.9 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08004866601705743		[learning rate: 0.0038952]
	Learning Rate: 0.00389517
	LOSS [training: 0.08004866601705743 | validation: 0.1869021176597542]
	TIME [epoch: 19.9 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08226130407238445		[learning rate: 0.0038576]
	Learning Rate: 0.00385759
	LOSS [training: 0.08226130407238445 | validation: 0.1850209114194705]
	TIME [epoch: 19.9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028931607892018		[learning rate: 0.0038204]
	Learning Rate: 0.00382037
	LOSS [training: 0.08028931607892018 | validation: 0.18878378812849064]
	TIME [epoch: 19.9 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07741933901266758		[learning rate: 0.0037835]
	Learning Rate: 0.00378351
	LOSS [training: 0.07741933901266758 | validation: 0.19941504575230798]
	TIME [epoch: 19.9 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07193996041545407		[learning rate: 0.003747]
	Learning Rate: 0.003747
	LOSS [training: 0.07193996041545407 | validation: 0.1981759435097426]
	TIME [epoch: 19.9 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07045682355925978		[learning rate: 0.0037109]
	Learning Rate: 0.00371085
	LOSS [training: 0.07045682355925978 | validation: 0.18698858926797837]
	TIME [epoch: 19.9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07967924867956414		[learning rate: 0.003675]
	Learning Rate: 0.00367505
	LOSS [training: 0.07967924867956414 | validation: 0.19925743007254332]
	TIME [epoch: 19.9 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641269345571833		[learning rate: 0.0036396]
	Learning Rate: 0.00363959
	LOSS [training: 0.07641269345571833 | validation: 0.19124924625458462]
	TIME [epoch: 19.9 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07704902012749948		[learning rate: 0.0036045]
	Learning Rate: 0.00360448
	LOSS [training: 0.07704902012749948 | validation: 0.1869340575979292]
	TIME [epoch: 19.9 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312975325245558		[learning rate: 0.0035697]
	Learning Rate: 0.0035697
	LOSS [training: 0.07312975325245558 | validation: 0.20568648950900917]
	TIME [epoch: 20 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735751752521677		[learning rate: 0.0035353]
	Learning Rate: 0.00353526
	LOSS [training: 0.07735751752521677 | validation: 0.18754671852394256]
	TIME [epoch: 19.9 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07404168062558494		[learning rate: 0.0035011]
	Learning Rate: 0.00350115
	LOSS [training: 0.07404168062558494 | validation: 0.18979787253234354]
	TIME [epoch: 19.9 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07750018921799338		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.07750018921799338 | validation: 0.19439210337284202]
	TIME [epoch: 19.9 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802297761396669		[learning rate: 0.0034339]
	Learning Rate: 0.00343391
	LOSS [training: 0.07802297761396669 | validation: 0.18462223339226236]
	TIME [epoch: 20 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765770200605094		[learning rate: 0.0034008]
	Learning Rate: 0.00340078
	LOSS [training: 0.08765770200605094 | validation: 0.1830807716003027]
	TIME [epoch: 19.9 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07364465756125292		[learning rate: 0.003368]
	Learning Rate: 0.00336797
	LOSS [training: 0.07364465756125292 | validation: 0.18945382532854918]
	TIME [epoch: 19.9 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0687035651133109		[learning rate: 0.0033355]
	Learning Rate: 0.00333548
	LOSS [training: 0.0687035651133109 | validation: 0.18182236905915203]
	TIME [epoch: 19.9 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516687548492388		[learning rate: 0.0033033]
	Learning Rate: 0.00330329
	LOSS [training: 0.08516687548492388 | validation: 0.18918532857976297]
	TIME [epoch: 20 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07693266494451913		[learning rate: 0.0032714]
	Learning Rate: 0.00327142
	LOSS [training: 0.07693266494451913 | validation: 0.18560965209648306]
	TIME [epoch: 20 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0835682364206981		[learning rate: 0.0032399]
	Learning Rate: 0.00323986
	LOSS [training: 0.0835682364206981 | validation: 0.18897204220737712]
	TIME [epoch: 20 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07803959641185516		[learning rate: 0.0032086]
	Learning Rate: 0.0032086
	LOSS [training: 0.07803959641185516 | validation: 0.18443487324207727]
	TIME [epoch: 19.9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07784783771541322		[learning rate: 0.0031776]
	Learning Rate: 0.00317764
	LOSS [training: 0.07784783771541322 | validation: 0.18932983602315842]
	TIME [epoch: 19.9 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590272120047523		[learning rate: 0.003147]
	Learning Rate: 0.00314699
	LOSS [training: 0.07590272120047523 | validation: 0.18627842235879935]
	TIME [epoch: 19.9 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0789285894542347		[learning rate: 0.0031166]
	Learning Rate: 0.00311662
	LOSS [training: 0.0789285894542347 | validation: 0.19406567334979943]
	TIME [epoch: 20 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644129305882577		[learning rate: 0.0030866]
	Learning Rate: 0.00308655
	LOSS [training: 0.07644129305882577 | validation: 0.18781685692871547]
	TIME [epoch: 19.9 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07674121738059032		[learning rate: 0.0030568]
	Learning Rate: 0.00305677
	LOSS [training: 0.07674121738059032 | validation: 0.18617918479626602]
	TIME [epoch: 19.9 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394046807511166		[learning rate: 0.0030273]
	Learning Rate: 0.00302728
	LOSS [training: 0.07394046807511166 | validation: 0.19121124346874158]
	TIME [epoch: 19.9 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07644615763927462		[learning rate: 0.0029981]
	Learning Rate: 0.00299807
	LOSS [training: 0.07644615763927462 | validation: 0.18267398729529108]
	TIME [epoch: 20 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07758666894489999		[learning rate: 0.0029691]
	Learning Rate: 0.00296915
	LOSS [training: 0.07758666894489999 | validation: 0.19305618707414535]
	TIME [epoch: 19.9 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07997264496971197		[learning rate: 0.0029405]
	Learning Rate: 0.0029405
	LOSS [training: 0.07997264496971197 | validation: 0.18325410247953589]
	TIME [epoch: 20 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0706324364488663		[learning rate: 0.0029121]
	Learning Rate: 0.00291213
	LOSS [training: 0.0706324364488663 | validation: 0.18872822589926264]
	TIME [epoch: 20 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676687763573944		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.07676687763573944 | validation: 0.18747132744615297]
	TIME [epoch: 20 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07562129662723961		[learning rate: 0.0028562]
	Learning Rate: 0.00285621
	LOSS [training: 0.07562129662723961 | validation: 0.17796672241452724]
	TIME [epoch: 19.9 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06949998637891752		[learning rate: 0.0028286]
	Learning Rate: 0.00282865
	LOSS [training: 0.06949998637891752 | validation: 0.18532384514644637]
	TIME [epoch: 19.9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0819653460132424		[learning rate: 0.0028014]
	Learning Rate: 0.00280136
	LOSS [training: 0.0819653460132424 | validation: 0.18734509793242965]
	TIME [epoch: 19.9 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07512210097476842		[learning rate: 0.0027743]
	Learning Rate: 0.00277433
	LOSS [training: 0.07512210097476842 | validation: 0.1832672285095092]
	TIME [epoch: 19.9 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07219456485128017		[learning rate: 0.0027476]
	Learning Rate: 0.00274756
	LOSS [training: 0.07219456485128017 | validation: 0.18596226253616424]
	TIME [epoch: 19.9 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08149221252715078		[learning rate: 0.0027211]
	Learning Rate: 0.00272105
	LOSS [training: 0.08149221252715078 | validation: 0.19052243661775414]
	TIME [epoch: 19.9 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07055698361071662		[learning rate: 0.0026948]
	Learning Rate: 0.0026948
	LOSS [training: 0.07055698361071662 | validation: 0.1859047971030768]
	TIME [epoch: 20 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06920228559306275		[learning rate: 0.0026688]
	Learning Rate: 0.0026688
	LOSS [training: 0.06920228559306275 | validation: 0.1829452803134375]
	TIME [epoch: 19.9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779432469260748		[learning rate: 0.002643]
	Learning Rate: 0.00264305
	LOSS [training: 0.0779432469260748 | validation: 0.1809487802895583]
	TIME [epoch: 20 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07610383528986256		[learning rate: 0.0026175]
	Learning Rate: 0.00261755
	LOSS [training: 0.07610383528986256 | validation: 0.20439282838189235]
	TIME [epoch: 20 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08593206885808052		[learning rate: 0.0025923]
	Learning Rate: 0.00259229
	LOSS [training: 0.08593206885808052 | validation: 0.18474423696211423]
	TIME [epoch: 19.9 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07775610522064091		[learning rate: 0.0025673]
	Learning Rate: 0.00256728
	LOSS [training: 0.07775610522064091 | validation: 0.19602910373000934]
	TIME [epoch: 19.9 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07939242169977229		[learning rate: 0.0025425]
	Learning Rate: 0.00254251
	LOSS [training: 0.07939242169977229 | validation: 0.1872656012280587]
	TIME [epoch: 19.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07453548293708934		[learning rate: 0.002518]
	Learning Rate: 0.00251798
	LOSS [training: 0.07453548293708934 | validation: 0.1926602684521971]
	TIME [epoch: 19.9 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08111391146377811		[learning rate: 0.0024937]
	Learning Rate: 0.00249369
	LOSS [training: 0.08111391146377811 | validation: 0.1974542688263608]
	TIME [epoch: 20 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972060870217182		[learning rate: 0.0024696]
	Learning Rate: 0.00246963
	LOSS [training: 0.06972060870217182 | validation: 0.19632062809719464]
	TIME [epoch: 20 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561495611785558		[learning rate: 0.0024458]
	Learning Rate: 0.0024458
	LOSS [training: 0.07561495611785558 | validation: 0.18646264849796051]
	TIME [epoch: 20 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532968598476635		[learning rate: 0.0024222]
	Learning Rate: 0.0024222
	LOSS [training: 0.07532968598476635 | validation: 0.18889546025092147]
	TIME [epoch: 19.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07717275523789399		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.07717275523789399 | validation: 0.19006041469228596]
	TIME [epoch: 19.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824420410056035		[learning rate: 0.0023757]
	Learning Rate: 0.00237569
	LOSS [training: 0.07824420410056035 | validation: 0.18810339918004634]
	TIME [epoch: 20 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678854060867252		[learning rate: 0.0023528]
	Learning Rate: 0.00235277
	LOSS [training: 0.07678854060867252 | validation: 0.19287296296355966]
	TIME [epoch: 19.9 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282457527531369		[learning rate: 0.0023301]
	Learning Rate: 0.00233007
	LOSS [training: 0.08282457527531369 | validation: 0.19249936293812397]
	TIME [epoch: 20 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07618889925226388		[learning rate: 0.0023076]
	Learning Rate: 0.00230759
	LOSS [training: 0.07618889925226388 | validation: 0.19669786462001768]
	TIME [epoch: 20 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07922247131739674		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.07922247131739674 | validation: 0.18371825080584248]
	TIME [epoch: 19.9 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07305238278782522		[learning rate: 0.0022633]
	Learning Rate: 0.00226327
	LOSS [training: 0.07305238278782522 | validation: 0.18796036886777137]
	TIME [epoch: 20 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07720006214722225		[learning rate: 0.0022414]
	Learning Rate: 0.00224144
	LOSS [training: 0.07720006214722225 | validation: 0.18634357542770946]
	TIME [epoch: 19.9 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07621438721134755		[learning rate: 0.0022198]
	Learning Rate: 0.00221981
	LOSS [training: 0.07621438721134755 | validation: 0.18498888383215267]
	TIME [epoch: 20 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540591323060881		[learning rate: 0.0021984]
	Learning Rate: 0.00219839
	LOSS [training: 0.07540591323060881 | validation: 0.1850730801567112]
	TIME [epoch: 19.9 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07048092704211834		[learning rate: 0.0021772]
	Learning Rate: 0.00217718
	LOSS [training: 0.07048092704211834 | validation: 0.18611496659896334]
	TIME [epoch: 20 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07002233602801074		[learning rate: 0.0021562]
	Learning Rate: 0.00215618
	LOSS [training: 0.07002233602801074 | validation: 0.19357320042600806]
	TIME [epoch: 19.9 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07042841612085314		[learning rate: 0.0021354]
	Learning Rate: 0.00213537
	LOSS [training: 0.07042841612085314 | validation: 0.18791394408527856]
	TIME [epoch: 20 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08168945279765144		[learning rate: 0.0021148]
	Learning Rate: 0.00211477
	LOSS [training: 0.08168945279765144 | validation: 0.1859603355242021]
	TIME [epoch: 19.9 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06715913024708368		[learning rate: 0.0020944]
	Learning Rate: 0.00209437
	LOSS [training: 0.06715913024708368 | validation: 0.1904103320731831]
	TIME [epoch: 19.9 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07199853491825313		[learning rate: 0.0020742]
	Learning Rate: 0.00207416
	LOSS [training: 0.07199853491825313 | validation: 0.1925909283064906]
	TIME [epoch: 19.9 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07241407579369144		[learning rate: 0.0020541]
	Learning Rate: 0.00205415
	LOSS [training: 0.07241407579369144 | validation: 0.1872355865443434]
	TIME [epoch: 82.1 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.075970391536145		[learning rate: 0.0020343]
	Learning Rate: 0.00203433
	LOSS [training: 0.075970391536145 | validation: 0.18521518107779944]
	TIME [epoch: 41.8 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081533685454108		[learning rate: 0.0020147]
	Learning Rate: 0.0020147
	LOSS [training: 0.07081533685454108 | validation: 0.19322009625811276]
	TIME [epoch: 41.8 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952954060226271		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.07952954060226271 | validation: 0.18744715445808216]
	TIME [epoch: 41.8 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08609728693301189		[learning rate: 0.001976]
	Learning Rate: 0.00197601
	LOSS [training: 0.08609728693301189 | validation: 0.1888397563610947]
	TIME [epoch: 41.8 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253956348144149		[learning rate: 0.0019569]
	Learning Rate: 0.00195695
	LOSS [training: 0.07253956348144149 | validation: 0.18972341320657565]
	TIME [epoch: 41.9 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06767602338884868		[learning rate: 0.0019381]
	Learning Rate: 0.00193807
	LOSS [training: 0.06767602338884868 | validation: 0.18265280052919886]
	TIME [epoch: 41.8 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0788139650860582		[learning rate: 0.0019194]
	Learning Rate: 0.00191937
	LOSS [training: 0.0788139650860582 | validation: 0.1887126555953385]
	TIME [epoch: 41.8 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07581437691074269		[learning rate: 0.0019008]
	Learning Rate: 0.00190085
	LOSS [training: 0.07581437691074269 | validation: 0.18501043402206915]
	TIME [epoch: 41.8 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08627146571451474		[learning rate: 0.0018825]
	Learning Rate: 0.00188251
	LOSS [training: 0.08627146571451474 | validation: 0.19103605338253465]
	TIME [epoch: 41.8 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796383824541821		[learning rate: 0.0018643]
	Learning Rate: 0.00186434
	LOSS [training: 0.07796383824541821 | validation: 0.18835793259462333]
	TIME [epoch: 41.8 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07952996361862577		[learning rate: 0.0018464]
	Learning Rate: 0.00184636
	LOSS [training: 0.07952996361862577 | validation: 0.18940625193867333]
	TIME [epoch: 41.8 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09354648878328856		[learning rate: 0.0018285]
	Learning Rate: 0.00182854
	LOSS [training: 0.09354648878328856 | validation: 0.1813838592912379]
	TIME [epoch: 41.8 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174827032933055		[learning rate: 0.0018109]
	Learning Rate: 0.0018109
	LOSS [training: 0.08174827032933055 | validation: 0.19331241617495112]
	TIME [epoch: 41.8 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08079798427093803		[learning rate: 0.0017934]
	Learning Rate: 0.00179343
	LOSS [training: 0.08079798427093803 | validation: 0.19222035146405891]
	TIME [epoch: 41.8 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset1_20241031_122042/states/model_facs_dec2_v2_argset1_215.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 3523.043 seconds.
