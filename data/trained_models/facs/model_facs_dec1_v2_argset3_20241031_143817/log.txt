Args:
Namespace(name='model_facs_dec1_v2_argset3', outdir='out/model_training/model_facs_dec1_v2_argset3', training_data='data/facs/facs_dec1_v2/training', validation_data='data/facs/facs_dec1_v2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05, 0.1, 0.15, 0.5], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1102333198

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2190730217895525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2190730217895525 | validation: 1.0301918227881188]
	TIME [epoch: 40.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.8576187126183575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8576187126183575 | validation: 0.8033418865998943]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.704189142464997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.704189142464997 | validation: 0.66057640071195]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.60144596449998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.60144596449998 | validation: 0.5415260404604985]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4734701866683284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4734701866683284 | validation: 0.4669408536301196]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.44129977519577723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44129977519577723 | validation: 0.39631457401096265]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.38134247010426253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38134247010426253 | validation: 0.3591001195941434]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.36069990419417214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36069990419417214 | validation: 0.344842926728941]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3209922556042791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3209922556042791 | validation: 0.3028005222809806]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32661719477752554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32661719477752554 | validation: 0.2926124411561005]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3012463264064919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3012463264064919 | validation: 0.33110437238117885]
	TIME [epoch: 11.3 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2989509498094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2989509498094 | validation: 0.29013122703379435]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31356712763607014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31356712763607014 | validation: 0.26671172748045613]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29674892123730895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29674892123730895 | validation: 0.2719150529640166]
	TIME [epoch: 11.3 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2863197629096184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2863197629096184 | validation: 0.26013428383577064]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3047787367923451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3047787367923451 | validation: 0.26153654997635595]
	TIME [epoch: 11.3 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2924828876834326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2924828876834326 | validation: 0.25956627934031695]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28471951403657675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28471951403657675 | validation: 0.2653871013993966]
	TIME [epoch: 11.4 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28794952507214894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28794952507214894 | validation: 0.259875570516073]
	TIME [epoch: 11.4 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2749505070557943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2749505070557943 | validation: 0.24499736738900507]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.269455112659979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.269455112659979 | validation: 0.2807509330188064]
	TIME [epoch: 11.4 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2749978184251442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2749978184251442 | validation: 0.23804947999500348]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.30189108073071247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30189108073071247 | validation: 0.24093300896988076]
	TIME [epoch: 11.4 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661002346097236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2661002346097236 | validation: 0.25474085686758835]
	TIME [epoch: 11.4 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27376604700741847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27376604700741847 | validation: 0.2301097659082129]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2581190386603321		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2581190386603321 | validation: 0.22003395167085982]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2828485314150294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2828485314150294 | validation: 0.24007834561391955]
	TIME [epoch: 11.3 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26789907679717645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26789907679717645 | validation: 0.2241630437580615]
	TIME [epoch: 11.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25199240746303103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25199240746303103 | validation: 0.20958333048568]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2692048350186061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2692048350186061 | validation: 0.2184602917707334]
	TIME [epoch: 11.3 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637339724892131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2637339724892131 | validation: 0.24418950484497204]
	TIME [epoch: 11.4 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558019430077834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2558019430077834 | validation: 0.2088829931610437]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24178417810011718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24178417810011718 | validation: 0.2509767281493739]
	TIME [epoch: 11.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577941445219303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2577941445219303 | validation: 0.20316351037652755]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330050008993184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24330050008993184 | validation: 0.2801403776054875]
	TIME [epoch: 11.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2559709993100132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2559709993100132 | validation: 0.21391805898545205]
	TIME [epoch: 11.4 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509114588410803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2509114588410803 | validation: 0.19838609656134543]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24391524171156156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24391524171156156 | validation: 0.19528223245667498]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2407624699505161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2407624699505161 | validation: 0.19968784704318823]
	TIME [epoch: 11.3 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505525655939137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2505525655939137 | validation: 0.1968586558933715]
	TIME [epoch: 11.3 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24188101281106075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24188101281106075 | validation: 0.19133724848658118]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24251160033510685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24251160033510685 | validation: 0.21714991791946453]
	TIME [epoch: 11.4 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2508891822871633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2508891822871633 | validation: 0.19918180521585244]
	TIME [epoch: 11.3 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24585877588487515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24585877588487515 | validation: 0.19804852037491666]
	TIME [epoch: 11.3 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23028198503651012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23028198503651012 | validation: 0.1979415713321552]
	TIME [epoch: 11.3 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23217267137944994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23217267137944994 | validation: 0.20759166109845775]
	TIME [epoch: 11.3 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22621255047599487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22621255047599487 | validation: 0.1991858003696335]
	TIME [epoch: 11.3 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24762148735647302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24762148735647302 | validation: 0.207613029530238]
	TIME [epoch: 11.3 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24039368936885494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24039368936885494 | validation: 0.19713848536087505]
	TIME [epoch: 11.3 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22612456492317679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22612456492317679 | validation: 0.1943384676379421]
	TIME [epoch: 11.3 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22309101500684755		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.22309101500684755 | validation: 0.18072977544610816]
	TIME [epoch: 49.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22511618653375218		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.22511618653375218 | validation: 0.21730452607496278]
	TIME [epoch: 22.1 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23086883339787836		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.23086883339787836 | validation: 0.20151240050956248]
	TIME [epoch: 22.1 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24504260716022566		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.24504260716022566 | validation: 0.1954103949849484]
	TIME [epoch: 22.1 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23205395936873174		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.23205395936873174 | validation: 0.19293074267177074]
	TIME [epoch: 22 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2216201558914601		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.2216201558914601 | validation: 0.17922840960160552]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2222320512750945		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.2222320512750945 | validation: 0.20638432891496858]
	TIME [epoch: 22 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2329411649665154		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.2329411649665154 | validation: 0.19124078123311689]
	TIME [epoch: 22.1 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2259285576539264		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.2259285576539264 | validation: 0.18948593171062839]
	TIME [epoch: 22 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23540012017771927		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.23540012017771927 | validation: 0.18943453272251665]
	TIME [epoch: 22.1 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2211005656147201		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.2211005656147201 | validation: 0.19908874100210416]
	TIME [epoch: 22 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23752703203813075		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.23752703203813075 | validation: 0.19415830943956486]
	TIME [epoch: 22 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2176194364709431		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.2176194364709431 | validation: 0.1831100283769166]
	TIME [epoch: 22.1 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21929518307840554		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.21929518307840554 | validation: 0.18866708358223513]
	TIME [epoch: 22.1 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21553488513532507		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.21553488513532507 | validation: 0.17973822724948052]
	TIME [epoch: 22 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22231689989352701		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.22231689989352701 | validation: 0.19048827197216286]
	TIME [epoch: 22 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2186030695066197		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.2186030695066197 | validation: 0.17259993813151653]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21002414403838762		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.21002414403838762 | validation: 0.1921750367721035]
	TIME [epoch: 22 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23036561224722193		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.23036561224722193 | validation: 0.18549023555596425]
	TIME [epoch: 22.1 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21369858587605559		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.21369858587605559 | validation: 0.1704250794251194]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22022348801159372		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.22022348801159372 | validation: 0.1875001743829484]
	TIME [epoch: 22.1 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2275629586943901		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.2275629586943901 | validation: 0.17441314615565454]
	TIME [epoch: 22.1 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20939698350190028		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.20939698350190028 | validation: 0.17129551969594878]
	TIME [epoch: 22.1 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20579107410855582		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.20579107410855582 | validation: 0.16762595835652863]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2099815219690345		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.2099815219690345 | validation: 0.1757004218471859]
	TIME [epoch: 22 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21009340949806235		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.21009340949806235 | validation: 0.16519266004195005]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21018859047994912		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.21018859047994912 | validation: 0.16239625444814512]
	TIME [epoch: 21.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2067548506628916		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.2067548506628916 | validation: 0.1671958735374435]
	TIME [epoch: 22 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2013955916580933		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.2013955916580933 | validation: 0.17444388821397286]
	TIME [epoch: 22 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20669751673495815		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.20669751673495815 | validation: 0.18262072188395626]
	TIME [epoch: 22 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20952104405663527		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.20952104405663527 | validation: 0.16166486103325275]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19586293185442907		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.19586293185442907 | validation: 0.15817708050204018]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19507526594357882		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.19507526594357882 | validation: 0.16013447747104012]
	TIME [epoch: 22.1 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20259172686140844		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.20259172686140844 | validation: 0.15712404312260558]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19821983761217063		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.19821983761217063 | validation: 0.17225647655218151]
	TIME [epoch: 22 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2236016294553483		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.2236016294553483 | validation: 0.15826777709634898]
	TIME [epoch: 22.1 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19244830773306917		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.19244830773306917 | validation: 0.18012955391685756]
	TIME [epoch: 22.1 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19324903780647654		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.19324903780647654 | validation: 0.15037671155761698]
	TIME [epoch: 22.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1924022259128364		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.1924022259128364 | validation: 0.16687914342602111]
	TIME [epoch: 22 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19586960704046122		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.19586960704046122 | validation: 0.15250466724216516]
	TIME [epoch: 21.9 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20126841344944932		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.20126841344944932 | validation: 0.15037274644451495]
	TIME [epoch: 21.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18721280839845314		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.18721280839845314 | validation: 0.15209778642065677]
	TIME [epoch: 21.9 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1863290521041505		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.1863290521041505 | validation: 0.15975917290370495]
	TIME [epoch: 21.9 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19390570616158118		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.19390570616158118 | validation: 0.15734507426698532]
	TIME [epoch: 21.9 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1882258831442721		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.1882258831442721 | validation: 0.14539724673978388]
	TIME [epoch: 21.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1875538273255385		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.1875538273255385 | validation: 0.14133024660415122]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_96.pth
	Model improved!!!
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18501123881707995		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.18501123881707995 | validation: 0.14457015470405557]
	TIME [epoch: 22.1 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18604180979397297		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.18604180979397297 | validation: 0.16490156955044838]
	TIME [epoch: 22 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1824238833304258		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.1824238833304258 | validation: 0.1592222064569428]
	TIME [epoch: 21.9 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19420404291390855		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.19420404291390855 | validation: 0.1490563823384429]
	TIME [epoch: 22 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18169483154099175		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.18169483154099175 | validation: 0.15471519471009149]
	TIME [epoch: 73.8 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18403008414790945		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.18403008414790945 | validation: 0.15199129077545376]
	TIME [epoch: 46 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17813837635437893		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.17813837635437893 | validation: 0.14118059199536553]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_103.pth
	Model improved!!!
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17978373503134445		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.17978373503134445 | validation: 0.14940681165388345]
	TIME [epoch: 45.9 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18984305085294373		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.18984305085294373 | validation: 0.1436721976187729]
	TIME [epoch: 46 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18042999510381388		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.18042999510381388 | validation: 0.1836867720297337]
	TIME [epoch: 46 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17844935613911972		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.17844935613911972 | validation: 0.13917605970818142]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_107.pth
	Model improved!!!
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18196590209543895		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.18196590209543895 | validation: 0.15638470014021863]
	TIME [epoch: 46 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1798077427282062		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.1798077427282062 | validation: 0.136644977554586]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18384450380707518		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.18384450380707518 | validation: 0.15650931686895167]
	TIME [epoch: 45.9 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17674952447077472		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.17674952447077472 | validation: 0.13815014195508377]
	TIME [epoch: 45.9 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17890480146750032		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.17890480146750032 | validation: 0.1418185983482529]
	TIME [epoch: 46 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.182933246604518		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.182933246604518 | validation: 0.1424649666689514]
	TIME [epoch: 46 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17532809222322956		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.17532809222322956 | validation: 0.13690761836470514]
	TIME [epoch: 46 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17979625045468303		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.17979625045468303 | validation: 0.13931885795781268]
	TIME [epoch: 46 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17756599584313185		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.17756599584313185 | validation: 0.16001470002692933]
	TIME [epoch: 45.9 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1754479154854014		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.1754479154854014 | validation: 0.13755896007929738]
	TIME [epoch: 46 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17356398299449063		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.17356398299449063 | validation: 0.13612032822121792]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_118.pth
	Model improved!!!
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17099931436159646		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.17099931436159646 | validation: 0.15119385218153902]
	TIME [epoch: 46 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17423849783415488		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.17423849783415488 | validation: 0.13416541720552688]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_120.pth
	Model improved!!!
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17673814042888916		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.17673814042888916 | validation: 0.13281021171567958]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17572724958715824		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.17572724958715824 | validation: 0.1336894170619904]
	TIME [epoch: 45.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17139208377403656		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.17139208377403656 | validation: 0.14081574906097438]
	TIME [epoch: 46 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18170340601712834		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.18170340601712834 | validation: 0.1335883580970064]
	TIME [epoch: 46.1 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1747310498141698		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.1747310498141698 | validation: 0.13721889850881341]
	TIME [epoch: 46 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17305523890346772		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.17305523890346772 | validation: 0.13974569266258371]
	TIME [epoch: 46 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1713750994911082		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.1713750994911082 | validation: 0.13318172050307195]
	TIME [epoch: 45.9 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16945120846330644		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.16945120846330644 | validation: 0.13790273561230995]
	TIME [epoch: 45.9 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1750574852161654		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.1750574852161654 | validation: 0.1322813296519913]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1711323655213833		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.1711323655213833 | validation: 0.13144118385597997]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16948493151119504		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.16948493151119504 | validation: 0.1348186074607504]
	TIME [epoch: 46.1 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17351171424364806		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.17351171424364806 | validation: 0.15616372280303265]
	TIME [epoch: 45.9 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17364795314998874		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.17364795314998874 | validation: 0.1334692220179166]
	TIME [epoch: 45.9 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16924376565694707		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.16924376565694707 | validation: 0.15564362051438166]
	TIME [epoch: 45.9 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17591978989201706		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.17591978989201706 | validation: 0.14946743715994665]
	TIME [epoch: 45.9 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16790945302523297		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.16790945302523297 | validation: 0.13322458057761408]
	TIME [epoch: 45.9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1698109047404535		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.1698109047404535 | validation: 0.13410370979997838]
	TIME [epoch: 45.8 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17170813296575985		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.17170813296575985 | validation: 0.134533593180718]
	TIME [epoch: 45.9 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17051443838836647		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.17051443838836647 | validation: 0.13855812747049662]
	TIME [epoch: 45.7 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1705420368388608		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.1705420368388608 | validation: 0.13519735544037087]
	TIME [epoch: 45.9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1742127325649333		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.1742127325649333 | validation: 0.13183143864300498]
	TIME [epoch: 46 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16675643435622645		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.16675643435622645 | validation: 0.14763997890291097]
	TIME [epoch: 46 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1741609433559246		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.1741609433559246 | validation: 0.13335725722361313]
	TIME [epoch: 45.9 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.168097021871358		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.168097021871358 | validation: 0.16284810117663215]
	TIME [epoch: 46 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17173900544492238		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.17173900544492238 | validation: 0.13742363610994565]
	TIME [epoch: 46 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.171773707211613		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.171773707211613 | validation: 0.143589427371775]
	TIME [epoch: 45.9 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16929631052311214		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.16929631052311214 | validation: 0.1460595079362142]
	TIME [epoch: 45.9 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16821030925792466		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.16821030925792466 | validation: 0.13257893114577773]
	TIME [epoch: 45.9 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17043609200973717		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.17043609200973717 | validation: 0.13052026205186468]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16609386242201948		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.16609386242201948 | validation: 0.17772280645425653]
	TIME [epoch: 45.9 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17144159748164145		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.17144159748164145 | validation: 0.13183566902998953]
	TIME [epoch: 46.1 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1675639804151118		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.1675639804151118 | validation: 0.13393315603525574]
	TIME [epoch: 46.1 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1719001222548111		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.1719001222548111 | validation: 0.13892561492089706]
	TIME [epoch: 46.1 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16647842951234956		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.16647842951234956 | validation: 0.1334425124857745]
	TIME [epoch: 46 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16738473009625507		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.16738473009625507 | validation: 0.13205994195774196]
	TIME [epoch: 45.9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1685669461697664		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.1685669461697664 | validation: 0.133542014752064]
	TIME [epoch: 45.8 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16751872397983866		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.16751872397983866 | validation: 0.1367722727875864]
	TIME [epoch: 45.9 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16823149405309545		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.16823149405309545 | validation: 0.13092259893790825]
	TIME [epoch: 45.8 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16478516711961141		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.16478516711961141 | validation: 0.13589881947877494]
	TIME [epoch: 45.8 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1722671901480737		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.1722671901480737 | validation: 0.12949334789577835]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_160.pth
	Model improved!!!
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1678687823337388		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.1678687823337388 | validation: 0.1417629487747197]
	TIME [epoch: 45.7 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17417862944350934		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.17417862944350934 | validation: 0.13059130955900716]
	TIME [epoch: 45.8 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1681161873623693		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.1681161873623693 | validation: 0.1344668116301786]
	TIME [epoch: 46 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16473224153742647		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.16473224153742647 | validation: 0.1335076599021578]
	TIME [epoch: 45.8 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.168039033242094		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.168039033242094 | validation: 0.13353175187764982]
	TIME [epoch: 45.9 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16866426585623065		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.16866426585623065 | validation: 0.1315371169751477]
	TIME [epoch: 46 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16568222917969674		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.16568222917969674 | validation: 0.14290789310283497]
	TIME [epoch: 45.9 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1729562258112343		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.1729562258112343 | validation: 0.1394524317598468]
	TIME [epoch: 45.9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16645045409341017		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.16645045409341017 | validation: 0.1319515099611102]
	TIME [epoch: 45.9 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16333023686663367		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.16333023686663367 | validation: 0.13690916484646648]
	TIME [epoch: 46.1 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16515882330333073		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.16515882330333073 | validation: 0.1439104835466512]
	TIME [epoch: 45.8 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16593538390399948		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.16593538390399948 | validation: 0.13192209527540447]
	TIME [epoch: 45.9 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16311672107084108		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.16311672107084108 | validation: 0.13210222847567016]
	TIME [epoch: 45.9 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.165235460783802		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.165235460783802 | validation: 0.1263786872727482]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_174.pth
	Model improved!!!
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16542515677637393		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.16542515677637393 | validation: 0.1296798592437533]
	TIME [epoch: 45.7 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16714355482967547		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.16714355482967547 | validation: 0.12944582925483983]
	TIME [epoch: 46 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16301552200044866		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.16301552200044866 | validation: 0.13211694048341843]
	TIME [epoch: 46 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1626305692635288		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.1626305692635288 | validation: 0.12613767191436193]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16195618164395134		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.16195618164395134 | validation: 0.1287997782877861]
	TIME [epoch: 45.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16397078719156466		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.16397078719156466 | validation: 0.12771685413561884]
	TIME [epoch: 46 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1664164349299169		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.1664164349299169 | validation: 0.13893664343299567]
	TIME [epoch: 46 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16608249563048957		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.16608249563048957 | validation: 0.1262569659175537]
	TIME [epoch: 46 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16327491915556186		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.16327491915556186 | validation: 0.12937785186035414]
	TIME [epoch: 46 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16084292961819283		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.16084292961819283 | validation: 0.1299092978896059]
	TIME [epoch: 45.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16172021048198895		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.16172021048198895 | validation: 0.1265168349649777]
	TIME [epoch: 45.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1617227870546725		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.1617227870546725 | validation: 0.12494503285105621]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16614455909062784		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.16614455909062784 | validation: 0.1254372461471517]
	TIME [epoch: 46 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16507544699961404		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.16507544699961404 | validation: 0.126941358022688]
	TIME [epoch: 46.1 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16095774787898462		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.16095774787898462 | validation: 0.129561337742336]
	TIME [epoch: 46.1 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16532043198599447		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.16532043198599447 | validation: 0.13108405102368254]
	TIME [epoch: 46.1 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15984872610541234		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.15984872610541234 | validation: 0.13056197545894044]
	TIME [epoch: 46.1 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16286217052713878		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.16286217052713878 | validation: 0.1263509272700047]
	TIME [epoch: 46.1 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16277884507790444		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.16277884507790444 | validation: 0.12707511061401439]
	TIME [epoch: 46.1 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16116042999728855		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.16116042999728855 | validation: 0.1276447230808043]
	TIME [epoch: 46.1 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15935064059874596		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.15935064059874596 | validation: 0.1276046939121483]
	TIME [epoch: 46 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1635117500804468		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.1635117500804468 | validation: 0.13008680177912718]
	TIME [epoch: 46 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1612303558776262		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.1612303558776262 | validation: 0.12655030989671723]
	TIME [epoch: 46 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15989200256514663		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.15989200256514663 | validation: 0.12675026851269716]
	TIME [epoch: 46 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1641570265487069		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.1641570265487069 | validation: 0.1255152770527988]
	TIME [epoch: 46 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16284151700749785		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.16284151700749785 | validation: 0.1335029742018472]
	TIME [epoch: 46 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16479403995542447		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.16479403995542447 | validation: 0.13377793566152665]
	TIME [epoch: 123 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15954162305943506		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.15954162305943506 | validation: 0.12400210665639402]
	TIME [epoch: 95.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_202.pth
	Model improved!!!
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16091953821448876		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.16091953821448876 | validation: 0.12893765621388292]
	TIME [epoch: 95.7 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1617974496495926		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.1617974496495926 | validation: 0.13035654384839837]
	TIME [epoch: 95.5 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1615634691787585		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.1615634691787585 | validation: 0.12975033240130918]
	TIME [epoch: 95.7 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16008118493645343		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.16008118493645343 | validation: 0.1264449659657293]
	TIME [epoch: 95.8 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16126389598468252		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.16126389598468252 | validation: 0.1246659472897305]
	TIME [epoch: 95.7 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1605215545763874		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.1605215545763874 | validation: 0.13026879857782617]
	TIME [epoch: 95.7 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16253104368554797		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.16253104368554797 | validation: 0.12685836096922828]
	TIME [epoch: 95.7 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1621504381111972		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.1621504381111972 | validation: 0.1291885383354795]
	TIME [epoch: 95.8 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1598268704101108		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.1598268704101108 | validation: 0.12560136276564685]
	TIME [epoch: 95.5 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1603957912977193		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.1603957912977193 | validation: 0.12484580631795902]
	TIME [epoch: 95.9 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16325591442077958		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.16325591442077958 | validation: 0.13261341243332153]
	TIME [epoch: 95.7 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15923208619035342		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.15923208619035342 | validation: 0.12425391863317883]
	TIME [epoch: 95.7 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16090456140881268		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.16090456140881268 | validation: 0.12602702758344203]
	TIME [epoch: 95.7 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15997379268292797		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.15997379268292797 | validation: 0.13247202703737251]
	TIME [epoch: 95.8 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15918405353536444		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.15918405353536444 | validation: 0.12718253443647276]
	TIME [epoch: 95.8 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15851253405846327		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.15851253405846327 | validation: 0.12609426921488148]
	TIME [epoch: 95.8 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15888718182498127		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.15888718182498127 | validation: 0.13126958114710235]
	TIME [epoch: 95.7 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15921363652296724		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.15921363652296724 | validation: 0.13004029261764088]
	TIME [epoch: 95.9 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15843390385105574		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.15843390385105574 | validation: 0.12543947760797014]
	TIME [epoch: 95.7 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15955776933545068		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.15955776933545068 | validation: 0.13244780946962342]
	TIME [epoch: 95.7 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15879708008336663		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.15879708008336663 | validation: 0.12367019412651456]
	TIME [epoch: 95.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_223.pth
	Model improved!!!
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15726322089376946		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.15726322089376946 | validation: 0.1217887184767102]
	TIME [epoch: 95.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1568084003029777		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.1568084003029777 | validation: 0.13076450945037926]
	TIME [epoch: 95.9 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15997859503490117		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.15997859503490117 | validation: 0.12673883255335214]
	TIME [epoch: 95.8 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15772827037499626		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.15772827037499626 | validation: 0.1376982429694313]
	TIME [epoch: 96 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16078273101303853		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.16078273101303853 | validation: 0.12666879820617186]
	TIME [epoch: 95.8 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1563977219737551		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.1563977219737551 | validation: 0.12720447518946276]
	TIME [epoch: 95.8 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15774867445495125		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.15774867445495125 | validation: 0.12796329400919015]
	TIME [epoch: 95.8 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15888653033231		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.15888653033231 | validation: 0.12302910079570728]
	TIME [epoch: 95.6 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15849507496891121		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.15849507496891121 | validation: 0.13435206314949974]
	TIME [epoch: 95.8 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1588183104491274		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.1588183104491274 | validation: 0.12505121040338815]
	TIME [epoch: 95.5 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16046547534258962		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.16046547534258962 | validation: 0.1234430574081929]
	TIME [epoch: 95.5 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15721371918461838		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.15721371918461838 | validation: 0.1409225583502863]
	TIME [epoch: 95.8 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1599952307190289		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.1599952307190289 | validation: 0.1263422406485925]
	TIME [epoch: 95.8 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15756085903416486		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.15756085903416486 | validation: 0.12441222674143175]
	TIME [epoch: 96 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15544787720652709		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.15544787720652709 | validation: 0.12414382745026571]
	TIME [epoch: 95.8 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15478471776447636		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.15478471776447636 | validation: 0.12608252115680646]
	TIME [epoch: 95.8 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15531415610656193		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.15531415610656193 | validation: 0.1263673067554202]
	TIME [epoch: 95.8 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15767964733910944		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.15767964733910944 | validation: 0.12348395426356293]
	TIME [epoch: 95.8 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1610631296331306		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.1610631296331306 | validation: 0.12404007834942961]
	TIME [epoch: 95.8 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15659164851592547		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.15659164851592547 | validation: 0.12801366606215372]
	TIME [epoch: 95.6 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1558466022317864		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.1558466022317864 | validation: 0.12249910530770217]
	TIME [epoch: 95.8 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16002490549550255		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.16002490549550255 | validation: 0.12288670431425142]
	TIME [epoch: 95.6 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1558548165869343		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.1558548165869343 | validation: 0.12522930013416483]
	TIME [epoch: 95.7 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15516597761605072		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.15516597761605072 | validation: 0.12586725559074344]
	TIME [epoch: 95.7 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1558829473452578		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.1558829473452578 | validation: 0.12628086151766116]
	TIME [epoch: 95.8 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15744887685109443		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.15744887685109443 | validation: 0.1304844733855845]
	TIME [epoch: 95.7 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15869858796803002		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.15869858796803002 | validation: 0.12225900650941249]
	TIME [epoch: 95.8 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15681325486647968		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.15681325486647968 | validation: 0.12542579602881182]
	TIME [epoch: 95.7 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15527977441029578		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.15527977441029578 | validation: 0.12342158980782636]
	TIME [epoch: 95.7 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15887772781618587		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.15887772781618587 | validation: 0.1274736997658955]
	TIME [epoch: 95.7 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15612801009637023		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.15612801009637023 | validation: 0.12400038300308669]
	TIME [epoch: 95.9 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1554993400290294		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.1554993400290294 | validation: 0.12424838339235038]
	TIME [epoch: 95.9 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1556727387025392		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.1556727387025392 | validation: 0.12370407739330198]
	TIME [epoch: 95.9 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15767024506401497		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.15767024506401497 | validation: 0.12481500393181229]
	TIME [epoch: 95.8 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15485763730301974		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.15485763730301974 | validation: 0.12731656404515532]
	TIME [epoch: 95.8 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15515338432357226		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.15515338432357226 | validation: 0.12425143582126723]
	TIME [epoch: 95.8 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1560780075163146		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.1560780075163146 | validation: 0.12480275492163598]
	TIME [epoch: 95.7 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15761352369284767		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.15761352369284767 | validation: 0.12223623290579304]
	TIME [epoch: 95.8 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15700151645263813		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.15700151645263813 | validation: 0.12863843267964972]
	TIME [epoch: 95.8 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15450624720326148		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.15450624720326148 | validation: 0.1268619753855885]
	TIME [epoch: 95.8 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15513050407725837		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.15513050407725837 | validation: 0.12384444741606879]
	TIME [epoch: 95.8 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15379807115470126		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.15379807115470126 | validation: 0.12398883717398257]
	TIME [epoch: 95.7 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15188849058209475		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.15188849058209475 | validation: 0.13190240727972302]
	TIME [epoch: 95.7 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15802269125031787		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.15802269125031787 | validation: 0.12305235518314941]
	TIME [epoch: 95.9 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15523183388950826		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.15523183388950826 | validation: 0.12897388545139066]
	TIME [epoch: 95.7 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15396242478369052		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.15396242478369052 | validation: 0.1293806238090292]
	TIME [epoch: 95.8 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15700600797639608		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.15700600797639608 | validation: 0.12621280035264132]
	TIME [epoch: 95.7 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15636203484320396		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.15636203484320396 | validation: 0.1263780687803226]
	TIME [epoch: 95.9 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15550745376180258		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.15550745376180258 | validation: 0.12197237733090235]
	TIME [epoch: 95.8 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15596591777254612		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.15596591777254612 | validation: 0.12193627896578045]
	TIME [epoch: 95.7 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15675341367585185		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.15675341367585185 | validation: 0.12270032860321581]
	TIME [epoch: 95.9 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15665530759158933		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.15665530759158933 | validation: 0.12297514177249795]
	TIME [epoch: 96 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15527239625707148		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.15527239625707148 | validation: 0.12446550573627804]
	TIME [epoch: 96 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15347070197907312		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.15347070197907312 | validation: 0.12283627380126638]
	TIME [epoch: 95.9 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15495956086611276		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.15495956086611276 | validation: 0.1339301755015448]
	TIME [epoch: 95.8 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15373446857050801		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.15373446857050801 | validation: 0.12444107861512824]
	TIME [epoch: 95.8 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1572060697826038		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.1572060697826038 | validation: 0.1258188782902412]
	TIME [epoch: 95.7 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15584287792283355		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.15584287792283355 | validation: 0.12594640330194093]
	TIME [epoch: 95.6 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15771605195869517		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.15771605195869517 | validation: 0.12274844879689335]
	TIME [epoch: 95.7 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15438921465962907		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.15438921465962907 | validation: 0.12585693381060745]
	TIME [epoch: 95.8 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15395170848622794		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.15395170848622794 | validation: 0.1209300652310367]
	TIME [epoch: 95.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1560352395624016		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.1560352395624016 | validation: 0.12289849963144879]
	TIME [epoch: 95.7 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15549788563990383		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.15549788563990383 | validation: 0.12690750923733424]
	TIME [epoch: 95.5 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15886190718631302		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.15886190718631302 | validation: 0.13089351408146005]
	TIME [epoch: 95.9 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15567210600371204		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.15567210600371204 | validation: 0.124735745827051]
	TIME [epoch: 95.8 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15448451396246063		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.15448451396246063 | validation: 0.12323478551533969]
	TIME [epoch: 95.9 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15717660891294574		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.15717660891294574 | validation: 0.12613528118388656]
	TIME [epoch: 95.6 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15464325190177639		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.15464325190177639 | validation: 0.12463513700892936]
	TIME [epoch: 95.9 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15262760338229384		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.15262760338229384 | validation: 0.12246043542462288]
	TIME [epoch: 96 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15295594509084676		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.15295594509084676 | validation: 0.12262477529490559]
	TIME [epoch: 95.7 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15255341885825305		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.15255341885825305 | validation: 0.12236609853708409]
	TIME [epoch: 95.7 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15571007624213937		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.15571007624213937 | validation: 0.12358720062504165]
	TIME [epoch: 95.8 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1549748000696389		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.1549748000696389 | validation: 0.1233358693525201]
	TIME [epoch: 95.7 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15239153865895375		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.15239153865895375 | validation: 0.12778649639314815]
	TIME [epoch: 95.7 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1581227545214184		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.1581227545214184 | validation: 0.12718326875768313]
	TIME [epoch: 95.7 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15357122357928987		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.15357122357928987 | validation: 0.12115666253070767]
	TIME [epoch: 95.8 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15207781198689976		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.15207781198689976 | validation: 0.1238955947576595]
	TIME [epoch: 95.7 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15410947996843818		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.15410947996843818 | validation: 0.1236222772224845]
	TIME [epoch: 223 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15352822993719892		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.15352822993719892 | validation: 0.12844538556873597]
	TIME [epoch: 196 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15443969005306926		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.15443969005306926 | validation: 0.12712684605033578]
	TIME [epoch: 196 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15695638934482073		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.15695638934482073 | validation: 0.12342018823734865]
	TIME [epoch: 196 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15433651839246884		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.15433651839246884 | validation: 0.12734052097279439]
	TIME [epoch: 196 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15673076483793416		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.15673076483793416 | validation: 0.12165328644813282]
	TIME [epoch: 196 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15261439990204498		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.15261439990204498 | validation: 0.12365594564688953]
	TIME [epoch: 196 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1557768354686465		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.1557768354686465 | validation: 0.1241591759326259]
	TIME [epoch: 196 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1547451331655957		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.1547451331655957 | validation: 0.13018766277048693]
	TIME [epoch: 196 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15349473324744173		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.15349473324744173 | validation: 0.1237545007168273]
	TIME [epoch: 196 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15402135959260743		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.15402135959260743 | validation: 0.12695320489940876]
	TIME [epoch: 196 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15504302396541333		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.15504302396541333 | validation: 0.12446388497507259]
	TIME [epoch: 196 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15506223732863575		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.15506223732863575 | validation: 0.12213309234125894]
	TIME [epoch: 196 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15132281263068717		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.15132281263068717 | validation: 0.1259009100224787]
	TIME [epoch: 196 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15566104781421508		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.15566104781421508 | validation: 0.12382700336243882]
	TIME [epoch: 196 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15263307776650034		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.15263307776650034 | validation: 0.12575860680395715]
	TIME [epoch: 196 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15340067253335246		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.15340067253335246 | validation: 0.12254381906201842]
	TIME [epoch: 196 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15260088771888458		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.15260088771888458 | validation: 0.12456407677391028]
	TIME [epoch: 196 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1530445306670785		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.1530445306670785 | validation: 0.12292376178458655]
	TIME [epoch: 196 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15048369440884232		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.15048369440884232 | validation: 0.12218899560946136]
	TIME [epoch: 196 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15437585905513654		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.15437585905513654 | validation: 0.12477005944121533]
	TIME [epoch: 196 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15315137123688174		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.15315137123688174 | validation: 0.12395574180562574]
	TIME [epoch: 196 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15357603402171496		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.15357603402171496 | validation: 0.1239757124717759]
	TIME [epoch: 196 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15626898486193938		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.15626898486193938 | validation: 0.12083332610804116]
	TIME [epoch: 196 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_324.pth
	Model improved!!!
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15240964282691935		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.15240964282691935 | validation: 0.1220629469770282]
	TIME [epoch: 197 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15274028325158584		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.15274028325158584 | validation: 0.1245258323188285]
	TIME [epoch: 196 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15375620453433758		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.15375620453433758 | validation: 0.1250468323215529]
	TIME [epoch: 197 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1532623509932206		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.1532623509932206 | validation: 0.12272473142848413]
	TIME [epoch: 196 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15206752489317538		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.15206752489317538 | validation: 0.12419893559198432]
	TIME [epoch: 196 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15530474249460471		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.15530474249460471 | validation: 0.12406339746025377]
	TIME [epoch: 196 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15286859965275065		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.15286859965275065 | validation: 0.12409049104276848]
	TIME [epoch: 196 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15545308323687837		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15545308323687837 | validation: 0.12261472097734542]
	TIME [epoch: 196 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15342961384250942		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.15342961384250942 | validation: 0.12363258925003637]
	TIME [epoch: 196 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15189431595766		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.15189431595766 | validation: 0.126076572388316]
	TIME [epoch: 197 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1545584990301242		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.1545584990301242 | validation: 0.12289762944388258]
	TIME [epoch: 196 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15268640846679213		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.15268640846679213 | validation: 0.12287834724977116]
	TIME [epoch: 196 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15348653471770562		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.15348653471770562 | validation: 0.12161434171335794]
	TIME [epoch: 196 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1535328463035878		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.1535328463035878 | validation: 0.1230490561481512]
	TIME [epoch: 196 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15161251789372354		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.15161251789372354 | validation: 0.12759955206648982]
	TIME [epoch: 196 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15423477825595924		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.15423477825595924 | validation: 0.12092789349265251]
	TIME [epoch: 196 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15325205888936672		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.15325205888936672 | validation: 0.12651715365532779]
	TIME [epoch: 196 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15309486352150983		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.15309486352150983 | validation: 0.12264749661007186]
	TIME [epoch: 196 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15278879685937405		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.15278879685937405 | validation: 0.12190488491361977]
	TIME [epoch: 196 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15305992465010476		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.15305992465010476 | validation: 0.12065261679737171]
	TIME [epoch: 196 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_344.pth
	Model improved!!!
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1534094570444938		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.1534094570444938 | validation: 0.12330401830604723]
	TIME [epoch: 196 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1532568426739234		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.1532568426739234 | validation: 0.1208517532548834]
	TIME [epoch: 196 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15408124445277252		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.15408124445277252 | validation: 0.12109886129554566]
	TIME [epoch: 196 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15132772843961634		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.15132772843961634 | validation: 0.12120049981169996]
	TIME [epoch: 196 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1511843798703695		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.1511843798703695 | validation: 0.12870488155307158]
	TIME [epoch: 196 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15199824175157145		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.15199824175157145 | validation: 0.12449870049763448]
	TIME [epoch: 196 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15500636705293439		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.15500636705293439 | validation: 0.1245603459856903]
	TIME [epoch: 196 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15347575654547077		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.15347575654547077 | validation: 0.12257009786739417]
	TIME [epoch: 196 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1506888734527824		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.1506888734527824 | validation: 0.1252004768380326]
	TIME [epoch: 196 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1525612547410821		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.1525612547410821 | validation: 0.12322082079068672]
	TIME [epoch: 196 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15266218805181506		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.15266218805181506 | validation: 0.12662693738411215]
	TIME [epoch: 197 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15374195093506368		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.15374195093506368 | validation: 0.11989706960263269]
	TIME [epoch: 196 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_356.pth
	Model improved!!!
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15335563644460037		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.15335563644460037 | validation: 0.12468593739414766]
	TIME [epoch: 196 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15178926281660074		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.15178926281660074 | validation: 0.1256742748866737]
	TIME [epoch: 196 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1518037006788273		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.1518037006788273 | validation: 0.12463033289346677]
	TIME [epoch: 196 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15212483117423856		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.15212483117423856 | validation: 0.1237712958839278]
	TIME [epoch: 196 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15266413841362736		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.15266413841362736 | validation: 0.12161358159531481]
	TIME [epoch: 196 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1519699061002909		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.1519699061002909 | validation: 0.12155230360948624]
	TIME [epoch: 196 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15304430031453964		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.15304430031453964 | validation: 0.11919909356867012]
	TIME [epoch: 196 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset3_20241031_143817/states/model_facs_dec1_v2_argset3_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15516694359775693		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.15516694359775693 | validation: 0.12703423420989202]
	TIME [epoch: 196 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15354716429876958		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.15354716429876958 | validation: 0.1245576228364911]
	TIME [epoch: 197 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1522495540796041		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.1522495540796041 | validation: 0.12318254465585525]
	TIME [epoch: 196 sec]
EPOCH 367/1000:
	Training over batches...
