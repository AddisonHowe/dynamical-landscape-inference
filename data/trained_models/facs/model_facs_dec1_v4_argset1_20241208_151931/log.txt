Args:
Namespace(name='model_facs_dec1_v4_argset1', outdir='out/model_training/model_facs_dec1_v4_argset1', training_data='data/training_data/facs/facs_dec1_v4/training', validation_data='data/training_data/facs/facs_dec1_v4/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[100, 300, 500, 700], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.6738450527191162], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3833584764

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.24752024689602548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24752024689602548 | validation: 0.24506327672946063]
	TIME [epoch: 29.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.24150187530278755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24150187530278755 | validation: 0.19299123354824133]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.20045761586351207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20045761586351207 | validation: 0.16647193390499762]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.19210767100408455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19210767100408455 | validation: 0.16618729521776718]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1876708277432156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1876708277432156 | validation: 0.14454676584490156]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.17046162569918913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17046162569918913 | validation: 0.13905127526730487]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.15586850239457406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15586850239457406 | validation: 0.12331515848838444]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.15340241903052668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15340241903052668 | validation: 0.12524523025954667]
	TIME [epoch: 4.14 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.14240720468345194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14240720468345194 | validation: 0.1322306424566423]
	TIME [epoch: 4.14 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.14011674634957788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14011674634957788 | validation: 0.12572953842347598]
	TIME [epoch: 4.14 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1389495526031627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1389495526031627 | validation: 0.12366495532000794]
	TIME [epoch: 4.14 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1377981972331824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1377981972331824 | validation: 0.1248719225397354]
	TIME [epoch: 4.14 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.13330439252613313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13330439252613313 | validation: 0.12350740444110785]
	TIME [epoch: 4.14 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.13449076358888754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13449076358888754 | validation: 0.12334460281002313]
	TIME [epoch: 4.13 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12983176610641534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12983176610641534 | validation: 0.11962792669292412]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12469023124463074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12469023124463074 | validation: 0.11619098696633655]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.11863676076904921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11863676076904921 | validation: 0.1138135390746559]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12050992844064724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12050992844064724 | validation: 0.13047554747971898]
	TIME [epoch: 4.13 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12183494796291096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12183494796291096 | validation: 0.13804219086600683]
	TIME [epoch: 4.13 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.11488813762790946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11488813762790946 | validation: 0.11016901071639738]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10898957594363218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10898957594363218 | validation: 0.11554873211893513]
	TIME [epoch: 4.13 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10653645179890277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10653645179890277 | validation: 0.12237848740074793]
	TIME [epoch: 4.12 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.11443471393618117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11443471393618117 | validation: 0.11661416044133543]
	TIME [epoch: 4.12 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10115390779465744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10115390779465744 | validation: 0.10511224564934303]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09586806524866849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09586806524866849 | validation: 0.09812704208391292]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09468835632033375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09468835632033375 | validation: 0.1112397952478652]
	TIME [epoch: 4.14 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09734747997888278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09734747997888278 | validation: 0.1114175737508174]
	TIME [epoch: 4.15 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0947275817063598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0947275817063598 | validation: 0.10716216278761644]
	TIME [epoch: 4.14 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09279889761522925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09279889761522925 | validation: 0.09802841415317338]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08255875207072513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08255875207072513 | validation: 0.09609553786698562]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0814767356479969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0814767356479969 | validation: 0.09789967861455856]
	TIME [epoch: 4.13 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08266863509282409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08266863509282409 | validation: 0.09083286956767851]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07591257739755948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07591257739755948 | validation: 0.08646652687759954]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08100084166240999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08100084166240999 | validation: 0.07682637144969455]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07483007846698984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07483007846698984 | validation: 0.08161755437446677]
	TIME [epoch: 4.13 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07262902510292012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07262902510292012 | validation: 0.07670817585241126]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07073191481589673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07073191481589673 | validation: 0.06869530776174133]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06563661871534959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06563661871534959 | validation: 0.07070867281726939]
	TIME [epoch: 4.12 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06294434380232743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06294434380232743 | validation: 0.06315718404124832]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06307934440165298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06307934440165298 | validation: 0.07021522315646253]
	TIME [epoch: 4.13 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05805357625074457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05805357625074457 | validation: 0.061795709531456855]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05619290208539499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05619290208539499 | validation: 0.06329681390029297]
	TIME [epoch: 4.13 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.061003662016551254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061003662016551254 | validation: 0.06354580980997727]
	TIME [epoch: 4.12 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05652328618123708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05652328618123708 | validation: 0.056604958323519416]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0516527559984277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0516527559984277 | validation: 0.052981148512715105]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.052097075396625246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052097075396625246 | validation: 0.05142337782631647]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05200534018281092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05200534018281092 | validation: 0.07424689816671468]
	TIME [epoch: 4.13 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.060205184929382725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.060205184929382725 | validation: 0.04879416410273382]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.048635295896423965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048635295896423965 | validation: 0.0500580859288367]
	TIME [epoch: 4.16 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04985414569391932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04985414569391932 | validation: 0.046165899200364346]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0481845852525331		[learning rate: 0.0099677]
	Learning Rate: 0.00996774
	LOSS [training: 0.0481845852525331 | validation: 0.05804325084178036]
	TIME [epoch: 4.13 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0519708031707059		[learning rate: 0.0099195]
	Learning Rate: 0.00991953
	LOSS [training: 0.0519708031707059 | validation: 0.04789670145591878]
	TIME [epoch: 4.12 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05586453042755569		[learning rate: 0.0098716]
	Learning Rate: 0.00987156
	LOSS [training: 0.05586453042755569 | validation: 0.04934594693000819]
	TIME [epoch: 4.12 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.045487232944296484		[learning rate: 0.0098238]
	Learning Rate: 0.00982383
	LOSS [training: 0.045487232944296484 | validation: 0.04291252207330812]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04483244171619188		[learning rate: 0.0097763]
	Learning Rate: 0.00977632
	LOSS [training: 0.04483244171619188 | validation: 0.053245899228952676]
	TIME [epoch: 4.13 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04698979023919279		[learning rate: 0.009729]
	Learning Rate: 0.00972904
	LOSS [training: 0.04698979023919279 | validation: 0.04658521767650553]
	TIME [epoch: 4.14 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04266176951292261		[learning rate: 0.009682]
	Learning Rate: 0.009682
	LOSS [training: 0.04266176951292261 | validation: 0.049740896285474234]
	TIME [epoch: 4.13 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04217902202178971		[learning rate: 0.0096352]
	Learning Rate: 0.00963518
	LOSS [training: 0.04217902202178971 | validation: 0.04602234021437687]
	TIME [epoch: 4.13 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05314842507105422		[learning rate: 0.0095886]
	Learning Rate: 0.00958858
	LOSS [training: 0.05314842507105422 | validation: 0.05252051353071085]
	TIME [epoch: 4.12 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.043597298763208274		[learning rate: 0.0095422]
	Learning Rate: 0.00954221
	LOSS [training: 0.043597298763208274 | validation: 0.043459844729903975]
	TIME [epoch: 4.12 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04149919327214905		[learning rate: 0.0094961]
	Learning Rate: 0.00949607
	LOSS [training: 0.04149919327214905 | validation: 0.04593177055686657]
	TIME [epoch: 4.13 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04543941567897389		[learning rate: 0.0094501]
	Learning Rate: 0.00945015
	LOSS [training: 0.04543941567897389 | validation: 0.046298778294159244]
	TIME [epoch: 4.13 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.043390562222147065		[learning rate: 0.0094044]
	Learning Rate: 0.00940445
	LOSS [training: 0.043390562222147065 | validation: 0.04913499116563024]
	TIME [epoch: 4.13 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04158071940957205		[learning rate: 0.009359]
	Learning Rate: 0.00935897
	LOSS [training: 0.04158071940957205 | validation: 0.04188468029098796]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03955098956777791		[learning rate: 0.0093137]
	Learning Rate: 0.00931371
	LOSS [training: 0.03955098956777791 | validation: 0.04677688890530927]
	TIME [epoch: 4.13 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04229188448954805		[learning rate: 0.0092687]
	Learning Rate: 0.00926867
	LOSS [training: 0.04229188448954805 | validation: 0.04445176356866298]
	TIME [epoch: 4.12 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04052068592206922		[learning rate: 0.0092239]
	Learning Rate: 0.00922385
	LOSS [training: 0.04052068592206922 | validation: 0.04535225933629199]
	TIME [epoch: 4.13 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04064237500399472		[learning rate: 0.0091792]
	Learning Rate: 0.00917925
	LOSS [training: 0.04064237500399472 | validation: 0.04056284990782647]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.037292764774568506		[learning rate: 0.0091349]
	Learning Rate: 0.00913486
	LOSS [training: 0.037292764774568506 | validation: 0.03984674778893927]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.041449303104200114		[learning rate: 0.0090907]
	Learning Rate: 0.00909068
	LOSS [training: 0.041449303104200114 | validation: 0.04422243141059346]
	TIME [epoch: 4.15 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04023905837123896		[learning rate: 0.0090467]
	Learning Rate: 0.00904672
	LOSS [training: 0.04023905837123896 | validation: 0.038754701567803924]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.038777678288215545		[learning rate: 0.009003]
	Learning Rate: 0.00900297
	LOSS [training: 0.038777678288215545 | validation: 0.042893580653776714]
	TIME [epoch: 4.14 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0436768908966241		[learning rate: 0.0089594]
	Learning Rate: 0.00895944
	LOSS [training: 0.0436768908966241 | validation: 0.04542402443822859]
	TIME [epoch: 4.14 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04157169274888081		[learning rate: 0.0089161]
	Learning Rate: 0.00891611
	LOSS [training: 0.04157169274888081 | validation: 0.03814525559963038]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03715548901555577		[learning rate: 0.008873]
	Learning Rate: 0.00887299
	LOSS [training: 0.03715548901555577 | validation: 0.03957349811378868]
	TIME [epoch: 4.15 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.034593969896240986		[learning rate: 0.0088301]
	Learning Rate: 0.00883009
	LOSS [training: 0.034593969896240986 | validation: 0.04840552886512731]
	TIME [epoch: 4.14 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.042258967067407886		[learning rate: 0.0087874]
	Learning Rate: 0.00878738
	LOSS [training: 0.042258967067407886 | validation: 0.03860353339655854]
	TIME [epoch: 4.14 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0373669131998019		[learning rate: 0.0087449]
	Learning Rate: 0.00874489
	LOSS [training: 0.0373669131998019 | validation: 0.03710584977336844]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.061894488216215154		[learning rate: 0.0087026]
	Learning Rate: 0.0087026
	LOSS [training: 0.061894488216215154 | validation: 0.044412785720268584]
	TIME [epoch: 4.14 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04465011556062392		[learning rate: 0.0086605]
	Learning Rate: 0.00866052
	LOSS [training: 0.04465011556062392 | validation: 0.03962274552241143]
	TIME [epoch: 4.14 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.047553455015245126		[learning rate: 0.0086186]
	Learning Rate: 0.00861864
	LOSS [training: 0.047553455015245126 | validation: 0.036641097879619]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03931268757488141		[learning rate: 0.008577]
	Learning Rate: 0.00857696
	LOSS [training: 0.03931268757488141 | validation: 0.03629270206621465]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03636410250664642		[learning rate: 0.0085355]
	Learning Rate: 0.00853548
	LOSS [training: 0.03636410250664642 | validation: 0.03650805785396374]
	TIME [epoch: 4.13 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.034298955994135245		[learning rate: 0.0084942]
	Learning Rate: 0.00849421
	LOSS [training: 0.034298955994135245 | validation: 0.03645352538678423]
	TIME [epoch: 4.12 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.033189841753085855		[learning rate: 0.0084531]
	Learning Rate: 0.00845313
	LOSS [training: 0.033189841753085855 | validation: 0.03771803195880543]
	TIME [epoch: 4.12 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0331789948355744		[learning rate: 0.0084123]
	Learning Rate: 0.00841225
	LOSS [training: 0.0331789948355744 | validation: 0.03693534043391195]
	TIME [epoch: 4.12 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03455824044297295		[learning rate: 0.0083716]
	Learning Rate: 0.00837157
	LOSS [training: 0.03455824044297295 | validation: 0.036179656262918185]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03552578775538439		[learning rate: 0.0083311]
	Learning Rate: 0.00833109
	LOSS [training: 0.03552578775538439 | validation: 0.03613489480448633]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03710850487333036		[learning rate: 0.0082908]
	Learning Rate: 0.0082908
	LOSS [training: 0.03710850487333036 | validation: 0.03679360496640002]
	TIME [epoch: 4.12 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03747581274087671		[learning rate: 0.0082507]
	Learning Rate: 0.00825071
	LOSS [training: 0.03747581274087671 | validation: 0.03965749051894076]
	TIME [epoch: 4.12 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03506611870282192		[learning rate: 0.0082108]
	Learning Rate: 0.00821081
	LOSS [training: 0.03506611870282192 | validation: 0.035886615390247574]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.033336548857857085		[learning rate: 0.0081711]
	Learning Rate: 0.0081711
	LOSS [training: 0.033336548857857085 | validation: 0.034778697445731456]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.032569501938451775		[learning rate: 0.0081316]
	Learning Rate: 0.00813159
	LOSS [training: 0.032569501938451775 | validation: 0.034545562419041005]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.036605768191961256		[learning rate: 0.0080923]
	Learning Rate: 0.00809227
	LOSS [training: 0.036605768191961256 | validation: 0.034650489809659075]
	TIME [epoch: 4.13 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03237037727577959		[learning rate: 0.0080531]
	Learning Rate: 0.00805313
	LOSS [training: 0.03237037727577959 | validation: 0.03295189927210978]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03445391673400255		[learning rate: 0.0080142]
	Learning Rate: 0.00801419
	LOSS [training: 0.03445391673400255 | validation: 0.0347499753960387]
	TIME [epoch: 4.13 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03198903270564678		[learning rate: 0.0079754]
	Learning Rate: 0.00797543
	LOSS [training: 0.03198903270564678 | validation: 0.03200751327607581]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03203199946447519		[learning rate: 0.0079369]
	Learning Rate: 0.00793687
	LOSS [training: 0.03203199946447519 | validation: 0.031742322433515616]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03153667580747464		[learning rate: 0.0078985]
	Learning Rate: 0.00789849
	LOSS [training: 0.03153667580747464 | validation: 0.03360561848326105]
	TIME [epoch: 4.15 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03056865283323051		[learning rate: 0.0078603]
	Learning Rate: 0.00786029
	LOSS [training: 0.03056865283323051 | validation: 0.03390447965862301]
	TIME [epoch: 4.12 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03392125196082626		[learning rate: 0.0078223]
	Learning Rate: 0.00782228
	LOSS [training: 0.03392125196082626 | validation: 0.03896072520010576]
	TIME [epoch: 31.7 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03257330740906781		[learning rate: 0.0077845]
	Learning Rate: 0.00778445
	LOSS [training: 0.03257330740906781 | validation: 0.03194915037342933]
	TIME [epoch: 7.95 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03345002319904806		[learning rate: 0.0077468]
	Learning Rate: 0.00774681
	LOSS [training: 0.03345002319904806 | validation: 0.03241936391084957]
	TIME [epoch: 7.95 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03015578292686655		[learning rate: 0.0077093]
	Learning Rate: 0.00770935
	LOSS [training: 0.03015578292686655 | validation: 0.031702616937458766]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030515737929239218		[learning rate: 0.0076721]
	Learning Rate: 0.00767206
	LOSS [training: 0.030515737929239218 | validation: 0.03333733207837227]
	TIME [epoch: 7.96 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030021604385292017		[learning rate: 0.007635]
	Learning Rate: 0.00763496
	LOSS [training: 0.030021604385292017 | validation: 0.03570315916229167]
	TIME [epoch: 7.95 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031522428607392454		[learning rate: 0.007598]
	Learning Rate: 0.00759804
	LOSS [training: 0.031522428607392454 | validation: 0.033156285369734854]
	TIME [epoch: 7.96 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030666435908069195		[learning rate: 0.0075613]
	Learning Rate: 0.0075613
	LOSS [training: 0.030666435908069195 | validation: 0.03246982078498541]
	TIME [epoch: 7.95 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028928453225404247		[learning rate: 0.0075247]
	Learning Rate: 0.00752474
	LOSS [training: 0.028928453225404247 | validation: 0.031019560333423152]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.033004026885087884		[learning rate: 0.0074883]
	Learning Rate: 0.00748835
	LOSS [training: 0.033004026885087884 | validation: 0.030492825582823773]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030363306176503985		[learning rate: 0.0074521]
	Learning Rate: 0.00745213
	LOSS [training: 0.030363306176503985 | validation: 0.03204784600252656]
	TIME [epoch: 7.95 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031177523089068956		[learning rate: 0.0074161]
	Learning Rate: 0.0074161
	LOSS [training: 0.031177523089068956 | validation: 0.032657901218916006]
	TIME [epoch: 7.95 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030732753606041135		[learning rate: 0.0073802]
	Learning Rate: 0.00738023
	LOSS [training: 0.030732753606041135 | validation: 0.03077222784457664]
	TIME [epoch: 7.95 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031014267699240927		[learning rate: 0.0073445]
	Learning Rate: 0.00734454
	LOSS [training: 0.031014267699240927 | validation: 0.03147917892875846]
	TIME [epoch: 7.94 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02933310483693853		[learning rate: 0.007309]
	Learning Rate: 0.00730903
	LOSS [training: 0.02933310483693853 | validation: 0.030570785222648524]
	TIME [epoch: 7.95 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030922395983287488		[learning rate: 0.0072737]
	Learning Rate: 0.00727368
	LOSS [training: 0.030922395983287488 | validation: 0.03186003243799892]
	TIME [epoch: 7.94 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030879248224520043		[learning rate: 0.0072385]
	Learning Rate: 0.00723851
	LOSS [training: 0.030879248224520043 | validation: 0.030489783470769975]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_117.pth
	Model improved!!!
EPOCH 118/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02852807553711174		[learning rate: 0.0072035]
	Learning Rate: 0.0072035
	LOSS [training: 0.02852807553711174 | validation: 0.031720500231045216]
	TIME [epoch: 7.95 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03082199914616246		[learning rate: 0.0071687]
	Learning Rate: 0.00716867
	LOSS [training: 0.03082199914616246 | validation: 0.03071650496507064]
	TIME [epoch: 7.95 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027659441443686945		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.027659441443686945 | validation: 0.03127060066092906]
	TIME [epoch: 7.95 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02852629426582103		[learning rate: 0.0070995]
	Learning Rate: 0.0070995
	LOSS [training: 0.02852629426582103 | validation: 0.02957958400588713]
	TIME [epoch: 7.94 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02779875800240904		[learning rate: 0.0070652]
	Learning Rate: 0.00706517
	LOSS [training: 0.02779875800240904 | validation: 0.03478976583789053]
	TIME [epoch: 7.99 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028497947474793617		[learning rate: 0.007031]
	Learning Rate: 0.00703101
	LOSS [training: 0.028497947474793617 | validation: 0.03382657267949805]
	TIME [epoch: 8 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029310389648445494		[learning rate: 0.006997]
	Learning Rate: 0.00699701
	LOSS [training: 0.029310389648445494 | validation: 0.03543848959010432]
	TIME [epoch: 8 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03499716876942317		[learning rate: 0.0069632]
	Learning Rate: 0.00696317
	LOSS [training: 0.03499716876942317 | validation: 0.030733832368228336]
	TIME [epoch: 8 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03072596067983883		[learning rate: 0.0069295]
	Learning Rate: 0.0069295
	LOSS [training: 0.03072596067983883 | validation: 0.030126244204025848]
	TIME [epoch: 7.99 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03318346432227482		[learning rate: 0.006896]
	Learning Rate: 0.00689599
	LOSS [training: 0.03318346432227482 | validation: 0.0320146392578592]
	TIME [epoch: 7.99 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0301756329972169		[learning rate: 0.0068626]
	Learning Rate: 0.00686264
	LOSS [training: 0.0301756329972169 | validation: 0.031391914605605406]
	TIME [epoch: 7.99 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029598316703487126		[learning rate: 0.0068295]
	Learning Rate: 0.00682945
	LOSS [training: 0.029598316703487126 | validation: 0.03034325097342913]
	TIME [epoch: 7.95 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030180819893407585		[learning rate: 0.0067964]
	Learning Rate: 0.00679643
	LOSS [training: 0.030180819893407585 | validation: 0.0320975217806117]
	TIME [epoch: 7.96 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028750052360373726		[learning rate: 0.0067636]
	Learning Rate: 0.00676356
	LOSS [training: 0.028750052360373726 | validation: 0.029621744405848163]
	TIME [epoch: 7.96 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028957898117651582		[learning rate: 0.0067309]
	Learning Rate: 0.00673085
	LOSS [training: 0.028957898117651582 | validation: 0.028993790426480318]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028486054129325786		[learning rate: 0.0066983]
	Learning Rate: 0.0066983
	LOSS [training: 0.028486054129325786 | validation: 0.027533654949126532]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_133.pth
	Model improved!!!
EPOCH 134/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028631846592109322		[learning rate: 0.0066659]
	Learning Rate: 0.00666591
	LOSS [training: 0.028631846592109322 | validation: 0.027947508461858745]
	TIME [epoch: 7.96 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026952376897993204		[learning rate: 0.0066337]
	Learning Rate: 0.00663368
	LOSS [training: 0.026952376897993204 | validation: 0.028483333794353794]
	TIME [epoch: 7.98 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027482847505018615		[learning rate: 0.0066016]
	Learning Rate: 0.0066016
	LOSS [training: 0.027482847505018615 | validation: 0.029615434194901688]
	TIME [epoch: 7.98 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02622110315817186		[learning rate: 0.0065697]
	Learning Rate: 0.00656967
	LOSS [training: 0.02622110315817186 | validation: 0.027566625237992137]
	TIME [epoch: 7.98 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026723457266666455		[learning rate: 0.0065379]
	Learning Rate: 0.0065379
	LOSS [training: 0.026723457266666455 | validation: 0.030483266310580386]
	TIME [epoch: 7.97 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02729004671175135		[learning rate: 0.0065063]
	Learning Rate: 0.00650629
	LOSS [training: 0.02729004671175135 | validation: 0.027565712286984918]
	TIME [epoch: 7.96 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.033496815477640364		[learning rate: 0.0064748]
	Learning Rate: 0.00647483
	LOSS [training: 0.033496815477640364 | validation: 0.031293856528894284]
	TIME [epoch: 7.96 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028587473901829252		[learning rate: 0.0064435]
	Learning Rate: 0.00644351
	LOSS [training: 0.028587473901829252 | validation: 0.02825350177354276]
	TIME [epoch: 7.96 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027381821689888505		[learning rate: 0.0064124]
	Learning Rate: 0.00641235
	LOSS [training: 0.027381821689888505 | validation: 0.027808183920730128]
	TIME [epoch: 7.96 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028325445303523503		[learning rate: 0.0063813]
	Learning Rate: 0.00638135
	LOSS [training: 0.028325445303523503 | validation: 0.02914906447646355]
	TIME [epoch: 7.95 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02664882901028154		[learning rate: 0.0063505]
	Learning Rate: 0.00635049
	LOSS [training: 0.02664882901028154 | validation: 0.02796483063947917]
	TIME [epoch: 7.96 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026271302866109666		[learning rate: 0.0063198]
	Learning Rate: 0.00631978
	LOSS [training: 0.026271302866109666 | validation: 0.0273360232131898]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025858729451367215		[learning rate: 0.0062892]
	Learning Rate: 0.00628922
	LOSS [training: 0.025858729451367215 | validation: 0.028810470726812157]
	TIME [epoch: 7.95 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029007081158073638		[learning rate: 0.0062588]
	Learning Rate: 0.0062588
	LOSS [training: 0.029007081158073638 | validation: 0.02895775210147228]
	TIME [epoch: 7.96 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02817127296972093		[learning rate: 0.0062285]
	Learning Rate: 0.00622854
	LOSS [training: 0.02817127296972093 | validation: 0.027796707444777174]
	TIME [epoch: 7.96 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025872780003855834		[learning rate: 0.0061984]
	Learning Rate: 0.00619842
	LOSS [training: 0.025872780003855834 | validation: 0.03128704077733264]
	TIME [epoch: 7.96 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027890600869019667		[learning rate: 0.0061684]
	Learning Rate: 0.00616844
	LOSS [training: 0.027890600869019667 | validation: 0.027270857599583285]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029712823420965137		[learning rate: 0.0061386]
	Learning Rate: 0.00613861
	LOSS [training: 0.029712823420965137 | validation: 0.02792183768114201]
	TIME [epoch: 7.95 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02673364417862573		[learning rate: 0.0061089]
	Learning Rate: 0.00610893
	LOSS [training: 0.02673364417862573 | validation: 0.029749447485809304]
	TIME [epoch: 7.96 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028546201542254204		[learning rate: 0.0060794]
	Learning Rate: 0.00607938
	LOSS [training: 0.028546201542254204 | validation: 0.027889259190983628]
	TIME [epoch: 7.95 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026283115467700364		[learning rate: 0.00605]
	Learning Rate: 0.00604999
	LOSS [training: 0.026283115467700364 | validation: 0.0284589415266677]
	TIME [epoch: 7.96 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025770190681443563		[learning rate: 0.0060207]
	Learning Rate: 0.00602073
	LOSS [training: 0.025770190681443563 | validation: 0.029409594311523915]
	TIME [epoch: 7.97 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027408888267425238		[learning rate: 0.0059916]
	Learning Rate: 0.00599161
	LOSS [training: 0.027408888267425238 | validation: 0.027388455185009555]
	TIME [epoch: 7.96 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025870916185540382		[learning rate: 0.0059626]
	Learning Rate: 0.00596264
	LOSS [training: 0.025870916185540382 | validation: 0.027976534695349414]
	TIME [epoch: 7.95 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02634268463020986		[learning rate: 0.0059338]
	Learning Rate: 0.00593381
	LOSS [training: 0.02634268463020986 | validation: 0.02933144415778756]
	TIME [epoch: 7.94 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025349058456208915		[learning rate: 0.0059051]
	Learning Rate: 0.00590511
	LOSS [training: 0.025349058456208915 | validation: 0.028331558269559607]
	TIME [epoch: 7.96 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024530593551156266		[learning rate: 0.0058766]
	Learning Rate: 0.00587655
	LOSS [training: 0.024530593551156266 | validation: 0.02827606872897534]
	TIME [epoch: 7.95 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02525890709988755		[learning rate: 0.0058481]
	Learning Rate: 0.00584814
	LOSS [training: 0.02525890709988755 | validation: 0.027210724757984722]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025553196491595754		[learning rate: 0.0058199]
	Learning Rate: 0.00581986
	LOSS [training: 0.025553196491595754 | validation: 0.027784230228604264]
	TIME [epoch: 7.95 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02539083643709415		[learning rate: 0.0057917]
	Learning Rate: 0.00579171
	LOSS [training: 0.02539083643709415 | validation: 0.02750061094369299]
	TIME [epoch: 7.96 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025341548753488995		[learning rate: 0.0057637]
	Learning Rate: 0.0057637
	LOSS [training: 0.025341548753488995 | validation: 0.028848926737434336]
	TIME [epoch: 7.97 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025656403308279164		[learning rate: 0.0057358]
	Learning Rate: 0.00573583
	LOSS [training: 0.025656403308279164 | validation: 0.0268966344900603]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_165.pth
	Model improved!!!
EPOCH 166/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02535002161838505		[learning rate: 0.0057081]
	Learning Rate: 0.0057081
	LOSS [training: 0.02535002161838505 | validation: 0.02884183636834167]
	TIME [epoch: 7.96 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030628781512542388		[learning rate: 0.0056805]
	Learning Rate: 0.00568049
	LOSS [training: 0.030628781512542388 | validation: 0.02783175093061867]
	TIME [epoch: 7.95 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024962833694630208		[learning rate: 0.005653]
	Learning Rate: 0.00565302
	LOSS [training: 0.024962833694630208 | validation: 0.0274440588629011]
	TIME [epoch: 7.95 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02461057108768719		[learning rate: 0.0056257]
	Learning Rate: 0.00562569
	LOSS [training: 0.02461057108768719 | validation: 0.027599058363731967]
	TIME [epoch: 7.95 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02449586134947047		[learning rate: 0.0055985]
	Learning Rate: 0.00559848
	LOSS [training: 0.02449586134947047 | validation: 0.02757057879687393]
	TIME [epoch: 7.96 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024778222866407892		[learning rate: 0.0055714]
	Learning Rate: 0.00557141
	LOSS [training: 0.024778222866407892 | validation: 0.02966298618951549]
	TIME [epoch: 7.95 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02833478733228512		[learning rate: 0.0055445]
	Learning Rate: 0.00554447
	LOSS [training: 0.02833478733228512 | validation: 0.028308286627753473]
	TIME [epoch: 7.95 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025970047277180528		[learning rate: 0.0055177]
	Learning Rate: 0.00551765
	LOSS [training: 0.025970047277180528 | validation: 0.0292116355966634]
	TIME [epoch: 7.95 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025496287552736554		[learning rate: 0.005491]
	Learning Rate: 0.00549097
	LOSS [training: 0.025496287552736554 | validation: 0.026945305839054245]
	TIME [epoch: 7.95 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024216259363258708		[learning rate: 0.0054644]
	Learning Rate: 0.00546442
	LOSS [training: 0.024216259363258708 | validation: 0.026770542648187397]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02390207648608501		[learning rate: 0.005438]
	Learning Rate: 0.00543799
	LOSS [training: 0.02390207648608501 | validation: 0.027076747938322404]
	TIME [epoch: 7.95 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025383984821006927		[learning rate: 0.0054117]
	Learning Rate: 0.0054117
	LOSS [training: 0.025383984821006927 | validation: 0.026011848811222083]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024743256352999208		[learning rate: 0.0053855]
	Learning Rate: 0.00538553
	LOSS [training: 0.024743256352999208 | validation: 0.027764569835422]
	TIME [epoch: 7.97 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024340353937030396		[learning rate: 0.0053595]
	Learning Rate: 0.00535948
	LOSS [training: 0.024340353937030396 | validation: 0.028607831608489176]
	TIME [epoch: 7.97 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022797501190865054		[learning rate: 0.0053336]
	Learning Rate: 0.00533356
	LOSS [training: 0.022797501190865054 | validation: 0.025967885964735617]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_180.pth
	Model improved!!!
EPOCH 181/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02380956587889581		[learning rate: 0.0053078]
	Learning Rate: 0.00530777
	LOSS [training: 0.02380956587889581 | validation: 0.02721636200398375]
	TIME [epoch: 7.97 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024373333530782176		[learning rate: 0.0052821]
	Learning Rate: 0.0052821
	LOSS [training: 0.024373333530782176 | validation: 0.027769090617847325]
	TIME [epoch: 7.96 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025122089565135546		[learning rate: 0.0052566]
	Learning Rate: 0.00525656
	LOSS [training: 0.025122089565135546 | validation: 0.02720088375840267]
	TIME [epoch: 7.94 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025262864326563387		[learning rate: 0.0052311]
	Learning Rate: 0.00523114
	LOSS [training: 0.025262864326563387 | validation: 0.027642302338956648]
	TIME [epoch: 7.95 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02369952754052491		[learning rate: 0.0052058]
	Learning Rate: 0.00520584
	LOSS [training: 0.02369952754052491 | validation: 0.028435220093136367]
	TIME [epoch: 7.95 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022738160370377476		[learning rate: 0.0051807]
	Learning Rate: 0.00518067
	LOSS [training: 0.022738160370377476 | validation: 0.026900574439442274]
	TIME [epoch: 7.95 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02326809811254411		[learning rate: 0.0051556]
	Learning Rate: 0.00515562
	LOSS [training: 0.02326809811254411 | validation: 0.027543816482199206]
	TIME [epoch: 7.95 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02387016388555252		[learning rate: 0.0051307]
	Learning Rate: 0.00513069
	LOSS [training: 0.02387016388555252 | validation: 0.028423570893143183]
	TIME [epoch: 7.94 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024705174083729145		[learning rate: 0.0051059]
	Learning Rate: 0.00510587
	LOSS [training: 0.024705174083729145 | validation: 0.026243864090373648]
	TIME [epoch: 7.95 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0236827953516264		[learning rate: 0.0050812]
	Learning Rate: 0.00508118
	LOSS [training: 0.0236827953516264 | validation: 0.02698193433605107]
	TIME [epoch: 7.95 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023001426493512066		[learning rate: 0.0050566]
	Learning Rate: 0.00505661
	LOSS [training: 0.023001426493512066 | validation: 0.02621235584481882]
	TIME [epoch: 7.96 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026196885863539368		[learning rate: 0.0050322]
	Learning Rate: 0.00503216
	LOSS [training: 0.026196885863539368 | validation: 0.026587123197713586]
	TIME [epoch: 7.97 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023659433116424444		[learning rate: 0.0050078]
	Learning Rate: 0.00500782
	LOSS [training: 0.023659433116424444 | validation: 0.03009294860089724]
	TIME [epoch: 7.97 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02500720564193001		[learning rate: 0.0049836]
	Learning Rate: 0.00498361
	LOSS [training: 0.02500720564193001 | validation: 0.025918800492705178]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023017055153646323		[learning rate: 0.0049595]
	Learning Rate: 0.00495951
	LOSS [training: 0.023017055153646323 | validation: 0.026111026887882426]
	TIME [epoch: 7.98 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02324673693378683		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.02324673693378683 | validation: 0.02635477080305944]
	TIME [epoch: 7.99 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024694005976269955		[learning rate: 0.0049117]
	Learning Rate: 0.00491166
	LOSS [training: 0.024694005976269955 | validation: 0.025444634809801636]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024116390645293775		[learning rate: 0.0048879]
	Learning Rate: 0.00488791
	LOSS [training: 0.024116390645293775 | validation: 0.02685353889248156]
	TIME [epoch: 7.97 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023342801345900426		[learning rate: 0.0048643]
	Learning Rate: 0.00486427
	LOSS [training: 0.023342801345900426 | validation: 0.027054018379440718]
	TIME [epoch: 7.95 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02529780602496644		[learning rate: 0.0048407]
	Learning Rate: 0.00484075
	LOSS [training: 0.02529780602496644 | validation: 0.02904482208873618]
	TIME [epoch: 7.96 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025658382767153768		[learning rate: 0.0048173]
	Learning Rate: 0.00481734
	LOSS [training: 0.025658382767153768 | validation: 0.026707739561663446]
	TIME [epoch: 8 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024503735437199015		[learning rate: 0.004794]
	Learning Rate: 0.00479404
	LOSS [training: 0.024503735437199015 | validation: 0.029261683918955797]
	TIME [epoch: 7.98 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02670422172666298		[learning rate: 0.0047709]
	Learning Rate: 0.00477086
	LOSS [training: 0.02670422172666298 | validation: 0.027781812838844917]
	TIME [epoch: 7.97 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02643946854407066		[learning rate: 0.0047478]
	Learning Rate: 0.00474779
	LOSS [training: 0.02643946854407066 | validation: 0.02687709078598303]
	TIME [epoch: 7.97 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024450338925126866		[learning rate: 0.0047248]
	Learning Rate: 0.00472483
	LOSS [training: 0.024450338925126866 | validation: 0.027675881332516014]
	TIME [epoch: 7.99 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02376026610603839		[learning rate: 0.004702]
	Learning Rate: 0.00470198
	LOSS [training: 0.02376026610603839 | validation: 0.027336543439123836]
	TIME [epoch: 8 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02293439590097102		[learning rate: 0.0046792]
	Learning Rate: 0.00467924
	LOSS [training: 0.02293439590097102 | validation: 0.027610169255762772]
	TIME [epoch: 8 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023810354446951985		[learning rate: 0.0046566]
	Learning Rate: 0.00465661
	LOSS [training: 0.023810354446951985 | validation: 0.028134841634302927]
	TIME [epoch: 8 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02394841867929005		[learning rate: 0.0046341]
	Learning Rate: 0.00463409
	LOSS [training: 0.02394841867929005 | validation: 0.0261135968601949]
	TIME [epoch: 7.99 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023076284233637556		[learning rate: 0.0046117]
	Learning Rate: 0.00461168
	LOSS [training: 0.023076284233637556 | validation: 0.027639382768308778]
	TIME [epoch: 8 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023021087262627637		[learning rate: 0.0045894]
	Learning Rate: 0.00458938
	LOSS [training: 0.023021087262627637 | validation: 0.027171714721309314]
	TIME [epoch: 8 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0229428954475909		[learning rate: 0.0045672]
	Learning Rate: 0.00456719
	LOSS [training: 0.0229428954475909 | validation: 0.026043802042242024]
	TIME [epoch: 7.98 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022353602410000797		[learning rate: 0.0045451]
	Learning Rate: 0.0045451
	LOSS [training: 0.022353602410000797 | validation: 0.025765929713079977]
	TIME [epoch: 7.95 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023324884854586517		[learning rate: 0.0045231]
	Learning Rate: 0.00452312
	LOSS [training: 0.023324884854586517 | validation: 0.025554192975675585]
	TIME [epoch: 7.95 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023221259881451142		[learning rate: 0.0045013]
	Learning Rate: 0.00450125
	LOSS [training: 0.023221259881451142 | validation: 0.027410825693080815]
	TIME [epoch: 7.98 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022169992046103985		[learning rate: 0.0044795]
	Learning Rate: 0.00447948
	LOSS [training: 0.022169992046103985 | validation: 0.02599709619161029]
	TIME [epoch: 7.97 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024645219779525735		[learning rate: 0.0044578]
	Learning Rate: 0.00445782
	LOSS [training: 0.024645219779525735 | validation: 0.028164757331816382]
	TIME [epoch: 7.99 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024345872137438804		[learning rate: 0.0044363]
	Learning Rate: 0.00443627
	LOSS [training: 0.024345872137438804 | validation: 0.02524067480576236]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022482208272078707		[learning rate: 0.0044148]
	Learning Rate: 0.00441481
	LOSS [training: 0.022482208272078707 | validation: 0.02611117458516067]
	TIME [epoch: 7.99 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021895830196844157		[learning rate: 0.0043935]
	Learning Rate: 0.00439346
	LOSS [training: 0.021895830196844157 | validation: 0.026288694253778843]
	TIME [epoch: 7.99 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022235292715332047		[learning rate: 0.0043722]
	Learning Rate: 0.00437222
	LOSS [training: 0.022235292715332047 | validation: 0.024765091460221253]
	TIME [epoch: 8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_221.pth
	Model improved!!!
EPOCH 222/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022900872997951096		[learning rate: 0.0043511]
	Learning Rate: 0.00435107
	LOSS [training: 0.022900872997951096 | validation: 0.025521530066055915]
	TIME [epoch: 7.97 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02145499786149922		[learning rate: 0.00433]
	Learning Rate: 0.00433003
	LOSS [training: 0.02145499786149922 | validation: 0.02710531395419065]
	TIME [epoch: 7.97 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024909692891346532		[learning rate: 0.0043091]
	Learning Rate: 0.00430909
	LOSS [training: 0.024909692891346532 | validation: 0.026648022113060197]
	TIME [epoch: 7.95 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02415577540023789		[learning rate: 0.0042883]
	Learning Rate: 0.00428826
	LOSS [training: 0.02415577540023789 | validation: 0.025587318141976786]
	TIME [epoch: 7.99 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022657737039042582		[learning rate: 0.0042675]
	Learning Rate: 0.00426752
	LOSS [training: 0.022657737039042582 | validation: 0.025404538270136223]
	TIME [epoch: 7.96 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022256587545805326		[learning rate: 0.0042469]
	Learning Rate: 0.00424688
	LOSS [training: 0.022256587545805326 | validation: 0.025919667535399957]
	TIME [epoch: 7.98 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021722341597015738		[learning rate: 0.0042263]
	Learning Rate: 0.00422634
	LOSS [training: 0.021722341597015738 | validation: 0.025040579586250722]
	TIME [epoch: 7.99 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02160508146587936		[learning rate: 0.0042059]
	Learning Rate: 0.00420591
	LOSS [training: 0.02160508146587936 | validation: 0.026662844592005172]
	TIME [epoch: 7.98 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021693623937017004		[learning rate: 0.0041856]
	Learning Rate: 0.00418557
	LOSS [training: 0.021693623937017004 | validation: 0.025567673441665283]
	TIME [epoch: 7.99 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02091032888106058		[learning rate: 0.0041653]
	Learning Rate: 0.00416533
	LOSS [training: 0.02091032888106058 | validation: 0.024771513751078163]
	TIME [epoch: 7.97 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021757876532648452		[learning rate: 0.0041452]
	Learning Rate: 0.00414518
	LOSS [training: 0.021757876532648452 | validation: 0.02572875455826523]
	TIME [epoch: 7.99 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02276458085336026		[learning rate: 0.0041251]
	Learning Rate: 0.00412514
	LOSS [training: 0.02276458085336026 | validation: 0.02583915046203855]
	TIME [epoch: 7.99 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022066910278832157		[learning rate: 0.0041052]
	Learning Rate: 0.00410519
	LOSS [training: 0.022066910278832157 | validation: 0.02495601724559129]
	TIME [epoch: 7.98 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022522265754051123		[learning rate: 0.0040853]
	Learning Rate: 0.00408534
	LOSS [training: 0.022522265754051123 | validation: 0.02610675844410099]
	TIME [epoch: 7.98 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022879389582649512		[learning rate: 0.0040656]
	Learning Rate: 0.00406558
	LOSS [training: 0.022879389582649512 | validation: 0.024680502044018376]
	TIME [epoch: 7.99 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023181517864219705		[learning rate: 0.0040459]
	Learning Rate: 0.00404592
	LOSS [training: 0.023181517864219705 | validation: 0.029375218107278226]
	TIME [epoch: 8.48 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027254863350698422		[learning rate: 0.0040264]
	Learning Rate: 0.00402636
	LOSS [training: 0.027254863350698422 | validation: 0.029174099850970216]
	TIME [epoch: 7.97 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024873261684515455		[learning rate: 0.0040069]
	Learning Rate: 0.00400689
	LOSS [training: 0.024873261684515455 | validation: 0.027436273451805604]
	TIME [epoch: 7.96 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023376700256879438		[learning rate: 0.0039875]
	Learning Rate: 0.00398751
	LOSS [training: 0.023376700256879438 | validation: 0.026321305334827166]
	TIME [epoch: 7.96 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02214700874316657		[learning rate: 0.0039682]
	Learning Rate: 0.00396823
	LOSS [training: 0.02214700874316657 | validation: 0.025224214032016388]
	TIME [epoch: 7.96 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022449479729925115		[learning rate: 0.003949]
	Learning Rate: 0.00394904
	LOSS [training: 0.022449479729925115 | validation: 0.027562944119620698]
	TIME [epoch: 7.95 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023240456306287956		[learning rate: 0.0039299]
	Learning Rate: 0.00392994
	LOSS [training: 0.023240456306287956 | validation: 0.02505823245172151]
	TIME [epoch: 7.96 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022205881789989872		[learning rate: 0.0039109]
	Learning Rate: 0.00391094
	LOSS [training: 0.022205881789989872 | validation: 0.024592641570086404]
	TIME [epoch: 7.95 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_244.pth
	Model improved!!!
EPOCH 245/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021442145973218054		[learning rate: 0.003892]
	Learning Rate: 0.00389202
	LOSS [training: 0.021442145973218054 | validation: 0.02387443270341363]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_245.pth
	Model improved!!!
EPOCH 246/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020924263358756554		[learning rate: 0.0038732]
	Learning Rate: 0.0038732
	LOSS [training: 0.020924263358756554 | validation: 0.024259423667824676]
	TIME [epoch: 7.97 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02335310588536123		[learning rate: 0.0038545]
	Learning Rate: 0.00385447
	LOSS [training: 0.02335310588536123 | validation: 0.025401537034580344]
	TIME [epoch: 7.95 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02182445270492306		[learning rate: 0.0038358]
	Learning Rate: 0.00383583
	LOSS [training: 0.02182445270492306 | validation: 0.024925754920417875]
	TIME [epoch: 7.95 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020889386464497728		[learning rate: 0.0038173]
	Learning Rate: 0.00381728
	LOSS [training: 0.020889386464497728 | validation: 0.029703655429155512]
	TIME [epoch: 7.94 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024951611803205778		[learning rate: 0.0037988]
	Learning Rate: 0.00379882
	LOSS [training: 0.024951611803205778 | validation: 0.02521865729478503]
	TIME [epoch: 7.94 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02260253657454798		[learning rate: 0.0037805]
	Learning Rate: 0.00378045
	LOSS [training: 0.02260253657454798 | validation: 0.025347972472775843]
	TIME [epoch: 7.97 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021419132812486294		[learning rate: 0.0037622]
	Learning Rate: 0.00376217
	LOSS [training: 0.021419132812486294 | validation: 0.0241590331373949]
	TIME [epoch: 7.96 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02167320169299745		[learning rate: 0.003744]
	Learning Rate: 0.00374398
	LOSS [training: 0.02167320169299745 | validation: 0.0250466118847399]
	TIME [epoch: 7.97 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02344384498756702		[learning rate: 0.0037259]
	Learning Rate: 0.00372587
	LOSS [training: 0.02344384498756702 | validation: 0.024968149658400367]
	TIME [epoch: 7.95 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022475991238233822		[learning rate: 0.0037079]
	Learning Rate: 0.00370786
	LOSS [training: 0.022475991238233822 | validation: 0.0256628986750964]
	TIME [epoch: 7.95 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022312495568298885		[learning rate: 0.0036899]
	Learning Rate: 0.00368992
	LOSS [training: 0.022312495568298885 | validation: 0.024897226105963486]
	TIME [epoch: 7.96 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0234467439133407		[learning rate: 0.0036721]
	Learning Rate: 0.00367208
	LOSS [training: 0.0234467439133407 | validation: 0.024913689027163056]
	TIME [epoch: 7.95 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021418265982834517		[learning rate: 0.0036543]
	Learning Rate: 0.00365432
	LOSS [training: 0.021418265982834517 | validation: 0.024998921820872266]
	TIME [epoch: 7.96 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022232443363793975		[learning rate: 0.0036367]
	Learning Rate: 0.00363665
	LOSS [training: 0.022232443363793975 | validation: 0.023617814498307896]
	TIME [epoch: 7.97 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_259.pth
	Model improved!!!
EPOCH 260/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021258451095754693		[learning rate: 0.0036191]
	Learning Rate: 0.00361907
	LOSS [training: 0.021258451095754693 | validation: 0.024237203323120914]
	TIME [epoch: 7.97 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021239038221471024		[learning rate: 0.0036016]
	Learning Rate: 0.00360156
	LOSS [training: 0.021239038221471024 | validation: 0.024628565375966055]
	TIME [epoch: 7.97 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022207320542583796		[learning rate: 0.0035841]
	Learning Rate: 0.00358415
	LOSS [training: 0.022207320542583796 | validation: 0.02416842425246456]
	TIME [epoch: 7.97 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02309165676716089		[learning rate: 0.0035668]
	Learning Rate: 0.00356682
	LOSS [training: 0.02309165676716089 | validation: 0.026536166560424675]
	TIME [epoch: 7.97 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02119353411114208		[learning rate: 0.0035496]
	Learning Rate: 0.00354957
	LOSS [training: 0.02119353411114208 | validation: 0.024919755870255886]
	TIME [epoch: 7.97 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020325996364679046		[learning rate: 0.0035324]
	Learning Rate: 0.0035324
	LOSS [training: 0.020325996364679046 | validation: 0.02535200102153916]
	TIME [epoch: 7.96 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02133557400921884		[learning rate: 0.0035153]
	Learning Rate: 0.00351532
	LOSS [training: 0.02133557400921884 | validation: 0.024235153751759286]
	TIME [epoch: 7.96 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022024722039721892		[learning rate: 0.0034983]
	Learning Rate: 0.00349832
	LOSS [training: 0.022024722039721892 | validation: 0.025345038290075644]
	TIME [epoch: 7.95 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02338016433435051		[learning rate: 0.0034814]
	Learning Rate: 0.0034814
	LOSS [training: 0.02338016433435051 | validation: 0.024654135499963443]
	TIME [epoch: 7.96 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023319258926112234		[learning rate: 0.0034646]
	Learning Rate: 0.00346457
	LOSS [training: 0.023319258926112234 | validation: 0.02909425073561883]
	TIME [epoch: 7.95 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026107452103263585		[learning rate: 0.0034478]
	Learning Rate: 0.00344781
	LOSS [training: 0.026107452103263585 | validation: 0.026241238738662184]
	TIME [epoch: 7.95 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022429041356531728		[learning rate: 0.0034311]
	Learning Rate: 0.00343114
	LOSS [training: 0.022429041356531728 | validation: 0.02400484517062813]
	TIME [epoch: 7.97 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021436904613330074		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.021436904613330074 | validation: 0.02380359073594224]
	TIME [epoch: 7.95 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02078727149642314		[learning rate: 0.003398]
	Learning Rate: 0.00339804
	LOSS [training: 0.02078727149642314 | validation: 0.023513685708670077]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_273.pth
	Model improved!!!
EPOCH 274/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02062448547701583		[learning rate: 0.0033816]
	Learning Rate: 0.0033816
	LOSS [training: 0.02062448547701583 | validation: 0.023650376615367813]
	TIME [epoch: 7.95 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020037859567361826		[learning rate: 0.0033653]
	Learning Rate: 0.00336525
	LOSS [training: 0.020037859567361826 | validation: 0.023895161807256694]
	TIME [epoch: 7.95 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020927085763776554		[learning rate: 0.003349]
	Learning Rate: 0.00334898
	LOSS [training: 0.020927085763776554 | validation: 0.024804548608690944]
	TIME [epoch: 7.96 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02093805688308539		[learning rate: 0.0033328]
	Learning Rate: 0.00333278
	LOSS [training: 0.02093805688308539 | validation: 0.023902153951016344]
	TIME [epoch: 7.95 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021000595433956742		[learning rate: 0.0033167]
	Learning Rate: 0.00331667
	LOSS [training: 0.021000595433956742 | validation: 0.023913493112097294]
	TIME [epoch: 7.95 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021124028252885563		[learning rate: 0.0033006]
	Learning Rate: 0.00330063
	LOSS [training: 0.021124028252885563 | validation: 0.024150636175346653]
	TIME [epoch: 7.95 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02112303646832411		[learning rate: 0.0032847]
	Learning Rate: 0.00328467
	LOSS [training: 0.02112303646832411 | validation: 0.02472489779927155]
	TIME [epoch: 7.96 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022121312009473513		[learning rate: 0.0032688]
	Learning Rate: 0.00326878
	LOSS [training: 0.022121312009473513 | validation: 0.023787020378068107]
	TIME [epoch: 7.96 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02145927403328977		[learning rate: 0.003253]
	Learning Rate: 0.00325297
	LOSS [training: 0.02145927403328977 | validation: 0.02414083153135178]
	TIME [epoch: 7.97 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020787086512621334		[learning rate: 0.0032372]
	Learning Rate: 0.00323724
	LOSS [training: 0.020787086512621334 | validation: 0.023556876952191632]
	TIME [epoch: 7.95 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020388001954074694		[learning rate: 0.0032216]
	Learning Rate: 0.00322159
	LOSS [training: 0.020388001954074694 | validation: 0.024105623757241915]
	TIME [epoch: 7.95 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02076716216109729		[learning rate: 0.003206]
	Learning Rate: 0.00320601
	LOSS [training: 0.02076716216109729 | validation: 0.024614633965622287]
	TIME [epoch: 7.95 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020976112506774374		[learning rate: 0.0031905]
	Learning Rate: 0.00319051
	LOSS [training: 0.020976112506774374 | validation: 0.023871670918360316]
	TIME [epoch: 7.95 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022228999108241606		[learning rate: 0.0031751]
	Learning Rate: 0.00317508
	LOSS [training: 0.022228999108241606 | validation: 0.022823038824424078]
	TIME [epoch: 7.96 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_287.pth
	Model improved!!!
EPOCH 288/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02152332968995506		[learning rate: 0.0031597]
	Learning Rate: 0.00315972
	LOSS [training: 0.02152332968995506 | validation: 0.024569170491415184]
	TIME [epoch: 7.98 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019961508731977946		[learning rate: 0.0031444]
	Learning Rate: 0.00314444
	LOSS [training: 0.019961508731977946 | validation: 0.024909066603063967]
	TIME [epoch: 7.98 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02099463728870057		[learning rate: 0.0031292]
	Learning Rate: 0.00312924
	LOSS [training: 0.02099463728870057 | validation: 0.023516281722515547]
	TIME [epoch: 7.99 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021749575436049707		[learning rate: 0.0031141]
	Learning Rate: 0.00311411
	LOSS [training: 0.021749575436049707 | validation: 0.023719032104075333]
	TIME [epoch: 7.99 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020395950571891332		[learning rate: 0.003099]
	Learning Rate: 0.00309905
	LOSS [training: 0.020395950571891332 | validation: 0.02406508605817673]
	TIME [epoch: 8 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020241561635802284		[learning rate: 0.0030841]
	Learning Rate: 0.00308406
	LOSS [training: 0.020241561635802284 | validation: 0.023533925963793233]
	TIME [epoch: 8 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02018010591973621		[learning rate: 0.0030691]
	Learning Rate: 0.00306915
	LOSS [training: 0.02018010591973621 | validation: 0.02387146534975339]
	TIME [epoch: 7.99 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021438352433880925		[learning rate: 0.0030543]
	Learning Rate: 0.0030543
	LOSS [training: 0.021438352433880925 | validation: 0.023220813947342347]
	TIME [epoch: 7.99 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020880893977993448		[learning rate: 0.0030395]
	Learning Rate: 0.00303953
	LOSS [training: 0.020880893977993448 | validation: 0.024791980100351874]
	TIME [epoch: 7.99 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020283406798364382		[learning rate: 0.0030248]
	Learning Rate: 0.00302484
	LOSS [training: 0.020283406798364382 | validation: 0.024969325073978494]
	TIME [epoch: 7.99 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020832105704644704		[learning rate: 0.0030102]
	Learning Rate: 0.00301021
	LOSS [training: 0.020832105704644704 | validation: 0.024440759970187773]
	TIME [epoch: 7.99 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020860397934647456		[learning rate: 0.0029957]
	Learning Rate: 0.00299565
	LOSS [training: 0.020860397934647456 | validation: 0.024331621851300334]
	TIME [epoch: 8 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022755832340863622		[learning rate: 0.0029812]
	Learning Rate: 0.00298116
	LOSS [training: 0.022755832340863622 | validation: 0.0236538548289775]
	TIME [epoch: 8 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019988780891932446		[learning rate: 0.0029667]
	Learning Rate: 0.00296675
	LOSS [training: 0.019988780891932446 | validation: 0.0242679046701987]
	TIME [epoch: 41 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022840230805360007		[learning rate: 0.0029524]
	Learning Rate: 0.0029524
	LOSS [training: 0.022840230805360007 | validation: 0.02528774255558473]
	TIME [epoch: 16.7 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02331070119198621		[learning rate: 0.0029381]
	Learning Rate: 0.00293812
	LOSS [training: 0.02331070119198621 | validation: 0.02619413186001703]
	TIME [epoch: 16.7 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022843621836137692		[learning rate: 0.0029239]
	Learning Rate: 0.00292392
	LOSS [training: 0.022843621836137692 | validation: 0.025084158766697767]
	TIME [epoch: 16.7 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021029798432538608		[learning rate: 0.0029098]
	Learning Rate: 0.00290978
	LOSS [training: 0.021029798432538608 | validation: 0.024696259680741354]
	TIME [epoch: 16.7 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022059382285626206		[learning rate: 0.0028957]
	Learning Rate: 0.00289571
	LOSS [training: 0.022059382285626206 | validation: 0.024304359325000996]
	TIME [epoch: 16.7 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021212571019912186		[learning rate: 0.0028817]
	Learning Rate: 0.0028817
	LOSS [training: 0.021212571019912186 | validation: 0.024067632171295567]
	TIME [epoch: 16.7 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021641305722641026		[learning rate: 0.0028678]
	Learning Rate: 0.00286777
	LOSS [training: 0.021641305722641026 | validation: 0.0239073085716011]
	TIME [epoch: 16.7 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021643181094701164		[learning rate: 0.0028539]
	Learning Rate: 0.0028539
	LOSS [training: 0.021643181094701164 | validation: 0.024126371443547512]
	TIME [epoch: 16.7 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02237513060739535		[learning rate: 0.0028401]
	Learning Rate: 0.0028401
	LOSS [training: 0.02237513060739535 | validation: 0.025209508391373165]
	TIME [epoch: 16.7 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02174737765194873		[learning rate: 0.0028264]
	Learning Rate: 0.00282636
	LOSS [training: 0.02174737765194873 | validation: 0.02349637439493449]
	TIME [epoch: 16.7 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02051912296277684		[learning rate: 0.0028127]
	Learning Rate: 0.0028127
	LOSS [training: 0.02051912296277684 | validation: 0.023549771010965597]
	TIME [epoch: 16.7 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02086001610616603		[learning rate: 0.0027991]
	Learning Rate: 0.00279909
	LOSS [training: 0.02086001610616603 | validation: 0.023350554418843348]
	TIME [epoch: 16.7 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020789110248124996		[learning rate: 0.0027856]
	Learning Rate: 0.00278556
	LOSS [training: 0.020789110248124996 | validation: 0.0236426861018687]
	TIME [epoch: 16.7 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020838392505722596		[learning rate: 0.0027721]
	Learning Rate: 0.00277209
	LOSS [training: 0.020838392505722596 | validation: 0.023879960430121177]
	TIME [epoch: 16.7 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021015531478158062		[learning rate: 0.0027587]
	Learning Rate: 0.00275868
	LOSS [training: 0.021015531478158062 | validation: 0.023517058145634095]
	TIME [epoch: 16.7 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020950054519834407		[learning rate: 0.0027453]
	Learning Rate: 0.00274534
	LOSS [training: 0.020950054519834407 | validation: 0.023999293275264472]
	TIME [epoch: 16.7 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020750151623084145		[learning rate: 0.0027321]
	Learning Rate: 0.00273207
	LOSS [training: 0.020750151623084145 | validation: 0.025063234472037222]
	TIME [epoch: 16.7 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021388897456011944		[learning rate: 0.0027189]
	Learning Rate: 0.00271885
	LOSS [training: 0.021388897456011944 | validation: 0.023688832275544264]
	TIME [epoch: 16.7 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021524843129192544		[learning rate: 0.0027057]
	Learning Rate: 0.00270571
	LOSS [training: 0.021524843129192544 | validation: 0.024385983773225223]
	TIME [epoch: 16.7 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021255787056055242		[learning rate: 0.0026926]
	Learning Rate: 0.00269262
	LOSS [training: 0.021255787056055242 | validation: 0.023800181750730797]
	TIME [epoch: 16.7 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019053352896997288		[learning rate: 0.0026796]
	Learning Rate: 0.0026796
	LOSS [training: 0.019053352896997288 | validation: 0.023363850219665343]
	TIME [epoch: 16.7 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01987971291387272		[learning rate: 0.0026666]
	Learning Rate: 0.00266664
	LOSS [training: 0.01987971291387272 | validation: 0.025740058549511387]
	TIME [epoch: 16.7 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020409670035050443		[learning rate: 0.0026537]
	Learning Rate: 0.00265375
	LOSS [training: 0.020409670035050443 | validation: 0.023605909413831994]
	TIME [epoch: 16.7 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019685409057918463		[learning rate: 0.0026409]
	Learning Rate: 0.00264091
	LOSS [training: 0.019685409057918463 | validation: 0.02331957784871863]
	TIME [epoch: 16.7 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021289849122159043		[learning rate: 0.0026281]
	Learning Rate: 0.00262814
	LOSS [training: 0.021289849122159043 | validation: 0.023489967115795735]
	TIME [epoch: 16.7 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02056233209180482		[learning rate: 0.0026154]
	Learning Rate: 0.00261543
	LOSS [training: 0.02056233209180482 | validation: 0.02411954333579269]
	TIME [epoch: 16.7 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020150306601624018		[learning rate: 0.0026028]
	Learning Rate: 0.00260279
	LOSS [training: 0.020150306601624018 | validation: 0.023925287183132072]
	TIME [epoch: 16.7 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01985288148727326		[learning rate: 0.0025902]
	Learning Rate: 0.0025902
	LOSS [training: 0.01985288148727326 | validation: 0.025143194104466665]
	TIME [epoch: 16.7 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02215434633588748		[learning rate: 0.0025777]
	Learning Rate: 0.00257767
	LOSS [training: 0.02215434633588748 | validation: 0.024146129993914158]
	TIME [epoch: 16.7 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020544480431863982		[learning rate: 0.0025652]
	Learning Rate: 0.00256521
	LOSS [training: 0.020544480431863982 | validation: 0.023643409728671145]
	TIME [epoch: 16.7 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020157461496198206		[learning rate: 0.0025528]
	Learning Rate: 0.0025528
	LOSS [training: 0.020157461496198206 | validation: 0.023611622588391227]
	TIME [epoch: 16.7 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019777622058945444		[learning rate: 0.0025405]
	Learning Rate: 0.00254046
	LOSS [training: 0.019777622058945444 | validation: 0.023730426101072354]
	TIME [epoch: 16.7 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02005057058128978		[learning rate: 0.0025282]
	Learning Rate: 0.00252817
	LOSS [training: 0.02005057058128978 | validation: 0.024395615377137497]
	TIME [epoch: 16.7 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02033635179879234		[learning rate: 0.0025159]
	Learning Rate: 0.00251595
	LOSS [training: 0.02033635179879234 | validation: 0.024670558372196203]
	TIME [epoch: 16.7 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021175642539524975		[learning rate: 0.0025038]
	Learning Rate: 0.00250378
	LOSS [training: 0.021175642539524975 | validation: 0.02490780728794133]
	TIME [epoch: 16.7 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01968813488632093		[learning rate: 0.0024917]
	Learning Rate: 0.00249167
	LOSS [training: 0.01968813488632093 | validation: 0.024248733235661905]
	TIME [epoch: 16.7 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019461931831699364		[learning rate: 0.0024796]
	Learning Rate: 0.00247962
	LOSS [training: 0.019461931831699364 | validation: 0.023746406870403764]
	TIME [epoch: 16.7 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0199455589857178		[learning rate: 0.0024676]
	Learning Rate: 0.00246763
	LOSS [training: 0.0199455589857178 | validation: 0.02325192840057699]
	TIME [epoch: 16.7 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020259413346458685		[learning rate: 0.0024557]
	Learning Rate: 0.0024557
	LOSS [training: 0.020259413346458685 | validation: 0.023070698095814232]
	TIME [epoch: 16.7 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01982782938980081		[learning rate: 0.0024438]
	Learning Rate: 0.00244383
	LOSS [training: 0.01982782938980081 | validation: 0.023663017101454076]
	TIME [epoch: 16.7 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020387022707880464		[learning rate: 0.002432]
	Learning Rate: 0.00243201
	LOSS [training: 0.020387022707880464 | validation: 0.024003738587163575]
	TIME [epoch: 16.7 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020198250463484516		[learning rate: 0.0024202]
	Learning Rate: 0.00242025
	LOSS [training: 0.020198250463484516 | validation: 0.023979602022699404]
	TIME [epoch: 16.7 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020717054552442368		[learning rate: 0.0024085]
	Learning Rate: 0.00240854
	LOSS [training: 0.020717054552442368 | validation: 0.024073388657593522]
	TIME [epoch: 16.7 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01996207341966788		[learning rate: 0.0023969]
	Learning Rate: 0.0023969
	LOSS [training: 0.01996207341966788 | validation: 0.023308017552077634]
	TIME [epoch: 16.7 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020155939914863547		[learning rate: 0.0023853]
	Learning Rate: 0.0023853
	LOSS [training: 0.020155939914863547 | validation: 0.022346057727604354]
	TIME [epoch: 16.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_346.pth
	Model improved!!!
EPOCH 347/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019479506049477985		[learning rate: 0.0023738]
	Learning Rate: 0.00237377
	LOSS [training: 0.019479506049477985 | validation: 0.024217033995743178]
	TIME [epoch: 16.7 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0198794665647432		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.0198794665647432 | validation: 0.02303000399207178]
	TIME [epoch: 16.7 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021242126012327067		[learning rate: 0.0023509]
	Learning Rate: 0.00235087
	LOSS [training: 0.021242126012327067 | validation: 0.023969555760236502]
	TIME [epoch: 16.7 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01955605265812775		[learning rate: 0.0023395]
	Learning Rate: 0.0023395
	LOSS [training: 0.01955605265812775 | validation: 0.023370948324615972]
	TIME [epoch: 16.7 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01888134543650701		[learning rate: 0.0023282]
	Learning Rate: 0.00232819
	LOSS [training: 0.01888134543650701 | validation: 0.022658414920561375]
	TIME [epoch: 16.7 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020023515084550338		[learning rate: 0.0023169]
	Learning Rate: 0.00231693
	LOSS [training: 0.020023515084550338 | validation: 0.024126781191346817]
	TIME [epoch: 16.7 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01836235824998016		[learning rate: 0.0023057]
	Learning Rate: 0.00230572
	LOSS [training: 0.01836235824998016 | validation: 0.022954555507705348]
	TIME [epoch: 16.7 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02008531632865246		[learning rate: 0.0022946]
	Learning Rate: 0.00229457
	LOSS [training: 0.02008531632865246 | validation: 0.024078913411998443]
	TIME [epoch: 16.7 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020500646684921436		[learning rate: 0.0022835]
	Learning Rate: 0.00228348
	LOSS [training: 0.020500646684921436 | validation: 0.023970585137661194]
	TIME [epoch: 16.7 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019872525205351755		[learning rate: 0.0022724]
	Learning Rate: 0.00227243
	LOSS [training: 0.019872525205351755 | validation: 0.02360118037763075]
	TIME [epoch: 16.7 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019651080420926465		[learning rate: 0.0022614]
	Learning Rate: 0.00226144
	LOSS [training: 0.019651080420926465 | validation: 0.02366021581438461]
	TIME [epoch: 16.7 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019680157396399212		[learning rate: 0.0022505]
	Learning Rate: 0.00225051
	LOSS [training: 0.019680157396399212 | validation: 0.024221897092661367]
	TIME [epoch: 16.7 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01907479234730074		[learning rate: 0.0022396]
	Learning Rate: 0.00223963
	LOSS [training: 0.01907479234730074 | validation: 0.023592047222736015]
	TIME [epoch: 16.7 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021157674928048056		[learning rate: 0.0022288]
	Learning Rate: 0.0022288
	LOSS [training: 0.021157674928048056 | validation: 0.02458178584244977]
	TIME [epoch: 16.7 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019779535287166066		[learning rate: 0.002218]
	Learning Rate: 0.00221802
	LOSS [training: 0.019779535287166066 | validation: 0.02347450790508163]
	TIME [epoch: 16.7 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018875545161255235		[learning rate: 0.0022073]
	Learning Rate: 0.00220729
	LOSS [training: 0.018875545161255235 | validation: 0.02366613092117999]
	TIME [epoch: 16.7 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01988404003594932		[learning rate: 0.0021966]
	Learning Rate: 0.00219662
	LOSS [training: 0.01988404003594932 | validation: 0.02406975656002562]
	TIME [epoch: 16.7 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01988100117467142		[learning rate: 0.002186]
	Learning Rate: 0.00218599
	LOSS [training: 0.01988100117467142 | validation: 0.02446268383340548]
	TIME [epoch: 16.7 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01932713862630145		[learning rate: 0.0021754]
	Learning Rate: 0.00217542
	LOSS [training: 0.01932713862630145 | validation: 0.023669088708826825]
	TIME [epoch: 16.7 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020611294223843803		[learning rate: 0.0021649]
	Learning Rate: 0.0021649
	LOSS [training: 0.020611294223843803 | validation: 0.02570352253221789]
	TIME [epoch: 16.7 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02118547658773758		[learning rate: 0.0021544]
	Learning Rate: 0.00215443
	LOSS [training: 0.02118547658773758 | validation: 0.024228923212617715]
	TIME [epoch: 16.7 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01965226407876719		[learning rate: 0.002144]
	Learning Rate: 0.00214402
	LOSS [training: 0.01965226407876719 | validation: 0.02386278164172513]
	TIME [epoch: 16.7 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01936276753115348		[learning rate: 0.0021336]
	Learning Rate: 0.00213365
	LOSS [training: 0.01936276753115348 | validation: 0.024106148672771412]
	TIME [epoch: 16.7 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019670751112862147		[learning rate: 0.0021233]
	Learning Rate: 0.00212333
	LOSS [training: 0.019670751112862147 | validation: 0.02332421463518629]
	TIME [epoch: 16.7 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019184236789742088		[learning rate: 0.0021131]
	Learning Rate: 0.00211306
	LOSS [training: 0.019184236789742088 | validation: 0.02379815682092849]
	TIME [epoch: 16.7 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018891166281558958		[learning rate: 0.0021028]
	Learning Rate: 0.00210284
	LOSS [training: 0.018891166281558958 | validation: 0.023405048611357407]
	TIME [epoch: 16.7 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018356407910301773		[learning rate: 0.0020927]
	Learning Rate: 0.00209267
	LOSS [training: 0.018356407910301773 | validation: 0.024280585020659926]
	TIME [epoch: 16.7 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019207083179424666		[learning rate: 0.0020826]
	Learning Rate: 0.00208255
	LOSS [training: 0.019207083179424666 | validation: 0.023520851610263738]
	TIME [epoch: 16.7 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0183105852190834		[learning rate: 0.0020725]
	Learning Rate: 0.00207248
	LOSS [training: 0.0183105852190834 | validation: 0.023172260045019724]
	TIME [epoch: 16.7 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019663687835572197		[learning rate: 0.0020625]
	Learning Rate: 0.00206246
	LOSS [training: 0.019663687835572197 | validation: 0.023776466650775156]
	TIME [epoch: 16.7 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019561821638947777		[learning rate: 0.0020525]
	Learning Rate: 0.00205249
	LOSS [training: 0.019561821638947777 | validation: 0.02464804026686636]
	TIME [epoch: 16.7 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019213829805297972		[learning rate: 0.0020426]
	Learning Rate: 0.00204256
	LOSS [training: 0.019213829805297972 | validation: 0.02457676105503985]
	TIME [epoch: 16.7 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01927566535520628		[learning rate: 0.0020327]
	Learning Rate: 0.00203269
	LOSS [training: 0.01927566535520628 | validation: 0.023836077401262906]
	TIME [epoch: 16.7 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01937046452258444		[learning rate: 0.0020229]
	Learning Rate: 0.00202286
	LOSS [training: 0.01937046452258444 | validation: 0.02399903715004408]
	TIME [epoch: 16.7 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018801576787754872		[learning rate: 0.0020131]
	Learning Rate: 0.00201307
	LOSS [training: 0.018801576787754872 | validation: 0.02378272486089061]
	TIME [epoch: 16.7 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01887177476918467		[learning rate: 0.0020033]
	Learning Rate: 0.00200334
	LOSS [training: 0.01887177476918467 | validation: 0.025122812285495483]
	TIME [epoch: 16.7 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019910082021753563		[learning rate: 0.0019937]
	Learning Rate: 0.00199365
	LOSS [training: 0.019910082021753563 | validation: 0.025997975788321064]
	TIME [epoch: 16.7 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020890934924531673		[learning rate: 0.001984]
	Learning Rate: 0.00198401
	LOSS [training: 0.020890934924531673 | validation: 0.02487254941674236]
	TIME [epoch: 16.7 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018689379142062743		[learning rate: 0.0019744]
	Learning Rate: 0.00197442
	LOSS [training: 0.018689379142062743 | validation: 0.024363134135925103]
	TIME [epoch: 16.7 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018115936661134733		[learning rate: 0.0019649]
	Learning Rate: 0.00196487
	LOSS [training: 0.018115936661134733 | validation: 0.024653808445446995]
	TIME [epoch: 16.7 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019264667202796168		[learning rate: 0.0019554]
	Learning Rate: 0.00195537
	LOSS [training: 0.019264667202796168 | validation: 0.024431287988324713]
	TIME [epoch: 16.7 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01881669208481217		[learning rate: 0.0019459]
	Learning Rate: 0.00194591
	LOSS [training: 0.01881669208481217 | validation: 0.02384978032205846]
	TIME [epoch: 16.7 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018770731527692916		[learning rate: 0.0019365]
	Learning Rate: 0.0019365
	LOSS [training: 0.018770731527692916 | validation: 0.02319704541328944]
	TIME [epoch: 16.7 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01836076291321786		[learning rate: 0.0019271]
	Learning Rate: 0.00192714
	LOSS [training: 0.01836076291321786 | validation: 0.02419453733196344]
	TIME [epoch: 16.7 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019103984381957474		[learning rate: 0.0019178]
	Learning Rate: 0.00191782
	LOSS [training: 0.019103984381957474 | validation: 0.023910208576339492]
	TIME [epoch: 16.7 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020034349318458322		[learning rate: 0.0019085]
	Learning Rate: 0.00190854
	LOSS [training: 0.020034349318458322 | validation: 0.024197623865306137]
	TIME [epoch: 16.7 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019209389518633168		[learning rate: 0.0018993]
	Learning Rate: 0.00189931
	LOSS [training: 0.019209389518633168 | validation: 0.02346426332951049]
	TIME [epoch: 16.7 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018203744423452475		[learning rate: 0.0018901]
	Learning Rate: 0.00189013
	LOSS [training: 0.018203744423452475 | validation: 0.02436609923273174]
	TIME [epoch: 16.7 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01924989364213874		[learning rate: 0.001881]
	Learning Rate: 0.00188099
	LOSS [training: 0.01924989364213874 | validation: 0.024002353706046104]
	TIME [epoch: 16.7 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019430930830219798		[learning rate: 0.0018719]
	Learning Rate: 0.00187189
	LOSS [training: 0.019430930830219798 | validation: 0.02463929756473739]
	TIME [epoch: 16.7 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019220093608248157		[learning rate: 0.0018628]
	Learning Rate: 0.00186284
	LOSS [training: 0.019220093608248157 | validation: 0.023965699379238637]
	TIME [epoch: 16.7 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019498440895634687		[learning rate: 0.0018538]
	Learning Rate: 0.00185383
	LOSS [training: 0.019498440895634687 | validation: 0.0241828458755131]
	TIME [epoch: 16.7 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017941791455529797		[learning rate: 0.0018449]
	Learning Rate: 0.00184487
	LOSS [training: 0.017941791455529797 | validation: 0.023530163662865266]
	TIME [epoch: 16.7 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01828437833957268		[learning rate: 0.0018359]
	Learning Rate: 0.00183594
	LOSS [training: 0.01828437833957268 | validation: 0.02362535637799748]
	TIME [epoch: 16.7 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019026683984711613		[learning rate: 0.0018271]
	Learning Rate: 0.00182707
	LOSS [training: 0.019026683984711613 | validation: 0.023985437501101815]
	TIME [epoch: 16.7 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018913759174927252		[learning rate: 0.0018182]
	Learning Rate: 0.00181823
	LOSS [training: 0.018913759174927252 | validation: 0.023651073445965214]
	TIME [epoch: 16.7 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018305065033063447		[learning rate: 0.0018094]
	Learning Rate: 0.00180944
	LOSS [training: 0.018305065033063447 | validation: 0.02998059476030113]
	TIME [epoch: 16.7 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01992889124191003		[learning rate: 0.0018007]
	Learning Rate: 0.00180069
	LOSS [training: 0.01992889124191003 | validation: 0.024187685987271296]
	TIME [epoch: 16.7 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01929182189388934		[learning rate: 0.001792]
	Learning Rate: 0.00179198
	LOSS [training: 0.01929182189388934 | validation: 0.02449789409332112]
	TIME [epoch: 16.7 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019480377818641394		[learning rate: 0.0017833]
	Learning Rate: 0.00178331
	LOSS [training: 0.019480377818641394 | validation: 0.022847535149111604]
	TIME [epoch: 16.7 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018618856082378146		[learning rate: 0.0017747]
	Learning Rate: 0.00177469
	LOSS [training: 0.018618856082378146 | validation: 0.024499109946771295]
	TIME [epoch: 16.7 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019209152981124585		[learning rate: 0.0017661]
	Learning Rate: 0.00176611
	LOSS [training: 0.019209152981124585 | validation: 0.02360117457217102]
	TIME [epoch: 16.7 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018794184620112477		[learning rate: 0.0017576]
	Learning Rate: 0.00175757
	LOSS [training: 0.018794184620112477 | validation: 0.02670726419534021]
	TIME [epoch: 16.7 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01982091496041882		[learning rate: 0.0017491]
	Learning Rate: 0.00174907
	LOSS [training: 0.01982091496041882 | validation: 0.02489056763764763]
	TIME [epoch: 16.7 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018867815707250237		[learning rate: 0.0017406]
	Learning Rate: 0.00174061
	LOSS [training: 0.018867815707250237 | validation: 0.02349563900675239]
	TIME [epoch: 16.7 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01908085388131978		[learning rate: 0.0017322]
	Learning Rate: 0.00173219
	LOSS [training: 0.01908085388131978 | validation: 0.024280481323282796]
	TIME [epoch: 16.7 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019868007679084698		[learning rate: 0.0017238]
	Learning Rate: 0.00172382
	LOSS [training: 0.019868007679084698 | validation: 0.024748258808517432]
	TIME [epoch: 16.7 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018132588626119207		[learning rate: 0.0017155]
	Learning Rate: 0.00171548
	LOSS [training: 0.018132588626119207 | validation: 0.02339335485881815]
	TIME [epoch: 16.7 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018307568211755266		[learning rate: 0.0017072]
	Learning Rate: 0.00170719
	LOSS [training: 0.018307568211755266 | validation: 0.022989265007169996]
	TIME [epoch: 16.7 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018933463444677483		[learning rate: 0.0016989]
	Learning Rate: 0.00169893
	LOSS [training: 0.018933463444677483 | validation: 0.023940895532475425]
	TIME [epoch: 16.7 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018214540217239422		[learning rate: 0.0016907]
	Learning Rate: 0.00169071
	LOSS [training: 0.018214540217239422 | validation: 0.023205576965150687]
	TIME [epoch: 16.7 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018549737269564253		[learning rate: 0.0016825]
	Learning Rate: 0.00168254
	LOSS [training: 0.018549737269564253 | validation: 0.024180157143506725]
	TIME [epoch: 16.7 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018339994028742448		[learning rate: 0.0016744]
	Learning Rate: 0.0016744
	LOSS [training: 0.018339994028742448 | validation: 0.023532453815382968]
	TIME [epoch: 16.7 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01876765563902318		[learning rate: 0.0016663]
	Learning Rate: 0.0016663
	LOSS [training: 0.01876765563902318 | validation: 0.023791997843321522]
	TIME [epoch: 16.7 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020324660964896407		[learning rate: 0.0016582]
	Learning Rate: 0.00165825
	LOSS [training: 0.020324660964896407 | validation: 0.023349888503368707]
	TIME [epoch: 16.7 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019111278513063695		[learning rate: 0.0016502]
	Learning Rate: 0.00165023
	LOSS [training: 0.019111278513063695 | validation: 0.02434765645115133]
	TIME [epoch: 16.7 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01800694868655608		[learning rate: 0.0016422]
	Learning Rate: 0.00164225
	LOSS [training: 0.01800694868655608 | validation: 0.025810863067662854]
	TIME [epoch: 16.7 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021071356496948006		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.021071356496948006 | validation: 0.024880563930852192]
	TIME [epoch: 16.7 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019826439932528476		[learning rate: 0.0016264]
	Learning Rate: 0.0016264
	LOSS [training: 0.019826439932528476 | validation: 0.023622643104655006]
	TIME [epoch: 16.7 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01912481951808265		[learning rate: 0.0016185]
	Learning Rate: 0.00161854
	LOSS [training: 0.01912481951808265 | validation: 0.02321420778450864]
	TIME [epoch: 16.7 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01848130700468462		[learning rate: 0.0016107]
	Learning Rate: 0.00161071
	LOSS [training: 0.01848130700468462 | validation: 0.023383314099185145]
	TIME [epoch: 16.7 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018431529688568954		[learning rate: 0.0016029]
	Learning Rate: 0.00160292
	LOSS [training: 0.018431529688568954 | validation: 0.022632885681171232]
	TIME [epoch: 16.7 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018247939570791023		[learning rate: 0.0015952]
	Learning Rate: 0.00159517
	LOSS [training: 0.018247939570791023 | validation: 0.02313344919272915]
	TIME [epoch: 16.7 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017269714811840937		[learning rate: 0.0015875]
	Learning Rate: 0.00158746
	LOSS [training: 0.017269714811840937 | validation: 0.02403284890861417]
	TIME [epoch: 16.7 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01859943141313775		[learning rate: 0.0015798]
	Learning Rate: 0.00157978
	LOSS [training: 0.01859943141313775 | validation: 0.023569589982720116]
	TIME [epoch: 16.7 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018463765791627805		[learning rate: 0.0015721]
	Learning Rate: 0.00157214
	LOSS [training: 0.018463765791627805 | validation: 0.025252742447872692]
	TIME [epoch: 16.7 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019226224657302633		[learning rate: 0.0015645]
	Learning Rate: 0.00156454
	LOSS [training: 0.019226224657302633 | validation: 0.02465162156514414]
	TIME [epoch: 16.7 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017513151050215968		[learning rate: 0.001557]
	Learning Rate: 0.00155697
	LOSS [training: 0.017513151050215968 | validation: 0.023489824082865724]
	TIME [epoch: 16.7 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01897558423182259		[learning rate: 0.0015494]
	Learning Rate: 0.00154944
	LOSS [training: 0.01897558423182259 | validation: 0.024031333551267086]
	TIME [epoch: 16.7 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018282662793087854		[learning rate: 0.0015419]
	Learning Rate: 0.00154195
	LOSS [training: 0.018282662793087854 | validation: 0.02318578852667048]
	TIME [epoch: 16.7 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018631135538938675		[learning rate: 0.0015345]
	Learning Rate: 0.00153449
	LOSS [training: 0.018631135538938675 | validation: 0.02367845922102629]
	TIME [epoch: 16.7 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01903640455582424		[learning rate: 0.0015271]
	Learning Rate: 0.00152707
	LOSS [training: 0.01903640455582424 | validation: 0.02375686753288962]
	TIME [epoch: 16.7 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018215458601443517		[learning rate: 0.0015197]
	Learning Rate: 0.00151969
	LOSS [training: 0.018215458601443517 | validation: 0.023600503059204136]
	TIME [epoch: 16.7 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01803881369704288		[learning rate: 0.0015123]
	Learning Rate: 0.00151234
	LOSS [training: 0.01803881369704288 | validation: 0.023052423471888392]
	TIME [epoch: 16.7 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0176238210508647		[learning rate: 0.001505]
	Learning Rate: 0.00150503
	LOSS [training: 0.0176238210508647 | validation: 0.027390734279719418]
	TIME [epoch: 16.7 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021990399297744028		[learning rate: 0.0014977]
	Learning Rate: 0.00149775
	LOSS [training: 0.021990399297744028 | validation: 0.029468441896467384]
	TIME [epoch: 16.7 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022061392365842657		[learning rate: 0.0014905]
	Learning Rate: 0.0014905
	LOSS [training: 0.022061392365842657 | validation: 0.027119146106924535]
	TIME [epoch: 16.7 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019303185443274033		[learning rate: 0.0014833]
	Learning Rate: 0.0014833
	LOSS [training: 0.019303185443274033 | validation: 0.026010468336830128]
	TIME [epoch: 16.7 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018948202312080057		[learning rate: 0.0014761]
	Learning Rate: 0.00147612
	LOSS [training: 0.018948202312080057 | validation: 0.024550942524691744]
	TIME [epoch: 16.7 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01811172956750863		[learning rate: 0.001469]
	Learning Rate: 0.00146899
	LOSS [training: 0.01811172956750863 | validation: 0.024520311399384504]
	TIME [epoch: 16.7 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019124199601967623		[learning rate: 0.0014619]
	Learning Rate: 0.00146188
	LOSS [training: 0.019124199601967623 | validation: 0.024779168777944505]
	TIME [epoch: 16.7 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018765128281882235		[learning rate: 0.0014548]
	Learning Rate: 0.00145481
	LOSS [training: 0.018765128281882235 | validation: 0.02468115011899108]
	TIME [epoch: 16.7 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017836940286621653		[learning rate: 0.0014478]
	Learning Rate: 0.00144778
	LOSS [training: 0.017836940286621653 | validation: 0.024338416024060682]
	TIME [epoch: 16.7 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017840599761073186		[learning rate: 0.0014408]
	Learning Rate: 0.00144078
	LOSS [training: 0.017840599761073186 | validation: 0.023969730655756003]
	TIME [epoch: 16.7 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018098851952507627		[learning rate: 0.0014338]
	Learning Rate: 0.00143381
	LOSS [training: 0.018098851952507627 | validation: 0.024318677433037672]
	TIME [epoch: 16.7 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01789686597578518		[learning rate: 0.0014269]
	Learning Rate: 0.00142688
	LOSS [training: 0.01789686597578518 | validation: 0.024707582979645013]
	TIME [epoch: 16.7 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018687009464690953		[learning rate: 0.00142]
	Learning Rate: 0.00141997
	LOSS [training: 0.018687009464690953 | validation: 0.024137310700919245]
	TIME [epoch: 16.7 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01885691614614671		[learning rate: 0.0014131]
	Learning Rate: 0.00141311
	LOSS [training: 0.01885691614614671 | validation: 0.02527604623470389]
	TIME [epoch: 16.7 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019435326393560024		[learning rate: 0.0014063]
	Learning Rate: 0.00140627
	LOSS [training: 0.019435326393560024 | validation: 0.025205862759257402]
	TIME [epoch: 16.7 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018046707585287338		[learning rate: 0.0013995]
	Learning Rate: 0.00139947
	LOSS [training: 0.018046707585287338 | validation: 0.023928945199874405]
	TIME [epoch: 16.7 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01842117257408105		[learning rate: 0.0013927]
	Learning Rate: 0.00139271
	LOSS [training: 0.01842117257408105 | validation: 0.024750868737673095]
	TIME [epoch: 16.7 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017928924477006003		[learning rate: 0.001386]
	Learning Rate: 0.00138597
	LOSS [training: 0.017928924477006003 | validation: 0.023507668053401043]
	TIME [epoch: 16.7 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018177794188935174		[learning rate: 0.0013793]
	Learning Rate: 0.00137927
	LOSS [training: 0.018177794188935174 | validation: 0.02333782349972662]
	TIME [epoch: 16.7 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018217515254402062		[learning rate: 0.0013726]
	Learning Rate: 0.0013726
	LOSS [training: 0.018217515254402062 | validation: 0.02347101699282296]
	TIME [epoch: 16.7 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0182026622484297		[learning rate: 0.001366]
	Learning Rate: 0.00136596
	LOSS [training: 0.0182026622484297 | validation: 0.023000983914916766]
	TIME [epoch: 16.7 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018734240932379104		[learning rate: 0.0013594]
	Learning Rate: 0.00135936
	LOSS [training: 0.018734240932379104 | validation: 0.024023943283971127]
	TIME [epoch: 16.7 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018134773494890163		[learning rate: 0.0013528]
	Learning Rate: 0.00135278
	LOSS [training: 0.018134773494890163 | validation: 0.0230149559874484]
	TIME [epoch: 16.7 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01795093686706825		[learning rate: 0.0013462]
	Learning Rate: 0.00134624
	LOSS [training: 0.01795093686706825 | validation: 0.023828300048269302]
	TIME [epoch: 16.7 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0186701054333778		[learning rate: 0.0013397]
	Learning Rate: 0.00133973
	LOSS [training: 0.0186701054333778 | validation: 0.023895188756798927]
	TIME [epoch: 16.7 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017866739535928634		[learning rate: 0.0013333]
	Learning Rate: 0.00133325
	LOSS [training: 0.017866739535928634 | validation: 0.022148235803648966]
	TIME [epoch: 16.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_466.pth
	Model improved!!!
EPOCH 467/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018473773151675046		[learning rate: 0.0013268]
	Learning Rate: 0.0013268
	LOSS [training: 0.018473773151675046 | validation: 0.023214685227791607]
	TIME [epoch: 16.8 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01782802003587901		[learning rate: 0.0013204]
	Learning Rate: 0.00132039
	LOSS [training: 0.01782802003587901 | validation: 0.02280917660058229]
	TIME [epoch: 16.8 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01806798924524763		[learning rate: 0.001314]
	Learning Rate: 0.001314
	LOSS [training: 0.01806798924524763 | validation: 0.02326898062324263]
	TIME [epoch: 16.7 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01811910201372448		[learning rate: 0.0013076]
	Learning Rate: 0.00130765
	LOSS [training: 0.01811910201372448 | validation: 0.022740225157944716]
	TIME [epoch: 16.7 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019489517133106763		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.019489517133106763 | validation: 0.023749177189874415]
	TIME [epoch: 16.7 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01844736633194291		[learning rate: 0.001295]
	Learning Rate: 0.00129503
	LOSS [training: 0.01844736633194291 | validation: 0.02200079940107232]
	TIME [epoch: 16.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_472.pth
	Model improved!!!
EPOCH 473/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01755885594273732		[learning rate: 0.0012888]
	Learning Rate: 0.00128877
	LOSS [training: 0.01755885594273732 | validation: 0.02328572791963406]
	TIME [epoch: 16.8 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01765860830796925		[learning rate: 0.0012825]
	Learning Rate: 0.00128254
	LOSS [training: 0.01765860830796925 | validation: 0.02277488466939633]
	TIME [epoch: 16.8 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01801030109979947		[learning rate: 0.0012763]
	Learning Rate: 0.00127634
	LOSS [training: 0.01801030109979947 | validation: 0.02269464713122464]
	TIME [epoch: 16.8 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017851103460522044		[learning rate: 0.0012702]
	Learning Rate: 0.00127016
	LOSS [training: 0.017851103460522044 | validation: 0.02414162449524428]
	TIME [epoch: 16.8 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01796573501185691		[learning rate: 0.001264]
	Learning Rate: 0.00126402
	LOSS [training: 0.01796573501185691 | validation: 0.022705536214079492]
	TIME [epoch: 16.8 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017955928666688842		[learning rate: 0.0012579]
	Learning Rate: 0.00125791
	LOSS [training: 0.017955928666688842 | validation: 0.022567709546071832]
	TIME [epoch: 16.8 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017371741333383782		[learning rate: 0.0012518]
	Learning Rate: 0.00125183
	LOSS [training: 0.017371741333383782 | validation: 0.023264354157329914]
	TIME [epoch: 16.8 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01829820118091931		[learning rate: 0.0012458]
	Learning Rate: 0.00124577
	LOSS [training: 0.01829820118091931 | validation: 0.02294112461568483]
	TIME [epoch: 16.8 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017629978036133		[learning rate: 0.0012397]
	Learning Rate: 0.00123975
	LOSS [training: 0.017629978036133 | validation: 0.023239118056964214]
	TIME [epoch: 16.8 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017870041220277206		[learning rate: 0.0012338]
	Learning Rate: 0.00123375
	LOSS [training: 0.017870041220277206 | validation: 0.022410563363078576]
	TIME [epoch: 16.8 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017737554994217797		[learning rate: 0.0012278]
	Learning Rate: 0.00122779
	LOSS [training: 0.017737554994217797 | validation: 0.0222549787785141]
	TIME [epoch: 16.8 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017620299799492544		[learning rate: 0.0012218]
	Learning Rate: 0.00122185
	LOSS [training: 0.017620299799492544 | validation: 0.022683166203270322]
	TIME [epoch: 16.8 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017871139373162856		[learning rate: 0.0012159]
	Learning Rate: 0.00121594
	LOSS [training: 0.017871139373162856 | validation: 0.023858855277929844]
	TIME [epoch: 16.8 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017837774099194556		[learning rate: 0.0012101]
	Learning Rate: 0.00121006
	LOSS [training: 0.017837774099194556 | validation: 0.022310074967814675]
	TIME [epoch: 16.8 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017883867359377238		[learning rate: 0.0012042]
	Learning Rate: 0.00120421
	LOSS [training: 0.017883867359377238 | validation: 0.0214312770644748]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_487.pth
	Model improved!!!
EPOCH 488/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017593252676282877		[learning rate: 0.0011984]
	Learning Rate: 0.00119839
	LOSS [training: 0.017593252676282877 | validation: 0.02248931825393095]
	TIME [epoch: 16.7 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017913628940179043		[learning rate: 0.0011926]
	Learning Rate: 0.00119259
	LOSS [training: 0.017913628940179043 | validation: 0.02194714821866249]
	TIME [epoch: 16.7 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018115933294143863		[learning rate: 0.0011868]
	Learning Rate: 0.00118682
	LOSS [training: 0.018115933294143863 | validation: 0.021819477264605425]
	TIME [epoch: 16.7 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017980400760308914		[learning rate: 0.0011811]
	Learning Rate: 0.00118108
	LOSS [training: 0.017980400760308914 | validation: 0.022291146694081648]
	TIME [epoch: 16.7 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01705770106688016		[learning rate: 0.0011754]
	Learning Rate: 0.00117537
	LOSS [training: 0.01705770106688016 | validation: 0.021890530985474027]
	TIME [epoch: 16.7 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01806940395443491		[learning rate: 0.0011697]
	Learning Rate: 0.00116969
	LOSS [training: 0.01806940395443491 | validation: 0.022283984073434928]
	TIME [epoch: 16.7 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017920106304652284		[learning rate: 0.001164]
	Learning Rate: 0.00116403
	LOSS [training: 0.017920106304652284 | validation: 0.022771127963647084]
	TIME [epoch: 16.7 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021339481501908602		[learning rate: 0.0011584]
	Learning Rate: 0.0011584
	LOSS [training: 0.021339481501908602 | validation: 0.023877870331591416]
	TIME [epoch: 16.7 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01749335094710438		[learning rate: 0.0011528]
	Learning Rate: 0.0011528
	LOSS [training: 0.01749335094710438 | validation: 0.023551526006066508]
	TIME [epoch: 16.8 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017876598717769157		[learning rate: 0.0011472]
	Learning Rate: 0.00114723
	LOSS [training: 0.017876598717769157 | validation: 0.02206422120131744]
	TIME [epoch: 16.8 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018197226769460773		[learning rate: 0.0011417]
	Learning Rate: 0.00114168
	LOSS [training: 0.018197226769460773 | validation: 0.022130003071617988]
	TIME [epoch: 16.8 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017527801400002464		[learning rate: 0.0011362]
	Learning Rate: 0.00113616
	LOSS [training: 0.017527801400002464 | validation: 0.022084370624079596]
	TIME [epoch: 16.8 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017657024949661825		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.017657024949661825 | validation: 0.022302319019840797]
	TIME [epoch: 16.8 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017402443484193664		[learning rate: 0.0011252]
	Learning Rate: 0.0011252
	LOSS [training: 0.017402443484193664 | validation: 0.02233089516536657]
	TIME [epoch: 59 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017250604654958025		[learning rate: 0.0011198]
	Learning Rate: 0.00111975
	LOSS [training: 0.017250604654958025 | validation: 0.022304286097006756]
	TIME [epoch: 35.2 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017721693632874184		[learning rate: 0.0011143]
	Learning Rate: 0.00111434
	LOSS [training: 0.017721693632874184 | validation: 0.021786734194143204]
	TIME [epoch: 35.2 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017863287675142878		[learning rate: 0.001109]
	Learning Rate: 0.00110895
	LOSS [training: 0.017863287675142878 | validation: 0.022292059308654716]
	TIME [epoch: 35.2 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018442326775813214		[learning rate: 0.0011036]
	Learning Rate: 0.00110359
	LOSS [training: 0.018442326775813214 | validation: 0.02277643023679769]
	TIME [epoch: 35.2 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017761956552787263		[learning rate: 0.0010983]
	Learning Rate: 0.00109825
	LOSS [training: 0.017761956552787263 | validation: 0.022237764469326748]
	TIME [epoch: 35.2 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017709836730086144		[learning rate: 0.0010929]
	Learning Rate: 0.00109294
	LOSS [training: 0.017709836730086144 | validation: 0.02214949782148462]
	TIME [epoch: 35.2 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018439263455363106		[learning rate: 0.0010877]
	Learning Rate: 0.00108766
	LOSS [training: 0.018439263455363106 | validation: 0.021709197626366816]
	TIME [epoch: 35.2 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01746863052825739		[learning rate: 0.0010824]
	Learning Rate: 0.0010824
	LOSS [training: 0.01746863052825739 | validation: 0.021550383794810973]
	TIME [epoch: 35.2 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017159769988465204		[learning rate: 0.0010772]
	Learning Rate: 0.00107716
	LOSS [training: 0.017159769988465204 | validation: 0.02252560737322003]
	TIME [epoch: 35.2 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017685783711194916		[learning rate: 0.001072]
	Learning Rate: 0.00107195
	LOSS [training: 0.017685783711194916 | validation: 0.022394798397245234]
	TIME [epoch: 35.2 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018234240639646623		[learning rate: 0.0010668]
	Learning Rate: 0.00106677
	LOSS [training: 0.018234240639646623 | validation: 0.02181105852948761]
	TIME [epoch: 35.2 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017047537584087454		[learning rate: 0.0010616]
	Learning Rate: 0.00106161
	LOSS [training: 0.017047537584087454 | validation: 0.02148421805030395]
	TIME [epoch: 35.2 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01738255271664876		[learning rate: 0.0010565]
	Learning Rate: 0.00105648
	LOSS [training: 0.01738255271664876 | validation: 0.023002036308356885]
	TIME [epoch: 35.2 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016937371814900612		[learning rate: 0.0010514]
	Learning Rate: 0.00105137
	LOSS [training: 0.016937371814900612 | validation: 0.022240023931191163]
	TIME [epoch: 35.2 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017448220409068873		[learning rate: 0.0010463]
	Learning Rate: 0.00104628
	LOSS [training: 0.017448220409068873 | validation: 0.022704306633821406]
	TIME [epoch: 35.2 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017799119026909446		[learning rate: 0.0010412]
	Learning Rate: 0.00104122
	LOSS [training: 0.017799119026909446 | validation: 0.022275214199339487]
	TIME [epoch: 35.2 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017181968582368996		[learning rate: 0.0010362]
	Learning Rate: 0.00103619
	LOSS [training: 0.017181968582368996 | validation: 0.02263658647292376]
	TIME [epoch: 35.2 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0174143102151101		[learning rate: 0.0010312]
	Learning Rate: 0.00103118
	LOSS [training: 0.0174143102151101 | validation: 0.022157057221077647]
	TIME [epoch: 35.2 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01710314692711026		[learning rate: 0.0010262]
	Learning Rate: 0.00102619
	LOSS [training: 0.01710314692711026 | validation: 0.02221982412734975]
	TIME [epoch: 35.2 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01657920828312384		[learning rate: 0.0010212]
	Learning Rate: 0.00102123
	LOSS [training: 0.01657920828312384 | validation: 0.02248523165215037]
	TIME [epoch: 35.2 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016889624516848195		[learning rate: 0.0010163]
	Learning Rate: 0.00101629
	LOSS [training: 0.016889624516848195 | validation: 0.021877005160353156]
	TIME [epoch: 35.2 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01753906240330738		[learning rate: 0.0010114]
	Learning Rate: 0.00101138
	LOSS [training: 0.01753906240330738 | validation: 0.02232243492545627]
	TIME [epoch: 35.2 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0166468080022696		[learning rate: 0.0010065]
	Learning Rate: 0.00100648
	LOSS [training: 0.0166468080022696 | validation: 0.022369506019339264]
	TIME [epoch: 35.2 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017282448641206316		[learning rate: 0.0010016]
	Learning Rate: 0.00100162
	LOSS [training: 0.017282448641206316 | validation: 0.02261149769213879]
	TIME [epoch: 35.2 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01675522718226788		[learning rate: 0.00099677]
	Learning Rate: 0.000996773
	LOSS [training: 0.01675522718226788 | validation: 0.021419389957347768]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_526.pth
	Model improved!!!
EPOCH 527/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01696056061218791		[learning rate: 0.00099195]
	Learning Rate: 0.000991953
	LOSS [training: 0.01696056061218791 | validation: 0.021724014831809885]
	TIME [epoch: 35.2 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017228006312600488		[learning rate: 0.00098716]
	Learning Rate: 0.000987156
	LOSS [training: 0.017228006312600488 | validation: 0.02248115747625219]
	TIME [epoch: 35.2 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016958919736548617		[learning rate: 0.00098238]
	Learning Rate: 0.000982383
	LOSS [training: 0.016958919736548617 | validation: 0.0213684198660307]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_529.pth
	Model improved!!!
EPOCH 530/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017323030611273816		[learning rate: 0.00097763]
	Learning Rate: 0.000977632
	LOSS [training: 0.017323030611273816 | validation: 0.02103521610487402]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_530.pth
	Model improved!!!
EPOCH 531/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018148754565418403		[learning rate: 0.0009729]
	Learning Rate: 0.000972904
	LOSS [training: 0.018148754565418403 | validation: 0.022736809829286747]
	TIME [epoch: 35.2 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017627766710785857		[learning rate: 0.0009682]
	Learning Rate: 0.0009682
	LOSS [training: 0.017627766710785857 | validation: 0.02157346280843291]
	TIME [epoch: 35.2 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01719257891000872		[learning rate: 0.00096352]
	Learning Rate: 0.000963518
	LOSS [training: 0.01719257891000872 | validation: 0.021918320378489436]
	TIME [epoch: 35.2 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017163143968240608		[learning rate: 0.00095886]
	Learning Rate: 0.000958858
	LOSS [training: 0.017163143968240608 | validation: 0.021042747562883157]
	TIME [epoch: 35.2 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016335252808617046		[learning rate: 0.00095422]
	Learning Rate: 0.000954221
	LOSS [training: 0.016335252808617046 | validation: 0.02169838884361987]
	TIME [epoch: 35.2 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016801287202567575		[learning rate: 0.00094961]
	Learning Rate: 0.000949607
	LOSS [training: 0.016801287202567575 | validation: 0.02137902793362724]
	TIME [epoch: 35.2 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016763037494352342		[learning rate: 0.00094501]
	Learning Rate: 0.000945015
	LOSS [training: 0.016763037494352342 | validation: 0.0217529728363563]
	TIME [epoch: 35.2 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016135561595343306		[learning rate: 0.00094044]
	Learning Rate: 0.000940445
	LOSS [training: 0.016135561595343306 | validation: 0.021588691028418514]
	TIME [epoch: 35.2 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01670856101808525		[learning rate: 0.0009359]
	Learning Rate: 0.000935897
	LOSS [training: 0.01670856101808525 | validation: 0.020905063914992274]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_539.pth
	Model improved!!!
EPOCH 540/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016371113100893155		[learning rate: 0.00093137]
	Learning Rate: 0.000931371
	LOSS [training: 0.016371113100893155 | validation: 0.02159693948266862]
	TIME [epoch: 35.2 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0161778136410568		[learning rate: 0.00092687]
	Learning Rate: 0.000926867
	LOSS [training: 0.0161778136410568 | validation: 0.021783584272032596]
	TIME [epoch: 35.2 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016783928900968713		[learning rate: 0.00092239]
	Learning Rate: 0.000922385
	LOSS [training: 0.016783928900968713 | validation: 0.022061799917918873]
	TIME [epoch: 35.2 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016826738088744787		[learning rate: 0.00091792]
	Learning Rate: 0.000917924
	LOSS [training: 0.016826738088744787 | validation: 0.021390562569383483]
	TIME [epoch: 35.2 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017118773573455846		[learning rate: 0.00091349]
	Learning Rate: 0.000913486
	LOSS [training: 0.017118773573455846 | validation: 0.02276298138020928]
	TIME [epoch: 35.2 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019831213639767416		[learning rate: 0.00090907]
	Learning Rate: 0.000909068
	LOSS [training: 0.019831213639767416 | validation: 0.025567420537002842]
	TIME [epoch: 35.2 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021397642646575774		[learning rate: 0.00090467]
	Learning Rate: 0.000904672
	LOSS [training: 0.021397642646575774 | validation: 0.023138514675284567]
	TIME [epoch: 35.2 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01911148603017061		[learning rate: 0.0009003]
	Learning Rate: 0.000900297
	LOSS [training: 0.01911148603017061 | validation: 0.02134972660441108]
	TIME [epoch: 35.2 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01768058399534813		[learning rate: 0.00089594]
	Learning Rate: 0.000895943
	LOSS [training: 0.01768058399534813 | validation: 0.021995220286857964]
	TIME [epoch: 35.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016412104155357383		[learning rate: 0.00089161]
	Learning Rate: 0.000891611
	LOSS [training: 0.016412104155357383 | validation: 0.02087532276104855]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017002115133700788		[learning rate: 0.0008873]
	Learning Rate: 0.000887299
	LOSS [training: 0.017002115133700788 | validation: 0.021950667748951404]
	TIME [epoch: 35.2 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01735574535531879		[learning rate: 0.00088301]
	Learning Rate: 0.000883009
	LOSS [training: 0.01735574535531879 | validation: 0.021503204929130878]
	TIME [epoch: 35.2 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017213073293180767		[learning rate: 0.00087874]
	Learning Rate: 0.000878738
	LOSS [training: 0.017213073293180767 | validation: 0.02182390853567461]
	TIME [epoch: 35.2 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016366124158754918		[learning rate: 0.00087449]
	Learning Rate: 0.000874489
	LOSS [training: 0.016366124158754918 | validation: 0.021575246666165584]
	TIME [epoch: 35.2 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017234299094122354		[learning rate: 0.00087026]
	Learning Rate: 0.00087026
	LOSS [training: 0.017234299094122354 | validation: 0.021416326417156174]
	TIME [epoch: 35.2 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0166154763420375		[learning rate: 0.00086605]
	Learning Rate: 0.000866052
	LOSS [training: 0.0166154763420375 | validation: 0.021699504538385383]
	TIME [epoch: 35.2 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01645467331717711		[learning rate: 0.00086186]
	Learning Rate: 0.000861864
	LOSS [training: 0.01645467331717711 | validation: 0.021422223652474773]
	TIME [epoch: 35.2 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01605166333897008		[learning rate: 0.0008577]
	Learning Rate: 0.000857696
	LOSS [training: 0.01605166333897008 | validation: 0.0210039664888157]
	TIME [epoch: 35.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01577561644185693		[learning rate: 0.00085355]
	Learning Rate: 0.000853548
	LOSS [training: 0.01577561644185693 | validation: 0.02098835181631727]
	TIME [epoch: 35.2 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015876883937998704		[learning rate: 0.00084942]
	Learning Rate: 0.000849421
	LOSS [training: 0.015876883937998704 | validation: 0.020779814873813987]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_559.pth
	Model improved!!!
EPOCH 560/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015651449421573708		[learning rate: 0.00084531]
	Learning Rate: 0.000845313
	LOSS [training: 0.015651449421573708 | validation: 0.021022502008173252]
	TIME [epoch: 35.3 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016144735733500903		[learning rate: 0.00084123]
	Learning Rate: 0.000841225
	LOSS [training: 0.016144735733500903 | validation: 0.021674771210600588]
	TIME [epoch: 35.2 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01620925046013359		[learning rate: 0.00083716]
	Learning Rate: 0.000837157
	LOSS [training: 0.01620925046013359 | validation: 0.02105851156098963]
	TIME [epoch: 35.2 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016715582173127196		[learning rate: 0.00083311]
	Learning Rate: 0.000833109
	LOSS [training: 0.016715582173127196 | validation: 0.0208651192813324]
	TIME [epoch: 35.2 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016053878516635537		[learning rate: 0.00082908]
	Learning Rate: 0.00082908
	LOSS [training: 0.016053878516635537 | validation: 0.020539458438790802]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_564.pth
	Model improved!!!
EPOCH 565/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015969025509789663		[learning rate: 0.00082507]
	Learning Rate: 0.000825071
	LOSS [training: 0.015969025509789663 | validation: 0.021013567457025206]
	TIME [epoch: 35.2 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016482355296799308		[learning rate: 0.00082108]
	Learning Rate: 0.000821081
	LOSS [training: 0.016482355296799308 | validation: 0.022196195996617454]
	TIME [epoch: 35.2 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016840563944681454		[learning rate: 0.00081711]
	Learning Rate: 0.00081711
	LOSS [training: 0.016840563944681454 | validation: 0.0211568726320585]
	TIME [epoch: 35.2 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016470687518348834		[learning rate: 0.00081316]
	Learning Rate: 0.000813159
	LOSS [training: 0.016470687518348834 | validation: 0.020732007071471534]
	TIME [epoch: 35.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016026150921566628		[learning rate: 0.00080923]
	Learning Rate: 0.000809226
	LOSS [training: 0.016026150921566628 | validation: 0.022229118957653324]
	TIME [epoch: 35.2 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01640815767235641		[learning rate: 0.00080531]
	Learning Rate: 0.000805313
	LOSS [training: 0.01640815767235641 | validation: 0.020443948688065983]
	TIME [epoch: 35.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_570.pth
	Model improved!!!
EPOCH 571/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01598050625343664		[learning rate: 0.00080142]
	Learning Rate: 0.000801419
	LOSS [training: 0.01598050625343664 | validation: 0.022449891587662196]
	TIME [epoch: 35.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016426587862079265		[learning rate: 0.00079754]
	Learning Rate: 0.000797544
	LOSS [training: 0.016426587862079265 | validation: 0.025041612524378507]
	TIME [epoch: 35.2 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01815356177836376		[learning rate: 0.00079369]
	Learning Rate: 0.000793686
	LOSS [training: 0.01815356177836376 | validation: 0.02232841178108638]
	TIME [epoch: 35.2 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016608678872663266		[learning rate: 0.00078985]
	Learning Rate: 0.000789848
	LOSS [training: 0.016608678872663266 | validation: 0.021039358164473398]
	TIME [epoch: 35.2 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01658365794298981		[learning rate: 0.00078603]
	Learning Rate: 0.000786029
	LOSS [training: 0.01658365794298981 | validation: 0.020692945355392945]
	TIME [epoch: 35.2 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015692286962672625		[learning rate: 0.00078223]
	Learning Rate: 0.000782228
	LOSS [training: 0.015692286962672625 | validation: 0.020596034812687593]
	TIME [epoch: 35.2 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01530224412563022		[learning rate: 0.00077845]
	Learning Rate: 0.000778445
	LOSS [training: 0.01530224412563022 | validation: 0.021031776779104075]
	TIME [epoch: 35.2 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015241194063895158		[learning rate: 0.00077468]
	Learning Rate: 0.000774681
	LOSS [training: 0.015241194063895158 | validation: 0.020630296761029104]
	TIME [epoch: 35.2 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01585371000744019		[learning rate: 0.00077093]
	Learning Rate: 0.000770935
	LOSS [training: 0.01585371000744019 | validation: 0.023564420901467098]
	TIME [epoch: 35.2 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01707790092399368		[learning rate: 0.00076721]
	Learning Rate: 0.000767206
	LOSS [training: 0.01707790092399368 | validation: 0.021618614951196585]
	TIME [epoch: 35.2 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015511079012317337		[learning rate: 0.0007635]
	Learning Rate: 0.000763496
	LOSS [training: 0.015511079012317337 | validation: 0.02096534609165233]
	TIME [epoch: 35.2 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01563871244486429		[learning rate: 0.0007598]
	Learning Rate: 0.000759804
	LOSS [training: 0.01563871244486429 | validation: 0.022840465376835904]
	TIME [epoch: 35.2 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016547320550403588		[learning rate: 0.00075613]
	Learning Rate: 0.00075613
	LOSS [training: 0.016547320550403588 | validation: 0.022791810698069764]
	TIME [epoch: 35.2 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01574427259843274		[learning rate: 0.00075247]
	Learning Rate: 0.000752473
	LOSS [training: 0.01574427259843274 | validation: 0.020870671740590502]
	TIME [epoch: 35.2 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015324084227956525		[learning rate: 0.00074883]
	Learning Rate: 0.000748835
	LOSS [training: 0.015324084227956525 | validation: 0.021456265091614857]
	TIME [epoch: 35.2 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01603526535777209		[learning rate: 0.00074521]
	Learning Rate: 0.000745213
	LOSS [training: 0.01603526535777209 | validation: 0.020962589365374488]
	TIME [epoch: 35.2 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015768237567869638		[learning rate: 0.00074161]
	Learning Rate: 0.00074161
	LOSS [training: 0.015768237567869638 | validation: 0.02078554410454203]
	TIME [epoch: 35.2 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0154035816634685		[learning rate: 0.00073802]
	Learning Rate: 0.000738023
	LOSS [training: 0.0154035816634685 | validation: 0.020878837426344162]
	TIME [epoch: 35.2 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014973028482863119		[learning rate: 0.00073445]
	Learning Rate: 0.000734454
	LOSS [training: 0.014973028482863119 | validation: 0.021834691385669885]
	TIME [epoch: 35.2 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01495980671648083		[learning rate: 0.0007309]
	Learning Rate: 0.000730903
	LOSS [training: 0.01495980671648083 | validation: 0.020908356415981124]
	TIME [epoch: 35.2 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015453904003637295		[learning rate: 0.00072737]
	Learning Rate: 0.000727368
	LOSS [training: 0.015453904003637295 | validation: 0.02141806859649698]
	TIME [epoch: 35.2 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01627055880423706		[learning rate: 0.00072385]
	Learning Rate: 0.000723851
	LOSS [training: 0.01627055880423706 | validation: 0.02105602038006395]
	TIME [epoch: 35.2 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016417548989453426		[learning rate: 0.00072035]
	Learning Rate: 0.00072035
	LOSS [training: 0.016417548989453426 | validation: 0.020684932212420865]
	TIME [epoch: 35.2 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016513269493073423		[learning rate: 0.00071687]
	Learning Rate: 0.000716867
	LOSS [training: 0.016513269493073423 | validation: 0.02120474029238691]
	TIME [epoch: 35.2 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01615712555921846		[learning rate: 0.0007134]
	Learning Rate: 0.0007134
	LOSS [training: 0.01615712555921846 | validation: 0.020978576076796387]
	TIME [epoch: 35.2 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015189050116311532		[learning rate: 0.00070995]
	Learning Rate: 0.00070995
	LOSS [training: 0.015189050116311532 | validation: 0.022352365354262077]
	TIME [epoch: 35.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016896424778495473		[learning rate: 0.00070652]
	Learning Rate: 0.000706517
	LOSS [training: 0.016896424778495473 | validation: 0.021728995456880378]
	TIME [epoch: 35.2 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015253254707834209		[learning rate: 0.0007031]
	Learning Rate: 0.000703101
	LOSS [training: 0.015253254707834209 | validation: 0.021771613700842674]
	TIME [epoch: 35.2 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01545476326378969		[learning rate: 0.0006997]
	Learning Rate: 0.000699701
	LOSS [training: 0.01545476326378969 | validation: 0.020960257538559915]
	TIME [epoch: 35.2 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014713144815794771		[learning rate: 0.00069632]
	Learning Rate: 0.000696317
	LOSS [training: 0.014713144815794771 | validation: 0.0208586608309856]
	TIME [epoch: 35.2 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015431313881130287		[learning rate: 0.00069295]
	Learning Rate: 0.00069295
	LOSS [training: 0.015431313881130287 | validation: 0.02102838400237199]
	TIME [epoch: 35.2 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014990984987399944		[learning rate: 0.0006896]
	Learning Rate: 0.000689599
	LOSS [training: 0.014990984987399944 | validation: 0.021947522941453388]
	TIME [epoch: 35.3 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01463538172759922		[learning rate: 0.00068626]
	Learning Rate: 0.000686264
	LOSS [training: 0.01463538172759922 | validation: 0.02156433216155619]
	TIME [epoch: 35.3 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015001266825434923		[learning rate: 0.00068295]
	Learning Rate: 0.000682945
	LOSS [training: 0.015001266825434923 | validation: 0.020931837554628862]
	TIME [epoch: 35.2 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015131589577445231		[learning rate: 0.00067964]
	Learning Rate: 0.000679643
	LOSS [training: 0.015131589577445231 | validation: 0.021111241164373823]
	TIME [epoch: 35.2 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014663143222745806		[learning rate: 0.00067636]
	Learning Rate: 0.000676356
	LOSS [training: 0.014663143222745806 | validation: 0.020703937041319457]
	TIME [epoch: 35.2 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014654961599590613		[learning rate: 0.00067309]
	Learning Rate: 0.000673085
	LOSS [training: 0.014654961599590613 | validation: 0.021656706922883514]
	TIME [epoch: 35.2 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015181203877883803		[learning rate: 0.00066983]
	Learning Rate: 0.00066983
	LOSS [training: 0.015181203877883803 | validation: 0.02129535621874779]
	TIME [epoch: 35.2 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014841815479322373		[learning rate: 0.00066659]
	Learning Rate: 0.000666591
	LOSS [training: 0.014841815479322373 | validation: 0.020764009576849134]
	TIME [epoch: 35.3 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015232583944732161		[learning rate: 0.00066337]
	Learning Rate: 0.000663368
	LOSS [training: 0.015232583944732161 | validation: 0.021568766274507722]
	TIME [epoch: 35.2 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015193295089085563		[learning rate: 0.00066016]
	Learning Rate: 0.00066016
	LOSS [training: 0.015193295089085563 | validation: 0.02123197919172279]
	TIME [epoch: 35.2 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014618876442328657		[learning rate: 0.00065697]
	Learning Rate: 0.000656967
	LOSS [training: 0.014618876442328657 | validation: 0.020737442427141314]
	TIME [epoch: 35.2 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015118694100844113		[learning rate: 0.00065379]
	Learning Rate: 0.00065379
	LOSS [training: 0.015118694100844113 | validation: 0.021041893663259554]
	TIME [epoch: 35.2 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01466364853359406		[learning rate: 0.00065063]
	Learning Rate: 0.000650629
	LOSS [training: 0.01466364853359406 | validation: 0.021108925966009107]
	TIME [epoch: 35.2 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015059997256154043		[learning rate: 0.00064748]
	Learning Rate: 0.000647482
	LOSS [training: 0.015059997256154043 | validation: 0.02181254983039739]
	TIME [epoch: 35.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014966516557110435		[learning rate: 0.00064435]
	Learning Rate: 0.000644351
	LOSS [training: 0.014966516557110435 | validation: 0.020996762643445643]
	TIME [epoch: 35.2 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01486542933886155		[learning rate: 0.00064124]
	Learning Rate: 0.000641235
	LOSS [training: 0.01486542933886155 | validation: 0.02198148150071884]
	TIME [epoch: 35.2 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015862452458629415		[learning rate: 0.00063813]
	Learning Rate: 0.000638134
	LOSS [training: 0.015862452458629415 | validation: 0.021140868078935653]
	TIME [epoch: 35.2 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014873544063532427		[learning rate: 0.00063505]
	Learning Rate: 0.000635049
	LOSS [training: 0.014873544063532427 | validation: 0.0214550514407609]
	TIME [epoch: 35.2 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01472794349797208		[learning rate: 0.00063198]
	Learning Rate: 0.000631978
	LOSS [training: 0.01472794349797208 | validation: 0.021202152211399733]
	TIME [epoch: 35.2 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015329716571893137		[learning rate: 0.00062892]
	Learning Rate: 0.000628922
	LOSS [training: 0.015329716571893137 | validation: 0.022001936896765103]
	TIME [epoch: 35.2 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01504147193859076		[learning rate: 0.00062588]
	Learning Rate: 0.00062588
	LOSS [training: 0.01504147193859076 | validation: 0.022520391352945788]
	TIME [epoch: 35.2 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0150102562186374		[learning rate: 0.00062285]
	Learning Rate: 0.000622853
	LOSS [training: 0.0150102562186374 | validation: 0.020953460046652436]
	TIME [epoch: 35.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014863426171136729		[learning rate: 0.00061984]
	Learning Rate: 0.000619842
	LOSS [training: 0.014863426171136729 | validation: 0.022359330307057838]
	TIME [epoch: 35.2 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01453144320128296		[learning rate: 0.00061684]
	Learning Rate: 0.000616844
	LOSS [training: 0.01453144320128296 | validation: 0.021162984109004412]
	TIME [epoch: 35.2 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014475722040870847		[learning rate: 0.00061386]
	Learning Rate: 0.000613861
	LOSS [training: 0.014475722040870847 | validation: 0.02150472706655218]
	TIME [epoch: 35.3 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015183022665429612		[learning rate: 0.00061089]
	Learning Rate: 0.000610893
	LOSS [training: 0.015183022665429612 | validation: 0.021040264930276702]
	TIME [epoch: 35.2 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014961247701419223		[learning rate: 0.00060794]
	Learning Rate: 0.000607938
	LOSS [training: 0.014961247701419223 | validation: 0.02202554641840963]
	TIME [epoch: 35.2 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014868410310352126		[learning rate: 0.000605]
	Learning Rate: 0.000604999
	LOSS [training: 0.014868410310352126 | validation: 0.02188834100550424]
	TIME [epoch: 35.2 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015277505321054097		[learning rate: 0.00060207]
	Learning Rate: 0.000602073
	LOSS [training: 0.015277505321054097 | validation: 0.02115446740552433]
	TIME [epoch: 35.2 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01487657522708704		[learning rate: 0.00059916]
	Learning Rate: 0.000599161
	LOSS [training: 0.01487657522708704 | validation: 0.021171322713116596]
	TIME [epoch: 35.2 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01465954837527536		[learning rate: 0.00059626]
	Learning Rate: 0.000596264
	LOSS [training: 0.01465954837527536 | validation: 0.021023115973124586]
	TIME [epoch: 35.2 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014771868092178503		[learning rate: 0.00059338]
	Learning Rate: 0.000593381
	LOSS [training: 0.014771868092178503 | validation: 0.02177704609327516]
	TIME [epoch: 35.2 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014288202962098541		[learning rate: 0.00059051]
	Learning Rate: 0.000590511
	LOSS [training: 0.014288202962098541 | validation: 0.021213689851308625]
	TIME [epoch: 35.2 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014619004917546252		[learning rate: 0.00058766]
	Learning Rate: 0.000587655
	LOSS [training: 0.014619004917546252 | validation: 0.02208667871759466]
	TIME [epoch: 35.2 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015476847860723094		[learning rate: 0.00058481]
	Learning Rate: 0.000584814
	LOSS [training: 0.015476847860723094 | validation: 0.0222705632119744]
	TIME [epoch: 35.2 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014802904812211184		[learning rate: 0.00058199]
	Learning Rate: 0.000581986
	LOSS [training: 0.014802904812211184 | validation: 0.02200025499667896]
	TIME [epoch: 35.2 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01515102827813175		[learning rate: 0.00057917]
	Learning Rate: 0.000579171
	LOSS [training: 0.01515102827813175 | validation: 0.021482877850541742]
	TIME [epoch: 35.2 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014425746589882478		[learning rate: 0.00057637]
	Learning Rate: 0.00057637
	LOSS [training: 0.014425746589882478 | validation: 0.021387766447226092]
	TIME [epoch: 35.2 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014555216552578838		[learning rate: 0.00057358]
	Learning Rate: 0.000573583
	LOSS [training: 0.014555216552578838 | validation: 0.021620251546200397]
	TIME [epoch: 35.2 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014616069382412786		[learning rate: 0.00057081]
	Learning Rate: 0.000570809
	LOSS [training: 0.014616069382412786 | validation: 0.02190868579895422]
	TIME [epoch: 35.2 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014404767687998967		[learning rate: 0.00056805]
	Learning Rate: 0.000568049
	LOSS [training: 0.014404767687998967 | validation: 0.021346080384186516]
	TIME [epoch: 35.2 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014550627247929234		[learning rate: 0.0005653]
	Learning Rate: 0.000565302
	LOSS [training: 0.014550627247929234 | validation: 0.02078858901639447]
	TIME [epoch: 35.2 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014384652858654444		[learning rate: 0.00056257]
	Learning Rate: 0.000562568
	LOSS [training: 0.014384652858654444 | validation: 0.022049265304078827]
	TIME [epoch: 35.2 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014742426398389435		[learning rate: 0.00055985]
	Learning Rate: 0.000559848
	LOSS [training: 0.014742426398389435 | validation: 0.021842615486553297]
	TIME [epoch: 35.2 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014940676530291104		[learning rate: 0.00055714]
	Learning Rate: 0.000557141
	LOSS [training: 0.014940676530291104 | validation: 0.02121127879781526]
	TIME [epoch: 35.2 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014538261761412425		[learning rate: 0.00055445]
	Learning Rate: 0.000554446
	LOSS [training: 0.014538261761412425 | validation: 0.021704434715157966]
	TIME [epoch: 35.2 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014660153990616022		[learning rate: 0.00055177]
	Learning Rate: 0.000551765
	LOSS [training: 0.014660153990616022 | validation: 0.021891640968099427]
	TIME [epoch: 35.2 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01448224113802383		[learning rate: 0.0005491]
	Learning Rate: 0.000549097
	LOSS [training: 0.01448224113802383 | validation: 0.022182393981528065]
	TIME [epoch: 35.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01484655631031004		[learning rate: 0.00054644]
	Learning Rate: 0.000546442
	LOSS [training: 0.01484655631031004 | validation: 0.02160457233332337]
	TIME [epoch: 35.2 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014280183933485699		[learning rate: 0.0005438]
	Learning Rate: 0.000543799
	LOSS [training: 0.014280183933485699 | validation: 0.020986745141182095]
	TIME [epoch: 35.2 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014667913550709307		[learning rate: 0.00054117]
	Learning Rate: 0.000541169
	LOSS [training: 0.014667913550709307 | validation: 0.021556961093566324]
	TIME [epoch: 35.2 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014750124287054528		[learning rate: 0.00053855]
	Learning Rate: 0.000538552
	LOSS [training: 0.014750124287054528 | validation: 0.0214003312840417]
	TIME [epoch: 35.2 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014492943883419226		[learning rate: 0.00053595]
	Learning Rate: 0.000535948
	LOSS [training: 0.014492943883419226 | validation: 0.021660716401165275]
	TIME [epoch: 35.2 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014309992122768555		[learning rate: 0.00053336]
	Learning Rate: 0.000533356
	LOSS [training: 0.014309992122768555 | validation: 0.02172099164596443]
	TIME [epoch: 35.2 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014368123633450977		[learning rate: 0.00053078]
	Learning Rate: 0.000530777
	LOSS [training: 0.014368123633450977 | validation: 0.021755422226467706]
	TIME [epoch: 35.2 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014346575883062982		[learning rate: 0.00052821]
	Learning Rate: 0.00052821
	LOSS [training: 0.014346575883062982 | validation: 0.02190071142693153]
	TIME [epoch: 35.2 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01400654045012606		[learning rate: 0.00052566]
	Learning Rate: 0.000525656
	LOSS [training: 0.01400654045012606 | validation: 0.02133788938718098]
	TIME [epoch: 35.2 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013779487080877827		[learning rate: 0.00052311]
	Learning Rate: 0.000523114
	LOSS [training: 0.013779487080877827 | validation: 0.021859083916165933]
	TIME [epoch: 35.2 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015213438554744324		[learning rate: 0.00052058]
	Learning Rate: 0.000520584
	LOSS [training: 0.015213438554744324 | validation: 0.021887153430059755]
	TIME [epoch: 35.2 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015586412462845043		[learning rate: 0.00051807]
	Learning Rate: 0.000518067
	LOSS [training: 0.015586412462845043 | validation: 0.02190412383055904]
	TIME [epoch: 35.2 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014724628528605127		[learning rate: 0.00051556]
	Learning Rate: 0.000515562
	LOSS [training: 0.014724628528605127 | validation: 0.02116227890621498]
	TIME [epoch: 35.2 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015176000689565303		[learning rate: 0.00051307]
	Learning Rate: 0.000513069
	LOSS [training: 0.015176000689565303 | validation: 0.02195426025399756]
	TIME [epoch: 35.2 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01505023737502885		[learning rate: 0.00051059]
	Learning Rate: 0.000510587
	LOSS [training: 0.01505023737502885 | validation: 0.021155913072370584]
	TIME [epoch: 35.2 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014729034097688226		[learning rate: 0.00050812]
	Learning Rate: 0.000508118
	LOSS [training: 0.014729034097688226 | validation: 0.021702798449076147]
	TIME [epoch: 35.2 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015122003424607929		[learning rate: 0.00050566]
	Learning Rate: 0.000505661
	LOSS [training: 0.015122003424607929 | validation: 0.022154941118346122]
	TIME [epoch: 35.2 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014922576264400937		[learning rate: 0.00050322]
	Learning Rate: 0.000503216
	LOSS [training: 0.014922576264400937 | validation: 0.021630362444428324]
	TIME [epoch: 35.2 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014899646440444466		[learning rate: 0.00050078]
	Learning Rate: 0.000500782
	LOSS [training: 0.014899646440444466 | validation: 0.02189649077339258]
	TIME [epoch: 35.2 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014755840203057721		[learning rate: 0.00049836]
	Learning Rate: 0.000498361
	LOSS [training: 0.014755840203057721 | validation: 0.02281289091626343]
	TIME [epoch: 35.2 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014989723756103033		[learning rate: 0.00049595]
	Learning Rate: 0.000495951
	LOSS [training: 0.014989723756103033 | validation: 0.022164116768809656]
	TIME [epoch: 35.2 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015011799120951958		[learning rate: 0.00049355]
	Learning Rate: 0.000493552
	LOSS [training: 0.015011799120951958 | validation: 0.021918114994710847]
	TIME [epoch: 35.2 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015230448464945466		[learning rate: 0.00049117]
	Learning Rate: 0.000491166
	LOSS [training: 0.015230448464945466 | validation: 0.021552749681486776]
	TIME [epoch: 35.2 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015454831785085632		[learning rate: 0.00048879]
	Learning Rate: 0.000488791
	LOSS [training: 0.015454831785085632 | validation: 0.02208398064608059]
	TIME [epoch: 35.2 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014587642024924746		[learning rate: 0.00048643]
	Learning Rate: 0.000486427
	LOSS [training: 0.014587642024924746 | validation: 0.022577435501467864]
	TIME [epoch: 35.2 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015189481998450166		[learning rate: 0.00048407]
	Learning Rate: 0.000484074
	LOSS [training: 0.015189481998450166 | validation: 0.02185015064297631]
	TIME [epoch: 35.2 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014103125981616135		[learning rate: 0.00048173]
	Learning Rate: 0.000481734
	LOSS [training: 0.014103125981616135 | validation: 0.021744144405508276]
	TIME [epoch: 35.2 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014974237581055108		[learning rate: 0.0004794]
	Learning Rate: 0.000479404
	LOSS [training: 0.014974237581055108 | validation: 0.020945377982347527]
	TIME [epoch: 35.2 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014287615183423552		[learning rate: 0.00047709]
	Learning Rate: 0.000477086
	LOSS [training: 0.014287615183423552 | validation: 0.021127585139654098]
	TIME [epoch: 35.2 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015007033863354863		[learning rate: 0.00047478]
	Learning Rate: 0.000474779
	LOSS [training: 0.015007033863354863 | validation: 0.021024077043957118]
	TIME [epoch: 35.2 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014617902795510318		[learning rate: 0.00047248]
	Learning Rate: 0.000472483
	LOSS [training: 0.014617902795510318 | validation: 0.02055074816974861]
	TIME [epoch: 35.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014844197486085743		[learning rate: 0.0004702]
	Learning Rate: 0.000470198
	LOSS [training: 0.014844197486085743 | validation: 0.021011235534401405]
	TIME [epoch: 35.2 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014480563786436461		[learning rate: 0.00046792]
	Learning Rate: 0.000467924
	LOSS [training: 0.014480563786436461 | validation: 0.02313175144015359]
	TIME [epoch: 35.2 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014353861133969172		[learning rate: 0.00046566]
	Learning Rate: 0.000465661
	LOSS [training: 0.014353861133969172 | validation: 0.020835196729877426]
	TIME [epoch: 35.2 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015085231870272385		[learning rate: 0.00046341]
	Learning Rate: 0.000463409
	LOSS [training: 0.015085231870272385 | validation: 0.022067719329012633]
	TIME [epoch: 35.2 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014629283556924022		[learning rate: 0.00046117]
	Learning Rate: 0.000461168
	LOSS [training: 0.014629283556924022 | validation: 0.020920423526454412]
	TIME [epoch: 35.2 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014324678707547084		[learning rate: 0.00045894]
	Learning Rate: 0.000458938
	LOSS [training: 0.014324678707547084 | validation: 0.02107417553704206]
	TIME [epoch: 35.2 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014843254551343615		[learning rate: 0.00045672]
	Learning Rate: 0.000456719
	LOSS [training: 0.014843254551343615 | validation: 0.02057848898207229]
	TIME [epoch: 35.2 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015022593048661376		[learning rate: 0.00045451]
	Learning Rate: 0.00045451
	LOSS [training: 0.015022593048661376 | validation: 0.0209403856165927]
	TIME [epoch: 35.2 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015375958880019913		[learning rate: 0.00045231]
	Learning Rate: 0.000452312
	LOSS [training: 0.015375958880019913 | validation: 0.021558620931718935]
	TIME [epoch: 35.2 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01480435182798383		[learning rate: 0.00045013]
	Learning Rate: 0.000450125
	LOSS [training: 0.01480435182798383 | validation: 0.02180464956252515]
	TIME [epoch: 35.2 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014804542160481908		[learning rate: 0.00044795]
	Learning Rate: 0.000447948
	LOSS [training: 0.014804542160481908 | validation: 0.021626194110176928]
	TIME [epoch: 35.2 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014853725015465344		[learning rate: 0.00044578]
	Learning Rate: 0.000445782
	LOSS [training: 0.014853725015465344 | validation: 0.020571775683498276]
	TIME [epoch: 35.2 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015142527252810905		[learning rate: 0.00044363]
	Learning Rate: 0.000443626
	LOSS [training: 0.015142527252810905 | validation: 0.0214545873600228]
	TIME [epoch: 35.2 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015318574509766624		[learning rate: 0.00044148]
	Learning Rate: 0.000441481
	LOSS [training: 0.015318574509766624 | validation: 0.020960516710071958]
	TIME [epoch: 35.2 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014906194285793336		[learning rate: 0.00043935]
	Learning Rate: 0.000439346
	LOSS [training: 0.014906194285793336 | validation: 0.021039663455504714]
	TIME [epoch: 35.2 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014570574915508979		[learning rate: 0.00043722]
	Learning Rate: 0.000437222
	LOSS [training: 0.014570574915508979 | validation: 0.021009452337089684]
	TIME [epoch: 35.2 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01496516478152436		[learning rate: 0.00043511]
	Learning Rate: 0.000435107
	LOSS [training: 0.01496516478152436 | validation: 0.021122757599550363]
	TIME [epoch: 35.2 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014572143566032958		[learning rate: 0.000433]
	Learning Rate: 0.000433003
	LOSS [training: 0.014572143566032958 | validation: 0.020819170630042235]
	TIME [epoch: 35.2 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014281666321503962		[learning rate: 0.00043091]
	Learning Rate: 0.000430909
	LOSS [training: 0.014281666321503962 | validation: 0.02173541041158233]
	TIME [epoch: 35.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014455112700420205		[learning rate: 0.00042883]
	Learning Rate: 0.000428826
	LOSS [training: 0.014455112700420205 | validation: 0.020962963145200186]
	TIME [epoch: 35.2 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014322169889789517		[learning rate: 0.00042675]
	Learning Rate: 0.000426752
	LOSS [training: 0.014322169889789517 | validation: 0.021421007610116127]
	TIME [epoch: 95.9 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014529583494087311		[learning rate: 0.00042469]
	Learning Rate: 0.000424688
	LOSS [training: 0.014529583494087311 | validation: 0.02113159733500312]
	TIME [epoch: 72 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014172343086779749		[learning rate: 0.00042263]
	Learning Rate: 0.000422634
	LOSS [training: 0.014172343086779749 | validation: 0.021831273700413722]
	TIME [epoch: 72.1 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015120903419930174		[learning rate: 0.00042059]
	Learning Rate: 0.000420591
	LOSS [training: 0.015120903419930174 | validation: 0.021440017296460848]
	TIME [epoch: 72.1 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014492923742843824		[learning rate: 0.00041856]
	Learning Rate: 0.000418557
	LOSS [training: 0.014492923742843824 | validation: 0.021569344221723755]
	TIME [epoch: 72.1 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014410494041573447		[learning rate: 0.00041653]
	Learning Rate: 0.000416533
	LOSS [training: 0.014410494041573447 | validation: 0.021372697028351637]
	TIME [epoch: 72.1 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01453674280861888		[learning rate: 0.00041452]
	Learning Rate: 0.000414518
	LOSS [training: 0.01453674280861888 | validation: 0.021948059419448853]
	TIME [epoch: 72.2 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01436429617704551		[learning rate: 0.00041251]
	Learning Rate: 0.000412514
	LOSS [training: 0.01436429617704551 | validation: 0.021786482965244925]
	TIME [epoch: 72.1 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014508198957844227		[learning rate: 0.00041052]
	Learning Rate: 0.000410519
	LOSS [training: 0.014508198957844227 | validation: 0.021430640544174262]
	TIME [epoch: 72 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014748784390455218		[learning rate: 0.00040853]
	Learning Rate: 0.000408534
	LOSS [training: 0.014748784390455218 | validation: 0.021547508421273624]
	TIME [epoch: 72.1 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014006394153747196		[learning rate: 0.00040656]
	Learning Rate: 0.000406558
	LOSS [training: 0.014006394153747196 | validation: 0.021500194136882006]
	TIME [epoch: 72.2 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014414018635798874		[learning rate: 0.00040459]
	Learning Rate: 0.000404592
	LOSS [training: 0.014414018635798874 | validation: 0.02177945230679526]
	TIME [epoch: 72.1 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01483996167789145		[learning rate: 0.00040264]
	Learning Rate: 0.000402636
	LOSS [training: 0.01483996167789145 | validation: 0.02163237896577817]
	TIME [epoch: 72.2 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014433811541854913		[learning rate: 0.00040069]
	Learning Rate: 0.000400689
	LOSS [training: 0.014433811541854913 | validation: 0.020594589151473563]
	TIME [epoch: 72.2 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014796633105667409		[learning rate: 0.00039875]
	Learning Rate: 0.000398751
	LOSS [training: 0.014796633105667409 | validation: 0.021114317710560816]
	TIME [epoch: 72.1 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015175888743533712		[learning rate: 0.00039682]
	Learning Rate: 0.000396823
	LOSS [training: 0.015175888743533712 | validation: 0.02149813072678196]
	TIME [epoch: 72 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015070091320716536		[learning rate: 0.0003949]
	Learning Rate: 0.000394904
	LOSS [training: 0.015070091320716536 | validation: 0.021236432593792737]
	TIME [epoch: 72.1 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014791478524729012		[learning rate: 0.00039299]
	Learning Rate: 0.000392994
	LOSS [training: 0.014791478524729012 | validation: 0.021660412283719618]
	TIME [epoch: 72.1 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01460097174784362		[learning rate: 0.00039109]
	Learning Rate: 0.000391094
	LOSS [training: 0.01460097174784362 | validation: 0.021790968979781274]
	TIME [epoch: 72.1 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014695823035461214		[learning rate: 0.0003892]
	Learning Rate: 0.000389202
	LOSS [training: 0.014695823035461214 | validation: 0.02173655542658259]
	TIME [epoch: 72.1 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014783074633647197		[learning rate: 0.00038732]
	Learning Rate: 0.00038732
	LOSS [training: 0.014783074633647197 | validation: 0.021740981019715735]
	TIME [epoch: 72.1 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01356982854652665		[learning rate: 0.00038545]
	Learning Rate: 0.000385447
	LOSS [training: 0.01356982854652665 | validation: 0.022354008211748183]
	TIME [epoch: 72.1 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014496800981475247		[learning rate: 0.00038358]
	Learning Rate: 0.000383583
	LOSS [training: 0.014496800981475247 | validation: 0.02132388912992203]
	TIME [epoch: 72.1 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014875370418122966		[learning rate: 0.00038173]
	Learning Rate: 0.000381728
	LOSS [training: 0.014875370418122966 | validation: 0.021400885029389662]
	TIME [epoch: 72 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01417994210692953		[learning rate: 0.00037988]
	Learning Rate: 0.000379882
	LOSS [training: 0.01417994210692953 | validation: 0.021443645607159306]
	TIME [epoch: 72.1 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014240172650367732		[learning rate: 0.00037805]
	Learning Rate: 0.000378045
	LOSS [training: 0.014240172650367732 | validation: 0.02086539160646196]
	TIME [epoch: 72.1 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01438524032433798		[learning rate: 0.00037622]
	Learning Rate: 0.000376217
	LOSS [training: 0.01438524032433798 | validation: 0.021601237503344195]
	TIME [epoch: 72.1 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014582991849323214		[learning rate: 0.0003744]
	Learning Rate: 0.000374398
	LOSS [training: 0.014582991849323214 | validation: 0.021937058743153492]
	TIME [epoch: 72.1 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014179068574584416		[learning rate: 0.00037259]
	Learning Rate: 0.000372587
	LOSS [training: 0.014179068574584416 | validation: 0.021637555771885277]
	TIME [epoch: 72.1 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014708641214421858		[learning rate: 0.00037079]
	Learning Rate: 0.000370786
	LOSS [training: 0.014708641214421858 | validation: 0.021142790539663156]
	TIME [epoch: 72.1 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013944098048274742		[learning rate: 0.00036899]
	Learning Rate: 0.000368992
	LOSS [training: 0.013944098048274742 | validation: 0.020500463752246165]
	TIME [epoch: 72 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013986271074636061		[learning rate: 0.00036721]
	Learning Rate: 0.000367208
	LOSS [training: 0.013986271074636061 | validation: 0.021435628757050046]
	TIME [epoch: 72.1 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014545124100429614		[learning rate: 0.00036543]
	Learning Rate: 0.000365432
	LOSS [training: 0.014545124100429614 | validation: 0.02165345137996232]
	TIME [epoch: 72.1 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014830652122341104		[learning rate: 0.00036367]
	Learning Rate: 0.000363665
	LOSS [training: 0.014830652122341104 | validation: 0.021713590124453713]
	TIME [epoch: 72.1 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014221519934951474		[learning rate: 0.00036191]
	Learning Rate: 0.000361907
	LOSS [training: 0.014221519934951474 | validation: 0.021874082396487304]
	TIME [epoch: 72.1 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01485631863228603		[learning rate: 0.00036016]
	Learning Rate: 0.000360156
	LOSS [training: 0.01485631863228603 | validation: 0.02184231074770436]
	TIME [epoch: 72.1 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015337641969242477		[learning rate: 0.00035841]
	Learning Rate: 0.000358415
	LOSS [training: 0.015337641969242477 | validation: 0.022815812407247504]
	TIME [epoch: 72.1 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014640756534412144		[learning rate: 0.00035668]
	Learning Rate: 0.000356682
	LOSS [training: 0.014640756534412144 | validation: 0.021328021549164595]
	TIME [epoch: 72.2 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014268978041736435		[learning rate: 0.00035496]
	Learning Rate: 0.000354957
	LOSS [training: 0.014268978041736435 | validation: 0.02184218833194146]
	TIME [epoch: 72.1 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014315814039278965		[learning rate: 0.00035324]
	Learning Rate: 0.00035324
	LOSS [training: 0.014315814039278965 | validation: 0.02062227050548493]
	TIME [epoch: 72.1 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014511254294026216		[learning rate: 0.00035153]
	Learning Rate: 0.000351532
	LOSS [training: 0.014511254294026216 | validation: 0.02165702822699816]
	TIME [epoch: 72.1 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014475156386486434		[learning rate: 0.00034983]
	Learning Rate: 0.000349832
	LOSS [training: 0.014475156386486434 | validation: 0.021215366652620315]
	TIME [epoch: 72 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014128344168414941		[learning rate: 0.00034814]
	Learning Rate: 0.00034814
	LOSS [training: 0.014128344168414941 | validation: 0.021468035507521896]
	TIME [epoch: 72.1 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013714988099308387		[learning rate: 0.00034646]
	Learning Rate: 0.000346457
	LOSS [training: 0.013714988099308387 | validation: 0.022254031715670145]
	TIME [epoch: 72.1 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014874014784128342		[learning rate: 0.00034478]
	Learning Rate: 0.000344781
	LOSS [training: 0.014874014784128342 | validation: 0.022085376010857628]
	TIME [epoch: 72.1 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01500057752713871		[learning rate: 0.00034311]
	Learning Rate: 0.000343114
	LOSS [training: 0.01500057752713871 | validation: 0.021900664702005454]
	TIME [epoch: 72 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015142105247998585		[learning rate: 0.00034145]
	Learning Rate: 0.000341455
	LOSS [training: 0.015142105247998585 | validation: 0.023052254041989097]
	TIME [epoch: 72.1 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015287028462960324		[learning rate: 0.0003398]
	Learning Rate: 0.000339804
	LOSS [training: 0.015287028462960324 | validation: 0.022143075991985884]
	TIME [epoch: 72.1 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014812454836208947		[learning rate: 0.00033816]
	Learning Rate: 0.00033816
	LOSS [training: 0.014812454836208947 | validation: 0.022322595216205762]
	TIME [epoch: 72 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014311849259306344		[learning rate: 0.00033653]
	Learning Rate: 0.000336525
	LOSS [training: 0.014311849259306344 | validation: 0.02078853423293126]
	TIME [epoch: 72.1 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014315646594959009		[learning rate: 0.0003349]
	Learning Rate: 0.000334898
	LOSS [training: 0.014315646594959009 | validation: 0.02178632012198738]
	TIME [epoch: 72 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014205802335788172		[learning rate: 0.00033328]
	Learning Rate: 0.000333278
	LOSS [training: 0.014205802335788172 | validation: 0.021046823687354162]
	TIME [epoch: 72.2 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014230792243623098		[learning rate: 0.00033167]
	Learning Rate: 0.000331666
	LOSS [training: 0.014230792243623098 | validation: 0.021371512973453785]
	TIME [epoch: 72.1 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014235499306877253		[learning rate: 0.00033006]
	Learning Rate: 0.000330063
	LOSS [training: 0.014235499306877253 | validation: 0.021459424200897942]
	TIME [epoch: 72.1 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014675750025223734		[learning rate: 0.00032847]
	Learning Rate: 0.000328467
	LOSS [training: 0.014675750025223734 | validation: 0.022347467288104567]
	TIME [epoch: 72.1 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01435493861717036		[learning rate: 0.00032688]
	Learning Rate: 0.000326878
	LOSS [training: 0.01435493861717036 | validation: 0.02102385522891312]
	TIME [epoch: 72.1 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014060097647692246		[learning rate: 0.0003253]
	Learning Rate: 0.000325297
	LOSS [training: 0.014060097647692246 | validation: 0.02176427607350818]
	TIME [epoch: 72.1 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014347106670311388		[learning rate: 0.00032372]
	Learning Rate: 0.000323724
	LOSS [training: 0.014347106670311388 | validation: 0.02160526240466555]
	TIME [epoch: 72.1 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014621225391498077		[learning rate: 0.00032216]
	Learning Rate: 0.000322159
	LOSS [training: 0.014621225391498077 | validation: 0.02204676092813995]
	TIME [epoch: 72.1 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014531933284370252		[learning rate: 0.0003206]
	Learning Rate: 0.000320601
	LOSS [training: 0.014531933284370252 | validation: 0.02192958403744566]
	TIME [epoch: 72 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014357434924993473		[learning rate: 0.00031905]
	Learning Rate: 0.000319051
	LOSS [training: 0.014357434924993473 | validation: 0.02094168561814839]
	TIME [epoch: 72 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014547717559242737		[learning rate: 0.00031751]
	Learning Rate: 0.000317508
	LOSS [training: 0.014547717559242737 | validation: 0.021727509888753743]
	TIME [epoch: 72.1 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014346622239319845		[learning rate: 0.00031597]
	Learning Rate: 0.000315972
	LOSS [training: 0.014346622239319845 | validation: 0.02225698451854091]
	TIME [epoch: 72 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014493793986534442		[learning rate: 0.00031444]
	Learning Rate: 0.000314444
	LOSS [training: 0.014493793986534442 | validation: 0.02298337943966049]
	TIME [epoch: 72 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014488923344437389		[learning rate: 0.00031292]
	Learning Rate: 0.000312924
	LOSS [training: 0.014488923344437389 | validation: 0.021011395895089966]
	TIME [epoch: 72.1 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014082326731882693		[learning rate: 0.00031141]
	Learning Rate: 0.00031141
	LOSS [training: 0.014082326731882693 | validation: 0.021966325036793966]
	TIME [epoch: 72 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013559639679056696		[learning rate: 0.0003099]
	Learning Rate: 0.000309905
	LOSS [training: 0.013559639679056696 | validation: 0.021922572593621185]
	TIME [epoch: 72.1 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014022168392044787		[learning rate: 0.00030841]
	Learning Rate: 0.000308406
	LOSS [training: 0.014022168392044787 | validation: 0.021188388096080424]
	TIME [epoch: 72 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013920420050967962		[learning rate: 0.00030691]
	Learning Rate: 0.000306915
	LOSS [training: 0.013920420050967962 | validation: 0.021614389171269417]
	TIME [epoch: 72.1 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014183657050176449		[learning rate: 0.00030543]
	Learning Rate: 0.00030543
	LOSS [training: 0.014183657050176449 | validation: 0.02191372171411125]
	TIME [epoch: 72 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.013885416763973221		[learning rate: 0.00030395]
	Learning Rate: 0.000303953
	LOSS [training: 0.013885416763973221 | validation: 0.021062842360662165]
	TIME [epoch: 72.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151931/states/model_facs_dec1_v4_argset1_771.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 17702.792 seconds.
