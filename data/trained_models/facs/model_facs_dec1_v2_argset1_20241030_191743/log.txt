Args:
Namespace(name='model_facs_dec1_v2_argset1', outdir='out/model_training/model_facs_dec1_v2_argset1', training_data='data/facs/facs_dec1_v2/training', validation_data='data/facs/facs_dec1_v2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 628939704

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.802880150844575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.802880150844575 | validation: 1.1881359470248394]
	TIME [epoch: 32 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.117131887557122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.117131887557122 | validation: 0.9535860900619589]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.8572835535861597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8572835535861597 | validation: 0.7214944420667903]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.7724756087049847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7724756087049847 | validation: 0.7009868038982363]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5854254655955047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5854254655955047 | validation: 0.5206695858579031]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4877537961781531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4877537961781531 | validation: 0.49426904708321723]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4496641274849507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4496641274849507 | validation: 0.39013099157304676]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.38819943542275714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38819943542275714 | validation: 0.37105927819652396]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.36522972783376906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36522972783376906 | validation: 0.3104702602013437]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3215110172459285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3215110172459285 | validation: 0.3024064630481561]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32668582469902147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32668582469902147 | validation: 0.26124367724461345]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32250491621444793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32250491621444793 | validation: 0.25794573676240984]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29500799281945744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29500799281945744 | validation: 0.28010681563723316]
	TIME [epoch: 8.25 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.30944321647447987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30944321647447987 | validation: 0.25459924984121757]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2861317084009835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2861317084009835 | validation: 0.26396821965219214]
	TIME [epoch: 8.3 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2778968655982674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2778968655982674 | validation: 0.22420071189531932]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570963248658778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2570963248658778 | validation: 0.23257484433497705]
	TIME [epoch: 8.29 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28113375287327086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28113375287327086 | validation: 0.23504246711756505]
	TIME [epoch: 8.29 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25524613677648444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25524613677648444 | validation: 0.3492443656198897]
	TIME [epoch: 8.28 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28489323050744314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.28489323050744314 | validation: 0.20652435464233507]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25491809224414985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25491809224414985 | validation: 0.2724125096396383]
	TIME [epoch: 8.26 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.266653846867361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.266653846867361 | validation: 0.1971230761257191]
	TIME [epoch: 8.25 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23086182485972973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23086182485972973 | validation: 0.24245120471810325]
	TIME [epoch: 8.31 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2795892296881154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2795892296881154 | validation: 0.19596140813202853]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23280077768914628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23280077768914628 | validation: 0.1999487543312494]
	TIME [epoch: 8.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25945452115944884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25945452115944884 | validation: 0.19509177898781221]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23850917721354695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23850917721354695 | validation: 0.18472690878161976]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2315849648138577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2315849648138577 | validation: 0.18957168800461877]
	TIME [epoch: 8.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2333100745533568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2333100745533568 | validation: 0.16608050595154614]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22414270192803296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22414270192803296 | validation: 0.260445639569101]
	TIME [epoch: 8.28 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2277687844100843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2277687844100843 | validation: 0.19694693317833]
	TIME [epoch: 8.29 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22932357818608903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22932357818608903 | validation: 0.1705418088170627]
	TIME [epoch: 8.28 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21620690316738067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21620690316738067 | validation: 0.188394268291802]
	TIME [epoch: 8.28 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22112690287059225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22112690287059225 | validation: 0.17468044472040728]
	TIME [epoch: 8.26 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22836095912256726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22836095912256726 | validation: 0.1735094842077419]
	TIME [epoch: 8.29 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22114129453719766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22114129453719766 | validation: 0.1695250854044384]
	TIME [epoch: 8.26 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22315749791334985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22315749791334985 | validation: 0.16531405912382136]
	TIME [epoch: 8.28 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21170347091935718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21170347091935718 | validation: 0.1618687447690475]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21618502489825855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21618502489825855 | validation: 0.1856233337083773]
	TIME [epoch: 8.26 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2123162477856713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2123162477856713 | validation: 0.16828580301128793]
	TIME [epoch: 8.26 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22278470236968162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22278470236968162 | validation: 0.1954596469207695]
	TIME [epoch: 8.29 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25090394654338266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25090394654338266 | validation: 0.17976036001088394]
	TIME [epoch: 8.27 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2067326116334911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2067326116334911 | validation: 0.16004859862850226]
	TIME [epoch: 8.27 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21189047399917627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21189047399917627 | validation: 0.2247762548348025]
	TIME [epoch: 8.28 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2260824070953427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2260824070953427 | validation: 0.1671129056853623]
	TIME [epoch: 8.25 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20558620362766244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20558620362766244 | validation: 0.16414313947685294]
	TIME [epoch: 8.24 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22533950359567512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22533950359567512 | validation: 0.16280917470985834]
	TIME [epoch: 8.26 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22744847248777525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22744847248777525 | validation: 0.16219345377848934]
	TIME [epoch: 8.23 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21961677700090912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21961677700090912 | validation: 0.25009110806979534]
	TIME [epoch: 8.25 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22366341576374474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22366341576374474 | validation: 0.15328918616047468]
	TIME [epoch: 8.26 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21326344557142393		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.21326344557142393 | validation: 0.16328022937197706]
	TIME [epoch: 38.5 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22595243734494433		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.22595243734494433 | validation: 0.15542139656052395]
	TIME [epoch: 15.8 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21829428925332525		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.21829428925332525 | validation: 0.15370101719604312]
	TIME [epoch: 15.8 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21094289052431167		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.21094289052431167 | validation: 0.18417055938634735]
	TIME [epoch: 15.8 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23190240508268656		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.23190240508268656 | validation: 0.16955056695991572]
	TIME [epoch: 15.8 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2146712758053929		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.2146712758053929 | validation: 0.15722807442203104]
	TIME [epoch: 15.8 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21088604918498385		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.21088604918498385 | validation: 0.205225919159059]
	TIME [epoch: 15.8 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21075033232472984		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.21075033232472984 | validation: 0.16679334705459614]
	TIME [epoch: 15.8 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20552274468110018		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.20552274468110018 | validation: 0.16610532083042634]
	TIME [epoch: 15.8 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2194749589253766		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.2194749589253766 | validation: 0.18159980357731326]
	TIME [epoch: 15.8 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21962221757420375		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.21962221757420375 | validation: 0.15578554313479537]
	TIME [epoch: 15.8 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21389728194275104		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.21389728194275104 | validation: 0.21287316015237936]
	TIME [epoch: 15.8 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2124482667673767		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.2124482667673767 | validation: 0.15539221846268186]
	TIME [epoch: 15.8 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20693363109095977		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.20693363109095977 | validation: 0.1544034966734616]
	TIME [epoch: 15.8 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21139958390396055		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.21139958390396055 | validation: 0.1685063066429657]
	TIME [epoch: 15.8 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2158924829089455		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.2158924829089455 | validation: 0.16399423775137845]
	TIME [epoch: 15.8 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20840171446180653		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.20840171446180653 | validation: 0.1630962298931871]
	TIME [epoch: 15.8 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2099207295275105		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.2099207295275105 | validation: 0.167101011153075]
	TIME [epoch: 15.8 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2107084930137468		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.2107084930137468 | validation: 0.18100052449319143]
	TIME [epoch: 15.8 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21178119967676445		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.21178119967676445 | validation: 0.14928956742779684]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20325889766676516		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.20325889766676516 | validation: 0.16554486525354734]
	TIME [epoch: 15.8 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20521560525268498		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.20521560525268498 | validation: 0.18980620985453828]
	TIME [epoch: 15.8 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2020335324039103		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.2020335324039103 | validation: 0.14862072372748392]
	TIME [epoch: 15.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20039179372895136		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.20039179372895136 | validation: 0.1613436853509982]
	TIME [epoch: 15.8 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20615184041111104		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.20615184041111104 | validation: 0.15305743949469433]
	TIME [epoch: 15.8 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20136421474919422		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.20136421474919422 | validation: 0.1464631758227728]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20653158985372475		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.20653158985372475 | validation: 0.15708557947439827]
	TIME [epoch: 15.8 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20006563571094085		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.20006563571094085 | validation: 0.1563157664372163]
	TIME [epoch: 15.8 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2091827459366343		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.2091827459366343 | validation: 0.17948434633364121]
	TIME [epoch: 15.7 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19478908422172747		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.19478908422172747 | validation: 0.14799143144558197]
	TIME [epoch: 15.8 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20516974164978652		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.20516974164978652 | validation: 0.15065133064691824]
	TIME [epoch: 15.8 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19000157866266965		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.19000157866266965 | validation: 0.15504325223947196]
	TIME [epoch: 15.8 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20824238439608447		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.20824238439608447 | validation: 0.15173915445489344]
	TIME [epoch: 15.8 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19993685348307533		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.19993685348307533 | validation: 0.15073391133040864]
	TIME [epoch: 15.8 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1991253249086851		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.1991253249086851 | validation: 0.15084115069178297]
	TIME [epoch: 15.8 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20121089305107487		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.20121089305107487 | validation: 0.1509117608426646]
	TIME [epoch: 15.8 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21029776021536528		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.21029776021536528 | validation: 0.1451001518026973]
	TIME [epoch: 15.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19677266400402824		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.19677266400402824 | validation: 0.16839378295465393]
	TIME [epoch: 15.8 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19723734673633328		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.19723734673633328 | validation: 0.15296329021932242]
	TIME [epoch: 15.8 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19065878694197502		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.19065878694197502 | validation: 0.15045793125663592]
	TIME [epoch: 15.8 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1996632800667469		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.1996632800667469 | validation: 0.1443463490927029]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19721328757922543		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.19721328757922543 | validation: 0.1462468200110299]
	TIME [epoch: 15.8 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19595205352768086		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.19595205352768086 | validation: 0.14402708477417572]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_93.pth
	Model improved!!!
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19954571777576943		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.19954571777576943 | validation: 0.14330207025798855]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1978797695805072		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.1978797695805072 | validation: 0.15414650359255938]
	TIME [epoch: 15.8 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1910146820923154		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.1910146820923154 | validation: 0.15419974414292273]
	TIME [epoch: 15.8 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18925377497648654		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.18925377497648654 | validation: 0.1531698349458639]
	TIME [epoch: 15.8 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19313847981333535		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.19313847981333535 | validation: 0.1437104857399066]
	TIME [epoch: 15.8 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2020118588040828		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.2020118588040828 | validation: 0.16722255844817027]
	TIME [epoch: 15.8 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20110595615476853		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.20110595615476853 | validation: 0.14107570048505721]
	TIME [epoch: 15.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_100.pth
	Model improved!!!
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19654068122028026		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.19654068122028026 | validation: 0.14218681286540927]
	TIME [epoch: 55.7 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18653865587270987		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.18653865587270987 | validation: 0.15803449426493063]
	TIME [epoch: 33 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18976830978759962		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.18976830978759962 | validation: 0.1411177924476535]
	TIME [epoch: 33 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2023722112284274		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.2023722112284274 | validation: 0.1399129075248251]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18813499552736843		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.18813499552736843 | validation: 0.14888766678885842]
	TIME [epoch: 33 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1954642358005143		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.1954642358005143 | validation: 0.14474026280289368]
	TIME [epoch: 33 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18704046547342804		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.18704046547342804 | validation: 0.14550510114805024]
	TIME [epoch: 33 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19292008397535718		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.19292008397535718 | validation: 0.14835248792164607]
	TIME [epoch: 33 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1902629592242947		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.1902629592242947 | validation: 0.13627680665732916]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18216082650981147		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.18216082650981147 | validation: 0.15087850154568383]
	TIME [epoch: 33 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18861589759614764		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.18861589759614764 | validation: 0.13574468094940556]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18517943690072733		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.18517943690072733 | validation: 0.1480492694933044]
	TIME [epoch: 33 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19615120159410374		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.19615120159410374 | validation: 0.1330862515696985]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_113.pth
	Model improved!!!
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18677765336068017		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.18677765336068017 | validation: 0.13466595423734234]
	TIME [epoch: 33 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1849776325629193		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.1849776325629193 | validation: 0.13909847318287183]
	TIME [epoch: 33 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18141846061716907		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.18141846061716907 | validation: 0.14823750939524458]
	TIME [epoch: 33 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18255040987987692		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.18255040987987692 | validation: 0.1344632405550905]
	TIME [epoch: 33 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18427664308322567		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.18427664308322567 | validation: 0.1523715981156815]
	TIME [epoch: 33 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18771155377753634		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.18771155377753634 | validation: 0.13747686682133237]
	TIME [epoch: 33 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18274224425236804		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.18274224425236804 | validation: 0.13576554302751562]
	TIME [epoch: 33 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18234596814683324		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.18234596814683324 | validation: 0.13015338482027597]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18315916989868797		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.18315916989868797 | validation: 0.13648137301495664]
	TIME [epoch: 33 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18046464768696904		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.18046464768696904 | validation: 0.14235970027966227]
	TIME [epoch: 33 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18978308994603066		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.18978308994603066 | validation: 0.1272391998586393]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_124.pth
	Model improved!!!
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17845915214542116		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.17845915214542116 | validation: 0.13119717526060348]
	TIME [epoch: 33 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17759084656944177		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.17759084656944177 | validation: 0.13420930565116027]
	TIME [epoch: 33 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18238226948202718		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.18238226948202718 | validation: 0.14289761450060648]
	TIME [epoch: 33 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18020253550288676		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.18020253550288676 | validation: 0.1419968321969656]
	TIME [epoch: 33 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17997147089359375		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.17997147089359375 | validation: 0.14147938251109857]
	TIME [epoch: 33 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18240668696006812		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.18240668696006812 | validation: 0.1302539551815523]
	TIME [epoch: 33 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17566621656474146		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.17566621656474146 | validation: 0.12797971667310806]
	TIME [epoch: 33 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17682058893548738		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.17682058893548738 | validation: 0.15432713039323892]
	TIME [epoch: 33 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17886509976183762		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.17886509976183762 | validation: 0.1315645588117397]
	TIME [epoch: 33 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17018101904430247		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.17018101904430247 | validation: 0.12750512916278073]
	TIME [epoch: 33 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1793888780490237		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.1793888780490237 | validation: 0.13153286644974335]
	TIME [epoch: 33 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17565791997310023		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.17565791997310023 | validation: 0.13009846569336064]
	TIME [epoch: 33 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1740312656510813		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.1740312656510813 | validation: 0.12568500731823037]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_137.pth
	Model improved!!!
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17113959828305284		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.17113959828305284 | validation: 0.13838517333044703]
	TIME [epoch: 33.2 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1726218637381287		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.1726218637381287 | validation: 0.12710366507855123]
	TIME [epoch: 33.1 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1700249138275596		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.1700249138275596 | validation: 0.13217698752486262]
	TIME [epoch: 33 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18347868453117613		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.18347868453117613 | validation: 0.1317053270025566]
	TIME [epoch: 33 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16805822303730275		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.16805822303730275 | validation: 0.13750995667833826]
	TIME [epoch: 33 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16584857922697102		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.16584857922697102 | validation: 0.13105760234107172]
	TIME [epoch: 33 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16563977275310796		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.16563977275310796 | validation: 0.12182546534725609]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_144.pth
	Model improved!!!
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1711763180681389		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.1711763180681389 | validation: 0.13263015993579233]
	TIME [epoch: 33 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1706244435218902		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.1706244435218902 | validation: 0.12941349911133299]
	TIME [epoch: 33.1 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17429570485064713		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.17429570485064713 | validation: 0.1192591687228157]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_147.pth
	Model improved!!!
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16803187047613402		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.16803187047613402 | validation: 0.12728552190000766]
	TIME [epoch: 33 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17123732089906166		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.17123732089906166 | validation: 0.14222488206223535]
	TIME [epoch: 33 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17777816130450505		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.17777816130450505 | validation: 0.11955755392774299]
	TIME [epoch: 33 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16649246105925683		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.16649246105925683 | validation: 0.12971880311492276]
	TIME [epoch: 33 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16528051574345695		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.16528051574345695 | validation: 0.12420223948589673]
	TIME [epoch: 33 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17013830310025865		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.17013830310025865 | validation: 0.12300944368614655]
	TIME [epoch: 33 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17524019513596942		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.17524019513596942 | validation: 0.12184401068157964]
	TIME [epoch: 33 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16765646317653446		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.16765646317653446 | validation: 0.12313286127875352]
	TIME [epoch: 33 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15897595645230522		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.15897595645230522 | validation: 0.12075039597131898]
	TIME [epoch: 33 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16419448134777662		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.16419448134777662 | validation: 0.1644357773686947]
	TIME [epoch: 33 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1688343106883072		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.1688343106883072 | validation: 0.11803612331139983]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_158.pth
	Model improved!!!
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16211982685502394		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.16211982685502394 | validation: 0.12017551284922164]
	TIME [epoch: 33 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16202010257622176		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.16202010257622176 | validation: 0.12174627945507008]
	TIME [epoch: 33 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16331360446710205		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.16331360446710205 | validation: 0.11727268260843574]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15924992229476448		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.15924992229476448 | validation: 0.11557279546310265]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_162.pth
	Model improved!!!
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17343612740479342		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.17343612740479342 | validation: 0.11924458261621829]
	TIME [epoch: 33 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15861209117445707		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.15861209117445707 | validation: 0.12679596062721865]
	TIME [epoch: 33 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1610745916736834		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.1610745916736834 | validation: 0.11763375375356218]
	TIME [epoch: 33 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16920528306301186		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.16920528306301186 | validation: 0.11750070453758528]
	TIME [epoch: 33 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1591312558458798		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.1591312558458798 | validation: 0.12211876537648007]
	TIME [epoch: 33 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15925470568415506		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.15925470568415506 | validation: 0.12683481851625153]
	TIME [epoch: 33 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15484236854854508		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.15484236854854508 | validation: 0.12004843789982103]
	TIME [epoch: 33 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15541614870965137		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.15541614870965137 | validation: 0.1307142137654016]
	TIME [epoch: 33 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.163556412138674		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.163556412138674 | validation: 0.12072291581552994]
	TIME [epoch: 33 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15487908486656052		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.15487908486656052 | validation: 0.11722409443438]
	TIME [epoch: 33 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15600801876275286		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.15600801876275286 | validation: 0.12987829570614667]
	TIME [epoch: 33 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16186642380711527		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.16186642380711527 | validation: 0.11603229826019698]
	TIME [epoch: 33 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16064656931288485		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.16064656931288485 | validation: 0.12449481567500756]
	TIME [epoch: 33 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15680656010110602		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.15680656010110602 | validation: 0.12147071154132291]
	TIME [epoch: 33 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15574635699130215		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.15574635699130215 | validation: 0.1143748423038525]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_177.pth
	Model improved!!!
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15168916202459592		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.15168916202459592 | validation: 0.1283984865971015]
	TIME [epoch: 33.1 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16025269128637984		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.16025269128637984 | validation: 0.12346940178298335]
	TIME [epoch: 33.1 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16051098914891213		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.16051098914891213 | validation: 0.11812263513221047]
	TIME [epoch: 33.1 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1548827425621063		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.1548827425621063 | validation: 0.12340319790379581]
	TIME [epoch: 33.1 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15599870012687436		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.15599870012687436 | validation: 0.12608569488024363]
	TIME [epoch: 33.2 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1524405582257759		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.1524405582257759 | validation: 0.1165863756951625]
	TIME [epoch: 33.1 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14879305252996977		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.14879305252996977 | validation: 0.12143513481587384]
	TIME [epoch: 33.1 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15283715708625623		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.15283715708625623 | validation: 0.1325322541042769]
	TIME [epoch: 33.1 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15075582337294613		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.15075582337294613 | validation: 0.11217822302013876]
	TIME [epoch: 33.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1492913144252124		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.1492913144252124 | validation: 0.11558551905627738]
	TIME [epoch: 33.1 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1479978310307594		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.1479978310307594 | validation: 0.1110489207244387]
	TIME [epoch: 33.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15631524775827588		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.15631524775827588 | validation: 0.1094473947019603]
	TIME [epoch: 33 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14727675319892988		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.14727675319892988 | validation: 0.11682214944997386]
	TIME [epoch: 33.2 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1481022352573718		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.1481022352573718 | validation: 0.11082077376333584]
	TIME [epoch: 33 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1529268037059118		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.1529268037059118 | validation: 0.1115039179627714]
	TIME [epoch: 33 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1423516422181594		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.1423516422181594 | validation: 0.11112715553786046]
	TIME [epoch: 33 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14548916379461016		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.14548916379461016 | validation: 0.11346492265534927]
	TIME [epoch: 33 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14881689836464237		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.14881689836464237 | validation: 0.1214305298831921]
	TIME [epoch: 33 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15053411267165628		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.15053411267165628 | validation: 0.11065081354386816]
	TIME [epoch: 33 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14432718199841973		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.14432718199841973 | validation: 0.11115860691090725]
	TIME [epoch: 33 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.145180602065919		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.145180602065919 | validation: 0.11890141267764509]
	TIME [epoch: 33 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15329926716572936		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.15329926716572936 | validation: 0.11559119054001124]
	TIME [epoch: 33 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14516074130902737		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.14516074130902737 | validation: 0.1149769016522697]
	TIME [epoch: 33 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14908715923803464		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.14908715923803464 | validation: 0.11505620854204582]
	TIME [epoch: 91.8 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14347711871378951		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.14347711871378951 | validation: 0.11411845375272929]
	TIME [epoch: 69.5 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1474806809712663		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.1474806809712663 | validation: 0.11357228157830827]
	TIME [epoch: 69.4 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14698389645212664		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.14698389645212664 | validation: 0.11436523287753778]
	TIME [epoch: 69.4 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14599713613134013		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.14599713613134013 | validation: 0.12144393384613958]
	TIME [epoch: 69.4 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14424515844540323		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.14424515844540323 | validation: 0.11681570502874232]
	TIME [epoch: 69.4 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14524351763883903		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.14524351763883903 | validation: 0.10980637957741295]
	TIME [epoch: 69.4 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14389141630879745		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.14389141630879745 | validation: 0.11265081566331756]
	TIME [epoch: 69.4 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14431805643441942		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.14431805643441942 | validation: 0.11351513596289457]
	TIME [epoch: 69.4 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.143715885283956		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.143715885283956 | validation: 0.12606139900702745]
	TIME [epoch: 69.4 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14146757441504032		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.14146757441504032 | validation: 0.11422456120133]
	TIME [epoch: 69.4 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14266261365420294		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.14266261365420294 | validation: 0.12266645201882712]
	TIME [epoch: 69.4 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14584389195901848		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.14584389195901848 | validation: 0.11515446804182403]
	TIME [epoch: 69.4 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14245074185631326		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.14245074185631326 | validation: 0.11029756428408452]
	TIME [epoch: 69.4 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14152438119496114		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.14152438119496114 | validation: 0.10955188166844887]
	TIME [epoch: 69.4 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14429324792835055		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.14429324792835055 | validation: 0.11301767509847704]
	TIME [epoch: 69.4 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14350666826083774		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.14350666826083774 | validation: 0.1120266776790532]
	TIME [epoch: 69.4 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1435323732908069		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.1435323732908069 | validation: 0.11475697851852087]
	TIME [epoch: 69.5 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14261019766023583		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.14261019766023583 | validation: 0.11269345040889271]
	TIME [epoch: 69.4 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14405580241373606		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.14405580241373606 | validation: 0.11105897815127119]
	TIME [epoch: 69.4 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14614993482299304		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.14614993482299304 | validation: 0.11121187812808886]
	TIME [epoch: 69.4 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14662292608901328		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.14662292608901328 | validation: 0.11278631506903485]
	TIME [epoch: 69.4 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1472002455421982		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.1472002455421982 | validation: 0.11644976530171372]
	TIME [epoch: 69.4 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14521086407249748		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.14521086407249748 | validation: 0.11782046039051182]
	TIME [epoch: 69.4 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14353448783095424		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.14353448783095424 | validation: 0.11391859728558948]
	TIME [epoch: 69.4 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14129252691291802		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.14129252691291802 | validation: 0.11418857752377023]
	TIME [epoch: 69.5 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14296861477548628		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.14296861477548628 | validation: 0.10881467087595893]
	TIME [epoch: 69.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_227.pth
	Model improved!!!
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14483969625128487		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.14483969625128487 | validation: 0.11974453038097432]
	TIME [epoch: 69.4 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14291187214665496		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.14291187214665496 | validation: 0.11166126683195172]
	TIME [epoch: 69.4 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14108120563400528		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.14108120563400528 | validation: 0.10881578487655832]
	TIME [epoch: 69.4 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14256059813642438		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.14256059813642438 | validation: 0.1268318181523235]
	TIME [epoch: 69.4 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14419783308209044		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.14419783308209044 | validation: 0.12211503304895069]
	TIME [epoch: 69.4 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14283770268403137		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.14283770268403137 | validation: 0.11760499943751923]
	TIME [epoch: 69.4 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14356482469692347		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.14356482469692347 | validation: 0.11537301739417702]
	TIME [epoch: 69.4 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14192424880021673		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.14192424880021673 | validation: 0.11135593497610616]
	TIME [epoch: 69.4 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14250201934244625		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.14250201934244625 | validation: 0.11435034600681981]
	TIME [epoch: 69.4 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1409531184083273		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1409531184083273 | validation: 0.11244428987808981]
	TIME [epoch: 69.4 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1397505167189523		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.1397505167189523 | validation: 0.1188937031707511]
	TIME [epoch: 69.5 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15057921740934366		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.15057921740934366 | validation: 0.11298407688630759]
	TIME [epoch: 69.4 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13707317760415771		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.13707317760415771 | validation: 0.11125574879852143]
	TIME [epoch: 69.4 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1415251850100507		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.1415251850100507 | validation: 0.11180729444298446]
	TIME [epoch: 69.4 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14021334751186101		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.14021334751186101 | validation: 0.11674298436266643]
	TIME [epoch: 69.4 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14250878174857953		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.14250878174857953 | validation: 0.11271235973191762]
	TIME [epoch: 69.4 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14469069330495501		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.14469069330495501 | validation: 0.11280736027444567]
	TIME [epoch: 69.4 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1377203226270934		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.1377203226270934 | validation: 0.11741090463188102]
	TIME [epoch: 69.4 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14065663425673516		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.14065663425673516 | validation: 0.11285918507192005]
	TIME [epoch: 69.4 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14437193048180305		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.14437193048180305 | validation: 0.11425583283556591]
	TIME [epoch: 69.4 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14151797441652067		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.14151797441652067 | validation: 0.11098836739416806]
	TIME [epoch: 69.4 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14095930465802609		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.14095930465802609 | validation: 0.11115710302259399]
	TIME [epoch: 69.4 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14053096130495554		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.14053096130495554 | validation: 0.11337813350742694]
	TIME [epoch: 69.4 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14210014597544993		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.14210014597544993 | validation: 0.11996030647264715]
	TIME [epoch: 69.4 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14286425083749482		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.14286425083749482 | validation: 0.11539286763560583]
	TIME [epoch: 69.5 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14079862811548635		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.14079862811548635 | validation: 0.11736858692937926]
	TIME [epoch: 69.5 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13829912877434566		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.13829912877434566 | validation: 0.11276628807048736]
	TIME [epoch: 69.4 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14136938473788277		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.14136938473788277 | validation: 0.11024879619360506]
	TIME [epoch: 69.5 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13714655608798013		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.13714655608798013 | validation: 0.11602309054631596]
	TIME [epoch: 69.4 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13669059403085912		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.13669059403085912 | validation: 0.11464311851162705]
	TIME [epoch: 69.4 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13911886277196714		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.13911886277196714 | validation: 0.12032323071376065]
	TIME [epoch: 69.4 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13898406602265315		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.13898406602265315 | validation: 0.11751141504982623]
	TIME [epoch: 69.4 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14584016822975865		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.14584016822975865 | validation: 0.11390400503203882]
	TIME [epoch: 69.4 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14061105142186756		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.14061105142186756 | validation: 0.11044104719996176]
	TIME [epoch: 69.4 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13995802733134646		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.13995802733134646 | validation: 0.10953681394382134]
	TIME [epoch: 69.4 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14214671232751086		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.14214671232751086 | validation: 0.12234839989090167]
	TIME [epoch: 69.5 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1381206203248422		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.1381206203248422 | validation: 0.11250380488486877]
	TIME [epoch: 69.4 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13947297595132585		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.13947297595132585 | validation: 0.11342766815721453]
	TIME [epoch: 69.4 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13785477357885303		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.13785477357885303 | validation: 0.11799303918460158]
	TIME [epoch: 69.4 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14242832380326245		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.14242832380326245 | validation: 0.11207783234911006]
	TIME [epoch: 69.4 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14248997055425427		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.14248997055425427 | validation: 0.10859386271733125]
	TIME [epoch: 69.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset1_20241030_191743/states/model_facs_dec1_v2_argset1_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1386647707816962		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.1386647707816962 | validation: 0.1132095318681808]
	TIME [epoch: 69.4 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14162256787607042		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.14162256787607042 | validation: 0.11269196565540036]
	TIME [epoch: 69.4 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1410063622636831		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.1410063622636831 | validation: 0.11001005581551071]
	TIME [epoch: 69.4 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13857858701490108		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.13857858701490108 | validation: 0.11104495180463107]
	TIME [epoch: 69.4 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14514047106703085		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.14514047106703085 | validation: 0.11422528946260364]
	TIME [epoch: 69.4 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13986661183190005		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.13986661183190005 | validation: 0.11251037121014931]
	TIME [epoch: 69.4 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13971902036456468		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.13971902036456468 | validation: 0.1119560879227112]
	TIME [epoch: 69.4 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1396132582630741		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.1396132582630741 | validation: 0.11108971435726718]
	TIME [epoch: 69.4 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14127209224438272		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.14127209224438272 | validation: 0.11261255259929463]
	TIME [epoch: 69.4 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1386398390575068		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.1386398390575068 | validation: 0.12144727824379728]
	TIME [epoch: 69.4 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14206584337039999		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.14206584337039999 | validation: 0.11327122308597608]
	TIME [epoch: 69.4 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14018136955163915		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.14018136955163915 | validation: 0.11438025416820548]
	TIME [epoch: 69.4 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13820513115326483		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.13820513115326483 | validation: 0.11687792935916738]
	TIME [epoch: 69.4 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14006271588753383		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.14006271588753383 | validation: 0.11276901218046786]
	TIME [epoch: 69.4 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14088466596880792		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.14088466596880792 | validation: 0.11455062871529123]
	TIME [epoch: 69.4 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1418621997129268		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.1418621997129268 | validation: 0.11343691232118025]
	TIME [epoch: 69.4 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1389866663133883		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.1389866663133883 | validation: 0.11182843008138157]
	TIME [epoch: 69.4 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1384563881844756		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.1384563881844756 | validation: 0.11005503216627413]
	TIME [epoch: 69.4 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1418480525844402		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.1418480525844402 | validation: 0.11318321339334739]
	TIME [epoch: 69.4 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13678669514021422		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.13678669514021422 | validation: 0.1124126372912535]
	TIME [epoch: 69.4 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14173314377727209		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.14173314377727209 | validation: 0.11204802136396937]
	TIME [epoch: 69.4 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13892784083585694		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.13892784083585694 | validation: 0.11241032487521112]
	TIME [epoch: 69.4 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1422262439194982		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.1422262439194982 | validation: 0.1146332186811824]
	TIME [epoch: 69.4 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1362602216958142		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.1362602216958142 | validation: 0.11420005136575498]
	TIME [epoch: 69.4 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13829885806789743		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.13829885806789743 | validation: 0.11559068767584976]
	TIME [epoch: 69.4 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1378752977893482		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.1378752977893482 | validation: 0.11271663499060973]
	TIME [epoch: 69.4 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14112826906531725		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.14112826906531725 | validation: 0.11685786675385243]
	TIME [epoch: 69.4 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14253086057480088		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.14253086057480088 | validation: 0.11331786570128097]
	TIME [epoch: 69.4 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13910048424748803		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.13910048424748803 | validation: 0.11385505645908334]
	TIME [epoch: 69.4 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1385743796128861		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.1385743796128861 | validation: 0.11409888636577818]
	TIME [epoch: 69.4 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13832763304608922		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.13832763304608922 | validation: 0.11153702346654318]
	TIME [epoch: 69.4 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1409723551719284		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.1409723551719284 | validation: 0.11198140780747252]
	TIME [epoch: 69.4 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1375039806825152		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.1375039806825152 | validation: 0.1172155803128416]
	TIME [epoch: 164 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13987969334650605		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.13987969334650605 | validation: 0.11031547795922991]
	TIME [epoch: 142 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13923658731165509		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.13923658731165509 | validation: 0.11291235976439959]
	TIME [epoch: 142 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1404933717296687		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.1404933717296687 | validation: 0.11512068400231698]
	TIME [epoch: 142 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13854722551258272		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.13854722551258272 | validation: 0.11662909764466631]
	TIME [epoch: 142 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1371396897637008		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.1371396897637008 | validation: 0.11083367536451454]
	TIME [epoch: 142 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13877152852924682		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.13877152852924682 | validation: 0.11797826294510685]
	TIME [epoch: 142 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14399908649520282		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.14399908649520282 | validation: 0.1118455455246147]
	TIME [epoch: 142 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13904835681902156		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.13904835681902156 | validation: 0.11480874622895579]
	TIME [epoch: 142 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1394226703616963		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.1394226703616963 | validation: 0.11007834656655895]
	TIME [epoch: 142 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14033653295134602		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.14033653295134602 | validation: 0.11039179453641687]
	TIME [epoch: 142 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14110900907972454		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.14110900907972454 | validation: 0.11145805234757152]
	TIME [epoch: 142 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13892363069141142		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.13892363069141142 | validation: 0.11139678144992746]
	TIME [epoch: 142 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1372889022136224		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.1372889022136224 | validation: 0.1174082803270566]
	TIME [epoch: 142 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14147246095067142		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.14147246095067142 | validation: 0.11324754809544116]
	TIME [epoch: 142 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13804380539496516		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.13804380539496516 | validation: 0.11218613138548564]
	TIME [epoch: 142 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14037488999525352		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.14037488999525352 | validation: 0.11120836530056885]
	TIME [epoch: 142 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13646969344728554		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.13646969344728554 | validation: 0.11087202357276478]
	TIME [epoch: 142 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13854502059132387		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.13854502059132387 | validation: 0.11776699000403767]
	TIME [epoch: 142 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14022966249679145		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.14022966249679145 | validation: 0.1112364406756557]
	TIME [epoch: 142 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1403222879082542		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.1403222879082542 | validation: 0.11468478293064295]
	TIME [epoch: 142 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13875034328984126		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.13875034328984126 | validation: 0.11389124016976597]
	TIME [epoch: 142 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13723755015805797		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.13723755015805797 | validation: 0.11050799638721118]
	TIME [epoch: 142 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13502593845320104		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.13502593845320104 | validation: 0.11330085503538016]
	TIME [epoch: 142 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13704142793880164		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.13704142793880164 | validation: 0.11091007124076199]
	TIME [epoch: 142 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13703092552922383		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.13703092552922383 | validation: 0.11531838654134237]
	TIME [epoch: 142 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13837068938277708		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.13837068938277708 | validation: 0.11305618049660153]
	TIME [epoch: 142 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13732235091529219		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.13732235091529219 | validation: 0.114480550145269]
	TIME [epoch: 142 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13837042131595187		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.13837042131595187 | validation: 0.11003386020181469]
	TIME [epoch: 142 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13598981029364696		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.13598981029364696 | validation: 0.11504815588715686]
	TIME [epoch: 142 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13754698263457188		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.13754698263457188 | validation: 0.1161709214515512]
	TIME [epoch: 142 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13999596743391532		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.13999596743391532 | validation: 0.11796313503848435]
	TIME [epoch: 142 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1386202346995676		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.1386202346995676 | validation: 0.1138944526446484]
	TIME [epoch: 142 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13875823523437422		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.13875823523437422 | validation: 0.11041723998323705]
	TIME [epoch: 142 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1408652704156879		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.1408652704156879 | validation: 0.11461057827073895]
	TIME [epoch: 142 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1368913402813682		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.1368913402813682 | validation: 0.11221258216666233]
	TIME [epoch: 142 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14145074815528805		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.14145074815528805 | validation: 0.11124394517111405]
	TIME [epoch: 142 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13655838414005336		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.13655838414005336 | validation: 0.11245470978390956]
	TIME [epoch: 142 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1364132773860723		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.1364132773860723 | validation: 0.11414235363485666]
	TIME [epoch: 142 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13838693650287803		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.13838693650287803 | validation: 0.11202144350272117]
	TIME [epoch: 142 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1380670749935933		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.1380670749935933 | validation: 0.11424317493439651]
	TIME [epoch: 142 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1385635836666724		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.1385635836666724 | validation: 0.11189912383673936]
	TIME [epoch: 142 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13692185230223358		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.13692185230223358 | validation: 0.1161525678205155]
	TIME [epoch: 142 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13838984516762223		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.13838984516762223 | validation: 0.11266709703579258]
	TIME [epoch: 142 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13847276326252675		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.13847276326252675 | validation: 0.11086938801532367]
	TIME [epoch: 142 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1415318768692767		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.1415318768692767 | validation: 0.11066645579465725]
	TIME [epoch: 142 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13918313877871982		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.13918313877871982 | validation: 0.1133521673238834]
	TIME [epoch: 142 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13729687908622584		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.13729687908622584 | validation: 0.11070406367916363]
	TIME [epoch: 142 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13899693203121447		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.13899693203121447 | validation: 0.11532929742132123]
	TIME [epoch: 142 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13751115679258255		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.13751115679258255 | validation: 0.1115053816574906]
	TIME [epoch: 142 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13750460307534648		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.13750460307534648 | validation: 0.11559612484788992]
	TIME [epoch: 142 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13933259999277567		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.13933259999277567 | validation: 0.11232908984184627]
	TIME [epoch: 142 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13951816589177524		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.13951816589177524 | validation: 0.11306378024482458]
	TIME [epoch: 142 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14034283239670411		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.14034283239670411 | validation: 0.11096707483934079]
	TIME [epoch: 142 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1376520150471945		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.1376520150471945 | validation: 0.1115909604247407]
	TIME [epoch: 142 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13721616837966846		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.13721616837966846 | validation: 0.11350070596766622]
	TIME [epoch: 142 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13887972041156443		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.13887972041156443 | validation: 0.11132624364607654]
	TIME [epoch: 142 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1375209349846446		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.1375209349846446 | validation: 0.11523377190263355]
	TIME [epoch: 142 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13820654296090157		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.13820654296090157 | validation: 0.11199169347869356]
	TIME [epoch: 142 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13992677772550008		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.13992677772550008 | validation: 0.111023921826926]
	TIME [epoch: 142 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13719176890883256		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.13719176890883256 | validation: 0.11296478689708281]
	TIME [epoch: 142 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1344843065010766		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.1344843065010766 | validation: 0.11090790207127157]
	TIME [epoch: 142 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1366278199214491		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.1366278199214491 | validation: 0.1109593082029329]
	TIME [epoch: 142 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1378028797059595		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.1378028797059595 | validation: 0.11214522494476749]
	TIME [epoch: 142 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13782991068137537		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.13782991068137537 | validation: 0.11598216394221442]
	TIME [epoch: 142 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13753589476794767		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.13753589476794767 | validation: 0.11198867095282361]
	TIME [epoch: 142 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1359957046973308		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.1359957046973308 | validation: 0.11313884162981813]
	TIME [epoch: 142 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13898903842032392		[learning rate: 0.00099155]
	Learning Rate: 0.000991553
	LOSS [training: 0.13898903842032392 | validation: 0.11309435075269733]
	TIME [epoch: 142 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13630844871555264		[learning rate: 0.00098437]
	Learning Rate: 0.000984369
	LOSS [training: 0.13630844871555264 | validation: 0.11190340121294189]
	TIME [epoch: 142 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13719842932833257		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.13719842932833257 | validation: 0.11335668893894327]
	TIME [epoch: 142 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13977988540929712		[learning rate: 0.00097016]
	Learning Rate: 0.000970157
	LOSS [training: 0.13977988540929712 | validation: 0.11079198273190957]
	TIME [epoch: 142 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13631680341000246		[learning rate: 0.00096313]
	Learning Rate: 0.000963128
	LOSS [training: 0.13631680341000246 | validation: 0.11108379643699129]
	TIME [epoch: 142 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1351849317780132		[learning rate: 0.00095615]
	Learning Rate: 0.00095615
	LOSS [training: 0.1351849317780132 | validation: 0.11148337543461014]
	TIME [epoch: 142 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13725222956137953		[learning rate: 0.00094922]
	Learning Rate: 0.000949223
	LOSS [training: 0.13725222956137953 | validation: 0.11208433164499462]
	TIME [epoch: 142 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13811647674682703		[learning rate: 0.00094235]
	Learning Rate: 0.000942346
	LOSS [training: 0.13811647674682703 | validation: 0.11090657015471062]
	TIME [epoch: 142 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13560096122779397		[learning rate: 0.00093552]
	Learning Rate: 0.000935519
	LOSS [training: 0.13560096122779397 | validation: 0.11398181201668807]
	TIME [epoch: 142 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13534841711476242		[learning rate: 0.00092874]
	Learning Rate: 0.000928741
	LOSS [training: 0.13534841711476242 | validation: 0.10979300985212706]
	TIME [epoch: 142 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13683039843194472		[learning rate: 0.00092201]
	Learning Rate: 0.000922012
	LOSS [training: 0.13683039843194472 | validation: 0.11110232718712625]
	TIME [epoch: 142 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13630843114810443		[learning rate: 0.00091533]
	Learning Rate: 0.000915333
	LOSS [training: 0.13630843114810443 | validation: 0.11078215840887724]
	TIME [epoch: 142 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13837757960608257		[learning rate: 0.0009087]
	Learning Rate: 0.000908701
	LOSS [training: 0.13837757960608257 | validation: 0.11112553049926652]
	TIME [epoch: 142 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13750733904008905		[learning rate: 0.00090212]
	Learning Rate: 0.000902118
	LOSS [training: 0.13750733904008905 | validation: 0.1119218017670025]
	TIME [epoch: 142 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13596915863094558		[learning rate: 0.00089558]
	Learning Rate: 0.000895582
	LOSS [training: 0.13596915863094558 | validation: 0.1145704672044227]
	TIME [epoch: 142 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13609608149723493		[learning rate: 0.00088909]
	Learning Rate: 0.000889093
	LOSS [training: 0.13609608149723493 | validation: 0.11362622239495694]
	TIME [epoch: 142 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13843097053872		[learning rate: 0.00088265]
	Learning Rate: 0.000882652
	LOSS [training: 0.13843097053872 | validation: 0.1126401071241808]
	TIME [epoch: 142 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13726546739330717		[learning rate: 0.00087626]
	Learning Rate: 0.000876257
	LOSS [training: 0.13726546739330717 | validation: 0.11238455675551143]
	TIME [epoch: 142 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13543305046946735		[learning rate: 0.00086991]
	Learning Rate: 0.000869909
	LOSS [training: 0.13543305046946735 | validation: 0.11333978036945994]
	TIME [epoch: 142 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13766592609791672		[learning rate: 0.00086361]
	Learning Rate: 0.000863606
	LOSS [training: 0.13766592609791672 | validation: 0.11072026585806302]
	TIME [epoch: 142 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1372722778075678		[learning rate: 0.00085735]
	Learning Rate: 0.000857349
	LOSS [training: 0.1372722778075678 | validation: 0.11218642920798927]
	TIME [epoch: 142 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1383014714918985		[learning rate: 0.00085114]
	Learning Rate: 0.000851138
	LOSS [training: 0.1383014714918985 | validation: 0.11313929792812023]
	TIME [epoch: 142 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13645228407081889		[learning rate: 0.00084497]
	Learning Rate: 0.000844972
	LOSS [training: 0.13645228407081889 | validation: 0.11470169368970344]
	TIME [epoch: 142 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1404660477689749		[learning rate: 0.00083885]
	Learning Rate: 0.00083885
	LOSS [training: 0.1404660477689749 | validation: 0.11090082327301327]
	TIME [epoch: 142 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13755945020417956		[learning rate: 0.00083277]
	Learning Rate: 0.000832772
	LOSS [training: 0.13755945020417956 | validation: 0.11056428943924708]
	TIME [epoch: 142 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13722902841025933		[learning rate: 0.00082674]
	Learning Rate: 0.000826739
	LOSS [training: 0.13722902841025933 | validation: 0.11104219052723574]
	TIME [epoch: 142 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13666398585058512		[learning rate: 0.00082075]
	Learning Rate: 0.000820749
	LOSS [training: 0.13666398585058512 | validation: 0.1110221540825929]
	TIME [epoch: 142 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13873823215319478		[learning rate: 0.0008148]
	Learning Rate: 0.000814803
	LOSS [training: 0.13873823215319478 | validation: 0.11192877711601276]
	TIME [epoch: 142 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.138123023429962		[learning rate: 0.0008089]
	Learning Rate: 0.0008089
	LOSS [training: 0.138123023429962 | validation: 0.11131690161870247]
	TIME [epoch: 142 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13665727703812047		[learning rate: 0.00080304]
	Learning Rate: 0.000803039
	LOSS [training: 0.13665727703812047 | validation: 0.11249617549062015]
	TIME [epoch: 142 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13702151538929777		[learning rate: 0.00079722]
	Learning Rate: 0.000797221
	LOSS [training: 0.13702151538929777 | validation: 0.11208998967572972]
	TIME [epoch: 142 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13904953061463926		[learning rate: 0.00079145]
	Learning Rate: 0.000791446
	LOSS [training: 0.13904953061463926 | validation: 0.11050344767238988]
	TIME [epoch: 142 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13524154552266252		[learning rate: 0.00078571]
	Learning Rate: 0.000785711
	LOSS [training: 0.13524154552266252 | validation: 0.11193444817460256]
	TIME [epoch: 142 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.136038431541772		[learning rate: 0.00078002]
	Learning Rate: 0.000780019
	LOSS [training: 0.136038431541772 | validation: 0.11162680992891208]
	TIME [epoch: 142 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13786680121333172		[learning rate: 0.00077437]
	Learning Rate: 0.000774368
	LOSS [training: 0.13786680121333172 | validation: 0.1130484930045614]
	TIME [epoch: 142 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13693897045810305		[learning rate: 0.00076876]
	Learning Rate: 0.000768758
	LOSS [training: 0.13693897045810305 | validation: 0.11260985020664202]
	TIME [epoch: 142 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1371023138160456		[learning rate: 0.00076319]
	Learning Rate: 0.000763188
	LOSS [training: 0.1371023138160456 | validation: 0.11416559801257128]
	TIME [epoch: 142 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1373397614456278		[learning rate: 0.00075766]
	Learning Rate: 0.000757659
	LOSS [training: 0.1373397614456278 | validation: 0.11299838529688558]
	TIME [epoch: 142 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13672307499636563		[learning rate: 0.00075217]
	Learning Rate: 0.000752169
	LOSS [training: 0.13672307499636563 | validation: 0.11204557514624233]
	TIME [epoch: 142 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13627467657110054		[learning rate: 0.00074672]
	Learning Rate: 0.00074672
	LOSS [training: 0.13627467657110054 | validation: 0.11368194867030712]
	TIME [epoch: 142 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13596638756682577		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.13596638756682577 | validation: 0.11159813740189248]
	TIME [epoch: 142 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1378635789989866		[learning rate: 0.00073594]
	Learning Rate: 0.000735939
	LOSS [training: 0.1378635789989866 | validation: 0.11083883344630012]
	TIME [epoch: 142 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13672639234837833		[learning rate: 0.00073061]
	Learning Rate: 0.000730608
	LOSS [training: 0.13672639234837833 | validation: 0.11193767495189388]
	TIME [epoch: 142 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13724564159831645		[learning rate: 0.00072531]
	Learning Rate: 0.000725314
	LOSS [training: 0.13724564159831645 | validation: 0.11033060068361444]
	TIME [epoch: 142 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13782794165028844		[learning rate: 0.00072006]
	Learning Rate: 0.00072006
	LOSS [training: 0.13782794165028844 | validation: 0.11075894065828965]
	TIME [epoch: 142 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1388859908166081		[learning rate: 0.00071484]
	Learning Rate: 0.000714843
	LOSS [training: 0.1388859908166081 | validation: 0.11379661856775951]
	TIME [epoch: 142 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13757646646677477		[learning rate: 0.00070966]
	Learning Rate: 0.000709664
	LOSS [training: 0.13757646646677477 | validation: 0.11438720675015512]
	TIME [epoch: 142 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13663385001983025		[learning rate: 0.00070452]
	Learning Rate: 0.000704522
	LOSS [training: 0.13663385001983025 | validation: 0.11336818124441135]
	TIME [epoch: 142 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1387985046027013		[learning rate: 0.00069942]
	Learning Rate: 0.000699418
	LOSS [training: 0.1387985046027013 | validation: 0.11194889249848586]
	TIME [epoch: 142 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13850930436716105		[learning rate: 0.00069435]
	Learning Rate: 0.000694351
	LOSS [training: 0.13850930436716105 | validation: 0.11032766952466581]
	TIME [epoch: 142 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13764791001087515		[learning rate: 0.00068932]
	Learning Rate: 0.00068932
	LOSS [training: 0.13764791001087515 | validation: 0.1131299239491808]
	TIME [epoch: 142 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13687737134003428		[learning rate: 0.00068433]
	Learning Rate: 0.000684326
	LOSS [training: 0.13687737134003428 | validation: 0.11315057688279331]
	TIME [epoch: 142 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13745589439091874		[learning rate: 0.00067937]
	Learning Rate: 0.000679368
	LOSS [training: 0.13745589439091874 | validation: 0.11168291087212597]
	TIME [epoch: 142 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1365899461902571		[learning rate: 0.00067445]
	Learning Rate: 0.000674446
	LOSS [training: 0.1365899461902571 | validation: 0.11190608089057004]
	TIME [epoch: 142 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13836448696186535		[learning rate: 0.00066956]
	Learning Rate: 0.00066956
	LOSS [training: 0.13836448696186535 | validation: 0.1109922876761027]
	TIME [epoch: 142 sec]
EPOCH 423/1000:
	Training over batches...
