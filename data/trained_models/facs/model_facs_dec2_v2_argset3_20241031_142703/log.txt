Args:
Namespace(name='model_facs_dec2_v2_argset3', outdir='out/model_training/model_facs_dec2_v2_argset3', training_data='data/facs/facs_dec2_v2/training', validation_data='data/facs/facs_dec2_v2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05, 0.1, 0.15, 0.5], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 126688166

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656298005295328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0656298005295328 | validation: 0.8361019090700009]
	TIME [epoch: 56.4 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186731113901075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6186731113901075 | validation: 0.738924199768912]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091382305615891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5091382305615891 | validation: 0.5815447953498729]
	TIME [epoch: 6.64 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.4205281501000281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4205281501000281 | validation: 0.5011376236173416]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.34857252229323055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34857252229323055 | validation: 0.42718223324610693]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2958064493544308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2958064493544308 | validation: 0.4411383040096965]
	TIME [epoch: 6.64 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.26944247781000835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26944247781000835 | validation: 0.3926863211775965]
	TIME [epoch: 6.62 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.22712544181414304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22712544181414304 | validation: 0.3007486816425431]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17257422167070163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17257422167070163 | validation: 0.2895772292687131]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1446131001425407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1446131001425407 | validation: 0.25945640218997557]
	TIME [epoch: 6.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.15152577533668546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.15152577533668546 | validation: 0.2533481298030869]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12102373519002771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12102373519002771 | validation: 0.23878273026955374]
	TIME [epoch: 6.63 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11270028668628748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11270028668628748 | validation: 0.2261726666760353]
	TIME [epoch: 6.61 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10915217264674931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10915217264674931 | validation: 0.22936066928671825]
	TIME [epoch: 6.62 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11630589364253698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11630589364253698 | validation: 0.230971762518491]
	TIME [epoch: 6.64 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659947936084062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10659947936084062 | validation: 0.2224970313470098]
	TIME [epoch: 6.64 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09694584297066494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09694584297066494 | validation: 0.24466970746875055]
	TIME [epoch: 6.65 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12699804521384062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12699804521384062 | validation: 0.22828813307495763]
	TIME [epoch: 6.65 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359117109997038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09359117109997038 | validation: 0.23596004579133956]
	TIME [epoch: 6.65 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10335120405798717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10335120405798717 | validation: 0.2497868865159767]
	TIME [epoch: 6.66 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10331789898452305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10331789898452305 | validation: 0.23619012854661103]
	TIME [epoch: 6.65 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11418729469320535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11418729469320535 | validation: 0.23887243067989125]
	TIME [epoch: 6.64 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.103850616647495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.103850616647495 | validation: 0.23397981634510834]
	TIME [epoch: 6.65 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10046857396416681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10046857396416681 | validation: 0.24360084118783432]
	TIME [epoch: 6.65 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10291944449576117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10291944449576117 | validation: 0.3573634645034479]
	TIME [epoch: 6.64 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13430805266261703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13430805266261703 | validation: 0.23895184283452242]
	TIME [epoch: 6.65 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09675591261383923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09675591261383923 | validation: 0.22478014633499335]
	TIME [epoch: 6.64 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09269705748623193		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09269705748623193 | validation: 0.2305838780409993]
	TIME [epoch: 6.72 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10149252625818773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10149252625818773 | validation: 0.22998370086982342]
	TIME [epoch: 6.66 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654222763363014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10654222763363014 | validation: 0.2414246916543084]
	TIME [epoch: 6.64 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1196746044332176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1196746044332176 | validation: 0.23081466847507093]
	TIME [epoch: 6.64 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0995461267657002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0995461267657002 | validation: 0.2287284398663673]
	TIME [epoch: 6.76 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1040564625736015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1040564625736015 | validation: 0.22736979054097367]
	TIME [epoch: 6.64 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10180207164808644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10180207164808644 | validation: 0.385509360319868]
	TIME [epoch: 6.64 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16005427389568927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16005427389568927 | validation: 0.24261244688936776]
	TIME [epoch: 6.64 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09728085772125049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09728085772125049 | validation: 0.2305041587184315]
	TIME [epoch: 6.64 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274042864164877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10274042864164877 | validation: 0.2307953690724676]
	TIME [epoch: 6.65 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10222342306760437		[learning rate: 0.0099758]
	Learning Rate: 0.00997579
	LOSS [training: 0.10222342306760437 | validation: 0.23189032318429045]
	TIME [epoch: 6.64 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090952766401189		[learning rate: 0.0098795]
	Learning Rate: 0.00987954
	LOSS [training: 0.10090952766401189 | validation: 0.23760439117741855]
	TIME [epoch: 6.63 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802777345950343		[learning rate: 0.0097842]
	Learning Rate: 0.00978422
	LOSS [training: 0.10802777345950343 | validation: 0.3312474468793698]
	TIME [epoch: 6.63 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12389908604019537		[learning rate: 0.0096898]
	Learning Rate: 0.00968982
	LOSS [training: 0.12389908604019537 | validation: 0.26325617446018057]
	TIME [epoch: 6.72 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094831561791079		[learning rate: 0.0095963]
	Learning Rate: 0.00959633
	LOSS [training: 0.1094831561791079 | validation: 0.2769379656812766]
	TIME [epoch: 6.65 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10293845110461204		[learning rate: 0.0095037]
	Learning Rate: 0.00950374
	LOSS [training: 0.10293845110461204 | validation: 0.25788759627975244]
	TIME [epoch: 6.64 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10935662414096549		[learning rate: 0.009412]
	Learning Rate: 0.00941205
	LOSS [training: 0.10935662414096549 | validation: 0.23336691491586978]
	TIME [epoch: 6.64 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09683832095248464		[learning rate: 0.0093212]
	Learning Rate: 0.00932124
	LOSS [training: 0.09683832095248464 | validation: 0.2921562090942031]
	TIME [epoch: 6.63 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11964040078990994		[learning rate: 0.0092313]
	Learning Rate: 0.00923131
	LOSS [training: 0.11964040078990994 | validation: 0.250995527652931]
	TIME [epoch: 6.63 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442284453409731		[learning rate: 0.0091422]
	Learning Rate: 0.00914224
	LOSS [training: 0.10442284453409731 | validation: 0.2651302569636569]
	TIME [epoch: 6.65 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09562025943394734		[learning rate: 0.009054]
	Learning Rate: 0.00905403
	LOSS [training: 0.09562025943394734 | validation: 0.25052788951866933]
	TIME [epoch: 6.64 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09475138659510127		[learning rate: 0.0089667]
	Learning Rate: 0.00896668
	LOSS [training: 0.09475138659510127 | validation: 0.2817619985726105]
	TIME [epoch: 6.64 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11272254607770057		[learning rate: 0.0088802]
	Learning Rate: 0.00888017
	LOSS [training: 0.11272254607770057 | validation: 0.29628700785248907]
	TIME [epoch: 6.64 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10223268107824283		[learning rate: 0.0087945]
	Learning Rate: 0.00879449
	LOSS [training: 0.10223268107824283 | validation: 0.26197420413990263]
	TIME [epoch: 60.6 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10163683403171349		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.10163683403171349 | validation: 0.23281898249515504]
	TIME [epoch: 12.9 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0994415651478647		[learning rate: 0.0086256]
	Learning Rate: 0.0086256
	LOSS [training: 0.0994415651478647 | validation: 0.22571498864688128]
	TIME [epoch: 12.9 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08496617510778341		[learning rate: 0.0085424]
	Learning Rate: 0.00854238
	LOSS [training: 0.08496617510778341 | validation: 0.2288624727440048]
	TIME [epoch: 12.9 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10141841359493828		[learning rate: 0.00846]
	Learning Rate: 0.00845996
	LOSS [training: 0.10141841359493828 | validation: 0.22747580505830245]
	TIME [epoch: 12.9 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10808981362224418		[learning rate: 0.0083783]
	Learning Rate: 0.00837834
	LOSS [training: 0.10808981362224418 | validation: 0.24031585431144742]
	TIME [epoch: 12.9 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09506005060616125		[learning rate: 0.0082975]
	Learning Rate: 0.0082975
	LOSS [training: 0.09506005060616125 | validation: 0.23127973642214292]
	TIME [epoch: 12.9 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910432230737574		[learning rate: 0.0082174]
	Learning Rate: 0.00821745
	LOSS [training: 0.10910432230737574 | validation: 0.2248541692845182]
	TIME [epoch: 12.9 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11713969150098752		[learning rate: 0.0081382]
	Learning Rate: 0.00813816
	LOSS [training: 0.11713969150098752 | validation: 0.2297224305484873]
	TIME [epoch: 12.9 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09046046158172602		[learning rate: 0.0080596]
	Learning Rate: 0.00805964
	LOSS [training: 0.09046046158172602 | validation: 0.2286633212683323]
	TIME [epoch: 12.9 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10119111442644985		[learning rate: 0.0079819]
	Learning Rate: 0.00798188
	LOSS [training: 0.10119111442644985 | validation: 0.23581190171140032]
	TIME [epoch: 12.9 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08521280565953437		[learning rate: 0.0079049]
	Learning Rate: 0.00790487
	LOSS [training: 0.08521280565953437 | validation: 0.22565668872807373]
	TIME [epoch: 12.9 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482279921009415		[learning rate: 0.0078286]
	Learning Rate: 0.0078286
	LOSS [training: 0.09482279921009415 | validation: 0.24319632078132278]
	TIME [epoch: 12.9 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10428998759175914		[learning rate: 0.0077531]
	Learning Rate: 0.00775307
	LOSS [training: 0.10428998759175914 | validation: 0.2255264062695601]
	TIME [epoch: 12.9 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160161199422421		[learning rate: 0.0076783]
	Learning Rate: 0.00767827
	LOSS [training: 0.10160161199422421 | validation: 0.23854080176543122]
	TIME [epoch: 12.9 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11025057503125163		[learning rate: 0.0076042]
	Learning Rate: 0.00760418
	LOSS [training: 0.11025057503125163 | validation: 0.2813770624626988]
	TIME [epoch: 12.9 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122648640049287		[learning rate: 0.0075308]
	Learning Rate: 0.00753082
	LOSS [training: 0.11122648640049287 | validation: 0.2901235943118641]
	TIME [epoch: 12.9 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1133138957413402		[learning rate: 0.0074582]
	Learning Rate: 0.00745816
	LOSS [training: 0.1133138957413402 | validation: 0.24471114923292192]
	TIME [epoch: 12.9 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09056807696886154		[learning rate: 0.0073862]
	Learning Rate: 0.0073862
	LOSS [training: 0.09056807696886154 | validation: 0.23419847311211686]
	TIME [epoch: 12.9 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11193539252830371		[learning rate: 0.0073149]
	Learning Rate: 0.00731494
	LOSS [training: 0.11193539252830371 | validation: 0.22427127240083053]
	TIME [epoch: 12.9 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09969006079685384		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.09969006079685384 | validation: 0.24005682646750162]
	TIME [epoch: 12.9 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08663298086252746		[learning rate: 0.0071745]
	Learning Rate: 0.00717446
	LOSS [training: 0.08663298086252746 | validation: 0.2596742056300957]
	TIME [epoch: 12.9 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10804414629557416		[learning rate: 0.0071052]
	Learning Rate: 0.00710524
	LOSS [training: 0.10804414629557416 | validation: 0.22625342366607723]
	TIME [epoch: 12.9 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10202752539977508		[learning rate: 0.0070367]
	Learning Rate: 0.00703669
	LOSS [training: 0.10202752539977508 | validation: 0.2245260139042851]
	TIME [epoch: 12.9 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869326158775614		[learning rate: 0.0069688]
	Learning Rate: 0.0069688
	LOSS [training: 0.0869326158775614 | validation: 0.22381464644546303]
	TIME [epoch: 12.9 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10176191611477615		[learning rate: 0.0069016]
	Learning Rate: 0.00690156
	LOSS [training: 0.10176191611477615 | validation: 0.23854917500837913]
	TIME [epoch: 12.9 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0940199365232085		[learning rate: 0.006835]
	Learning Rate: 0.00683497
	LOSS [training: 0.0940199365232085 | validation: 0.23202875117241237]
	TIME [epoch: 12.9 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10536082492021516		[learning rate: 0.006769]
	Learning Rate: 0.00676903
	LOSS [training: 0.10536082492021516 | validation: 0.2327664548341407]
	TIME [epoch: 12.9 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681821620060085		[learning rate: 0.0067037]
	Learning Rate: 0.00670372
	LOSS [training: 0.09681821620060085 | validation: 0.22774353503600334]
	TIME [epoch: 12.9 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.093840917752429		[learning rate: 0.006639]
	Learning Rate: 0.00663904
	LOSS [training: 0.093840917752429 | validation: 0.2280212599451404]
	TIME [epoch: 12.9 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.091694807445462		[learning rate: 0.006575]
	Learning Rate: 0.00657498
	LOSS [training: 0.091694807445462 | validation: 0.2413603984117798]
	TIME [epoch: 12.9 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09044840677074156		[learning rate: 0.0065115]
	Learning Rate: 0.00651155
	LOSS [training: 0.09044840677074156 | validation: 0.31297608813146094]
	TIME [epoch: 12.9 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10795832161581038		[learning rate: 0.0064487]
	Learning Rate: 0.00644872
	LOSS [training: 0.10795832161581038 | validation: 0.2526542957136755]
	TIME [epoch: 12.9 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09828232338400658		[learning rate: 0.0063865]
	Learning Rate: 0.0063865
	LOSS [training: 0.09828232338400658 | validation: 0.23668661085754653]
	TIME [epoch: 12.9 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09273850500555947		[learning rate: 0.0063249]
	Learning Rate: 0.00632488
	LOSS [training: 0.09273850500555947 | validation: 0.22879699825370794]
	TIME [epoch: 12.9 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09053892039473366		[learning rate: 0.0062639]
	Learning Rate: 0.00626386
	LOSS [training: 0.09053892039473366 | validation: 0.23455447227192933]
	TIME [epoch: 12.9 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009801333284013		[learning rate: 0.0062034]
	Learning Rate: 0.00620343
	LOSS [training: 0.1009801333284013 | validation: 0.23313082153811165]
	TIME [epoch: 12.9 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716207687886922		[learning rate: 0.0061436]
	Learning Rate: 0.00614357
	LOSS [training: 0.08716207687886922 | validation: 0.23656170717024674]
	TIME [epoch: 12.9 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262602778042157		[learning rate: 0.0060843]
	Learning Rate: 0.0060843
	LOSS [training: 0.10262602778042157 | validation: 0.24103336706768355]
	TIME [epoch: 12.9 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08823620031536143		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.08823620031536143 | validation: 0.26755965226750505]
	TIME [epoch: 12.9 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10299640956293749		[learning rate: 0.0059675]
	Learning Rate: 0.00596746
	LOSS [training: 0.10299640956293749 | validation: 0.228795770824049]
	TIME [epoch: 12.9 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08692706030772411		[learning rate: 0.0059099]
	Learning Rate: 0.00590988
	LOSS [training: 0.08692706030772411 | validation: 0.26268250628427503]
	TIME [epoch: 12.9 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10263117002994271		[learning rate: 0.0058529]
	Learning Rate: 0.00585286
	LOSS [training: 0.10263117002994271 | validation: 0.2782445347775301]
	TIME [epoch: 12.9 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0988405686513856		[learning rate: 0.0057964]
	Learning Rate: 0.00579639
	LOSS [training: 0.0988405686513856 | validation: 0.2333235047797838]
	TIME [epoch: 12.9 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09037440365873642		[learning rate: 0.0057405]
	Learning Rate: 0.00574047
	LOSS [training: 0.09037440365873642 | validation: 0.2365797464378237]
	TIME [epoch: 12.9 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09856092281722106		[learning rate: 0.0056851]
	Learning Rate: 0.00568508
	LOSS [training: 0.09856092281722106 | validation: 0.2399034612215855]
	TIME [epoch: 12.8 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08863982381784102		[learning rate: 0.0056302]
	Learning Rate: 0.00563023
	LOSS [training: 0.08863982381784102 | validation: 0.26935950021688676]
	TIME [epoch: 12.9 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09685634261773474		[learning rate: 0.0055759]
	Learning Rate: 0.00557591
	LOSS [training: 0.09685634261773474 | validation: 0.24704801566511073]
	TIME [epoch: 12.9 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09813595483277107		[learning rate: 0.0055221]
	Learning Rate: 0.00552211
	LOSS [training: 0.09813595483277107 | validation: 0.2254855635205269]
	TIME [epoch: 12.9 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08678640900390512		[learning rate: 0.0054688]
	Learning Rate: 0.00546883
	LOSS [training: 0.08678640900390512 | validation: 0.2232418866069373]
	TIME [epoch: 12.9 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0932835462124538		[learning rate: 0.0054161]
	Learning Rate: 0.00541607
	LOSS [training: 0.0932835462124538 | validation: 0.2565033376805981]
	TIME [epoch: 74.2 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09413585993106931		[learning rate: 0.0053638]
	Learning Rate: 0.00536381
	LOSS [training: 0.09413585993106931 | validation: 0.24015050980644187]
	TIME [epoch: 26.9 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09525872127740678		[learning rate: 0.0053121]
	Learning Rate: 0.00531206
	LOSS [training: 0.09525872127740678 | validation: 0.22881847038618938]
	TIME [epoch: 26.9 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09351630426944149		[learning rate: 0.0052608]
	Learning Rate: 0.00526081
	LOSS [training: 0.09351630426944149 | validation: 0.27248126328917965]
	TIME [epoch: 26.9 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09793034858031628		[learning rate: 0.0052101]
	Learning Rate: 0.00521005
	LOSS [training: 0.09793034858031628 | validation: 0.22369694050711458]
	TIME [epoch: 26.9 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743906064670394		[learning rate: 0.0051598]
	Learning Rate: 0.00515978
	LOSS [training: 0.08743906064670394 | validation: 0.22212838883675604]
	TIME [epoch: 26.9 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051097285806335		[learning rate: 0.00511]
	Learning Rate: 0.00511
	LOSS [training: 0.1051097285806335 | validation: 0.22180918577968442]
	TIME [epoch: 26.9 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_107.pth
	Model improved!!!
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08944217950145152		[learning rate: 0.0050607]
	Learning Rate: 0.0050607
	LOSS [training: 0.08944217950145152 | validation: 0.23068406493139043]
	TIME [epoch: 26.9 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0893093454054751		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.0893093454054751 | validation: 0.23447705347144587]
	TIME [epoch: 27 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499875774978143		[learning rate: 0.0049635]
	Learning Rate: 0.00496352
	LOSS [training: 0.09499875774978143 | validation: 0.24437062227592715]
	TIME [epoch: 26.9 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08669049865728574		[learning rate: 0.0049156]
	Learning Rate: 0.00491563
	LOSS [training: 0.08669049865728574 | validation: 0.2220494183785014]
	TIME [epoch: 26.9 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966303270764178		[learning rate: 0.0048682]
	Learning Rate: 0.0048682
	LOSS [training: 0.0966303270764178 | validation: 0.22572878824757325]
	TIME [epoch: 26.9 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005519707764051		[learning rate: 0.0048212]
	Learning Rate: 0.00482123
	LOSS [training: 0.1005519707764051 | validation: 0.24314680076967898]
	TIME [epoch: 26.9 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582437068572123		[learning rate: 0.0047747]
	Learning Rate: 0.00477471
	LOSS [training: 0.08582437068572123 | validation: 0.23095383277224774]
	TIME [epoch: 26.9 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.085367561057302		[learning rate: 0.0047286]
	Learning Rate: 0.00472865
	LOSS [training: 0.085367561057302 | validation: 0.2182309297538233]
	TIME [epoch: 26.9 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09658626238844031		[learning rate: 0.004683]
	Learning Rate: 0.00468302
	LOSS [training: 0.09658626238844031 | validation: 0.260458022055797]
	TIME [epoch: 26.9 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10502160951965525		[learning rate: 0.0046378]
	Learning Rate: 0.00463784
	LOSS [training: 0.10502160951965525 | validation: 0.22535081247249125]
	TIME [epoch: 26.9 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0893423110020436		[learning rate: 0.0045931]
	Learning Rate: 0.00459309
	LOSS [training: 0.0893423110020436 | validation: 0.28040147318784375]
	TIME [epoch: 26.9 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427340222656114		[learning rate: 0.0045488]
	Learning Rate: 0.00454878
	LOSS [training: 0.09427340222656114 | validation: 0.22335227195176952]
	TIME [epoch: 26.9 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0976108858726682		[learning rate: 0.0045049]
	Learning Rate: 0.00450489
	LOSS [training: 0.0976108858726682 | validation: 0.22005708945125668]
	TIME [epoch: 26.9 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295337175936104		[learning rate: 0.0044614]
	Learning Rate: 0.00446143
	LOSS [training: 0.08295337175936104 | validation: 0.23120971280441005]
	TIME [epoch: 26.9 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08879452585729367		[learning rate: 0.0044184]
	Learning Rate: 0.00441838
	LOSS [training: 0.08879452585729367 | validation: 0.22291666187899126]
	TIME [epoch: 26.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08941500776033524		[learning rate: 0.0043758]
	Learning Rate: 0.00437575
	LOSS [training: 0.08941500776033524 | validation: 0.22197685720881086]
	TIME [epoch: 26.9 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09531538942424088		[learning rate: 0.0043335]
	Learning Rate: 0.00433353
	LOSS [training: 0.09531538942424088 | validation: 0.24207629797545624]
	TIME [epoch: 26.9 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09851340051743275		[learning rate: 0.0042917]
	Learning Rate: 0.00429172
	LOSS [training: 0.09851340051743275 | validation: 0.21205342238259905]
	TIME [epoch: 26.9 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10203166120032518		[learning rate: 0.0042503]
	Learning Rate: 0.00425031
	LOSS [training: 0.10203166120032518 | validation: 0.21217179672452618]
	TIME [epoch: 26.9 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10177527789421739		[learning rate: 0.0042093]
	Learning Rate: 0.00420931
	LOSS [training: 0.10177527789421739 | validation: 0.21270128214917958]
	TIME [epoch: 26.9 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08687825945752044		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.08687825945752044 | validation: 0.21291330402198674]
	TIME [epoch: 26.9 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590325156709773		[learning rate: 0.0041285]
	Learning Rate: 0.00412847
	LOSS [training: 0.08590325156709773 | validation: 0.2435690622893321]
	TIME [epoch: 26.9 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09208735854750666		[learning rate: 0.0040886]
	Learning Rate: 0.00408864
	LOSS [training: 0.09208735854750666 | validation: 0.24474174156279177]
	TIME [epoch: 26.9 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09595377622041659		[learning rate: 0.0040492]
	Learning Rate: 0.00404919
	LOSS [training: 0.09595377622041659 | validation: 0.2237638355902902]
	TIME [epoch: 26.9 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09102886997296036		[learning rate: 0.0040101]
	Learning Rate: 0.00401012
	LOSS [training: 0.09102886997296036 | validation: 0.21924628407940797]
	TIME [epoch: 26.9 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08930314174381652		[learning rate: 0.0039714]
	Learning Rate: 0.00397143
	LOSS [training: 0.08930314174381652 | validation: 0.2166700893902975]
	TIME [epoch: 26.9 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710869706844924		[learning rate: 0.0039331]
	Learning Rate: 0.00393312
	LOSS [training: 0.09710869706844924 | validation: 0.22420801029300103]
	TIME [epoch: 26.9 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892559867742315		[learning rate: 0.0038952]
	Learning Rate: 0.00389517
	LOSS [training: 0.08892559867742315 | validation: 0.2122677897041858]
	TIME [epoch: 26.9 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880063700566748		[learning rate: 0.0038576]
	Learning Rate: 0.00385759
	LOSS [training: 0.08880063700566748 | validation: 0.21946067603817446]
	TIME [epoch: 26.9 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08882612650783922		[learning rate: 0.0038204]
	Learning Rate: 0.00382037
	LOSS [training: 0.08882612650783922 | validation: 0.2583812545578063]
	TIME [epoch: 26.9 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939008305743925		[learning rate: 0.0037835]
	Learning Rate: 0.00378351
	LOSS [training: 0.0939008305743925 | validation: 0.22007516508948793]
	TIME [epoch: 26.9 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09474640272775872		[learning rate: 0.003747]
	Learning Rate: 0.003747
	LOSS [training: 0.09474640272775872 | validation: 0.22805003783677633]
	TIME [epoch: 26.9 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702671291673884		[learning rate: 0.0037109]
	Learning Rate: 0.00371085
	LOSS [training: 0.08702671291673884 | validation: 0.22028794866053614]
	TIME [epoch: 26.9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710721192705479		[learning rate: 0.003675]
	Learning Rate: 0.00367505
	LOSS [training: 0.09710721192705479 | validation: 0.22280419078978594]
	TIME [epoch: 26.9 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839840675479928		[learning rate: 0.0036396]
	Learning Rate: 0.00363959
	LOSS [training: 0.08839840675479928 | validation: 0.21836306250713158]
	TIME [epoch: 26.9 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0869435366153358		[learning rate: 0.0036045]
	Learning Rate: 0.00360448
	LOSS [training: 0.0869435366153358 | validation: 0.21966265153443942]
	TIME [epoch: 26.9 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09174707053086689		[learning rate: 0.0035697]
	Learning Rate: 0.0035697
	LOSS [training: 0.09174707053086689 | validation: 0.23880990408686292]
	TIME [epoch: 26.9 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08843061485443583		[learning rate: 0.0035353]
	Learning Rate: 0.00353526
	LOSS [training: 0.08843061485443583 | validation: 0.22330502843930747]
	TIME [epoch: 26.9 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415066988676493		[learning rate: 0.0035011]
	Learning Rate: 0.00350115
	LOSS [training: 0.09415066988676493 | validation: 0.2186328475883961]
	TIME [epoch: 26.9 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08762411639542698		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.08762411639542698 | validation: 0.21762486084853586]
	TIME [epoch: 26.9 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09010580151063288		[learning rate: 0.0034339]
	Learning Rate: 0.00343391
	LOSS [training: 0.09010580151063288 | validation: 0.24022459655919384]
	TIME [epoch: 26.9 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222901236039651		[learning rate: 0.0034008]
	Learning Rate: 0.00340078
	LOSS [training: 0.08222901236039651 | validation: 0.22246227145916442]
	TIME [epoch: 26.9 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830883284003012		[learning rate: 0.003368]
	Learning Rate: 0.00336797
	LOSS [training: 0.08830883284003012 | validation: 0.21902320872581799]
	TIME [epoch: 27 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09464997264377155		[learning rate: 0.0033355]
	Learning Rate: 0.00333548
	LOSS [training: 0.09464997264377155 | validation: 0.24016680120112288]
	TIME [epoch: 26.9 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050182474274365		[learning rate: 0.0033033]
	Learning Rate: 0.00330329
	LOSS [training: 0.09050182474274365 | validation: 0.2168999856640077]
	TIME [epoch: 26.9 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681729619209236		[learning rate: 0.0032714]
	Learning Rate: 0.00327142
	LOSS [training: 0.08681729619209236 | validation: 0.22156047953536798]
	TIME [epoch: 26.9 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575428471271805		[learning rate: 0.0032399]
	Learning Rate: 0.00323986
	LOSS [training: 0.08575428471271805 | validation: 0.21900404742980623]
	TIME [epoch: 26.9 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09193563528043429		[learning rate: 0.0032086]
	Learning Rate: 0.0032086
	LOSS [training: 0.09193563528043429 | validation: 0.23169678148530162]
	TIME [epoch: 26.9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446797447211968		[learning rate: 0.0031776]
	Learning Rate: 0.00317764
	LOSS [training: 0.08446797447211968 | validation: 0.2329430658856889]
	TIME [epoch: 26.9 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878885293445115		[learning rate: 0.003147]
	Learning Rate: 0.00314699
	LOSS [training: 0.10878885293445115 | validation: 0.251145883412301]
	TIME [epoch: 26.9 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673241858873305		[learning rate: 0.0031166]
	Learning Rate: 0.00311662
	LOSS [training: 0.09673241858873305 | validation: 0.22586212093568647]
	TIME [epoch: 26.9 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09289188778433137		[learning rate: 0.0030866]
	Learning Rate: 0.00308655
	LOSS [training: 0.09289188778433137 | validation: 0.22223726972381275]
	TIME [epoch: 26.9 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0857908721021017		[learning rate: 0.0030568]
	Learning Rate: 0.00305677
	LOSS [training: 0.0857908721021017 | validation: 0.224415143331207]
	TIME [epoch: 26.9 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08729632165648361		[learning rate: 0.0030273]
	Learning Rate: 0.00302728
	LOSS [training: 0.08729632165648361 | validation: 0.23422000799985349]
	TIME [epoch: 26.9 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09172226688850818		[learning rate: 0.0029981]
	Learning Rate: 0.00299807
	LOSS [training: 0.09172226688850818 | validation: 0.2206107207293696]
	TIME [epoch: 26.9 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0966599366310564		[learning rate: 0.0029691]
	Learning Rate: 0.00296915
	LOSS [training: 0.0966599366310564 | validation: 0.2232318351657555]
	TIME [epoch: 26.9 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0888539582908675		[learning rate: 0.0029405]
	Learning Rate: 0.0029405
	LOSS [training: 0.0888539582908675 | validation: 0.2391085418722177]
	TIME [epoch: 26.9 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923511156295219		[learning rate: 0.0029121]
	Learning Rate: 0.00291213
	LOSS [training: 0.0923511156295219 | validation: 0.22542591738977089]
	TIME [epoch: 26.9 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09226965658911679		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.09226965658911679 | validation: 0.2202551494245767]
	TIME [epoch: 26.9 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0907624809301971		[learning rate: 0.0028562]
	Learning Rate: 0.00285621
	LOSS [training: 0.0907624809301971 | validation: 0.2147268732574787]
	TIME [epoch: 26.9 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942115972847942		[learning rate: 0.0028286]
	Learning Rate: 0.00282865
	LOSS [training: 0.09942115972847942 | validation: 0.22493725748260646]
	TIME [epoch: 26.9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08982475357074683		[learning rate: 0.0028014]
	Learning Rate: 0.00280136
	LOSS [training: 0.08982475357074683 | validation: 0.2570480853053236]
	TIME [epoch: 26.9 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09990478586197969		[learning rate: 0.0027743]
	Learning Rate: 0.00277433
	LOSS [training: 0.09990478586197969 | validation: 0.23838569693430006]
	TIME [epoch: 26.9 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419182999363568		[learning rate: 0.0027476]
	Learning Rate: 0.00274756
	LOSS [training: 0.09419182999363568 | validation: 0.231904999114486]
	TIME [epoch: 26.9 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09157181950969888		[learning rate: 0.0027211]
	Learning Rate: 0.00272105
	LOSS [training: 0.09157181950969888 | validation: 0.22086384237618534]
	TIME [epoch: 26.9 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095192406339818		[learning rate: 0.0026948]
	Learning Rate: 0.0026948
	LOSS [training: 0.08095192406339818 | validation: 0.21243303386533927]
	TIME [epoch: 26.9 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544092304557847		[learning rate: 0.0026688]
	Learning Rate: 0.0026688
	LOSS [training: 0.09544092304557847 | validation: 0.22296354601692703]
	TIME [epoch: 26.9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828472808863135		[learning rate: 0.002643]
	Learning Rate: 0.00264305
	LOSS [training: 0.08828472808863135 | validation: 0.2206026982901841]
	TIME [epoch: 26.9 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09937608685379604		[learning rate: 0.0026175]
	Learning Rate: 0.00261755
	LOSS [training: 0.09937608685379604 | validation: 0.21660711892671258]
	TIME [epoch: 26.9 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0857256015959464		[learning rate: 0.0025923]
	Learning Rate: 0.00259229
	LOSS [training: 0.0857256015959464 | validation: 0.21821012819984373]
	TIME [epoch: 26.9 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760221914098924		[learning rate: 0.0025673]
	Learning Rate: 0.00256728
	LOSS [training: 0.08760221914098924 | validation: 0.2160409012593418]
	TIME [epoch: 26.9 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09082645114553954		[learning rate: 0.0025425]
	Learning Rate: 0.00254251
	LOSS [training: 0.09082645114553954 | validation: 0.22799714564028314]
	TIME [epoch: 26.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0882175732130252		[learning rate: 0.002518]
	Learning Rate: 0.00251798
	LOSS [training: 0.0882175732130252 | validation: 0.21821695742646544]
	TIME [epoch: 26.9 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0912543377181936		[learning rate: 0.0024937]
	Learning Rate: 0.00249369
	LOSS [training: 0.0912543377181936 | validation: 0.2282802851615225]
	TIME [epoch: 26.9 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09300838132783443		[learning rate: 0.0024696]
	Learning Rate: 0.00246963
	LOSS [training: 0.09300838132783443 | validation: 0.2584445432171766]
	TIME [epoch: 26.9 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09946376034306759		[learning rate: 0.0024458]
	Learning Rate: 0.0024458
	LOSS [training: 0.09946376034306759 | validation: 0.22011654689726082]
	TIME [epoch: 26.9 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10160273353036017		[learning rate: 0.0024222]
	Learning Rate: 0.0024222
	LOSS [training: 0.10160273353036017 | validation: 0.2293142419580249]
	TIME [epoch: 26.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10050062862776159		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.10050062862776159 | validation: 0.22156527677329918]
	TIME [epoch: 26.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838842320423726		[learning rate: 0.0023757]
	Learning Rate: 0.00237569
	LOSS [training: 0.08838842320423726 | validation: 0.22186755928030272]
	TIME [epoch: 26.9 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09601002043094942		[learning rate: 0.0023528]
	Learning Rate: 0.00235277
	LOSS [training: 0.09601002043094942 | validation: 0.21967930671372418]
	TIME [epoch: 26.9 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08719205679286175		[learning rate: 0.0023301]
	Learning Rate: 0.00233007
	LOSS [training: 0.08719205679286175 | validation: 0.2268926814250649]
	TIME [epoch: 26.9 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09472287643509901		[learning rate: 0.0023076]
	Learning Rate: 0.00230759
	LOSS [training: 0.09472287643509901 | validation: 0.22289773988028397]
	TIME [epoch: 26.9 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09107867400544345		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.09107867400544345 | validation: 0.22210315708789174]
	TIME [epoch: 26.9 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08796379632564424		[learning rate: 0.0022633]
	Learning Rate: 0.00226327
	LOSS [training: 0.08796379632564424 | validation: 0.21927137211193626]
	TIME [epoch: 26.9 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08927880767149247		[learning rate: 0.0022414]
	Learning Rate: 0.00224144
	LOSS [training: 0.08927880767149247 | validation: 0.2236548117789454]
	TIME [epoch: 26.9 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341511941947693		[learning rate: 0.0022198]
	Learning Rate: 0.00221981
	LOSS [training: 0.09341511941947693 | validation: 0.22254879142136058]
	TIME [epoch: 26.9 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08693538898547729		[learning rate: 0.0021984]
	Learning Rate: 0.00219839
	LOSS [training: 0.08693538898547729 | validation: 0.22367101518675014]
	TIME [epoch: 26.9 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0816321282627097		[learning rate: 0.0021772]
	Learning Rate: 0.00217718
	LOSS [training: 0.0816321282627097 | validation: 0.21712386215299986]
	TIME [epoch: 26.9 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853667999634864		[learning rate: 0.0021562]
	Learning Rate: 0.00215618
	LOSS [training: 0.0853667999634864 | validation: 0.24605348669967372]
	TIME [epoch: 26.9 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08760022860341098		[learning rate: 0.0021354]
	Learning Rate: 0.00213537
	LOSS [training: 0.08760022860341098 | validation: 0.21771234125455569]
	TIME [epoch: 26.9 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08929511547706452		[learning rate: 0.0021148]
	Learning Rate: 0.00211477
	LOSS [training: 0.08929511547706452 | validation: 0.2201764865056889]
	TIME [epoch: 26.9 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590906355181502		[learning rate: 0.0020944]
	Learning Rate: 0.00209437
	LOSS [training: 0.08590906355181502 | validation: 0.2316622233061394]
	TIME [epoch: 26.9 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08240288450142594		[learning rate: 0.0020742]
	Learning Rate: 0.00207416
	LOSS [training: 0.08240288450142594 | validation: 0.2256341771133174]
	TIME [epoch: 26.9 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0886442232155283		[learning rate: 0.0020541]
	Learning Rate: 0.00205415
	LOSS [training: 0.0886442232155283 | validation: 0.2199896939152792]
	TIME [epoch: 103 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991050100308726		[learning rate: 0.0020343]
	Learning Rate: 0.00203433
	LOSS [training: 0.08991050100308726 | validation: 0.21611899313718153]
	TIME [epoch: 56.2 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09398772704824314		[learning rate: 0.0020147]
	Learning Rate: 0.0020147
	LOSS [training: 0.09398772704824314 | validation: 0.228456720095216]
	TIME [epoch: 56.2 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09481210795518828		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.09481210795518828 | validation: 0.2196178351107757]
	TIME [epoch: 56.2 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09590468360313054		[learning rate: 0.001976]
	Learning Rate: 0.00197601
	LOSS [training: 0.09590468360313054 | validation: 0.22153400611055848]
	TIME [epoch: 56.2 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08386747685816345		[learning rate: 0.0019569]
	Learning Rate: 0.00195695
	LOSS [training: 0.08386747685816345 | validation: 0.23267273358141188]
	TIME [epoch: 56.2 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08573619039890745		[learning rate: 0.0019381]
	Learning Rate: 0.00193807
	LOSS [training: 0.08573619039890745 | validation: 0.21484409481987995]
	TIME [epoch: 56.2 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.084960999040678		[learning rate: 0.0019194]
	Learning Rate: 0.00191937
	LOSS [training: 0.084960999040678 | validation: 0.21555725733501327]
	TIME [epoch: 56.2 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081660007680475		[learning rate: 0.0019008]
	Learning Rate: 0.00190085
	LOSS [training: 0.09081660007680475 | validation: 0.23390673440436588]
	TIME [epoch: 56.1 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863212967042914		[learning rate: 0.0018825]
	Learning Rate: 0.00188251
	LOSS [training: 0.0863212967042914 | validation: 0.21197480101119875]
	TIME [epoch: 56.1 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_210.pth
	Model improved!!!
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08422762026639204		[learning rate: 0.0018643]
	Learning Rate: 0.00186434
	LOSS [training: 0.08422762026639204 | validation: 0.229863516476229]
	TIME [epoch: 56.3 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09659189489774231		[learning rate: 0.0018464]
	Learning Rate: 0.00184636
	LOSS [training: 0.09659189489774231 | validation: 0.22762708804790105]
	TIME [epoch: 56.2 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08708303964688555		[learning rate: 0.0018285]
	Learning Rate: 0.00182854
	LOSS [training: 0.08708303964688555 | validation: 0.22502230485059416]
	TIME [epoch: 56.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872750684326405		[learning rate: 0.0018109]
	Learning Rate: 0.0018109
	LOSS [training: 0.08872750684326405 | validation: 0.21249676436002787]
	TIME [epoch: 56.2 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08261725005037648		[learning rate: 0.0017934]
	Learning Rate: 0.00179343
	LOSS [training: 0.08261725005037648 | validation: 0.21409672965821305]
	TIME [epoch: 56.2 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08735937363619281		[learning rate: 0.0017761]
	Learning Rate: 0.00177613
	LOSS [training: 0.08735937363619281 | validation: 0.2332638270537678]
	TIME [epoch: 56.2 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652969622551392		[learning rate: 0.001759]
	Learning Rate: 0.00175899
	LOSS [training: 0.08652969622551392 | validation: 0.21463556315457835]
	TIME [epoch: 56.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839094855946412		[learning rate: 0.001742]
	Learning Rate: 0.00174202
	LOSS [training: 0.0839094855946412 | validation: 0.22693701858544083]
	TIME [epoch: 56.3 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08827319452622746		[learning rate: 0.0017252]
	Learning Rate: 0.00172521
	LOSS [training: 0.08827319452622746 | validation: 0.22340084905133734]
	TIME [epoch: 56.2 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08747892971355853		[learning rate: 0.0017086]
	Learning Rate: 0.00170857
	LOSS [training: 0.08747892971355853 | validation: 0.2183544312653391]
	TIME [epoch: 56.3 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09427731822274288		[learning rate: 0.0016921]
	Learning Rate: 0.00169208
	LOSS [training: 0.09427731822274288 | validation: 0.22728547050228784]
	TIME [epoch: 56.2 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09072335319200422		[learning rate: 0.0016758]
	Learning Rate: 0.00167575
	LOSS [training: 0.09072335319200422 | validation: 0.22946528723307497]
	TIME [epoch: 56.2 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08181353101376623		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.08181353101376623 | validation: 0.21906456808929586]
	TIME [epoch: 56.2 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853002679395862		[learning rate: 0.0016436]
	Learning Rate: 0.00164357
	LOSS [training: 0.0853002679395862 | validation: 0.21987936452756465]
	TIME [epoch: 56.3 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0806481925936124		[learning rate: 0.0016277]
	Learning Rate: 0.00162772
	LOSS [training: 0.0806481925936124 | validation: 0.2241794369431202]
	TIME [epoch: 56.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341856370704552		[learning rate: 0.001612]
	Learning Rate: 0.00161201
	LOSS [training: 0.09341856370704552 | validation: 0.21568892194768907]
	TIME [epoch: 56.1 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771251351240333		[learning rate: 0.0015965]
	Learning Rate: 0.00159646
	LOSS [training: 0.08771251351240333 | validation: 0.22399128825213585]
	TIME [epoch: 56.2 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08848893114700676		[learning rate: 0.0015811]
	Learning Rate: 0.00158106
	LOSS [training: 0.08848893114700676 | validation: 0.21207725694562357]
	TIME [epoch: 56.2 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08487337218673043		[learning rate: 0.0015658]
	Learning Rate: 0.0015658
	LOSS [training: 0.08487337218673043 | validation: 0.21971884573091405]
	TIME [epoch: 56.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874452699689273		[learning rate: 0.0015507]
	Learning Rate: 0.00155069
	LOSS [training: 0.0874452699689273 | validation: 0.21951184577903107]
	TIME [epoch: 56.2 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08261343009344824		[learning rate: 0.0015357]
	Learning Rate: 0.00153573
	LOSS [training: 0.08261343009344824 | validation: 0.21621224371568598]
	TIME [epoch: 56.2 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09402492999940625		[learning rate: 0.0015209]
	Learning Rate: 0.00152092
	LOSS [training: 0.09402492999940625 | validation: 0.21612147189832315]
	TIME [epoch: 56.2 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09691422868311447		[learning rate: 0.0015062]
	Learning Rate: 0.00150624
	LOSS [training: 0.09691422868311447 | validation: 0.23694798747331192]
	TIME [epoch: 56.2 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09005735380886834		[learning rate: 0.0014917]
	Learning Rate: 0.00149171
	LOSS [training: 0.09005735380886834 | validation: 0.2188309087190404]
	TIME [epoch: 56.2 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09096267395951715		[learning rate: 0.0014773]
	Learning Rate: 0.00147732
	LOSS [training: 0.09096267395951715 | validation: 0.21718143026669162]
	TIME [epoch: 56.3 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08446600823867231		[learning rate: 0.0014631]
	Learning Rate: 0.00146306
	LOSS [training: 0.08446600823867231 | validation: 0.22136406762372013]
	TIME [epoch: 56.3 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08771309687640494		[learning rate: 0.0014489]
	Learning Rate: 0.00144895
	LOSS [training: 0.08771309687640494 | validation: 0.21640391741716242]
	TIME [epoch: 56.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08681844745442778		[learning rate: 0.001435]
	Learning Rate: 0.00143497
	LOSS [training: 0.08681844745442778 | validation: 0.21478718496523938]
	TIME [epoch: 56.2 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09796772069177556		[learning rate: 0.0014211]
	Learning Rate: 0.00142112
	LOSS [training: 0.09796772069177556 | validation: 0.2177166872995468]
	TIME [epoch: 56.2 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09211003229632925		[learning rate: 0.0014074]
	Learning Rate: 0.00140741
	LOSS [training: 0.09211003229632925 | validation: 0.22686745923591736]
	TIME [epoch: 56.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08326028972374333		[learning rate: 0.0013938]
	Learning Rate: 0.00139383
	LOSS [training: 0.08326028972374333 | validation: 0.22184108165297514]
	TIME [epoch: 56.3 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0872784396055859		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.0872784396055859 | validation: 0.22085978592587646]
	TIME [epoch: 56.2 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08022988106038638		[learning rate: 0.0013671]
	Learning Rate: 0.00136707
	LOSS [training: 0.08022988106038638 | validation: 0.21582013225569158]
	TIME [epoch: 56.4 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08139366834594884		[learning rate: 0.0013539]
	Learning Rate: 0.00135388
	LOSS [training: 0.08139366834594884 | validation: 0.22087453730677536]
	TIME [epoch: 56.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738961888286674		[learning rate: 0.0013408]
	Learning Rate: 0.00134081
	LOSS [training: 0.08738961888286674 | validation: 0.21677631914694515]
	TIME [epoch: 56.2 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08743650034424436		[learning rate: 0.0013279]
	Learning Rate: 0.00132788
	LOSS [training: 0.08743650034424436 | validation: 0.2187512528621333]
	TIME [epoch: 56.2 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08821115049539077		[learning rate: 0.0013151]
	Learning Rate: 0.00131507
	LOSS [training: 0.08821115049539077 | validation: 0.21558318019370384]
	TIME [epoch: 56.2 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08635968212149725		[learning rate: 0.0013024]
	Learning Rate: 0.00130238
	LOSS [training: 0.08635968212149725 | validation: 0.22679093624213698]
	TIME [epoch: 56.2 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08499803546087588		[learning rate: 0.0012898]
	Learning Rate: 0.00128981
	LOSS [training: 0.08499803546087588 | validation: 0.2291539922618764]
	TIME [epoch: 56.2 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08553982347232296		[learning rate: 0.0012774]
	Learning Rate: 0.00127737
	LOSS [training: 0.08553982347232296 | validation: 0.22122913867767124]
	TIME [epoch: 56.2 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08048989515779417		[learning rate: 0.001265]
	Learning Rate: 0.00126504
	LOSS [training: 0.08048989515779417 | validation: 0.22484851919290783]
	TIME [epoch: 56.2 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08482687754722294		[learning rate: 0.0012528]
	Learning Rate: 0.00125284
	LOSS [training: 0.08482687754722294 | validation: 0.21936726841533488]
	TIME [epoch: 56.3 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09206673286540815		[learning rate: 0.0012407]
	Learning Rate: 0.00124075
	LOSS [training: 0.09206673286540815 | validation: 0.2166292614368438]
	TIME [epoch: 56.3 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323835007539807		[learning rate: 0.0012288]
	Learning Rate: 0.00122878
	LOSS [training: 0.08323835007539807 | validation: 0.2217689906243668]
	TIME [epoch: 56.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08260625099717857		[learning rate: 0.0012169]
	Learning Rate: 0.00121692
	LOSS [training: 0.08260625099717857 | validation: 0.22374732647216738]
	TIME [epoch: 56.2 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031347085746197		[learning rate: 0.0012052]
	Learning Rate: 0.00120518
	LOSS [training: 0.09031347085746197 | validation: 0.21756127215660614]
	TIME [epoch: 56.2 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08315057457750025		[learning rate: 0.0011936]
	Learning Rate: 0.00119355
	LOSS [training: 0.08315057457750025 | validation: 0.21920060084801823]
	TIME [epoch: 56.3 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08827217740381135		[learning rate: 0.001182]
	Learning Rate: 0.00118204
	LOSS [training: 0.08827217740381135 | validation: 0.2177857904131047]
	TIME [epoch: 56.2 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09528163584221067		[learning rate: 0.0011706]
	Learning Rate: 0.00117063
	LOSS [training: 0.09528163584221067 | validation: 0.22132723954787134]
	TIME [epoch: 56.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09022600868428277		[learning rate: 0.0011593]
	Learning Rate: 0.00115934
	LOSS [training: 0.09022600868428277 | validation: 0.2264481256474116]
	TIME [epoch: 56.2 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08494724920176452		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.08494724920176452 | validation: 0.21824648389355622]
	TIME [epoch: 56.2 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09394429607972317		[learning rate: 0.0011371]
	Learning Rate: 0.00113708
	LOSS [training: 0.09394429607972317 | validation: 0.21899704204079698]
	TIME [epoch: 56.2 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08190504679378646		[learning rate: 0.0011261]
	Learning Rate: 0.00112611
	LOSS [training: 0.08190504679378646 | validation: 0.2167497204844872]
	TIME [epoch: 56.2 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08267194138121724		[learning rate: 0.0011152]
	Learning Rate: 0.00111524
	LOSS [training: 0.08267194138121724 | validation: 0.22172906478902135]
	TIME [epoch: 56.2 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0874673945751209		[learning rate: 0.0011045]
	Learning Rate: 0.00110448
	LOSS [training: 0.0874673945751209 | validation: 0.21809490945013035]
	TIME [epoch: 56.2 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0861037481014061		[learning rate: 0.0010938]
	Learning Rate: 0.00109382
	LOSS [training: 0.0861037481014061 | validation: 0.217132778161326]
	TIME [epoch: 56.3 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08324030187354821		[learning rate: 0.0010833]
	Learning Rate: 0.00108327
	LOSS [training: 0.08324030187354821 | validation: 0.22455423721792298]
	TIME [epoch: 56.3 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915704356798303		[learning rate: 0.0010728]
	Learning Rate: 0.00107282
	LOSS [training: 0.0915704356798303 | validation: 0.22826549949430439]
	TIME [epoch: 56.2 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09329621496011643		[learning rate: 0.0010625]
	Learning Rate: 0.00106247
	LOSS [training: 0.09329621496011643 | validation: 0.21468501862725714]
	TIME [epoch: 56.2 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08048356248986169		[learning rate: 0.0010522]
	Learning Rate: 0.00105222
	LOSS [training: 0.08048356248986169 | validation: 0.22741943368229714]
	TIME [epoch: 56.2 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548168320702718		[learning rate: 0.0010421]
	Learning Rate: 0.00104206
	LOSS [training: 0.08548168320702718 | validation: 0.2198362989390602]
	TIME [epoch: 56.2 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580690627060503		[learning rate: 0.001032]
	Learning Rate: 0.00103201
	LOSS [training: 0.08580690627060503 | validation: 0.21836016522625937]
	TIME [epoch: 56.1 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08615606309969534		[learning rate: 0.0010221]
	Learning Rate: 0.00102205
	LOSS [training: 0.08615606309969534 | validation: 0.21081762684611177]
	TIME [epoch: 56.3 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_273.pth
	Model improved!!!
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08480407564059003		[learning rate: 0.0010122]
	Learning Rate: 0.00101219
	LOSS [training: 0.08480407564059003 | validation: 0.21565895774571195]
	TIME [epoch: 56.2 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09558664457653863		[learning rate: 0.0010024]
	Learning Rate: 0.00100243
	LOSS [training: 0.09558664457653863 | validation: 0.2138674780437705]
	TIME [epoch: 56.2 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08527592540105601		[learning rate: 0.00099275]
	Learning Rate: 0.000992755
	LOSS [training: 0.08527592540105601 | validation: 0.22061417723939114]
	TIME [epoch: 56.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776786092192279		[learning rate: 0.00098318]
	Learning Rate: 0.000983177
	LOSS [training: 0.0776786092192279 | validation: 0.21518160976912043]
	TIME [epoch: 56.2 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08218007626526963		[learning rate: 0.00097369]
	Learning Rate: 0.000973691
	LOSS [training: 0.08218007626526963 | validation: 0.22310838044297213]
	TIME [epoch: 56.2 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09518829717043573		[learning rate: 0.0009643]
	Learning Rate: 0.000964296
	LOSS [training: 0.09518829717043573 | validation: 0.21587131736076895]
	TIME [epoch: 56.3 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08552052063612935		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.08552052063612935 | validation: 0.2145481204154966]
	TIME [epoch: 56.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09197451682601214		[learning rate: 0.00094578]
	Learning Rate: 0.000945779
	LOSS [training: 0.09197451682601214 | validation: 0.2241728536633817]
	TIME [epoch: 56.2 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09137017159676039		[learning rate: 0.00093665]
	Learning Rate: 0.000936653
	LOSS [training: 0.09137017159676039 | validation: 0.2153099516685294]
	TIME [epoch: 56.2 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832615243210821		[learning rate: 0.00092762]
	Learning Rate: 0.000927616
	LOSS [training: 0.0832615243210821 | validation: 0.2203242228311409]
	TIME [epoch: 56.2 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08972309340449307		[learning rate: 0.00091867]
	Learning Rate: 0.000918666
	LOSS [training: 0.08972309340449307 | validation: 0.21528833742736742]
	TIME [epoch: 56.2 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08415032671982764		[learning rate: 0.0009098]
	Learning Rate: 0.000909803
	LOSS [training: 0.08415032671982764 | validation: 0.22649974165836306]
	TIME [epoch: 56.1 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0939814734003075		[learning rate: 0.00090102]
	Learning Rate: 0.000901025
	LOSS [training: 0.0939814734003075 | validation: 0.21562882586707174]
	TIME [epoch: 56.3 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08723412246032591		[learning rate: 0.00089233]
	Learning Rate: 0.000892332
	LOSS [training: 0.08723412246032591 | validation: 0.21843731340717984]
	TIME [epoch: 56.2 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08752393412264804		[learning rate: 0.00088372]
	Learning Rate: 0.000883722
	LOSS [training: 0.08752393412264804 | validation: 0.22097951797816118]
	TIME [epoch: 56.2 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08075924866112866		[learning rate: 0.0008752]
	Learning Rate: 0.000875196
	LOSS [training: 0.08075924866112866 | validation: 0.2208230768455022]
	TIME [epoch: 56.2 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977447638893826		[learning rate: 0.00086675]
	Learning Rate: 0.000866752
	LOSS [training: 0.09977447638893826 | validation: 0.20999726680547537]
	TIME [epoch: 56.3 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_290.pth
	Model improved!!!
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642145006747962		[learning rate: 0.00085839]
	Learning Rate: 0.000858389
	LOSS [training: 0.08642145006747962 | validation: 0.21744595134149733]
	TIME [epoch: 56.2 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08263858076129266		[learning rate: 0.00085011]
	Learning Rate: 0.000850107
	LOSS [training: 0.08263858076129266 | validation: 0.22097780919512403]
	TIME [epoch: 56.1 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997303887198717		[learning rate: 0.00084191]
	Learning Rate: 0.000841905
	LOSS [training: 0.08997303887198717 | validation: 0.2166122542922158]
	TIME [epoch: 56.1 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08484092652384595		[learning rate: 0.00083378]
	Learning Rate: 0.000833782
	LOSS [training: 0.08484092652384595 | validation: 0.21790072724114873]
	TIME [epoch: 56.2 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108409332875684		[learning rate: 0.00082574]
	Learning Rate: 0.000825738
	LOSS [training: 0.08108409332875684 | validation: 0.22310626434563732]
	TIME [epoch: 56.2 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0829300367913158		[learning rate: 0.00081777]
	Learning Rate: 0.000817771
	LOSS [training: 0.0829300367913158 | validation: 0.21903670813073162]
	TIME [epoch: 56.2 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08811502050075329		[learning rate: 0.00080988]
	Learning Rate: 0.000809881
	LOSS [training: 0.08811502050075329 | validation: 0.21529304244820827]
	TIME [epoch: 56.1 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08558441192862003		[learning rate: 0.00080207]
	Learning Rate: 0.000802067
	LOSS [training: 0.08558441192862003 | validation: 0.22266242680268716]
	TIME [epoch: 56.1 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08608569550567062		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.08608569550567062 | validation: 0.21919727390376031]
	TIME [epoch: 56.1 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902416799163008		[learning rate: 0.00078666]
	Learning Rate: 0.000786664
	LOSS [training: 0.08902416799163008 | validation: 0.21819494067314602]
	TIME [epoch: 56.1 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08814489596109235		[learning rate: 0.00077907]
	Learning Rate: 0.000779074
	LOSS [training: 0.08814489596109235 | validation: 0.2145865848967527]
	TIME [epoch: 162 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08493396611719854		[learning rate: 0.00077156]
	Learning Rate: 0.000771558
	LOSS [training: 0.08493396611719854 | validation: 0.22043721911352301]
	TIME [epoch: 115 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08517608493578945		[learning rate: 0.00076411]
	Learning Rate: 0.000764113
	LOSS [training: 0.08517608493578945 | validation: 0.2203806304166655]
	TIME [epoch: 115 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069844749921118		[learning rate: 0.00075674]
	Learning Rate: 0.000756741
	LOSS [training: 0.08069844749921118 | validation: 0.2128461829572167]
	TIME [epoch: 115 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1014789597205967		[learning rate: 0.00074944]
	Learning Rate: 0.00074944
	LOSS [training: 0.1014789597205967 | validation: 0.21347724455411715]
	TIME [epoch: 115 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08971444803336799		[learning rate: 0.00074221]
	Learning Rate: 0.000742209
	LOSS [training: 0.08971444803336799 | validation: 0.21640872187748977]
	TIME [epoch: 115 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285682168725629		[learning rate: 0.00073505]
	Learning Rate: 0.000735048
	LOSS [training: 0.08285682168725629 | validation: 0.2191766050054016]
	TIME [epoch: 115 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09126522415364308		[learning rate: 0.00072796]
	Learning Rate: 0.000727956
	LOSS [training: 0.09126522415364308 | validation: 0.21794535175680171]
	TIME [epoch: 115 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08415056711011278		[learning rate: 0.00072093]
	Learning Rate: 0.000720933
	LOSS [training: 0.08415056711011278 | validation: 0.21415413954791176]
	TIME [epoch: 115 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08355336478765314		[learning rate: 0.00071398]
	Learning Rate: 0.000713977
	LOSS [training: 0.08355336478765314 | validation: 0.22217894551220377]
	TIME [epoch: 115 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08902973843412741		[learning rate: 0.00070709]
	Learning Rate: 0.000707088
	LOSS [training: 0.08902973843412741 | validation: 0.21999646869803346]
	TIME [epoch: 115 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08270352145726281		[learning rate: 0.00070027]
	Learning Rate: 0.000700266
	LOSS [training: 0.08270352145726281 | validation: 0.2103706688430058]
	TIME [epoch: 115 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09108789983044104		[learning rate: 0.00069351]
	Learning Rate: 0.00069351
	LOSS [training: 0.09108789983044104 | validation: 0.2142465406215467]
	TIME [epoch: 115 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0885864638549934		[learning rate: 0.00068682]
	Learning Rate: 0.000686819
	LOSS [training: 0.0885864638549934 | validation: 0.22378184804148704]
	TIME [epoch: 115 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09311163083147254		[learning rate: 0.00068019]
	Learning Rate: 0.000680192
	LOSS [training: 0.09311163083147254 | validation: 0.21776534310189355]
	TIME [epoch: 115 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08082698678630279		[learning rate: 0.00067363]
	Learning Rate: 0.000673629
	LOSS [training: 0.08082698678630279 | validation: 0.21925095729114702]
	TIME [epoch: 115 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08824223684089777		[learning rate: 0.00066713]
	Learning Rate: 0.00066713
	LOSS [training: 0.08824223684089777 | validation: 0.2190240864119934]
	TIME [epoch: 115 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222017980697878		[learning rate: 0.00066069]
	Learning Rate: 0.000660693
	LOSS [training: 0.08222017980697878 | validation: 0.21492169438418743]
	TIME [epoch: 115 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08832764160032927		[learning rate: 0.00065432]
	Learning Rate: 0.000654319
	LOSS [training: 0.08832764160032927 | validation: 0.21146669850365113]
	TIME [epoch: 115 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08363784206176757		[learning rate: 0.00064801]
	Learning Rate: 0.000648006
	LOSS [training: 0.08363784206176757 | validation: 0.20682780481165242]
	TIME [epoch: 115 sec]
	Saving model to: out/model_training/model_facs_dec2_v2_argset3_20241031_142703/states/model_facs_dec2_v2_argset3_320.pth
	Model improved!!!
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08555031307352809		[learning rate: 0.00064175]
	Learning Rate: 0.000641754
	LOSS [training: 0.08555031307352809 | validation: 0.2155102240675958]
	TIME [epoch: 115 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08734926217786931		[learning rate: 0.00063556]
	Learning Rate: 0.000635562
	LOSS [training: 0.08734926217786931 | validation: 0.22380259700056546]
	TIME [epoch: 115 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323844428699169		[learning rate: 0.00062943]
	Learning Rate: 0.00062943
	LOSS [training: 0.08323844428699169 | validation: 0.2168499332575419]
	TIME [epoch: 114 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08009068601517584		[learning rate: 0.00062336]
	Learning Rate: 0.000623357
	LOSS [training: 0.08009068601517584 | validation: 0.21103597338626734]
	TIME [epoch: 115 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09518988044480828		[learning rate: 0.00061734]
	Learning Rate: 0.000617343
	LOSS [training: 0.09518988044480828 | validation: 0.21760419925787708]
	TIME [epoch: 115 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08900574382157443		[learning rate: 0.00061139]
	Learning Rate: 0.000611386
	LOSS [training: 0.08900574382157443 | validation: 0.21622169215289122]
	TIME [epoch: 115 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200352340090111		[learning rate: 0.00060549]
	Learning Rate: 0.000605487
	LOSS [training: 0.08200352340090111 | validation: 0.21376262034762272]
	TIME [epoch: 115 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08930906807829084		[learning rate: 0.00059965]
	Learning Rate: 0.000599646
	LOSS [training: 0.08930906807829084 | validation: 0.2206448955694042]
	TIME [epoch: 115 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08646243712159984		[learning rate: 0.00059386]
	Learning Rate: 0.00059386
	LOSS [training: 0.08646243712159984 | validation: 0.21703750607578026]
	TIME [epoch: 115 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08451185411614666		[learning rate: 0.00058813]
	Learning Rate: 0.00058813
	LOSS [training: 0.08451185411614666 | validation: 0.21791780364551927]
	TIME [epoch: 115 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915643250341576		[learning rate: 0.00058246]
	Learning Rate: 0.000582456
	LOSS [training: 0.0915643250341576 | validation: 0.21706653369499113]
	TIME [epoch: 115 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08223939006628173		[learning rate: 0.00057684]
	Learning Rate: 0.000576836
	LOSS [training: 0.08223939006628173 | validation: 0.21451842183863815]
	TIME [epoch: 115 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08211806478326433		[learning rate: 0.00057127]
	Learning Rate: 0.000571271
	LOSS [training: 0.08211806478326433 | validation: 0.21696739504951118]
	TIME [epoch: 115 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09859839943287987		[learning rate: 0.00056576]
	Learning Rate: 0.000565759
	LOSS [training: 0.09859839943287987 | validation: 0.2145377646574063]
	TIME [epoch: 115 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730352293533616		[learning rate: 0.0005603]
	Learning Rate: 0.0005603
	LOSS [training: 0.08730352293533616 | validation: 0.21464904248254107]
	TIME [epoch: 115 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08662052551792186		[learning rate: 0.00055489]
	Learning Rate: 0.000554895
	LOSS [training: 0.08662052551792186 | validation: 0.21812518211214932]
	TIME [epoch: 115 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08761407391303357		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.08761407391303357 | validation: 0.2166643578044162]
	TIME [epoch: 115 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08173664684166065		[learning rate: 0.00054424]
	Learning Rate: 0.000544239
	LOSS [training: 0.08173664684166065 | validation: 0.21258679526549776]
	TIME [epoch: 115 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274271477767427		[learning rate: 0.00053899]
	Learning Rate: 0.000538988
	LOSS [training: 0.08274271477767427 | validation: 0.21705292105897317]
	TIME [epoch: 115 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375650463371285		[learning rate: 0.00053379]
	Learning Rate: 0.000533787
	LOSS [training: 0.09375650463371285 | validation: 0.2176510213746328]
	TIME [epoch: 115 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08581313675787841		[learning rate: 0.00052864]
	Learning Rate: 0.000528637
	LOSS [training: 0.08581313675787841 | validation: 0.21057794307116748]
	TIME [epoch: 115 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09071753398948929		[learning rate: 0.00052354]
	Learning Rate: 0.000523537
	LOSS [training: 0.09071753398948929 | validation: 0.21313083193980797]
	TIME [epoch: 115 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09467560171984582		[learning rate: 0.00051849]
	Learning Rate: 0.000518486
	LOSS [training: 0.09467560171984582 | validation: 0.21640711629002893]
	TIME [epoch: 115 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419373690611614		[learning rate: 0.00051348]
	Learning Rate: 0.000513483
	LOSS [training: 0.09419373690611614 | validation: 0.217967369548118]
	TIME [epoch: 115 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08374703658153904		[learning rate: 0.00050853]
	Learning Rate: 0.000508529
	LOSS [training: 0.08374703658153904 | validation: 0.21953794415591843]
	TIME [epoch: 115 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08426518871264421		[learning rate: 0.00050362]
	Learning Rate: 0.000503623
	LOSS [training: 0.08426518871264421 | validation: 0.21331173008079768]
	TIME [epoch: 115 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873200156543254		[learning rate: 0.00049876]
	Learning Rate: 0.000498764
	LOSS [training: 0.0873200156543254 | validation: 0.21173611035273587]
	TIME [epoch: 115 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08437451676027227		[learning rate: 0.00049395]
	Learning Rate: 0.000493951
	LOSS [training: 0.08437451676027227 | validation: 0.21646705510011066]
	TIME [epoch: 115 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08005968293565799		[learning rate: 0.00048919]
	Learning Rate: 0.000489186
	LOSS [training: 0.08005968293565799 | validation: 0.2114978294340195]
	TIME [epoch: 115 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809727195307425		[learning rate: 0.00048447]
	Learning Rate: 0.000484466
	LOSS [training: 0.0809727195307425 | validation: 0.21293932916058425]
	TIME [epoch: 115 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08100143410080438		[learning rate: 0.00047979]
	Learning Rate: 0.000479792
	LOSS [training: 0.08100143410080438 | validation: 0.2123628743696625]
	TIME [epoch: 115 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148938535806301		[learning rate: 0.00047516]
	Learning Rate: 0.000475162
	LOSS [training: 0.08148938535806301 | validation: 0.21244080180462716]
	TIME [epoch: 115 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09331872684941217		[learning rate: 0.00047058]
	Learning Rate: 0.000470578
	LOSS [training: 0.09331872684941217 | validation: 0.21277577125779307]
	TIME [epoch: 115 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358637722586448		[learning rate: 0.00046604]
	Learning Rate: 0.000466038
	LOSS [training: 0.08358637722586448 | validation: 0.2126259137154511]
	TIME [epoch: 115 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08230960554730583		[learning rate: 0.00046154]
	Learning Rate: 0.000461541
	LOSS [training: 0.08230960554730583 | validation: 0.21761975448206622]
	TIME [epoch: 115 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08133927912945724		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.08133927912945724 | validation: 0.2120805634377037]
	TIME [epoch: 115 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592975414383469		[learning rate: 0.00045268]
	Learning Rate: 0.000452678
	LOSS [training: 0.08592975414383469 | validation: 0.2098211096863188]
	TIME [epoch: 115 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08877290024572074		[learning rate: 0.00044831]
	Learning Rate: 0.00044831
	LOSS [training: 0.08877290024572074 | validation: 0.2191839824063116]
	TIME [epoch: 115 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08129234056139996		[learning rate: 0.00044399]
	Learning Rate: 0.000443985
	LOSS [training: 0.08129234056139996 | validation: 0.214695888411363]
	TIME [epoch: 115 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08665062238784955		[learning rate: 0.0004397]
	Learning Rate: 0.000439701
	LOSS [training: 0.08665062238784955 | validation: 0.21579963207017233]
	TIME [epoch: 115 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08341716192807101		[learning rate: 0.00043546]
	Learning Rate: 0.000435459
	LOSS [training: 0.08341716192807101 | validation: 0.21715335079560077]
	TIME [epoch: 115 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0826916611562062		[learning rate: 0.00043126]
	Learning Rate: 0.000431258
	LOSS [training: 0.0826916611562062 | validation: 0.2182814845534535]
	TIME [epoch: 115 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08350115422047041		[learning rate: 0.0004271]
	Learning Rate: 0.000427097
	LOSS [training: 0.08350115422047041 | validation: 0.2146013806327926]
	TIME [epoch: 115 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09174840227348892		[learning rate: 0.00042298]
	Learning Rate: 0.000422976
	LOSS [training: 0.09174840227348892 | validation: 0.21525291147266282]
	TIME [epoch: 115 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642275934621993		[learning rate: 0.0004189]
	Learning Rate: 0.000418895
	LOSS [training: 0.08642275934621993 | validation: 0.21381578722565742]
	TIME [epoch: 115 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08851645449137217		[learning rate: 0.00041485]
	Learning Rate: 0.000414853
	LOSS [training: 0.08851645449137217 | validation: 0.21035430180034992]
	TIME [epoch: 115 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07902452999813672		[learning rate: 0.00041085]
	Learning Rate: 0.000410851
	LOSS [training: 0.07902452999813672 | validation: 0.2145889352155323]
	TIME [epoch: 115 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08628326128237757		[learning rate: 0.00040689]
	Learning Rate: 0.000406887
	LOSS [training: 0.08628326128237757 | validation: 0.21869604743614193]
	TIME [epoch: 115 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0865833608676347		[learning rate: 0.00040296]
	Learning Rate: 0.000402961
	LOSS [training: 0.0865833608676347 | validation: 0.21733269856220083]
	TIME [epoch: 115 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832466518722687		[learning rate: 0.00039907]
	Learning Rate: 0.000399073
	LOSS [training: 0.07832466518722687 | validation: 0.21689273158544933]
	TIME [epoch: 115 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0929749611354043		[learning rate: 0.00039522]
	Learning Rate: 0.000395223
	LOSS [training: 0.0929749611354043 | validation: 0.21874620003664286]
	TIME [epoch: 115 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0832151492562857		[learning rate: 0.00039141]
	Learning Rate: 0.00039141
	LOSS [training: 0.0832151492562857 | validation: 0.2202821309149261]
	TIME [epoch: 115 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08529691302328496		[learning rate: 0.00038763]
	Learning Rate: 0.000387633
	LOSS [training: 0.08529691302328496 | validation: 0.21887025160466209]
	TIME [epoch: 115 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08870544056806745		[learning rate: 0.00038389]
	Learning Rate: 0.000383893
	LOSS [training: 0.08870544056806745 | validation: 0.2161131460815618]
	TIME [epoch: 115 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09064755768024156		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.09064755768024156 | validation: 0.2122195636429125]
	TIME [epoch: 115 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08874918488190792		[learning rate: 0.00037652]
	Learning Rate: 0.000376521
	LOSS [training: 0.08874918488190792 | validation: 0.21285160555866503]
	TIME [epoch: 115 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09532287953750593		[learning rate: 0.00037289]
	Learning Rate: 0.000372888
	LOSS [training: 0.09532287953750593 | validation: 0.2159655673451741]
	TIME [epoch: 115 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0828185691311064		[learning rate: 0.00036929]
	Learning Rate: 0.000369291
	LOSS [training: 0.0828185691311064 | validation: 0.21359860826085592]
	TIME [epoch: 115 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08590807389454189		[learning rate: 0.00036573]
	Learning Rate: 0.000365728
	LOSS [training: 0.08590807389454189 | validation: 0.2150486216674533]
	TIME [epoch: 115 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08468462931144871		[learning rate: 0.0003622]
	Learning Rate: 0.000362199
	LOSS [training: 0.08468462931144871 | validation: 0.2155661148433707]
	TIME [epoch: 115 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08394632087630428		[learning rate: 0.0003587]
	Learning Rate: 0.000358705
	LOSS [training: 0.08394632087630428 | validation: 0.21816755135061863]
	TIME [epoch: 115 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08071271462299011		[learning rate: 0.00035524]
	Learning Rate: 0.000355244
	LOSS [training: 0.08071271462299011 | validation: 0.2166355351373403]
	TIME [epoch: 115 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0809132969685431		[learning rate: 0.00035182]
	Learning Rate: 0.000351816
	LOSS [training: 0.0809132969685431 | validation: 0.21286628226404364]
	TIME [epoch: 115 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08880572875996898		[learning rate: 0.00034842]
	Learning Rate: 0.000348422
	LOSS [training: 0.08880572875996898 | validation: 0.2135211694352187]
	TIME [epoch: 115 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08447319151802879		[learning rate: 0.00034506]
	Learning Rate: 0.00034506
	LOSS [training: 0.08447319151802879 | validation: 0.21123312602381097]
	TIME [epoch: 115 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08718445652012907		[learning rate: 0.00034173]
	Learning Rate: 0.000341731
	LOSS [training: 0.08718445652012907 | validation: 0.21468493703016656]
	TIME [epoch: 115 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639518277512302		[learning rate: 0.00033843]
	Learning Rate: 0.000338434
	LOSS [training: 0.08639518277512302 | validation: 0.21282385589886677]
	TIME [epoch: 115 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08596451174159628		[learning rate: 0.00033517]
	Learning Rate: 0.000335168
	LOSS [training: 0.08596451174159628 | validation: 0.21846212409028903]
	TIME [epoch: 115 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08330760340190967		[learning rate: 0.00033193]
	Learning Rate: 0.000331935
	LOSS [training: 0.08330760340190967 | validation: 0.21354141376432118]
	TIME [epoch: 115 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08301344257212002		[learning rate: 0.00032873]
	Learning Rate: 0.000328732
	LOSS [training: 0.08301344257212002 | validation: 0.21409778668919527]
	TIME [epoch: 115 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131149531399934		[learning rate: 0.00032556]
	Learning Rate: 0.00032556
	LOSS [training: 0.08131149531399934 | validation: 0.21623654196992784]
	TIME [epoch: 115 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09024693232331875		[learning rate: 0.00032242]
	Learning Rate: 0.000322419
	LOSS [training: 0.09024693232331875 | validation: 0.2107258798081461]
	TIME [epoch: 115 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08252120519925422		[learning rate: 0.00031931]
	Learning Rate: 0.000319308
	LOSS [training: 0.08252120519925422 | validation: 0.21426735538082245]
	TIME [epoch: 115 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08586617345585348		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.08586617345585348 | validation: 0.2149467174399626]
	TIME [epoch: 115 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08174083242528248		[learning rate: 0.00031318]
	Learning Rate: 0.000313177
	LOSS [training: 0.08174083242528248 | validation: 0.21387646309737868]
	TIME [epoch: 115 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887854119456981		[learning rate: 0.00031016]
	Learning Rate: 0.000310155
	LOSS [training: 0.0887854119456981 | validation: 0.21687687584195528]
	TIME [epoch: 115 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07892444799579904		[learning rate: 0.00030716]
	Learning Rate: 0.000307163
	LOSS [training: 0.07892444799579904 | validation: 0.22145125353861017]
	TIME [epoch: 115 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08420138221682572		[learning rate: 0.0003042]
	Learning Rate: 0.000304199
	LOSS [training: 0.08420138221682572 | validation: 0.212597769221348]
	TIME [epoch: 115 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08727920502136467		[learning rate: 0.00030126]
	Learning Rate: 0.000301264
	LOSS [training: 0.08727920502136467 | validation: 0.21481719395310025]
	TIME [epoch: 115 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09608764594455935		[learning rate: 0.00029836]
	Learning Rate: 0.000298357
	LOSS [training: 0.09608764594455935 | validation: 0.21063401203848503]
	TIME [epoch: 115 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08754279050941416		[learning rate: 0.00029548]
	Learning Rate: 0.000295479
	LOSS [training: 0.08754279050941416 | validation: 0.21591268518142823]
	TIME [epoch: 115 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582583348911499		[learning rate: 0.00029263]
	Learning Rate: 0.000292628
	LOSS [training: 0.08582583348911499 | validation: 0.21514135871928797]
	TIME [epoch: 115 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07920823021741748		[learning rate: 0.0002898]
	Learning Rate: 0.000289805
	LOSS [training: 0.07920823021741748 | validation: 0.2120855401943408]
	TIME [epoch: 115 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07985834475468818		[learning rate: 0.00028701]
	Learning Rate: 0.000287008
	LOSS [training: 0.07985834475468818 | validation: 0.20863630464766372]
	TIME [epoch: 115 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824875599262116		[learning rate: 0.00028424]
	Learning Rate: 0.000284239
	LOSS [training: 0.0824875599262116 | validation: 0.21465178790647998]
	TIME [epoch: 115 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08655946904564718		[learning rate: 0.0002815]
	Learning Rate: 0.000281497
	LOSS [training: 0.08655946904564718 | validation: 0.2157806201106587]
	TIME [epoch: 115 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069455828010717		[learning rate: 0.00027878]
	Learning Rate: 0.000278781
	LOSS [training: 0.08069455828010717 | validation: 0.21319149921637018]
	TIME [epoch: 115 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774562882726954		[learning rate: 0.00027609]
	Learning Rate: 0.000276091
	LOSS [training: 0.0774562882726954 | validation: 0.21614049327435797]
	TIME [epoch: 115 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681853772406623		[learning rate: 0.00027343]
	Learning Rate: 0.000273427
	LOSS [training: 0.09681853772406623 | validation: 0.21746352731725332]
	TIME [epoch: 115 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07729400069987535		[learning rate: 0.00027079]
	Learning Rate: 0.000270789
	LOSS [training: 0.07729400069987535 | validation: 0.21924555027694712]
	TIME [epoch: 115 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643687091973293		[learning rate: 0.00026818]
	Learning Rate: 0.000268177
	LOSS [training: 0.08643687091973293 | validation: 0.21966693501983858]
	TIME [epoch: 115 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08321054018783845		[learning rate: 0.00026559]
	Learning Rate: 0.000265589
	LOSS [training: 0.08321054018783845 | validation: 0.215381240668364]
	TIME [epoch: 115 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994992582424114		[learning rate: 0.00026303]
	Learning Rate: 0.000263027
	LOSS [training: 0.07994992582424114 | validation: 0.20983863096316174]
	TIME [epoch: 115 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08323453405008809		[learning rate: 0.00026049]
	Learning Rate: 0.000260489
	LOSS [training: 0.08323453405008809 | validation: 0.21313421098689234]
	TIME [epoch: 115 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295652377514864		[learning rate: 0.00025798]
	Learning Rate: 0.000257976
	LOSS [training: 0.08295652377514864 | validation: 0.2140824979769682]
	TIME [epoch: 115 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592269951730748		[learning rate: 0.00025549]
	Learning Rate: 0.000255487
	LOSS [training: 0.08592269951730748 | validation: 0.21537381709895922]
	TIME [epoch: 115 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08402265904704463		[learning rate: 0.00025302]
	Learning Rate: 0.000253022
	LOSS [training: 0.08402265904704463 | validation: 0.214544506209293]
	TIME [epoch: 115 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984962537058805		[learning rate: 0.00025058]
	Learning Rate: 0.00025058
	LOSS [training: 0.08984962537058805 | validation: 0.21419277161166272]
	TIME [epoch: 115 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08557041661002926		[learning rate: 0.00024816]
	Learning Rate: 0.000248163
	LOSS [training: 0.08557041661002926 | validation: 0.21541379471341993]
	TIME [epoch: 115 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09089939056498665		[learning rate: 0.00024577]
	Learning Rate: 0.000245768
	LOSS [training: 0.09089939056498665 | validation: 0.21095058988831403]
	TIME [epoch: 115 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0853491465291232		[learning rate: 0.0002434]
	Learning Rate: 0.000243397
	LOSS [training: 0.0853491465291232 | validation: 0.21239009088636518]
	TIME [epoch: 115 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782133734992326		[learning rate: 0.00024105]
	Learning Rate: 0.000241049
	LOSS [training: 0.0782133734992326 | validation: 0.21555236645220807]
	TIME [epoch: 115 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08599799910987597		[learning rate: 0.00023872]
	Learning Rate: 0.000238723
	LOSS [training: 0.08599799910987597 | validation: 0.21194230563687902]
	TIME [epoch: 115 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274886917825514		[learning rate: 0.00023642]
	Learning Rate: 0.00023642
	LOSS [training: 0.08274886917825514 | validation: 0.21200111121344914]
	TIME [epoch: 115 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08763401024932534		[learning rate: 0.00023414]
	Learning Rate: 0.000234139
	LOSS [training: 0.08763401024932534 | validation: 0.2123627419566167]
	TIME [epoch: 115 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653658908288203		[learning rate: 0.00023188]
	Learning Rate: 0.00023188
	LOSS [training: 0.08653658908288203 | validation: 0.21549454657401673]
	TIME [epoch: 115 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928086441341221		[learning rate: 0.00022964]
	Learning Rate: 0.000229643
	LOSS [training: 0.08928086441341221 | validation: 0.21554763294599144]
	TIME [epoch: 115 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09007923514060479		[learning rate: 0.00022743]
	Learning Rate: 0.000227427
	LOSS [training: 0.09007923514060479 | validation: 0.2138716232001463]
	TIME [epoch: 115 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08380890576642339		[learning rate: 0.00022523]
	Learning Rate: 0.000225233
	LOSS [training: 0.08380890576642339 | validation: 0.21153626054402372]
	TIME [epoch: 115 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08335150317840727		[learning rate: 0.00022306]
	Learning Rate: 0.00022306
	LOSS [training: 0.08335150317840727 | validation: 0.217833929751299]
	TIME [epoch: 115 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08025518319724904		[learning rate: 0.00022091]
	Learning Rate: 0.000220908
	LOSS [training: 0.08025518319724904 | validation: 0.2150842090050817]
	TIME [epoch: 115 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08637314401823659		[learning rate: 0.00021878]
	Learning Rate: 0.000218776
	LOSS [training: 0.08637314401823659 | validation: 0.2135071001838226]
	TIME [epoch: 114 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07957831819766281		[learning rate: 0.00021667]
	Learning Rate: 0.000216665
	LOSS [training: 0.07957831819766281 | validation: 0.2135276199344785]
	TIME [epoch: 115 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08284646934726927		[learning rate: 0.00021457]
	Learning Rate: 0.000214575
	LOSS [training: 0.08284646934726927 | validation: 0.21219978680507634]
	TIME [epoch: 115 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482387395518513		[learning rate: 0.0002125]
	Learning Rate: 0.000212505
	LOSS [training: 0.09482387395518513 | validation: 0.2114113176315249]
	TIME [epoch: 115 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08488951939972299		[learning rate: 0.00021045]
	Learning Rate: 0.000210454
	LOSS [training: 0.08488951939972299 | validation: 0.21221665712541504]
	TIME [epoch: 115 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157083708422197		[learning rate: 0.00020842]
	Learning Rate: 0.000208424
	LOSS [training: 0.08157083708422197 | validation: 0.21104014922795666]
	TIME [epoch: 114 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08789328980162305		[learning rate: 0.00020641]
	Learning Rate: 0.000206413
	LOSS [training: 0.08789328980162305 | validation: 0.21745375590619495]
	TIME [epoch: 115 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08753477981792683		[learning rate: 0.00020442]
	Learning Rate: 0.000204421
	LOSS [training: 0.08753477981792683 | validation: 0.20952398194425376]
	TIME [epoch: 114 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285084117720252		[learning rate: 0.00020245]
	Learning Rate: 0.000202449
	LOSS [training: 0.08285084117720252 | validation: 0.2104073982273041]
	TIME [epoch: 115 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09415659564426176		[learning rate: 0.0002005]
	Learning Rate: 0.000200496
	LOSS [training: 0.09415659564426176 | validation: 0.2134430849698131]
	TIME [epoch: 114 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08244974213533261		[learning rate: 0.00019856]
	Learning Rate: 0.000198561
	LOSS [training: 0.08244974213533261 | validation: 0.21248902384198157]
	TIME [epoch: 115 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358209498063467		[learning rate: 0.00019665]
	Learning Rate: 0.000196646
	LOSS [training: 0.08358209498063467 | validation: 0.21231817481889745]
	TIME [epoch: 114 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274084572298959		[learning rate: 0.00019475]
	Learning Rate: 0.000194748
	LOSS [training: 0.08274084572298959 | validation: 0.210558306428198]
	TIME [epoch: 115 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0834684499051434		[learning rate: 0.00019287]
	Learning Rate: 0.000192869
	LOSS [training: 0.0834684499051434 | validation: 0.21765990060345136]
	TIME [epoch: 115 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919392205712551		[learning rate: 0.00019101]
	Learning Rate: 0.000191008
	LOSS [training: 0.07919392205712551 | validation: 0.21589063134288636]
	TIME [epoch: 115 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09590640605215953		[learning rate: 0.00018917]
	Learning Rate: 0.000189166
	LOSS [training: 0.09590640605215953 | validation: 0.21346798660846333]
	TIME [epoch: 114 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08257810725829921		[learning rate: 0.00018734]
	Learning Rate: 0.00018734
	LOSS [training: 0.08257810725829921 | validation: 0.21195023963483628]
	TIME [epoch: 115 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09171073704360995		[learning rate: 0.00018553]
	Learning Rate: 0.000185533
	LOSS [training: 0.09171073704360995 | validation: 0.2146669041743159]
	TIME [epoch: 114 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148127523530845		[learning rate: 0.00018374]
	Learning Rate: 0.000183743
	LOSS [training: 0.08148127523530845 | validation: 0.216836848141326]
	TIME [epoch: 115 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08882018603008068		[learning rate: 0.00018197]
	Learning Rate: 0.00018197
	LOSS [training: 0.08882018603008068 | validation: 0.2085037215481145]
	TIME [epoch: 114 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07851333313157205		[learning rate: 0.00018021]
	Learning Rate: 0.000180214
	LOSS [training: 0.07851333313157205 | validation: 0.21300627276065962]
	TIME [epoch: 115 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09639377304858054		[learning rate: 0.00017848]
	Learning Rate: 0.000178476
	LOSS [training: 0.09639377304858054 | validation: 0.20853102252374967]
	TIME [epoch: 114 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0818711236807544		[learning rate: 0.00017675]
	Learning Rate: 0.000176754
	LOSS [training: 0.0818711236807544 | validation: 0.20894132543354565]
	TIME [epoch: 115 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.088034399181952		[learning rate: 0.00017505]
	Learning Rate: 0.000175048
	LOSS [training: 0.088034399181952 | validation: 0.21286276756825878]
	TIME [epoch: 114 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08206840368213839		[learning rate: 0.00017336]
	Learning Rate: 0.000173359
	LOSS [training: 0.08206840368213839 | validation: 0.2157463466531363]
	TIME [epoch: 115 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08419901300501231		[learning rate: 0.00017169]
	Learning Rate: 0.000171687
	LOSS [training: 0.08419901300501231 | validation: 0.215888913970728]
	TIME [epoch: 114 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08830105776422215		[learning rate: 0.00017003]
	Learning Rate: 0.00017003
	LOSS [training: 0.08830105776422215 | validation: 0.21761801455874608]
	TIME [epoch: 115 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532018321058574		[learning rate: 0.00016839]
	Learning Rate: 0.00016839
	LOSS [training: 0.08532018321058574 | validation: 0.21336800770454495]
	TIME [epoch: 114 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07602461842123155		[learning rate: 0.00016677]
	Learning Rate: 0.000166765
	LOSS [training: 0.07602461842123155 | validation: 0.2127612455711904]
	TIME [epoch: 114 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09163612819197718		[learning rate: 0.00016516]
	Learning Rate: 0.000165156
	LOSS [training: 0.09163612819197718 | validation: 0.21188421584675043]
	TIME [epoch: 114 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08429951817524889		[learning rate: 0.00016356]
	Learning Rate: 0.000163563
	LOSS [training: 0.08429951817524889 | validation: 0.20950750329532444]
	TIME [epoch: 115 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08575134346009557		[learning rate: 0.00016198]
	Learning Rate: 0.000161985
	LOSS [training: 0.08575134346009557 | validation: 0.21230562383096396]
	TIME [epoch: 115 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08710892975852517		[learning rate: 0.00016042]
	Learning Rate: 0.000160422
	LOSS [training: 0.08710892975852517 | validation: 0.20982281022148266]
	TIME [epoch: 115 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07949169670265839		[learning rate: 0.00015887]
	Learning Rate: 0.000158874
	LOSS [training: 0.07949169670265839 | validation: 0.21286725796932215]
	TIME [epoch: 115 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0877248745093052		[learning rate: 0.00015734]
	Learning Rate: 0.000157341
	LOSS [training: 0.0877248745093052 | validation: 0.21269019553382099]
	TIME [epoch: 115 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0833985226251309		[learning rate: 0.00015582]
	Learning Rate: 0.000155823
	LOSS [training: 0.0833985226251309 | validation: 0.2129147599799799]
	TIME [epoch: 115 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.090189885864174		[learning rate: 0.00015432]
	Learning Rate: 0.00015432
	LOSS [training: 0.090189885864174 | validation: 0.2086715684366346]
	TIME [epoch: 115 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08560223314977572		[learning rate: 0.00015283]
	Learning Rate: 0.000152831
	LOSS [training: 0.08560223314977572 | validation: 0.21296701770715007]
	TIME [epoch: 115 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08447152512541585		[learning rate: 0.00015136]
	Learning Rate: 0.000151356
	LOSS [training: 0.08447152512541585 | validation: 0.21557470013432775]
	TIME [epoch: 115 sec]
EPOCH 471/1000:
	Training over batches...
