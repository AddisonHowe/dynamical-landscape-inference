Args:
Namespace(name='model_facs_dec2_v1_argset3', outdir='out/model_training/model_facs_dec2_v1_argset3', training_data='data/facs/facs_dec2_v1/training', validation_data='data/facs/facs_dec2_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[100, 300, 500, 700], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.275067687034607], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2424776046

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2233345463187709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2233345463187709 | validation: 0.136342577066464]
	TIME [epoch: 51.2 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11030705279720156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11030705279720156 | validation: 0.12053863310816705]
	TIME [epoch: 4.71 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08784740016640558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08784740016640558 | validation: 0.1069863203761663]
	TIME [epoch: 4.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08207728216100768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08207728216100768 | validation: 0.09041768239803843]
	TIME [epoch: 4.66 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07898850334898944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07898850334898944 | validation: 0.0895464754025721]
	TIME [epoch: 4.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07038789068557268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07038789068557268 | validation: 0.08243004157345936]
	TIME [epoch: 4.67 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.062383473415094766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.062383473415094766 | validation: 0.08222238719918153]
	TIME [epoch: 4.66 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.061634810136070986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.061634810136070986 | validation: 0.07812632505894906]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06683372481737364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06683372481737364 | validation: 0.07616525755630074]
	TIME [epoch: 4.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577712718014542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0577712718014542 | validation: 0.07126617686470407]
	TIME [epoch: 4.66 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049961616065219275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049961616065219275 | validation: 0.08196302273606734]
	TIME [epoch: 4.67 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06028225933644438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06028225933644438 | validation: 0.0916507518174766]
	TIME [epoch: 4.65 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06412957634648433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06412957634648433 | validation: 0.07069228474519351]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.054276362372132375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054276362372132375 | validation: 0.0663261363074638]
	TIME [epoch: 4.67 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048880772792635675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.048880772792635675 | validation: 0.06722961478742819]
	TIME [epoch: 4.66 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529167147246936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04529167147246936 | validation: 0.07163064708756633]
	TIME [epoch: 4.67 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04860182856002392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04860182856002392 | validation: 0.0655966222413312]
	TIME [epoch: 4.67 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049790667177219076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049790667177219076 | validation: 0.07178667178779397]
	TIME [epoch: 4.68 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467483428563447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04467483428563447 | validation: 0.06133639881539543]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.038531375409831266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038531375409831266 | validation: 0.06903646542178522]
	TIME [epoch: 4.65 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855439588222155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03855439588222155 | validation: 0.058074294624484435]
	TIME [epoch: 4.65 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.037251985402158794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037251985402158794 | validation: 0.058344009094602196]
	TIME [epoch: 4.7 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193029006941332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04193029006941332 | validation: 0.06054926274684634]
	TIME [epoch: 4.69 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209541585358932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04209541585358932 | validation: 0.059595895058696176]
	TIME [epoch: 4.69 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042847827594459126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042847827594459126 | validation: 0.054648861789538476]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04127278618308779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04127278618308779 | validation: 0.054037158639734725]
	TIME [epoch: 4.7 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03514033255477306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03514033255477306 | validation: 0.07322292892978223]
	TIME [epoch: 4.69 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04114831100613601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04114831100613601 | validation: 0.059306619465848275]
	TIME [epoch: 4.69 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0361756028054035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0361756028054035 | validation: 0.0599579307754421]
	TIME [epoch: 4.69 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03490040336115273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03490040336115273 | validation: 0.06270194941186988]
	TIME [epoch: 4.68 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03750957367833657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03750957367833657 | validation: 0.06303240526003494]
	TIME [epoch: 4.68 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036466959702972104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036466959702972104 | validation: 0.059425652859998596]
	TIME [epoch: 4.68 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044035498695517386		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.044035498695517386 | validation: 0.06480819719333036]
	TIME [epoch: 4.68 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03745493517299573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03745493517299573 | validation: 0.055282174155263306]
	TIME [epoch: 4.68 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0331159243141596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0331159243141596 | validation: 0.05811054696234521]
	TIME [epoch: 4.69 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.040000020695614556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.040000020695614556 | validation: 0.05337098208156195]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032767811721535305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.032767811721535305 | validation: 0.05258908178867692]
	TIME [epoch: 4.69 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03846528320004544		[learning rate: 0.0099839]
	Learning Rate: 0.00998385
	LOSS [training: 0.03846528320004544 | validation: 0.07343114239194456]
	TIME [epoch: 4.69 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03866529565945068		[learning rate: 0.0099195]
	Learning Rate: 0.00991953
	LOSS [training: 0.03866529565945068 | validation: 0.05419498944553897]
	TIME [epoch: 4.7 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029958513336754682		[learning rate: 0.0098556]
	Learning Rate: 0.00985563
	LOSS [training: 0.029958513336754682 | validation: 0.08019701404958116]
	TIME [epoch: 4.7 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420599869691514		[learning rate: 0.0097921]
	Learning Rate: 0.00979213
	LOSS [training: 0.0420599869691514 | validation: 0.0633786122277123]
	TIME [epoch: 4.7 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030419762976340938		[learning rate: 0.009729]
	Learning Rate: 0.00972904
	LOSS [training: 0.030419762976340938 | validation: 0.05404482508419756]
	TIME [epoch: 4.69 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03606256662547135		[learning rate: 0.0096664]
	Learning Rate: 0.00966636
	LOSS [training: 0.03606256662547135 | validation: 0.057493459804973036]
	TIME [epoch: 4.68 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.039748437976485126		[learning rate: 0.0096041]
	Learning Rate: 0.00960409
	LOSS [training: 0.039748437976485126 | validation: 0.05608800908936522]
	TIME [epoch: 4.68 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03102274406083751		[learning rate: 0.0095422]
	Learning Rate: 0.00954221
	LOSS [training: 0.03102274406083751 | validation: 0.05915148183774749]
	TIME [epoch: 4.69 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03267935915830551		[learning rate: 0.0094807]
	Learning Rate: 0.00948074
	LOSS [training: 0.03267935915830551 | validation: 0.07453973658794336]
	TIME [epoch: 4.69 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04874012444346243		[learning rate: 0.0094197]
	Learning Rate: 0.00941966
	LOSS [training: 0.04874012444346243 | validation: 0.05561350448480637]
	TIME [epoch: 4.7 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036849032282575495		[learning rate: 0.009359]
	Learning Rate: 0.00935897
	LOSS [training: 0.036849032282575495 | validation: 0.055744966728366555]
	TIME [epoch: 4.69 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03194227819551157		[learning rate: 0.0092987]
	Learning Rate: 0.00929867
	LOSS [training: 0.03194227819551157 | validation: 0.060412633581049716]
	TIME [epoch: 4.68 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033885376882124646		[learning rate: 0.0092388]
	Learning Rate: 0.00923877
	LOSS [training: 0.033885376882124646 | validation: 0.06095926721678014]
	TIME [epoch: 4.68 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027414179686967365		[learning rate: 0.0091792]
	Learning Rate: 0.00917925
	LOSS [training: 0.027414179686967365 | validation: 0.061742428424693706]
	TIME [epoch: 4.7 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03436315818589424		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.03436315818589424 | validation: 0.05943383618465883]
	TIME [epoch: 4.69 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029099007774360842		[learning rate: 0.0090614]
	Learning Rate: 0.00906135
	LOSS [training: 0.029099007774360842 | validation: 0.061567422230190245]
	TIME [epoch: 4.69 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03246162930177628		[learning rate: 0.009003]
	Learning Rate: 0.00900297
	LOSS [training: 0.03246162930177628 | validation: 0.06057765121725345]
	TIME [epoch: 4.69 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.034177224943963		[learning rate: 0.008945]
	Learning Rate: 0.00894497
	LOSS [training: 0.034177224943963 | validation: 0.06328065507068316]
	TIME [epoch: 4.69 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03983626917261504		[learning rate: 0.0088873]
	Learning Rate: 0.00888734
	LOSS [training: 0.03983626917261504 | validation: 0.06479974575838907]
	TIME [epoch: 4.69 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03417861364720206		[learning rate: 0.0088301]
	Learning Rate: 0.00883009
	LOSS [training: 0.03417861364720206 | validation: 0.05633950173404151]
	TIME [epoch: 4.69 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154217322839436		[learning rate: 0.0087732]
	Learning Rate: 0.0087732
	LOSS [training: 0.03154217322839436 | validation: 0.058575990781408495]
	TIME [epoch: 4.68 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030091266301131202		[learning rate: 0.0087167]
	Learning Rate: 0.00871668
	LOSS [training: 0.030091266301131202 | validation: 0.06636334431408072]
	TIME [epoch: 4.69 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03661949920887158		[learning rate: 0.0086605]
	Learning Rate: 0.00866052
	LOSS [training: 0.03661949920887158 | validation: 0.06022427208728513]
	TIME [epoch: 4.69 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029318890398757527		[learning rate: 0.0086047]
	Learning Rate: 0.00860472
	LOSS [training: 0.029318890398757527 | validation: 0.05490367591530444]
	TIME [epoch: 4.68 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03132966269331211		[learning rate: 0.0085493]
	Learning Rate: 0.00854929
	LOSS [training: 0.03132966269331211 | validation: 0.05089986300067249]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397684863032904		[learning rate: 0.0084942]
	Learning Rate: 0.00849421
	LOSS [training: 0.03397684863032904 | validation: 0.05580884747036389]
	TIME [epoch: 4.69 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028467884814537617		[learning rate: 0.0084395]
	Learning Rate: 0.00843948
	LOSS [training: 0.028467884814537617 | validation: 0.06021203335229157]
	TIME [epoch: 4.68 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030014876282047128		[learning rate: 0.0083851]
	Learning Rate: 0.00838511
	LOSS [training: 0.030014876282047128 | validation: 0.06033619518458517]
	TIME [epoch: 4.69 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03263135913573484		[learning rate: 0.0083311]
	Learning Rate: 0.00833109
	LOSS [training: 0.03263135913573484 | validation: 0.07968985886691266]
	TIME [epoch: 4.69 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232540286045068		[learning rate: 0.0082774]
	Learning Rate: 0.00827742
	LOSS [training: 0.03232540286045068 | validation: 0.06057934768918641]
	TIME [epoch: 4.69 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032547136870958226		[learning rate: 0.0082241]
	Learning Rate: 0.00822409
	LOSS [training: 0.032547136870958226 | validation: 0.05407240983578061]
	TIME [epoch: 4.69 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02939195205975835		[learning rate: 0.0081711]
	Learning Rate: 0.0081711
	LOSS [training: 0.02939195205975835 | validation: 0.05437887420244951]
	TIME [epoch: 4.68 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318618367555641		[learning rate: 0.0081185]
	Learning Rate: 0.00811846
	LOSS [training: 0.03318618367555641 | validation: 0.05210394551987746]
	TIME [epoch: 4.68 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029467632627454957		[learning rate: 0.0080662]
	Learning Rate: 0.00806616
	LOSS [training: 0.029467632627454957 | validation: 0.051986963334747595]
	TIME [epoch: 4.69 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028835491357618002		[learning rate: 0.0080142]
	Learning Rate: 0.00801419
	LOSS [training: 0.028835491357618002 | validation: 0.07755510348118867]
	TIME [epoch: 4.69 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03431109462483882		[learning rate: 0.0079626]
	Learning Rate: 0.00796256
	LOSS [training: 0.03431109462483882 | validation: 0.05576460739606355]
	TIME [epoch: 4.68 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224434396162362		[learning rate: 0.0079113]
	Learning Rate: 0.00791126
	LOSS [training: 0.03224434396162362 | validation: 0.05913345193876583]
	TIME [epoch: 4.69 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03174373546748621		[learning rate: 0.0078603]
	Learning Rate: 0.00786029
	LOSS [training: 0.03174373546748621 | validation: 0.05881714186743646]
	TIME [epoch: 4.69 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824924009231517		[learning rate: 0.0078097]
	Learning Rate: 0.00780965
	LOSS [training: 0.03824924009231517 | validation: 0.0672570313590128]
	TIME [epoch: 4.7 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026684886416602115		[learning rate: 0.0077593]
	Learning Rate: 0.00775934
	LOSS [training: 0.026684886416602115 | validation: 0.06695448276942975]
	TIME [epoch: 4.69 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035430211438907434		[learning rate: 0.0077093]
	Learning Rate: 0.00770935
	LOSS [training: 0.035430211438907434 | validation: 0.056429566661405806]
	TIME [epoch: 4.7 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03541048320148231		[learning rate: 0.0076597]
	Learning Rate: 0.00765968
	LOSS [training: 0.03541048320148231 | validation: 0.05653555125661271]
	TIME [epoch: 4.69 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02739335262926428		[learning rate: 0.0076103]
	Learning Rate: 0.00761033
	LOSS [training: 0.02739335262926428 | validation: 0.05802946085374244]
	TIME [epoch: 4.69 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192462366319454		[learning rate: 0.0075613]
	Learning Rate: 0.0075613
	LOSS [training: 0.03192462366319454 | validation: 0.05523810969977502]
	TIME [epoch: 4.69 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02763806722353282		[learning rate: 0.0075126]
	Learning Rate: 0.00751259
	LOSS [training: 0.02763806722353282 | validation: 0.07106097065685746]
	TIME [epoch: 4.68 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03781600975097636		[learning rate: 0.0074642]
	Learning Rate: 0.00746419
	LOSS [training: 0.03781600975097636 | validation: 0.05371004066185637]
	TIME [epoch: 4.69 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031009094311732044		[learning rate: 0.0074161]
	Learning Rate: 0.0074161
	LOSS [training: 0.031009094311732044 | validation: 0.07124391815604712]
	TIME [epoch: 4.69 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030253810622565505		[learning rate: 0.0073683]
	Learning Rate: 0.00736832
	LOSS [training: 0.030253810622565505 | validation: 0.07026974538572174]
	TIME [epoch: 4.68 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03182001844069338		[learning rate: 0.0073208]
	Learning Rate: 0.00732085
	LOSS [training: 0.03182001844069338 | validation: 0.056766767005042386]
	TIME [epoch: 4.68 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02571690165127033		[learning rate: 0.0072737]
	Learning Rate: 0.00727368
	LOSS [training: 0.02571690165127033 | validation: 0.06745981534098222]
	TIME [epoch: 4.69 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029617141917429046		[learning rate: 0.0072268]
	Learning Rate: 0.00722682
	LOSS [training: 0.029617141917429046 | validation: 0.05752316881687765]
	TIME [epoch: 4.69 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024282223930616957		[learning rate: 0.0071803]
	Learning Rate: 0.00718026
	LOSS [training: 0.024282223930616957 | validation: 0.06533569536659792]
	TIME [epoch: 4.68 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328705956728553		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.0328705956728553 | validation: 0.09071244547469254]
	TIME [epoch: 4.69 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04173493827987187		[learning rate: 0.007088]
	Learning Rate: 0.00708804
	LOSS [training: 0.04173493827987187 | validation: 0.06393470912333027]
	TIME [epoch: 4.68 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027850762483028015		[learning rate: 0.0070424]
	Learning Rate: 0.00704238
	LOSS [training: 0.027850762483028015 | validation: 0.06390311695549847]
	TIME [epoch: 4.69 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028231597644649553		[learning rate: 0.006997]
	Learning Rate: 0.00699701
	LOSS [training: 0.028231597644649553 | validation: 0.054198435609748574]
	TIME [epoch: 4.69 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024596605337838275		[learning rate: 0.0069519]
	Learning Rate: 0.00695193
	LOSS [training: 0.024596605337838275 | validation: 0.04800139339692702]
	TIME [epoch: 4.68 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028653403017389244		[learning rate: 0.0069071]
	Learning Rate: 0.00690714
	LOSS [training: 0.028653403017389244 | validation: 0.05618917814733092]
	TIME [epoch: 4.69 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030625149625863157		[learning rate: 0.0068626]
	Learning Rate: 0.00686264
	LOSS [training: 0.030625149625863157 | validation: 0.05549866633264208]
	TIME [epoch: 4.69 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026594883637661715		[learning rate: 0.0068184]
	Learning Rate: 0.00681843
	LOSS [training: 0.026594883637661715 | validation: 0.05595548862128123]
	TIME [epoch: 4.68 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048418405751631		[learning rate: 0.0067745]
	Learning Rate: 0.0067745
	LOSS [training: 0.03048418405751631 | validation: 0.06330845448427784]
	TIME [epoch: 4.68 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03090334759143091		[learning rate: 0.0067309]
	Learning Rate: 0.00673085
	LOSS [training: 0.03090334759143091 | validation: 0.048558129113968736]
	TIME [epoch: 4.68 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0318563445821322		[learning rate: 0.0066875]
	Learning Rate: 0.00668749
	LOSS [training: 0.0318563445821322 | validation: 0.07050818193686359]
	TIME [epoch: 4.69 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033823210620514535		[learning rate: 0.0066444]
	Learning Rate: 0.00664441
	LOSS [training: 0.033823210620514535 | validation: 0.06162362233927557]
	TIME [epoch: 54.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029037324012834147		[learning rate: 0.0066016]
	Learning Rate: 0.0066016
	LOSS [training: 0.029037324012834147 | validation: 0.048346902312299544]
	TIME [epoch: 9.08 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025374014768224575		[learning rate: 0.0065591]
	Learning Rate: 0.00655907
	LOSS [training: 0.025374014768224575 | validation: 0.05737206946188078]
	TIME [epoch: 9.05 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029831078411453715		[learning rate: 0.0065168]
	Learning Rate: 0.00651681
	LOSS [training: 0.029831078411453715 | validation: 0.06692393083106761]
	TIME [epoch: 9.06 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028497635409628543		[learning rate: 0.0064748]
	Learning Rate: 0.00647483
	LOSS [training: 0.028497635409628543 | validation: 0.057746268430474465]
	TIME [epoch: 9.05 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024497732119374456		[learning rate: 0.0064331]
	Learning Rate: 0.00643311
	LOSS [training: 0.024497732119374456 | validation: 0.054425904275334336]
	TIME [epoch: 9.06 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024562376295719987		[learning rate: 0.0063917]
	Learning Rate: 0.00639166
	LOSS [training: 0.024562376295719987 | validation: 0.05203951124000094]
	TIME [epoch: 9.06 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0264750908732795		[learning rate: 0.0063505]
	Learning Rate: 0.00635049
	LOSS [training: 0.0264750908732795 | validation: 0.0513694306096623]
	TIME [epoch: 9.06 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027909059329004327		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.027909059329004327 | validation: 0.06161482267282579]
	TIME [epoch: 9.08 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026534763446221996		[learning rate: 0.0062689]
	Learning Rate: 0.00626892
	LOSS [training: 0.026534763446221996 | validation: 0.06654939112514768]
	TIME [epoch: 9.06 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028791950238857184		[learning rate: 0.0062285]
	Learning Rate: 0.00622854
	LOSS [training: 0.028791950238857184 | validation: 0.06267570256702562]
	TIME [epoch: 9.05 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028176653098816288		[learning rate: 0.0061884]
	Learning Rate: 0.00618841
	LOSS [training: 0.028176653098816288 | validation: 0.05234475353589221]
	TIME [epoch: 9.05 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022538681009092038		[learning rate: 0.0061485]
	Learning Rate: 0.00614854
	LOSS [training: 0.022538681009092038 | validation: 0.04992327435683155]
	TIME [epoch: 9.06 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026354276728683866		[learning rate: 0.0061089]
	Learning Rate: 0.00610893
	LOSS [training: 0.026354276728683866 | validation: 0.04798461490797533]
	TIME [epoch: 9.05 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02570235157744187		[learning rate: 0.0060696]
	Learning Rate: 0.00606957
	LOSS [training: 0.02570235157744187 | validation: 0.06751220319801998]
	TIME [epoch: 9.05 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031766740226968466		[learning rate: 0.0060305]
	Learning Rate: 0.00603047
	LOSS [training: 0.031766740226968466 | validation: 0.05396043718794269]
	TIME [epoch: 9.04 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021339473267172573		[learning rate: 0.0059916]
	Learning Rate: 0.00599161
	LOSS [training: 0.021339473267172573 | validation: 0.050911819115119064]
	TIME [epoch: 9.04 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02399533949983841		[learning rate: 0.005953]
	Learning Rate: 0.00595301
	LOSS [training: 0.02399533949983841 | validation: 0.06303839704055765]
	TIME [epoch: 9.04 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025276493091384692		[learning rate: 0.0059147]
	Learning Rate: 0.00591466
	LOSS [training: 0.025276493091384692 | validation: 0.06056905089905534]
	TIME [epoch: 9.05 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030543070625766996		[learning rate: 0.0058766]
	Learning Rate: 0.00587655
	LOSS [training: 0.030543070625766996 | validation: 0.0565342190753953]
	TIME [epoch: 9.04 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029959918294816184		[learning rate: 0.0058387]
	Learning Rate: 0.00583869
	LOSS [training: 0.029959918294816184 | validation: 0.049820651015127684]
	TIME [epoch: 9.07 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023329548784276843		[learning rate: 0.0058011]
	Learning Rate: 0.00580108
	LOSS [training: 0.023329548784276843 | validation: 0.04665629682057679]
	TIME [epoch: 9.04 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022992402242344473		[learning rate: 0.0057637]
	Learning Rate: 0.0057637
	LOSS [training: 0.022992402242344473 | validation: 0.04950617793317291]
	TIME [epoch: 9.04 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02926668597504248		[learning rate: 0.0057266]
	Learning Rate: 0.00572657
	LOSS [training: 0.02926668597504248 | validation: 0.07706272073477394]
	TIME [epoch: 9.04 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02977225349391647		[learning rate: 0.0056897]
	Learning Rate: 0.00568968
	LOSS [training: 0.02977225349391647 | validation: 0.08794725087332408]
	TIME [epoch: 9.03 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029428236944778613		[learning rate: 0.005653]
	Learning Rate: 0.00565302
	LOSS [training: 0.029428236944778613 | validation: 0.051304644318932974]
	TIME [epoch: 9.05 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023048129990484167		[learning rate: 0.0056166]
	Learning Rate: 0.0056166
	LOSS [training: 0.023048129990484167 | validation: 0.051279680950039534]
	TIME [epoch: 9.05 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02489191138646703		[learning rate: 0.0055804]
	Learning Rate: 0.00558042
	LOSS [training: 0.02489191138646703 | validation: 0.05206818469926665]
	TIME [epoch: 9.05 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02506719075117718		[learning rate: 0.0055445]
	Learning Rate: 0.00554447
	LOSS [training: 0.02506719075117718 | validation: 0.05266609647165115]
	TIME [epoch: 9.04 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024721288215402842		[learning rate: 0.0055087]
	Learning Rate: 0.00550874
	LOSS [training: 0.024721288215402842 | validation: 0.054894454967474485]
	TIME [epoch: 9.04 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026203763062594625		[learning rate: 0.0054733]
	Learning Rate: 0.00547325
	LOSS [training: 0.026203763062594625 | validation: 0.05080897721752341]
	TIME [epoch: 9.04 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024948329898257064		[learning rate: 0.005438]
	Learning Rate: 0.00543799
	LOSS [training: 0.024948329898257064 | validation: 0.04607550377572263]
	TIME [epoch: 9.04 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026915796754847326		[learning rate: 0.005403]
	Learning Rate: 0.00540296
	LOSS [training: 0.026915796754847326 | validation: 0.04757519184569436]
	TIME [epoch: 9.07 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023597491225372334		[learning rate: 0.0053681]
	Learning Rate: 0.00536815
	LOSS [training: 0.023597491225372334 | validation: 0.055899665326681475]
	TIME [epoch: 9.05 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030499234740854024		[learning rate: 0.0053336]
	Learning Rate: 0.00533356
	LOSS [training: 0.030499234740854024 | validation: 0.06359577293556269]
	TIME [epoch: 9.06 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030001238855841432		[learning rate: 0.0052992]
	Learning Rate: 0.0052992
	LOSS [training: 0.030001238855841432 | validation: 0.05415107035218654]
	TIME [epoch: 9.05 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023033937051448482		[learning rate: 0.0052651]
	Learning Rate: 0.00526506
	LOSS [training: 0.023033937051448482 | validation: 0.04939627005224965]
	TIME [epoch: 9.06 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023577686525193847		[learning rate: 0.0052311]
	Learning Rate: 0.00523114
	LOSS [training: 0.023577686525193847 | validation: 0.0604011856948023]
	TIME [epoch: 9.04 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0266079054050406		[learning rate: 0.0051974]
	Learning Rate: 0.00519744
	LOSS [training: 0.0266079054050406 | validation: 0.055301231538513636]
	TIME [epoch: 9.06 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028202560548375104		[learning rate: 0.005164]
	Learning Rate: 0.00516396
	LOSS [training: 0.028202560548375104 | validation: 0.05264897958164601]
	TIME [epoch: 9.04 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02142044991235259		[learning rate: 0.0051307]
	Learning Rate: 0.00513069
	LOSS [training: 0.02142044991235259 | validation: 0.04699089700732453]
	TIME [epoch: 9.06 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028987055735212434		[learning rate: 0.0050976]
	Learning Rate: 0.00509763
	LOSS [training: 0.028987055735212434 | validation: 0.04942492532000316]
	TIME [epoch: 9.04 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028032280895508185		[learning rate: 0.0050648]
	Learning Rate: 0.00506479
	LOSS [training: 0.028032280895508185 | validation: 0.04929849978875375]
	TIME [epoch: 9.06 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023894480484546156		[learning rate: 0.0050322]
	Learning Rate: 0.00503216
	LOSS [training: 0.023894480484546156 | validation: 0.05756693948726923]
	TIME [epoch: 9.05 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027440911219191774		[learning rate: 0.0049997]
	Learning Rate: 0.00499974
	LOSS [training: 0.027440911219191774 | validation: 0.049160685392391386]
	TIME [epoch: 9.06 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025829244854736408		[learning rate: 0.0049675]
	Learning Rate: 0.00496753
	LOSS [training: 0.025829244854736408 | validation: 0.047686945830194574]
	TIME [epoch: 9.05 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026919671992023636		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.026919671992023636 | validation: 0.05072552513439954]
	TIME [epoch: 9.06 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025596278496272752		[learning rate: 0.0049037]
	Learning Rate: 0.00490373
	LOSS [training: 0.025596278496272752 | validation: 0.05152517541411951]
	TIME [epoch: 9.05 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024177080819971337		[learning rate: 0.0048721]
	Learning Rate: 0.00487213
	LOSS [training: 0.024177080819971337 | validation: 0.05077873099443078]
	TIME [epoch: 9.05 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028521985896921787		[learning rate: 0.0048407]
	Learning Rate: 0.00484075
	LOSS [training: 0.028521985896921787 | validation: 0.052392446040465133]
	TIME [epoch: 9.07 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024189138037189112		[learning rate: 0.0048096]
	Learning Rate: 0.00480956
	LOSS [training: 0.024189138037189112 | validation: 0.048381484292639505]
	TIME [epoch: 9.06 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026836491059641754		[learning rate: 0.0047786]
	Learning Rate: 0.00477857
	LOSS [training: 0.026836491059641754 | validation: 0.05061577772457519]
	TIME [epoch: 9.06 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02697822009423089		[learning rate: 0.0047478]
	Learning Rate: 0.00474779
	LOSS [training: 0.02697822009423089 | validation: 0.0565123406990414]
	TIME [epoch: 9.04 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027658993060154638		[learning rate: 0.0047172]
	Learning Rate: 0.0047172
	LOSS [training: 0.027658993060154638 | validation: 0.04742622749277586]
	TIME [epoch: 9.05 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024852041979608386		[learning rate: 0.0046868]
	Learning Rate: 0.00468681
	LOSS [training: 0.024852041979608386 | validation: 0.052760456009300565]
	TIME [epoch: 9.05 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024429732964242046		[learning rate: 0.0046566]
	Learning Rate: 0.00465661
	LOSS [training: 0.024429732964242046 | validation: 0.05236634017189533]
	TIME [epoch: 9.05 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02535365042377602		[learning rate: 0.0046266]
	Learning Rate: 0.00462661
	LOSS [training: 0.02535365042377602 | validation: 0.053903972668360306]
	TIME [epoch: 9.06 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027939211496806796		[learning rate: 0.0045968]
	Learning Rate: 0.00459681
	LOSS [training: 0.027939211496806796 | validation: 0.049319846541401105]
	TIME [epoch: 9.05 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023236368780761192		[learning rate: 0.0045672]
	Learning Rate: 0.00456719
	LOSS [training: 0.023236368780761192 | validation: 0.048998921939943284]
	TIME [epoch: 9.07 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024785248808580164		[learning rate: 0.0045378]
	Learning Rate: 0.00453777
	LOSS [training: 0.024785248808580164 | validation: 0.05741858476555915]
	TIME [epoch: 9.07 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025918612110202632		[learning rate: 0.0045085]
	Learning Rate: 0.00450853
	LOSS [training: 0.025918612110202632 | validation: 0.0484310967644341]
	TIME [epoch: 9.06 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021816693608447076		[learning rate: 0.0044795]
	Learning Rate: 0.00447948
	LOSS [training: 0.021816693608447076 | validation: 0.050231960606777114]
	TIME [epoch: 9.05 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029391982877579		[learning rate: 0.0044506]
	Learning Rate: 0.00445063
	LOSS [training: 0.029391982877579 | validation: 0.058525150079554486]
	TIME [epoch: 9.06 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03154991182905891		[learning rate: 0.004422]
	Learning Rate: 0.00442195
	LOSS [training: 0.03154991182905891 | validation: 0.05128592098048205]
	TIME [epoch: 9.06 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023535937840484657		[learning rate: 0.0043935]
	Learning Rate: 0.00439346
	LOSS [training: 0.023535937840484657 | validation: 0.05704268217092789]
	TIME [epoch: 9.05 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02336477462299786		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.02336477462299786 | validation: 0.06179216545131638]
	TIME [epoch: 9.06 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02669975358927747		[learning rate: 0.004337]
	Learning Rate: 0.00433704
	LOSS [training: 0.02669975358927747 | validation: 0.050584647161056734]
	TIME [epoch: 9.06 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022518379197023985		[learning rate: 0.0043091]
	Learning Rate: 0.00430909
	LOSS [training: 0.022518379197023985 | validation: 0.050327589228655635]
	TIME [epoch: 9.05 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02299008241718434		[learning rate: 0.0042813]
	Learning Rate: 0.00428133
	LOSS [training: 0.02299008241718434 | validation: 0.053409042580277725]
	TIME [epoch: 9.06 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021043123087598307		[learning rate: 0.0042537]
	Learning Rate: 0.00425375
	LOSS [training: 0.021043123087598307 | validation: 0.05160522172753843]
	TIME [epoch: 9.06 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022310719605466333		[learning rate: 0.0042263]
	Learning Rate: 0.00422634
	LOSS [training: 0.022310719605466333 | validation: 0.052054977053021464]
	TIME [epoch: 9.06 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024993441304797952		[learning rate: 0.0041991]
	Learning Rate: 0.00419912
	LOSS [training: 0.024993441304797952 | validation: 0.04846077199545664]
	TIME [epoch: 9.07 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02257525271456362		[learning rate: 0.0041721]
	Learning Rate: 0.00417206
	LOSS [training: 0.02257525271456362 | validation: 0.04990091638623931]
	TIME [epoch: 9.05 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01994762053706721		[learning rate: 0.0041452]
	Learning Rate: 0.00414518
	LOSS [training: 0.01994762053706721 | validation: 0.05464114740026591]
	TIME [epoch: 9.06 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02312655896825553		[learning rate: 0.0041185]
	Learning Rate: 0.00411848
	LOSS [training: 0.02312655896825553 | validation: 0.0496796077787913]
	TIME [epoch: 9.06 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024397133600171823		[learning rate: 0.0040919]
	Learning Rate: 0.00409195
	LOSS [training: 0.024397133600171823 | validation: 0.05090961194694568]
	TIME [epoch: 9.07 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024921339938609927		[learning rate: 0.0040656]
	Learning Rate: 0.00406558
	LOSS [training: 0.024921339938609927 | validation: 0.052230239575954567]
	TIME [epoch: 9.06 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026094564149411803		[learning rate: 0.0040394]
	Learning Rate: 0.00403939
	LOSS [training: 0.026094564149411803 | validation: 0.05159113533313268]
	TIME [epoch: 9.06 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025562926735498745		[learning rate: 0.0040134]
	Learning Rate: 0.00401337
	LOSS [training: 0.025562926735498745 | validation: 0.058323973289486554]
	TIME [epoch: 9.03 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023936682758589567		[learning rate: 0.0039875]
	Learning Rate: 0.00398751
	LOSS [training: 0.023936682758589567 | validation: 0.050035629763808376]
	TIME [epoch: 9.04 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02594106589668458		[learning rate: 0.0039618]
	Learning Rate: 0.00396182
	LOSS [training: 0.02594106589668458 | validation: 0.05568742436411221]
	TIME [epoch: 9.05 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026219538467577498		[learning rate: 0.0039363]
	Learning Rate: 0.0039363
	LOSS [training: 0.026219538467577498 | validation: 0.051675378487188936]
	TIME [epoch: 9.05 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021744043701039176		[learning rate: 0.0039109]
	Learning Rate: 0.00391094
	LOSS [training: 0.021744043701039176 | validation: 0.05370303106638147]
	TIME [epoch: 9.05 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029029255563991517		[learning rate: 0.0038857]
	Learning Rate: 0.00388574
	LOSS [training: 0.029029255563991517 | validation: 0.05034343462426978]
	TIME [epoch: 9.05 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025153096257407883		[learning rate: 0.0038607]
	Learning Rate: 0.00386071
	LOSS [training: 0.025153096257407883 | validation: 0.04928870477244973]
	TIME [epoch: 9.05 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025791835576437962		[learning rate: 0.0038358]
	Learning Rate: 0.00383583
	LOSS [training: 0.025791835576437962 | validation: 0.04936241918668531]
	TIME [epoch: 9.06 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024201359225889656		[learning rate: 0.0038111]
	Learning Rate: 0.00381112
	LOSS [training: 0.024201359225889656 | validation: 0.061005364668691095]
	TIME [epoch: 9.05 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02240562148733812		[learning rate: 0.0037866]
	Learning Rate: 0.00378657
	LOSS [training: 0.02240562148733812 | validation: 0.050913835021510014]
	TIME [epoch: 9.06 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019467602660910414		[learning rate: 0.0037622]
	Learning Rate: 0.00376217
	LOSS [training: 0.019467602660910414 | validation: 0.05073447499305721]
	TIME [epoch: 9.04 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022661478748242796		[learning rate: 0.0037379]
	Learning Rate: 0.00373793
	LOSS [training: 0.022661478748242796 | validation: 0.056422668225984365]
	TIME [epoch: 9.06 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024385145514106688		[learning rate: 0.0037139]
	Learning Rate: 0.00371385
	LOSS [training: 0.024385145514106688 | validation: 0.05709151525937742]
	TIME [epoch: 9.05 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020882591618982923		[learning rate: 0.0036899]
	Learning Rate: 0.00368992
	LOSS [training: 0.020882591618982923 | validation: 0.05263199146443978]
	TIME [epoch: 9.05 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02436845344250305		[learning rate: 0.0036662]
	Learning Rate: 0.00366615
	LOSS [training: 0.02436845344250305 | validation: 0.05576338198136073]
	TIME [epoch: 9.05 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027101074039557423		[learning rate: 0.0036425]
	Learning Rate: 0.00364253
	LOSS [training: 0.027101074039557423 | validation: 0.08715301062968277]
	TIME [epoch: 9.05 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03829569202794944		[learning rate: 0.0036191]
	Learning Rate: 0.00361907
	LOSS [training: 0.03829569202794944 | validation: 0.05166555952231037]
	TIME [epoch: 9.06 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021372349865291504		[learning rate: 0.0035957]
	Learning Rate: 0.00359575
	LOSS [training: 0.021372349865291504 | validation: 0.04861027774073348]
	TIME [epoch: 9.05 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02118894978460613		[learning rate: 0.0035726]
	Learning Rate: 0.00357258
	LOSS [training: 0.02118894978460613 | validation: 0.04688524048798246]
	TIME [epoch: 9.06 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02208708347544297		[learning rate: 0.0035496]
	Learning Rate: 0.00354957
	LOSS [training: 0.02208708347544297 | validation: 0.053324730905143905]
	TIME [epoch: 9.05 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02099109605666126		[learning rate: 0.0035267]
	Learning Rate: 0.0035267
	LOSS [training: 0.02099109605666126 | validation: 0.052810038825614296]
	TIME [epoch: 9.05 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022549003141959074		[learning rate: 0.003504]
	Learning Rate: 0.00350398
	LOSS [training: 0.022549003141959074 | validation: 0.053598590420226015]
	TIME [epoch: 9.06 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02538739858632488		[learning rate: 0.0034814]
	Learning Rate: 0.0034814
	LOSS [training: 0.02538739858632488 | validation: 0.05829438838027087]
	TIME [epoch: 9.06 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02359157943584805		[learning rate: 0.003459]
	Learning Rate: 0.00345897
	LOSS [training: 0.02359157943584805 | validation: 0.07974895980396801]
	TIME [epoch: 9.06 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025241208034698218		[learning rate: 0.0034367]
	Learning Rate: 0.00343669
	LOSS [training: 0.025241208034698218 | validation: 0.05534995511212226]
	TIME [epoch: 9.06 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656811629861056		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.02656811629861056 | validation: 0.054814039834766765]
	TIME [epoch: 9.05 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02418313972852603		[learning rate: 0.0033926]
	Learning Rate: 0.00339255
	LOSS [training: 0.02418313972852603 | validation: 0.055087875593287323]
	TIME [epoch: 9.06 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023816828953415664		[learning rate: 0.0033707]
	Learning Rate: 0.00337069
	LOSS [training: 0.023816828953415664 | validation: 0.05655212424190455]
	TIME [epoch: 9.05 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02432950093203407		[learning rate: 0.003349]
	Learning Rate: 0.00334898
	LOSS [training: 0.02432950093203407 | validation: 0.05107538522760396]
	TIME [epoch: 9.06 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03361514662928171		[learning rate: 0.0033274]
	Learning Rate: 0.0033274
	LOSS [training: 0.03361514662928171 | validation: 0.05962539062489798]
	TIME [epoch: 9.05 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02373087889158788		[learning rate: 0.003306]
	Learning Rate: 0.00330596
	LOSS [training: 0.02373087889158788 | validation: 0.050935210285420605]
	TIME [epoch: 9.05 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02057299778230058		[learning rate: 0.0032847]
	Learning Rate: 0.00328467
	LOSS [training: 0.02057299778230058 | validation: 0.055346495282604616]
	TIME [epoch: 9.05 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01930261232067448		[learning rate: 0.0032635]
	Learning Rate: 0.0032635
	LOSS [training: 0.01930261232067448 | validation: 0.045620822825769014]
	TIME [epoch: 9.05 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021326467385325693		[learning rate: 0.0032425]
	Learning Rate: 0.00324248
	LOSS [training: 0.021326467385325693 | validation: 0.05509761526442886]
	TIME [epoch: 9.04 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0214268172855473		[learning rate: 0.0032216]
	Learning Rate: 0.00322159
	LOSS [training: 0.0214268172855473 | validation: 0.06400830569272634]
	TIME [epoch: 9.05 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248482521648523		[learning rate: 0.0032008]
	Learning Rate: 0.00320083
	LOSS [training: 0.0248482521648523 | validation: 0.0479134072087542]
	TIME [epoch: 9.05 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018768881926478565		[learning rate: 0.0031802]
	Learning Rate: 0.00318021
	LOSS [training: 0.018768881926478565 | validation: 0.047765037693532165]
	TIME [epoch: 9.05 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018188729386741244		[learning rate: 0.0031597]
	Learning Rate: 0.00315972
	LOSS [training: 0.018188729386741244 | validation: 0.0471964350493912]
	TIME [epoch: 9.04 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029680838454663586		[learning rate: 0.0031394]
	Learning Rate: 0.00313937
	LOSS [training: 0.029680838454663586 | validation: 0.0556484515876305]
	TIME [epoch: 9.05 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025513443315986664		[learning rate: 0.0031191]
	Learning Rate: 0.00311914
	LOSS [training: 0.025513443315986664 | validation: 0.052589188743472653]
	TIME [epoch: 9.04 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021901180082312795		[learning rate: 0.003099]
	Learning Rate: 0.00309905
	LOSS [training: 0.021901180082312795 | validation: 0.05578891633752424]
	TIME [epoch: 9.04 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01942864917887232		[learning rate: 0.0030791]
	Learning Rate: 0.00307908
	LOSS [training: 0.01942864917887232 | validation: 0.05245937566404213]
	TIME [epoch: 9.04 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02057216605832944		[learning rate: 0.0030592]
	Learning Rate: 0.00305924
	LOSS [training: 0.02057216605832944 | validation: 0.05055259176366442]
	TIME [epoch: 9.03 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02540976779283037		[learning rate: 0.0030395]
	Learning Rate: 0.00303953
	LOSS [training: 0.02540976779283037 | validation: 0.05745607696773803]
	TIME [epoch: 9.04 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03840423432039241		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.03840423432039241 | validation: 0.0584249208490994]
	TIME [epoch: 9.04 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02722907777636542		[learning rate: 0.0030005]
	Learning Rate: 0.0030005
	LOSS [training: 0.02722907777636542 | validation: 0.048616409527413515]
	TIME [epoch: 9.04 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021875084730287615		[learning rate: 0.0029812]
	Learning Rate: 0.00298116
	LOSS [training: 0.021875084730287615 | validation: 0.05180646010043941]
	TIME [epoch: 9.04 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02468938393990856		[learning rate: 0.002962]
	Learning Rate: 0.00296196
	LOSS [training: 0.02468938393990856 | validation: 0.050119675783705846]
	TIME [epoch: 9.04 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021626497585186113		[learning rate: 0.0029429]
	Learning Rate: 0.00294288
	LOSS [training: 0.021626497585186113 | validation: 0.04665462408886897]
	TIME [epoch: 9.04 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022853916910259793		[learning rate: 0.0029239]
	Learning Rate: 0.00292392
	LOSS [training: 0.022853916910259793 | validation: 0.0530721734632726]
	TIME [epoch: 9.05 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02185977563169913		[learning rate: 0.0029051]
	Learning Rate: 0.00290508
	LOSS [training: 0.02185977563169913 | validation: 0.04961700722486335]
	TIME [epoch: 9.06 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023354195893597468		[learning rate: 0.0028864]
	Learning Rate: 0.00288636
	LOSS [training: 0.023354195893597468 | validation: 0.05226814985284144]
	TIME [epoch: 9.05 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021834783092723735		[learning rate: 0.0028678]
	Learning Rate: 0.00286777
	LOSS [training: 0.021834783092723735 | validation: 0.04950903996554649]
	TIME [epoch: 9.04 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022831577724654103		[learning rate: 0.0028493]
	Learning Rate: 0.00284929
	LOSS [training: 0.022831577724654103 | validation: 0.050098180629245904]
	TIME [epoch: 9.04 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022431871394745072		[learning rate: 0.0028309]
	Learning Rate: 0.00283093
	LOSS [training: 0.022431871394745072 | validation: 0.055727327567820645]
	TIME [epoch: 9.05 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025773064121667355		[learning rate: 0.0028127]
	Learning Rate: 0.0028127
	LOSS [training: 0.025773064121667355 | validation: 0.05313325352529377]
	TIME [epoch: 9.04 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018681489315496864		[learning rate: 0.0027946]
	Learning Rate: 0.00279457
	LOSS [training: 0.018681489315496864 | validation: 0.06374363443938652]
	TIME [epoch: 9.03 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019423882022027418		[learning rate: 0.0027766]
	Learning Rate: 0.00277657
	LOSS [training: 0.019423882022027418 | validation: 0.04847172547255404]
	TIME [epoch: 9.05 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0180950389897629		[learning rate: 0.0027587]
	Learning Rate: 0.00275868
	LOSS [training: 0.0180950389897629 | validation: 0.05234731998329714]
	TIME [epoch: 9.06 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021469592125096283		[learning rate: 0.0027409]
	Learning Rate: 0.00274091
	LOSS [training: 0.021469592125096283 | validation: 0.05123721441334292]
	TIME [epoch: 9.05 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025720038786320624		[learning rate: 0.0027233]
	Learning Rate: 0.00272325
	LOSS [training: 0.025720038786320624 | validation: 0.05192422787138769]
	TIME [epoch: 9.06 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021805929162581852		[learning rate: 0.0027057]
	Learning Rate: 0.00270571
	LOSS [training: 0.021805929162581852 | validation: 0.05437213216535314]
	TIME [epoch: 9.04 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022595736094759324		[learning rate: 0.0026883]
	Learning Rate: 0.00268827
	LOSS [training: 0.022595736094759324 | validation: 0.07036922838476684]
	TIME [epoch: 9.05 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02281124792261758		[learning rate: 0.002671]
	Learning Rate: 0.00267096
	LOSS [training: 0.02281124792261758 | validation: 0.047018077531301765]
	TIME [epoch: 9.04 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020285978422194685		[learning rate: 0.0026537]
	Learning Rate: 0.00265375
	LOSS [training: 0.020285978422194685 | validation: 0.05453076035401631]
	TIME [epoch: 9.04 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019299355183205958		[learning rate: 0.0026367]
	Learning Rate: 0.00263665
	LOSS [training: 0.019299355183205958 | validation: 0.04932340193509088]
	TIME [epoch: 9.05 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021640023074244848		[learning rate: 0.0026197]
	Learning Rate: 0.00261966
	LOSS [training: 0.021640023074244848 | validation: 0.049978365732230225]
	TIME [epoch: 9.06 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021473846489948094		[learning rate: 0.0026028]
	Learning Rate: 0.00260279
	LOSS [training: 0.021473846489948094 | validation: 0.048221960112583936]
	TIME [epoch: 9.05 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01799640473153872		[learning rate: 0.002586]
	Learning Rate: 0.00258602
	LOSS [training: 0.01799640473153872 | validation: 0.048385212966544716]
	TIME [epoch: 9.05 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018820655581295205		[learning rate: 0.0025694]
	Learning Rate: 0.00256936
	LOSS [training: 0.018820655581295205 | validation: 0.047004834453433515]
	TIME [epoch: 9.05 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02467811459303416		[learning rate: 0.0025528]
	Learning Rate: 0.0025528
	LOSS [training: 0.02467811459303416 | validation: 0.05729512613181555]
	TIME [epoch: 9.06 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02039650292881286		[learning rate: 0.0025364]
	Learning Rate: 0.00253636
	LOSS [training: 0.02039650292881286 | validation: 0.06610825135288104]
	TIME [epoch: 9.05 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024667660424256273		[learning rate: 0.00252]
	Learning Rate: 0.00252002
	LOSS [training: 0.024667660424256273 | validation: 0.05040100277174306]
	TIME [epoch: 9.06 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020104678088052736		[learning rate: 0.0025038]
	Learning Rate: 0.00250378
	LOSS [training: 0.020104678088052736 | validation: 0.048589960612587274]
	TIME [epoch: 9.05 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023101528669459852		[learning rate: 0.0024877]
	Learning Rate: 0.00248765
	LOSS [training: 0.023101528669459852 | validation: 0.051068403243654206]
	TIME [epoch: 9.05 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02019706020214483		[learning rate: 0.0024716]
	Learning Rate: 0.00247162
	LOSS [training: 0.02019706020214483 | validation: 0.04661857612984491]
	TIME [epoch: 9.03 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020771341201669492		[learning rate: 0.0024557]
	Learning Rate: 0.0024557
	LOSS [training: 0.020771341201669492 | validation: 0.05436920989534816]
	TIME [epoch: 9.04 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02199633412738579		[learning rate: 0.0024399]
	Learning Rate: 0.00243988
	LOSS [training: 0.02199633412738579 | validation: 0.05727190037466839]
	TIME [epoch: 9.03 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244269965493647		[learning rate: 0.0024242]
	Learning Rate: 0.00242416
	LOSS [training: 0.02244269965493647 | validation: 0.048462620841284686]
	TIME [epoch: 9.05 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020809762757086247		[learning rate: 0.0024085]
	Learning Rate: 0.00240854
	LOSS [training: 0.020809762757086247 | validation: 0.04822193658630189]
	TIME [epoch: 9.06 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019566458679953692		[learning rate: 0.002393]
	Learning Rate: 0.00239303
	LOSS [training: 0.019566458679953692 | validation: 0.04903403368632173]
	TIME [epoch: 9.03 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018974347316723917		[learning rate: 0.0023776]
	Learning Rate: 0.00237761
	LOSS [training: 0.018974347316723917 | validation: 0.04799764641168733]
	TIME [epoch: 9.04 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02047592703465968		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.02047592703465968 | validation: 0.0535957141876713]
	TIME [epoch: 9.04 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020758097361682555		[learning rate: 0.0023471]
	Learning Rate: 0.00234707
	LOSS [training: 0.020758097361682555 | validation: 0.04713985649540357]
	TIME [epoch: 9.03 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017665071514855874		[learning rate: 0.002332]
	Learning Rate: 0.00233195
	LOSS [training: 0.017665071514855874 | validation: 0.0498692165145634]
	TIME [epoch: 9.03 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021097357223993477		[learning rate: 0.0023169]
	Learning Rate: 0.00231693
	LOSS [training: 0.021097357223993477 | validation: 0.04909373124932794]
	TIME [epoch: 9.04 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021120303275233995		[learning rate: 0.002302]
	Learning Rate: 0.002302
	LOSS [training: 0.021120303275233995 | validation: 0.046369626572496325]
	TIME [epoch: 9.07 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02027565483627184		[learning rate: 0.0022872]
	Learning Rate: 0.00228717
	LOSS [training: 0.02027565483627184 | validation: 0.05634110891721167]
	TIME [epoch: 9.03 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021271717606323418		[learning rate: 0.0022724]
	Learning Rate: 0.00227243
	LOSS [training: 0.021271717606323418 | validation: 0.04964585251884809]
	TIME [epoch: 9.04 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018123310715730374		[learning rate: 0.0022578]
	Learning Rate: 0.00225779
	LOSS [training: 0.018123310715730374 | validation: 0.047561472699398484]
	TIME [epoch: 9.03 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023217849419390764		[learning rate: 0.0022432]
	Learning Rate: 0.00224325
	LOSS [training: 0.023217849419390764 | validation: 0.05034106375067908]
	TIME [epoch: 9.05 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018071352268835075		[learning rate: 0.0022288]
	Learning Rate: 0.0022288
	LOSS [training: 0.018071352268835075 | validation: 0.04497695383700849]
	TIME [epoch: 9.05 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_270.pth
	Model improved!!!
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02045817794516331		[learning rate: 0.0022144]
	Learning Rate: 0.00221444
	LOSS [training: 0.02045817794516331 | validation: 0.05378216765644878]
	TIME [epoch: 9.03 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01785279603125619		[learning rate: 0.0022002]
	Learning Rate: 0.00220017
	LOSS [training: 0.01785279603125619 | validation: 0.05285697128213649]
	TIME [epoch: 9.06 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020325018091543905		[learning rate: 0.002186]
	Learning Rate: 0.00218599
	LOSS [training: 0.020325018091543905 | validation: 0.04690389412196178]
	TIME [epoch: 9.04 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0183035937447109		[learning rate: 0.0021719]
	Learning Rate: 0.00217191
	LOSS [training: 0.0183035937447109 | validation: 0.04766455506097156]
	TIME [epoch: 9.03 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023908061697903937		[learning rate: 0.0021579]
	Learning Rate: 0.00215792
	LOSS [training: 0.023908061697903937 | validation: 0.04742474234259411]
	TIME [epoch: 9.04 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020082662835434705		[learning rate: 0.002144]
	Learning Rate: 0.00214402
	LOSS [training: 0.020082662835434705 | validation: 0.05301198665944207]
	TIME [epoch: 9.05 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018717751595554326		[learning rate: 0.0021302]
	Learning Rate: 0.0021302
	LOSS [training: 0.018717751595554326 | validation: 0.04876768059477637]
	TIME [epoch: 9.05 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019640354531076213		[learning rate: 0.0021165]
	Learning Rate: 0.00211648
	LOSS [training: 0.019640354531076213 | validation: 0.04824295335802105]
	TIME [epoch: 9.05 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020514694846952303		[learning rate: 0.0021028]
	Learning Rate: 0.00210284
	LOSS [training: 0.020514694846952303 | validation: 0.05023220968981376]
	TIME [epoch: 9.05 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020819409504533017		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.020819409504533017 | validation: 0.04906699168245997]
	TIME [epoch: 9.06 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02165151778091129		[learning rate: 0.0020758]
	Learning Rate: 0.00207584
	LOSS [training: 0.02165151778091129 | validation: 0.05121180653867885]
	TIME [epoch: 9.05 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018314427953679595		[learning rate: 0.0020625]
	Learning Rate: 0.00206246
	LOSS [training: 0.018314427953679595 | validation: 0.045266737321964484]
	TIME [epoch: 9.06 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02229949572620502		[learning rate: 0.0020492]
	Learning Rate: 0.00204917
	LOSS [training: 0.02229949572620502 | validation: 0.04957214038251647]
	TIME [epoch: 9.05 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018704773071913636		[learning rate: 0.002036]
	Learning Rate: 0.00203597
	LOSS [training: 0.018704773071913636 | validation: 0.04880020224635897]
	TIME [epoch: 9.05 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019593186958785987		[learning rate: 0.0020229]
	Learning Rate: 0.00202286
	LOSS [training: 0.019593186958785987 | validation: 0.04823954920953576]
	TIME [epoch: 9.05 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017573049961773245		[learning rate: 0.0020098]
	Learning Rate: 0.00200982
	LOSS [training: 0.017573049961773245 | validation: 0.04594677554270114]
	TIME [epoch: 9.04 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019281676422621498		[learning rate: 0.0019969]
	Learning Rate: 0.00199687
	LOSS [training: 0.019281676422621498 | validation: 0.05573880750169639]
	TIME [epoch: 9.05 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01751596139542191		[learning rate: 0.001984]
	Learning Rate: 0.00198401
	LOSS [training: 0.01751596139542191 | validation: 0.06366698276168332]
	TIME [epoch: 9.03 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021158910926684052		[learning rate: 0.0019712]
	Learning Rate: 0.00197123
	LOSS [training: 0.021158910926684052 | validation: 0.04741939268253355]
	TIME [epoch: 9.04 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016540635936933747		[learning rate: 0.0019585]
	Learning Rate: 0.00195853
	LOSS [training: 0.016540635936933747 | validation: 0.04865426185020598]
	TIME [epoch: 9.05 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019222405433833117		[learning rate: 0.0019459]
	Learning Rate: 0.00194591
	LOSS [training: 0.019222405433833117 | validation: 0.04842896547530983]
	TIME [epoch: 9.05 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019061993086134352		[learning rate: 0.0019334]
	Learning Rate: 0.00193337
	LOSS [training: 0.019061993086134352 | validation: 0.05104400527633522]
	TIME [epoch: 9.05 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021084702049360353		[learning rate: 0.0019209]
	Learning Rate: 0.00192092
	LOSS [training: 0.021084702049360353 | validation: 0.04667795427682267]
	TIME [epoch: 9.04 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0219996231164698		[learning rate: 0.0019085]
	Learning Rate: 0.00190854
	LOSS [training: 0.0219996231164698 | validation: 0.05140462772817289]
	TIME [epoch: 9.05 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019591681121601687		[learning rate: 0.0018962]
	Learning Rate: 0.00189625
	LOSS [training: 0.019591681121601687 | validation: 0.04755158254984789]
	TIME [epoch: 9.05 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018536447141805593		[learning rate: 0.001884]
	Learning Rate: 0.00188403
	LOSS [training: 0.018536447141805593 | validation: 0.04915165937376185]
	TIME [epoch: 9.06 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017295668746684017		[learning rate: 0.0018719]
	Learning Rate: 0.00187189
	LOSS [training: 0.017295668746684017 | validation: 0.04915292130003521]
	TIME [epoch: 9.05 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019947995901639006		[learning rate: 0.0018598]
	Learning Rate: 0.00185983
	LOSS [training: 0.019947995901639006 | validation: 0.04757285134572384]
	TIME [epoch: 9.06 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018704952792510585		[learning rate: 0.0018478]
	Learning Rate: 0.00184785
	LOSS [training: 0.018704952792510585 | validation: 0.05051028967375432]
	TIME [epoch: 9.05 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018836980944572382		[learning rate: 0.0018359]
	Learning Rate: 0.00183594
	LOSS [training: 0.018836980944572382 | validation: 0.05951555959455735]
	TIME [epoch: 9.05 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022554970293633993		[learning rate: 0.0018241]
	Learning Rate: 0.00182412
	LOSS [training: 0.022554970293633993 | validation: 0.051707955224711034]
	TIME [epoch: 64.5 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017377050984422278		[learning rate: 0.0018124]
	Learning Rate: 0.00181236
	LOSS [training: 0.017377050984422278 | validation: 0.046753574901955454]
	TIME [epoch: 19.1 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021507197928080753		[learning rate: 0.0018007]
	Learning Rate: 0.00180069
	LOSS [training: 0.021507197928080753 | validation: 0.05323723545592575]
	TIME [epoch: 19.1 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017665733872653754		[learning rate: 0.0017891]
	Learning Rate: 0.00178909
	LOSS [training: 0.017665733872653754 | validation: 0.04713030643688233]
	TIME [epoch: 19.1 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0189238349988171		[learning rate: 0.0017776]
	Learning Rate: 0.00177756
	LOSS [training: 0.0189238349988171 | validation: 0.05115506838350067]
	TIME [epoch: 19.1 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020752220686986473		[learning rate: 0.0017661]
	Learning Rate: 0.00176611
	LOSS [training: 0.020752220686986473 | validation: 0.04674653172324117]
	TIME [epoch: 19.1 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021119044798141834		[learning rate: 0.0017547]
	Learning Rate: 0.00175473
	LOSS [training: 0.021119044798141834 | validation: 0.0640649686123683]
	TIME [epoch: 19.1 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020026657235440164		[learning rate: 0.0017434]
	Learning Rate: 0.00174343
	LOSS [training: 0.020026657235440164 | validation: 0.05258548465185303]
	TIME [epoch: 19.1 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018199335673360767		[learning rate: 0.0017322]
	Learning Rate: 0.00173219
	LOSS [training: 0.018199335673360767 | validation: 0.04690455853553543]
	TIME [epoch: 19.2 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019168293024982606		[learning rate: 0.001721]
	Learning Rate: 0.00172103
	LOSS [training: 0.019168293024982606 | validation: 0.047881370026405114]
	TIME [epoch: 19.1 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01928130577248713		[learning rate: 0.0017099]
	Learning Rate: 0.00170995
	LOSS [training: 0.01928130577248713 | validation: 0.04929223221803036]
	TIME [epoch: 19.1 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017862002863489875		[learning rate: 0.0016989]
	Learning Rate: 0.00169893
	LOSS [training: 0.017862002863489875 | validation: 0.0517071261052028]
	TIME [epoch: 19.1 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01898799886202019		[learning rate: 0.001688]
	Learning Rate: 0.00168798
	LOSS [training: 0.01898799886202019 | validation: 0.04607797029199984]
	TIME [epoch: 19.2 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017535955919076064		[learning rate: 0.0016771]
	Learning Rate: 0.00167711
	LOSS [training: 0.017535955919076064 | validation: 0.04835684595687467]
	TIME [epoch: 19.1 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0205238651483741		[learning rate: 0.0016663]
	Learning Rate: 0.0016663
	LOSS [training: 0.0205238651483741 | validation: 0.05394744283616225]
	TIME [epoch: 19.1 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02444686992556206		[learning rate: 0.0016556]
	Learning Rate: 0.00165557
	LOSS [training: 0.02444686992556206 | validation: 0.05620829853622979]
	TIME [epoch: 19.2 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021020039708451434		[learning rate: 0.0016449]
	Learning Rate: 0.0016449
	LOSS [training: 0.021020039708451434 | validation: 0.04663921413585691]
	TIME [epoch: 19.1 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01878082276338519		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.01878082276338519 | validation: 0.04497519570324894]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_318.pth
	Model improved!!!
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017851117054665962		[learning rate: 0.0016238]
	Learning Rate: 0.00162378
	LOSS [training: 0.017851117054665962 | validation: 0.04859163978563106]
	TIME [epoch: 19 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016732663933913563		[learning rate: 0.0016133]
	Learning Rate: 0.00161332
	LOSS [training: 0.016732663933913563 | validation: 0.04892588604665598]
	TIME [epoch: 19 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017783969856534295		[learning rate: 0.0016029]
	Learning Rate: 0.00160292
	LOSS [training: 0.017783969856534295 | validation: 0.04757002561470305]
	TIME [epoch: 19.2 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018956199460888654		[learning rate: 0.0015926]
	Learning Rate: 0.00159259
	LOSS [training: 0.018956199460888654 | validation: 0.049414046403366635]
	TIME [epoch: 19.1 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019310862203014024		[learning rate: 0.0015823]
	Learning Rate: 0.00158233
	LOSS [training: 0.019310862203014024 | validation: 0.04972531048356432]
	TIME [epoch: 19.1 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01796470566103176		[learning rate: 0.0015721]
	Learning Rate: 0.00157214
	LOSS [training: 0.01796470566103176 | validation: 0.047602914050882655]
	TIME [epoch: 19.1 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01829055768776629		[learning rate: 0.001562]
	Learning Rate: 0.00156201
	LOSS [training: 0.01829055768776629 | validation: 0.04899711662048347]
	TIME [epoch: 19.1 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018351044528302718		[learning rate: 0.0015519]
	Learning Rate: 0.00155195
	LOSS [training: 0.018351044528302718 | validation: 0.05773816227021327]
	TIME [epoch: 19.1 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020298041624781406		[learning rate: 0.0015419]
	Learning Rate: 0.00154195
	LOSS [training: 0.020298041624781406 | validation: 0.049342921873610994]
	TIME [epoch: 19.1 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018014643445851793		[learning rate: 0.001532]
	Learning Rate: 0.00153202
	LOSS [training: 0.018014643445851793 | validation: 0.04830899637086567]
	TIME [epoch: 19.1 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019080500323362958		[learning rate: 0.0015221]
	Learning Rate: 0.00152215
	LOSS [training: 0.019080500323362958 | validation: 0.044515512813384374]
	TIME [epoch: 19.1 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_329.pth
	Model improved!!!
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018631166538190358		[learning rate: 0.0015123]
	Learning Rate: 0.00151234
	LOSS [training: 0.018631166538190358 | validation: 0.050596305540232415]
	TIME [epoch: 19.1 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017803972157672175		[learning rate: 0.0015026]
	Learning Rate: 0.0015026
	LOSS [training: 0.017803972157672175 | validation: 0.0477032046223909]
	TIME [epoch: 19.1 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019849383659436746		[learning rate: 0.0014929]
	Learning Rate: 0.00149291
	LOSS [training: 0.019849383659436746 | validation: 0.04701710053758306]
	TIME [epoch: 19 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017203537780945372		[learning rate: 0.0014833]
	Learning Rate: 0.0014833
	LOSS [training: 0.017203537780945372 | validation: 0.04712401549894081]
	TIME [epoch: 19.1 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022270967241442084		[learning rate: 0.0014737]
	Learning Rate: 0.00147374
	LOSS [training: 0.022270967241442084 | validation: 0.04923872246719296]
	TIME [epoch: 19.1 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018954024241332964		[learning rate: 0.0014642]
	Learning Rate: 0.00146425
	LOSS [training: 0.018954024241332964 | validation: 0.051025087935341995]
	TIME [epoch: 19.1 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018048849707784257		[learning rate: 0.0014548]
	Learning Rate: 0.00145481
	LOSS [training: 0.018048849707784257 | validation: 0.047391946083856044]
	TIME [epoch: 19 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019604230494629976		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.019604230494629976 | validation: 0.048036830651995564]
	TIME [epoch: 19 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017655747664157943		[learning rate: 0.0014361]
	Learning Rate: 0.00143613
	LOSS [training: 0.017655747664157943 | validation: 0.047479824271035635]
	TIME [epoch: 19 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884155925845442		[learning rate: 0.0014269]
	Learning Rate: 0.00142688
	LOSS [training: 0.01884155925845442 | validation: 0.04647973647260109]
	TIME [epoch: 19 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017559620216794525		[learning rate: 0.0014177]
	Learning Rate: 0.00141768
	LOSS [training: 0.017559620216794525 | validation: 0.046818321068696656]
	TIME [epoch: 19 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018867722490574612		[learning rate: 0.0014085]
	Learning Rate: 0.00140855
	LOSS [training: 0.018867722490574612 | validation: 0.04797826389543449]
	TIME [epoch: 19 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01827397530977451		[learning rate: 0.0013995]
	Learning Rate: 0.00139947
	LOSS [training: 0.01827397530977451 | validation: 0.049304563974984845]
	TIME [epoch: 19 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016889791176955847		[learning rate: 0.0013905]
	Learning Rate: 0.00139046
	LOSS [training: 0.016889791176955847 | validation: 0.047366649077211075]
	TIME [epoch: 19 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017466774016948194		[learning rate: 0.0013815]
	Learning Rate: 0.0013815
	LOSS [training: 0.017466774016948194 | validation: 0.04501470222802467]
	TIME [epoch: 19.1 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017653951084296765		[learning rate: 0.0013726]
	Learning Rate: 0.0013726
	LOSS [training: 0.017653951084296765 | validation: 0.048676121989356155]
	TIME [epoch: 19.1 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019482221748812128		[learning rate: 0.0013638]
	Learning Rate: 0.00136376
	LOSS [training: 0.019482221748812128 | validation: 0.0501057351769798]
	TIME [epoch: 19.1 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018762612784599376		[learning rate: 0.001355]
	Learning Rate: 0.00135497
	LOSS [training: 0.018762612784599376 | validation: 0.05021049325273386]
	TIME [epoch: 19.1 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01877506974738885		[learning rate: 0.0013462]
	Learning Rate: 0.00134624
	LOSS [training: 0.01877506974738885 | validation: 0.04953604925657286]
	TIME [epoch: 19 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017660832557401		[learning rate: 0.0013376]
	Learning Rate: 0.00133757
	LOSS [training: 0.017660832557401 | validation: 0.04441655513397627]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_349.pth
	Model improved!!!
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019275614921052817		[learning rate: 0.001329]
	Learning Rate: 0.00132895
	LOSS [training: 0.019275614921052817 | validation: 0.04861518530221015]
	TIME [epoch: 18.9 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020610528086785252		[learning rate: 0.0013204]
	Learning Rate: 0.00132039
	LOSS [training: 0.020610528086785252 | validation: 0.054588413502962306]
	TIME [epoch: 19 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019138479249612952		[learning rate: 0.0013119]
	Learning Rate: 0.00131188
	LOSS [training: 0.019138479249612952 | validation: 0.05086420560509664]
	TIME [epoch: 18.9 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020062339420855203		[learning rate: 0.0013034]
	Learning Rate: 0.00130343
	LOSS [training: 0.020062339420855203 | validation: 0.04605230224331587]
	TIME [epoch: 19 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01997419838334717		[learning rate: 0.001295]
	Learning Rate: 0.00129503
	LOSS [training: 0.01997419838334717 | validation: 0.04438013694209347]
	TIME [epoch: 19 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_354.pth
	Model improved!!!
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017652945594425994		[learning rate: 0.0012867]
	Learning Rate: 0.00128669
	LOSS [training: 0.017652945594425994 | validation: 0.0463274315994738]
	TIME [epoch: 19 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01727062709113839		[learning rate: 0.0012784]
	Learning Rate: 0.0012784
	LOSS [training: 0.01727062709113839 | validation: 0.045502421409724506]
	TIME [epoch: 19 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017505547466530463		[learning rate: 0.0012702]
	Learning Rate: 0.00127016
	LOSS [training: 0.017505547466530463 | validation: 0.04658878065275152]
	TIME [epoch: 18.9 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01686069796859179		[learning rate: 0.001262]
	Learning Rate: 0.00126198
	LOSS [training: 0.01686069796859179 | validation: 0.048288550663052786]
	TIME [epoch: 18.9 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791806584201222		[learning rate: 0.0012538]
	Learning Rate: 0.00125385
	LOSS [training: 0.01791806584201222 | validation: 0.04591278625868382]
	TIME [epoch: 19 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017468914835386387		[learning rate: 0.0012458]
	Learning Rate: 0.00124577
	LOSS [training: 0.017468914835386387 | validation: 0.04706380333228633]
	TIME [epoch: 19 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020640949758482234		[learning rate: 0.0012377]
	Learning Rate: 0.00123775
	LOSS [training: 0.020640949758482234 | validation: 0.04652565716860627]
	TIME [epoch: 18.9 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018833919248482062		[learning rate: 0.0012298]
	Learning Rate: 0.00122977
	LOSS [training: 0.018833919248482062 | validation: 0.04844385241644805]
	TIME [epoch: 19 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022315664496715015		[learning rate: 0.0012218]
	Learning Rate: 0.00122185
	LOSS [training: 0.022315664496715015 | validation: 0.05211282707668047]
	TIME [epoch: 19 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01892043114534087		[learning rate: 0.001214]
	Learning Rate: 0.00121398
	LOSS [training: 0.01892043114534087 | validation: 0.04632216233080604]
	TIME [epoch: 19 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01753410813742399		[learning rate: 0.0012062]
	Learning Rate: 0.00120616
	LOSS [training: 0.01753410813742399 | validation: 0.0537569830512788]
	TIME [epoch: 18.9 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018395008006928715		[learning rate: 0.0011984]
	Learning Rate: 0.00119839
	LOSS [training: 0.018395008006928715 | validation: 0.047578642969732854]
	TIME [epoch: 18.9 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017665275637985978		[learning rate: 0.0011907]
	Learning Rate: 0.00119066
	LOSS [training: 0.017665275637985978 | validation: 0.049345072214538474]
	TIME [epoch: 18.9 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019566041730233734		[learning rate: 0.001183]
	Learning Rate: 0.00118299
	LOSS [training: 0.019566041730233734 | validation: 0.05331191156203676]
	TIME [epoch: 18.9 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019454172910416158		[learning rate: 0.0011754]
	Learning Rate: 0.00117537
	LOSS [training: 0.019454172910416158 | validation: 0.04691533990087141]
	TIME [epoch: 18.9 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01948032675004812		[learning rate: 0.0011678]
	Learning Rate: 0.0011678
	LOSS [training: 0.01948032675004812 | validation: 0.04657669685305005]
	TIME [epoch: 18.9 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019645507718557654		[learning rate: 0.0011603]
	Learning Rate: 0.00116028
	LOSS [training: 0.019645507718557654 | validation: 0.04689803492044845]
	TIME [epoch: 18.9 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018767115899032308		[learning rate: 0.0011528]
	Learning Rate: 0.0011528
	LOSS [training: 0.018767115899032308 | validation: 0.04863176942563807]
	TIME [epoch: 18.9 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017682895759296983		[learning rate: 0.0011454]
	Learning Rate: 0.00114537
	LOSS [training: 0.017682895759296983 | validation: 0.0488325654719806]
	TIME [epoch: 18.9 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019974331754105262		[learning rate: 0.001138]
	Learning Rate: 0.00113799
	LOSS [training: 0.019974331754105262 | validation: 0.05046722568237632]
	TIME [epoch: 18.9 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019190962609688583		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.019190962609688583 | validation: 0.0514513678075977]
	TIME [epoch: 18.9 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017231672657493927		[learning rate: 0.0011234]
	Learning Rate: 0.00112338
	LOSS [training: 0.017231672657493927 | validation: 0.04723258929077166]
	TIME [epoch: 18.9 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017253640377522757		[learning rate: 0.0011161]
	Learning Rate: 0.00111614
	LOSS [training: 0.017253640377522757 | validation: 0.048540260744162685]
	TIME [epoch: 18.9 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017584971020233195		[learning rate: 0.001109]
	Learning Rate: 0.00110895
	LOSS [training: 0.017584971020233195 | validation: 0.045764917519608865]
	TIME [epoch: 19 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020125164090004845		[learning rate: 0.0011018]
	Learning Rate: 0.00110181
	LOSS [training: 0.020125164090004845 | validation: 0.05081069476300566]
	TIME [epoch: 19 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0185622585351032		[learning rate: 0.0010947]
	Learning Rate: 0.00109471
	LOSS [training: 0.0185622585351032 | validation: 0.04811073978688037]
	TIME [epoch: 18.9 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017736564024301064		[learning rate: 0.0010877]
	Learning Rate: 0.00108766
	LOSS [training: 0.017736564024301064 | validation: 0.04865539916522825]
	TIME [epoch: 18.9 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018094385455072262		[learning rate: 0.0010806]
	Learning Rate: 0.00108065
	LOSS [training: 0.018094385455072262 | validation: 0.04765425783184763]
	TIME [epoch: 18.9 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021307305183112482		[learning rate: 0.0010737]
	Learning Rate: 0.00107369
	LOSS [training: 0.021307305183112482 | validation: 0.04805558465396237]
	TIME [epoch: 18.9 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017778466662495232		[learning rate: 0.0010668]
	Learning Rate: 0.00106677
	LOSS [training: 0.017778466662495232 | validation: 0.04710095624803421]
	TIME [epoch: 18.9 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017747104529249554		[learning rate: 0.0010599]
	Learning Rate: 0.0010599
	LOSS [training: 0.017747104529249554 | validation: 0.04837636577537374]
	TIME [epoch: 19 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017002698002092607		[learning rate: 0.0010531]
	Learning Rate: 0.00105307
	LOSS [training: 0.017002698002092607 | validation: 0.049257475745421886]
	TIME [epoch: 18.9 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018165415095220117		[learning rate: 0.0010463]
	Learning Rate: 0.00104628
	LOSS [training: 0.018165415095220117 | validation: 0.04597259353190628]
	TIME [epoch: 18.9 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016985964911665912		[learning rate: 0.0010395]
	Learning Rate: 0.00103954
	LOSS [training: 0.016985964911665912 | validation: 0.044993705547123085]
	TIME [epoch: 18.9 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018299385449925314		[learning rate: 0.0010328]
	Learning Rate: 0.00103284
	LOSS [training: 0.018299385449925314 | validation: 0.053387354846103366]
	TIME [epoch: 19 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016961757919751512		[learning rate: 0.0010262]
	Learning Rate: 0.00102619
	LOSS [training: 0.016961757919751512 | validation: 0.044793706935134334]
	TIME [epoch: 19 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016589120679324606		[learning rate: 0.0010196]
	Learning Rate: 0.00101958
	LOSS [training: 0.016589120679324606 | validation: 0.049057749998787765]
	TIME [epoch: 18.9 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016847978770701797		[learning rate: 0.001013]
	Learning Rate: 0.00101301
	LOSS [training: 0.016847978770701797 | validation: 0.04604495863619383]
	TIME [epoch: 19 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020822951376815616		[learning rate: 0.0010065]
	Learning Rate: 0.00100648
	LOSS [training: 0.020822951376815616 | validation: 0.05292043103739333]
	TIME [epoch: 18.9 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017441435475664548		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.017441435475664548 | validation: 0.05017207361036528]
	TIME [epoch: 19 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01928060483004942		[learning rate: 0.00099356]
	Learning Rate: 0.000993557
	LOSS [training: 0.01928060483004942 | validation: 0.04735408208265955]
	TIME [epoch: 19 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020853071412416723		[learning rate: 0.00098716]
	Learning Rate: 0.000987156
	LOSS [training: 0.020853071412416723 | validation: 0.05109971762318637]
	TIME [epoch: 19 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01953389404287488		[learning rate: 0.0009808]
	Learning Rate: 0.000980797
	LOSS [training: 0.01953389404287488 | validation: 0.04573041564411147]
	TIME [epoch: 18.9 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0161154651051328		[learning rate: 0.00097448]
	Learning Rate: 0.000974478
	LOSS [training: 0.0161154651051328 | validation: 0.047421146544040636]
	TIME [epoch: 18.9 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017796776359568237		[learning rate: 0.0009682]
	Learning Rate: 0.0009682
	LOSS [training: 0.017796776359568237 | validation: 0.04872881969400855]
	TIME [epoch: 18.9 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017203229370693053		[learning rate: 0.00096196]
	Learning Rate: 0.000961962
	LOSS [training: 0.017203229370693053 | validation: 0.048946109871772586]
	TIME [epoch: 18.9 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016790161615415137		[learning rate: 0.00095576]
	Learning Rate: 0.000955764
	LOSS [training: 0.016790161615415137 | validation: 0.049399228011123085]
	TIME [epoch: 19.1 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019103921237984683		[learning rate: 0.00094961]
	Learning Rate: 0.000949607
	LOSS [training: 0.019103921237984683 | validation: 0.04819045563521663]
	TIME [epoch: 19 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0185850580513988		[learning rate: 0.00094349]
	Learning Rate: 0.000943489
	LOSS [training: 0.0185850580513988 | validation: 0.05110286207556869]
	TIME [epoch: 19 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020645893402405954		[learning rate: 0.00093741]
	Learning Rate: 0.00093741
	LOSS [training: 0.020645893402405954 | validation: 0.04794293087512598]
	TIME [epoch: 19 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01865463477634612		[learning rate: 0.00093137]
	Learning Rate: 0.000931371
	LOSS [training: 0.01865463477634612 | validation: 0.048260963605449306]
	TIME [epoch: 18.9 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018465850291750283		[learning rate: 0.00092537]
	Learning Rate: 0.000925371
	LOSS [training: 0.018465850291750283 | validation: 0.05025043853848585]
	TIME [epoch: 18.9 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01651644001989945		[learning rate: 0.00091941]
	Learning Rate: 0.000919409
	LOSS [training: 0.01651644001989945 | validation: 0.04426316688662029]
	TIME [epoch: 18.9 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_407.pth
	Model improved!!!
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016955009959587788		[learning rate: 0.00091349]
	Learning Rate: 0.000913486
	LOSS [training: 0.016955009959587788 | validation: 0.04709258286125727]
	TIME [epoch: 19 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01751325468090958		[learning rate: 0.0009076]
	Learning Rate: 0.0009076
	LOSS [training: 0.01751325468090958 | validation: 0.052372233798193155]
	TIME [epoch: 19 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018328954008050857		[learning rate: 0.00090175]
	Learning Rate: 0.000901753
	LOSS [training: 0.018328954008050857 | validation: 0.04665173818346714]
	TIME [epoch: 19.1 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01619688708699457		[learning rate: 0.00089594]
	Learning Rate: 0.000895943
	LOSS [training: 0.01619688708699457 | validation: 0.04817601519243203]
	TIME [epoch: 19.1 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01974954462316135		[learning rate: 0.00089017]
	Learning Rate: 0.000890171
	LOSS [training: 0.01974954462316135 | validation: 0.04843505291329152]
	TIME [epoch: 19 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019820824777081452		[learning rate: 0.00088444]
	Learning Rate: 0.000884436
	LOSS [training: 0.019820824777081452 | validation: 0.04892643083259507]
	TIME [epoch: 18.9 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020298220521333628		[learning rate: 0.00087874]
	Learning Rate: 0.000878738
	LOSS [training: 0.020298220521333628 | validation: 0.04690536464086986]
	TIME [epoch: 18.9 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017749300801647844		[learning rate: 0.00087308]
	Learning Rate: 0.000873077
	LOSS [training: 0.017749300801647844 | validation: 0.04768118073347226]
	TIME [epoch: 18.9 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016678009295428557		[learning rate: 0.00086745]
	Learning Rate: 0.000867452
	LOSS [training: 0.016678009295428557 | validation: 0.04893790372724507]
	TIME [epoch: 19 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01751070946298743		[learning rate: 0.00086186]
	Learning Rate: 0.000861864
	LOSS [training: 0.01751070946298743 | validation: 0.044734340882068686]
	TIME [epoch: 18.9 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017157562171816805		[learning rate: 0.00085631]
	Learning Rate: 0.000856311
	LOSS [training: 0.017157562171816805 | validation: 0.05007727238832578]
	TIME [epoch: 18.9 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712235596644807		[learning rate: 0.00085079]
	Learning Rate: 0.000850794
	LOSS [training: 0.01712235596644807 | validation: 0.045937745813442045]
	TIME [epoch: 18.9 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01742285634683644		[learning rate: 0.00084531]
	Learning Rate: 0.000845313
	LOSS [training: 0.01742285634683644 | validation: 0.050133325658243494]
	TIME [epoch: 18.9 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017279311077077527		[learning rate: 0.00083987]
	Learning Rate: 0.000839867
	LOSS [training: 0.017279311077077527 | validation: 0.04562450935230804]
	TIME [epoch: 18.9 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017531790503365903		[learning rate: 0.00083446]
	Learning Rate: 0.000834456
	LOSS [training: 0.017531790503365903 | validation: 0.05119308659776684]
	TIME [epoch: 18.9 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01691002394323784		[learning rate: 0.00082908]
	Learning Rate: 0.00082908
	LOSS [training: 0.01691002394323784 | validation: 0.045422526783477836]
	TIME [epoch: 18.9 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016632307839430163		[learning rate: 0.00082374]
	Learning Rate: 0.000823739
	LOSS [training: 0.016632307839430163 | validation: 0.04749624214045861]
	TIME [epoch: 18.9 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017912395892672094		[learning rate: 0.00081843]
	Learning Rate: 0.000818432
	LOSS [training: 0.017912395892672094 | validation: 0.04495632922076705]
	TIME [epoch: 18.9 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778239563003369		[learning rate: 0.00081316]
	Learning Rate: 0.000813159
	LOSS [training: 0.01778239563003369 | validation: 0.048490440116967036]
	TIME [epoch: 18.9 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016334806031696243		[learning rate: 0.00080792]
	Learning Rate: 0.00080792
	LOSS [training: 0.016334806031696243 | validation: 0.04660168251961636]
	TIME [epoch: 18.9 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017164626612983513		[learning rate: 0.00080272]
	Learning Rate: 0.000802715
	LOSS [training: 0.017164626612983513 | validation: 0.049922126778603235]
	TIME [epoch: 18.9 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01876316181050387		[learning rate: 0.00079754]
	Learning Rate: 0.000797544
	LOSS [training: 0.01876316181050387 | validation: 0.046366901969152524]
	TIME [epoch: 18.9 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017846339186682825		[learning rate: 0.00079241]
	Learning Rate: 0.000792405
	LOSS [training: 0.017846339186682825 | validation: 0.049610014298004865]
	TIME [epoch: 18.9 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712555898235624		[learning rate: 0.0007873]
	Learning Rate: 0.0007873
	LOSS [training: 0.01712555898235624 | validation: 0.046881857862073335]
	TIME [epoch: 18.9 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01897540691798821		[learning rate: 0.00078223]
	Learning Rate: 0.000782228
	LOSS [training: 0.01897540691798821 | validation: 0.048493408804761565]
	TIME [epoch: 18.9 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019465877994028165		[learning rate: 0.00077719]
	Learning Rate: 0.000777188
	LOSS [training: 0.019465877994028165 | validation: 0.04645615066889231]
	TIME [epoch: 18.9 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019865115876469466		[learning rate: 0.00077218]
	Learning Rate: 0.000772181
	LOSS [training: 0.019865115876469466 | validation: 0.046545114183377576]
	TIME [epoch: 18.9 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017641637685581663		[learning rate: 0.00076721]
	Learning Rate: 0.000767206
	LOSS [training: 0.017641637685581663 | validation: 0.052133533818700055]
	TIME [epoch: 18.9 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018867717206439965		[learning rate: 0.00076226]
	Learning Rate: 0.000762264
	LOSS [training: 0.018867717206439965 | validation: 0.04946828691790988]
	TIME [epoch: 18.9 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017315379021209453		[learning rate: 0.00075735]
	Learning Rate: 0.000757353
	LOSS [training: 0.017315379021209453 | validation: 0.04648257399239582]
	TIME [epoch: 18.9 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017252618139253908		[learning rate: 0.00075247]
	Learning Rate: 0.000752473
	LOSS [training: 0.017252618139253908 | validation: 0.04626206550426385]
	TIME [epoch: 19 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017817852743590466		[learning rate: 0.00074763]
	Learning Rate: 0.000747626
	LOSS [training: 0.017817852743590466 | validation: 0.04730389462143801]
	TIME [epoch: 18.9 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01625993181396323		[learning rate: 0.00074281]
	Learning Rate: 0.000742809
	LOSS [training: 0.01625993181396323 | validation: 0.050824409897923216]
	TIME [epoch: 19 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017150512255940865		[learning rate: 0.00073802]
	Learning Rate: 0.000738023
	LOSS [training: 0.017150512255940865 | validation: 0.04742938464645779]
	TIME [epoch: 18.9 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01608271555965992		[learning rate: 0.00073327]
	Learning Rate: 0.000733269
	LOSS [training: 0.01608271555965992 | validation: 0.04841976079861228]
	TIME [epoch: 18.9 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016115446767839284		[learning rate: 0.00072854]
	Learning Rate: 0.000728544
	LOSS [training: 0.016115446767839284 | validation: 0.047878912613187226]
	TIME [epoch: 18.9 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016556856874897722		[learning rate: 0.00072385]
	Learning Rate: 0.000723851
	LOSS [training: 0.016556856874897722 | validation: 0.046354136207639535]
	TIME [epoch: 18.9 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01807281785253905		[learning rate: 0.00071919]
	Learning Rate: 0.000719187
	LOSS [training: 0.01807281785253905 | validation: 0.05034683736532007]
	TIME [epoch: 18.9 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02024349686796399		[learning rate: 0.00071455]
	Learning Rate: 0.000714554
	LOSS [training: 0.02024349686796399 | validation: 0.05108562044870154]
	TIME [epoch: 18.9 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01817263111553348		[learning rate: 0.00070995]
	Learning Rate: 0.00070995
	LOSS [training: 0.01817263111553348 | validation: 0.04570360309649552]
	TIME [epoch: 18.9 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017251844734446672		[learning rate: 0.00070538]
	Learning Rate: 0.000705377
	LOSS [training: 0.017251844734446672 | validation: 0.049209968834718607]
	TIME [epoch: 18.9 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01899322907053721		[learning rate: 0.00070083]
	Learning Rate: 0.000700832
	LOSS [training: 0.01899322907053721 | validation: 0.04933940435758932]
	TIME [epoch: 19 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01879742325146331		[learning rate: 0.00069632]
	Learning Rate: 0.000696317
	LOSS [training: 0.01879742325146331 | validation: 0.045850208069490424]
	TIME [epoch: 19 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01739408795511144		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.01739408795511144 | validation: 0.04843395379013163]
	TIME [epoch: 19 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01827645414170016		[learning rate: 0.00068737]
	Learning Rate: 0.000687374
	LOSS [training: 0.01827645414170016 | validation: 0.04823350769753833]
	TIME [epoch: 19 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811558084433429		[learning rate: 0.00068295]
	Learning Rate: 0.000682945
	LOSS [training: 0.01811558084433429 | validation: 0.047935428527848885]
	TIME [epoch: 19 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016325494681321807		[learning rate: 0.00067855]
	Learning Rate: 0.000678545
	LOSS [training: 0.016325494681321807 | validation: 0.04461760305574801]
	TIME [epoch: 19.1 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0166150193225461		[learning rate: 0.00067417]
	Learning Rate: 0.000674174
	LOSS [training: 0.0166150193225461 | validation: 0.051656310317955874]
	TIME [epoch: 19.1 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01684148383026965		[learning rate: 0.00066983]
	Learning Rate: 0.00066983
	LOSS [training: 0.01684148383026965 | validation: 0.04724613407305189]
	TIME [epoch: 19 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018900340212158473		[learning rate: 0.00066552]
	Learning Rate: 0.000665515
	LOSS [training: 0.018900340212158473 | validation: 0.04848505992010299]
	TIME [epoch: 19 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016475588020360733		[learning rate: 0.00066123]
	Learning Rate: 0.000661227
	LOSS [training: 0.016475588020360733 | validation: 0.049235187233645006]
	TIME [epoch: 19 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017488384881444975		[learning rate: 0.00065697]
	Learning Rate: 0.000656967
	LOSS [training: 0.017488384881444975 | validation: 0.04897273724430987]
	TIME [epoch: 19.1 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01737412450718383		[learning rate: 0.00065273]
	Learning Rate: 0.000652735
	LOSS [training: 0.01737412450718383 | validation: 0.05439594607459158]
	TIME [epoch: 19 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020423098828252342		[learning rate: 0.00064853]
	Learning Rate: 0.00064853
	LOSS [training: 0.020423098828252342 | validation: 0.04814136111761785]
	TIME [epoch: 19.1 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019875095883695893		[learning rate: 0.00064435]
	Learning Rate: 0.000644351
	LOSS [training: 0.019875095883695893 | validation: 0.04751422918256485]
	TIME [epoch: 19.1 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016512126328980914		[learning rate: 0.0006402]
	Learning Rate: 0.0006402
	LOSS [training: 0.016512126328980914 | validation: 0.048172281988690634]
	TIME [epoch: 19 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020108805649666855		[learning rate: 0.00063608]
	Learning Rate: 0.000636076
	LOSS [training: 0.020108805649666855 | validation: 0.049417107495454644]
	TIME [epoch: 19 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018224445785628447		[learning rate: 0.00063198]
	Learning Rate: 0.000631978
	LOSS [training: 0.018224445785628447 | validation: 0.0486112151573632]
	TIME [epoch: 19 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01765517880773411		[learning rate: 0.00062791]
	Learning Rate: 0.000627906
	LOSS [training: 0.01765517880773411 | validation: 0.04691115686476049]
	TIME [epoch: 19 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01698529584002077		[learning rate: 0.00062386]
	Learning Rate: 0.000623861
	LOSS [training: 0.01698529584002077 | validation: 0.04842300045960241]
	TIME [epoch: 19 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01653930087262919		[learning rate: 0.00061984]
	Learning Rate: 0.000619842
	LOSS [training: 0.01653930087262919 | validation: 0.048437389032644815]
	TIME [epoch: 19 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745929686925384		[learning rate: 0.00061585]
	Learning Rate: 0.000615848
	LOSS [training: 0.01745929686925384 | validation: 0.047147745557939935]
	TIME [epoch: 19 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01855705698548813		[learning rate: 0.00061188]
	Learning Rate: 0.000611881
	LOSS [training: 0.01855705698548813 | validation: 0.04640447328992543]
	TIME [epoch: 19 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020641018779056337		[learning rate: 0.00060794]
	Learning Rate: 0.000607938
	LOSS [training: 0.020641018779056337 | validation: 0.050558102588813776]
	TIME [epoch: 18.9 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01739885971602449		[learning rate: 0.00060402]
	Learning Rate: 0.000604022
	LOSS [training: 0.01739885971602449 | validation: 0.04625192972822022]
	TIME [epoch: 18.9 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0164713525158468		[learning rate: 0.00060013]
	Learning Rate: 0.00060013
	LOSS [training: 0.0164713525158468 | validation: 0.046550446093918396]
	TIME [epoch: 19 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017419828350500922		[learning rate: 0.00059626]
	Learning Rate: 0.000596264
	LOSS [training: 0.017419828350500922 | validation: 0.04831089156140747]
	TIME [epoch: 19 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016188150538860996		[learning rate: 0.00059242]
	Learning Rate: 0.000592422
	LOSS [training: 0.016188150538860996 | validation: 0.04901090591795336]
	TIME [epoch: 19 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850785436520903		[learning rate: 0.00058861]
	Learning Rate: 0.000588606
	LOSS [training: 0.01850785436520903 | validation: 0.04716190859463206]
	TIME [epoch: 19 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019848806522277853		[learning rate: 0.00058481]
	Learning Rate: 0.000584814
	LOSS [training: 0.019848806522277853 | validation: 0.0500903182594042]
	TIME [epoch: 19 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019574401691213456		[learning rate: 0.00058105]
	Learning Rate: 0.000581046
	LOSS [training: 0.019574401691213456 | validation: 0.050109093022213724]
	TIME [epoch: 18.9 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016504609875761717		[learning rate: 0.0005773]
	Learning Rate: 0.000577302
	LOSS [training: 0.016504609875761717 | validation: 0.0462789439836742]
	TIME [epoch: 19 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01666131281100461		[learning rate: 0.00057358]
	Learning Rate: 0.000573583
	LOSS [training: 0.01666131281100461 | validation: 0.04822834931080811]
	TIME [epoch: 19 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017864113870361437		[learning rate: 0.00056989]
	Learning Rate: 0.000569888
	LOSS [training: 0.017864113870361437 | validation: 0.04621598812084729]
	TIME [epoch: 19 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018022165191795815		[learning rate: 0.00056622]
	Learning Rate: 0.000566216
	LOSS [training: 0.018022165191795815 | validation: 0.04909917806602879]
	TIME [epoch: 19 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017135249118390292		[learning rate: 0.00056257]
	Learning Rate: 0.000562568
	LOSS [training: 0.017135249118390292 | validation: 0.046892906982409666]
	TIME [epoch: 19 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018709908005767616		[learning rate: 0.00055894]
	Learning Rate: 0.000558944
	LOSS [training: 0.018709908005767616 | validation: 0.04604526016955693]
	TIME [epoch: 19 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018928225774280535		[learning rate: 0.00055534]
	Learning Rate: 0.000555343
	LOSS [training: 0.018928225774280535 | validation: 0.04930082316246662]
	TIME [epoch: 19 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016727839352631627		[learning rate: 0.00055177]
	Learning Rate: 0.000551765
	LOSS [training: 0.016727839352631627 | validation: 0.04818777427005237]
	TIME [epoch: 19 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018547350557519698		[learning rate: 0.00054821]
	Learning Rate: 0.00054821
	LOSS [training: 0.018547350557519698 | validation: 0.049092732838259726]
	TIME [epoch: 19 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017115544230187043		[learning rate: 0.00054468]
	Learning Rate: 0.000544679
	LOSS [training: 0.017115544230187043 | validation: 0.047766300810516034]
	TIME [epoch: 19 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017758687880980693		[learning rate: 0.00054117]
	Learning Rate: 0.000541169
	LOSS [training: 0.017758687880980693 | validation: 0.04490806101242146]
	TIME [epoch: 19 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017797694061384393		[learning rate: 0.00053768]
	Learning Rate: 0.000537683
	LOSS [training: 0.017797694061384393 | validation: 0.047139224129277055]
	TIME [epoch: 19 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019321257762206237		[learning rate: 0.00053422]
	Learning Rate: 0.000534219
	LOSS [training: 0.019321257762206237 | validation: 0.04726657359325751]
	TIME [epoch: 19 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018085322098356997		[learning rate: 0.00053078]
	Learning Rate: 0.000530777
	LOSS [training: 0.018085322098356997 | validation: 0.05091843056922582]
	TIME [epoch: 19 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01745159072000482		[learning rate: 0.00052736]
	Learning Rate: 0.000527358
	LOSS [training: 0.01745159072000482 | validation: 0.046354217711838674]
	TIME [epoch: 19 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019446185732151573		[learning rate: 0.00052396]
	Learning Rate: 0.00052396
	LOSS [training: 0.019446185732151573 | validation: 0.047725272615422636]
	TIME [epoch: 18.9 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017108478893618134		[learning rate: 0.00052058]
	Learning Rate: 0.000520584
	LOSS [training: 0.017108478893618134 | validation: 0.046639542689621304]
	TIME [epoch: 19 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017154917318465735		[learning rate: 0.00051723]
	Learning Rate: 0.000517231
	LOSS [training: 0.017154917318465735 | validation: 0.04614069714679999]
	TIME [epoch: 19 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018937687665016942		[learning rate: 0.0005139]
	Learning Rate: 0.000513898
	LOSS [training: 0.018937687665016942 | validation: 0.04723696639487457]
	TIME [epoch: 19 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020725897605945058		[learning rate: 0.00051059]
	Learning Rate: 0.000510587
	LOSS [training: 0.020725897605945058 | validation: 0.04857438116732371]
	TIME [epoch: 19.1 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017084689485647998		[learning rate: 0.0005073]
	Learning Rate: 0.000507298
	LOSS [training: 0.017084689485647998 | validation: 0.04866521342645317]
	TIME [epoch: 19 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01867986471290201		[learning rate: 0.00050403]
	Learning Rate: 0.00050403
	LOSS [training: 0.01867986471290201 | validation: 0.048473870860888224]
	TIME [epoch: 19 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017451190249327085		[learning rate: 0.00050078]
	Learning Rate: 0.000500782
	LOSS [training: 0.017451190249327085 | validation: 0.049740001113012786]
	TIME [epoch: 85.4 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019099775380564843		[learning rate: 0.00049756]
	Learning Rate: 0.000497556
	LOSS [training: 0.019099775380564843 | validation: 0.04580942260701362]
	TIME [epoch: 40 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0161189608319282		[learning rate: 0.00049435]
	Learning Rate: 0.000494351
	LOSS [training: 0.0161189608319282 | validation: 0.047619192784586324]
	TIME [epoch: 40 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01877195653854884		[learning rate: 0.00049117]
	Learning Rate: 0.000491166
	LOSS [training: 0.01877195653854884 | validation: 0.046845444654584845]
	TIME [epoch: 40 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018799061575926597		[learning rate: 0.000488]
	Learning Rate: 0.000488001
	LOSS [training: 0.018799061575926597 | validation: 0.04957172083649356]
	TIME [epoch: 39.9 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01846950418434841		[learning rate: 0.00048486]
	Learning Rate: 0.000484857
	LOSS [training: 0.01846950418434841 | validation: 0.046427343800238524]
	TIME [epoch: 40 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018031715728938757		[learning rate: 0.00048173]
	Learning Rate: 0.000481734
	LOSS [training: 0.018031715728938757 | validation: 0.0485086283748866]
	TIME [epoch: 40 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016917656130077303		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.016917656130077303 | validation: 0.04640617752828179]
	TIME [epoch: 40 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016676572614420605		[learning rate: 0.00047555]
	Learning Rate: 0.000475546
	LOSS [training: 0.016676572614420605 | validation: 0.04847322063347173]
	TIME [epoch: 40 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015949265684745702		[learning rate: 0.00047248]
	Learning Rate: 0.000472483
	LOSS [training: 0.015949265684745702 | validation: 0.04638267626630581]
	TIME [epoch: 40 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020352127109455168		[learning rate: 0.00046944]
	Learning Rate: 0.000469439
	LOSS [training: 0.020352127109455168 | validation: 0.04711749198665132]
	TIME [epoch: 40 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018540487026709174		[learning rate: 0.00046641]
	Learning Rate: 0.000466414
	LOSS [training: 0.018540487026709174 | validation: 0.04922305669790525]
	TIME [epoch: 40 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718767383175938		[learning rate: 0.00046341]
	Learning Rate: 0.000463409
	LOSS [training: 0.01718767383175938 | validation: 0.04715793809942839]
	TIME [epoch: 39.9 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016785688714369605		[learning rate: 0.00046042]
	Learning Rate: 0.000460424
	LOSS [training: 0.016785688714369605 | validation: 0.04783051020566227]
	TIME [epoch: 40 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018363728985672047		[learning rate: 0.00045746]
	Learning Rate: 0.000457458
	LOSS [training: 0.018363728985672047 | validation: 0.04832139628569612]
	TIME [epoch: 40 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019492243743542345		[learning rate: 0.00045451]
	Learning Rate: 0.00045451
	LOSS [training: 0.019492243743542345 | validation: 0.04618157981418251]
	TIME [epoch: 39.9 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01665645756602169		[learning rate: 0.00045158]
	Learning Rate: 0.000451582
	LOSS [training: 0.01665645756602169 | validation: 0.045683580092774206]
	TIME [epoch: 40 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018293525154143373		[learning rate: 0.00044867]
	Learning Rate: 0.000448673
	LOSS [training: 0.018293525154143373 | validation: 0.04571442784795703]
	TIME [epoch: 40 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017178979350353302		[learning rate: 0.00044578]
	Learning Rate: 0.000445782
	LOSS [training: 0.017178979350353302 | validation: 0.047749004452519915]
	TIME [epoch: 40 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018312781178301662		[learning rate: 0.00044291]
	Learning Rate: 0.00044291
	LOSS [training: 0.018312781178301662 | validation: 0.04844777686934885]
	TIME [epoch: 40 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018545571148166424		[learning rate: 0.00044006]
	Learning Rate: 0.000440057
	LOSS [training: 0.018545571148166424 | validation: 0.046822947336321745]
	TIME [epoch: 40 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017832599550844187		[learning rate: 0.00043722]
	Learning Rate: 0.000437222
	LOSS [training: 0.017832599550844187 | validation: 0.04828261176978369]
	TIME [epoch: 40 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016598351161024847		[learning rate: 0.0004344]
	Learning Rate: 0.000434405
	LOSS [training: 0.016598351161024847 | validation: 0.048537493723708254]
	TIME [epoch: 40.1 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207569430196028		[learning rate: 0.00043161]
	Learning Rate: 0.000431606
	LOSS [training: 0.02207569430196028 | validation: 0.049078882611119645]
	TIME [epoch: 40 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016788052456626373		[learning rate: 0.00042883]
	Learning Rate: 0.000428826
	LOSS [training: 0.016788052456626373 | validation: 0.047393501938195644]
	TIME [epoch: 40.1 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017585337051278332		[learning rate: 0.00042606]
	Learning Rate: 0.000426063
	LOSS [training: 0.017585337051278332 | validation: 0.047383555106990966]
	TIME [epoch: 40 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015659757163084424		[learning rate: 0.00042332]
	Learning Rate: 0.000423318
	LOSS [training: 0.015659757163084424 | validation: 0.04743173474270959]
	TIME [epoch: 40 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01585444185912361		[learning rate: 0.00042059]
	Learning Rate: 0.000420591
	LOSS [training: 0.01585444185912361 | validation: 0.047179715239680536]
	TIME [epoch: 40 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019395156781652188		[learning rate: 0.00041788]
	Learning Rate: 0.000417881
	LOSS [training: 0.019395156781652188 | validation: 0.04910125451126558]
	TIME [epoch: 40 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017503794533145812		[learning rate: 0.00041519]
	Learning Rate: 0.000415189
	LOSS [training: 0.017503794533145812 | validation: 0.04718654489844264]
	TIME [epoch: 40 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01860381010519299		[learning rate: 0.00041251]
	Learning Rate: 0.000412514
	LOSS [training: 0.01860381010519299 | validation: 0.04803948266982214]
	TIME [epoch: 40 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020079881669323937		[learning rate: 0.00040986]
	Learning Rate: 0.000409856
	LOSS [training: 0.020079881669323937 | validation: 0.046706453546329005]
	TIME [epoch: 40 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016477403698229753		[learning rate: 0.00040722]
	Learning Rate: 0.000407216
	LOSS [training: 0.016477403698229753 | validation: 0.047344371600433276]
	TIME [epoch: 40 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016175660411365447		[learning rate: 0.00040459]
	Learning Rate: 0.000404592
	LOSS [training: 0.016175660411365447 | validation: 0.0460014061861006]
	TIME [epoch: 39.9 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018752843544795644		[learning rate: 0.00040199]
	Learning Rate: 0.000401986
	LOSS [training: 0.018752843544795644 | validation: 0.04916271487618208]
	TIME [epoch: 39.9 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017022599318006038		[learning rate: 0.0003994]
	Learning Rate: 0.000399396
	LOSS [training: 0.017022599318006038 | validation: 0.04898418448567173]
	TIME [epoch: 40 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01711701387284942		[learning rate: 0.00039682]
	Learning Rate: 0.000396823
	LOSS [training: 0.01711701387284942 | validation: 0.04532362355295869]
	TIME [epoch: 40 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01644484961220764		[learning rate: 0.00039427]
	Learning Rate: 0.000394266
	LOSS [training: 0.01644484961220764 | validation: 0.047287170228389824]
	TIME [epoch: 40 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017043272561093295		[learning rate: 0.00039173]
	Learning Rate: 0.000391726
	LOSS [training: 0.017043272561093295 | validation: 0.04762793947265109]
	TIME [epoch: 40 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02069890158509672		[learning rate: 0.0003892]
	Learning Rate: 0.000389202
	LOSS [training: 0.02069890158509672 | validation: 0.047400392451645346]
	TIME [epoch: 39.9 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016662287900186593		[learning rate: 0.00038669]
	Learning Rate: 0.000386695
	LOSS [training: 0.016662287900186593 | validation: 0.04826505432614317]
	TIME [epoch: 40 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018452505042586914		[learning rate: 0.0003842]
	Learning Rate: 0.000384204
	LOSS [training: 0.018452505042586914 | validation: 0.047140072011133086]
	TIME [epoch: 40 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017260632883584193		[learning rate: 0.00038173]
	Learning Rate: 0.000381728
	LOSS [training: 0.017260632883584193 | validation: 0.04665642819259963]
	TIME [epoch: 40 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018020079509736935		[learning rate: 0.00037927]
	Learning Rate: 0.000379269
	LOSS [training: 0.018020079509736935 | validation: 0.049612526949565465]
	TIME [epoch: 40 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017576338552840395		[learning rate: 0.00037683]
	Learning Rate: 0.000376825
	LOSS [training: 0.017576338552840395 | validation: 0.04553063401666142]
	TIME [epoch: 40 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017032087777129036		[learning rate: 0.0003744]
	Learning Rate: 0.000374398
	LOSS [training: 0.017032087777129036 | validation: 0.047787197063691084]
	TIME [epoch: 40 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019060603169229626		[learning rate: 0.00037199]
	Learning Rate: 0.000371986
	LOSS [training: 0.019060603169229626 | validation: 0.047966407810622294]
	TIME [epoch: 40 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02004728788097642		[learning rate: 0.00036959]
	Learning Rate: 0.000369589
	LOSS [training: 0.02004728788097642 | validation: 0.04719030987974103]
	TIME [epoch: 40 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015942749747869266		[learning rate: 0.00036721]
	Learning Rate: 0.000367208
	LOSS [training: 0.015942749747869266 | validation: 0.04710590795701663]
	TIME [epoch: 39.9 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016199730651549532		[learning rate: 0.00036484]
	Learning Rate: 0.000364842
	LOSS [training: 0.016199730651549532 | validation: 0.0469208735363903]
	TIME [epoch: 40 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016735970501974066		[learning rate: 0.00036249]
	Learning Rate: 0.000362492
	LOSS [training: 0.016735970501974066 | validation: 0.04790047744962912]
	TIME [epoch: 40 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01706855811028797		[learning rate: 0.00036016]
	Learning Rate: 0.000360156
	LOSS [training: 0.01706855811028797 | validation: 0.0490444163058812]
	TIME [epoch: 40 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019973150842849063		[learning rate: 0.00035784]
	Learning Rate: 0.000357836
	LOSS [training: 0.019973150842849063 | validation: 0.047083687231315285]
	TIME [epoch: 40 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019858022267704542		[learning rate: 0.00035553]
	Learning Rate: 0.000355531
	LOSS [training: 0.019858022267704542 | validation: 0.0477057531703473]
	TIME [epoch: 40 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018286668934624058		[learning rate: 0.00035324]
	Learning Rate: 0.00035324
	LOSS [training: 0.018286668934624058 | validation: 0.04672621042484683]
	TIME [epoch: 40 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016472840678946728		[learning rate: 0.00035096]
	Learning Rate: 0.000350964
	LOSS [training: 0.016472840678946728 | validation: 0.04549638713332323]
	TIME [epoch: 40 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018426812416718424		[learning rate: 0.0003487]
	Learning Rate: 0.000348703
	LOSS [training: 0.018426812416718424 | validation: 0.046977535749326935]
	TIME [epoch: 40 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016148235997006467		[learning rate: 0.00034646]
	Learning Rate: 0.000346457
	LOSS [training: 0.016148235997006467 | validation: 0.04666181009850477]
	TIME [epoch: 40 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01733882695096592		[learning rate: 0.00034422]
	Learning Rate: 0.000344225
	LOSS [training: 0.01733882695096592 | validation: 0.048381671498303656]
	TIME [epoch: 40 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01618770472719597		[learning rate: 0.00034201]
	Learning Rate: 0.000342007
	LOSS [training: 0.01618770472719597 | validation: 0.0469635380119133]
	TIME [epoch: 39.9 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02003892637528791		[learning rate: 0.0003398]
	Learning Rate: 0.000339804
	LOSS [training: 0.02003892637528791 | validation: 0.04834278428959606]
	TIME [epoch: 40 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016554172894296715		[learning rate: 0.00033761]
	Learning Rate: 0.000337614
	LOSS [training: 0.016554172894296715 | validation: 0.047404851240979755]
	TIME [epoch: 40 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017502655870513396		[learning rate: 0.00033544]
	Learning Rate: 0.000335439
	LOSS [training: 0.017502655870513396 | validation: 0.04832425823648762]
	TIME [epoch: 40 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01932303914158274		[learning rate: 0.00033328]
	Learning Rate: 0.000333278
	LOSS [training: 0.01932303914158274 | validation: 0.04989252003001689]
	TIME [epoch: 40 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017038886248508325		[learning rate: 0.00033113]
	Learning Rate: 0.000331131
	LOSS [training: 0.017038886248508325 | validation: 0.047357155141179844]
	TIME [epoch: 40 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017212798390379393		[learning rate: 0.000329]
	Learning Rate: 0.000328998
	LOSS [training: 0.017212798390379393 | validation: 0.04722893635124225]
	TIME [epoch: 39.9 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015752004242893518		[learning rate: 0.00032688]
	Learning Rate: 0.000326878
	LOSS [training: 0.015752004242893518 | validation: 0.04647525102570663]
	TIME [epoch: 40 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01828674822521412		[learning rate: 0.00032477]
	Learning Rate: 0.000324772
	LOSS [training: 0.01828674822521412 | validation: 0.049152144472375044]
	TIME [epoch: 39.9 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01610552927403761		[learning rate: 0.00032268]
	Learning Rate: 0.00032268
	LOSS [training: 0.01610552927403761 | validation: 0.04650440458306389]
	TIME [epoch: 40 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019168798681509547		[learning rate: 0.0003206]
	Learning Rate: 0.000320601
	LOSS [training: 0.019168798681509547 | validation: 0.04937210902014528]
	TIME [epoch: 40 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01805665680373465		[learning rate: 0.00031854]
	Learning Rate: 0.000318535
	LOSS [training: 0.01805665680373465 | validation: 0.04712513512106225]
	TIME [epoch: 40 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01591583026542144		[learning rate: 0.00031648]
	Learning Rate: 0.000316483
	LOSS [training: 0.01591583026542144 | validation: 0.04696991255126744]
	TIME [epoch: 40 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018004821288082812		[learning rate: 0.00031444]
	Learning Rate: 0.000314444
	LOSS [training: 0.018004821288082812 | validation: 0.04635398923260434]
	TIME [epoch: 40 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0163289816468124		[learning rate: 0.00031242]
	Learning Rate: 0.000312419
	LOSS [training: 0.0163289816468124 | validation: 0.0473717628336139]
	TIME [epoch: 39.9 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016734293640125766		[learning rate: 0.00031041]
	Learning Rate: 0.000310406
	LOSS [training: 0.016734293640125766 | validation: 0.04494950091960359]
	TIME [epoch: 40 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01633422359163978		[learning rate: 0.00030841]
	Learning Rate: 0.000308406
	LOSS [training: 0.01633422359163978 | validation: 0.04652507929366167]
	TIME [epoch: 39.9 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016285198905620975		[learning rate: 0.00030642]
	Learning Rate: 0.000306419
	LOSS [training: 0.016285198905620975 | validation: 0.04663569525855849]
	TIME [epoch: 40 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017265267302693184		[learning rate: 0.00030444]
	Learning Rate: 0.000304445
	LOSS [training: 0.017265267302693184 | validation: 0.04654510221388873]
	TIME [epoch: 40 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01722573983637333		[learning rate: 0.00030248]
	Learning Rate: 0.000302484
	LOSS [training: 0.01722573983637333 | validation: 0.04583747114531283]
	TIME [epoch: 40 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016871881679049155		[learning rate: 0.00030053]
	Learning Rate: 0.000300535
	LOSS [training: 0.016871881679049155 | validation: 0.047568569763350596]
	TIME [epoch: 40 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01838047571859753		[learning rate: 0.0002986]
	Learning Rate: 0.000298598
	LOSS [training: 0.01838047571859753 | validation: 0.04677301748118697]
	TIME [epoch: 40 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018165879823737227		[learning rate: 0.00029667]
	Learning Rate: 0.000296675
	LOSS [training: 0.018165879823737227 | validation: 0.045917884410603585]
	TIME [epoch: 40.1 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015987740700427536		[learning rate: 0.00029476]
	Learning Rate: 0.000294763
	LOSS [training: 0.015987740700427536 | validation: 0.046994443571818784]
	TIME [epoch: 40 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018304900433611604		[learning rate: 0.00029286]
	Learning Rate: 0.000292864
	LOSS [training: 0.018304900433611604 | validation: 0.04685070623569171]
	TIME [epoch: 40 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01794688165349744		[learning rate: 0.00029098]
	Learning Rate: 0.000290978
	LOSS [training: 0.01794688165349744 | validation: 0.04585349361087329]
	TIME [epoch: 40 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01699460151155465		[learning rate: 0.0002891]
	Learning Rate: 0.000289103
	LOSS [training: 0.01699460151155465 | validation: 0.046304920214293416]
	TIME [epoch: 40 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016903960310362953		[learning rate: 0.00028724]
	Learning Rate: 0.00028724
	LOSS [training: 0.016903960310362953 | validation: 0.04728815790646166]
	TIME [epoch: 40 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017975332695869404		[learning rate: 0.00028539]
	Learning Rate: 0.00028539
	LOSS [training: 0.017975332695869404 | validation: 0.04601700809922575]
	TIME [epoch: 40 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016586624217614036		[learning rate: 0.00028355]
	Learning Rate: 0.000283551
	LOSS [training: 0.016586624217614036 | validation: 0.04897014855713708]
	TIME [epoch: 39.9 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016611300690289217		[learning rate: 0.00028172]
	Learning Rate: 0.000281724
	LOSS [training: 0.016611300690289217 | validation: 0.046849155018186525]
	TIME [epoch: 40 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017030884305653728		[learning rate: 0.00027991]
	Learning Rate: 0.000279909
	LOSS [training: 0.017030884305653728 | validation: 0.046466938000248335]
	TIME [epoch: 39.9 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01630115041046601		[learning rate: 0.00027811]
	Learning Rate: 0.000278106
	LOSS [training: 0.01630115041046601 | validation: 0.046222066606346965]
	TIME [epoch: 40 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01689287118336421		[learning rate: 0.00027631]
	Learning Rate: 0.000276314
	LOSS [training: 0.01689287118336421 | validation: 0.048221851856187374]
	TIME [epoch: 40 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016564194695327432		[learning rate: 0.00027453]
	Learning Rate: 0.000274534
	LOSS [training: 0.016564194695327432 | validation: 0.04733774154824486]
	TIME [epoch: 40 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850027446832993		[learning rate: 0.00027277]
	Learning Rate: 0.000272765
	LOSS [training: 0.01850027446832993 | validation: 0.04843132756026697]
	TIME [epoch: 40 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01702380099225523		[learning rate: 0.00027101]
	Learning Rate: 0.000271008
	LOSS [training: 0.01702380099225523 | validation: 0.047454076258036604]
	TIME [epoch: 40 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.015915823817701884		[learning rate: 0.00026926]
	Learning Rate: 0.000269262
	LOSS [training: 0.015915823817701884 | validation: 0.04826455427822764]
	TIME [epoch: 40 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018453172032330288		[learning rate: 0.00026753]
	Learning Rate: 0.000267527
	LOSS [training: 0.018453172032330288 | validation: 0.04821183128279937]
	TIME [epoch: 40 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018307541852680007		[learning rate: 0.0002658]
	Learning Rate: 0.000265804
	LOSS [training: 0.018307541852680007 | validation: 0.046371475884493286]
	TIME [epoch: 40 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017834775809770644		[learning rate: 0.00026409]
	Learning Rate: 0.000264091
	LOSS [training: 0.017834775809770644 | validation: 0.046603708711096856]
	TIME [epoch: 40 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0181796991004556		[learning rate: 0.00026239]
	Learning Rate: 0.00026239
	LOSS [training: 0.0181796991004556 | validation: 0.047369322894769805]
	TIME [epoch: 40.2 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016706084535384844		[learning rate: 0.0002607]
	Learning Rate: 0.0002607
	LOSS [training: 0.016706084535384844 | validation: 0.047311579552628893]
	TIME [epoch: 40.2 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778629703311575		[learning rate: 0.00025902]
	Learning Rate: 0.00025902
	LOSS [training: 0.01778629703311575 | validation: 0.0460706662916399]
	TIME [epoch: 40.2 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018598692819395926		[learning rate: 0.00025735]
	Learning Rate: 0.000257351
	LOSS [training: 0.018598692819395926 | validation: 0.046399796196817576]
	TIME [epoch: 40.1 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01649134142905206		[learning rate: 0.00025569]
	Learning Rate: 0.000255693
	LOSS [training: 0.01649134142905206 | validation: 0.04806943767239561]
	TIME [epoch: 40.1 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0161839826066568		[learning rate: 0.00025405]
	Learning Rate: 0.000254046
	LOSS [training: 0.0161839826066568 | validation: 0.047964197672782184]
	TIME [epoch: 40.2 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01904783707396172		[learning rate: 0.00025241]
	Learning Rate: 0.000252409
	LOSS [training: 0.01904783707396172 | validation: 0.04847487533995298]
	TIME [epoch: 40.1 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016525476375899233		[learning rate: 0.00025078]
	Learning Rate: 0.000250783
	LOSS [training: 0.016525476375899233 | validation: 0.04792883936472332]
	TIME [epoch: 40.2 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset3_20241208_152033/states/model_facs_dec2_v1_argset3_608.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 10620.050 seconds.
