Args:
Namespace(name='model_facs_dec1_v1_argset1', outdir='out/model_training/model_facs_dec1_v1_argset1', training_data='data/training_data/facs/facs_dec1_v1/training', validation_data='data/training_data/facs/facs_dec1_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.1, 1.3, 1.5, 2.0], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3139082630

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.344961555921131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.344961555921131 | validation: 1.1897303229024392]
	TIME [epoch: 32.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2648697142332004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2648697142332004 | validation: 1.1022849565495494]
	TIME [epoch: 8.63 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.2018375830992425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2018375830992425 | validation: 1.0395457066668143]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1676511205221047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1676511205221047 | validation: 1.0608641293614185]
	TIME [epoch: 8.58 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1517725131223637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1517725131223637 | validation: 1.022858461176909]
	TIME [epoch: 8.58 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1139510279628644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1139510279628644 | validation: 0.985142346284601]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.0684315617048166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0684315617048166 | validation: 0.9680830592865028]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.0315362281268523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0315362281268523 | validation: 0.9441381437835883]
	TIME [epoch: 8.59 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.9913806428894003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9913806428894003 | validation: 0.8847598078194666]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.9504756902156547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9504756902156547 | validation: 0.8798863902936114]
	TIME [epoch: 8.59 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.9748494710802441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9748494710802441 | validation: 0.816162564722642]
	TIME [epoch: 8.58 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.812842009081033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.812842009081033 | validation: 0.8481982663114902]
	TIME [epoch: 8.59 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.81986720286651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.81986720286651 | validation: 0.7008071713637289]
	TIME [epoch: 8.58 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.7270372272085707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7270372272085707 | validation: 0.595046770503713]
	TIME [epoch: 8.63 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.665871763368077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.665871763368077 | validation: 0.606465470918778]
	TIME [epoch: 8.63 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6076134597544375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6076134597544375 | validation: 0.5490799907485668]
	TIME [epoch: 8.61 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6047028741886592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6047028741886592 | validation: 0.4933962340048958]
	TIME [epoch: 8.6 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.512237959542854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.512237959542854 | validation: 0.45820606771215033]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4904823052305623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4904823052305623 | validation: 0.4090212028981255]
	TIME [epoch: 8.61 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.46178736309188806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46178736309188806 | validation: 0.4219056465902451]
	TIME [epoch: 8.62 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4735517634916564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4735517634916564 | validation: 0.38233295581502713]
	TIME [epoch: 8.66 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4395944055734549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4395944055734549 | validation: 0.41466529381746076]
	TIME [epoch: 8.67 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.46842560958354634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46842560958354634 | validation: 0.3816354984319785]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4118950142691106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4118950142691106 | validation: 0.3484181170441679]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.39943392526642324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39943392526642324 | validation: 0.35031710791568893]
	TIME [epoch: 8.64 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.44606080728480957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44606080728480957 | validation: 0.33305378423520915]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.38173842229269117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38173842229269117 | validation: 0.34127061467968867]
	TIME [epoch: 8.61 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.39795202280638514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39795202280638514 | validation: 0.3740023012625853]
	TIME [epoch: 8.64 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4093618521023222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4093618521023222 | validation: 0.3476648698293162]
	TIME [epoch: 8.64 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.37364215540470364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37364215540470364 | validation: 0.31801286619523933]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3859292729078154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3859292729078154 | validation: 0.3274370182674197]
	TIME [epoch: 8.61 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.37254341368806027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37254341368806027 | validation: 0.3339066138472859]
	TIME [epoch: 8.6 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3929935188071247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3929935188071247 | validation: 0.361378156110882]
	TIME [epoch: 8.6 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.38171293433911563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38171293433911563 | validation: 0.3136813959483339]
	TIME [epoch: 8.61 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.37864489792271305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37864489792271305 | validation: 0.3140322465560167]
	TIME [epoch: 8.62 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.37672279790478114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37672279790478114 | validation: 0.30391413564288017]
	TIME [epoch: 8.61 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3469872205383897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3469872205383897 | validation: 0.3156310820483989]
	TIME [epoch: 8.66 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.35005637777987264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35005637777987264 | validation: 0.2907013676631519]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3547359435760473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3547359435760473 | validation: 0.2855350618487744]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.35713105284762664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35713105284762664 | validation: 0.32455523931394364]
	TIME [epoch: 8.65 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.377042161250543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.377042161250543 | validation: 0.30887355808227857]
	TIME [epoch: 8.64 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.34745869315574457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.34745869315574457 | validation: 0.28722108489170656]
	TIME [epoch: 8.63 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3256164585591914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3256164585591914 | validation: 0.3054138643757008]
	TIME [epoch: 8.63 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3434835734338419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3434835734338419 | validation: 0.302706823206187]
	TIME [epoch: 8.64 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3322673994313677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3322673994313677 | validation: 0.2680339685909293]
	TIME [epoch: 8.62 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31837989097727964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31837989097727964 | validation: 0.29297128173854]
	TIME [epoch: 8.64 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3267381683808958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3267381683808958 | validation: 0.2638290906501337]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32959445631774115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32959445631774115 | validation: 0.27279111456432337]
	TIME [epoch: 8.65 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3419230779291094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3419230779291094 | validation: 0.27150384550495266]
	TIME [epoch: 8.64 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.33641235777788975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33641235777788975 | validation: 0.288078218489774]
	TIME [epoch: 8.63 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3374241170408614		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.3374241170408614 | validation: 0.29972384799433527]
	TIME [epoch: 39.2 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3274200102175591		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.3274200102175591 | validation: 0.25695161055863514]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3216953422051145		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.3216953422051145 | validation: 0.2944557126590648]
	TIME [epoch: 16.4 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31421567416313484		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.31421567416313484 | validation: 0.2777466140146007]
	TIME [epoch: 16.5 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3314861889005771		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.3314861889005771 | validation: 0.2625362416949607]
	TIME [epoch: 16.5 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3008370109376403		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.3008370109376403 | validation: 0.2526230238455067]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31503507574568856		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.31503507574568856 | validation: 0.2481641136165627]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32512771746718566		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.32512771746718566 | validation: 0.27892218298173777]
	TIME [epoch: 16.5 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3172400194456179		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.3172400194456179 | validation: 0.24182270311725557]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3112487869153559		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.3112487869153559 | validation: 0.2763412452176799]
	TIME [epoch: 16.6 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3179747098074652		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.3179747098074652 | validation: 0.24465098510617297]
	TIME [epoch: 16.5 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29628523280886115		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.29628523280886115 | validation: 0.24271402449830534]
	TIME [epoch: 16.5 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2946828634615178		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.2946828634615178 | validation: 0.24038145222649865]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29193962964769665		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.29193962964769665 | validation: 0.25481121004688967]
	TIME [epoch: 16.5 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3006688014431876		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.3006688014431876 | validation: 0.26004416891996923]
	TIME [epoch: 16.4 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3006787005606267		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.3006787005606267 | validation: 0.25407974069380546]
	TIME [epoch: 16.5 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29988137759423783		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.29988137759423783 | validation: 0.23761725323805294]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2916153956640169		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.2916153956640169 | validation: 0.237258835594214]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3040571952810271		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.3040571952810271 | validation: 0.23491457835732454]
	TIME [epoch: 16.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28522797760241597		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.28522797760241597 | validation: 0.23430942959074832]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29739715063939737		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.29739715063939737 | validation: 0.2389280721149591]
	TIME [epoch: 16.5 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28534995268098257		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.28534995268098257 | validation: 0.22885893101354093]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2866150774200115		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.2866150774200115 | validation: 0.2425083036166808]
	TIME [epoch: 16.5 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27938086859977834		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.27938086859977834 | validation: 0.23799140521877962]
	TIME [epoch: 16.5 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27761658278423074		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.27761658278423074 | validation: 0.23580718540670823]
	TIME [epoch: 16.5 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28674222942229144		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.28674222942229144 | validation: 0.2501471986963019]
	TIME [epoch: 16.5 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29058230690337156		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.29058230690337156 | validation: 0.240697742523231]
	TIME [epoch: 16.5 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2799720590653723		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.2799720590653723 | validation: 0.2345731842098629]
	TIME [epoch: 16.5 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2874639089140401		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.2874639089140401 | validation: 0.256848498376388]
	TIME [epoch: 16.5 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2875316816033153		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.2875316816033153 | validation: 0.2436808168754523]
	TIME [epoch: 16.5 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27835245628110156		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.27835245628110156 | validation: 0.2241191620895573]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28474962924103203		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.28474962924103203 | validation: 0.2428705947502081]
	TIME [epoch: 16.5 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29004284598441143		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.29004284598441143 | validation: 0.22899868370713788]
	TIME [epoch: 16.5 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2848358976275219		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.2848358976275219 | validation: 0.22259978368376787]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_84.pth
	Model improved!!!
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27883169705504635		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.27883169705504635 | validation: 0.22929887730284584]
	TIME [epoch: 16.5 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28739967338143085		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.28739967338143085 | validation: 0.22705882666528962]
	TIME [epoch: 16.5 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29006609834289676		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.29006609834289676 | validation: 0.22773214135562858]
	TIME [epoch: 16.5 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2847767567562806		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.2847767567562806 | validation: 0.23921547035729232]
	TIME [epoch: 16.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2836472348252696		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.2836472348252696 | validation: 0.24496735929870644]
	TIME [epoch: 16.5 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2833564078524734		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.2833564078524734 | validation: 0.2215531749482218]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28462525394193827		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.28462525394193827 | validation: 0.217545913248511]
	TIME [epoch: 16.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28684437730596124		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.28684437730596124 | validation: 0.23357058705931197]
	TIME [epoch: 16.5 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2807814459524999		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.2807814459524999 | validation: 0.22755461353054507]
	TIME [epoch: 16.4 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27411363010116524		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.27411363010116524 | validation: 0.22552699356854794]
	TIME [epoch: 16.4 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29282373388003835		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.29282373388003835 | validation: 0.2369402182681512]
	TIME [epoch: 16.4 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28749303796914427		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.28749303796914427 | validation: 0.2192889634703467]
	TIME [epoch: 16.4 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27974888099072387		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.27974888099072387 | validation: 0.22204794558984084]
	TIME [epoch: 16.4 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2829712092843869		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.2829712092843869 | validation: 0.22666662555590858]
	TIME [epoch: 16.4 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2741976169835297		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.2741976169835297 | validation: 0.22722421865090756]
	TIME [epoch: 16.4 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27620907634777425		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.27620907634777425 | validation: 0.21940159501844336]
	TIME [epoch: 16.4 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2758887847880467		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.2758887847880467 | validation: 0.21815700820105194]
	TIME [epoch: 57.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2750107948439966		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.2750107948439966 | validation: 0.2208088193222885]
	TIME [epoch: 34.5 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29804188958835426		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.29804188958835426 | validation: 0.22691748419348468]
	TIME [epoch: 34.6 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26914170883942073		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.26914170883942073 | validation: 0.21869336476343637]
	TIME [epoch: 34.6 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27463771512404134		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.27463771512404134 | validation: 0.22731968156411772]
	TIME [epoch: 34.6 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28802939639519576		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.28802939639519576 | validation: 0.2151620471815316]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27194980033763755		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.27194980033763755 | validation: 0.22308923300790084]
	TIME [epoch: 34.5 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2701502728370053		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.2701502728370053 | validation: 0.22091459330889843]
	TIME [epoch: 34.6 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2730004327036642		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.2730004327036642 | validation: 0.24217265142034777]
	TIME [epoch: 34.6 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28051183291363296		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.28051183291363296 | validation: 0.22355980295283695]
	TIME [epoch: 34.5 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2798835629446225		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.2798835629446225 | validation: 0.21437783088298415]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2821315321734241		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.2821315321734241 | validation: 0.21775935159760423]
	TIME [epoch: 34.6 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27119488451700563		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.27119488451700563 | validation: 0.21582560066320972]
	TIME [epoch: 34.6 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2708993644571871		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.2708993644571871 | validation: 0.219781073550591]
	TIME [epoch: 34.6 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27522262907161815		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.27522262907161815 | validation: 0.22408038289352722]
	TIME [epoch: 34.6 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26309632756389556		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.26309632756389556 | validation: 0.22772248037093878]
	TIME [epoch: 34.6 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27435391451006524		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.27435391451006524 | validation: 0.21899376184549668]
	TIME [epoch: 34.5 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27349557353383974		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.27349557353383974 | validation: 0.22244703136350658]
	TIME [epoch: 34.6 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2703463102638408		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.2703463102638408 | validation: 0.21588112595820155]
	TIME [epoch: 34.5 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639805901544755		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.2639805901544755 | validation: 0.22023954229486856]
	TIME [epoch: 34.5 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28771117635319715		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.28771117635319715 | validation: 0.21276682611224523]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26752447775595195		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.26752447775595195 | validation: 0.2111557379126232]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26468993028878707		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.26468993028878707 | validation: 0.22115524115442872]
	TIME [epoch: 34.5 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26373150222046804		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.26373150222046804 | validation: 0.23695590607728872]
	TIME [epoch: 34.5 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.28139906132234355		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.28139906132234355 | validation: 0.21975752985888847]
	TIME [epoch: 34.6 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660056729756603		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.2660056729756603 | validation: 0.21765745982654727]
	TIME [epoch: 34.5 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2684752048275943		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.2684752048275943 | validation: 0.2165166517379115]
	TIME [epoch: 34.5 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26894888361937214		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.26894888361937214 | validation: 0.22061872111556885]
	TIME [epoch: 34.5 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2690524467075423		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.2690524467075423 | validation: 0.2220831983731447]
	TIME [epoch: 34.6 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2637949088576526		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.2637949088576526 | validation: 0.2191394954988192]
	TIME [epoch: 34.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614052968275681		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.2614052968275681 | validation: 0.21974084831351554]
	TIME [epoch: 34.5 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25697819038941316		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.25697819038941316 | validation: 0.2351994316544283]
	TIME [epoch: 34.5 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.268413252549983		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.268413252549983 | validation: 0.2274734281906084]
	TIME [epoch: 34.5 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27053888651730323		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.27053888651730323 | validation: 0.2243745144583802]
	TIME [epoch: 34.5 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2661381409448432		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.2661381409448432 | validation: 0.2137573069739096]
	TIME [epoch: 34.5 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26020050016192625		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.26020050016192625 | validation: 0.21522257664273306]
	TIME [epoch: 34.6 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26824902861657285		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.26824902861657285 | validation: 0.22149104958968654]
	TIME [epoch: 34.5 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2582892384554566		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.2582892384554566 | validation: 0.22476126409479588]
	TIME [epoch: 34.5 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577846646911463		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.2577846646911463 | validation: 0.23203054358885292]
	TIME [epoch: 34.5 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2841424899943661		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.2841424899943661 | validation: 0.22047768405438523]
	TIME [epoch: 34.5 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26444173616660843		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.26444173616660843 | validation: 0.21221341828984008]
	TIME [epoch: 34.5 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2659259712149317		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.2659259712149317 | validation: 0.22642448561496203]
	TIME [epoch: 34.5 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2719105998624152		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.2719105998624152 | validation: 0.21767326201270998]
	TIME [epoch: 34.5 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2588244073857004		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.2588244073857004 | validation: 0.21922120440418014]
	TIME [epoch: 34.5 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26974373220555214		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.26974373220555214 | validation: 0.21116573534226712]
	TIME [epoch: 34.6 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26906731128038247		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.26906731128038247 | validation: 0.2179258115986329]
	TIME [epoch: 34.5 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2660835399952228		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.2660835399952228 | validation: 0.21790633976439314]
	TIME [epoch: 34.5 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687973747582137		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.2687973747582137 | validation: 0.22100358591275487]
	TIME [epoch: 34.5 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2605794044554303		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.2605794044554303 | validation: 0.22173324251402615]
	TIME [epoch: 34.5 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2664043038766409		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.2664043038766409 | validation: 0.21055443500240223]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2629653980194399		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.2629653980194399 | validation: 0.2113669925768186]
	TIME [epoch: 34.5 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2606412592558383		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.2606412592558383 | validation: 0.21567676029384747]
	TIME [epoch: 34.4 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2631975496449545		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.2631975496449545 | validation: 0.21379519612607942]
	TIME [epoch: 34.5 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2654149979703823		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.2654149979703823 | validation: 0.22440693257235655]
	TIME [epoch: 34.6 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26712288500349957		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.26712288500349957 | validation: 0.21660060929425584]
	TIME [epoch: 34.5 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25429943945935324		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.25429943945935324 | validation: 0.21846383747593162]
	TIME [epoch: 34.5 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25926458034586514		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.25926458034586514 | validation: 0.2148224146198507]
	TIME [epoch: 34.5 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2688561621495202		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.2688561621495202 | validation: 0.2197858032737395]
	TIME [epoch: 34.5 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2624357823511529		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.2624357823511529 | validation: 0.21600976344440498]
	TIME [epoch: 34.5 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25893392793358466		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.25893392793358466 | validation: 0.2196318235223398]
	TIME [epoch: 34.5 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2567786248403629		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.2567786248403629 | validation: 0.21571080923787758]
	TIME [epoch: 34.6 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26363307118334806		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.26363307118334806 | validation: 0.21487527015002716]
	TIME [epoch: 34.5 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2569737491412518		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.2569737491412518 | validation: 0.21218703915339082]
	TIME [epoch: 34.5 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26549559711833276		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.26549559711833276 | validation: 0.21735595735433044]
	TIME [epoch: 34.5 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564005199464486		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.2564005199464486 | validation: 0.22568856862058215]
	TIME [epoch: 34.5 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568384178486134		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.2568384178486134 | validation: 0.21727998847453422]
	TIME [epoch: 34.5 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25991811577099894		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.25991811577099894 | validation: 0.21020952363599016]
	TIME [epoch: 34.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25601688943564044		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.25601688943564044 | validation: 0.21670880937528292]
	TIME [epoch: 34.6 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26368161390934153		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.26368161390934153 | validation: 0.21083650880988364]
	TIME [epoch: 34.5 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2656837073488715		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.2656837073488715 | validation: 0.2165074044073317]
	TIME [epoch: 34.6 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26438934115551405		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.26438934115551405 | validation: 0.21737946838691175]
	TIME [epoch: 34.5 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2560634884409695		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.2560634884409695 | validation: 0.2149837881418632]
	TIME [epoch: 34.5 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2598295897095145		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.2598295897095145 | validation: 0.21842345230910226]
	TIME [epoch: 34.5 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2614844078214697		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.2614844078214697 | validation: 0.21394811509713704]
	TIME [epoch: 34.5 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26333240428051624		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.26333240428051624 | validation: 0.2143460404834327]
	TIME [epoch: 34.5 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2568584318598641		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.2568584318598641 | validation: 0.21315193243969652]
	TIME [epoch: 34.5 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25744063171675724		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.25744063171675724 | validation: 0.2148167214011658]
	TIME [epoch: 34.5 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25607704300677386		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.25607704300677386 | validation: 0.21180020606221475]
	TIME [epoch: 34.4 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26383377478007963		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.26383377478007963 | validation: 0.21369722830240834]
	TIME [epoch: 34.5 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25965141998927316		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.25965141998927316 | validation: 0.21628911619377478]
	TIME [epoch: 34.5 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27190718896482863		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.27190718896482863 | validation: 0.2114930961085258]
	TIME [epoch: 34.5 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2509123101256332		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.2509123101256332 | validation: 0.21818513301491946]
	TIME [epoch: 34.6 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25762577729407304		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.25762577729407304 | validation: 0.21311222753411574]
	TIME [epoch: 34.5 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2523646521268535		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.2523646521268535 | validation: 0.21670399095352416]
	TIME [epoch: 34.5 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2556556655053944		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.2556556655053944 | validation: 0.21098582012945225]
	TIME [epoch: 34.6 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2558946470213464		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.2558946470213464 | validation: 0.2138481300236717]
	TIME [epoch: 34.5 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2665058403689119		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.2665058403689119 | validation: 0.21669458181668735]
	TIME [epoch: 34.6 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2525070477490222		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.2525070477490222 | validation: 0.21820585797129932]
	TIME [epoch: 34.5 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2547596839580505		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.2547596839580505 | validation: 0.2084933885426537]
	TIME [epoch: 34.6 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_189.pth
	Model improved!!!
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25929016130595356		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.25929016130595356 | validation: 0.20816592603044856]
	TIME [epoch: 34.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.257060217909161		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.257060217909161 | validation: 0.21225395007785255]
	TIME [epoch: 34.6 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25768676387782774		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.25768676387782774 | validation: 0.21361231978288236]
	TIME [epoch: 34.6 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25409805219908504		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.25409805219908504 | validation: 0.21495001619750834]
	TIME [epoch: 34.6 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25649301793447		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.25649301793447 | validation: 0.21891743002442943]
	TIME [epoch: 34.5 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2541316790044687		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.2541316790044687 | validation: 0.21542127603943376]
	TIME [epoch: 34.5 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2593482861702656		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.2593482861702656 | validation: 0.22041517546904404]
	TIME [epoch: 34.6 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2639888786467684		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.2639888786467684 | validation: 0.21897972535464807]
	TIME [epoch: 34.5 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2592630219098892		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.2592630219098892 | validation: 0.2146457292654131]
	TIME [epoch: 34.5 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25805590482080154		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.25805590482080154 | validation: 0.21125003199224804]
	TIME [epoch: 34.6 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25340969036005584		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.25340969036005584 | validation: 0.2130349590574585]
	TIME [epoch: 34.5 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25396376726588454		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.25396376726588454 | validation: 0.21357082397523047]
	TIME [epoch: 95.2 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2540044422177874		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.2540044422177874 | validation: 0.2151731732990895]
	TIME [epoch: 72.4 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2512211974847833		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.2512211974847833 | validation: 0.21230719230064105]
	TIME [epoch: 72.4 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2553315248812233		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.2553315248812233 | validation: 0.20973920570572244]
	TIME [epoch: 72.4 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2517421339105577		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.2517421339105577 | validation: 0.21147661099025666]
	TIME [epoch: 72.4 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2532204453861684		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.2532204453861684 | validation: 0.21403281255539844]
	TIME [epoch: 72.5 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25697355285032214		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.25697355285032214 | validation: 0.21455209972429704]
	TIME [epoch: 72.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24895719750634027		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.24895719750634027 | validation: 0.21658585956055992]
	TIME [epoch: 72.4 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564641203273903		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.2564641203273903 | validation: 0.2121887042538794]
	TIME [epoch: 72.4 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25470473516931197		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.25470473516931197 | validation: 0.21279283499302326]
	TIME [epoch: 72.4 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25127412528787835		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.25127412528787835 | validation: 0.2113871001983952]
	TIME [epoch: 72.4 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548166819516209		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.2548166819516209 | validation: 0.20873787576264236]
	TIME [epoch: 72.4 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25370756238840614		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.25370756238840614 | validation: 0.2091740603946433]
	TIME [epoch: 72.4 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502141804309017		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.2502141804309017 | validation: 0.20560870746011095]
	TIME [epoch: 72.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_214.pth
	Model improved!!!
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2483545456171972		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.2483545456171972 | validation: 0.2112770791407185]
	TIME [epoch: 72.4 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25204172282664844		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.25204172282664844 | validation: 0.2150345077835245]
	TIME [epoch: 72.4 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548295715331364		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.2548295715331364 | validation: 0.21848348287655703]
	TIME [epoch: 72.4 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24994741018015112		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.24994741018015112 | validation: 0.217954189790544]
	TIME [epoch: 72.4 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26814900057615726		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.26814900057615726 | validation: 0.20995853218928814]
	TIME [epoch: 72.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25365537517333747		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.25365537517333747 | validation: 0.2069229238822472]
	TIME [epoch: 72.4 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2513740109879387		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.2513740109879387 | validation: 0.20910945066862094]
	TIME [epoch: 72.4 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25082043930527803		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.25082043930527803 | validation: 0.21227481953810257]
	TIME [epoch: 72.4 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501166715400528		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.2501166715400528 | validation: 0.20962639776774453]
	TIME [epoch: 72.3 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25024601279874326		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.25024601279874326 | validation: 0.21217628865075744]
	TIME [epoch: 72.4 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2537042199681628		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.2537042199681628 | validation: 0.2192982024082771]
	TIME [epoch: 72.4 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2555703935713681		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.2555703935713681 | validation: 0.20973122621847734]
	TIME [epoch: 72.3 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2564135168027932		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.2564135168027932 | validation: 0.2062101735017659]
	TIME [epoch: 72.4 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2480214260344977		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.2480214260344977 | validation: 0.20747733564614584]
	TIME [epoch: 72.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25427640811027113		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.25427640811027113 | validation: 0.21270754767838546]
	TIME [epoch: 72.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25181124582076814		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.25181124582076814 | validation: 0.20995867491175718]
	TIME [epoch: 72.4 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2535626137777725		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.2535626137777725 | validation: 0.21023929540761427]
	TIME [epoch: 72.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24865542242081537		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.24865542242081537 | validation: 0.2161135794379061]
	TIME [epoch: 72.3 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25271456963806077		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.25271456963806077 | validation: 0.21175231934720395]
	TIME [epoch: 72.3 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2518012933645564		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.2518012933645564 | validation: 0.21165725684979245]
	TIME [epoch: 72.4 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2570198282344509		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.2570198282344509 | validation: 0.21393149973162573]
	TIME [epoch: 72.4 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25501901631843255		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.25501901631843255 | validation: 0.21142477679648713]
	TIME [epoch: 72.4 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25874902059472366		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.25874902059472366 | validation: 0.21536500770793882]
	TIME [epoch: 72.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25912179321775614		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.25912179321775614 | validation: 0.21422506859520776]
	TIME [epoch: 72.3 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502716787547569		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.2502716787547569 | validation: 0.20868369020469713]
	TIME [epoch: 72.4 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2485304301287116		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.2485304301287116 | validation: 0.20899565113121715]
	TIME [epoch: 72.4 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.250929475021117		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.250929475021117 | validation: 0.21294837434927957]
	TIME [epoch: 72.2 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24852877531878706		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.24852877531878706 | validation: 0.2127755953633071]
	TIME [epoch: 72.4 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504454308156628		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.2504454308156628 | validation: 0.20948532422390778]
	TIME [epoch: 72.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25125768345186067		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.25125768345186067 | validation: 0.21224822195676185]
	TIME [epoch: 72.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24799345529970482		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.24799345529970482 | validation: 0.21202008953150148]
	TIME [epoch: 72.4 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25149548807361416		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.25149548807361416 | validation: 0.2127988504928751]
	TIME [epoch: 72.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502821725992271		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.2502821725992271 | validation: 0.21577294073450912]
	TIME [epoch: 72.4 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2548031804734077		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.2548031804734077 | validation: 0.21346770012867183]
	TIME [epoch: 72.3 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511855209142765		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.2511855209142765 | validation: 0.20957277858256015]
	TIME [epoch: 72.4 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2473750496896118		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.2473750496896118 | validation: 0.21518989503813427]
	TIME [epoch: 72.5 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24967485507739098		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.24967485507739098 | validation: 0.21049027770138756]
	TIME [epoch: 72.3 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2565279667585138		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.2565279667585138 | validation: 0.21824270585736044]
	TIME [epoch: 72.4 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24888325741819783		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.24888325741819783 | validation: 0.21176818737804748]
	TIME [epoch: 72.5 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24747646032865486		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.24747646032865486 | validation: 0.21274184516873412]
	TIME [epoch: 72.4 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25057132898430184		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.25057132898430184 | validation: 0.21344964203549105]
	TIME [epoch: 72.3 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24868581117713504		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.24868581117713504 | validation: 0.2097702001035592]
	TIME [epoch: 72.3 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24913528627694637		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.24913528627694637 | validation: 0.21056450697594675]
	TIME [epoch: 72.4 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24609543949998655		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.24609543949998655 | validation: 0.21125212252605213]
	TIME [epoch: 72.3 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2505103848275917		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.2505103848275917 | validation: 0.21316610558592827]
	TIME [epoch: 72.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2500116319872142		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.2500116319872142 | validation: 0.21081154988699438]
	TIME [epoch: 72.4 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.250959378235253		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.250959378235253 | validation: 0.20747772480958243]
	TIME [epoch: 72.4 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24902547759257523		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.24902547759257523 | validation: 0.20941940558939312]
	TIME [epoch: 72.4 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25311846555098755		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.25311846555098755 | validation: 0.21466579172312708]
	TIME [epoch: 72.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24729810985511236		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.24729810985511236 | validation: 0.2098813091251493]
	TIME [epoch: 72.4 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942277802949267		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.24942277802949267 | validation: 0.20987784441976842]
	TIME [epoch: 72.4 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2481586174470053		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.2481586174470053 | validation: 0.2108530852495128]
	TIME [epoch: 72.5 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24417223404805818		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.24417223404805818 | validation: 0.21087598885807987]
	TIME [epoch: 72.4 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25286545383192743		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.25286545383192743 | validation: 0.20552142849765725]
	TIME [epoch: 72.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24761012228410298		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.24761012228410298 | validation: 0.2087599117554803]
	TIME [epoch: 72.5 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25282561302599044		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.25282561302599044 | validation: 0.21055581059964643]
	TIME [epoch: 72.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2428916867623807		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.2428916867623807 | validation: 0.2100761883603181]
	TIME [epoch: 72.4 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25165404129995933		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.25165404129995933 | validation: 0.21135304444088776]
	TIME [epoch: 72.4 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2503273507913782		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.2503273507913782 | validation: 0.2109354359886082]
	TIME [epoch: 72.4 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24837971797973393		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.24837971797973393 | validation: 0.2113558985653436]
	TIME [epoch: 72.5 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504662910647769		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.2504662910647769 | validation: 0.21094639080061545]
	TIME [epoch: 72.4 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24809514525634868		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.24809514525634868 | validation: 0.21806782092635565]
	TIME [epoch: 72.4 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25011519411252964		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.25011519411252964 | validation: 0.21068994176192368]
	TIME [epoch: 72.5 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2514888058399754		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.2514888058399754 | validation: 0.21152444756619246]
	TIME [epoch: 72.4 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25564092809470756		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.25564092809470756 | validation: 0.21636310274589796]
	TIME [epoch: 72.4 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2471385875243928		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.2471385875243928 | validation: 0.20621557176792038]
	TIME [epoch: 72.4 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25056410635142656		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.25056410635142656 | validation: 0.20712771649990716]
	TIME [epoch: 72.4 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24368049594677244		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.24368049594677244 | validation: 0.21451522442383958]
	TIME [epoch: 72.4 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24646422637856405		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.24646422637856405 | validation: 0.21012886283395954]
	TIME [epoch: 72.5 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24956114432193108		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.24956114432193108 | validation: 0.20918302986169485]
	TIME [epoch: 72.3 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2491664021334954		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.2491664021334954 | validation: 0.20947761819794378]
	TIME [epoch: 72.4 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24529096656144933		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.24529096656144933 | validation: 0.20574168532064005]
	TIME [epoch: 72.4 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24842685544743245		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.24842685544743245 | validation: 0.21252718498645326]
	TIME [epoch: 72.4 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24772287068270324		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.24772287068270324 | validation: 0.2103572063692643]
	TIME [epoch: 72.4 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24898100189307984		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.24898100189307984 | validation: 0.2068858819165121]
	TIME [epoch: 72.5 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782239948664564		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.24782239948664564 | validation: 0.20544506280596958]
	TIME [epoch: 72.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_290.pth
	Model improved!!!
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24891479437253636		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.24891479437253636 | validation: 0.21059785115175061]
	TIME [epoch: 72.1 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24509510900863027		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.24509510900863027 | validation: 0.21021660575441733]
	TIME [epoch: 72.1 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24524242349039105		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.24524242349039105 | validation: 0.20406164174992228]
	TIME [epoch: 72.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_293.pth
	Model improved!!!
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511268364595904		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.2511268364595904 | validation: 0.21001455648990236]
	TIME [epoch: 72 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24944645102148813		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.24944645102148813 | validation: 0.20862285949258091]
	TIME [epoch: 72.2 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504616293912246		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.2504616293912246 | validation: 0.20523324924443412]
	TIME [epoch: 72.1 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25121953846386974		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.25121953846386974 | validation: 0.2047459586199391]
	TIME [epoch: 72.4 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24682368219944326		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.24682368219944326 | validation: 0.2081894421549209]
	TIME [epoch: 72.5 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2501774005012411		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.2501774005012411 | validation: 0.2035145404099635]
	TIME [epoch: 72 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_299.pth
	Model improved!!!
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24639963186798006		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.24639963186798006 | validation: 0.20782240973915864]
	TIME [epoch: 72.1 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24514466501681242		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.24514466501681242 | validation: 0.21197400435156938]
	TIME [epoch: 171 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24643122370421852		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.24643122370421852 | validation: 0.21365069446378424]
	TIME [epoch: 148 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2511703906625181		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.2511703906625181 | validation: 0.20936432696230484]
	TIME [epoch: 148 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24950171415257338		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.24950171415257338 | validation: 0.21352311920259082]
	TIME [epoch: 148 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2502252598055506		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.2502252598055506 | validation: 0.20851895209389187]
	TIME [epoch: 148 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24959177433400145		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.24959177433400145 | validation: 0.20999617611845714]
	TIME [epoch: 148 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24657112658242983		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.24657112658242983 | validation: 0.2066198689836211]
	TIME [epoch: 148 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.247820382846996		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.247820382846996 | validation: 0.21050888583491217]
	TIME [epoch: 148 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24424021327507514		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.24424021327507514 | validation: 0.2097524581420364]
	TIME [epoch: 148 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24541120165510644		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.24541120165510644 | validation: 0.21456499424858705]
	TIME [epoch: 148 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25121754926288026		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.25121754926288026 | validation: 0.21055772533082734]
	TIME [epoch: 148 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24533919835922594		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.24533919835922594 | validation: 0.21071505148186992]
	TIME [epoch: 148 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24881875698160508		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.24881875698160508 | validation: 0.21114804447030827]
	TIME [epoch: 148 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.255515304722778		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.255515304722778 | validation: 0.20615999065695792]
	TIME [epoch: 148 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24624406668724586		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.24624406668724586 | validation: 0.20999314986749415]
	TIME [epoch: 148 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2494692861460739		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.2494692861460739 | validation: 0.20688496946626983]
	TIME [epoch: 148 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2475957292609786		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.2475957292609786 | validation: 0.20901193099674248]
	TIME [epoch: 148 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24543266011967702		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.24543266011967702 | validation: 0.20737793303494573]
	TIME [epoch: 148 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24443526827087128		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.24443526827087128 | validation: 0.20779903335823624]
	TIME [epoch: 148 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24782883003773426		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.24782883003773426 | validation: 0.20400514167893027]
	TIME [epoch: 148 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24277414279521836		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.24277414279521836 | validation: 0.21027308730269825]
	TIME [epoch: 148 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24662422710842366		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.24662422710842366 | validation: 0.20546360840384978]
	TIME [epoch: 148 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24884720929033044		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.24884720929033044 | validation: 0.20845086728929202]
	TIME [epoch: 148 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24970583681661393		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.24970583681661393 | validation: 0.21226104242535565]
	TIME [epoch: 148 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2462023051159822		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.2462023051159822 | validation: 0.20809524079352495]
	TIME [epoch: 148 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.245051139765919		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.245051139765919 | validation: 0.2091503487454272]
	TIME [epoch: 148 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24990906670805738		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.24990906670805738 | validation: 0.2106255284642149]
	TIME [epoch: 148 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24371143503117723		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.24371143503117723 | validation: 0.2084745032904629]
	TIME [epoch: 148 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25132198278557755		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.25132198278557755 | validation: 0.21048689096505885]
	TIME [epoch: 148 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24987437073141458		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.24987437073141458 | validation: 0.2092396968629448]
	TIME [epoch: 148 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24765186972956366		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.24765186972956366 | validation: 0.20641982281531157]
	TIME [epoch: 148 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24942469997872097		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.24942469997872097 | validation: 0.20902394090814486]
	TIME [epoch: 148 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25096029198716724		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.25096029198716724 | validation: 0.21059433603469063]
	TIME [epoch: 148 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2504827388197529		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.2504827388197529 | validation: 0.20698552114147056]
	TIME [epoch: 148 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24715353318508804		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.24715353318508804 | validation: 0.20884677037798588]
	TIME [epoch: 148 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24904860131662812		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.24904860131662812 | validation: 0.20844402093227887]
	TIME [epoch: 148 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24934339827683014		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.24934339827683014 | validation: 0.20876524776959782]
	TIME [epoch: 148 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24618967190043106		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.24618967190043106 | validation: 0.20635796754043967]
	TIME [epoch: 148 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24553754852469858		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.24553754852469858 | validation: 0.20762749113456555]
	TIME [epoch: 148 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2461192236477133		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.2461192236477133 | validation: 0.20854124414742153]
	TIME [epoch: 148 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24776836503148347		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.24776836503148347 | validation: 0.21154347607296192]
	TIME [epoch: 148 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24702479299343702		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.24702479299343702 | validation: 0.21227801148633857]
	TIME [epoch: 148 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24263228669008677		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.24263228669008677 | validation: 0.2086846423155002]
	TIME [epoch: 148 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2482763094553814		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.2482763094553814 | validation: 0.2052221686379767]
	TIME [epoch: 148 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2499377908205699		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.2499377908205699 | validation: 0.2108404869802556]
	TIME [epoch: 148 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24391754297901627		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.24391754297901627 | validation: 0.20729109436759172]
	TIME [epoch: 148 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695650795933152		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.24695650795933152 | validation: 0.20598581818696382]
	TIME [epoch: 148 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25071339393732894		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.25071339393732894 | validation: 0.2084063546694736]
	TIME [epoch: 148 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24624150163757727		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.24624150163757727 | validation: 0.21003990283013954]
	TIME [epoch: 148 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470919375024144		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.2470919375024144 | validation: 0.2057073203703373]
	TIME [epoch: 148 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2444458945587796		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.2444458945587796 | validation: 0.20932742679018862]
	TIME [epoch: 148 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456456090708132		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.2456456090708132 | validation: 0.21196621507545793]
	TIME [epoch: 148 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24567531682635838		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.24567531682635838 | validation: 0.21037326123900799]
	TIME [epoch: 148 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24774348731520304		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.24774348731520304 | validation: 0.20688997857443883]
	TIME [epoch: 148 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24866985459222626		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.24866985459222626 | validation: 0.2105959400730711]
	TIME [epoch: 148 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24452401003788737		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.24452401003788737 | validation: 0.20739153324987242]
	TIME [epoch: 148 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24507154076572757		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.24507154076572757 | validation: 0.20638444681224763]
	TIME [epoch: 148 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24672862451844793		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.24672862451844793 | validation: 0.20993312520991902]
	TIME [epoch: 148 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24646272900305258		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.24646272900305258 | validation: 0.20488238070015713]
	TIME [epoch: 148 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24531260186982698		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.24531260186982698 | validation: 0.211805039619901]
	TIME [epoch: 148 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24328832512548312		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.24328832512548312 | validation: 0.21071291829790534]
	TIME [epoch: 148 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24608187407950113		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.24608187407950113 | validation: 0.209929436918332]
	TIME [epoch: 148 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.250005004783068		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.250005004783068 | validation: 0.2134505649613406]
	TIME [epoch: 148 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24938283648995865		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.24938283648995865 | validation: 0.20876819853181106]
	TIME [epoch: 148 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2469774508372998		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.2469774508372998 | validation: 0.21212110501956022]
	TIME [epoch: 148 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2487028811030518		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.2487028811030518 | validation: 0.20930451192411206]
	TIME [epoch: 148 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488182413170633		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.2488182413170633 | validation: 0.20825223337963691]
	TIME [epoch: 148 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2465315372159981		[learning rate: 0.00099155]
	Learning Rate: 0.000991553
	LOSS [training: 0.2465315372159981 | validation: 0.21098641104031784]
	TIME [epoch: 148 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2459775389760526		[learning rate: 0.00098437]
	Learning Rate: 0.000984369
	LOSS [training: 0.2459775389760526 | validation: 0.20815455822266632]
	TIME [epoch: 148 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2433682530570551		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.2433682530570551 | validation: 0.20799421546175764]
	TIME [epoch: 148 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24615653814603689		[learning rate: 0.00097016]
	Learning Rate: 0.000970157
	LOSS [training: 0.24615653814603689 | validation: 0.21017359528787685]
	TIME [epoch: 148 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2423131648575992		[learning rate: 0.00096313]
	Learning Rate: 0.000963128
	LOSS [training: 0.2423131648575992 | validation: 0.20956282363598824]
	TIME [epoch: 148 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24344014749693568		[learning rate: 0.00095615]
	Learning Rate: 0.00095615
	LOSS [training: 0.24344014749693568 | validation: 0.21031373003956602]
	TIME [epoch: 148 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24740736356707008		[learning rate: 0.00094922]
	Learning Rate: 0.000949223
	LOSS [training: 0.24740736356707008 | validation: 0.20549602184042798]
	TIME [epoch: 149 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2470130127693094		[learning rate: 0.00094235]
	Learning Rate: 0.000942346
	LOSS [training: 0.2470130127693094 | validation: 0.2086839693905916]
	TIME [epoch: 149 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24821384405426325		[learning rate: 0.00093552]
	Learning Rate: 0.000935519
	LOSS [training: 0.24821384405426325 | validation: 0.20826239352955947]
	TIME [epoch: 149 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24259540274329486		[learning rate: 0.00092874]
	Learning Rate: 0.000928741
	LOSS [training: 0.24259540274329486 | validation: 0.2069842644515772]
	TIME [epoch: 149 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24785172063114727		[learning rate: 0.00092201]
	Learning Rate: 0.000922012
	LOSS [training: 0.24785172063114727 | validation: 0.2030911950879039]
	TIME [epoch: 149 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_378.pth
	Model improved!!!
EPOCH 379/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24330917368482177		[learning rate: 0.00091533]
	Learning Rate: 0.000915333
	LOSS [training: 0.24330917368482177 | validation: 0.20811679962442803]
	TIME [epoch: 149 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24752374693728454		[learning rate: 0.0009087]
	Learning Rate: 0.000908701
	LOSS [training: 0.24752374693728454 | validation: 0.20647391112700642]
	TIME [epoch: 149 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23896826652704947		[learning rate: 0.00090212]
	Learning Rate: 0.000902118
	LOSS [training: 0.23896826652704947 | validation: 0.20798302450672512]
	TIME [epoch: 149 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24109518933643903		[learning rate: 0.00089558]
	Learning Rate: 0.000895582
	LOSS [training: 0.24109518933643903 | validation: 0.21181729132892196]
	TIME [epoch: 149 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24192481263252238		[learning rate: 0.00088909]
	Learning Rate: 0.000889093
	LOSS [training: 0.24192481263252238 | validation: 0.2107408522367455]
	TIME [epoch: 149 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2456312135314819		[learning rate: 0.00088265]
	Learning Rate: 0.000882652
	LOSS [training: 0.2456312135314819 | validation: 0.20341899416176784]
	TIME [epoch: 149 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24482601609653906		[learning rate: 0.00087626]
	Learning Rate: 0.000876257
	LOSS [training: 0.24482601609653906 | validation: 0.2061276715093788]
	TIME [epoch: 149 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24359147373658543		[learning rate: 0.00086991]
	Learning Rate: 0.000869909
	LOSS [training: 0.24359147373658543 | validation: 0.20942061738805856]
	TIME [epoch: 149 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478712342036613		[learning rate: 0.00086361]
	Learning Rate: 0.000863606
	LOSS [training: 0.2478712342036613 | validation: 0.21359676638540517]
	TIME [epoch: 149 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24640129018288567		[learning rate: 0.00085735]
	Learning Rate: 0.000857349
	LOSS [training: 0.24640129018288567 | validation: 0.2093630571195892]
	TIME [epoch: 149 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2449194792783476		[learning rate: 0.00085114]
	Learning Rate: 0.000851138
	LOSS [training: 0.2449194792783476 | validation: 0.2128408360105678]
	TIME [epoch: 149 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.248751229581456		[learning rate: 0.00084497]
	Learning Rate: 0.000844972
	LOSS [training: 0.248751229581456 | validation: 0.2080227532642474]
	TIME [epoch: 149 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24121440744594616		[learning rate: 0.00083885]
	Learning Rate: 0.00083885
	LOSS [training: 0.24121440744594616 | validation: 0.20841869071085511]
	TIME [epoch: 149 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24207599559422535		[learning rate: 0.00083277]
	Learning Rate: 0.000832772
	LOSS [training: 0.24207599559422535 | validation: 0.21057560782378984]
	TIME [epoch: 149 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24433754023873713		[learning rate: 0.00082674]
	Learning Rate: 0.000826739
	LOSS [training: 0.24433754023873713 | validation: 0.2077847056328214]
	TIME [epoch: 149 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24241031427754575		[learning rate: 0.00082075]
	Learning Rate: 0.000820749
	LOSS [training: 0.24241031427754575 | validation: 0.21005298883616014]
	TIME [epoch: 149 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24547877881626082		[learning rate: 0.0008148]
	Learning Rate: 0.000814803
	LOSS [training: 0.24547877881626082 | validation: 0.2085279068431997]
	TIME [epoch: 149 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24276541481455058		[learning rate: 0.0008089]
	Learning Rate: 0.0008089
	LOSS [training: 0.24276541481455058 | validation: 0.20701238352091728]
	TIME [epoch: 149 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24449179114866304		[learning rate: 0.00080304]
	Learning Rate: 0.000803039
	LOSS [training: 0.24449179114866304 | validation: 0.21061071810660917]
	TIME [epoch: 149 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2434713201056625		[learning rate: 0.00079722]
	Learning Rate: 0.000797221
	LOSS [training: 0.2434713201056625 | validation: 0.20759215301701803]
	TIME [epoch: 149 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.245266340378953		[learning rate: 0.00079145]
	Learning Rate: 0.000791446
	LOSS [training: 0.245266340378953 | validation: 0.20716539972272305]
	TIME [epoch: 149 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2450904859967478		[learning rate: 0.00078571]
	Learning Rate: 0.000785711
	LOSS [training: 0.2450904859967478 | validation: 0.20700576646476226]
	TIME [epoch: 149 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24163025292758764		[learning rate: 0.00078002]
	Learning Rate: 0.000780019
	LOSS [training: 0.24163025292758764 | validation: 0.2088982211449822]
	TIME [epoch: 148 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24382230652872106		[learning rate: 0.00077437]
	Learning Rate: 0.000774368
	LOSS [training: 0.24382230652872106 | validation: 0.20190167292559727]
	TIME [epoch: 148 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset1_20241017_113153/states/model_facs_dec1_v1_argset1_402.pth
	Model improved!!!
EPOCH 403/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24492086942184452		[learning rate: 0.00076876]
	Learning Rate: 0.000768758
	LOSS [training: 0.24492086942184452 | validation: 0.20885403727030605]
	TIME [epoch: 148 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24461976244993264		[learning rate: 0.00076319]
	Learning Rate: 0.000763188
	LOSS [training: 0.24461976244993264 | validation: 0.20315293175918397]
	TIME [epoch: 148 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24468097307269576		[learning rate: 0.00075766]
	Learning Rate: 0.000757659
	LOSS [training: 0.24468097307269576 | validation: 0.2053961907870731]
	TIME [epoch: 148 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24140373840182686		[learning rate: 0.00075217]
	Learning Rate: 0.000752169
	LOSS [training: 0.24140373840182686 | validation: 0.20727910692635323]
	TIME [epoch: 148 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24261418912821886		[learning rate: 0.00074672]
	Learning Rate: 0.00074672
	LOSS [training: 0.24261418912821886 | validation: 0.20872725540913278]
	TIME [epoch: 148 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2446014215362752		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.2446014215362752 | validation: 0.2098380773874049]
	TIME [epoch: 148 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24265675635986117		[learning rate: 0.00073594]
	Learning Rate: 0.000735939
	LOSS [training: 0.24265675635986117 | validation: 0.21071400920740319]
	TIME [epoch: 148 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24516947457416624		[learning rate: 0.00073061]
	Learning Rate: 0.000730608
	LOSS [training: 0.24516947457416624 | validation: 0.20879758085635025]
	TIME [epoch: 148 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24609687556948248		[learning rate: 0.00072531]
	Learning Rate: 0.000725314
	LOSS [training: 0.24609687556948248 | validation: 0.2063093405428526]
	TIME [epoch: 148 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24541051152328222		[learning rate: 0.00072006]
	Learning Rate: 0.00072006
	LOSS [training: 0.24541051152328222 | validation: 0.20373395861893803]
	TIME [epoch: 148 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2478676183856363		[learning rate: 0.00071484]
	Learning Rate: 0.000714843
	LOSS [training: 0.2478676183856363 | validation: 0.20783027029837267]
	TIME [epoch: 148 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24644452317360374		[learning rate: 0.00070966]
	Learning Rate: 0.000709664
	LOSS [training: 0.24644452317360374 | validation: 0.2065922984144321]
	TIME [epoch: 148 sec]
EPOCH 415/1000:
	Training over batches...
