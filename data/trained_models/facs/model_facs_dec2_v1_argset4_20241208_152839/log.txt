Args:
Namespace(name='model_facs_dec2_v1_argset4', outdir='out/model_training/model_facs_dec2_v1_argset4', training_data='data/facs/facs_dec2_v1/training', validation_data='data/facs/facs_dec2_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[100, 300, 500, 700], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 1.275067687034607], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3031397746

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.323823166648616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.323823166648616 | validation: 0.4121118965190215]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.29961087411073417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29961087411073417 | validation: 0.37386295301432304]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.27362013930937945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27362013930937945 | validation: 0.3518500943053019]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.25911442527990536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25911442527990536 | validation: 0.3696961379620466]
	TIME [epoch: 4.85 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602695050302969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2602695050302969 | validation: 0.3236935265632291]
	TIME [epoch: 4.84 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.21811600604212542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21811600604212542 | validation: 0.33972309298640896]
	TIME [epoch: 4.86 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.24150029576658932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24150029576658932 | validation: 0.2789517750335599]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.20853942053062324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20853942053062324 | validation: 0.2603223873737641]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1926726620637348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1926726620637348 | validation: 0.39746918073664245]
	TIME [epoch: 4.87 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.232808349267053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.232808349267053 | validation: 0.2406566944446246]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.165637305358262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.165637305358262 | validation: 0.22396802949699463]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559787864158729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1559787864158729 | validation: 0.21236005917622955]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17590581538437472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17590581538437472 | validation: 0.22132756803242942]
	TIME [epoch: 4.85 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.16276706128022495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16276706128022495 | validation: 0.20916126830113047]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12971624593181164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12971624593181164 | validation: 0.23250569344361116]
	TIME [epoch: 4.87 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662898675095773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1662898675095773 | validation: 0.25600143292848687]
	TIME [epoch: 4.87 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128102791356267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17128102791356267 | validation: 0.18900536073724597]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12960000342677894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12960000342677894 | validation: 0.1850142205906505]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13102668817011884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13102668817011884 | validation: 0.20082870027742156]
	TIME [epoch: 4.85 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989332583688639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11989332583688639 | validation: 0.19585895852734259]
	TIME [epoch: 4.85 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13297526061169934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13297526061169934 | validation: 0.39214235969182154]
	TIME [epoch: 4.85 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.17445403619930547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17445403619930547 | validation: 0.1702852978839819]
	TIME [epoch: 4.85 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589439266260472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09589439266260472 | validation: 0.16284092431168826]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10473598519874586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10473598519874586 | validation: 0.2082378050520779]
	TIME [epoch: 4.87 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12568492555764035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12568492555764035 | validation: 0.20244522793058523]
	TIME [epoch: 4.86 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13678772541027026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13678772541027026 | validation: 0.17903159114412315]
	TIME [epoch: 4.87 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10194766767232363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10194766767232363 | validation: 0.17557102283140785]
	TIME [epoch: 4.87 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09057990096224929		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09057990096224929 | validation: 0.16932196743800945]
	TIME [epoch: 4.86 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13421185087482063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13421185087482063 | validation: 0.19841302421517937]
	TIME [epoch: 4.86 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11617054183325905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11617054183325905 | validation: 0.1604693979114437]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09406966419749575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09406966419749575 | validation: 0.2020801951360131]
	TIME [epoch: 4.88 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12966454159470334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12966454159470334 | validation: 0.1804758105568522]
	TIME [epoch: 4.87 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10049665705536172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10049665705536172 | validation: 0.18878479783828575]
	TIME [epoch: 4.87 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12203580675460338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12203580675460338 | validation: 0.18826916064881644]
	TIME [epoch: 4.87 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.13090167441147485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13090167441147485 | validation: 0.17243062279257892]
	TIME [epoch: 4.86 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043723337152813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1043723337152813 | validation: 0.16460184148630036]
	TIME [epoch: 4.87 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012671605248203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11012671605248203 | validation: 0.2022105426671958]
	TIME [epoch: 4.87 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.12222489142039868		[learning rate: 0.0099839]
	Learning Rate: 0.00998385
	LOSS [training: 0.12222489142039868 | validation: 0.1633995512076733]
	TIME [epoch: 4.87 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08903390288728788		[learning rate: 0.0099195]
	Learning Rate: 0.00991953
	LOSS [training: 0.08903390288728788 | validation: 0.15792258720922742]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09287111783371566		[learning rate: 0.0098556]
	Learning Rate: 0.00985563
	LOSS [training: 0.09287111783371566 | validation: 0.18734404123629306]
	TIME [epoch: 4.87 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383794143234488		[learning rate: 0.0097921]
	Learning Rate: 0.00979213
	LOSS [training: 0.11383794143234488 | validation: 0.16220048972467233]
	TIME [epoch: 4.86 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09885020731401388		[learning rate: 0.009729]
	Learning Rate: 0.00972904
	LOSS [training: 0.09885020731401388 | validation: 0.20417643699823063]
	TIME [epoch: 4.86 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777156240937841		[learning rate: 0.0096664]
	Learning Rate: 0.00966636
	LOSS [training: 0.10777156240937841 | validation: 0.158873072529585]
	TIME [epoch: 4.86 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08618618347227724		[learning rate: 0.0096041]
	Learning Rate: 0.00960409
	LOSS [training: 0.08618618347227724 | validation: 0.26108791348102905]
	TIME [epoch: 4.86 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1280800746157626		[learning rate: 0.0095422]
	Learning Rate: 0.00954221
	LOSS [training: 0.1280800746157626 | validation: 0.17639817444087252]
	TIME [epoch: 4.87 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10362823499649967		[learning rate: 0.0094807]
	Learning Rate: 0.00948074
	LOSS [training: 0.10362823499649967 | validation: 0.18098241283680908]
	TIME [epoch: 4.86 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09717073106819152		[learning rate: 0.0094197]
	Learning Rate: 0.00941966
	LOSS [training: 0.09717073106819152 | validation: 0.15311352477611773]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0863297779377024		[learning rate: 0.009359]
	Learning Rate: 0.00935897
	LOSS [training: 0.0863297779377024 | validation: 0.14403145226515818]
	TIME [epoch: 4.88 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09310594732279746		[learning rate: 0.0092987]
	Learning Rate: 0.00929867
	LOSS [training: 0.09310594732279746 | validation: 0.16883278629157572]
	TIME [epoch: 4.87 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0932107318830188		[learning rate: 0.0092388]
	Learning Rate: 0.00923877
	LOSS [training: 0.0932107318830188 | validation: 0.15507953409538255]
	TIME [epoch: 4.87 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09732915944624047		[learning rate: 0.0091792]
	Learning Rate: 0.00917925
	LOSS [training: 0.09732915944624047 | validation: 0.13409966262072315]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09370260340690371		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.09370260340690371 | validation: 0.16259998464513425]
	TIME [epoch: 4.87 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08984083892963571		[learning rate: 0.0090614]
	Learning Rate: 0.00906135
	LOSS [training: 0.08984083892963571 | validation: 0.1755741142801528]
	TIME [epoch: 4.87 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09960252200337383		[learning rate: 0.009003]
	Learning Rate: 0.00900297
	LOSS [training: 0.09960252200337383 | validation: 0.1439777323035242]
	TIME [epoch: 4.86 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167489151186966		[learning rate: 0.008945]
	Learning Rate: 0.00894497
	LOSS [training: 0.11167489151186966 | validation: 0.15582057167614705]
	TIME [epoch: 4.87 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08998873165081651		[learning rate: 0.0088873]
	Learning Rate: 0.00888734
	LOSS [training: 0.08998873165081651 | validation: 0.168508818464105]
	TIME [epoch: 4.87 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375078214272492		[learning rate: 0.0088301]
	Learning Rate: 0.00883009
	LOSS [training: 0.09375078214272492 | validation: 0.14099492817334475]
	TIME [epoch: 4.86 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07782512764895844		[learning rate: 0.0087732]
	Learning Rate: 0.0087732
	LOSS [training: 0.07782512764895844 | validation: 0.18087150110939235]
	TIME [epoch: 4.86 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0895403738532324		[learning rate: 0.0087167]
	Learning Rate: 0.00871668
	LOSS [training: 0.0895403738532324 | validation: 0.1601851787762771]
	TIME [epoch: 4.86 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09235669934540863		[learning rate: 0.0086605]
	Learning Rate: 0.00866052
	LOSS [training: 0.09235669934540863 | validation: 0.14305209502239502]
	TIME [epoch: 4.86 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08063025614465812		[learning rate: 0.0086047]
	Learning Rate: 0.00860472
	LOSS [training: 0.08063025614465812 | validation: 0.14687021950840806]
	TIME [epoch: 4.86 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08132080195643145		[learning rate: 0.0085493]
	Learning Rate: 0.00854929
	LOSS [training: 0.08132080195643145 | validation: 0.17684087197906476]
	TIME [epoch: 4.86 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09211002212206933		[learning rate: 0.0084942]
	Learning Rate: 0.00849421
	LOSS [training: 0.09211002212206933 | validation: 0.1305653111594146]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08215353057287586		[learning rate: 0.0084395]
	Learning Rate: 0.00843948
	LOSS [training: 0.08215353057287586 | validation: 0.13816580369563064]
	TIME [epoch: 4.87 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08926352086379927		[learning rate: 0.0083851]
	Learning Rate: 0.00838511
	LOSS [training: 0.08926352086379927 | validation: 0.1385793978473761]
	TIME [epoch: 4.87 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08639199199278652		[learning rate: 0.0083311]
	Learning Rate: 0.00833109
	LOSS [training: 0.08639199199278652 | validation: 0.14124604339716676]
	TIME [epoch: 4.86 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08535008684408787		[learning rate: 0.0082774]
	Learning Rate: 0.00827742
	LOSS [training: 0.08535008684408787 | validation: 0.14162517424872006]
	TIME [epoch: 4.86 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07111640678590361		[learning rate: 0.0082241]
	Learning Rate: 0.00822409
	LOSS [training: 0.07111640678590361 | validation: 0.19004566280341637]
	TIME [epoch: 4.86 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08286362326321761		[learning rate: 0.0081711]
	Learning Rate: 0.0081711
	LOSS [training: 0.08286362326321761 | validation: 0.14490234475980468]
	TIME [epoch: 4.86 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08152700542398322		[learning rate: 0.0081185]
	Learning Rate: 0.00811846
	LOSS [training: 0.08152700542398322 | validation: 0.1421254242141397]
	TIME [epoch: 4.86 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0763660288300669		[learning rate: 0.0080662]
	Learning Rate: 0.00806616
	LOSS [training: 0.0763660288300669 | validation: 0.1483033338364071]
	TIME [epoch: 4.86 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108045916205105		[learning rate: 0.0080142]
	Learning Rate: 0.00801419
	LOSS [training: 0.08108045916205105 | validation: 0.17052295841742593]
	TIME [epoch: 4.87 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07694848030104764		[learning rate: 0.0079626]
	Learning Rate: 0.00796256
	LOSS [training: 0.07694848030104764 | validation: 0.16775059898227632]
	TIME [epoch: 4.87 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07695393600210904		[learning rate: 0.0079113]
	Learning Rate: 0.00791126
	LOSS [training: 0.07695393600210904 | validation: 0.13218484756323268]
	TIME [epoch: 4.86 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07250780804239368		[learning rate: 0.0078603]
	Learning Rate: 0.00786029
	LOSS [training: 0.07250780804239368 | validation: 0.2158738168301746]
	TIME [epoch: 4.86 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.087697603872423		[learning rate: 0.0078097]
	Learning Rate: 0.00780965
	LOSS [training: 0.087697603872423 | validation: 0.14162764944082412]
	TIME [epoch: 4.86 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09116143038617427		[learning rate: 0.0077593]
	Learning Rate: 0.00775934
	LOSS [training: 0.09116143038617427 | validation: 0.14074729111524267]
	TIME [epoch: 4.86 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0782561256986653		[learning rate: 0.0077093]
	Learning Rate: 0.00770935
	LOSS [training: 0.0782561256986653 | validation: 0.17066691342004509]
	TIME [epoch: 4.86 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740745077473775		[learning rate: 0.0076597]
	Learning Rate: 0.00765968
	LOSS [training: 0.07740745077473775 | validation: 0.23257873874001814]
	TIME [epoch: 4.87 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09711257497490786		[learning rate: 0.0076103]
	Learning Rate: 0.00761033
	LOSS [training: 0.09711257497490786 | validation: 0.17271444787707202]
	TIME [epoch: 4.87 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06974999437194888		[learning rate: 0.0075613]
	Learning Rate: 0.0075613
	LOSS [training: 0.06974999437194888 | validation: 0.15103633752635087]
	TIME [epoch: 4.87 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855244554364163		[learning rate: 0.0075126]
	Learning Rate: 0.00751259
	LOSS [training: 0.07855244554364163 | validation: 0.1251089868977444]
	TIME [epoch: 4.87 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159440533702786		[learning rate: 0.0074642]
	Learning Rate: 0.00746419
	LOSS [training: 0.07159440533702786 | validation: 0.11657218490817414]
	TIME [epoch: 4.86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07420019268562023		[learning rate: 0.0074161]
	Learning Rate: 0.0074161
	LOSS [training: 0.07420019268562023 | validation: 0.15343318497114794]
	TIME [epoch: 4.87 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144062140138142		[learning rate: 0.0073683]
	Learning Rate: 0.00736832
	LOSS [training: 0.07144062140138142 | validation: 0.1338984438104585]
	TIME [epoch: 4.87 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566554827824021		[learning rate: 0.0073208]
	Learning Rate: 0.00732085
	LOSS [training: 0.06566554827824021 | validation: 0.12376040353475781]
	TIME [epoch: 4.87 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07605090656738306		[learning rate: 0.0072737]
	Learning Rate: 0.00727368
	LOSS [training: 0.07605090656738306 | validation: 0.12711799949056904]
	TIME [epoch: 4.87 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06333197928121714		[learning rate: 0.0072268]
	Learning Rate: 0.00722682
	LOSS [training: 0.06333197928121714 | validation: 0.16528037697525777]
	TIME [epoch: 4.88 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08156087017847626		[learning rate: 0.0071803]
	Learning Rate: 0.00718026
	LOSS [training: 0.08156087017847626 | validation: 0.18497143365039787]
	TIME [epoch: 4.88 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.10206999688292775		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.10206999688292775 | validation: 0.1662343140677312]
	TIME [epoch: 4.88 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811434107690209		[learning rate: 0.007088]
	Learning Rate: 0.00708804
	LOSS [training: 0.07811434107690209 | validation: 0.12113473509169789]
	TIME [epoch: 4.87 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0698082633879969		[learning rate: 0.0070424]
	Learning Rate: 0.00704238
	LOSS [training: 0.0698082633879969 | validation: 0.13569141838697119]
	TIME [epoch: 4.87 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07748566701294032		[learning rate: 0.006997]
	Learning Rate: 0.00699701
	LOSS [training: 0.07748566701294032 | validation: 0.13613310037401585]
	TIME [epoch: 4.87 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351345298464747		[learning rate: 0.0069519]
	Learning Rate: 0.00695193
	LOSS [training: 0.07351345298464747 | validation: 0.14444233834257303]
	TIME [epoch: 4.87 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07253264641646986		[learning rate: 0.0069071]
	Learning Rate: 0.00690714
	LOSS [training: 0.07253264641646986 | validation: 0.15008489231458727]
	TIME [epoch: 4.87 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06581755575322665		[learning rate: 0.0068626]
	Learning Rate: 0.00686264
	LOSS [training: 0.06581755575322665 | validation: 0.14340388660846803]
	TIME [epoch: 4.87 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468535450489576		[learning rate: 0.0068184]
	Learning Rate: 0.00681843
	LOSS [training: 0.06468535450489576 | validation: 0.19603810928250198]
	TIME [epoch: 4.86 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725729217400533		[learning rate: 0.0067745]
	Learning Rate: 0.0067745
	LOSS [training: 0.0725729217400533 | validation: 0.13881798074892066]
	TIME [epoch: 4.87 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05626228630873683		[learning rate: 0.0067309]
	Learning Rate: 0.00673085
	LOSS [training: 0.05626228630873683 | validation: 0.14639770066262076]
	TIME [epoch: 4.86 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07418816466757958		[learning rate: 0.0066875]
	Learning Rate: 0.00668749
	LOSS [training: 0.07418816466757958 | validation: 0.12254492923536144]
	TIME [epoch: 4.86 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11636565985134806		[learning rate: 0.0066444]
	Learning Rate: 0.00664441
	LOSS [training: 0.11636565985134806 | validation: 0.15899570614431913]
	TIME [epoch: 51.2 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09527812147933974		[learning rate: 0.0066016]
	Learning Rate: 0.0066016
	LOSS [training: 0.09527812147933974 | validation: 0.12718749213113065]
	TIME [epoch: 9.34 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06935111866489155		[learning rate: 0.0065591]
	Learning Rate: 0.00655907
	LOSS [training: 0.06935111866489155 | validation: 0.12145840910004221]
	TIME [epoch: 9.33 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07141371450741674		[learning rate: 0.0065168]
	Learning Rate: 0.00651681
	LOSS [training: 0.07141371450741674 | validation: 0.16629057664789332]
	TIME [epoch: 9.32 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06348019505591565		[learning rate: 0.0064748]
	Learning Rate: 0.00647483
	LOSS [training: 0.06348019505591565 | validation: 0.16822871553167568]
	TIME [epoch: 9.34 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086613988463651		[learning rate: 0.0064331]
	Learning Rate: 0.00643311
	LOSS [training: 0.07086613988463651 | validation: 0.15081521757789051]
	TIME [epoch: 9.33 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07235881099252615		[learning rate: 0.0063917]
	Learning Rate: 0.00639166
	LOSS [training: 0.07235881099252615 | validation: 0.12292340296439566]
	TIME [epoch: 9.33 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05763582935339309		[learning rate: 0.0063505]
	Learning Rate: 0.00635049
	LOSS [training: 0.05763582935339309 | validation: 0.14940425180991718]
	TIME [epoch: 9.33 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08247385700038137		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.08247385700038137 | validation: 0.1524845738029869]
	TIME [epoch: 9.34 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716716630057568		[learning rate: 0.0062689]
	Learning Rate: 0.00626892
	LOSS [training: 0.06716716630057568 | validation: 0.15672522767526495]
	TIME [epoch: 9.33 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06966791371060198		[learning rate: 0.0062285]
	Learning Rate: 0.00622854
	LOSS [training: 0.06966791371060198 | validation: 0.1658652408678966]
	TIME [epoch: 9.33 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07430754831623727		[learning rate: 0.0061884]
	Learning Rate: 0.00618841
	LOSS [training: 0.07430754831623727 | validation: 0.13680151761694234]
	TIME [epoch: 9.33 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06578325387195694		[learning rate: 0.0061485]
	Learning Rate: 0.00614854
	LOSS [training: 0.06578325387195694 | validation: 0.17537996727684912]
	TIME [epoch: 9.34 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07181169262566559		[learning rate: 0.0061089]
	Learning Rate: 0.00610893
	LOSS [training: 0.07181169262566559 | validation: 0.1603214352850883]
	TIME [epoch: 9.33 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0748372293023138		[learning rate: 0.0060696]
	Learning Rate: 0.00606957
	LOSS [training: 0.0748372293023138 | validation: 0.1779142617310645]
	TIME [epoch: 9.33 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159919447028272		[learning rate: 0.0060305]
	Learning Rate: 0.00603047
	LOSS [training: 0.07159919447028272 | validation: 0.13105569511304302]
	TIME [epoch: 9.34 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018369185696445		[learning rate: 0.0059916]
	Learning Rate: 0.00599161
	LOSS [training: 0.06018369185696445 | validation: 0.1268153888311456]
	TIME [epoch: 9.34 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05793538302682893		[learning rate: 0.005953]
	Learning Rate: 0.00595301
	LOSS [training: 0.05793538302682893 | validation: 0.11425197714499571]
	TIME [epoch: 9.33 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_118.pth
	Model improved!!!
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06353660432497228		[learning rate: 0.0059147]
	Learning Rate: 0.00591466
	LOSS [training: 0.06353660432497228 | validation: 0.18019876295781587]
	TIME [epoch: 9.34 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416633036611744		[learning rate: 0.0058766]
	Learning Rate: 0.00587655
	LOSS [training: 0.06416633036611744 | validation: 0.12128684612756252]
	TIME [epoch: 9.33 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07166648646789682		[learning rate: 0.0058387]
	Learning Rate: 0.00583869
	LOSS [training: 0.07166648646789682 | validation: 0.1377919136863255]
	TIME [epoch: 9.33 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06342922455183181		[learning rate: 0.0058011]
	Learning Rate: 0.00580108
	LOSS [training: 0.06342922455183181 | validation: 0.11419566847119497]
	TIME [epoch: 9.33 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06034781146328037		[learning rate: 0.0057637]
	Learning Rate: 0.0057637
	LOSS [training: 0.06034781146328037 | validation: 0.20211550555607566]
	TIME [epoch: 9.33 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06672549143912856		[learning rate: 0.0057266]
	Learning Rate: 0.00572657
	LOSS [training: 0.06672549143912856 | validation: 0.1489747537776128]
	TIME [epoch: 9.33 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0660967512770432		[learning rate: 0.0056897]
	Learning Rate: 0.00568968
	LOSS [training: 0.0660967512770432 | validation: 0.1289731349843104]
	TIME [epoch: 9.34 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0637553778607301		[learning rate: 0.005653]
	Learning Rate: 0.00565302
	LOSS [training: 0.0637553778607301 | validation: 0.14956208628716458]
	TIME [epoch: 9.33 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07238468232271923		[learning rate: 0.0056166]
	Learning Rate: 0.0056166
	LOSS [training: 0.07238468232271923 | validation: 0.11536224931382669]
	TIME [epoch: 9.33 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06633055144927655		[learning rate: 0.0055804]
	Learning Rate: 0.00558042
	LOSS [training: 0.06633055144927655 | validation: 0.12456422845392137]
	TIME [epoch: 9.33 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.060147913772715805		[learning rate: 0.0055445]
	Learning Rate: 0.00554447
	LOSS [training: 0.060147913772715805 | validation: 0.1481418293138765]
	TIME [epoch: 9.33 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05448161318888854		[learning rate: 0.0055087]
	Learning Rate: 0.00550874
	LOSS [training: 0.05448161318888854 | validation: 0.114096058199723]
	TIME [epoch: 9.32 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07551684474589204		[learning rate: 0.0054733]
	Learning Rate: 0.00547325
	LOSS [training: 0.07551684474589204 | validation: 0.16550767048239134]
	TIME [epoch: 9.33 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06779107106786965		[learning rate: 0.005438]
	Learning Rate: 0.00543799
	LOSS [training: 0.06779107106786965 | validation: 0.1235275280168751]
	TIME [epoch: 9.33 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0641161040362296		[learning rate: 0.005403]
	Learning Rate: 0.00540296
	LOSS [training: 0.0641161040362296 | validation: 0.1262332957529338]
	TIME [epoch: 9.33 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06654159359365273		[learning rate: 0.0053681]
	Learning Rate: 0.00536815
	LOSS [training: 0.06654159359365273 | validation: 0.19887120495272892]
	TIME [epoch: 9.32 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09021546654147924		[learning rate: 0.0053336]
	Learning Rate: 0.00533356
	LOSS [training: 0.09021546654147924 | validation: 0.14381900931999614]
	TIME [epoch: 9.32 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147163076465032		[learning rate: 0.0052992]
	Learning Rate: 0.0052992
	LOSS [training: 0.07147163076465032 | validation: 0.13608348907505552]
	TIME [epoch: 9.33 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06240384955960448		[learning rate: 0.0052651]
	Learning Rate: 0.00526506
	LOSS [training: 0.06240384955960448 | validation: 0.12054681769519691]
	TIME [epoch: 9.33 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05815423206162226		[learning rate: 0.0052311]
	Learning Rate: 0.00523114
	LOSS [training: 0.05815423206162226 | validation: 0.1536238876203946]
	TIME [epoch: 9.32 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05765221856405216		[learning rate: 0.0051974]
	Learning Rate: 0.00519744
	LOSS [training: 0.05765221856405216 | validation: 0.12040793455054677]
	TIME [epoch: 9.33 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058377416064476134		[learning rate: 0.005164]
	Learning Rate: 0.00516396
	LOSS [training: 0.058377416064476134 | validation: 0.11335406213196333]
	TIME [epoch: 9.33 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_140.pth
	Model improved!!!
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05788102157675847		[learning rate: 0.0051307]
	Learning Rate: 0.00513069
	LOSS [training: 0.05788102157675847 | validation: 0.14077583281867975]
	TIME [epoch: 9.33 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.057177457361614004		[learning rate: 0.0050976]
	Learning Rate: 0.00509763
	LOSS [training: 0.057177457361614004 | validation: 0.15145212898501115]
	TIME [epoch: 9.33 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058001111382404935		[learning rate: 0.0050648]
	Learning Rate: 0.00506479
	LOSS [training: 0.058001111382404935 | validation: 0.11175887101059495]
	TIME [epoch: 9.33 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_143.pth
	Model improved!!!
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279120181488601		[learning rate: 0.0050322]
	Learning Rate: 0.00503216
	LOSS [training: 0.06279120181488601 | validation: 0.12128474597467087]
	TIME [epoch: 9.34 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05927971005629495		[learning rate: 0.0049997]
	Learning Rate: 0.00499974
	LOSS [training: 0.05927971005629495 | validation: 0.1438639687740896]
	TIME [epoch: 9.33 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05783181454250823		[learning rate: 0.0049675]
	Learning Rate: 0.00496753
	LOSS [training: 0.05783181454250823 | validation: 0.11921601775197611]
	TIME [epoch: 9.34 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.060423678281641406		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.060423678281641406 | validation: 0.15994005082973606]
	TIME [epoch: 9.34 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06306058426505662		[learning rate: 0.0049037]
	Learning Rate: 0.00490373
	LOSS [training: 0.06306058426505662 | validation: 0.12710712737755364]
	TIME [epoch: 9.34 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05881003421858119		[learning rate: 0.0048721]
	Learning Rate: 0.00487213
	LOSS [training: 0.05881003421858119 | validation: 0.12547020553322888]
	TIME [epoch: 9.33 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06443323159452813		[learning rate: 0.0048407]
	Learning Rate: 0.00484075
	LOSS [training: 0.06443323159452813 | validation: 0.15957188869730027]
	TIME [epoch: 9.33 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058451870966987986		[learning rate: 0.0048096]
	Learning Rate: 0.00480956
	LOSS [training: 0.058451870966987986 | validation: 0.13152699917903388]
	TIME [epoch: 9.32 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.056398090169914976		[learning rate: 0.0047786]
	Learning Rate: 0.00477857
	LOSS [training: 0.056398090169914976 | validation: 0.11766331146970782]
	TIME [epoch: 9.33 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.051918393196765236		[learning rate: 0.0047478]
	Learning Rate: 0.00474779
	LOSS [training: 0.051918393196765236 | validation: 0.13356876531903988]
	TIME [epoch: 9.33 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05987330778454918		[learning rate: 0.0047172]
	Learning Rate: 0.0047172
	LOSS [training: 0.05987330778454918 | validation: 0.14486972469811268]
	TIME [epoch: 9.33 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06913145837728658		[learning rate: 0.0046868]
	Learning Rate: 0.00468681
	LOSS [training: 0.06913145837728658 | validation: 0.12518942375590297]
	TIME [epoch: 9.32 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05903763878478881		[learning rate: 0.0046566]
	Learning Rate: 0.00465661
	LOSS [training: 0.05903763878478881 | validation: 0.14172168121353962]
	TIME [epoch: 9.33 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0658312176034174		[learning rate: 0.0046266]
	Learning Rate: 0.00462661
	LOSS [training: 0.0658312176034174 | validation: 0.11996351270573878]
	TIME [epoch: 9.32 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05585997925168419		[learning rate: 0.0045968]
	Learning Rate: 0.00459681
	LOSS [training: 0.05585997925168419 | validation: 0.15000602381462033]
	TIME [epoch: 9.33 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0541705942174662		[learning rate: 0.0045672]
	Learning Rate: 0.00456719
	LOSS [training: 0.0541705942174662 | validation: 0.12990298759979943]
	TIME [epoch: 9.33 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785395977813603		[learning rate: 0.0045378]
	Learning Rate: 0.00453777
	LOSS [training: 0.06785395977813603 | validation: 0.10766834766007542]
	TIME [epoch: 9.34 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_160.pth
	Model improved!!!
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06257617711794458		[learning rate: 0.0045085]
	Learning Rate: 0.00450853
	LOSS [training: 0.06257617711794458 | validation: 0.11325086950571187]
	TIME [epoch: 9.32 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05808805073685146		[learning rate: 0.0044795]
	Learning Rate: 0.00447948
	LOSS [training: 0.05808805073685146 | validation: 0.12143614859290808]
	TIME [epoch: 9.33 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05594194031016536		[learning rate: 0.0044506]
	Learning Rate: 0.00445063
	LOSS [training: 0.05594194031016536 | validation: 0.12666696549612075]
	TIME [epoch: 9.33 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05548294905661208		[learning rate: 0.004422]
	Learning Rate: 0.00442195
	LOSS [training: 0.05548294905661208 | validation: 0.11609132256048438]
	TIME [epoch: 9.33 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06510730369107888		[learning rate: 0.0043935]
	Learning Rate: 0.00439346
	LOSS [training: 0.06510730369107888 | validation: 0.1521011169490376]
	TIME [epoch: 9.33 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.061684297396219265		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.061684297396219265 | validation: 0.13562856295972944]
	TIME [epoch: 9.33 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05293886204408442		[learning rate: 0.004337]
	Learning Rate: 0.00433704
	LOSS [training: 0.05293886204408442 | validation: 0.12907353416347972]
	TIME [epoch: 9.32 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561534448591551		[learning rate: 0.0043091]
	Learning Rate: 0.00430909
	LOSS [training: 0.05561534448591551 | validation: 0.11574007134072849]
	TIME [epoch: 9.32 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05444462885662046		[learning rate: 0.0042813]
	Learning Rate: 0.00428133
	LOSS [training: 0.05444462885662046 | validation: 0.12820435042721634]
	TIME [epoch: 9.31 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.054221296024934654		[learning rate: 0.0042537]
	Learning Rate: 0.00425375
	LOSS [training: 0.054221296024934654 | validation: 0.12599457009737872]
	TIME [epoch: 9.32 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.057964610127186615		[learning rate: 0.0042263]
	Learning Rate: 0.00422634
	LOSS [training: 0.057964610127186615 | validation: 0.1321401719927311]
	TIME [epoch: 9.34 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05487000591784441		[learning rate: 0.0041991]
	Learning Rate: 0.00419912
	LOSS [training: 0.05487000591784441 | validation: 0.13890466792253314]
	TIME [epoch: 9.32 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05444457169946064		[learning rate: 0.0041721]
	Learning Rate: 0.00417206
	LOSS [training: 0.05444457169946064 | validation: 0.1233614968290738]
	TIME [epoch: 9.32 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05240936391116211		[learning rate: 0.0041452]
	Learning Rate: 0.00414518
	LOSS [training: 0.05240936391116211 | validation: 0.12896291608642166]
	TIME [epoch: 9.32 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058906842523237316		[learning rate: 0.0041185]
	Learning Rate: 0.00411848
	LOSS [training: 0.058906842523237316 | validation: 0.11866339426692195]
	TIME [epoch: 9.33 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.056786962448772		[learning rate: 0.0040919]
	Learning Rate: 0.00409195
	LOSS [training: 0.056786962448772 | validation: 0.13669937532528467]
	TIME [epoch: 9.33 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.062042868160236936		[learning rate: 0.0040656]
	Learning Rate: 0.00406558
	LOSS [training: 0.062042868160236936 | validation: 0.1540477208877527]
	TIME [epoch: 9.32 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.056289102682822424		[learning rate: 0.0040394]
	Learning Rate: 0.00403939
	LOSS [training: 0.056289102682822424 | validation: 0.1334073904887705]
	TIME [epoch: 9.33 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05289653403822589		[learning rate: 0.0040134]
	Learning Rate: 0.00401337
	LOSS [training: 0.05289653403822589 | validation: 0.12516747640545917]
	TIME [epoch: 9.33 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271641788483615		[learning rate: 0.0039875]
	Learning Rate: 0.00398751
	LOSS [training: 0.06271641788483615 | validation: 0.13078940759033383]
	TIME [epoch: 9.32 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05451516714413255		[learning rate: 0.0039618]
	Learning Rate: 0.00396182
	LOSS [training: 0.05451516714413255 | validation: 0.11454835347539195]
	TIME [epoch: 9.32 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.051601413274336254		[learning rate: 0.0039363]
	Learning Rate: 0.0039363
	LOSS [training: 0.051601413274336254 | validation: 0.12490311878645088]
	TIME [epoch: 9.32 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05246105958137687		[learning rate: 0.0039109]
	Learning Rate: 0.00391094
	LOSS [training: 0.05246105958137687 | validation: 0.12946212111712585]
	TIME [epoch: 9.33 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.055326422504995296		[learning rate: 0.0038857]
	Learning Rate: 0.00388574
	LOSS [training: 0.055326422504995296 | validation: 0.11686473736919592]
	TIME [epoch: 9.33 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05763834792207321		[learning rate: 0.0038607]
	Learning Rate: 0.00386071
	LOSS [training: 0.05763834792207321 | validation: 0.13474697227165228]
	TIME [epoch: 9.33 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05644547292262864		[learning rate: 0.0038358]
	Learning Rate: 0.00383583
	LOSS [training: 0.05644547292262864 | validation: 0.13716745038537032]
	TIME [epoch: 9.32 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508023001933229		[learning rate: 0.0038111]
	Learning Rate: 0.00381112
	LOSS [training: 0.05508023001933229 | validation: 0.1553372442932869]
	TIME [epoch: 9.34 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06378427756389393		[learning rate: 0.0037866]
	Learning Rate: 0.00378657
	LOSS [training: 0.06378427756389393 | validation: 0.13800801150684153]
	TIME [epoch: 9.32 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.057388164996162214		[learning rate: 0.0037622]
	Learning Rate: 0.00376217
	LOSS [training: 0.057388164996162214 | validation: 0.11912309164933492]
	TIME [epoch: 9.32 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06089013953062196		[learning rate: 0.0037379]
	Learning Rate: 0.00373793
	LOSS [training: 0.06089013953062196 | validation: 0.15071188761537402]
	TIME [epoch: 9.32 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164402408624443		[learning rate: 0.0037139]
	Learning Rate: 0.00371385
	LOSS [training: 0.05164402408624443 | validation: 0.1288627526379577]
	TIME [epoch: 9.34 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05230790213500266		[learning rate: 0.0036899]
	Learning Rate: 0.00368992
	LOSS [training: 0.05230790213500266 | validation: 0.1338554001611025]
	TIME [epoch: 9.33 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05338066425099814		[learning rate: 0.0036662]
	Learning Rate: 0.00366615
	LOSS [training: 0.05338066425099814 | validation: 0.11845540831845817]
	TIME [epoch: 9.33 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854542287721832		[learning rate: 0.0036425]
	Learning Rate: 0.00364253
	LOSS [training: 0.04854542287721832 | validation: 0.12323195683178668]
	TIME [epoch: 9.33 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068285355790298		[learning rate: 0.0036191]
	Learning Rate: 0.00361907
	LOSS [training: 0.05068285355790298 | validation: 0.11972971205043813]
	TIME [epoch: 9.33 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068163494649227		[learning rate: 0.0035957]
	Learning Rate: 0.00359575
	LOSS [training: 0.05068163494649227 | validation: 0.12202528257370839]
	TIME [epoch: 9.33 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05577598230313287		[learning rate: 0.0035726]
	Learning Rate: 0.00357258
	LOSS [training: 0.05577598230313287 | validation: 0.1185492630726058]
	TIME [epoch: 9.32 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494825476019614		[learning rate: 0.0035496]
	Learning Rate: 0.00354957
	LOSS [training: 0.0494825476019614 | validation: 0.13605276858298251]
	TIME [epoch: 9.33 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0563719954882112		[learning rate: 0.0035267]
	Learning Rate: 0.0035267
	LOSS [training: 0.0563719954882112 | validation: 0.13967832972906746]
	TIME [epoch: 9.33 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06035276802933367		[learning rate: 0.003504]
	Learning Rate: 0.00350398
	LOSS [training: 0.06035276802933367 | validation: 0.15921635240505974]
	TIME [epoch: 9.33 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058580152436943124		[learning rate: 0.0034814]
	Learning Rate: 0.0034814
	LOSS [training: 0.058580152436943124 | validation: 0.12607515134538255]
	TIME [epoch: 9.32 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05377369604911066		[learning rate: 0.003459]
	Learning Rate: 0.00345897
	LOSS [training: 0.05377369604911066 | validation: 0.13317022399441875]
	TIME [epoch: 9.34 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05773462524916194		[learning rate: 0.0034367]
	Learning Rate: 0.00343669
	LOSS [training: 0.05773462524916194 | validation: 0.12608405710638512]
	TIME [epoch: 9.34 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06601387448886095		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.06601387448886095 | validation: 0.1261430369711801]
	TIME [epoch: 9.91 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06227751078532721		[learning rate: 0.0033926]
	Learning Rate: 0.00339255
	LOSS [training: 0.06227751078532721 | validation: 0.11745564295865765]
	TIME [epoch: 9.33 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049354589675913		[learning rate: 0.0033707]
	Learning Rate: 0.00337069
	LOSS [training: 0.05049354589675913 | validation: 0.12351538119113112]
	TIME [epoch: 9.34 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.053319154866834105		[learning rate: 0.003349]
	Learning Rate: 0.00334898
	LOSS [training: 0.053319154866834105 | validation: 0.12391026652037221]
	TIME [epoch: 9.34 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.052342308122633414		[learning rate: 0.0033274]
	Learning Rate: 0.0033274
	LOSS [training: 0.052342308122633414 | validation: 0.11802028805561687]
	TIME [epoch: 9.33 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04864428582281098		[learning rate: 0.003306]
	Learning Rate: 0.00330596
	LOSS [training: 0.04864428582281098 | validation: 0.1337223887892507]
	TIME [epoch: 9.34 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0475323080425661		[learning rate: 0.0032847]
	Learning Rate: 0.00328467
	LOSS [training: 0.0475323080425661 | validation: 0.13288984816120325]
	TIME [epoch: 9.34 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05252186839529326		[learning rate: 0.0032635]
	Learning Rate: 0.0032635
	LOSS [training: 0.05252186839529326 | validation: 0.15244697440889263]
	TIME [epoch: 9.35 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049854571870121524		[learning rate: 0.0032425]
	Learning Rate: 0.00324248
	LOSS [training: 0.049854571870121524 | validation: 0.1223440597815952]
	TIME [epoch: 9.33 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05568176227069711		[learning rate: 0.0032216]
	Learning Rate: 0.00322159
	LOSS [training: 0.05568176227069711 | validation: 0.12441488035195002]
	TIME [epoch: 9.34 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924909934542929		[learning rate: 0.0032008]
	Learning Rate: 0.00320083
	LOSS [training: 0.04924909934542929 | validation: 0.13832670896248617]
	TIME [epoch: 9.34 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0492624806667275		[learning rate: 0.0031802]
	Learning Rate: 0.00318021
	LOSS [training: 0.0492624806667275 | validation: 0.11831154533609595]
	TIME [epoch: 9.34 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05169651117859409		[learning rate: 0.0031597]
	Learning Rate: 0.00315972
	LOSS [training: 0.05169651117859409 | validation: 0.1129201395886748]
	TIME [epoch: 9.33 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04879368541077641		[learning rate: 0.0031394]
	Learning Rate: 0.00313937
	LOSS [training: 0.04879368541077641 | validation: 0.12277072967490732]
	TIME [epoch: 9.34 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0484660631492124		[learning rate: 0.0031191]
	Learning Rate: 0.00311914
	LOSS [training: 0.0484660631492124 | validation: 0.13387823238267138]
	TIME [epoch: 9.34 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.062056502750928805		[learning rate: 0.003099]
	Learning Rate: 0.00309905
	LOSS [training: 0.062056502750928805 | validation: 0.13797213777867562]
	TIME [epoch: 9.34 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05473200125376436		[learning rate: 0.0030791]
	Learning Rate: 0.00307908
	LOSS [training: 0.05473200125376436 | validation: 0.11835373431817768]
	TIME [epoch: 9.33 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0491781491044507		[learning rate: 0.0030592]
	Learning Rate: 0.00305924
	LOSS [training: 0.0491781491044507 | validation: 0.13896961338484637]
	TIME [epoch: 9.34 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334889239289047		[learning rate: 0.0030395]
	Learning Rate: 0.00303953
	LOSS [training: 0.05334889239289047 | validation: 0.11385918039752327]
	TIME [epoch: 9.35 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856117438867882		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.04856117438867882 | validation: 0.11747982048191274]
	TIME [epoch: 9.34 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04891873195696428		[learning rate: 0.0030005]
	Learning Rate: 0.0030005
	LOSS [training: 0.04891873195696428 | validation: 0.11734391650354811]
	TIME [epoch: 9.33 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04763512292161509		[learning rate: 0.0029812]
	Learning Rate: 0.00298116
	LOSS [training: 0.04763512292161509 | validation: 0.11841177598740917]
	TIME [epoch: 9.33 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05652498711633429		[learning rate: 0.002962]
	Learning Rate: 0.00296196
	LOSS [training: 0.05652498711633429 | validation: 0.10656111330532066]
	TIME [epoch: 9.34 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_226.pth
	Model improved!!!
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.058423216088392266		[learning rate: 0.0029429]
	Learning Rate: 0.00294288
	LOSS [training: 0.058423216088392266 | validation: 0.13237795363621746]
	TIME [epoch: 9.33 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.053196877997863115		[learning rate: 0.0029239]
	Learning Rate: 0.00292392
	LOSS [training: 0.053196877997863115 | validation: 0.13885455303380412]
	TIME [epoch: 9.34 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0596973454214745		[learning rate: 0.0029051]
	Learning Rate: 0.00290508
	LOSS [training: 0.0596973454214745 | validation: 0.1127850791788827]
	TIME [epoch: 9.33 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05278803241613579		[learning rate: 0.0028864]
	Learning Rate: 0.00288636
	LOSS [training: 0.05278803241613579 | validation: 0.11810790380908257]
	TIME [epoch: 9.34 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.050953484050483965		[learning rate: 0.0028678]
	Learning Rate: 0.00286777
	LOSS [training: 0.050953484050483965 | validation: 0.11011387937804108]
	TIME [epoch: 9.33 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.053440341691503315		[learning rate: 0.0028493]
	Learning Rate: 0.00284929
	LOSS [training: 0.053440341691503315 | validation: 0.13122305678236484]
	TIME [epoch: 9.33 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05040292207337466		[learning rate: 0.0028309]
	Learning Rate: 0.00283093
	LOSS [training: 0.05040292207337466 | validation: 0.12075903754111014]
	TIME [epoch: 9.33 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501594562275276		[learning rate: 0.0028127]
	Learning Rate: 0.0028127
	LOSS [training: 0.06501594562275276 | validation: 0.14612415149774513]
	TIME [epoch: 9.33 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.054741671087819015		[learning rate: 0.0027946]
	Learning Rate: 0.00279457
	LOSS [training: 0.054741671087819015 | validation: 0.11387820966574186]
	TIME [epoch: 9.33 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04722308953789624		[learning rate: 0.0027766]
	Learning Rate: 0.00277657
	LOSS [training: 0.04722308953789624 | validation: 0.1200763259932136]
	TIME [epoch: 9.33 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05346016504405006		[learning rate: 0.0027587]
	Learning Rate: 0.00275868
	LOSS [training: 0.05346016504405006 | validation: 0.12198855956026633]
	TIME [epoch: 9.34 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824677362666031		[learning rate: 0.0027409]
	Learning Rate: 0.00274091
	LOSS [training: 0.04824677362666031 | validation: 0.12934156993652512]
	TIME [epoch: 9.34 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432531175137871		[learning rate: 0.0027233]
	Learning Rate: 0.00272325
	LOSS [training: 0.05432531175137871 | validation: 0.11506279366654347]
	TIME [epoch: 9.33 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049122910401208086		[learning rate: 0.0027057]
	Learning Rate: 0.00270571
	LOSS [training: 0.049122910401208086 | validation: 0.12182341870598018]
	TIME [epoch: 9.33 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05361515546177136		[learning rate: 0.0026883]
	Learning Rate: 0.00268827
	LOSS [training: 0.05361515546177136 | validation: 0.12240989316358813]
	TIME [epoch: 9.34 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0540228578709171		[learning rate: 0.002671]
	Learning Rate: 0.00267096
	LOSS [training: 0.0540228578709171 | validation: 0.11591919535824413]
	TIME [epoch: 9.34 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04808681452686029		[learning rate: 0.0026537]
	Learning Rate: 0.00265375
	LOSS [training: 0.04808681452686029 | validation: 0.11356144433682815]
	TIME [epoch: 9.33 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368988185460833		[learning rate: 0.0026367]
	Learning Rate: 0.00263665
	LOSS [training: 0.05368988185460833 | validation: 0.12529333672133597]
	TIME [epoch: 9.33 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.052929070853256904		[learning rate: 0.0026197]
	Learning Rate: 0.00261966
	LOSS [training: 0.052929070853256904 | validation: 0.12643186679219287]
	TIME [epoch: 9.34 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.051293712264658134		[learning rate: 0.0026028]
	Learning Rate: 0.00260279
	LOSS [training: 0.051293712264658134 | validation: 0.12343877011306363]
	TIME [epoch: 9.34 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04583798687527664		[learning rate: 0.002586]
	Learning Rate: 0.00258602
	LOSS [training: 0.04583798687527664 | validation: 0.12009310167843396]
	TIME [epoch: 9.33 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046893634077612587		[learning rate: 0.0025694]
	Learning Rate: 0.00256936
	LOSS [training: 0.046893634077612587 | validation: 0.12537572290971927]
	TIME [epoch: 9.33 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.057738677521912675		[learning rate: 0.0025528]
	Learning Rate: 0.0025528
	LOSS [training: 0.057738677521912675 | validation: 0.10748981851577637]
	TIME [epoch: 9.34 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388872833822722		[learning rate: 0.0025364]
	Learning Rate: 0.00253636
	LOSS [training: 0.05388872833822722 | validation: 0.14658764875940672]
	TIME [epoch: 9.34 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962131794067328		[learning rate: 0.00252]
	Learning Rate: 0.00252002
	LOSS [training: 0.04962131794067328 | validation: 0.11250957809385279]
	TIME [epoch: 9.33 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.050660943722763536		[learning rate: 0.0025038]
	Learning Rate: 0.00250378
	LOSS [training: 0.050660943722763536 | validation: 0.11885360408619061]
	TIME [epoch: 9.33 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05138341365707804		[learning rate: 0.0024877]
	Learning Rate: 0.00248765
	LOSS [training: 0.05138341365707804 | validation: 0.12881951528487817]
	TIME [epoch: 9.34 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05284992096489691		[learning rate: 0.0024716]
	Learning Rate: 0.00247162
	LOSS [training: 0.05284992096489691 | validation: 0.12812453500984408]
	TIME [epoch: 9.34 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048753340478268035		[learning rate: 0.0024557]
	Learning Rate: 0.0024557
	LOSS [training: 0.048753340478268035 | validation: 0.11644554906438456]
	TIME [epoch: 9.32 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04976613764526639		[learning rate: 0.0024399]
	Learning Rate: 0.00243988
	LOSS [training: 0.04976613764526639 | validation: 0.13270262385746426]
	TIME [epoch: 9.34 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04788693037081287		[learning rate: 0.0024242]
	Learning Rate: 0.00242416
	LOSS [training: 0.04788693037081287 | validation: 0.11243098862429253]
	TIME [epoch: 9.34 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05491086750594289		[learning rate: 0.0024085]
	Learning Rate: 0.00240854
	LOSS [training: 0.05491086750594289 | validation: 0.11393622362968986]
	TIME [epoch: 9.34 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049232637513249966		[learning rate: 0.002393]
	Learning Rate: 0.00239303
	LOSS [training: 0.049232637513249966 | validation: 0.11522934127786683]
	TIME [epoch: 9.33 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360346937925127		[learning rate: 0.0023776]
	Learning Rate: 0.00237761
	LOSS [training: 0.05360346937925127 | validation: 0.12752090761732665]
	TIME [epoch: 9.33 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068098622371924		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.05068098622371924 | validation: 0.11987414720726146]
	TIME [epoch: 9.34 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203051408989644		[learning rate: 0.0023471]
	Learning Rate: 0.00234707
	LOSS [training: 0.05203051408989644 | validation: 0.11580047370282529]
	TIME [epoch: 9.34 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769732103231912		[learning rate: 0.002332]
	Learning Rate: 0.00233195
	LOSS [training: 0.04769732103231912 | validation: 0.1275060488226405]
	TIME [epoch: 9.34 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05286423842147734		[learning rate: 0.0023169]
	Learning Rate: 0.00231693
	LOSS [training: 0.05286423842147734 | validation: 0.1359061479725951]
	TIME [epoch: 9.35 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05465412852221249		[learning rate: 0.002302]
	Learning Rate: 0.002302
	LOSS [training: 0.05465412852221249 | validation: 0.1379678010490138]
	TIME [epoch: 9.35 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048827212724936384		[learning rate: 0.0022872]
	Learning Rate: 0.00228717
	LOSS [training: 0.048827212724936384 | validation: 0.11667577712792772]
	TIME [epoch: 9.34 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043989934526092275		[learning rate: 0.0022724]
	Learning Rate: 0.00227243
	LOSS [training: 0.043989934526092275 | validation: 0.11749303194926007]
	TIME [epoch: 9.34 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0482862947525804		[learning rate: 0.0022578]
	Learning Rate: 0.00225779
	LOSS [training: 0.0482862947525804 | validation: 0.1152581558983148]
	TIME [epoch: 9.34 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04981125733090471		[learning rate: 0.0022432]
	Learning Rate: 0.00224325
	LOSS [training: 0.04981125733090471 | validation: 0.11302848496566661]
	TIME [epoch: 9.34 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0469187125924202		[learning rate: 0.0022288]
	Learning Rate: 0.0022288
	LOSS [training: 0.0469187125924202 | validation: 0.10960228247129396]
	TIME [epoch: 9.33 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05161082132606451		[learning rate: 0.0022144]
	Learning Rate: 0.00221444
	LOSS [training: 0.05161082132606451 | validation: 0.12062130968765963]
	TIME [epoch: 9.32 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05132664098070114		[learning rate: 0.0022002]
	Learning Rate: 0.00220017
	LOSS [training: 0.05132664098070114 | validation: 0.11955314430002335]
	TIME [epoch: 9.32 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046966789152768		[learning rate: 0.002186]
	Learning Rate: 0.00218599
	LOSS [training: 0.046966789152768 | validation: 0.1199875740120403]
	TIME [epoch: 9.34 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04782283344601807		[learning rate: 0.0021719]
	Learning Rate: 0.00217191
	LOSS [training: 0.04782283344601807 | validation: 0.11090170397860005]
	TIME [epoch: 9.33 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04678695045011522		[learning rate: 0.0021579]
	Learning Rate: 0.00215792
	LOSS [training: 0.04678695045011522 | validation: 0.1197979901220819]
	TIME [epoch: 9.33 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04866803619010995		[learning rate: 0.002144]
	Learning Rate: 0.00214402
	LOSS [training: 0.04866803619010995 | validation: 0.11540744874171613]
	TIME [epoch: 9.33 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04893431387075339		[learning rate: 0.0021302]
	Learning Rate: 0.0021302
	LOSS [training: 0.04893431387075339 | validation: 0.12188216088482297]
	TIME [epoch: 9.34 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04995620328632054		[learning rate: 0.0021165]
	Learning Rate: 0.00211648
	LOSS [training: 0.04995620328632054 | validation: 0.12461646849363664]
	TIME [epoch: 9.33 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047484936612020495		[learning rate: 0.0021028]
	Learning Rate: 0.00210284
	LOSS [training: 0.047484936612020495 | validation: 0.11414693266251012]
	TIME [epoch: 9.32 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048049511706915606		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.048049511706915606 | validation: 0.1182406225248761]
	TIME [epoch: 9.33 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049047726128747714		[learning rate: 0.0020758]
	Learning Rate: 0.00207584
	LOSS [training: 0.049047726128747714 | validation: 0.11575418725316496]
	TIME [epoch: 9.33 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043876831730259566		[learning rate: 0.0020625]
	Learning Rate: 0.00206246
	LOSS [training: 0.043876831730259566 | validation: 0.106881365278384]
	TIME [epoch: 9.33 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04685310651316138		[learning rate: 0.0020492]
	Learning Rate: 0.00204917
	LOSS [training: 0.04685310651316138 | validation: 0.14482317335826522]
	TIME [epoch: 9.32 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04629498841153501		[learning rate: 0.002036]
	Learning Rate: 0.00203597
	LOSS [training: 0.04629498841153501 | validation: 0.11850579349676679]
	TIME [epoch: 9.33 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04996953977752708		[learning rate: 0.0020229]
	Learning Rate: 0.00202286
	LOSS [training: 0.04996953977752708 | validation: 0.11412688317809358]
	TIME [epoch: 9.34 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04691022855813503		[learning rate: 0.0020098]
	Learning Rate: 0.00200982
	LOSS [training: 0.04691022855813503 | validation: 0.11893199166838704]
	TIME [epoch: 9.33 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04432695240323061		[learning rate: 0.0019969]
	Learning Rate: 0.00199687
	LOSS [training: 0.04432695240323061 | validation: 0.1107680245212949]
	TIME [epoch: 9.33 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04984747043092924		[learning rate: 0.001984]
	Learning Rate: 0.00198401
	LOSS [training: 0.04984747043092924 | validation: 0.11754610818666779]
	TIME [epoch: 9.33 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529148239941643		[learning rate: 0.0019712]
	Learning Rate: 0.00197123
	LOSS [training: 0.04529148239941643 | validation: 0.11695220549899843]
	TIME [epoch: 9.33 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046693633539792605		[learning rate: 0.0019585]
	Learning Rate: 0.00195853
	LOSS [training: 0.046693633539792605 | validation: 0.10998531645583497]
	TIME [epoch: 9.33 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04695656284565873		[learning rate: 0.0019459]
	Learning Rate: 0.00194591
	LOSS [training: 0.04695656284565873 | validation: 0.11755199453306722]
	TIME [epoch: 9.32 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611951739326222		[learning rate: 0.0019334]
	Learning Rate: 0.00193337
	LOSS [training: 0.04611951739326222 | validation: 0.11948472092821147]
	TIME [epoch: 9.33 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044751131759356924		[learning rate: 0.0019209]
	Learning Rate: 0.00192092
	LOSS [training: 0.044751131759356924 | validation: 0.12233669492828454]
	TIME [epoch: 9.33 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04685063531647764		[learning rate: 0.0019085]
	Learning Rate: 0.00190854
	LOSS [training: 0.04685063531647764 | validation: 0.11555103134306902]
	TIME [epoch: 9.33 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047077197763496705		[learning rate: 0.0018962]
	Learning Rate: 0.00189625
	LOSS [training: 0.047077197763496705 | validation: 0.10761003976986339]
	TIME [epoch: 9.33 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046898717068928626		[learning rate: 0.001884]
	Learning Rate: 0.00188403
	LOSS [training: 0.046898717068928626 | validation: 0.11938911809598604]
	TIME [epoch: 9.33 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047073983572124244		[learning rate: 0.0018719]
	Learning Rate: 0.00187189
	LOSS [training: 0.047073983572124244 | validation: 0.12654246402630653]
	TIME [epoch: 9.33 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05656762102904135		[learning rate: 0.0018598]
	Learning Rate: 0.00185983
	LOSS [training: 0.05656762102904135 | validation: 0.10496273178230489]
	TIME [epoch: 9.32 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_298.pth
	Model improved!!!
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04613100970670418		[learning rate: 0.0018478]
	Learning Rate: 0.00184785
	LOSS [training: 0.04613100970670418 | validation: 0.11660188230672168]
	TIME [epoch: 9.32 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05218487720174521		[learning rate: 0.0018359]
	Learning Rate: 0.00183594
	LOSS [training: 0.05218487720174521 | validation: 0.11732940654134588]
	TIME [epoch: 9.33 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04992477161057521		[learning rate: 0.0018241]
	Learning Rate: 0.00182412
	LOSS [training: 0.04992477161057521 | validation: 0.11195407351670406]
	TIME [epoch: 61.6 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05022284484226082		[learning rate: 0.0018124]
	Learning Rate: 0.00181236
	LOSS [training: 0.05022284484226082 | validation: 0.1169763611924737]
	TIME [epoch: 19.6 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04790607839876637		[learning rate: 0.0018007]
	Learning Rate: 0.00180069
	LOSS [training: 0.04790607839876637 | validation: 0.12767020909145146]
	TIME [epoch: 19.6 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04335779834509976		[learning rate: 0.0017891]
	Learning Rate: 0.00178909
	LOSS [training: 0.04335779834509976 | validation: 0.11476767702383042]
	TIME [epoch: 19.6 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04944691025098795		[learning rate: 0.0017776]
	Learning Rate: 0.00177756
	LOSS [training: 0.04944691025098795 | validation: 0.12330538734661385]
	TIME [epoch: 19.6 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049905883431619606		[learning rate: 0.0017661]
	Learning Rate: 0.00176611
	LOSS [training: 0.049905883431619606 | validation: 0.12074406557000937]
	TIME [epoch: 19.6 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835784010589164		[learning rate: 0.0017547]
	Learning Rate: 0.00175473
	LOSS [training: 0.04835784010589164 | validation: 0.11353988512547591]
	TIME [epoch: 19.6 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672321280904174		[learning rate: 0.0017434]
	Learning Rate: 0.00174343
	LOSS [training: 0.04672321280904174 | validation: 0.12629796368847507]
	TIME [epoch: 19.6 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04646935104291519		[learning rate: 0.0017322]
	Learning Rate: 0.00173219
	LOSS [training: 0.04646935104291519 | validation: 0.1279257762822459]
	TIME [epoch: 19.6 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048435497831321235		[learning rate: 0.001721]
	Learning Rate: 0.00172103
	LOSS [training: 0.048435497831321235 | validation: 0.11259814075774954]
	TIME [epoch: 19.6 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04752605753120345		[learning rate: 0.0017099]
	Learning Rate: 0.00170995
	LOSS [training: 0.04752605753120345 | validation: 0.12254354956704022]
	TIME [epoch: 19.6 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659335693233327		[learning rate: 0.0016989]
	Learning Rate: 0.00169893
	LOSS [training: 0.04659335693233327 | validation: 0.12247830827123542]
	TIME [epoch: 19.6 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04517860699966926		[learning rate: 0.001688]
	Learning Rate: 0.00168798
	LOSS [training: 0.04517860699966926 | validation: 0.10937852813587516]
	TIME [epoch: 19.6 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05133766660590352		[learning rate: 0.0016771]
	Learning Rate: 0.00167711
	LOSS [training: 0.05133766660590352 | validation: 0.1312217815994377]
	TIME [epoch: 19.6 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04503794916469291		[learning rate: 0.0016663]
	Learning Rate: 0.0016663
	LOSS [training: 0.04503794916469291 | validation: 0.11640927082349672]
	TIME [epoch: 19.6 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126905880251565		[learning rate: 0.0016556]
	Learning Rate: 0.00165557
	LOSS [training: 0.05126905880251565 | validation: 0.11693543430539573]
	TIME [epoch: 19.6 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04978822105959152		[learning rate: 0.0016449]
	Learning Rate: 0.0016449
	LOSS [training: 0.04978822105959152 | validation: 0.12008607836854396]
	TIME [epoch: 19.6 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04478648765619608		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.04478648765619608 | validation: 0.11852079440375476]
	TIME [epoch: 19.7 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.052986930944374455		[learning rate: 0.0016238]
	Learning Rate: 0.00162378
	LOSS [training: 0.052986930944374455 | validation: 0.13545953148779755]
	TIME [epoch: 19.7 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561170302286948		[learning rate: 0.0016133]
	Learning Rate: 0.00161332
	LOSS [training: 0.04561170302286948 | validation: 0.11371103671148919]
	TIME [epoch: 19.6 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045182857491031264		[learning rate: 0.0016029]
	Learning Rate: 0.00160292
	LOSS [training: 0.045182857491031264 | validation: 0.10282468342972716]
	TIME [epoch: 19.6 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_321.pth
	Model improved!!!
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04653133578034567		[learning rate: 0.0015926]
	Learning Rate: 0.00159259
	LOSS [training: 0.04653133578034567 | validation: 0.12568397947581264]
	TIME [epoch: 19.6 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555028004516992		[learning rate: 0.0015823]
	Learning Rate: 0.00158233
	LOSS [training: 0.04555028004516992 | validation: 0.11121322192342072]
	TIME [epoch: 19.6 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04908383465236284		[learning rate: 0.0015721]
	Learning Rate: 0.00157214
	LOSS [training: 0.04908383465236284 | validation: 0.11853563521994773]
	TIME [epoch: 19.6 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049314542346429596		[learning rate: 0.001562]
	Learning Rate: 0.00156201
	LOSS [training: 0.049314542346429596 | validation: 0.11288157341732416]
	TIME [epoch: 19.6 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389200941153633		[learning rate: 0.0015519]
	Learning Rate: 0.00155195
	LOSS [training: 0.04389200941153633 | validation: 0.11445711482687806]
	TIME [epoch: 19.6 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464482416030966		[learning rate: 0.0015419]
	Learning Rate: 0.00154195
	LOSS [training: 0.0464482416030966 | validation: 0.11718345056517855]
	TIME [epoch: 19.6 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05131561217628533		[learning rate: 0.001532]
	Learning Rate: 0.00153202
	LOSS [training: 0.05131561217628533 | validation: 0.12191785377628885]
	TIME [epoch: 19.6 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04625851306671464		[learning rate: 0.0015221]
	Learning Rate: 0.00152215
	LOSS [training: 0.04625851306671464 | validation: 0.11771686603926128]
	TIME [epoch: 19.6 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04488261891022132		[learning rate: 0.0015123]
	Learning Rate: 0.00151234
	LOSS [training: 0.04488261891022132 | validation: 0.12000571797711244]
	TIME [epoch: 19.6 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05636892637193764		[learning rate: 0.0015026]
	Learning Rate: 0.0015026
	LOSS [training: 0.05636892637193764 | validation: 0.11745996904521916]
	TIME [epoch: 19.6 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442280538474611		[learning rate: 0.0014929]
	Learning Rate: 0.00149291
	LOSS [training: 0.04442280538474611 | validation: 0.1144634098719578]
	TIME [epoch: 19.6 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05117021038072629		[learning rate: 0.0014833]
	Learning Rate: 0.0014833
	LOSS [training: 0.05117021038072629 | validation: 0.12305699923491775]
	TIME [epoch: 19.6 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047725447728036996		[learning rate: 0.0014737]
	Learning Rate: 0.00147374
	LOSS [training: 0.047725447728036996 | validation: 0.11833360234297746]
	TIME [epoch: 19.6 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04952119335118517		[learning rate: 0.0014642]
	Learning Rate: 0.00146425
	LOSS [training: 0.04952119335118517 | validation: 0.1171497373950297]
	TIME [epoch: 19.6 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0441339606111663		[learning rate: 0.0014548]
	Learning Rate: 0.00145481
	LOSS [training: 0.0441339606111663 | validation: 0.1340965020974607]
	TIME [epoch: 19.6 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0476108059494096		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.0476108059494096 | validation: 0.11644693638472418]
	TIME [epoch: 19.6 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463149097158904		[learning rate: 0.0014361]
	Learning Rate: 0.00143613
	LOSS [training: 0.0463149097158904 | validation: 0.11252781054392584]
	TIME [epoch: 19.6 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046500584808033506		[learning rate: 0.0014269]
	Learning Rate: 0.00142688
	LOSS [training: 0.046500584808033506 | validation: 0.12123068192673633]
	TIME [epoch: 19.6 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046997265217428114		[learning rate: 0.0014177]
	Learning Rate: 0.00141768
	LOSS [training: 0.046997265217428114 | validation: 0.12323606219038045]
	TIME [epoch: 19.6 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04384615772527546		[learning rate: 0.0014085]
	Learning Rate: 0.00140855
	LOSS [training: 0.04384615772527546 | validation: 0.1268760657353594]
	TIME [epoch: 19.6 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04571603053788263		[learning rate: 0.0013995]
	Learning Rate: 0.00139947
	LOSS [training: 0.04571603053788263 | validation: 0.12819861389315096]
	TIME [epoch: 19.6 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.054179296167572735		[learning rate: 0.0013905]
	Learning Rate: 0.00139046
	LOSS [training: 0.054179296167572735 | validation: 0.12281590058139442]
	TIME [epoch: 19.6 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049937343209879824		[learning rate: 0.0013815]
	Learning Rate: 0.0013815
	LOSS [training: 0.049937343209879824 | validation: 0.12218442641854484]
	TIME [epoch: 19.6 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049139651420032765		[learning rate: 0.0013726]
	Learning Rate: 0.0013726
	LOSS [training: 0.049139651420032765 | validation: 0.1193062703240678]
	TIME [epoch: 19.6 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04313492233835631		[learning rate: 0.0013638]
	Learning Rate: 0.00136376
	LOSS [training: 0.04313492233835631 | validation: 0.12363674658378247]
	TIME [epoch: 19.6 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04991270705118346		[learning rate: 0.001355]
	Learning Rate: 0.00135497
	LOSS [training: 0.04991270705118346 | validation: 0.11662376677779435]
	TIME [epoch: 19.6 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689531959389604		[learning rate: 0.0013462]
	Learning Rate: 0.00134624
	LOSS [training: 0.04689531959389604 | validation: 0.11378874159365468]
	TIME [epoch: 19.6 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043661578387704694		[learning rate: 0.0013376]
	Learning Rate: 0.00133757
	LOSS [training: 0.043661578387704694 | validation: 0.11400173006234679]
	TIME [epoch: 19.6 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042395233888672945		[learning rate: 0.001329]
	Learning Rate: 0.00132895
	LOSS [training: 0.042395233888672945 | validation: 0.11403058247628875]
	TIME [epoch: 19.6 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045726702700327256		[learning rate: 0.0013204]
	Learning Rate: 0.00132039
	LOSS [training: 0.045726702700327256 | validation: 0.1168138545814227]
	TIME [epoch: 19.6 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04405952818449635		[learning rate: 0.0013119]
	Learning Rate: 0.00131188
	LOSS [training: 0.04405952818449635 | validation: 0.11794925088657587]
	TIME [epoch: 19.6 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04259384953177815		[learning rate: 0.0013034]
	Learning Rate: 0.00130343
	LOSS [training: 0.04259384953177815 | validation: 0.1153364947496132]
	TIME [epoch: 19.6 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046717863261963484		[learning rate: 0.001295]
	Learning Rate: 0.00129503
	LOSS [training: 0.046717863261963484 | validation: 0.11689021657966787]
	TIME [epoch: 19.6 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.053224917661256615		[learning rate: 0.0012867]
	Learning Rate: 0.00128669
	LOSS [training: 0.053224917661256615 | validation: 0.12800873329799034]
	TIME [epoch: 19.6 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044232315482486226		[learning rate: 0.0012784]
	Learning Rate: 0.0012784
	LOSS [training: 0.044232315482486226 | validation: 0.11753245887081723]
	TIME [epoch: 19.6 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05077052182158319		[learning rate: 0.0012702]
	Learning Rate: 0.00127016
	LOSS [training: 0.05077052182158319 | validation: 0.11708130879734607]
	TIME [epoch: 19.6 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04737279459281311		[learning rate: 0.001262]
	Learning Rate: 0.00126198
	LOSS [training: 0.04737279459281311 | validation: 0.12027097982296436]
	TIME [epoch: 19.6 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048316112540091015		[learning rate: 0.0012538]
	Learning Rate: 0.00125385
	LOSS [training: 0.048316112540091015 | validation: 0.10892879469299313]
	TIME [epoch: 19.6 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046802006452689913		[learning rate: 0.0012458]
	Learning Rate: 0.00124577
	LOSS [training: 0.046802006452689913 | validation: 0.11957914571827648]
	TIME [epoch: 19.6 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047191458926094346		[learning rate: 0.0012377]
	Learning Rate: 0.00123775
	LOSS [training: 0.047191458926094346 | validation: 0.1115865219241431]
	TIME [epoch: 19.6 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048179342091535945		[learning rate: 0.0012298]
	Learning Rate: 0.00122977
	LOSS [training: 0.048179342091535945 | validation: 0.11185445858246774]
	TIME [epoch: 19.6 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043622723884299934		[learning rate: 0.0012218]
	Learning Rate: 0.00122185
	LOSS [training: 0.043622723884299934 | validation: 0.11947051131778132]
	TIME [epoch: 19.6 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0436715786672383		[learning rate: 0.001214]
	Learning Rate: 0.00121398
	LOSS [training: 0.0436715786672383 | validation: 0.11590051622701485]
	TIME [epoch: 19.6 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04613520897726854		[learning rate: 0.0012062]
	Learning Rate: 0.00120616
	LOSS [training: 0.04613520897726854 | validation: 0.11095494711159108]
	TIME [epoch: 19.6 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05130485710850849		[learning rate: 0.0011984]
	Learning Rate: 0.00119839
	LOSS [training: 0.05130485710850849 | validation: 0.11161009207593528]
	TIME [epoch: 19.6 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04880474871063209		[learning rate: 0.0011907]
	Learning Rate: 0.00119066
	LOSS [training: 0.04880474871063209 | validation: 0.11524263937556765]
	TIME [epoch: 19.6 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471575841731254		[learning rate: 0.001183]
	Learning Rate: 0.00118299
	LOSS [training: 0.0471575841731254 | validation: 0.11461601909391012]
	TIME [epoch: 19.6 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049328879966608785		[learning rate: 0.0011754]
	Learning Rate: 0.00117537
	LOSS [training: 0.049328879966608785 | validation: 0.11201800407525522]
	TIME [epoch: 19.6 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043604429871957895		[learning rate: 0.0011678]
	Learning Rate: 0.0011678
	LOSS [training: 0.043604429871957895 | validation: 0.10573448876477697]
	TIME [epoch: 19.6 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05135254803369869		[learning rate: 0.0011603]
	Learning Rate: 0.00116028
	LOSS [training: 0.05135254803369869 | validation: 0.11536831460513]
	TIME [epoch: 19.6 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755443368914834		[learning rate: 0.0011528]
	Learning Rate: 0.0011528
	LOSS [training: 0.04755443368914834 | validation: 0.11312620920658148]
	TIME [epoch: 19.6 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04496103255928245		[learning rate: 0.0011454]
	Learning Rate: 0.00114537
	LOSS [training: 0.04496103255928245 | validation: 0.10937907320008344]
	TIME [epoch: 19.6 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045779337026037634		[learning rate: 0.001138]
	Learning Rate: 0.00113799
	LOSS [training: 0.045779337026037634 | validation: 0.10982866928616568]
	TIME [epoch: 19.6 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044263329265053365		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.044263329265053365 | validation: 0.11219928419152558]
	TIME [epoch: 19.6 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738303853563006		[learning rate: 0.0011234]
	Learning Rate: 0.00112338
	LOSS [training: 0.04738303853563006 | validation: 0.11967045385364009]
	TIME [epoch: 19.6 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279238700259225		[learning rate: 0.0011161]
	Learning Rate: 0.00111614
	LOSS [training: 0.04279238700259225 | validation: 0.11346544036125152]
	TIME [epoch: 19.6 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04707467148692381		[learning rate: 0.001109]
	Learning Rate: 0.00110895
	LOSS [training: 0.04707467148692381 | validation: 0.11151037114424525]
	TIME [epoch: 19.6 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739042046833417		[learning rate: 0.0011018]
	Learning Rate: 0.00110181
	LOSS [training: 0.04739042046833417 | validation: 0.1163481471337369]
	TIME [epoch: 19.6 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389663707847363		[learning rate: 0.0010947]
	Learning Rate: 0.00109471
	LOSS [training: 0.04389663707847363 | validation: 0.11399935060703688]
	TIME [epoch: 19.6 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04217990254356853		[learning rate: 0.0010877]
	Learning Rate: 0.00108766
	LOSS [training: 0.04217990254356853 | validation: 0.12066145135266837]
	TIME [epoch: 19.6 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.050289521696063225		[learning rate: 0.0010806]
	Learning Rate: 0.00108065
	LOSS [training: 0.050289521696063225 | validation: 0.1153968300716578]
	TIME [epoch: 19.6 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445903783494479		[learning rate: 0.0010737]
	Learning Rate: 0.00107369
	LOSS [training: 0.04445903783494479 | validation: 0.11498714943137375]
	TIME [epoch: 19.6 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666653979870286		[learning rate: 0.0010668]
	Learning Rate: 0.00106677
	LOSS [training: 0.04666653979870286 | validation: 0.11295445291424691]
	TIME [epoch: 19.6 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.051199029577053495		[learning rate: 0.0010599]
	Learning Rate: 0.0010599
	LOSS [training: 0.051199029577053495 | validation: 0.11261768922327817]
	TIME [epoch: 19.6 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641278700002082		[learning rate: 0.0010531]
	Learning Rate: 0.00105307
	LOSS [training: 0.04641278700002082 | validation: 0.11254470469279892]
	TIME [epoch: 19.6 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04409687772978371		[learning rate: 0.0010463]
	Learning Rate: 0.00104628
	LOSS [training: 0.04409687772978371 | validation: 0.11256716479994644]
	TIME [epoch: 19.6 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048990285664932215		[learning rate: 0.0010395]
	Learning Rate: 0.00103954
	LOSS [training: 0.048990285664932215 | validation: 0.11863927975107424]
	TIME [epoch: 19.6 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.049278948761518504		[learning rate: 0.0010328]
	Learning Rate: 0.00103284
	LOSS [training: 0.049278948761518504 | validation: 0.11808154171497022]
	TIME [epoch: 19.6 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045810478240216376		[learning rate: 0.0010262]
	Learning Rate: 0.00102619
	LOSS [training: 0.045810478240216376 | validation: 0.12104120338598048]
	TIME [epoch: 19.6 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04251574824084043		[learning rate: 0.0010196]
	Learning Rate: 0.00101958
	LOSS [training: 0.04251574824084043 | validation: 0.11197864364301736]
	TIME [epoch: 19.6 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323433506899868		[learning rate: 0.001013]
	Learning Rate: 0.00101301
	LOSS [training: 0.04323433506899868 | validation: 0.11603224778272539]
	TIME [epoch: 19.6 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352511487448244		[learning rate: 0.0010065]
	Learning Rate: 0.00100648
	LOSS [training: 0.04352511487448244 | validation: 0.11637428928416771]
	TIME [epoch: 19.6 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639934286779578		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.04639934286779578 | validation: 0.11627227543516327]
	TIME [epoch: 19.6 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04399431084097302		[learning rate: 0.00099356]
	Learning Rate: 0.000993557
	LOSS [training: 0.04399431084097302 | validation: 0.10979246540786372]
	TIME [epoch: 19.6 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04198664474036955		[learning rate: 0.00098716]
	Learning Rate: 0.000987156
	LOSS [training: 0.04198664474036955 | validation: 0.11561388836494509]
	TIME [epoch: 19.6 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05119154901928713		[learning rate: 0.0009808]
	Learning Rate: 0.000980797
	LOSS [training: 0.05119154901928713 | validation: 0.11194363115734898]
	TIME [epoch: 19.6 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04311711995534803		[learning rate: 0.00097448]
	Learning Rate: 0.000974478
	LOSS [training: 0.04311711995534803 | validation: 0.1118783998889741]
	TIME [epoch: 19.6 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04447792287281242		[learning rate: 0.0009682]
	Learning Rate: 0.0009682
	LOSS [training: 0.04447792287281242 | validation: 0.11195351215924533]
	TIME [epoch: 19.6 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.050126541300916844		[learning rate: 0.00096196]
	Learning Rate: 0.000961962
	LOSS [training: 0.050126541300916844 | validation: 0.10855465482595453]
	TIME [epoch: 19.6 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0431120185364977		[learning rate: 0.00095576]
	Learning Rate: 0.000955764
	LOSS [training: 0.0431120185364977 | validation: 0.11254679507786802]
	TIME [epoch: 19.5 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656238700949571		[learning rate: 0.00094961]
	Learning Rate: 0.000949607
	LOSS [training: 0.04656238700949571 | validation: 0.11821332736136408]
	TIME [epoch: 19.5 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030367106050138		[learning rate: 0.00094349]
	Learning Rate: 0.000943489
	LOSS [training: 0.05030367106050138 | validation: 0.1132240863980604]
	TIME [epoch: 19.5 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486249570217227		[learning rate: 0.00093741]
	Learning Rate: 0.00093741
	LOSS [training: 0.04486249570217227 | validation: 0.11646064297401933]
	TIME [epoch: 19.5 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0440149424023471		[learning rate: 0.00093137]
	Learning Rate: 0.000931371
	LOSS [training: 0.0440149424023471 | validation: 0.11172355893593112]
	TIME [epoch: 19.5 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857208657488256		[learning rate: 0.00092537]
	Learning Rate: 0.000925371
	LOSS [training: 0.04857208657488256 | validation: 0.12011646834098713]
	TIME [epoch: 19.5 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04681443569805794		[learning rate: 0.00091941]
	Learning Rate: 0.000919409
	LOSS [training: 0.04681443569805794 | validation: 0.10939526568087243]
	TIME [epoch: 19.5 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0527570232373645		[learning rate: 0.00091349]
	Learning Rate: 0.000913486
	LOSS [training: 0.0527570232373645 | validation: 0.12333168121561862]
	TIME [epoch: 19.5 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0437064468726421		[learning rate: 0.0009076]
	Learning Rate: 0.0009076
	LOSS [training: 0.0437064468726421 | validation: 0.11645617823148284]
	TIME [epoch: 19.5 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04301589443506414		[learning rate: 0.00090175]
	Learning Rate: 0.000901753
	LOSS [training: 0.04301589443506414 | validation: 0.11519087029782929]
	TIME [epoch: 19.5 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045232416225911946		[learning rate: 0.00089594]
	Learning Rate: 0.000895943
	LOSS [training: 0.045232416225911946 | validation: 0.11661989514762594]
	TIME [epoch: 19.5 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047057382759983335		[learning rate: 0.00089017]
	Learning Rate: 0.000890171
	LOSS [training: 0.047057382759983335 | validation: 0.11988510409858845]
	TIME [epoch: 19.5 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042521725426096335		[learning rate: 0.00088444]
	Learning Rate: 0.000884436
	LOSS [training: 0.042521725426096335 | validation: 0.11572620277214457]
	TIME [epoch: 19.5 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588735568920975		[learning rate: 0.00087874]
	Learning Rate: 0.000878738
	LOSS [training: 0.04588735568920975 | validation: 0.1080672119101748]
	TIME [epoch: 19.5 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04753045016552888		[learning rate: 0.00087308]
	Learning Rate: 0.000873077
	LOSS [training: 0.04753045016552888 | validation: 0.11266851824856298]
	TIME [epoch: 19.5 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538284274736798		[learning rate: 0.00086745]
	Learning Rate: 0.000867452
	LOSS [training: 0.04538284274736798 | validation: 0.1105745435502169]
	TIME [epoch: 19.5 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05017761916802989		[learning rate: 0.00086186]
	Learning Rate: 0.000861864
	LOSS [training: 0.05017761916802989 | validation: 0.11680802665616304]
	TIME [epoch: 19.5 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04504426368713555		[learning rate: 0.00085631]
	Learning Rate: 0.000856311
	LOSS [training: 0.04504426368713555 | validation: 0.11729383662227366]
	TIME [epoch: 19.5 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642686046190726		[learning rate: 0.00085079]
	Learning Rate: 0.000850794
	LOSS [training: 0.04642686046190726 | validation: 0.11020216939094678]
	TIME [epoch: 19.5 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042091405656828444		[learning rate: 0.00084531]
	Learning Rate: 0.000845313
	LOSS [training: 0.042091405656828444 | validation: 0.11828590544473201]
	TIME [epoch: 19.5 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042950688656491647		[learning rate: 0.00083987]
	Learning Rate: 0.000839867
	LOSS [training: 0.042950688656491647 | validation: 0.1170848328462284]
	TIME [epoch: 19.5 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04645237252029123		[learning rate: 0.00083446]
	Learning Rate: 0.000834456
	LOSS [training: 0.04645237252029123 | validation: 0.11508329851303059]
	TIME [epoch: 19.5 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04716418397048217		[learning rate: 0.00082908]
	Learning Rate: 0.00082908
	LOSS [training: 0.04716418397048217 | validation: 0.1143025681003689]
	TIME [epoch: 19.5 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04389931765324668		[learning rate: 0.00082374]
	Learning Rate: 0.000823739
	LOSS [training: 0.04389931765324668 | validation: 0.12011352365682848]
	TIME [epoch: 19.5 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04442276152268251		[learning rate: 0.00081843]
	Learning Rate: 0.000818432
	LOSS [training: 0.04442276152268251 | validation: 0.1111551070397543]
	TIME [epoch: 19.5 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.048087996688369744		[learning rate: 0.00081316]
	Learning Rate: 0.000813159
	LOSS [training: 0.048087996688369744 | validation: 0.11465962802499181]
	TIME [epoch: 19.5 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0429259049517064		[learning rate: 0.00080792]
	Learning Rate: 0.00080792
	LOSS [training: 0.0429259049517064 | validation: 0.11565621197599082]
	TIME [epoch: 19.5 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044822052062300444		[learning rate: 0.00080272]
	Learning Rate: 0.000802715
	LOSS [training: 0.044822052062300444 | validation: 0.11384308072291101]
	TIME [epoch: 19.5 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043057960712608284		[learning rate: 0.00079754]
	Learning Rate: 0.000797544
	LOSS [training: 0.043057960712608284 | validation: 0.11475672663984039]
	TIME [epoch: 19.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04278539602930121		[learning rate: 0.00079241]
	Learning Rate: 0.000792405
	LOSS [training: 0.04278539602930121 | validation: 0.11739290965625074]
	TIME [epoch: 19.5 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04191973550120397		[learning rate: 0.0007873]
	Learning Rate: 0.0007873
	LOSS [training: 0.04191973550120397 | validation: 0.1153774489034266]
	TIME [epoch: 19.5 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04546196150114569		[learning rate: 0.00078223]
	Learning Rate: 0.000782228
	LOSS [training: 0.04546196150114569 | validation: 0.11545981248264163]
	TIME [epoch: 19.5 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046632968063510305		[learning rate: 0.00077719]
	Learning Rate: 0.000777188
	LOSS [training: 0.046632968063510305 | validation: 0.11955611563452151]
	TIME [epoch: 19.5 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608668328428826		[learning rate: 0.00077218]
	Learning Rate: 0.000772181
	LOSS [training: 0.04608668328428826 | validation: 0.11510962825432666]
	TIME [epoch: 19.5 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659932704360042		[learning rate: 0.00076721]
	Learning Rate: 0.000767206
	LOSS [training: 0.04659932704360042 | validation: 0.11923674487992769]
	TIME [epoch: 19.5 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046691435292549266		[learning rate: 0.00076226]
	Learning Rate: 0.000762264
	LOSS [training: 0.046691435292549266 | validation: 0.1125112731155988]
	TIME [epoch: 19.5 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04328246969638915		[learning rate: 0.00075735]
	Learning Rate: 0.000757353
	LOSS [training: 0.04328246969638915 | validation: 0.11707427165529258]
	TIME [epoch: 19.5 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493452752055935		[learning rate: 0.00075247]
	Learning Rate: 0.000752473
	LOSS [training: 0.04493452752055935 | validation: 0.12188365024554022]
	TIME [epoch: 19.5 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043943046253377825		[learning rate: 0.00074763]
	Learning Rate: 0.000747626
	LOSS [training: 0.043943046253377825 | validation: 0.11281877824726962]
	TIME [epoch: 19.5 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042996649053318084		[learning rate: 0.00074281]
	Learning Rate: 0.000742809
	LOSS [training: 0.042996649053318084 | validation: 0.11893746453071506]
	TIME [epoch: 19.5 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04143212865267101		[learning rate: 0.00073802]
	Learning Rate: 0.000738023
	LOSS [training: 0.04143212865267101 | validation: 0.11221372858872775]
	TIME [epoch: 19.5 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04831091190050385		[learning rate: 0.00073327]
	Learning Rate: 0.000733269
	LOSS [training: 0.04831091190050385 | validation: 0.11135185431545187]
	TIME [epoch: 19.5 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044355720571280566		[learning rate: 0.00072854]
	Learning Rate: 0.000728544
	LOSS [training: 0.044355720571280566 | validation: 0.12353561537188452]
	TIME [epoch: 19.5 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043795989454851386		[learning rate: 0.00072385]
	Learning Rate: 0.000723851
	LOSS [training: 0.043795989454851386 | validation: 0.11274232225940238]
	TIME [epoch: 19.5 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045008359917027195		[learning rate: 0.00071919]
	Learning Rate: 0.000719187
	LOSS [training: 0.045008359917027195 | validation: 0.11355075489540561]
	TIME [epoch: 19.5 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041761349045382645		[learning rate: 0.00071455]
	Learning Rate: 0.000714554
	LOSS [training: 0.041761349045382645 | validation: 0.11071727078802501]
	TIME [epoch: 19.5 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04451016982173486		[learning rate: 0.00070995]
	Learning Rate: 0.00070995
	LOSS [training: 0.04451016982173486 | validation: 0.11695310667956059]
	TIME [epoch: 19.5 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743257540867853		[learning rate: 0.00070538]
	Learning Rate: 0.000705377
	LOSS [training: 0.04743257540867853 | validation: 0.11429281997341366]
	TIME [epoch: 19.5 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044197645966195694		[learning rate: 0.00070083]
	Learning Rate: 0.000700832
	LOSS [training: 0.044197645966195694 | validation: 0.1119851300006814]
	TIME [epoch: 19.5 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043178320287179925		[learning rate: 0.00069632]
	Learning Rate: 0.000696317
	LOSS [training: 0.043178320287179925 | validation: 0.11235671098785517]
	TIME [epoch: 19.5 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04564340247139531		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.04564340247139531 | validation: 0.11377671800011009]
	TIME [epoch: 19.5 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229993701661736		[learning rate: 0.00068737]
	Learning Rate: 0.000687374
	LOSS [training: 0.04229993701661736 | validation: 0.12550599597908624]
	TIME [epoch: 19.5 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657044570301491		[learning rate: 0.00068295]
	Learning Rate: 0.000682945
	LOSS [training: 0.04657044570301491 | validation: 0.11471811186484392]
	TIME [epoch: 19.6 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04747843849671086		[learning rate: 0.00067855]
	Learning Rate: 0.000678545
	LOSS [training: 0.04747843849671086 | validation: 0.11633085769372664]
	TIME [epoch: 19.5 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04330032473493538		[learning rate: 0.00067417]
	Learning Rate: 0.000674174
	LOSS [training: 0.04330032473493538 | validation: 0.11289389637080097]
	TIME [epoch: 19.5 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04519063201422428		[learning rate: 0.00066983]
	Learning Rate: 0.00066983
	LOSS [training: 0.04519063201422428 | validation: 0.11337744443757732]
	TIME [epoch: 19.5 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0422369455117933		[learning rate: 0.00066552]
	Learning Rate: 0.000665515
	LOSS [training: 0.0422369455117933 | validation: 0.11842853745896127]
	TIME [epoch: 19.5 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044789771127695936		[learning rate: 0.00066123]
	Learning Rate: 0.000661227
	LOSS [training: 0.044789771127695936 | validation: 0.11012188741608564]
	TIME [epoch: 19.5 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582160507564699		[learning rate: 0.00065697]
	Learning Rate: 0.000656967
	LOSS [training: 0.04582160507564699 | validation: 0.11658152040690106]
	TIME [epoch: 19.5 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04715924250968356		[learning rate: 0.00065273]
	Learning Rate: 0.000652735
	LOSS [training: 0.04715924250968356 | validation: 0.11742864140857177]
	TIME [epoch: 19.5 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434845261958832		[learning rate: 0.00064853]
	Learning Rate: 0.00064853
	LOSS [training: 0.04434845261958832 | validation: 0.11469153828051104]
	TIME [epoch: 19.5 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446189193559667		[learning rate: 0.00064435]
	Learning Rate: 0.000644351
	LOSS [training: 0.04446189193559667 | validation: 0.1154265983083894]
	TIME [epoch: 19.5 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540418406404934		[learning rate: 0.0006402]
	Learning Rate: 0.0006402
	LOSS [training: 0.04540418406404934 | validation: 0.11444016844676344]
	TIME [epoch: 19.6 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04203041486120002		[learning rate: 0.00063608]
	Learning Rate: 0.000636076
	LOSS [training: 0.04203041486120002 | validation: 0.11635186742242187]
	TIME [epoch: 19.6 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04301838125047974		[learning rate: 0.00063198]
	Learning Rate: 0.000631978
	LOSS [training: 0.04301838125047974 | validation: 0.11955593163340032]
	TIME [epoch: 19.5 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04018819666142134		[learning rate: 0.00062791]
	Learning Rate: 0.000627906
	LOSS [training: 0.04018819666142134 | validation: 0.11430131701867827]
	TIME [epoch: 19.5 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472142101276555		[learning rate: 0.00062386]
	Learning Rate: 0.000623861
	LOSS [training: 0.04472142101276555 | validation: 0.11892467638907343]
	TIME [epoch: 19.5 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042981102941995405		[learning rate: 0.00061984]
	Learning Rate: 0.000619842
	LOSS [training: 0.042981102941995405 | validation: 0.11278572898021594]
	TIME [epoch: 19.6 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042404991231584276		[learning rate: 0.00061585]
	Learning Rate: 0.000615848
	LOSS [training: 0.042404991231584276 | validation: 0.11109278196398395]
	TIME [epoch: 19.6 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177088653172658		[learning rate: 0.00061188]
	Learning Rate: 0.000611881
	LOSS [training: 0.04177088653172658 | validation: 0.1203278752729251]
	TIME [epoch: 19.6 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427661919150856		[learning rate: 0.00060794]
	Learning Rate: 0.000607938
	LOSS [training: 0.0427661919150856 | validation: 0.11176222292426478]
	TIME [epoch: 19.5 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042255204441838626		[learning rate: 0.00060402]
	Learning Rate: 0.000604022
	LOSS [training: 0.042255204441838626 | validation: 0.1142660082368571]
	TIME [epoch: 19.5 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046278372154736194		[learning rate: 0.00060013]
	Learning Rate: 0.00060013
	LOSS [training: 0.046278372154736194 | validation: 0.11459877510292361]
	TIME [epoch: 19.6 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04628174179831798		[learning rate: 0.00059626]
	Learning Rate: 0.000596264
	LOSS [training: 0.04628174179831798 | validation: 0.10973895205828557]
	TIME [epoch: 19.5 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043242184914501		[learning rate: 0.00059242]
	Learning Rate: 0.000592422
	LOSS [training: 0.043242184914501 | validation: 0.11586787664631955]
	TIME [epoch: 19.6 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472175981773846		[learning rate: 0.00058861]
	Learning Rate: 0.000588606
	LOSS [training: 0.04472175981773846 | validation: 0.11542403676321604]
	TIME [epoch: 19.6 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04835822009796727		[learning rate: 0.00058481]
	Learning Rate: 0.000584814
	LOSS [training: 0.04835822009796727 | validation: 0.11305953057236666]
	TIME [epoch: 19.5 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.046783039759689386		[learning rate: 0.00058105]
	Learning Rate: 0.000581046
	LOSS [training: 0.046783039759689386 | validation: 0.10986329003295464]
	TIME [epoch: 19.5 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318720985107588		[learning rate: 0.0005773]
	Learning Rate: 0.000577302
	LOSS [training: 0.04318720985107588 | validation: 0.11768906193906287]
	TIME [epoch: 19.5 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863791859111674		[learning rate: 0.00057358]
	Learning Rate: 0.000573583
	LOSS [training: 0.04863791859111674 | validation: 0.1159424833102134]
	TIME [epoch: 19.5 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04214744374849061		[learning rate: 0.00056989]
	Learning Rate: 0.000569888
	LOSS [training: 0.04214744374849061 | validation: 0.11199293375794905]
	TIME [epoch: 19.6 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04124985607283038		[learning rate: 0.00056622]
	Learning Rate: 0.000566216
	LOSS [training: 0.04124985607283038 | validation: 0.11507123478475394]
	TIME [epoch: 19.6 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041654005854568514		[learning rate: 0.00056257]
	Learning Rate: 0.000562568
	LOSS [training: 0.041654005854568514 | validation: 0.11660386714054462]
	TIME [epoch: 19.6 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04250496033536562		[learning rate: 0.00055894]
	Learning Rate: 0.000558944
	LOSS [training: 0.04250496033536562 | validation: 0.11382131148736474]
	TIME [epoch: 19.6 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04764328583953856		[learning rate: 0.00055534]
	Learning Rate: 0.000555343
	LOSS [training: 0.04764328583953856 | validation: 0.11692538272624763]
	TIME [epoch: 19.6 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041437348975764385		[learning rate: 0.00055177]
	Learning Rate: 0.000551765
	LOSS [training: 0.041437348975764385 | validation: 0.11550849333599861]
	TIME [epoch: 19.6 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045403268887791885		[learning rate: 0.00054821]
	Learning Rate: 0.00054821
	LOSS [training: 0.045403268887791885 | validation: 0.11686621271230109]
	TIME [epoch: 19.5 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463473093969605		[learning rate: 0.00054468]
	Learning Rate: 0.000544679
	LOSS [training: 0.0463473093969605 | validation: 0.12354046453626033]
	TIME [epoch: 19.5 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042666891420239605		[learning rate: 0.00054117]
	Learning Rate: 0.000541169
	LOSS [training: 0.042666891420239605 | validation: 0.11216926929477647]
	TIME [epoch: 19.5 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04464220079649527		[learning rate: 0.00053768]
	Learning Rate: 0.000537683
	LOSS [training: 0.04464220079649527 | validation: 0.11318333313082345]
	TIME [epoch: 19.5 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644346236698024		[learning rate: 0.00053422]
	Learning Rate: 0.000534219
	LOSS [training: 0.04644346236698024 | validation: 0.11148267915017127]
	TIME [epoch: 19.5 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04299024848509616		[learning rate: 0.00053078]
	Learning Rate: 0.000530777
	LOSS [training: 0.04299024848509616 | validation: 0.11549509615382136]
	TIME [epoch: 19.6 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04526817817866513		[learning rate: 0.00052736]
	Learning Rate: 0.000527358
	LOSS [training: 0.04526817817866513 | validation: 0.11475645040976772]
	TIME [epoch: 19.6 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.045832826379333724		[learning rate: 0.00052396]
	Learning Rate: 0.00052396
	LOSS [training: 0.045832826379333724 | validation: 0.11479870665483653]
	TIME [epoch: 19.5 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04060150410142896		[learning rate: 0.00052058]
	Learning Rate: 0.000520584
	LOSS [training: 0.04060150410142896 | validation: 0.11232988425509235]
	TIME [epoch: 19.5 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04825780057818		[learning rate: 0.00051723]
	Learning Rate: 0.000517231
	LOSS [training: 0.04825780057818 | validation: 0.11486049134963504]
	TIME [epoch: 19.6 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04091478127556213		[learning rate: 0.0005139]
	Learning Rate: 0.000513898
	LOSS [training: 0.04091478127556213 | validation: 0.11310252644382156]
	TIME [epoch: 19.6 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417029077827778		[learning rate: 0.00051059]
	Learning Rate: 0.000510587
	LOSS [training: 0.04417029077827778 | validation: 0.11767632791560023]
	TIME [epoch: 19.5 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041246183426340746		[learning rate: 0.0005073]
	Learning Rate: 0.000507298
	LOSS [training: 0.041246183426340746 | validation: 0.113204273000364]
	TIME [epoch: 19.5 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05222596612084705		[learning rate: 0.00050403]
	Learning Rate: 0.00050403
	LOSS [training: 0.05222596612084705 | validation: 0.11323909243738697]
	TIME [epoch: 19.5 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04153183230481779		[learning rate: 0.00050078]
	Learning Rate: 0.000500782
	LOSS [training: 0.04153183230481779 | validation: 0.11223702121533244]
	TIME [epoch: 82.6 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04146962725505803		[learning rate: 0.00049756]
	Learning Rate: 0.000497556
	LOSS [training: 0.04146962725505803 | validation: 0.11017505608823225]
	TIME [epoch: 41 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04430593588420839		[learning rate: 0.00049435]
	Learning Rate: 0.000494351
	LOSS [training: 0.04430593588420839 | validation: 0.11942670490922004]
	TIME [epoch: 41 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043400504819440966		[learning rate: 0.00049117]
	Learning Rate: 0.000491166
	LOSS [training: 0.043400504819440966 | validation: 0.1224018028564462]
	TIME [epoch: 41 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042951072004797176		[learning rate: 0.000488]
	Learning Rate: 0.000488001
	LOSS [training: 0.042951072004797176 | validation: 0.1134296647045211]
	TIME [epoch: 41 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04154164585909077		[learning rate: 0.00048486]
	Learning Rate: 0.000484857
	LOSS [training: 0.04154164585909077 | validation: 0.11710727500097569]
	TIME [epoch: 41 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04033118088738942		[learning rate: 0.00048173]
	Learning Rate: 0.000481734
	LOSS [training: 0.04033118088738942 | validation: 0.1147672711351186]
	TIME [epoch: 41 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041469523592128944		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.041469523592128944 | validation: 0.11476577801859268]
	TIME [epoch: 41.1 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083887192617614		[learning rate: 0.00047555]
	Learning Rate: 0.000475546
	LOSS [training: 0.04083887192617614 | validation: 0.11573077291040623]
	TIME [epoch: 41 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159852984030409		[learning rate: 0.00047248]
	Learning Rate: 0.000472483
	LOSS [training: 0.04159852984030409 | validation: 0.10996376806829126]
	TIME [epoch: 41 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04108827920194211		[learning rate: 0.00046944]
	Learning Rate: 0.000469439
	LOSS [training: 0.04108827920194211 | validation: 0.11170660633495029]
	TIME [epoch: 41 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043052561116168224		[learning rate: 0.00046641]
	Learning Rate: 0.000466414
	LOSS [training: 0.043052561116168224 | validation: 0.11278903180685404]
	TIME [epoch: 41 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04650366499897589		[learning rate: 0.00046341]
	Learning Rate: 0.000463409
	LOSS [training: 0.04650366499897589 | validation: 0.11152245068523683]
	TIME [epoch: 41 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433677941172179		[learning rate: 0.00046042]
	Learning Rate: 0.000460424
	LOSS [training: 0.0433677941172179 | validation: 0.11179386958097011]
	TIME [epoch: 41 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044233381169972504		[learning rate: 0.00045746]
	Learning Rate: 0.000457458
	LOSS [training: 0.044233381169972504 | validation: 0.11134845989623356]
	TIME [epoch: 41 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042088221126473216		[learning rate: 0.00045451]
	Learning Rate: 0.00045451
	LOSS [training: 0.042088221126473216 | validation: 0.1142515827355394]
	TIME [epoch: 41 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.041305285922464144		[learning rate: 0.00045158]
	Learning Rate: 0.000451582
	LOSS [training: 0.041305285922464144 | validation: 0.11164374316373724]
	TIME [epoch: 41 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694343439362357		[learning rate: 0.00044867]
	Learning Rate: 0.000448673
	LOSS [training: 0.04694343439362357 | validation: 0.11311835896168891]
	TIME [epoch: 41 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.047706658348945365		[learning rate: 0.00044578]
	Learning Rate: 0.000445782
	LOSS [training: 0.047706658348945365 | validation: 0.1153849703004425]
	TIME [epoch: 41 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042748587572758096		[learning rate: 0.00044291]
	Learning Rate: 0.00044291
	LOSS [training: 0.042748587572758096 | validation: 0.11484739995475213]
	TIME [epoch: 41 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.040626773715061425		[learning rate: 0.00044006]
	Learning Rate: 0.000440057
	LOSS [training: 0.040626773715061425 | validation: 0.11047894330286258]
	TIME [epoch: 41 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585405465055046		[learning rate: 0.00043722]
	Learning Rate: 0.000437222
	LOSS [training: 0.04585405465055046 | validation: 0.11142789959957908]
	TIME [epoch: 41 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset4_20241208_152839/states/model_facs_dec2_v1_argset4_522.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 7372.420 seconds.
