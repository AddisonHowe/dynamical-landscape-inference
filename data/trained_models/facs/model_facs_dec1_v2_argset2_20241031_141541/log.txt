Args:
Namespace(name='model_facs_dec1_v2_argset2', outdir='out/model_training/model_facs_dec1_v2_argset2', training_data='data/facs/facs_dec1_v2/training', validation_data='data/facs/facs_dec1_v2/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05, 0.1, 0.15, 0.5], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1355361292

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.6539738958294148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6539738958294148 | validation: 1.154973048999563]
	TIME [epoch: 33.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1581463713657048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1581463713657048 | validation: 0.9218026071528456]
	TIME [epoch: 8.51 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.020647360280797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.020647360280797 | validation: 0.9095182639484021]
	TIME [epoch: 8.49 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.8398183323152052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8398183323152052 | validation: 0.8481722358711791]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.7521917508268269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7521917508268269 | validation: 0.7011497921675159]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6183153601852475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6183153601852475 | validation: 0.6155216830186394]
	TIME [epoch: 8.48 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.5219501962176963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5219501962176963 | validation: 0.5370587814894138]
	TIME [epoch: 8.5 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.4579607399587529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4579607399587529 | validation: 0.4789181678276398]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.41838868785835376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41838868785835376 | validation: 0.432360586738053]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3694083095201572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3694083095201572 | validation: 0.3962996360132642]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.348982289035712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.348982289035712 | validation: 0.3740898897877627]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32932910596683207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32932910596683207 | validation: 0.3439707893478012]
	TIME [epoch: 8.46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32116145741975527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32116145741975527 | validation: 0.3349718494111157]
	TIME [epoch: 8.46 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31010284615430983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31010284615430983 | validation: 0.3552966442963889]
	TIME [epoch: 8.45 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.30818234666866257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.30818234666866257 | validation: 0.30626997757893826]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29343989888600536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29343989888600536 | validation: 0.3279832001716869]
	TIME [epoch: 8.45 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3138169243699244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3138169243699244 | validation: 0.28476698102409265]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2800618574013651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2800618574013651 | validation: 0.26412085641972055]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27612411171510015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27612411171510015 | validation: 0.2565444770056201]
	TIME [epoch: 8.43 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.32202896959390986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32202896959390986 | validation: 0.2522921553131]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26483729232522113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26483729232522113 | validation: 0.24483767056377131]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25857131339255895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25857131339255895 | validation: 0.24631264368651107]
	TIME [epoch: 8.44 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25217712044383583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25217712044383583 | validation: 0.21926251534398458]
	TIME [epoch: 8.41 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24379109393457835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24379109393457835 | validation: 0.21603848528865682]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2727453865138503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2727453865138503 | validation: 0.21110349044389415]
	TIME [epoch: 8.49 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24553324962693077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24553324962693077 | validation: 0.22307774649239284]
	TIME [epoch: 8.44 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23417626991817628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23417626991817628 | validation: 0.2567353981137666]
	TIME [epoch: 8.44 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2597741134794221		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2597741134794221 | validation: 0.22254575170538438]
	TIME [epoch: 8.45 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22978895911715394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22978895911715394 | validation: 0.22899802734823424]
	TIME [epoch: 8.46 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23320783859170954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23320783859170954 | validation: 0.18832729914386975]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24340729243396728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24340729243396728 | validation: 0.18921767284777716]
	TIME [epoch: 8.47 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24396256319486298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24396256319486298 | validation: 0.19508870038325296]
	TIME [epoch: 8.47 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23979564425726876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23979564425726876 | validation: 0.21587784289193995]
	TIME [epoch: 8.45 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2318691340101955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2318691340101955 | validation: 0.1975706628813036]
	TIME [epoch: 8.47 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23389607341896634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23389607341896634 | validation: 0.21589828309260167]
	TIME [epoch: 8.47 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2333566442105778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2333566442105778 | validation: 0.1840827736669607]
	TIME [epoch: 8.47 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26617466851261257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26617466851261257 | validation: 0.1977647852927239]
	TIME [epoch: 8.4 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23069101498052813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23069101498052813 | validation: 0.18464185853779036]
	TIME [epoch: 8.4 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.248688882332326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.248688882332326 | validation: 0.21320530565124246]
	TIME [epoch: 8.4 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22669468706626597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22669468706626597 | validation: 0.18088654144539668]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23580010705428237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23580010705428237 | validation: 0.1911629835305349]
	TIME [epoch: 8.45 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2231950945399065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2231950945399065 | validation: 0.18198106078217965]
	TIME [epoch: 8.44 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21637624835584168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.21637624835584168 | validation: 0.20561670013095582]
	TIME [epoch: 8.45 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22767042659359982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22767042659359982 | validation: 0.2334970703902223]
	TIME [epoch: 8.44 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26119212810440695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26119212810440695 | validation: 0.18276525422344284]
	TIME [epoch: 8.44 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22137368076845254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22137368076845254 | validation: 0.19805336754166836]
	TIME [epoch: 8.43 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23276221704969427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23276221704969427 | validation: 0.181273861835948]
	TIME [epoch: 8.44 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22026469119851785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22026469119851785 | validation: 0.18424346076284942]
	TIME [epoch: 8.45 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22601570561564122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.22601570561564122 | validation: 0.17991124212603582]
	TIME [epoch: 8.44 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23265659333652847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23265659333652847 | validation: 0.17898695384592872]
	TIME [epoch: 8.45 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2304647020268726		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.2304647020268726 | validation: 0.21799999177281632]
	TIME [epoch: 38.9 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2263884873893802		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.2263884873893802 | validation: 0.1955060700836253]
	TIME [epoch: 16.3 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22436771677046452		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.22436771677046452 | validation: 0.1772992362780348]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22326970679696237		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.22326970679696237 | validation: 0.17625985740779598]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.232936649147341		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.232936649147341 | validation: 0.18895518415608187]
	TIME [epoch: 16.3 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21692377263908647		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.21692377263908647 | validation: 0.18080632639439603]
	TIME [epoch: 16.3 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22796691369738556		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.22796691369738556 | validation: 0.2593192766597433]
	TIME [epoch: 16.3 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23059421835941118		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.23059421835941118 | validation: 0.1766892193635734]
	TIME [epoch: 16.3 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22112460889618799		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.22112460889618799 | validation: 0.17814306211536776]
	TIME [epoch: 16.3 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22028269034063505		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.22028269034063505 | validation: 0.17201826966967407]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_60.pth
	Model improved!!!
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21779581361930359		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.21779581361930359 | validation: 0.17639725054511168]
	TIME [epoch: 16.3 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.219662292721149		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.219662292721149 | validation: 0.17288943405438278]
	TIME [epoch: 16.3 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22064357815894434		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.22064357815894434 | validation: 0.18243638679121982]
	TIME [epoch: 16.3 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22065539740728013		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.22065539740728013 | validation: 0.1824386496043156]
	TIME [epoch: 16.3 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22085815382936813		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.22085815382936813 | validation: 0.17969956681647004]
	TIME [epoch: 16.3 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2197432002559113		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.2197432002559113 | validation: 0.17673625863367745]
	TIME [epoch: 16.3 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22235786840769342		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.22235786840769342 | validation: 0.17221428394035035]
	TIME [epoch: 16.3 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21399240348277673		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.21399240348277673 | validation: 0.19496739640097324]
	TIME [epoch: 16.3 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21715768025838686		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.21715768025838686 | validation: 0.1769871016042276]
	TIME [epoch: 16.3 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2252396534574174		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.2252396534574174 | validation: 0.1916892353474562]
	TIME [epoch: 16.3 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21434660153054452		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.21434660153054452 | validation: 0.18610578889682633]
	TIME [epoch: 16.3 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2202204108460597		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.2202204108460597 | validation: 0.19976546854252977]
	TIME [epoch: 16.3 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22060500819323647		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.22060500819323647 | validation: 0.17379047983315662]
	TIME [epoch: 16.3 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21458469269976435		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.21458469269976435 | validation: 0.18575246802251186]
	TIME [epoch: 16.3 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21598027087686825		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.21598027087686825 | validation: 0.19225520942883498]
	TIME [epoch: 16.3 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21865907115317162		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.21865907115317162 | validation: 0.16801710060657474]
	TIME [epoch: 16.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21053734340041305		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.21053734340041305 | validation: 0.20993662436004698]
	TIME [epoch: 16.3 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21951642702022992		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.21951642702022992 | validation: 0.17229606458074087]
	TIME [epoch: 16.3 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21120252631530737		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.21120252631530737 | validation: 0.1792889518240563]
	TIME [epoch: 16.3 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2159448270845428		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.2159448270845428 | validation: 0.17681499114317686]
	TIME [epoch: 16.3 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2215581801878959		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.2215581801878959 | validation: 0.16925450559158114]
	TIME [epoch: 16.3 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21802343052706688		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.21802343052706688 | validation: 0.17402998528629127]
	TIME [epoch: 16.3 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2147624761495397		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.2147624761495397 | validation: 0.21262525562729043]
	TIME [epoch: 16.3 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21669892307550206		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.21669892307550206 | validation: 0.20423143329340143]
	TIME [epoch: 16.3 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21154947847076744		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.21154947847076744 | validation: 0.17655978408784576]
	TIME [epoch: 16.3 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21704566396812064		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.21704566396812064 | validation: 0.1782171209264745]
	TIME [epoch: 16.3 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21224006268340959		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.21224006268340959 | validation: 0.18331334247843398]
	TIME [epoch: 16.3 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21428268792885538		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.21428268792885538 | validation: 0.16862783331244088]
	TIME [epoch: 16.3 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21498094391407305		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.21498094391407305 | validation: 0.17095670981950864]
	TIME [epoch: 16.3 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21267326952787566		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.21267326952787566 | validation: 0.18130352248924253]
	TIME [epoch: 16.3 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2155967093486493		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.2155967093486493 | validation: 0.18356944010147225]
	TIME [epoch: 16.3 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2051269985676453		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.2051269985676453 | validation: 0.16794818733820616]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20838175314752616		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.20838175314752616 | validation: 0.17742714662274042]
	TIME [epoch: 16.1 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21058363394019539		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.21058363394019539 | validation: 0.16806178382966444]
	TIME [epoch: 16.1 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20933736727850824		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.20933736727850824 | validation: 0.16667712430886086]
	TIME [epoch: 16.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21335515600712276		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.21335515600712276 | validation: 0.16917604850245652]
	TIME [epoch: 16.3 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2095121392569361		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.2095121392569361 | validation: 0.20381491788201417]
	TIME [epoch: 16.2 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21100677044017055		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.21100677044017055 | validation: 0.17096670057423313]
	TIME [epoch: 16.3 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20643010503434897		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.20643010503434897 | validation: 0.16701509401115036]
	TIME [epoch: 16.3 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20705040421554236		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.20705040421554236 | validation: 0.1673267086613488]
	TIME [epoch: 16.3 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22428394880669378		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.22428394880669378 | validation: 0.16734749091570764]
	TIME [epoch: 56.6 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2051923286016167		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.2051923286016167 | validation: 0.17043625779864618]
	TIME [epoch: 34.2 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21013988331279765		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.21013988331279765 | validation: 0.16714765027545275]
	TIME [epoch: 34.2 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20681344361315823		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.20681344361315823 | validation: 0.16546016883335915]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21016177172258196		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.21016177172258196 | validation: 0.20023192984866722]
	TIME [epoch: 34.2 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20980195747537636		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.20980195747537636 | validation: 0.16430457544623894]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20443868698301668		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.20443868698301668 | validation: 0.16552276929980375]
	TIME [epoch: 34.2 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20224787674067224		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.20224787674067224 | validation: 0.1643023615124176]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_108.pth
	Model improved!!!
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21185933537398952		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.21185933537398952 | validation: 0.18724352249877355]
	TIME [epoch: 34.2 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21032665750172777		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.21032665750172777 | validation: 0.18998402743404896]
	TIME [epoch: 34.2 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20578748556793836		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.20578748556793836 | validation: 0.22774372181164898]
	TIME [epoch: 34.2 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21040559387967447		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.21040559387967447 | validation: 0.16381958087696985]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2042427763422799		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.2042427763422799 | validation: 0.1621519042689849]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_113.pth
	Model improved!!!
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20568027717833262		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.20568027717833262 | validation: 0.16789904058426194]
	TIME [epoch: 34.2 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20797487467987805		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.20797487467987805 | validation: 0.1665317167642455]
	TIME [epoch: 34.2 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20688797143179286		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.20688797143179286 | validation: 0.16552974132733433]
	TIME [epoch: 34.2 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20249214657300443		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.20249214657300443 | validation: 0.1624405383731327]
	TIME [epoch: 34.2 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20848886261843025		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.20848886261843025 | validation: 0.16908547219165473]
	TIME [epoch: 34.2 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20971960936599557		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.20971960936599557 | validation: 0.16493536295439698]
	TIME [epoch: 34.2 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20890681083372356		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.20890681083372356 | validation: 0.1744716022053063]
	TIME [epoch: 34.2 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20582843000654286		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.20582843000654286 | validation: 0.1645746960516433]
	TIME [epoch: 34.2 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2009583781062921		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.2009583781062921 | validation: 0.16309943409108546]
	TIME [epoch: 34.2 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20193077134417892		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.20193077134417892 | validation: 0.16189168307205856]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20399071451248044		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.20399071451248044 | validation: 0.164419337812905]
	TIME [epoch: 34.2 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20145708647653324		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.20145708647653324 | validation: 0.17492058314464404]
	TIME [epoch: 34.2 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20463690183602293		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.20463690183602293 | validation: 0.16108260127639024]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_126.pth
	Model improved!!!
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20401473657162925		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.20401473657162925 | validation: 0.1619225104007447]
	TIME [epoch: 34.1 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2040129064680616		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.2040129064680616 | validation: 0.175355559525547]
	TIME [epoch: 34.1 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2030575062374034		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.2030575062374034 | validation: 0.16565313629476333]
	TIME [epoch: 34.1 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20098291682699923		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.20098291682699923 | validation: 0.16657842735035913]
	TIME [epoch: 34.1 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2022360527094789		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.2022360527094789 | validation: 0.18634103907655947]
	TIME [epoch: 34.1 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20520942986363103		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.20520942986363103 | validation: 0.15962841799425953]
	TIME [epoch: 34.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19993644061227578		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.19993644061227578 | validation: 0.17098299090718022]
	TIME [epoch: 34.1 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20125840773228398		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.20125840773228398 | validation: 0.17625232295882895]
	TIME [epoch: 34.1 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20096745648343092		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.20096745648343092 | validation: 0.18561603287900513]
	TIME [epoch: 34.1 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1987873235030896		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.1987873235030896 | validation: 0.16758432525691766]
	TIME [epoch: 34.1 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21181403827125253		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.21181403827125253 | validation: 0.1639996020796252]
	TIME [epoch: 34.1 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20306484245416853		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.20306484245416853 | validation: 0.1723042854672175]
	TIME [epoch: 34.1 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1995136455087095		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.1995136455087095 | validation: 0.1797357961783089]
	TIME [epoch: 34.1 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1990017741588166		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.1990017741588166 | validation: 0.16537091366607348]
	TIME [epoch: 34.1 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20643490882651597		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.20643490882651597 | validation: 0.15881012345546264]
	TIME [epoch: 34.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_141.pth
	Model improved!!!
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20233496940193288		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.20233496940193288 | validation: 0.16807683872458806]
	TIME [epoch: 34.1 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19724656805126428		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.19724656805126428 | validation: 0.20367701935382532]
	TIME [epoch: 34.1 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20209845268871382		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.20209845268871382 | validation: 0.16624939277044534]
	TIME [epoch: 34.1 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1983905838153283		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.1983905838153283 | validation: 0.18311065954815636]
	TIME [epoch: 34.1 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20136094134266677		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.20136094134266677 | validation: 0.15836903637799812]
	TIME [epoch: 34.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_146.pth
	Model improved!!!
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19753982699347916		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.19753982699347916 | validation: 0.1646407606915657]
	TIME [epoch: 34.1 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19614113168439848		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.19614113168439848 | validation: 0.18262026218991356]
	TIME [epoch: 34.1 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1995784532984615		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.1995784532984615 | validation: 0.17025542880954214]
	TIME [epoch: 34.1 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19650772022546859		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.19650772022546859 | validation: 0.1546382042638008]
	TIME [epoch: 33.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_150.pth
	Model improved!!!
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1955698177194307		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.1955698177194307 | validation: 0.16750215846349176]
	TIME [epoch: 34.2 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1971359820569695		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.1971359820569695 | validation: 0.15974971747603903]
	TIME [epoch: 34.2 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19393042990452267		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.19393042990452267 | validation: 0.160886480690032]
	TIME [epoch: 34.1 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20776769264197856		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.20776769264197856 | validation: 0.162144703558825]
	TIME [epoch: 33.9 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19923048797297657		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.19923048797297657 | validation: 0.16321327104387645]
	TIME [epoch: 34.1 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19413676293074103		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.19413676293074103 | validation: 0.16646416344218032]
	TIME [epoch: 34.1 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20008408084268062		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.20008408084268062 | validation: 0.17568276993380041]
	TIME [epoch: 34.1 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19937962407323837		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.19937962407323837 | validation: 0.1720139414549334]
	TIME [epoch: 34.1 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19927331047895822		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.19927331047895822 | validation: 0.17159229133733384]
	TIME [epoch: 34.1 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19774833234355835		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.19774833234355835 | validation: 0.16305607981886203]
	TIME [epoch: 34.1 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19663096399630972		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.19663096399630972 | validation: 0.16341605061374778]
	TIME [epoch: 34.1 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19795128749668897		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.19795128749668897 | validation: 0.15820818603542042]
	TIME [epoch: 34.1 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19594662129526308		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.19594662129526308 | validation: 0.18606908337370182]
	TIME [epoch: 34.1 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19269333238244346		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.19269333238244346 | validation: 0.15632246266444888]
	TIME [epoch: 34.1 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1920686324198564		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.1920686324198564 | validation: 0.15270469271660242]
	TIME [epoch: 34.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_165.pth
	Model improved!!!
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1934506995452739		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.1934506995452739 | validation: 0.15177940051039762]
	TIME [epoch: 34.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1913851935683473		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.1913851935683473 | validation: 0.17493070768505853]
	TIME [epoch: 34.1 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19595649922460776		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.19595649922460776 | validation: 0.15351830869820243]
	TIME [epoch: 34.1 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19269939260964927		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.19269939260964927 | validation: 0.15793200787498507]
	TIME [epoch: 34.2 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1924172548385867		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.1924172548385867 | validation: 0.15353910548797273]
	TIME [epoch: 34.1 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18932599606774994		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.18932599606774994 | validation: 0.15384733829990438]
	TIME [epoch: 34.2 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19889359201997145		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.19889359201997145 | validation: 0.1643651888879217]
	TIME [epoch: 34.1 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19115969498500215		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.19115969498500215 | validation: 0.15843527951435438]
	TIME [epoch: 34.1 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1960084587139519		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.1960084587139519 | validation: 0.1495380501601247]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_174.pth
	Model improved!!!
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1888223265004324		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.1888223265004324 | validation: 0.1528371009955866]
	TIME [epoch: 34.2 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1877415178910371		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.1877415178910371 | validation: 0.17043049726415513]
	TIME [epoch: 34.2 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19370717870335355		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.19370717870335355 | validation: 0.1683519764708475]
	TIME [epoch: 34.2 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19117654498773717		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.19117654498773717 | validation: 0.1480026796745817]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_178.pth
	Model improved!!!
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18748249107560477		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.18748249107560477 | validation: 0.1499977968066858]
	TIME [epoch: 34 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1919133245378649		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.1919133245378649 | validation: 0.15992410514078292]
	TIME [epoch: 34.2 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19052307659661918		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.19052307659661918 | validation: 0.16042849889810867]
	TIME [epoch: 34.2 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19244153565231067		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.19244153565231067 | validation: 0.1492756014100085]
	TIME [epoch: 34.2 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19287757398452143		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.19287757398452143 | validation: 0.1477715179156554]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_183.pth
	Model improved!!!
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1847804941245665		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.1847804941245665 | validation: 0.14785620794173635]
	TIME [epoch: 34.2 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18578834395601593		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.18578834395601593 | validation: 0.1454194157898552]
	TIME [epoch: 34.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_185.pth
	Model improved!!!
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18468371681404386		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.18468371681404386 | validation: 0.1611492432285454]
	TIME [epoch: 34.3 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19503745607903375		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.19503745607903375 | validation: 0.14462626155843483]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_187.pth
	Model improved!!!
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18436683958091593		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.18436683958091593 | validation: 0.14573671152386533]
	TIME [epoch: 34 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.184360395281593		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.184360395281593 | validation: 0.1532229515770592]
	TIME [epoch: 34.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1825416602389729		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.1825416602389729 | validation: 0.14475464736725918]
	TIME [epoch: 34.2 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18259377901829407		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.18259377901829407 | validation: 0.15383435894610167]
	TIME [epoch: 34.3 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18540394078569214		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.18540394078569214 | validation: 0.15086027762130372]
	TIME [epoch: 34.3 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1832215100898951		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.1832215100898951 | validation: 0.14582349372412842]
	TIME [epoch: 34.2 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18748543945413434		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.18748543945413434 | validation: 0.1597746095055409]
	TIME [epoch: 34.2 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18457507342635507		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.18457507342635507 | validation: 0.155427372239628]
	TIME [epoch: 34.3 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18502378391746135		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.18502378391746135 | validation: 0.1529877890539259]
	TIME [epoch: 34.3 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18173303916863923		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.18173303916863923 | validation: 0.15816806474227438]
	TIME [epoch: 34.2 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18534253144502733		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.18534253144502733 | validation: 0.14197234158881095]
	TIME [epoch: 34.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_198.pth
	Model improved!!!
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17951907437588652		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.17951907437588652 | validation: 0.14070365526461254]
	TIME [epoch: 34 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18262705305140925		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.18262705305140925 | validation: 0.14573445365645532]
	TIME [epoch: 34.2 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18068633562102268		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.18068633562102268 | validation: 0.14076752563926395]
	TIME [epoch: 95.1 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18121670265994994		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.18121670265994994 | validation: 0.14225882211297636]
	TIME [epoch: 71.2 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1823986429289757		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.1823986429289757 | validation: 0.14719897900785311]
	TIME [epoch: 71.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18611060104635702		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.18611060104635702 | validation: 0.15711602887451148]
	TIME [epoch: 71.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17858222604609938		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.17858222604609938 | validation: 0.14165716509315893]
	TIME [epoch: 71.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17660297466254113		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.17660297466254113 | validation: 0.14792603462402465]
	TIME [epoch: 71.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17968716550309558		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.17968716550309558 | validation: 0.14742898815174907]
	TIME [epoch: 71.2 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17735362769977214		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.17735362769977214 | validation: 0.14890627948157065]
	TIME [epoch: 71.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.177267254175998		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.177267254175998 | validation: 0.1565570163346026]
	TIME [epoch: 71.3 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1852013446637001		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.1852013446637001 | validation: 0.13544455524599092]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_210.pth
	Model improved!!!
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18071773945162886		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.18071773945162886 | validation: 0.1489371164076777]
	TIME [epoch: 71.3 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17844207693165984		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.17844207693165984 | validation: 0.13565527968312688]
	TIME [epoch: 71.3 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17693477426219437		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.17693477426219437 | validation: 0.1488227887221127]
	TIME [epoch: 71.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17802043064001113		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.17802043064001113 | validation: 0.14506010468594022]
	TIME [epoch: 71.3 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1792964355169754		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.1792964355169754 | validation: 0.13630280914736426]
	TIME [epoch: 71.3 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1758132200263591		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.1758132200263591 | validation: 0.14448689337502396]
	TIME [epoch: 71.3 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17354101797879792		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.17354101797879792 | validation: 0.1393520096113875]
	TIME [epoch: 71.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1801564454084762		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.1801564454084762 | validation: 0.1341112778360272]
	TIME [epoch: 71.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_218.pth
	Model improved!!!
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17439204083247173		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.17439204083247173 | validation: 0.15127378800429075]
	TIME [epoch: 71.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1769370931348835		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.1769370931348835 | validation: 0.14055241741165714]
	TIME [epoch: 71.3 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17462608281841285		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.17462608281841285 | validation: 0.14759202046610836]
	TIME [epoch: 71.3 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17901522591067717		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.17901522591067717 | validation: 0.13635331728116878]
	TIME [epoch: 71.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17564612130045507		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.17564612130045507 | validation: 0.14757493588123666]
	TIME [epoch: 71.3 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17239545495758923		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.17239545495758923 | validation: 0.13331108955088228]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17521496765241648		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.17521496765241648 | validation: 0.13700700365262075]
	TIME [epoch: 71.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17176567047656752		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.17176567047656752 | validation: 0.13553131742646654]
	TIME [epoch: 71.3 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17539850096051848		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.17539850096051848 | validation: 0.132844813049948]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_227.pth
	Model improved!!!
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1705838276795313		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.1705838276795313 | validation: 0.14691749413793345]
	TIME [epoch: 71.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17163668302402088		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.17163668302402088 | validation: 0.13926119073124427]
	TIME [epoch: 71.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17303824181006125		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.17303824181006125 | validation: 0.13092612665097386]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_230.pth
	Model improved!!!
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17172066314145606		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.17172066314145606 | validation: 0.13681534429067713]
	TIME [epoch: 71.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1681810842829292		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.1681810842829292 | validation: 0.13287030818153295]
	TIME [epoch: 71.2 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17227524562143856		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.17227524562143856 | validation: 0.13768871640947306]
	TIME [epoch: 71.2 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1737377551489709		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.1737377551489709 | validation: 0.1414325848767511]
	TIME [epoch: 71.3 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.17146925118596337		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.17146925118596337 | validation: 0.13319389738686027]
	TIME [epoch: 71.2 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1757993766592841		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.1757993766592841 | validation: 0.14292229416416216]
	TIME [epoch: 71.2 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1663528381480267		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.1663528381480267 | validation: 0.13140150641803436]
	TIME [epoch: 71.2 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1701326859765299		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.1701326859765299 | validation: 0.13715920276798335]
	TIME [epoch: 71.3 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16971966831217003		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.16971966831217003 | validation: 0.1380895740012657]
	TIME [epoch: 71.2 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16611531730108928		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.16611531730108928 | validation: 0.13345294771637886]
	TIME [epoch: 71.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16763582064142266		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.16763582064142266 | validation: 0.14518397270175853]
	TIME [epoch: 71.3 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1643205620013721		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.1643205620013721 | validation: 0.13054416800144997]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_242.pth
	Model improved!!!
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1727646065415567		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.1727646065415567 | validation: 0.12940003744545175]
	TIME [epoch: 71.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_243.pth
	Model improved!!!
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16611705817831499		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.16611705817831499 | validation: 0.12968385312573258]
	TIME [epoch: 71.2 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16377128808716523		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.16377128808716523 | validation: 0.1302858676409549]
	TIME [epoch: 71.2 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16453912021646147		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.16453912021646147 | validation: 0.13907109074821478]
	TIME [epoch: 71.2 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16536636488223375		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.16536636488223375 | validation: 0.13726108636191714]
	TIME [epoch: 71.2 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16556762161067165		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.16556762161067165 | validation: 0.13115897921497982]
	TIME [epoch: 71.2 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16288242295230287		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.16288242295230287 | validation: 0.1352100022166543]
	TIME [epoch: 71.3 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16306346312540645		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.16306346312540645 | validation: 0.13892180043083258]
	TIME [epoch: 71.7 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16774365760132762		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.16774365760132762 | validation: 0.129297418853434]
	TIME [epoch: 71.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_251.pth
	Model improved!!!
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1652430811816726		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.1652430811816726 | validation: 0.13132232462478866]
	TIME [epoch: 71.4 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1591779265612117		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.1591779265612117 | validation: 0.12969623138154673]
	TIME [epoch: 71.3 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16440240350998434		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.16440240350998434 | validation: 0.13043155513395138]
	TIME [epoch: 71.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16237509523066782		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.16237509523066782 | validation: 0.1314221596185871]
	TIME [epoch: 71.3 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16525798064043234		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.16525798064043234 | validation: 0.14827304747131223]
	TIME [epoch: 71.3 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16685415492178676		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.16685415492178676 | validation: 0.12841747925983057]
	TIME [epoch: 71.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_257.pth
	Model improved!!!
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1618273954503686		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.1618273954503686 | validation: 0.13532186193197115]
	TIME [epoch: 71.3 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1629131000090922		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.1629131000090922 | validation: 0.13494594062882243]
	TIME [epoch: 71.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16289625515579498		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.16289625515579498 | validation: 0.13519364262590733]
	TIME [epoch: 71.3 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15977000400504268		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.15977000400504268 | validation: 0.13268346288420818]
	TIME [epoch: 71.3 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16365290205567987		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.16365290205567987 | validation: 0.12667805993080206]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15935036498661456		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.15935036498661456 | validation: 0.12883775856055796]
	TIME [epoch: 71.3 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16068241472531847		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.16068241472531847 | validation: 0.12608700134557468]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_264.pth
	Model improved!!!
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16015985565992893		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.16015985565992893 | validation: 0.12600169476300271]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_265.pth
	Model improved!!!
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15971633469105442		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.15971633469105442 | validation: 0.1401458147718584]
	TIME [epoch: 71.2 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16463542379727436		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.16463542379727436 | validation: 0.12995739631293945]
	TIME [epoch: 71.3 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1571600792976792		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.1571600792976792 | validation: 0.1263529851073218]
	TIME [epoch: 71.3 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15852581608811275		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.15852581608811275 | validation: 0.1240760262046781]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_269.pth
	Model improved!!!
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15966511469265057		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.15966511469265057 | validation: 0.12714397005393327]
	TIME [epoch: 71.2 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16146182358511374		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.16146182358511374 | validation: 0.13695723543288646]
	TIME [epoch: 71.2 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16190484442307507		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.16190484442307507 | validation: 0.13428867397880978]
	TIME [epoch: 71.3 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16131495913486923		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.16131495913486923 | validation: 0.13245858499266217]
	TIME [epoch: 71.3 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1624929770574695		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.1624929770574695 | validation: 0.12476143709380863]
	TIME [epoch: 71.3 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15864379768012457		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.15864379768012457 | validation: 0.12760129833078399]
	TIME [epoch: 71.3 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15786509383725414		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.15786509383725414 | validation: 0.12458961343689501]
	TIME [epoch: 71.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15938865970026375		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.15938865970026375 | validation: 0.12950676720180407]
	TIME [epoch: 71.3 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1585626318159863		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.1585626318159863 | validation: 0.12853526223924597]
	TIME [epoch: 71.3 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1597165704306705		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.1597165704306705 | validation: 0.12306837655077318]
	TIME [epoch: 71.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1580773128087434		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.1580773128087434 | validation: 0.12775474696630815]
	TIME [epoch: 71.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15642337385538657		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.15642337385538657 | validation: 0.12708013284173608]
	TIME [epoch: 71.4 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15673935280579468		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.15673935280579468 | validation: 0.1281590536593411]
	TIME [epoch: 71.2 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15700812256666782		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.15700812256666782 | validation: 0.12400519112210318]
	TIME [epoch: 71.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1550063145244811		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.1550063145244811 | validation: 0.12419447311130342]
	TIME [epoch: 71.4 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15457686304763818		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.15457686304763818 | validation: 0.12906913678309356]
	TIME [epoch: 71.3 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15686945196927202		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.15686945196927202 | validation: 0.12481596665442171]
	TIME [epoch: 71.2 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15765148698413248		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.15765148698413248 | validation: 0.12905900066640563]
	TIME [epoch: 71.2 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16066331762166072		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.16066331762166072 | validation: 0.12087050813027975]
	TIME [epoch: 71.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_288.pth
	Model improved!!!
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15707686060941412		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.15707686060941412 | validation: 0.13120099578010774]
	TIME [epoch: 71.3 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1566035469034203		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.1566035469034203 | validation: 0.12914067203725238]
	TIME [epoch: 71.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15816802765477803		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.15816802765477803 | validation: 0.12450786653100301]
	TIME [epoch: 71.3 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15430011820587813		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.15430011820587813 | validation: 0.12416906448887403]
	TIME [epoch: 71.4 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15582123974125192		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.15582123974125192 | validation: 0.1257335419031987]
	TIME [epoch: 71.4 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15687829283481966		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.15687829283481966 | validation: 0.12219604409276466]
	TIME [epoch: 71.4 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15693675623008793		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.15693675623008793 | validation: 0.13376154020107622]
	TIME [epoch: 71.2 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16119454644034872		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.16119454644034872 | validation: 0.12378445135790143]
	TIME [epoch: 71.4 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1569710255380135		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.1569710255380135 | validation: 0.12916311586265578]
	TIME [epoch: 71.3 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15610315622670765		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.15610315622670765 | validation: 0.12463350890839368]
	TIME [epoch: 71.3 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1531641256932297		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.1531641256932297 | validation: 0.13546704224530373]
	TIME [epoch: 71.3 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1621625881817554		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.1621625881817554 | validation: 0.1247460248889742]
	TIME [epoch: 71.3 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15426043870516443		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.15426043870516443 | validation: 0.1248968745851329]
	TIME [epoch: 169 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15576251073498654		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.15576251073498654 | validation: 0.12616459915822756]
	TIME [epoch: 146 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15408989313125596		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.15408989313125596 | validation: 0.12539678284919817]
	TIME [epoch: 146 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1541004157749046		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.1541004157749046 | validation: 0.12215516189714651]
	TIME [epoch: 146 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15586840561670798		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.15586840561670798 | validation: 0.12335528183225528]
	TIME [epoch: 146 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15545862434299396		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.15545862434299396 | validation: 0.1204765008804169]
	TIME [epoch: 146 sec]
	Saving model to: out/model_training/model_facs_dec1_v2_argset2_20241031_141541/states/model_facs_dec1_v2_argset2_306.pth
	Model improved!!!
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1549645603167492		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.1549645603167492 | validation: 0.13364485596425046]
	TIME [epoch: 146 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15633347070325818		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.15633347070325818 | validation: 0.12520407698217617]
	TIME [epoch: 146 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15433825943518334		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.15433825943518334 | validation: 0.1259736143918046]
	TIME [epoch: 146 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15841755776436275		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.15841755776436275 | validation: 0.1313411211499127]
	TIME [epoch: 146 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15812064594504582		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.15812064594504582 | validation: 0.12300702380564447]
	TIME [epoch: 146 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15540554271568247		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.15540554271568247 | validation: 0.12520582181916168]
	TIME [epoch: 146 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.154032803960807		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.154032803960807 | validation: 0.12383100882937167]
	TIME [epoch: 146 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1567058896576161		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.1567058896576161 | validation: 0.12550449213207288]
	TIME [epoch: 146 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15461145821645397		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.15461145821645397 | validation: 0.12461323953560036]
	TIME [epoch: 146 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1532492994100568		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.1532492994100568 | validation: 0.12746580480023822]
	TIME [epoch: 146 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15425304738900925		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.15425304738900925 | validation: 0.1269657258772302]
	TIME [epoch: 146 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15595691599783318		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.15595691599783318 | validation: 0.12291865855268987]
	TIME [epoch: 146 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15626754043994304		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.15626754043994304 | validation: 0.1260420562590459]
	TIME [epoch: 146 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15601290578831326		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.15601290578831326 | validation: 0.12736477305688546]
	TIME [epoch: 146 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15286649149828657		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.15286649149828657 | validation: 0.12367174961223289]
	TIME [epoch: 146 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1530983911575691		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.1530983911575691 | validation: 0.12319857631108896]
	TIME [epoch: 146 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15362009604157392		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.15362009604157392 | validation: 0.12557287972761388]
	TIME [epoch: 146 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15187507891868127		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.15187507891868127 | validation: 0.13191353702253938]
	TIME [epoch: 146 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1552177252267196		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.1552177252267196 | validation: 0.12528544118968252]
	TIME [epoch: 146 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15532891892717945		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.15532891892717945 | validation: 0.12662913355729397]
	TIME [epoch: 146 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1581695148023842		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.1581695148023842 | validation: 0.12432019063045312]
	TIME [epoch: 146 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15578106093789118		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.15578106093789118 | validation: 0.13132047956384568]
	TIME [epoch: 146 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15612980472661583		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.15612980472661583 | validation: 0.1235636750476814]
	TIME [epoch: 146 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1531945009697068		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.1531945009697068 | validation: 0.1223589677743206]
	TIME [epoch: 146 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15340249294238711		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.15340249294238711 | validation: 0.12680743471534095]
	TIME [epoch: 146 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15419973586173355		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.15419973586173355 | validation: 0.12207281957433788]
	TIME [epoch: 146 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15199513494841135		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.15199513494841135 | validation: 0.12453720953590157]
	TIME [epoch: 146 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15341981672055285		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.15341981672055285 | validation: 0.12371917321059447]
	TIME [epoch: 146 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15456384123558045		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.15456384123558045 | validation: 0.12234170354260257]
	TIME [epoch: 146 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1525437935758516		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.1525437935758516 | validation: 0.12777064942953703]
	TIME [epoch: 146 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15631907363752542		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.15631907363752542 | validation: 0.13091828710946585]
	TIME [epoch: 146 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15339054700473623		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.15339054700473623 | validation: 0.12379803199748798]
	TIME [epoch: 146 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15612356498278498		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.15612356498278498 | validation: 0.12855532570201084]
	TIME [epoch: 146 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15351175541320314		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.15351175541320314 | validation: 0.12261736887348255]
	TIME [epoch: 146 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15481029834605955		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.15481029834605955 | validation: 0.12622031029729194]
	TIME [epoch: 146 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15346446814244605		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.15346446814244605 | validation: 0.12344886104787556]
	TIME [epoch: 146 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1526337430605424		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.1526337430605424 | validation: 0.1243453829737566]
	TIME [epoch: 146 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.156185443600358		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.156185443600358 | validation: 0.12372002230571089]
	TIME [epoch: 146 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1530794492011713		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.1530794492011713 | validation: 0.12768733981195346]
	TIME [epoch: 146 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1583296532309165		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.1583296532309165 | validation: 0.12254968147231313]
	TIME [epoch: 146 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15455487433196913		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.15455487433196913 | validation: 0.12412947327947119]
	TIME [epoch: 146 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1518387624430759		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.1518387624430759 | validation: 0.122086157762789]
	TIME [epoch: 146 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15448123524430948		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.15448123524430948 | validation: 0.1255890066101916]
	TIME [epoch: 146 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1544288130889204		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.1544288130889204 | validation: 0.12304408678750389]
	TIME [epoch: 146 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15519450570155033		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.15519450570155033 | validation: 0.12569390435529998]
	TIME [epoch: 146 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1540452689084891		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.1540452689084891 | validation: 0.12245344004511463]
	TIME [epoch: 146 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1527639488428072		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.1527639488428072 | validation: 0.12380541202256908]
	TIME [epoch: 146 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1529782388017585		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.1529782388017585 | validation: 0.12692877452568033]
	TIME [epoch: 146 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15628744557542304		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.15628744557542304 | validation: 0.12225899722576554]
	TIME [epoch: 146 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15324852712421075		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.15324852712421075 | validation: 0.12912293932069918]
	TIME [epoch: 146 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15482985439978678		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.15482985439978678 | validation: 0.1258779392269347]
	TIME [epoch: 146 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15430320304143574		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.15430320304143574 | validation: 0.1280424456817501]
	TIME [epoch: 146 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1519695828758889		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.1519695828758889 | validation: 0.12282698431325223]
	TIME [epoch: 146 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1549116561298222		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.1549116561298222 | validation: 0.12343460687908236]
	TIME [epoch: 146 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15101698041120878		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.15101698041120878 | validation: 0.12542755697516889]
	TIME [epoch: 146 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15140231031829868		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.15140231031829868 | validation: 0.12427015280020384]
	TIME [epoch: 146 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15129392621240786		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.15129392621240786 | validation: 0.12609515112504405]
	TIME [epoch: 146 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1534396901255877		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.1534396901255877 | validation: 0.12307783073818812]
	TIME [epoch: 146 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1544064875632116		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.1544064875632116 | validation: 0.12973554467570397]
	TIME [epoch: 146 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15572789204411414		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.15572789204411414 | validation: 0.13053850506780523]
	TIME [epoch: 146 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15208474517438456		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.15208474517438456 | validation: 0.12264659611378423]
	TIME [epoch: 146 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1531219669964689		[learning rate: 0.00099155]
	Learning Rate: 0.000991553
	LOSS [training: 0.1531219669964689 | validation: 0.12258054942011694]
	TIME [epoch: 146 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1501477234254965		[learning rate: 0.00098437]
	Learning Rate: 0.000984369
	LOSS [training: 0.1501477234254965 | validation: 0.12540008708956712]
	TIME [epoch: 146 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15475122632422814		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.15475122632422814 | validation: 0.12083023667375467]
	TIME [epoch: 146 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1558588432150014		[learning rate: 0.00097016]
	Learning Rate: 0.000970157
	LOSS [training: 0.1558588432150014 | validation: 0.12475670201833862]
	TIME [epoch: 146 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1529838019920544		[learning rate: 0.00096313]
	Learning Rate: 0.000963128
	LOSS [training: 0.1529838019920544 | validation: 0.12384026381798496]
	TIME [epoch: 146 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1512709923326747		[learning rate: 0.00095615]
	Learning Rate: 0.00095615
	LOSS [training: 0.1512709923326747 | validation: 0.12584428873944759]
	TIME [epoch: 146 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1523293970121232		[learning rate: 0.00094922]
	Learning Rate: 0.000949223
	LOSS [training: 0.1523293970121232 | validation: 0.12246059297984815]
	TIME [epoch: 146 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15436113059729956		[learning rate: 0.00094235]
	Learning Rate: 0.000942346
	LOSS [training: 0.15436113059729956 | validation: 0.12109889863787686]
	TIME [epoch: 146 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15345005800751535		[learning rate: 0.00093552]
	Learning Rate: 0.000935519
	LOSS [training: 0.15345005800751535 | validation: 0.12061307960165901]
	TIME [epoch: 146 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15254234426433413		[learning rate: 0.00092874]
	Learning Rate: 0.000928741
	LOSS [training: 0.15254234426433413 | validation: 0.12193555714785502]
	TIME [epoch: 146 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15287840221122337		[learning rate: 0.00092201]
	Learning Rate: 0.000922012
	LOSS [training: 0.15287840221122337 | validation: 0.12347852401938042]
	TIME [epoch: 146 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15161765995383641		[learning rate: 0.00091533]
	Learning Rate: 0.000915333
	LOSS [training: 0.15161765995383641 | validation: 0.12362896909790262]
	TIME [epoch: 146 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15349258604402696		[learning rate: 0.0009087]
	Learning Rate: 0.000908701
	LOSS [training: 0.15349258604402696 | validation: 0.12241829103312558]
	TIME [epoch: 146 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1535464289144005		[learning rate: 0.00090212]
	Learning Rate: 0.000902118
	LOSS [training: 0.1535464289144005 | validation: 0.12342480327870868]
	TIME [epoch: 146 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1530903602082329		[learning rate: 0.00089558]
	Learning Rate: 0.000895582
	LOSS [training: 0.1530903602082329 | validation: 0.1235334976803647]
	TIME [epoch: 146 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1545098289326991		[learning rate: 0.00088909]
	Learning Rate: 0.000889093
	LOSS [training: 0.1545098289326991 | validation: 0.12355973984062456]
	TIME [epoch: 146 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15147930112580293		[learning rate: 0.00088265]
	Learning Rate: 0.000882652
	LOSS [training: 0.15147930112580293 | validation: 0.12284400348654283]
	TIME [epoch: 146 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15330074631808543		[learning rate: 0.00087626]
	Learning Rate: 0.000876257
	LOSS [training: 0.15330074631808543 | validation: 0.12439000141959558]
	TIME [epoch: 146 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.154392878640034		[learning rate: 0.00086991]
	Learning Rate: 0.000869909
	LOSS [training: 0.154392878640034 | validation: 0.12186625888668043]
	TIME [epoch: 146 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1507182516854245		[learning rate: 0.00086361]
	Learning Rate: 0.000863606
	LOSS [training: 0.1507182516854245 | validation: 0.12434373659625866]
	TIME [epoch: 146 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1520502328717671		[learning rate: 0.00085735]
	Learning Rate: 0.000857349
	LOSS [training: 0.1520502328717671 | validation: 0.1226742524157638]
	TIME [epoch: 146 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14976398913842529		[learning rate: 0.00085114]
	Learning Rate: 0.000851138
	LOSS [training: 0.14976398913842529 | validation: 0.12372701940060142]
	TIME [epoch: 146 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1511053036587914		[learning rate: 0.00084497]
	Learning Rate: 0.000844972
	LOSS [training: 0.1511053036587914 | validation: 0.12427998531682354]
	TIME [epoch: 146 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15052263111251665		[learning rate: 0.00083885]
	Learning Rate: 0.00083885
	LOSS [training: 0.15052263111251665 | validation: 0.12630429134027454]
	TIME [epoch: 146 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1531062893862579		[learning rate: 0.00083277]
	Learning Rate: 0.000832772
	LOSS [training: 0.1531062893862579 | validation: 0.12096828607638033]
	TIME [epoch: 146 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15313637975693206		[learning rate: 0.00082674]
	Learning Rate: 0.000826739
	LOSS [training: 0.15313637975693206 | validation: 0.1274382281122282]
	TIME [epoch: 146 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15369272487431782		[learning rate: 0.00082075]
	Learning Rate: 0.000820749
	LOSS [training: 0.15369272487431782 | validation: 0.12211901255467213]
	TIME [epoch: 146 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1499236287328103		[learning rate: 0.0008148]
	Learning Rate: 0.000814803
	LOSS [training: 0.1499236287328103 | validation: 0.12279284737581753]
	TIME [epoch: 146 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14976777187078907		[learning rate: 0.0008089]
	Learning Rate: 0.0008089
	LOSS [training: 0.14976777187078907 | validation: 0.12598783738404595]
	TIME [epoch: 146 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14856523486956855		[learning rate: 0.00080304]
	Learning Rate: 0.000803039
	LOSS [training: 0.14856523486956855 | validation: 0.12559277157022558]
	TIME [epoch: 146 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15300517557310864		[learning rate: 0.00079722]
	Learning Rate: 0.000797221
	LOSS [training: 0.15300517557310864 | validation: 0.12333971343332464]
	TIME [epoch: 146 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14987544012915038		[learning rate: 0.00079145]
	Learning Rate: 0.000791446
	LOSS [training: 0.14987544012915038 | validation: 0.12097850557866927]
	TIME [epoch: 146 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1512306536784139		[learning rate: 0.00078571]
	Learning Rate: 0.000785711
	LOSS [training: 0.1512306536784139 | validation: 0.12364511793774717]
	TIME [epoch: 146 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15454255336732778		[learning rate: 0.00078002]
	Learning Rate: 0.000780019
	LOSS [training: 0.15454255336732778 | validation: 0.12288413953882707]
	TIME [epoch: 146 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15157892332244527		[learning rate: 0.00077437]
	Learning Rate: 0.000774368
	LOSS [training: 0.15157892332244527 | validation: 0.12482611497426961]
	TIME [epoch: 146 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.152960366037834		[learning rate: 0.00076876]
	Learning Rate: 0.000768758
	LOSS [training: 0.152960366037834 | validation: 0.12182111624677212]
	TIME [epoch: 146 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15297918116962558		[learning rate: 0.00076319]
	Learning Rate: 0.000763188
	LOSS [training: 0.15297918116962558 | validation: 0.12349627878457559]
	TIME [epoch: 146 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15157580729681183		[learning rate: 0.00075766]
	Learning Rate: 0.000757659
	LOSS [training: 0.15157580729681183 | validation: 0.1226628587901647]
	TIME [epoch: 146 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15486300219976876		[learning rate: 0.00075217]
	Learning Rate: 0.000752169
	LOSS [training: 0.15486300219976876 | validation: 0.12439363079104397]
	TIME [epoch: 146 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15370246993794395		[learning rate: 0.00074672]
	Learning Rate: 0.00074672
	LOSS [training: 0.15370246993794395 | validation: 0.12226051767568473]
	TIME [epoch: 146 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15305531828612418		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.15305531828612418 | validation: 0.12320635722332798]
	TIME [epoch: 146 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1514738777332877		[learning rate: 0.00073594]
	Learning Rate: 0.000735939
	LOSS [training: 0.1514738777332877 | validation: 0.12592195271204049]
	TIME [epoch: 146 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1515124856709669		[learning rate: 0.00073061]
	Learning Rate: 0.000730608
	LOSS [training: 0.1515124856709669 | validation: 0.12351771261986337]
	TIME [epoch: 146 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1523056417020612		[learning rate: 0.00072531]
	Learning Rate: 0.000725314
	LOSS [training: 0.1523056417020612 | validation: 0.12124177277460717]
	TIME [epoch: 146 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15332028608661694		[learning rate: 0.00072006]
	Learning Rate: 0.00072006
	LOSS [training: 0.15332028608661694 | validation: 0.12309684763567881]
	TIME [epoch: 146 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15007177784302303		[learning rate: 0.00071484]
	Learning Rate: 0.000714843
	LOSS [training: 0.15007177784302303 | validation: 0.1284009722754461]
	TIME [epoch: 146 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15178166767879434		[learning rate: 0.00070966]
	Learning Rate: 0.000709664
	LOSS [training: 0.15178166767879434 | validation: 0.12432378796847354]
	TIME [epoch: 146 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1538591727545841		[learning rate: 0.00070452]
	Learning Rate: 0.000704522
	LOSS [training: 0.1538591727545841 | validation: 0.12347007989454181]
	TIME [epoch: 146 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1516540091327499		[learning rate: 0.00069942]
	Learning Rate: 0.000699418
	LOSS [training: 0.1516540091327499 | validation: 0.1218551946291883]
	TIME [epoch: 146 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.15307350865044597		[learning rate: 0.00069435]
	Learning Rate: 0.000694351
	LOSS [training: 0.15307350865044597 | validation: 0.1247478988102231]
	TIME [epoch: 146 sec]
EPOCH 418/1000:
	Training over batches...
