Args:
Namespace(name='model_facs_dec2_v1_argset2', outdir='out/model_training/model_facs_dec2_v1_argset2', training_data='data/training_data/facs/facs_dec2_v1/training', validation_data='data/training_data/facs/facs_dec2_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.275067687034607], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 683170382

Training model...

Saving initial model state to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.1741594795531179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1741594795531179 | validation: 0.1437750299725532]
	TIME [epoch: 46.4 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655466495897387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11655466495897387 | validation: 0.15372939065654453]
	TIME [epoch: 5.03 sec]
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09946261329279898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09946261329279898 | validation: 0.12539986835755454]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544121371697876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09544121371697876 | validation: 0.1195214276060186]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08541861202865905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08541861202865905 | validation: 0.11236000420557878]
	TIME [epoch: 4.95 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887289445144466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0887289445144466 | validation: 0.14602225555841356]
	TIME [epoch: 4.93 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.08838669299068194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08838669299068194 | validation: 0.10230753094874018]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.07338710737450725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07338710737450725 | validation: 0.09565452878290534]
	TIME [epoch: 4.94 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381172766040652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06381172766040652 | validation: 0.0897649371694178]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06487642397011317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06487642397011317 | validation: 0.10278588982137143]
	TIME [epoch: 4.92 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901606776811378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06901606776811378 | validation: 0.07735584740686689]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.057047798784632175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.057047798784632175 | validation: 0.0815172134464268]
	TIME [epoch: 4.91 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320252845864307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05320252845864307 | validation: 0.0744568996870875]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.051863843571261295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.051863843571261295 | validation: 0.08114031476864202]
	TIME [epoch: 4.92 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05758738282072223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05758738282072223 | validation: 0.07125721849237017]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05659195250212759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05659195250212759 | validation: 0.06688791634841405]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.05167092438949288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05167092438949288 | validation: 0.09309927604217189]
	TIME [epoch: 4.92 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.055265705331161645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055265705331161645 | validation: 0.06488752441088023]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968204741778141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03968204741778141 | validation: 0.07449004162299308]
	TIME [epoch: 4.92 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.043818219957495616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.043818219957495616 | validation: 0.07171771665151885]
	TIME [epoch: 4.91 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04688524920063479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04688524920063479 | validation: 0.07643041791319038]
	TIME [epoch: 4.91 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04727017235782615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04727017235782615 | validation: 0.0662923589698743]
	TIME [epoch: 4.93 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042118923792575265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042118923792575265 | validation: 0.0698801640576595]
	TIME [epoch: 4.91 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036528854232666684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.036528854232666684 | validation: 0.0586095124969188]
	TIME [epoch: 4.91 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03576188650682362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03576188650682362 | validation: 0.06479012023872793]
	TIME [epoch: 4.94 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03690868754968285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03690868754968285 | validation: 0.0654137477378807]
	TIME [epoch: 4.93 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04671100803245208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04671100803245208 | validation: 0.05613817959207494]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.042504676369748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.042504676369748 | validation: 0.10064946338337113]
	TIME [epoch: 4.92 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.052430366363437814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052430366363437814 | validation: 0.054446397479355216]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815444934622175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03815444934622175 | validation: 0.06467874829587747]
	TIME [epoch: 4.93 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.038647534060764294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.038647534060764294 | validation: 0.06374252931757778]
	TIME [epoch: 4.93 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04146760478745553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04146760478745553 | validation: 0.05636267450157992]
	TIME [epoch: 4.92 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03377355787158503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03377355787158503 | validation: 0.06338614307040392]
	TIME [epoch: 4.92 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.037204745468853995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.037204745468853995 | validation: 0.05791107764404668]
	TIME [epoch: 4.92 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.033565705878546875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.033565705878546875 | validation: 0.05883135696319306]
	TIME [epoch: 4.92 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03666587195020154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.03666587195020154 | validation: 0.061965614092974255]
	TIME [epoch: 4.93 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.034341284192428476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.034341284192428476 | validation: 0.053805058328457465]
	TIME [epoch: 4.92 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577938974000794		[learning rate: 0.0099758]
	Learning Rate: 0.00997579
	LOSS [training: 0.03577938974000794 | validation: 0.07079833218200571]
	TIME [epoch: 4.92 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.044044851189493354		[learning rate: 0.0098795]
	Learning Rate: 0.00987954
	LOSS [training: 0.044044851189493354 | validation: 0.06328716478288082]
	TIME [epoch: 4.92 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03293173269792456		[learning rate: 0.0097842]
	Learning Rate: 0.00978422
	LOSS [training: 0.03293173269792456 | validation: 0.0649077624632656]
	TIME [epoch: 4.92 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497908201769438		[learning rate: 0.0096898]
	Learning Rate: 0.00968982
	LOSS [training: 0.03497908201769438 | validation: 0.05735332860847414]
	TIME [epoch: 4.92 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03290010978832336		[learning rate: 0.0095963]
	Learning Rate: 0.00959633
	LOSS [training: 0.03290010978832336 | validation: 0.058801211729648854]
	TIME [epoch: 4.92 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03847168279061674		[learning rate: 0.0095037]
	Learning Rate: 0.00950374
	LOSS [training: 0.03847168279061674 | validation: 0.060650962493546005]
	TIME [epoch: 4.92 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03390891396700131		[learning rate: 0.009412]
	Learning Rate: 0.00941205
	LOSS [training: 0.03390891396700131 | validation: 0.07084839143109532]
	TIME [epoch: 4.92 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.037531861275780926		[learning rate: 0.0093212]
	Learning Rate: 0.00932124
	LOSS [training: 0.037531861275780926 | validation: 0.05479850985033592]
	TIME [epoch: 4.91 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0390415532644774		[learning rate: 0.0092313]
	Learning Rate: 0.00923131
	LOSS [training: 0.0390415532644774 | validation: 0.05749963663750035]
	TIME [epoch: 4.92 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03354107126009977		[learning rate: 0.0091422]
	Learning Rate: 0.00914224
	LOSS [training: 0.03354107126009977 | validation: 0.055289832100918535]
	TIME [epoch: 4.92 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03753714749737226		[learning rate: 0.009054]
	Learning Rate: 0.00905403
	LOSS [training: 0.03753714749737226 | validation: 0.06734074317155356]
	TIME [epoch: 4.93 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03726329573483963		[learning rate: 0.0089667]
	Learning Rate: 0.00896668
	LOSS [training: 0.03726329573483963 | validation: 0.0688877781329818]
	TIME [epoch: 4.93 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655801114471667		[learning rate: 0.0088802]
	Learning Rate: 0.00888017
	LOSS [training: 0.03655801114471667 | validation: 0.05190603018766582]
	TIME [epoch: 4.93 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031049331260856038		[learning rate: 0.0087945]
	Learning Rate: 0.00879449
	LOSS [training: 0.031049331260856038 | validation: 0.06129441116551948]
	TIME [epoch: 50 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032336884013427575		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.032336884013427575 | validation: 0.06218185022272097]
	TIME [epoch: 9.51 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313213231190959		[learning rate: 0.0086256]
	Learning Rate: 0.0086256
	LOSS [training: 0.03313213231190959 | validation: 0.05247897797231389]
	TIME [epoch: 9.5 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03596482942645901		[learning rate: 0.0085424]
	Learning Rate: 0.00854238
	LOSS [training: 0.03596482942645901 | validation: 0.07219736744967208]
	TIME [epoch: 9.5 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.04887804392317237		[learning rate: 0.00846]
	Learning Rate: 0.00845996
	LOSS [training: 0.04887804392317237 | validation: 0.05558991512141872]
	TIME [epoch: 9.51 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232712285956948		[learning rate: 0.0083783]
	Learning Rate: 0.00837834
	LOSS [training: 0.03232712285956948 | validation: 0.061507967985995324]
	TIME [epoch: 9.49 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02875279911312588		[learning rate: 0.0082975]
	Learning Rate: 0.0082975
	LOSS [training: 0.02875279911312588 | validation: 0.06732492375982482]
	TIME [epoch: 9.51 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026168616239153585		[learning rate: 0.0082174]
	Learning Rate: 0.00821745
	LOSS [training: 0.026168616239153585 | validation: 0.05690955789110492]
	TIME [epoch: 9.49 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032558508642185194		[learning rate: 0.0081382]
	Learning Rate: 0.00813816
	LOSS [training: 0.032558508642185194 | validation: 0.06819623350868297]
	TIME [epoch: 9.49 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035036102586761986		[learning rate: 0.0080596]
	Learning Rate: 0.00805964
	LOSS [training: 0.035036102586761986 | validation: 0.07381935903184213]
	TIME [epoch: 9.49 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03464103501133463		[learning rate: 0.0079819]
	Learning Rate: 0.00798188
	LOSS [training: 0.03464103501133463 | validation: 0.057909259912682316]
	TIME [epoch: 9.5 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03192921482147003		[learning rate: 0.0079049]
	Learning Rate: 0.00790487
	LOSS [training: 0.03192921482147003 | validation: 0.05179182345468861]
	TIME [epoch: 9.49 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289719890199015		[learning rate: 0.0078286]
	Learning Rate: 0.0078286
	LOSS [training: 0.03289719890199015 | validation: 0.07243289010732945]
	TIME [epoch: 9.49 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.036694981010378845		[learning rate: 0.0077531]
	Learning Rate: 0.00775307
	LOSS [training: 0.036694981010378845 | validation: 0.07371632267766104]
	TIME [epoch: 9.48 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.035895537671626586		[learning rate: 0.0076783]
	Learning Rate: 0.00767827
	LOSS [training: 0.035895537671626586 | validation: 0.05611395253069552]
	TIME [epoch: 9.48 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030605596289081265		[learning rate: 0.0076042]
	Learning Rate: 0.00760418
	LOSS [training: 0.030605596289081265 | validation: 0.05810633551190817]
	TIME [epoch: 9.51 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030572419406707657		[learning rate: 0.0075308]
	Learning Rate: 0.00753082
	LOSS [training: 0.030572419406707657 | validation: 0.06830526681792097]
	TIME [epoch: 9.5 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029042490717438016		[learning rate: 0.0074582]
	Learning Rate: 0.00745816
	LOSS [training: 0.029042490717438016 | validation: 0.056518693783995474]
	TIME [epoch: 9.48 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026012298061779515		[learning rate: 0.0073862]
	Learning Rate: 0.0073862
	LOSS [training: 0.026012298061779515 | validation: 0.05375731340873054]
	TIME [epoch: 9.52 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03111331697245875		[learning rate: 0.0073149]
	Learning Rate: 0.00731494
	LOSS [training: 0.03111331697245875 | validation: 0.06736042298787329]
	TIME [epoch: 9.51 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024097246480304826		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.024097246480304826 | validation: 0.0724800536771969]
	TIME [epoch: 9.49 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031602539303886075		[learning rate: 0.0071745]
	Learning Rate: 0.00717446
	LOSS [training: 0.031602539303886075 | validation: 0.06242747621144907]
	TIME [epoch: 9.5 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02977485449020203		[learning rate: 0.0071052]
	Learning Rate: 0.00710524
	LOSS [training: 0.02977485449020203 | validation: 0.051423043506104785]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395588479339794		[learning rate: 0.0070367]
	Learning Rate: 0.00703669
	LOSS [training: 0.0395588479339794 | validation: 0.05029662614185253]
	TIME [epoch: 9.51 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.029648160951480297		[learning rate: 0.0069688]
	Learning Rate: 0.0069688
	LOSS [training: 0.029648160951480297 | validation: 0.05801410650143259]
	TIME [epoch: 9.51 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.032807123013173796		[learning rate: 0.0069016]
	Learning Rate: 0.00690156
	LOSS [training: 0.032807123013173796 | validation: 0.059481223507152896]
	TIME [epoch: 9.5 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02511787871287088		[learning rate: 0.006835]
	Learning Rate: 0.00683497
	LOSS [training: 0.02511787871287088 | validation: 0.05267182712433725]
	TIME [epoch: 9.49 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025899787078717994		[learning rate: 0.006769]
	Learning Rate: 0.00676903
	LOSS [training: 0.025899787078717994 | validation: 0.05313550430674281]
	TIME [epoch: 9.5 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030933873502774253		[learning rate: 0.0067037]
	Learning Rate: 0.00670372
	LOSS [training: 0.030933873502774253 | validation: 0.04859436230391724]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025063940405817112		[learning rate: 0.006639]
	Learning Rate: 0.00663904
	LOSS [training: 0.025063940405817112 | validation: 0.05712107372676215]
	TIME [epoch: 9.49 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745228645497899		[learning rate: 0.006575]
	Learning Rate: 0.00657498
	LOSS [training: 0.02745228645497899 | validation: 0.049688761211492086]
	TIME [epoch: 9.51 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023984598558831182		[learning rate: 0.0065115]
	Learning Rate: 0.00651155
	LOSS [training: 0.023984598558831182 | validation: 0.05546605503919077]
	TIME [epoch: 9.5 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023010783495202733		[learning rate: 0.0064487]
	Learning Rate: 0.00644872
	LOSS [training: 0.023010783495202733 | validation: 0.07324313616781429]
	TIME [epoch: 9.49 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02986236395537609		[learning rate: 0.0063865]
	Learning Rate: 0.0063865
	LOSS [training: 0.02986236395537609 | validation: 0.06513415120265555]
	TIME [epoch: 9.5 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024683134290205275		[learning rate: 0.0063249]
	Learning Rate: 0.00632488
	LOSS [training: 0.024683134290205275 | validation: 0.05717296717957308]
	TIME [epoch: 9.51 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03262128603804194		[learning rate: 0.0062639]
	Learning Rate: 0.00626386
	LOSS [training: 0.03262128603804194 | validation: 0.06067001452885079]
	TIME [epoch: 9.5 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416814303442437		[learning rate: 0.0062034]
	Learning Rate: 0.00620343
	LOSS [training: 0.03416814303442437 | validation: 0.05697878615069797]
	TIME [epoch: 9.48 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031744552428242555		[learning rate: 0.0061436]
	Learning Rate: 0.00614357
	LOSS [training: 0.031744552428242555 | validation: 0.05680422537109195]
	TIME [epoch: 9.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0323344128426349		[learning rate: 0.0060843]
	Learning Rate: 0.0060843
	LOSS [training: 0.0323344128426349 | validation: 0.06501939311984631]
	TIME [epoch: 9.51 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026028486089552934		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.026028486089552934 | validation: 0.06623167877727494]
	TIME [epoch: 9.5 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03445118732561136		[learning rate: 0.0059675]
	Learning Rate: 0.00596746
	LOSS [training: 0.03445118732561136 | validation: 0.047387661654766634]
	TIME [epoch: 9.5 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027031443044087975		[learning rate: 0.0059099]
	Learning Rate: 0.00590988
	LOSS [training: 0.027031443044087975 | validation: 0.05271191980580556]
	TIME [epoch: 9.48 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024737588739126508		[learning rate: 0.0058529]
	Learning Rate: 0.00585286
	LOSS [training: 0.024737588739126508 | validation: 0.052646052410990865]
	TIME [epoch: 9.48 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026386405460929834		[learning rate: 0.0057964]
	Learning Rate: 0.00579639
	LOSS [training: 0.026386405460929834 | validation: 0.05001618586294143]
	TIME [epoch: 9.52 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023062463038546473		[learning rate: 0.0057405]
	Learning Rate: 0.00574047
	LOSS [training: 0.023062463038546473 | validation: 0.05037983258995587]
	TIME [epoch: 9.51 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026205845727968507		[learning rate: 0.0056851]
	Learning Rate: 0.00568508
	LOSS [training: 0.026205845727968507 | validation: 0.048121276271488]
	TIME [epoch: 9.52 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024760145471650653		[learning rate: 0.0056302]
	Learning Rate: 0.00563023
	LOSS [training: 0.024760145471650653 | validation: 0.061742740307546035]
	TIME [epoch: 9.5 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025959578740119334		[learning rate: 0.0055759]
	Learning Rate: 0.00557591
	LOSS [training: 0.025959578740119334 | validation: 0.050845128512719606]
	TIME [epoch: 9.5 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02387013500957106		[learning rate: 0.0055221]
	Learning Rate: 0.00552211
	LOSS [training: 0.02387013500957106 | validation: 0.0537948960428711]
	TIME [epoch: 9.49 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02985767951757247		[learning rate: 0.0054688]
	Learning Rate: 0.00546883
	LOSS [training: 0.02985767951757247 | validation: 0.05557733179837725]
	TIME [epoch: 9.49 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.030929522053560803		[learning rate: 0.0054161]
	Learning Rate: 0.00541607
	LOSS [training: 0.030929522053560803 | validation: 0.06434386323904448]
	TIME [epoch: 60.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.03173299972891268		[learning rate: 0.0053638]
	Learning Rate: 0.00536381
	LOSS [training: 0.03173299972891268 | validation: 0.048968231305771937]
	TIME [epoch: 20 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024893880764736667		[learning rate: 0.0053121]
	Learning Rate: 0.00531206
	LOSS [training: 0.024893880764736667 | validation: 0.06097007540223393]
	TIME [epoch: 20 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021415524242256033		[learning rate: 0.0052608]
	Learning Rate: 0.00526081
	LOSS [training: 0.021415524242256033 | validation: 0.053114572608285504]
	TIME [epoch: 20 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024302011813403572		[learning rate: 0.0052101]
	Learning Rate: 0.00521005
	LOSS [training: 0.024302011813403572 | validation: 0.051759908547159304]
	TIME [epoch: 20 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024138266589012084		[learning rate: 0.0051598]
	Learning Rate: 0.00515978
	LOSS [training: 0.024138266589012084 | validation: 0.05691469143501213]
	TIME [epoch: 20 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024290945398604935		[learning rate: 0.00511]
	Learning Rate: 0.00511
	LOSS [training: 0.024290945398604935 | validation: 0.06051882011196165]
	TIME [epoch: 20 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.031045228876933388		[learning rate: 0.0050607]
	Learning Rate: 0.0050607
	LOSS [training: 0.031045228876933388 | validation: 0.04984728470503312]
	TIME [epoch: 20 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021866222269605495		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.021866222269605495 | validation: 0.07942961651455123]
	TIME [epoch: 20 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027329577417763914		[learning rate: 0.0049635]
	Learning Rate: 0.00496352
	LOSS [training: 0.027329577417763914 | validation: 0.05231373317334577]
	TIME [epoch: 20 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023502844884151625		[learning rate: 0.0049156]
	Learning Rate: 0.00491563
	LOSS [training: 0.023502844884151625 | validation: 0.06892966554271511]
	TIME [epoch: 20 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027902645080634975		[learning rate: 0.0048682]
	Learning Rate: 0.0048682
	LOSS [training: 0.027902645080634975 | validation: 0.04887680059667278]
	TIME [epoch: 20 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024012122580995797		[learning rate: 0.0048212]
	Learning Rate: 0.00482123
	LOSS [training: 0.024012122580995797 | validation: 0.05620125110432115]
	TIME [epoch: 20 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021823209326025612		[learning rate: 0.0047747]
	Learning Rate: 0.00477471
	LOSS [training: 0.021823209326025612 | validation: 0.05079704106693156]
	TIME [epoch: 20 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02196764949262998		[learning rate: 0.0047286]
	Learning Rate: 0.00472865
	LOSS [training: 0.02196764949262998 | validation: 0.05299166585761304]
	TIME [epoch: 20 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02779978559590387		[learning rate: 0.004683]
	Learning Rate: 0.00468302
	LOSS [training: 0.02779978559590387 | validation: 0.05964472771101892]
	TIME [epoch: 20 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.026965289192880507		[learning rate: 0.0046378]
	Learning Rate: 0.00463784
	LOSS [training: 0.026965289192880507 | validation: 0.06541957156703831]
	TIME [epoch: 20 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.028414925943691337		[learning rate: 0.0045931]
	Learning Rate: 0.00459309
	LOSS [training: 0.028414925943691337 | validation: 0.05355271793930434]
	TIME [epoch: 20 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02217143673562432		[learning rate: 0.0045488]
	Learning Rate: 0.00454878
	LOSS [training: 0.02217143673562432 | validation: 0.052973116624437516]
	TIME [epoch: 20 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022287120260527572		[learning rate: 0.0045049]
	Learning Rate: 0.00450489
	LOSS [training: 0.022287120260527572 | validation: 0.052569631904598735]
	TIME [epoch: 20 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02294125401379111		[learning rate: 0.0044614]
	Learning Rate: 0.00446143
	LOSS [training: 0.02294125401379111 | validation: 0.05077874610266253]
	TIME [epoch: 20 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.027649711921501695		[learning rate: 0.0044184]
	Learning Rate: 0.00441838
	LOSS [training: 0.027649711921501695 | validation: 0.04577942985044544]
	TIME [epoch: 20 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023826865494125868		[learning rate: 0.0043758]
	Learning Rate: 0.00437575
	LOSS [training: 0.023826865494125868 | validation: 0.051885587057100294]
	TIME [epoch: 20 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022601400597031068		[learning rate: 0.0043335]
	Learning Rate: 0.00433353
	LOSS [training: 0.022601400597031068 | validation: 0.05426028472024633]
	TIME [epoch: 20 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0216379555417255		[learning rate: 0.0042917]
	Learning Rate: 0.00429172
	LOSS [training: 0.0216379555417255 | validation: 0.04791780594198383]
	TIME [epoch: 20 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02290780077400449		[learning rate: 0.0042503]
	Learning Rate: 0.00425031
	LOSS [training: 0.02290780077400449 | validation: 0.05397171997146349]
	TIME [epoch: 20 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023318748203073062		[learning rate: 0.0042093]
	Learning Rate: 0.00420931
	LOSS [training: 0.023318748203073062 | validation: 0.04966795957903476]
	TIME [epoch: 20.1 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022502181790983653		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.022502181790983653 | validation: 0.054179771980566095]
	TIME [epoch: 20 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02676340617204387		[learning rate: 0.0041285]
	Learning Rate: 0.00412847
	LOSS [training: 0.02676340617204387 | validation: 0.05382876489799282]
	TIME [epoch: 20 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02964483394437533		[learning rate: 0.0040886]
	Learning Rate: 0.00408864
	LOSS [training: 0.02964483394437533 | validation: 0.05322198354471177]
	TIME [epoch: 20 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.025157319013905492		[learning rate: 0.0040492]
	Learning Rate: 0.00404919
	LOSS [training: 0.025157319013905492 | validation: 0.06301662702317103]
	TIME [epoch: 20 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211392469727939		[learning rate: 0.0040101]
	Learning Rate: 0.00401012
	LOSS [training: 0.0211392469727939 | validation: 0.05111153991432608]
	TIME [epoch: 20 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02449182410038744		[learning rate: 0.0039714]
	Learning Rate: 0.00397143
	LOSS [training: 0.02449182410038744 | validation: 0.06265874491370634]
	TIME [epoch: 20 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023284854801549314		[learning rate: 0.0039331]
	Learning Rate: 0.00393312
	LOSS [training: 0.023284854801549314 | validation: 0.062236103083731495]
	TIME [epoch: 20 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02451888134392283		[learning rate: 0.0038952]
	Learning Rate: 0.00389517
	LOSS [training: 0.02451888134392283 | validation: 0.05968014650627017]
	TIME [epoch: 20 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02169861768461941		[learning rate: 0.0038576]
	Learning Rate: 0.00385759
	LOSS [training: 0.02169861768461941 | validation: 0.05304088710096877]
	TIME [epoch: 20 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527913018733012		[learning rate: 0.0038204]
	Learning Rate: 0.00382037
	LOSS [training: 0.02527913018733012 | validation: 0.05617201198838708]
	TIME [epoch: 20 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02141173971969531		[learning rate: 0.0037835]
	Learning Rate: 0.00378351
	LOSS [training: 0.02141173971969531 | validation: 0.05358583065129884]
	TIME [epoch: 20 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022480327523306736		[learning rate: 0.003747]
	Learning Rate: 0.003747
	LOSS [training: 0.022480327523306736 | validation: 0.05769388318981761]
	TIME [epoch: 20 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020992094460633347		[learning rate: 0.0037109]
	Learning Rate: 0.00371085
	LOSS [training: 0.020992094460633347 | validation: 0.0598401747301216]
	TIME [epoch: 20 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02594359325037277		[learning rate: 0.003675]
	Learning Rate: 0.00367505
	LOSS [training: 0.02594359325037277 | validation: 0.052751710809085375]
	TIME [epoch: 20 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020620765778900846		[learning rate: 0.0036396]
	Learning Rate: 0.00363959
	LOSS [training: 0.020620765778900846 | validation: 0.05022140037034603]
	TIME [epoch: 19.9 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019810757221368547		[learning rate: 0.0036045]
	Learning Rate: 0.00360448
	LOSS [training: 0.019810757221368547 | validation: 0.05616795398591378]
	TIME [epoch: 20 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02733834322982344		[learning rate: 0.0035697]
	Learning Rate: 0.0035697
	LOSS [training: 0.02733834322982344 | validation: 0.049913143588831685]
	TIME [epoch: 20 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024573340078767554		[learning rate: 0.0035353]
	Learning Rate: 0.00353526
	LOSS [training: 0.024573340078767554 | validation: 0.05778691083538613]
	TIME [epoch: 20 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167877097176394		[learning rate: 0.0035011]
	Learning Rate: 0.00350115
	LOSS [training: 0.02167877097176394 | validation: 0.05985032076187743]
	TIME [epoch: 20 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02155937723727799		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.02155937723727799 | validation: 0.05010526160629503]
	TIME [epoch: 20 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023599045251902716		[learning rate: 0.0034339]
	Learning Rate: 0.00343391
	LOSS [training: 0.023599045251902716 | validation: 0.04989869193528248]
	TIME [epoch: 19.9 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022827973879621256		[learning rate: 0.0034008]
	Learning Rate: 0.00340078
	LOSS [training: 0.022827973879621256 | validation: 0.047446908654205144]
	TIME [epoch: 20 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02392824177048779		[learning rate: 0.003368]
	Learning Rate: 0.00336797
	LOSS [training: 0.02392824177048779 | validation: 0.06826627239771503]
	TIME [epoch: 20 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02572993484427684		[learning rate: 0.0033355]
	Learning Rate: 0.00333548
	LOSS [training: 0.02572993484427684 | validation: 0.05963155414140554]
	TIME [epoch: 20 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02485553646828562		[learning rate: 0.0033033]
	Learning Rate: 0.00330329
	LOSS [training: 0.02485553646828562 | validation: 0.04872497366820516]
	TIME [epoch: 19.9 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024922119136597195		[learning rate: 0.0032714]
	Learning Rate: 0.00327142
	LOSS [training: 0.024922119136597195 | validation: 0.055048001143351524]
	TIME [epoch: 20 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01939567657506001		[learning rate: 0.0032399]
	Learning Rate: 0.00323986
	LOSS [training: 0.01939567657506001 | validation: 0.05543988350100506]
	TIME [epoch: 20 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022506702699135163		[learning rate: 0.0032086]
	Learning Rate: 0.0032086
	LOSS [training: 0.022506702699135163 | validation: 0.05149937391794434]
	TIME [epoch: 20 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020638649509043254		[learning rate: 0.0031776]
	Learning Rate: 0.00317764
	LOSS [training: 0.020638649509043254 | validation: 0.060367015283311835]
	TIME [epoch: 20 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022487523659203618		[learning rate: 0.003147]
	Learning Rate: 0.00314699
	LOSS [training: 0.022487523659203618 | validation: 0.049090310516064356]
	TIME [epoch: 20 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02400796573487268		[learning rate: 0.0031166]
	Learning Rate: 0.00311662
	LOSS [training: 0.02400796573487268 | validation: 0.05263439304238164]
	TIME [epoch: 20 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021776249427265228		[learning rate: 0.0030866]
	Learning Rate: 0.00308655
	LOSS [training: 0.021776249427265228 | validation: 0.054225453374836315]
	TIME [epoch: 20 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020336261976671374		[learning rate: 0.0030568]
	Learning Rate: 0.00305677
	LOSS [training: 0.020336261976671374 | validation: 0.055683673472486]
	TIME [epoch: 20 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022270030259608355		[learning rate: 0.0030273]
	Learning Rate: 0.00302728
	LOSS [training: 0.022270030259608355 | validation: 0.056255050565815715]
	TIME [epoch: 20 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022657290382811616		[learning rate: 0.0029981]
	Learning Rate: 0.00299807
	LOSS [training: 0.022657290382811616 | validation: 0.04832183977835029]
	TIME [epoch: 20 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019476609004308063		[learning rate: 0.0029691]
	Learning Rate: 0.00296915
	LOSS [training: 0.019476609004308063 | validation: 0.057606861515729024]
	TIME [epoch: 20 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02130577103854554		[learning rate: 0.0029405]
	Learning Rate: 0.0029405
	LOSS [training: 0.02130577103854554 | validation: 0.055717080171173605]
	TIME [epoch: 20 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019972442852239845		[learning rate: 0.0029121]
	Learning Rate: 0.00291213
	LOSS [training: 0.019972442852239845 | validation: 0.05682966431466189]
	TIME [epoch: 20 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02620940668175376		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.02620940668175376 | validation: 0.052635364408507634]
	TIME [epoch: 20 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0218460573116712		[learning rate: 0.0028562]
	Learning Rate: 0.00285621
	LOSS [training: 0.0218460573116712 | validation: 0.05155831014696448]
	TIME [epoch: 19.9 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0209960665281197		[learning rate: 0.0028286]
	Learning Rate: 0.00282865
	LOSS [training: 0.0209960665281197 | validation: 0.0526970319127875]
	TIME [epoch: 20 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021078909669720237		[learning rate: 0.0028014]
	Learning Rate: 0.00280136
	LOSS [training: 0.021078909669720237 | validation: 0.05060539918543325]
	TIME [epoch: 20 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021187311204776998		[learning rate: 0.0027743]
	Learning Rate: 0.00277433
	LOSS [training: 0.021187311204776998 | validation: 0.05015123699908086]
	TIME [epoch: 20 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019993557898756627		[learning rate: 0.0027476]
	Learning Rate: 0.00274756
	LOSS [training: 0.019993557898756627 | validation: 0.05837889408612675]
	TIME [epoch: 20 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02120844748550746		[learning rate: 0.0027211]
	Learning Rate: 0.00272105
	LOSS [training: 0.02120844748550746 | validation: 0.047242252554582385]
	TIME [epoch: 20 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024064835458674487		[learning rate: 0.0026948]
	Learning Rate: 0.0026948
	LOSS [training: 0.024064835458674487 | validation: 0.06063419993787464]
	TIME [epoch: 20 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02091237981374109		[learning rate: 0.0026688]
	Learning Rate: 0.0026688
	LOSS [training: 0.02091237981374109 | validation: 0.04984081421111121]
	TIME [epoch: 20 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022397310475784752		[learning rate: 0.002643]
	Learning Rate: 0.00264305
	LOSS [training: 0.022397310475784752 | validation: 0.05520875585625396]
	TIME [epoch: 20 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023460667316906207		[learning rate: 0.0026175]
	Learning Rate: 0.00261755
	LOSS [training: 0.023460667316906207 | validation: 0.051265155379918256]
	TIME [epoch: 20 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021722475799199815		[learning rate: 0.0025923]
	Learning Rate: 0.00259229
	LOSS [training: 0.021722475799199815 | validation: 0.05147875691962431]
	TIME [epoch: 20 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02085143664999969		[learning rate: 0.0025673]
	Learning Rate: 0.00256728
	LOSS [training: 0.02085143664999969 | validation: 0.0501115995307631]
	TIME [epoch: 20 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02007337516455479		[learning rate: 0.0025425]
	Learning Rate: 0.00254251
	LOSS [training: 0.02007337516455479 | validation: 0.052935712975610255]
	TIME [epoch: 19.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02236981700274132		[learning rate: 0.002518]
	Learning Rate: 0.00251798
	LOSS [training: 0.02236981700274132 | validation: 0.05754944002449077]
	TIME [epoch: 20 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02167128022373034		[learning rate: 0.0024937]
	Learning Rate: 0.00249369
	LOSS [training: 0.02167128022373034 | validation: 0.05081643811865972]
	TIME [epoch: 20 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021744512214321964		[learning rate: 0.0024696]
	Learning Rate: 0.00246963
	LOSS [training: 0.021744512214321964 | validation: 0.056040413864803025]
	TIME [epoch: 20 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02277595728682035		[learning rate: 0.0024458]
	Learning Rate: 0.0024458
	LOSS [training: 0.02277595728682035 | validation: 0.050768438228245394]
	TIME [epoch: 20 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02224510143951958		[learning rate: 0.0024222]
	Learning Rate: 0.0024222
	LOSS [training: 0.02224510143951958 | validation: 0.05255685947104559]
	TIME [epoch: 20 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022118853357816118		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.022118853357816118 | validation: 0.05990873875608251]
	TIME [epoch: 20 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024562126085689515		[learning rate: 0.0023757]
	Learning Rate: 0.00237569
	LOSS [training: 0.024562126085689515 | validation: 0.05031491863754444]
	TIME [epoch: 20 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020390944574968616		[learning rate: 0.0023528]
	Learning Rate: 0.00235277
	LOSS [training: 0.020390944574968616 | validation: 0.04911442924107084]
	TIME [epoch: 20 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022605405175081597		[learning rate: 0.0023301]
	Learning Rate: 0.00233007
	LOSS [training: 0.022605405175081597 | validation: 0.0507184039689388]
	TIME [epoch: 20 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02404876312626579		[learning rate: 0.0023076]
	Learning Rate: 0.00230759
	LOSS [training: 0.02404876312626579 | validation: 0.05095405148262074]
	TIME [epoch: 20 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020340712320059597		[learning rate: 0.0022853]
	Learning Rate: 0.00228532
	LOSS [training: 0.020340712320059597 | validation: 0.050639568770923765]
	TIME [epoch: 20 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01898773003579491		[learning rate: 0.0022633]
	Learning Rate: 0.00226327
	LOSS [training: 0.01898773003579491 | validation: 0.050184393288133906]
	TIME [epoch: 20 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022128244485525868		[learning rate: 0.0022414]
	Learning Rate: 0.00224144
	LOSS [training: 0.022128244485525868 | validation: 0.056319117483698555]
	TIME [epoch: 20 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018655470720062437		[learning rate: 0.0022198]
	Learning Rate: 0.00221981
	LOSS [training: 0.018655470720062437 | validation: 0.05097861307504232]
	TIME [epoch: 20 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02095426623840237		[learning rate: 0.0021984]
	Learning Rate: 0.00219839
	LOSS [training: 0.02095426623840237 | validation: 0.05703332712123492]
	TIME [epoch: 20 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02038865992343241		[learning rate: 0.0021772]
	Learning Rate: 0.00217718
	LOSS [training: 0.02038865992343241 | validation: 0.05410627589809045]
	TIME [epoch: 20 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.024283163157539978		[learning rate: 0.0021562]
	Learning Rate: 0.00215618
	LOSS [training: 0.024283163157539978 | validation: 0.048844951253882544]
	TIME [epoch: 20 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021182085719818687		[learning rate: 0.0021354]
	Learning Rate: 0.00213537
	LOSS [training: 0.021182085719818687 | validation: 0.04976080608081147]
	TIME [epoch: 20 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020008918114740933		[learning rate: 0.0021148]
	Learning Rate: 0.00211477
	LOSS [training: 0.020008918114740933 | validation: 0.0543856919636795]
	TIME [epoch: 20 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020422794866439407		[learning rate: 0.0020944]
	Learning Rate: 0.00209437
	LOSS [training: 0.020422794866439407 | validation: 0.055550879048679856]
	TIME [epoch: 20 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023785603161372078		[learning rate: 0.0020742]
	Learning Rate: 0.00207416
	LOSS [training: 0.023785603161372078 | validation: 0.047605091170337]
	TIME [epoch: 20 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022475175799597052		[learning rate: 0.0020541]
	Learning Rate: 0.00205415
	LOSS [training: 0.022475175799597052 | validation: 0.059536206414409557]
	TIME [epoch: 82 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022955671218815296		[learning rate: 0.0020343]
	Learning Rate: 0.00203433
	LOSS [training: 0.022955671218815296 | validation: 0.05299544173101698]
	TIME [epoch: 42 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.023308385473448722		[learning rate: 0.0020147]
	Learning Rate: 0.0020147
	LOSS [training: 0.023308385473448722 | validation: 0.05359428703145872]
	TIME [epoch: 42 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019927175476780867		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.019927175476780867 | validation: 0.04924436046573642]
	TIME [epoch: 42 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019857285591018563		[learning rate: 0.001976]
	Learning Rate: 0.00197601
	LOSS [training: 0.019857285591018563 | validation: 0.04939686598800224]
	TIME [epoch: 42 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018368053556857313		[learning rate: 0.0019569]
	Learning Rate: 0.00195695
	LOSS [training: 0.018368053556857313 | validation: 0.052488541694168]
	TIME [epoch: 42 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02001552872607018		[learning rate: 0.0019381]
	Learning Rate: 0.00193807
	LOSS [training: 0.02001552872607018 | validation: 0.04926945214841527]
	TIME [epoch: 42 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022121527072260765		[learning rate: 0.0019194]
	Learning Rate: 0.00191937
	LOSS [training: 0.022121527072260765 | validation: 0.05021434729761218]
	TIME [epoch: 42.1 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0223799020814707		[learning rate: 0.0019008]
	Learning Rate: 0.00190085
	LOSS [training: 0.0223799020814707 | validation: 0.052923597212295136]
	TIME [epoch: 41.9 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02182055306797935		[learning rate: 0.0018825]
	Learning Rate: 0.00188251
	LOSS [training: 0.02182055306797935 | validation: 0.04965313806452424]
	TIME [epoch: 42 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020917986880148565		[learning rate: 0.0018643]
	Learning Rate: 0.00186434
	LOSS [training: 0.020917986880148565 | validation: 0.04936604281681861]
	TIME [epoch: 42 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02113352967067134		[learning rate: 0.0018464]
	Learning Rate: 0.00184636
	LOSS [training: 0.02113352967067134 | validation: 0.05469922844450015]
	TIME [epoch: 41.9 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018756644934407787		[learning rate: 0.0018285]
	Learning Rate: 0.00182854
	LOSS [training: 0.018756644934407787 | validation: 0.051439105171583295]
	TIME [epoch: 42 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019907516789955317		[learning rate: 0.0018109]
	Learning Rate: 0.0018109
	LOSS [training: 0.019907516789955317 | validation: 0.04967590057170791]
	TIME [epoch: 42 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020411249146546902		[learning rate: 0.0017934]
	Learning Rate: 0.00179343
	LOSS [training: 0.020411249146546902 | validation: 0.05262339653114225]
	TIME [epoch: 42 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0206193608248325		[learning rate: 0.0017761]
	Learning Rate: 0.00177613
	LOSS [training: 0.0206193608248325 | validation: 0.05379996593769109]
	TIME [epoch: 42 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021593506426562173		[learning rate: 0.001759]
	Learning Rate: 0.00175899
	LOSS [training: 0.021593506426562173 | validation: 0.04961876698577348]
	TIME [epoch: 42 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021162676107794685		[learning rate: 0.001742]
	Learning Rate: 0.00174202
	LOSS [training: 0.021162676107794685 | validation: 0.052358312042221966]
	TIME [epoch: 42 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018882962055986927		[learning rate: 0.0017252]
	Learning Rate: 0.00172521
	LOSS [training: 0.018882962055986927 | validation: 0.04625794466030027]
	TIME [epoch: 42 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019674793691930204		[learning rate: 0.0017086]
	Learning Rate: 0.00170857
	LOSS [training: 0.019674793691930204 | validation: 0.04957706325810162]
	TIME [epoch: 42 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020201733904688057		[learning rate: 0.0016921]
	Learning Rate: 0.00169208
	LOSS [training: 0.020201733904688057 | validation: 0.05073232947238973]
	TIME [epoch: 42 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01811672522098287		[learning rate: 0.0016758]
	Learning Rate: 0.00167575
	LOSS [training: 0.01811672522098287 | validation: 0.05407231609203625]
	TIME [epoch: 42 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019261643230336054		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.019261643230336054 | validation: 0.051629247119028054]
	TIME [epoch: 42 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020289941468552904		[learning rate: 0.0016436]
	Learning Rate: 0.00164357
	LOSS [training: 0.020289941468552904 | validation: 0.051776269359520004]
	TIME [epoch: 42 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019328176780215534		[learning rate: 0.0016277]
	Learning Rate: 0.00162772
	LOSS [training: 0.019328176780215534 | validation: 0.054342435313764884]
	TIME [epoch: 42 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01877256025585156		[learning rate: 0.001612]
	Learning Rate: 0.00161201
	LOSS [training: 0.01877256025585156 | validation: 0.04825378518674009]
	TIME [epoch: 42 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021239292754104768		[learning rate: 0.0015965]
	Learning Rate: 0.00159646
	LOSS [training: 0.021239292754104768 | validation: 0.05076345230444293]
	TIME [epoch: 42 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020088344909981563		[learning rate: 0.0015811]
	Learning Rate: 0.00158106
	LOSS [training: 0.020088344909981563 | validation: 0.049086004699307365]
	TIME [epoch: 42.1 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017738453393223837		[learning rate: 0.0015658]
	Learning Rate: 0.0015658
	LOSS [training: 0.017738453393223837 | validation: 0.04814826203336992]
	TIME [epoch: 41.9 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021913080500122396		[learning rate: 0.0015507]
	Learning Rate: 0.00155069
	LOSS [training: 0.021913080500122396 | validation: 0.051086918270675206]
	TIME [epoch: 42 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019251002037509835		[learning rate: 0.0015357]
	Learning Rate: 0.00153573
	LOSS [training: 0.019251002037509835 | validation: 0.05241427314516289]
	TIME [epoch: 42 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020004232040672733		[learning rate: 0.0015209]
	Learning Rate: 0.00152092
	LOSS [training: 0.020004232040672733 | validation: 0.05347764999178994]
	TIME [epoch: 42 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018341733147629633		[learning rate: 0.0015062]
	Learning Rate: 0.00150624
	LOSS [training: 0.018341733147629633 | validation: 0.05304944392941302]
	TIME [epoch: 42 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021238972197279084		[learning rate: 0.0014917]
	Learning Rate: 0.00149171
	LOSS [training: 0.021238972197279084 | validation: 0.04928212497665981]
	TIME [epoch: 42 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02100240931049177		[learning rate: 0.0014773]
	Learning Rate: 0.00147732
	LOSS [training: 0.02100240931049177 | validation: 0.05423135466032767]
	TIME [epoch: 42 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021287060544841443		[learning rate: 0.0014631]
	Learning Rate: 0.00146306
	LOSS [training: 0.021287060544841443 | validation: 0.04905752126440775]
	TIME [epoch: 42 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018350053628734077		[learning rate: 0.0014489]
	Learning Rate: 0.00144895
	LOSS [training: 0.018350053628734077 | validation: 0.0523243983569105]
	TIME [epoch: 42 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01986874580943362		[learning rate: 0.001435]
	Learning Rate: 0.00143497
	LOSS [training: 0.01986874580943362 | validation: 0.053747422804174036]
	TIME [epoch: 42 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020653391521563307		[learning rate: 0.0014211]
	Learning Rate: 0.00142112
	LOSS [training: 0.020653391521563307 | validation: 0.04857334581680712]
	TIME [epoch: 42 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02095708997522904		[learning rate: 0.0014074]
	Learning Rate: 0.00140741
	LOSS [training: 0.02095708997522904 | validation: 0.048385309988339384]
	TIME [epoch: 42 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01962118337698006		[learning rate: 0.0013938]
	Learning Rate: 0.00139383
	LOSS [training: 0.01962118337698006 | validation: 0.04961029938574837]
	TIME [epoch: 42 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018824288171366214		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.018824288171366214 | validation: 0.05072841280559587]
	TIME [epoch: 42 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020845206707237		[learning rate: 0.0013671]
	Learning Rate: 0.00136707
	LOSS [training: 0.02020845206707237 | validation: 0.051685612669330194]
	TIME [epoch: 42 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019310397436593456		[learning rate: 0.0013539]
	Learning Rate: 0.00135388
	LOSS [training: 0.019310397436593456 | validation: 0.05008368643110674]
	TIME [epoch: 42 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019751437122604028		[learning rate: 0.0013408]
	Learning Rate: 0.00134081
	LOSS [training: 0.019751437122604028 | validation: 0.04987834855132008]
	TIME [epoch: 42 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01958959245680693		[learning rate: 0.0013279]
	Learning Rate: 0.00132788
	LOSS [training: 0.01958959245680693 | validation: 0.05154230291334954]
	TIME [epoch: 42 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0178148678110117		[learning rate: 0.0013151]
	Learning Rate: 0.00131507
	LOSS [training: 0.0178148678110117 | validation: 0.052092082662228575]
	TIME [epoch: 42 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845328253251416		[learning rate: 0.0013024]
	Learning Rate: 0.00130238
	LOSS [training: 0.01845328253251416 | validation: 0.05143408350809685]
	TIME [epoch: 41.9 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019403171886739755		[learning rate: 0.0012898]
	Learning Rate: 0.00128981
	LOSS [training: 0.019403171886739755 | validation: 0.050817859001410906]
	TIME [epoch: 41.9 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019750644947501162		[learning rate: 0.0012774]
	Learning Rate: 0.00127737
	LOSS [training: 0.019750644947501162 | validation: 0.0485177269013355]
	TIME [epoch: 42 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020099567429939916		[learning rate: 0.001265]
	Learning Rate: 0.00126504
	LOSS [training: 0.020099567429939916 | validation: 0.049594751534719594]
	TIME [epoch: 42 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021602954384568825		[learning rate: 0.0012528]
	Learning Rate: 0.00125284
	LOSS [training: 0.021602954384568825 | validation: 0.051760005360196155]
	TIME [epoch: 42 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019254676235952346		[learning rate: 0.0012407]
	Learning Rate: 0.00124075
	LOSS [training: 0.019254676235952346 | validation: 0.051039693355151114]
	TIME [epoch: 42 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021080112308188445		[learning rate: 0.0012288]
	Learning Rate: 0.00122878
	LOSS [training: 0.021080112308188445 | validation: 0.052077843019227014]
	TIME [epoch: 42 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01850474086464554		[learning rate: 0.0012169]
	Learning Rate: 0.00121692
	LOSS [training: 0.01850474086464554 | validation: 0.05269709449552182]
	TIME [epoch: 42 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020396446311498985		[learning rate: 0.0012052]
	Learning Rate: 0.00120518
	LOSS [training: 0.020396446311498985 | validation: 0.05523411656891641]
	TIME [epoch: 42 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020125487670166364		[learning rate: 0.0011936]
	Learning Rate: 0.00119355
	LOSS [training: 0.020125487670166364 | validation: 0.051898826276747106]
	TIME [epoch: 42 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01944125656885969		[learning rate: 0.001182]
	Learning Rate: 0.00118204
	LOSS [training: 0.01944125656885969 | validation: 0.050077092971740636]
	TIME [epoch: 42 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019466787061067043		[learning rate: 0.0011706]
	Learning Rate: 0.00117063
	LOSS [training: 0.019466787061067043 | validation: 0.04863950934363247]
	TIME [epoch: 42.1 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02542457209668361		[learning rate: 0.0011593]
	Learning Rate: 0.00115934
	LOSS [training: 0.02542457209668361 | validation: 0.051848716574096676]
	TIME [epoch: 42 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022492642142071542		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.022492642142071542 | validation: 0.05140129219825874]
	TIME [epoch: 42 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020123750231625		[learning rate: 0.0011371]
	Learning Rate: 0.00113708
	LOSS [training: 0.02020123750231625 | validation: 0.05774478399742648]
	TIME [epoch: 42 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018688741861381093		[learning rate: 0.0011261]
	Learning Rate: 0.00112611
	LOSS [training: 0.018688741861381093 | validation: 0.04848201426129592]
	TIME [epoch: 42 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019348076735675613		[learning rate: 0.0011152]
	Learning Rate: 0.00111524
	LOSS [training: 0.019348076735675613 | validation: 0.04873312674630733]
	TIME [epoch: 42 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019913060823900354		[learning rate: 0.0011045]
	Learning Rate: 0.00110448
	LOSS [training: 0.019913060823900354 | validation: 0.048718077596333814]
	TIME [epoch: 41.9 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018642298675504678		[learning rate: 0.0010938]
	Learning Rate: 0.00109382
	LOSS [training: 0.018642298675504678 | validation: 0.050723528515165754]
	TIME [epoch: 42 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018944220532217507		[learning rate: 0.0010833]
	Learning Rate: 0.00108327
	LOSS [training: 0.018944220532217507 | validation: 0.051403042147541385]
	TIME [epoch: 42 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019081559857297564		[learning rate: 0.0010728]
	Learning Rate: 0.00107282
	LOSS [training: 0.019081559857297564 | validation: 0.05003941202579093]
	TIME [epoch: 42 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.016779417804684213		[learning rate: 0.0010625]
	Learning Rate: 0.00106247
	LOSS [training: 0.016779417804684213 | validation: 0.049711702172229214]
	TIME [epoch: 41.9 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0202956294907414		[learning rate: 0.0010522]
	Learning Rate: 0.00105222
	LOSS [training: 0.0202956294907414 | validation: 0.05119756017126034]
	TIME [epoch: 42 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01804631667203956		[learning rate: 0.0010421]
	Learning Rate: 0.00104206
	LOSS [training: 0.01804631667203956 | validation: 0.04902791003406175]
	TIME [epoch: 42 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01940267825399928		[learning rate: 0.001032]
	Learning Rate: 0.00103201
	LOSS [training: 0.01940267825399928 | validation: 0.0515969879230955]
	TIME [epoch: 42 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018934553248530772		[learning rate: 0.0010221]
	Learning Rate: 0.00102205
	LOSS [training: 0.018934553248530772 | validation: 0.04869268316341291]
	TIME [epoch: 42 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018612572942243402		[learning rate: 0.0010122]
	Learning Rate: 0.00101219
	LOSS [training: 0.018612572942243402 | validation: 0.0490706314499638]
	TIME [epoch: 42 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02225572208715878		[learning rate: 0.0010024]
	Learning Rate: 0.00100243
	LOSS [training: 0.02225572208715878 | validation: 0.050647617659107566]
	TIME [epoch: 41.9 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020548414562127516		[learning rate: 0.00099275]
	Learning Rate: 0.000992755
	LOSS [training: 0.020548414562127516 | validation: 0.04896013597323713]
	TIME [epoch: 41.9 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017862503569139255		[learning rate: 0.00098318]
	Learning Rate: 0.000983177
	LOSS [training: 0.017862503569139255 | validation: 0.04981941144156418]
	TIME [epoch: 42 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022165874728814067		[learning rate: 0.00097369]
	Learning Rate: 0.000973691
	LOSS [training: 0.022165874728814067 | validation: 0.050521886574654895]
	TIME [epoch: 42 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802694329081701		[learning rate: 0.0009643]
	Learning Rate: 0.000964296
	LOSS [training: 0.01802694329081701 | validation: 0.04956170304584815]
	TIME [epoch: 42 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019638012462211387		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.019638012462211387 | validation: 0.048974544537848184]
	TIME [epoch: 42 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02297617987282298		[learning rate: 0.00094578]
	Learning Rate: 0.000945779
	LOSS [training: 0.02297617987282298 | validation: 0.05131645100199025]
	TIME [epoch: 42 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020080750287826826		[learning rate: 0.00093665]
	Learning Rate: 0.000936653
	LOSS [training: 0.020080750287826826 | validation: 0.048854439837178236]
	TIME [epoch: 42 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019460853184416947		[learning rate: 0.00092762]
	Learning Rate: 0.000927616
	LOSS [training: 0.019460853184416947 | validation: 0.04901749986407932]
	TIME [epoch: 42 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01812496331003211		[learning rate: 0.00091867]
	Learning Rate: 0.000918666
	LOSS [training: 0.01812496331003211 | validation: 0.050601673263951666]
	TIME [epoch: 42 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.022133408673303177		[learning rate: 0.0009098]
	Learning Rate: 0.000909803
	LOSS [training: 0.022133408673303177 | validation: 0.052119337521358236]
	TIME [epoch: 41.9 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.021298335785151473		[learning rate: 0.00090102]
	Learning Rate: 0.000901025
	LOSS [training: 0.021298335785151473 | validation: 0.05002128319072848]
	TIME [epoch: 42 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020334884964047485		[learning rate: 0.00089233]
	Learning Rate: 0.000892332
	LOSS [training: 0.020334884964047485 | validation: 0.05227757918373201]
	TIME [epoch: 42 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018999224087836112		[learning rate: 0.00088372]
	Learning Rate: 0.000883722
	LOSS [training: 0.018999224087836112 | validation: 0.048273749115313146]
	TIME [epoch: 42 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018682948360799152		[learning rate: 0.0008752]
	Learning Rate: 0.000875196
	LOSS [training: 0.018682948360799152 | validation: 0.05165843571169328]
	TIME [epoch: 42 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017756659375649027		[learning rate: 0.00086675]
	Learning Rate: 0.000866752
	LOSS [training: 0.017756659375649027 | validation: 0.04895638117423389]
	TIME [epoch: 42 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019358405910944874		[learning rate: 0.00085839]
	Learning Rate: 0.000858389
	LOSS [training: 0.019358405910944874 | validation: 0.050842199743206105]
	TIME [epoch: 42 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01858986430019587		[learning rate: 0.00085011]
	Learning Rate: 0.000850107
	LOSS [training: 0.01858986430019587 | validation: 0.04874862485760935]
	TIME [epoch: 42.1 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.0199649959400362		[learning rate: 0.00084191]
	Learning Rate: 0.000841905
	LOSS [training: 0.0199649959400362 | validation: 0.05527333484919482]
	TIME [epoch: 41.9 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020292489381533343		[learning rate: 0.00083378]
	Learning Rate: 0.000833782
	LOSS [training: 0.020292489381533343 | validation: 0.0492736977576154]
	TIME [epoch: 42 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018136985214552648		[learning rate: 0.00082574]
	Learning Rate: 0.000825738
	LOSS [training: 0.018136985214552648 | validation: 0.052754997842243294]
	TIME [epoch: 41.9 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01778898466452159		[learning rate: 0.00081777]
	Learning Rate: 0.000817771
	LOSS [training: 0.01778898466452159 | validation: 0.04998406048060596]
	TIME [epoch: 42 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01794414994896682		[learning rate: 0.00080988]
	Learning Rate: 0.000809881
	LOSS [training: 0.01794414994896682 | validation: 0.05072247043859219]
	TIME [epoch: 41.9 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018138205227176817		[learning rate: 0.00080207]
	Learning Rate: 0.000802067
	LOSS [training: 0.018138205227176817 | validation: 0.04772352056615178]
	TIME [epoch: 42.1 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018258521589816883		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.018258521589816883 | validation: 0.048000978927254224]
	TIME [epoch: 42 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.02068926706721951		[learning rate: 0.00078666]
	Learning Rate: 0.000786664
	LOSS [training: 0.02068926706721951 | validation: 0.05102491570348563]
	TIME [epoch: 42.1 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020689101918972955		[learning rate: 0.00077907]
	Learning Rate: 0.000779074
	LOSS [training: 0.020689101918972955 | validation: 0.05069524176233323]
	TIME [epoch: 127 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018962202531678293		[learning rate: 0.00077156]
	Learning Rate: 0.000771558
	LOSS [training: 0.018962202531678293 | validation: 0.049980271526534815]
	TIME [epoch: 86.1 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017809985169108634		[learning rate: 0.00076411]
	Learning Rate: 0.000764113
	LOSS [training: 0.017809985169108634 | validation: 0.051126059841460625]
	TIME [epoch: 86 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019369533089312843		[learning rate: 0.00075674]
	Learning Rate: 0.000756741
	LOSS [training: 0.019369533089312843 | validation: 0.049495986772946005]
	TIME [epoch: 85.9 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01826423672788513		[learning rate: 0.00074944]
	Learning Rate: 0.00074944
	LOSS [training: 0.01826423672788513 | validation: 0.04950929828904024]
	TIME [epoch: 85.9 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017559636299856563		[learning rate: 0.00074221]
	Learning Rate: 0.000742209
	LOSS [training: 0.017559636299856563 | validation: 0.04952433574740967]
	TIME [epoch: 86 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.019084618944749606		[learning rate: 0.00073505]
	Learning Rate: 0.000735048
	LOSS [training: 0.019084618944749606 | validation: 0.05029082185249109]
	TIME [epoch: 86 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017674295860952916		[learning rate: 0.00072796]
	Learning Rate: 0.000727956
	LOSS [training: 0.017674295860952916 | validation: 0.05213160293164249]
	TIME [epoch: 86.1 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018588184848709197		[learning rate: 0.00072093]
	Learning Rate: 0.000720933
	LOSS [training: 0.018588184848709197 | validation: 0.04910394182648577]
	TIME [epoch: 85.9 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.020879951922326154		[learning rate: 0.00071398]
	Learning Rate: 0.000713977
	LOSS [training: 0.020879951922326154 | validation: 0.04729487392333381]
	TIME [epoch: 85.9 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017815926630283828		[learning rate: 0.00070709]
	Learning Rate: 0.000707088
	LOSS [training: 0.017815926630283828 | validation: 0.04986971622393672]
	TIME [epoch: 86.1 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01752869626945741		[learning rate: 0.00070027]
	Learning Rate: 0.000700266
	LOSS [training: 0.01752869626945741 | validation: 0.0483986615731919]
	TIME [epoch: 85.9 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018004863817336462		[learning rate: 0.00069351]
	Learning Rate: 0.00069351
	LOSS [training: 0.018004863817336462 | validation: 0.049995526960532125]
	TIME [epoch: 86 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018225825050865868		[learning rate: 0.00068682]
	Learning Rate: 0.000686819
	LOSS [training: 0.018225825050865868 | validation: 0.04964851508918788]
	TIME [epoch: 86 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017477417648075384		[learning rate: 0.00068019]
	Learning Rate: 0.000680192
	LOSS [training: 0.017477417648075384 | validation: 0.049444015871578206]
	TIME [epoch: 86.1 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01973044519411077		[learning rate: 0.00067363]
	Learning Rate: 0.000673629
	LOSS [training: 0.01973044519411077 | validation: 0.049875646625255954]
	TIME [epoch: 86 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018048300858284242		[learning rate: 0.00066713]
	Learning Rate: 0.00066713
	LOSS [training: 0.018048300858284242 | validation: 0.04806298996406515]
	TIME [epoch: 86 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.018013451043955235		[learning rate: 0.00066069]
	Learning Rate: 0.000660693
	LOSS [training: 0.018013451043955235 | validation: 0.05113134961263974]
	TIME [epoch: 86 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017076191489984547		[learning rate: 0.00065432]
	Learning Rate: 0.000654319
	LOSS [training: 0.017076191489984547 | validation: 0.05019215621351923]
	TIME [epoch: 86.1 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01845999180901434		[learning rate: 0.00064801]
	Learning Rate: 0.000648006
	LOSS [training: 0.01845999180901434 | validation: 0.05091666316460921]
	TIME [epoch: 86 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01775340280882603		[learning rate: 0.00064175]
	Learning Rate: 0.000641754
	LOSS [training: 0.01775340280882603 | validation: 0.051237824342716856]
	TIME [epoch: 86.1 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.01659493173913114		[learning rate: 0.00063556]
	Learning Rate: 0.000635562
	LOSS [training: 0.01659493173913114 | validation: 0.04872504936876168]
	TIME [epoch: 85.9 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.017651968083729295		[learning rate: 0.00062943]
	Learning Rate: 0.00062943
	LOSS [training: 0.017651968083729295 | validation: 0.04784174741262234]
	TIME [epoch: 86 sec]
	Saving model to: out/model_training/model_facs_dec2_v1_argset2_20241207_171612/states/model_facs_dec2_v1_argset2_323.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 9124.079 seconds.
