Args:
Namespace(name='model_facs_dec1_v1_argset2', outdir='out/model_training/model_facs_dec1_v1_argset2', training_data='data/training_data/facs/facs_dec1_v1/training', validation_data='data/training_data/facs/facs_dec1_v1/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.3547579050064087], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1205230343

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2141732652236391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2141732652236391 | validation: 0.17384458235084693]
	TIME [epoch: 31.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20376829458412923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.20376829458412923 | validation: 0.1666997950217857]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19730050824216208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.19730050824216208 | validation: 0.15942766622015636]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18960858552448767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18960858552448767 | validation: 0.15480458288292942]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.18642636158878842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.18642636158878842 | validation: 0.15057507827630484]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.181457336931203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.181457336931203 | validation: 0.14830422923734804]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1748366129732044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1748366129732044 | validation: 0.13707620889145652]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1715393905739512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1715393905739512 | validation: 0.13288597536877825]
	TIME [epoch: 8.64 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.16015632882694603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.16015632882694603 | validation: 0.12670739782736257]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.14769896675358282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14769896675358282 | validation: 0.11716738335778662]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.13400791783326627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13400791783326627 | validation: 0.13047064076228737]
	TIME [epoch: 8.29 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.11731274055688944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11731274055688944 | validation: 0.10590389107537823]
	TIME [epoch: 8.29 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.12767844635761802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12767844635761802 | validation: 0.11425442968798136]
	TIME [epoch: 8.31 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1150617243402116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1150617243402116 | validation: 0.09947090878571958]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.10530044813832601		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10530044813832601 | validation: 0.10525644757933714]
	TIME [epoch: 8.29 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.09473944536424739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09473944536424739 | validation: 0.09000399967712083]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.09388867430046031		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09388867430046031 | validation: 0.09398242626965483]
	TIME [epoch: 8.35 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.09429496206729743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09429496206729743 | validation: 0.08653264364055072]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.09151678238443418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09151678238443418 | validation: 0.07454116032109927]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.073204624941293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.073204624941293 | validation: 0.06779226901789465]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.07004419890937075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07004419890937075 | validation: 0.06496783172718293]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0746216585858637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0746216585858637 | validation: 0.058638600434406066]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.06492977375074711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06492977375074711 | validation: 0.05522620014573258]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.06122726612869741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06122726612869741 | validation: 0.053663977712436806]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.06739310684313021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06739310684313021 | validation: 0.04996204365972965]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.056421180580278486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.056421180580278486 | validation: 0.052477554027004894]
	TIME [epoch: 8.3 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05873130035645902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05873130035645902 | validation: 0.0523730712525058]
	TIME [epoch: 8.29 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0574300441930111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0574300441930111 | validation: 0.04661286807008096]
	TIME [epoch: 8.33 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05719352807881358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05719352807881358 | validation: 0.0459032886770941]
	TIME [epoch: 8.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.06077583223343833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06077583223343833 | validation: 0.045225376108858704]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.055473488368322395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055473488368322395 | validation: 0.045466231515153666]
	TIME [epoch: 8.33 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.054378110282468445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054378110282468445 | validation: 0.045000257179539226]
	TIME [epoch: 8.34 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.052605617028154084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.052605617028154084 | validation: 0.04810925906033337]
	TIME [epoch: 8.32 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0532629178312535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0532629178312535 | validation: 0.04561639466971629]
	TIME [epoch: 8.33 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05439452146706677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05439452146706677 | validation: 0.04705717950312202]
	TIME [epoch: 8.33 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05253328186591411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05253328186591411 | validation: 0.044905071682614636]
	TIME [epoch: 8.31 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05387712114833166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05387712114833166 | validation: 0.04523049523300861]
	TIME [epoch: 8.32 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05730237670826627		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05730237670826627 | validation: 0.04536401645494013]
	TIME [epoch: 8.31 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05965932383681413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05965932383681413 | validation: 0.04249409891677151]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_39.pth
	Model improved!!!
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.055294351461313555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.055294351461313555 | validation: 0.04582148191848441]
	TIME [epoch: 8.32 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05719018216909603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05719018216909603 | validation: 0.044863983589327146]
	TIME [epoch: 8.32 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.054950934024273645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.054950934024273645 | validation: 0.04181158970919256]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05112207874611044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05112207874611044 | validation: 0.045276418144108384]
	TIME [epoch: 8.32 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05147245643680848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05147245643680848 | validation: 0.04229393622876052]
	TIME [epoch: 8.32 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05410344573841164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05410344573841164 | validation: 0.04400046367689024]
	TIME [epoch: 8.32 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05220182932744457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05220182932744457 | validation: 0.04664322308920836]
	TIME [epoch: 8.32 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05110821462089881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05110821462089881 | validation: 0.045182771190694596]
	TIME [epoch: 8.32 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05074296034021538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05074296034021538 | validation: 0.04094169147529177]
	TIME [epoch: 8.32 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05096780997639915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05096780997639915 | validation: 0.04131320054847097]
	TIME [epoch: 8.32 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.049064822640653157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049064822640653157 | validation: 0.04250339517992482]
	TIME [epoch: 8.32 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05146324025689203		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.05146324025689203 | validation: 0.0406065712699236]
	TIME [epoch: 37.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.051263213525652045		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.051263213525652045 | validation: 0.042436008902832334]
	TIME [epoch: 16.1 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.052682817120766855		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.052682817120766855 | validation: 0.041223681057804315]
	TIME [epoch: 16.1 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05269006739888782		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.05269006739888782 | validation: 0.042528220910500444]
	TIME [epoch: 16.1 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05147037087548892		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.05147037087548892 | validation: 0.040644677853263964]
	TIME [epoch: 16.1 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.048502332227659685		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.048502332227659685 | validation: 0.04386254834148322]
	TIME [epoch: 16 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05196175923145114		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.05196175923145114 | validation: 0.04251522820370046]
	TIME [epoch: 16.1 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04845044880710783		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.04845044880710783 | validation: 0.040245826001571935]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04969305421097673		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.04969305421097673 | validation: 0.03892857017248586]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05144580377706081		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.05144580377706081 | validation: 0.03988556796550154]
	TIME [epoch: 16.1 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05127941014240836		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.05127941014240836 | validation: 0.04035645167525848]
	TIME [epoch: 16.1 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.048949408313784575		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.048949408313784575 | validation: 0.0440831076901833]
	TIME [epoch: 16.1 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.05015405276500812		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.05015405276500812 | validation: 0.04078273166334433]
	TIME [epoch: 16.1 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0483389677585821		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.0483389677585821 | validation: 0.0400776139205778]
	TIME [epoch: 16.1 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0522011626405531		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.0522011626405531 | validation: 0.040192635921550604]
	TIME [epoch: 16 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.047107703804384456		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.047107703804384456 | validation: 0.03983400982483763]
	TIME [epoch: 16.1 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04877290345545974		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.04877290345545974 | validation: 0.03997320192838165]
	TIME [epoch: 16.1 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04925907421036948		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.04925907421036948 | validation: 0.04272847091382496]
	TIME [epoch: 16.1 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.049609191274088214		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.049609191274088214 | validation: 0.03883000635891539]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04883808744325955		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.04883808744325955 | validation: 0.039773326339625145]
	TIME [epoch: 16.1 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04790366180575159		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.04790366180575159 | validation: 0.04155416634210086]
	TIME [epoch: 16 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04907861290185742		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.04907861290185742 | validation: 0.041829838412554055]
	TIME [epoch: 16.1 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04703773767988528		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.04703773767988528 | validation: 0.04334908366530695]
	TIME [epoch: 16.1 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04828402621225459		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.04828402621225459 | validation: 0.04301586115005951]
	TIME [epoch: 16.1 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04762487028442735		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.04762487028442735 | validation: 0.04007121950707961]
	TIME [epoch: 16.1 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.049320369572332344		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.049320369572332344 | validation: 0.03802884877557998]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04788362250984834		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.04788362250984834 | validation: 0.037977584399069717]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045451108055761295		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.045451108055761295 | validation: 0.04005243693909712]
	TIME [epoch: 16 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.049443630295771264		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.049443630295771264 | validation: 0.03996939454311605]
	TIME [epoch: 16 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04694185024924418		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.04694185024924418 | validation: 0.0444126628816878]
	TIME [epoch: 16.1 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04961370322594372		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.04961370322594372 | validation: 0.0397749586517427]
	TIME [epoch: 16.1 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04737230437514445		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.04737230437514445 | validation: 0.038755791597451704]
	TIME [epoch: 16.1 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04828853653010164		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.04828853653010164 | validation: 0.03856537701165333]
	TIME [epoch: 16.1 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04902840188114998		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.04902840188114998 | validation: 0.042209543466326604]
	TIME [epoch: 16.1 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04819811620172373		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.04819811620172373 | validation: 0.037665644001124425]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_85.pth
	Model improved!!!
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04844878563496899		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.04844878563496899 | validation: 0.03983736619742193]
	TIME [epoch: 16.1 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.057607561524988964		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.057607561524988964 | validation: 0.039617413472253823]
	TIME [epoch: 16 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.046840313441243224		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.046840313441243224 | validation: 0.03856970633235214]
	TIME [epoch: 16.1 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045877359164688124		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.045877359164688124 | validation: 0.0402866281811043]
	TIME [epoch: 16 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04655485515068434		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.04655485515068434 | validation: 0.03886604663347874]
	TIME [epoch: 16.1 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04617437102205099		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.04617437102205099 | validation: 0.039817078356692716]
	TIME [epoch: 16 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0476002656689453		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.0476002656689453 | validation: 0.03774478676417191]
	TIME [epoch: 16.1 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04520825710464526		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.04520825710464526 | validation: 0.038487856327236454]
	TIME [epoch: 16 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.048348415024011084		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.048348415024011084 | validation: 0.037900210808443614]
	TIME [epoch: 16.1 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04742181388613225		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.04742181388613225 | validation: 0.03710270608411727]
	TIME [epoch: 16.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04613211456296761		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.04613211456296761 | validation: 0.03817105128287157]
	TIME [epoch: 16 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04639773516047804		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.04639773516047804 | validation: 0.038747394774546896]
	TIME [epoch: 16 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04564532447036814		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.04564532447036814 | validation: 0.03753549415371732]
	TIME [epoch: 16 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0457808530043901		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.0457808530043901 | validation: 0.039292346463044865]
	TIME [epoch: 16 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04632332089764032		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.04632332089764032 | validation: 0.036131387986457056]
	TIME [epoch: 16 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_100.pth
	Model improved!!!
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04583997594978773		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.04583997594978773 | validation: 0.03777966150929188]
	TIME [epoch: 55.8 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043647915342826756		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.043647915342826756 | validation: 0.03822041008848492]
	TIME [epoch: 33.9 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0457778777178145		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.0457778777178145 | validation: 0.03753611865714127]
	TIME [epoch: 33.8 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045666586862460994		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.045666586862460994 | validation: 0.03872056164319606]
	TIME [epoch: 33.8 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04845084310257478		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.04845084310257478 | validation: 0.037276640665578877]
	TIME [epoch: 33.8 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04671859724480831		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.04671859724480831 | validation: 0.03766610918699259]
	TIME [epoch: 33.9 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04570972811373438		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.04570972811373438 | validation: 0.037849316702412795]
	TIME [epoch: 33.8 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0463877889802948		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.0463877889802948 | validation: 0.03745221065855475]
	TIME [epoch: 33.9 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.047093452085962745		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.047093452085962745 | validation: 0.03759707533932059]
	TIME [epoch: 33.8 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04580200338536742		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.04580200338536742 | validation: 0.03771205111338458]
	TIME [epoch: 33.9 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04674480245386887		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.04674480245386887 | validation: 0.037158715826067674]
	TIME [epoch: 33.8 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04547531537012419		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.04547531537012419 | validation: 0.03831961885392725]
	TIME [epoch: 33.8 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.046754945005033764		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.046754945005033764 | validation: 0.03770386055650747]
	TIME [epoch: 33.8 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044335542837410334		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.044335542837410334 | validation: 0.03836445458502593]
	TIME [epoch: 33.8 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04829250641393625		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.04829250641393625 | validation: 0.03802847673317913]
	TIME [epoch: 33.8 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04493734104038403		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.04493734104038403 | validation: 0.03690027010741943]
	TIME [epoch: 33.8 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045952119835994364		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.045952119835994364 | validation: 0.03729850913880237]
	TIME [epoch: 33.8 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.046643010922264916		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.046643010922264916 | validation: 0.037028525484987855]
	TIME [epoch: 33.8 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04576545453627678		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.04576545453627678 | validation: 0.03708411476998694]
	TIME [epoch: 33.8 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04573051551423824		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.04573051551423824 | validation: 0.03686631155627178]
	TIME [epoch: 33.8 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045444505902308356		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.045444505902308356 | validation: 0.03664380917628908]
	TIME [epoch: 33.8 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045892582214086854		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.045892582214086854 | validation: 0.0376341353929459]
	TIME [epoch: 33.8 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04616741550395637		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.04616741550395637 | validation: 0.03604055367487924]
	TIME [epoch: 33.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04443735335247403		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.04443735335247403 | validation: 0.036204718437795096]
	TIME [epoch: 33.8 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04573609856849206		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.04573609856849206 | validation: 0.038582864536711795]
	TIME [epoch: 33.8 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0461803042462145		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.0461803042462145 | validation: 0.03690634261712491]
	TIME [epoch: 33.8 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044683903386063505		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.044683903386063505 | validation: 0.0372485376320542]
	TIME [epoch: 33.8 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04464779929765179		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.04464779929765179 | validation: 0.037583119629470696]
	TIME [epoch: 33.8 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0454938430814345		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.0454938430814345 | validation: 0.036737469918245926]
	TIME [epoch: 33.8 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045835662945308275		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.045835662945308275 | validation: 0.03953316793666435]
	TIME [epoch: 33.8 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04521299457814023		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.04521299457814023 | validation: 0.03749517772447482]
	TIME [epoch: 33.8 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04470134259654068		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.04470134259654068 | validation: 0.03757378886350438]
	TIME [epoch: 33.8 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04692493815784413		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.04692493815784413 | validation: 0.037119559809498166]
	TIME [epoch: 33.8 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0437116338121916		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.0437116338121916 | validation: 0.03819293525359273]
	TIME [epoch: 33.8 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04469974759446691		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.04469974759446691 | validation: 0.03921435737579011]
	TIME [epoch: 33.8 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045729316575431556		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.045729316575431556 | validation: 0.036850437733609444]
	TIME [epoch: 33.8 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045731090376477324		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.045731090376477324 | validation: 0.03678732867033495]
	TIME [epoch: 33.8 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04637986560734358		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.04637986560734358 | validation: 0.03773212949549648]
	TIME [epoch: 33.8 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044966378679577035		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.044966378679577035 | validation: 0.037291730619270665]
	TIME [epoch: 33.8 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04481959225911435		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.04481959225911435 | validation: 0.036650542272643194]
	TIME [epoch: 33.8 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04491979218070715		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.04491979218070715 | validation: 0.039500523941429166]
	TIME [epoch: 33.8 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044921223072157866		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.044921223072157866 | validation: 0.03580692369404453]
	TIME [epoch: 33.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_142.pth
	Model improved!!!
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04538042300081269		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.04538042300081269 | validation: 0.03747968988037686]
	TIME [epoch: 33.8 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045745433615553534		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.045745433615553534 | validation: 0.03645909479955072]
	TIME [epoch: 33.8 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045507445429132355		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.045507445429132355 | validation: 0.036745816359321656]
	TIME [epoch: 33.8 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04424766424940838		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.04424766424940838 | validation: 0.03656886962964]
	TIME [epoch: 33.9 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044916224878874644		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.044916224878874644 | validation: 0.036479715657915905]
	TIME [epoch: 33.8 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045004681707813826		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.045004681707813826 | validation: 0.03672451563835601]
	TIME [epoch: 33.9 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.046126711142680216		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.046126711142680216 | validation: 0.0378290512008778]
	TIME [epoch: 33.9 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04632635468113011		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.04632635468113011 | validation: 0.036850476147147836]
	TIME [epoch: 33.9 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04422853058027787		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.04422853058027787 | validation: 0.03669727256929818]
	TIME [epoch: 33.9 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043716030598849785		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.043716030598849785 | validation: 0.0367037808215298]
	TIME [epoch: 33.8 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04493091103636396		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.04493091103636396 | validation: 0.03712595408597184]
	TIME [epoch: 33.8 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04416920818768544		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.04416920818768544 | validation: 0.036961247962376494]
	TIME [epoch: 33.8 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04599336881687657		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.04599336881687657 | validation: 0.03666625082713348]
	TIME [epoch: 33.8 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04422916300693774		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.04422916300693774 | validation: 0.0369056136426164]
	TIME [epoch: 33.8 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045221143372259354		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.045221143372259354 | validation: 0.03689054802777285]
	TIME [epoch: 33.8 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045050373062281206		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.045050373062281206 | validation: 0.036846023756544596]
	TIME [epoch: 33.9 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044976952511331936		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.044976952511331936 | validation: 0.036837086105608235]
	TIME [epoch: 33.8 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04435025567362603		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.04435025567362603 | validation: 0.0376421001162426]
	TIME [epoch: 33.8 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04534109364740116		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.04534109364740116 | validation: 0.03634809187272174]
	TIME [epoch: 33.8 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04351720157730341		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.04351720157730341 | validation: 0.03684960972992407]
	TIME [epoch: 33.8 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04564350330744877		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.04564350330744877 | validation: 0.03698193139488404]
	TIME [epoch: 33.8 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044368874187472686		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.044368874187472686 | validation: 0.03665824048276078]
	TIME [epoch: 33.8 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04386272206186285		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.04386272206186285 | validation: 0.03556892733485608]
	TIME [epoch: 33.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_165.pth
	Model improved!!!
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04410393572761509		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.04410393572761509 | validation: 0.03638733889907229]
	TIME [epoch: 33.9 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04400455669410008		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.04400455669410008 | validation: 0.03601874235004372]
	TIME [epoch: 33.8 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045550619122793484		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.045550619122793484 | validation: 0.03695522281873746]
	TIME [epoch: 33.9 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04370742327216309		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.04370742327216309 | validation: 0.03732165300009171]
	TIME [epoch: 33.8 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04448696069865843		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.04448696069865843 | validation: 0.03744424430931564]
	TIME [epoch: 33.9 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04370075180362933		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.04370075180362933 | validation: 0.039646195994046306]
	TIME [epoch: 33.8 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044504123828170115		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.044504123828170115 | validation: 0.03667695731384763]
	TIME [epoch: 33.9 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04352411738804612		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.04352411738804612 | validation: 0.037784645222888366]
	TIME [epoch: 33.9 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04347018091370553		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.04347018091370553 | validation: 0.03687050284139391]
	TIME [epoch: 33.9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044471391117381416		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.044471391117381416 | validation: 0.03636244551040184]
	TIME [epoch: 33.9 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04431599345466758		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.04431599345466758 | validation: 0.03622186334340295]
	TIME [epoch: 33.9 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045450562531755424		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.045450562531755424 | validation: 0.037849245499465126]
	TIME [epoch: 33.9 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045272081314052935		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.045272081314052935 | validation: 0.03724931895295714]
	TIME [epoch: 33.9 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04426892907099227		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.04426892907099227 | validation: 0.036083430974602176]
	TIME [epoch: 33.9 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043473401178086186		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.043473401178086186 | validation: 0.036109135571834025]
	TIME [epoch: 33.9 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0442291373641675		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.0442291373641675 | validation: 0.03768814210172247]
	TIME [epoch: 33.9 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04473022870529492		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.04473022870529492 | validation: 0.036512633693729826]
	TIME [epoch: 33.9 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04386727800988497		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.04386727800988497 | validation: 0.036511558128517384]
	TIME [epoch: 33.9 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04357689199647551		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.04357689199647551 | validation: 0.03706370858630022]
	TIME [epoch: 33.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04476125452200031		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.04476125452200031 | validation: 0.03635369651766542]
	TIME [epoch: 33.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0435175276998497		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.0435175276998497 | validation: 0.0364578909069078]
	TIME [epoch: 33.9 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04374733601221736		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.04374733601221736 | validation: 0.036476985962821014]
	TIME [epoch: 33.9 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0444458673737049		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.0444458673737049 | validation: 0.03743948692248944]
	TIME [epoch: 33.9 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044211908973586976		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.044211908973586976 | validation: 0.03745525219599534]
	TIME [epoch: 33.9 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044101881611301685		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.044101881611301685 | validation: 0.037358456920019]
	TIME [epoch: 33.9 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04492572026111055		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.04492572026111055 | validation: 0.03601424383625169]
	TIME [epoch: 33.9 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04452449664011148		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.04452449664011148 | validation: 0.036303977992530746]
	TIME [epoch: 33.9 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044056994525347726		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.044056994525347726 | validation: 0.03573903682529298]
	TIME [epoch: 33.9 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04303794915002862		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.04303794915002862 | validation: 0.03655262837869448]
	TIME [epoch: 33.9 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04357595233699497		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.04357595233699497 | validation: 0.03618726601744859]
	TIME [epoch: 33.8 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04398604071949064		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.04398604071949064 | validation: 0.03681570400865107]
	TIME [epoch: 33.9 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04386987462911087		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.04386987462911087 | validation: 0.03664912972218392]
	TIME [epoch: 33.9 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043329390879898066		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.043329390879898066 | validation: 0.036772549133357396]
	TIME [epoch: 33.9 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04436041861846479		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.04436041861846479 | validation: 0.0370132844146879]
	TIME [epoch: 33.8 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0432368204876786		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.0432368204876786 | validation: 0.03699858719842986]
	TIME [epoch: 33.9 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.045864786743664926		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.045864786743664926 | validation: 0.03725583425099724]
	TIME [epoch: 92.9 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04273939949553673		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.04273939949553673 | validation: 0.03786655827732145]
	TIME [epoch: 71.1 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04391158841956186		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.04391158841956186 | validation: 0.03663123085628039]
	TIME [epoch: 71.1 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043824917244699245		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.043824917244699245 | validation: 0.03648928426047199]
	TIME [epoch: 71.1 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04245546295729747		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.04245546295729747 | validation: 0.03594286049707828]
	TIME [epoch: 71.1 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043434061671171066		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.043434061671171066 | validation: 0.03601578102560825]
	TIME [epoch: 71.1 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044875195937847286		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.044875195937847286 | validation: 0.037176197501374776]
	TIME [epoch: 71.1 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04376014867139519		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.04376014867139519 | validation: 0.03574916357303904]
	TIME [epoch: 71.1 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04399465786020509		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.04399465786020509 | validation: 0.03667505696251094]
	TIME [epoch: 71.1 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04335740012518624		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.04335740012518624 | validation: 0.03624365385139836]
	TIME [epoch: 71.1 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04420349643224469		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.04420349643224469 | validation: 0.03660424385838896]
	TIME [epoch: 71.1 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043831758567729945		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.043831758567729945 | validation: 0.035302678397432265]
	TIME [epoch: 71.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_212.pth
	Model improved!!!
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04346721700943835		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.04346721700943835 | validation: 0.03617449140799021]
	TIME [epoch: 71.1 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043836965116547784		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.043836965116547784 | validation: 0.03643353745848038]
	TIME [epoch: 71.1 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0441194731170638		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.0441194731170638 | validation: 0.03692915885245801]
	TIME [epoch: 71.1 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044384346137266946		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.044384346137266946 | validation: 0.03677019024775653]
	TIME [epoch: 71.1 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043786340704859206		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.043786340704859206 | validation: 0.03612541093350463]
	TIME [epoch: 71.1 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04434770251834413		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.04434770251834413 | validation: 0.03697637466515874]
	TIME [epoch: 71.1 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04419627479678386		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.04419627479678386 | validation: 0.03658504906960895]
	TIME [epoch: 71.1 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04294404544528294		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.04294404544528294 | validation: 0.03645445922409874]
	TIME [epoch: 71.1 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04419069145505978		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.04419069145505978 | validation: 0.03583619014101115]
	TIME [epoch: 71.1 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04375256664605472		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.04375256664605472 | validation: 0.03641292925886212]
	TIME [epoch: 71.1 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042730278464112086		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.042730278464112086 | validation: 0.03615358670956738]
	TIME [epoch: 71.1 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043719591907163034		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.043719591907163034 | validation: 0.03639583609454404]
	TIME [epoch: 71 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04432801894273364		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.04432801894273364 | validation: 0.0360935950703758]
	TIME [epoch: 71 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04376686014237593		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.04376686014237593 | validation: 0.036104304352817564]
	TIME [epoch: 71.1 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043309985706375086		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.043309985706375086 | validation: 0.03669982500868129]
	TIME [epoch: 71.1 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04419501270934312		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.04419501270934312 | validation: 0.035933127737987805]
	TIME [epoch: 71.1 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04306695342355416		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.04306695342355416 | validation: 0.03634760979062378]
	TIME [epoch: 71.1 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04378679209554223		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.04378679209554223 | validation: 0.03673917826363261]
	TIME [epoch: 71.1 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04280497123663942		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.04280497123663942 | validation: 0.03658504243710944]
	TIME [epoch: 71.1 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043690215915764115		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.043690215915764115 | validation: 0.03664082592917305]
	TIME [epoch: 71 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044384000967703195		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.044384000967703195 | validation: 0.03653681057589693]
	TIME [epoch: 71 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042955861790245194		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.042955861790245194 | validation: 0.036163171380935784]
	TIME [epoch: 71.1 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0440532581335554		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.0440532581335554 | validation: 0.03654019406108558]
	TIME [epoch: 71.1 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04263592828012971		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.04263592828012971 | validation: 0.03637981966937535]
	TIME [epoch: 71.1 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043810176334266086		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.043810176334266086 | validation: 0.035926986685130606]
	TIME [epoch: 71.1 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0435908499272006		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.0435908499272006 | validation: 0.03564068875636468]
	TIME [epoch: 71.1 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04356668062943376		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.04356668062943376 | validation: 0.036437247027111284]
	TIME [epoch: 71 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043164089002828476		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.043164089002828476 | validation: 0.035943845132471924]
	TIME [epoch: 71 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04347345615078128		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.04347345615078128 | validation: 0.03613169975364689]
	TIME [epoch: 71.1 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04379957156369375		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.04379957156369375 | validation: 0.03588974344829636]
	TIME [epoch: 71 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04287908163348475		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.04287908163348475 | validation: 0.0361432692208397]
	TIME [epoch: 71.1 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04310592230356366		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.04310592230356366 | validation: 0.03570616162755322]
	TIME [epoch: 71 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04288376194709264		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.04288376194709264 | validation: 0.036726612510412246]
	TIME [epoch: 71.1 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042680764613898046		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.042680764613898046 | validation: 0.035769181565339744]
	TIME [epoch: 71.1 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04313567037533158		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.04313567037533158 | validation: 0.03731832186072205]
	TIME [epoch: 71.1 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04385181547675914		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.04385181547675914 | validation: 0.037004018039793064]
	TIME [epoch: 71 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044070076403073026		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.044070076403073026 | validation: 0.03620353578035797]
	TIME [epoch: 71.1 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043902936022068906		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.043902936022068906 | validation: 0.036696245640694694]
	TIME [epoch: 71 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04272459070741519		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.04272459070741519 | validation: 0.035904317749934696]
	TIME [epoch: 71 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042651870626982114		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.042651870626982114 | validation: 0.03611011798268855]
	TIME [epoch: 71 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0439781144808769		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.0439781144808769 | validation: 0.03538020526572028]
	TIME [epoch: 71 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042475376902751744		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.042475376902751744 | validation: 0.03600610780058052]
	TIME [epoch: 71.1 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04422138004570714		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.04422138004570714 | validation: 0.036495040176684604]
	TIME [epoch: 71.1 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04381868690172102		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.04381868690172102 | validation: 0.03597193524055389]
	TIME [epoch: 71 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042544673235651885		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.042544673235651885 | validation: 0.035398008480764145]
	TIME [epoch: 71.1 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042659652201294494		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.042659652201294494 | validation: 0.035587607272689045]
	TIME [epoch: 71 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043632070641523635		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.043632070641523635 | validation: 0.03583055526205977]
	TIME [epoch: 71.1 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04295185944691923		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.04295185944691923 | validation: 0.037237188283668066]
	TIME [epoch: 71 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04295837381352922		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.04295837381352922 | validation: 0.03612901384256249]
	TIME [epoch: 71.1 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042850797030326904		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.042850797030326904 | validation: 0.03674803254323886]
	TIME [epoch: 71 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04434863419616691		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.04434863419616691 | validation: 0.03612919059218317]
	TIME [epoch: 71 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043377831395335804		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.043377831395335804 | validation: 0.03544635496594554]
	TIME [epoch: 71 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04301634348373479		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.04301634348373479 | validation: 0.03666528871413088]
	TIME [epoch: 71.1 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04330392407845377		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.04330392407845377 | validation: 0.036383202145489395]
	TIME [epoch: 71 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043316058939604475		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.043316058939604475 | validation: 0.03612853642028522]
	TIME [epoch: 71.1 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04341518490983463		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.04341518490983463 | validation: 0.036464015784710445]
	TIME [epoch: 71.1 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043247980547625416		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.043247980547625416 | validation: 0.03556467529384401]
	TIME [epoch: 71 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04249719088049044		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.04249719088049044 | validation: 0.036954458737319465]
	TIME [epoch: 71 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04347082161939162		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.04347082161939162 | validation: 0.03624831061008212]
	TIME [epoch: 71.1 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043004741526409256		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.043004741526409256 | validation: 0.036565523443470666]
	TIME [epoch: 71 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042586248396485005		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.042586248396485005 | validation: 0.035760370484201325]
	TIME [epoch: 71.1 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043198257206120326		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.043198257206120326 | validation: 0.03609957100747733]
	TIME [epoch: 71 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042622875925420384		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.042622875925420384 | validation: 0.035829124617880966]
	TIME [epoch: 71.1 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04313680058622785		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.04313680058622785 | validation: 0.03653922466398141]
	TIME [epoch: 71.1 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04375438602503906		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.04375438602503906 | validation: 0.03647621719992376]
	TIME [epoch: 71 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043242393928657606		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.043242393928657606 | validation: 0.03620095250599705]
	TIME [epoch: 71.1 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043423499156661265		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.043423499156661265 | validation: 0.03649432781444909]
	TIME [epoch: 71.1 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04325256932716023		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.04325256932716023 | validation: 0.03611689408410267]
	TIME [epoch: 71.1 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0431580606810219		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.0431580606810219 | validation: 0.03594116143651971]
	TIME [epoch: 71.1 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04276611577551859		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.04276611577551859 | validation: 0.03573846517647554]
	TIME [epoch: 71.1 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04273726350684401		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.04273726350684401 | validation: 0.03610419713884035]
	TIME [epoch: 71.1 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04292162047444323		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.04292162047444323 | validation: 0.035948461292149556]
	TIME [epoch: 71.1 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04287635218392738		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.04287635218392738 | validation: 0.03568598688902826]
	TIME [epoch: 71.1 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04276807162649609		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.04276807162649609 | validation: 0.03608569947075594]
	TIME [epoch: 71.1 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043313740186808745		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.043313740186808745 | validation: 0.0358222954134509]
	TIME [epoch: 71.1 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042810042368436545		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.042810042368436545 | validation: 0.035871665792524446]
	TIME [epoch: 71 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04326482066956309		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.04326482066956309 | validation: 0.03558175045776919]
	TIME [epoch: 71.1 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04309516888601603		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.04309516888601603 | validation: 0.03589218603346855]
	TIME [epoch: 71.1 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04324539933859651		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.04324539933859651 | validation: 0.0355116115256502]
	TIME [epoch: 71.1 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04316292651830141		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.04316292651830141 | validation: 0.03607349101529066]
	TIME [epoch: 71 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043211539502350106		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.043211539502350106 | validation: 0.03642863764050121]
	TIME [epoch: 71 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04249041111206083		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.04249041111206083 | validation: 0.03517902668268756]
	TIME [epoch: 71 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_294.pth
	Model improved!!!
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04302505891314636		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.04302505891314636 | validation: 0.03602603678072769]
	TIME [epoch: 71.1 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04253916299338565		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.04253916299338565 | validation: 0.03605854995341334]
	TIME [epoch: 71.1 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043721872454211386		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.043721872454211386 | validation: 0.035894498714442745]
	TIME [epoch: 71.1 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0431489272719715		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.0431489272719715 | validation: 0.03643014145068674]
	TIME [epoch: 71.1 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04325655387003922		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.04325655387003922 | validation: 0.03580854921776776]
	TIME [epoch: 71.1 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043728454583302705		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.043728454583302705 | validation: 0.03582992207504285]
	TIME [epoch: 71.1 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04281865226394616		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.04281865226394616 | validation: 0.03576806093019473]
	TIME [epoch: 168 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042740635470136845		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.042740635470136845 | validation: 0.03524214853989619]
	TIME [epoch: 146 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0437081594963303		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.0437081594963303 | validation: 0.034823384752606955]
	TIME [epoch: 146 sec]
	Saving model to: out/model_training/model_facs_dec1_v1_argset2_20241103_092114/states/model_facs_dec1_v1_argset2_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042096013702359214		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.042096013702359214 | validation: 0.036344745559493206]
	TIME [epoch: 146 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04345429456265892		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.04345429456265892 | validation: 0.035693143660472756]
	TIME [epoch: 146 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04326953547107732		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.04326953547107732 | validation: 0.03588638865193859]
	TIME [epoch: 146 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042457059827141534		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.042457059827141534 | validation: 0.036230271543537765]
	TIME [epoch: 146 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04319820660185808		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.04319820660185808 | validation: 0.036246570129838875]
	TIME [epoch: 146 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043015933211771794		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.043015933211771794 | validation: 0.03704636556404356]
	TIME [epoch: 146 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04307330338170288		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.04307330338170288 | validation: 0.03626959558622644]
	TIME [epoch: 146 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043402120271614546		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.043402120271614546 | validation: 0.0361321106852971]
	TIME [epoch: 146 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04296605810561493		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.04296605810561493 | validation: 0.03601543504075963]
	TIME [epoch: 146 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.044420196041913135		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.044420196041913135 | validation: 0.036444890203746506]
	TIME [epoch: 146 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04415760870514715		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.04415760870514715 | validation: 0.03576173379213181]
	TIME [epoch: 146 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04309099444978717		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.04309099444978717 | validation: 0.03535281425492742]
	TIME [epoch: 146 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04179450089818554		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.04179450089818554 | validation: 0.03490417940003257]
	TIME [epoch: 146 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04289890823357299		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.04289890823357299 | validation: 0.03574969514895447]
	TIME [epoch: 145 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04297434512175227		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.04297434512175227 | validation: 0.03607277174811585]
	TIME [epoch: 146 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04341467695025922		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.04341467695025922 | validation: 0.03612278626605101]
	TIME [epoch: 146 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042897274601067764		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.042897274601067764 | validation: 0.03656418283094686]
	TIME [epoch: 146 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042330499182541725		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.042330499182541725 | validation: 0.035999193949690575]
	TIME [epoch: 146 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042588227481236474		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.042588227481236474 | validation: 0.0353858783651068]
	TIME [epoch: 146 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04209385461959089		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.04209385461959089 | validation: 0.03549900361695406]
	TIME [epoch: 146 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04292727294345889		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.04292727294345889 | validation: 0.03607471363852412]
	TIME [epoch: 146 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042286687729777804		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.042286687729777804 | validation: 0.03628897479489488]
	TIME [epoch: 146 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0433248497931358		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.0433248497931358 | validation: 0.03544108954100049]
	TIME [epoch: 146 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042153427491711436		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.042153427491711436 | validation: 0.03656772304490145]
	TIME [epoch: 146 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04312094182473276		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.04312094182473276 | validation: 0.03591042832089901]
	TIME [epoch: 146 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04252733276041374		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.04252733276041374 | validation: 0.0357992786907907]
	TIME [epoch: 146 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04198772282118882		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.04198772282118882 | validation: 0.03539101000418239]
	TIME [epoch: 146 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04282980062612932		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.04282980062612932 | validation: 0.0356639875494149]
	TIME [epoch: 146 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0430773827701244		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.0430773827701244 | validation: 0.03586577508925181]
	TIME [epoch: 146 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04283942328899371		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.04283942328899371 | validation: 0.0364407091819159]
	TIME [epoch: 146 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042589385518401975		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.042589385518401975 | validation: 0.03569160201040441]
	TIME [epoch: 146 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042150127564235834		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.042150127564235834 | validation: 0.03648734922657772]
	TIME [epoch: 146 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04250427787849814		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.04250427787849814 | validation: 0.03565751078150059]
	TIME [epoch: 146 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043029243799410144		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.043029243799410144 | validation: 0.03682992974816941]
	TIME [epoch: 146 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04300865324743642		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.04300865324743642 | validation: 0.03650617526068603]
	TIME [epoch: 146 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042629503309472294		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.042629503309472294 | validation: 0.035643673388247685]
	TIME [epoch: 146 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043523840457918184		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.043523840457918184 | validation: 0.03549211445415039]
	TIME [epoch: 146 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04196564716125203		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.04196564716125203 | validation: 0.03589398468631461]
	TIME [epoch: 146 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04269724913784725		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.04269724913784725 | validation: 0.036208196819441506]
	TIME [epoch: 146 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042995503291282655		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.042995503291282655 | validation: 0.03609782457703604]
	TIME [epoch: 146 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04303629819372199		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.04303629819372199 | validation: 0.03614052188012582]
	TIME [epoch: 146 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04265913935569909		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.04265913935569909 | validation: 0.03564844361182344]
	TIME [epoch: 146 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04324548901472116		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.04324548901472116 | validation: 0.035636036550973]
	TIME [epoch: 146 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04257645057913902		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.04257645057913902 | validation: 0.0363897732692386]
	TIME [epoch: 146 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04200404954668571		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.04200404954668571 | validation: 0.03545400612506293]
	TIME [epoch: 146 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04255066356171114		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.04255066356171114 | validation: 0.03631928746847135]
	TIME [epoch: 146 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04311836670679464		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.04311836670679464 | validation: 0.035932559093352585]
	TIME [epoch: 146 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042802748584707916		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.042802748584707916 | validation: 0.03639821745743266]
	TIME [epoch: 146 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04236115056066351		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.04236115056066351 | validation: 0.03572316631095149]
	TIME [epoch: 146 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042935522416361976		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.042935522416361976 | validation: 0.03606662455280397]
	TIME [epoch: 146 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04305953195913054		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.04305953195913054 | validation: 0.035490855560440515]
	TIME [epoch: 146 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042776042721670245		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.042776042721670245 | validation: 0.03574467551636963]
	TIME [epoch: 146 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042540884365463966		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.042540884365463966 | validation: 0.03581485247827128]
	TIME [epoch: 146 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042498253258730634		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.042498253258730634 | validation: 0.03602078466588508]
	TIME [epoch: 146 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04207995022611643		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.04207995022611643 | validation: 0.03556353331660476]
	TIME [epoch: 145 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04299753162284111		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.04299753162284111 | validation: 0.03569034511881785]
	TIME [epoch: 145 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042771559249608605		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.042771559249608605 | validation: 0.03605566639680992]
	TIME [epoch: 146 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042371883385101665		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.042371883385101665 | validation: 0.03546688675509543]
	TIME [epoch: 146 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04194919010141367		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.04194919010141367 | validation: 0.03633193693426885]
	TIME [epoch: 146 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.041730615874368264		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.041730615874368264 | validation: 0.03543933476012989]
	TIME [epoch: 146 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04248418486451813		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.04248418486451813 | validation: 0.035896522318322674]
	TIME [epoch: 146 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042945107230445444		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.042945107230445444 | validation: 0.03593300335654913]
	TIME [epoch: 146 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04253354904750365		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.04253354904750365 | validation: 0.03618848970340927]
	TIME [epoch: 146 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04245105560672074		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.04245105560672074 | validation: 0.035565502084885396]
	TIME [epoch: 146 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.041494635710745624		[learning rate: 0.00099155]
	Learning Rate: 0.000991553
	LOSS [training: 0.041494635710745624 | validation: 0.036277551094559386]
	TIME [epoch: 146 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04297269424670111		[learning rate: 0.00098437]
	Learning Rate: 0.000984369
	LOSS [training: 0.04297269424670111 | validation: 0.03581481779756386]
	TIME [epoch: 146 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04198090002249926		[learning rate: 0.00097724]
	Learning Rate: 0.000977237
	LOSS [training: 0.04198090002249926 | validation: 0.03553299860317772]
	TIME [epoch: 146 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042657593782698115		[learning rate: 0.00097016]
	Learning Rate: 0.000970157
	LOSS [training: 0.042657593782698115 | validation: 0.03614017786896974]
	TIME [epoch: 146 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04274019350280914		[learning rate: 0.00096313]
	Learning Rate: 0.000963128
	LOSS [training: 0.04274019350280914 | validation: 0.0358248265702756]
	TIME [epoch: 146 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04263254150844314		[learning rate: 0.00095615]
	Learning Rate: 0.00095615
	LOSS [training: 0.04263254150844314 | validation: 0.03632324358405657]
	TIME [epoch: 146 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04259523649301109		[learning rate: 0.00094922]
	Learning Rate: 0.000949223
	LOSS [training: 0.04259523649301109 | validation: 0.035598168333663804]
	TIME [epoch: 146 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042152848298502126		[learning rate: 0.00094235]
	Learning Rate: 0.000942346
	LOSS [training: 0.042152848298502126 | validation: 0.03612218863043925]
	TIME [epoch: 146 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04282738349610677		[learning rate: 0.00093552]
	Learning Rate: 0.000935519
	LOSS [training: 0.04282738349610677 | validation: 0.03540664051757418]
	TIME [epoch: 146 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04199373518657853		[learning rate: 0.00092874]
	Learning Rate: 0.000928741
	LOSS [training: 0.04199373518657853 | validation: 0.035680040794463345]
	TIME [epoch: 146 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04215612747222899		[learning rate: 0.00092201]
	Learning Rate: 0.000922012
	LOSS [training: 0.04215612747222899 | validation: 0.03567480007066059]
	TIME [epoch: 146 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04274406113731294		[learning rate: 0.00091533]
	Learning Rate: 0.000915333
	LOSS [training: 0.04274406113731294 | validation: 0.03563932688277993]
	TIME [epoch: 145 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04338218912713001		[learning rate: 0.0009087]
	Learning Rate: 0.000908701
	LOSS [training: 0.04338218912713001 | validation: 0.03628934099115744]
	TIME [epoch: 146 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04221194567455536		[learning rate: 0.00090212]
	Learning Rate: 0.000902118
	LOSS [training: 0.04221194567455536 | validation: 0.03590001292766045]
	TIME [epoch: 146 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04268845435846568		[learning rate: 0.00089558]
	Learning Rate: 0.000895582
	LOSS [training: 0.04268845435846568 | validation: 0.036246813072090565]
	TIME [epoch: 146 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04331540897499056		[learning rate: 0.00088909]
	Learning Rate: 0.000889093
	LOSS [training: 0.04331540897499056 | validation: 0.03547442136030858]
	TIME [epoch: 146 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04235572386836813		[learning rate: 0.00088265]
	Learning Rate: 0.000882652
	LOSS [training: 0.04235572386836813 | validation: 0.03517518804365082]
	TIME [epoch: 146 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042384033226855265		[learning rate: 0.00087626]
	Learning Rate: 0.000876257
	LOSS [training: 0.042384033226855265 | validation: 0.03570581004479792]
	TIME [epoch: 146 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042208884724754314		[learning rate: 0.00086991]
	Learning Rate: 0.000869909
	LOSS [training: 0.042208884724754314 | validation: 0.036069130107974516]
	TIME [epoch: 146 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04251657175235202		[learning rate: 0.00086361]
	Learning Rate: 0.000863606
	LOSS [training: 0.04251657175235202 | validation: 0.0365180852972647]
	TIME [epoch: 146 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042115255798671127		[learning rate: 0.00085735]
	Learning Rate: 0.000857349
	LOSS [training: 0.042115255798671127 | validation: 0.03583780536314639]
	TIME [epoch: 146 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0425205213147366		[learning rate: 0.00085114]
	Learning Rate: 0.000851138
	LOSS [training: 0.0425205213147366 | validation: 0.036333466452197004]
	TIME [epoch: 146 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04263179192608493		[learning rate: 0.00084497]
	Learning Rate: 0.000844972
	LOSS [training: 0.04263179192608493 | validation: 0.036730513263920225]
	TIME [epoch: 146 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.041981871000494796		[learning rate: 0.00083885]
	Learning Rate: 0.00083885
	LOSS [training: 0.041981871000494796 | validation: 0.03606324023848682]
	TIME [epoch: 146 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042960118614397906		[learning rate: 0.00083277]
	Learning Rate: 0.000832772
	LOSS [training: 0.042960118614397906 | validation: 0.03554285597015905]
	TIME [epoch: 146 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0416148410529649		[learning rate: 0.00082674]
	Learning Rate: 0.000826739
	LOSS [training: 0.0416148410529649 | validation: 0.03602987216848903]
	TIME [epoch: 146 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043256806771773515		[learning rate: 0.00082075]
	Learning Rate: 0.000820749
	LOSS [training: 0.043256806771773515 | validation: 0.03547186748144204]
	TIME [epoch: 146 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04203237428179638		[learning rate: 0.0008148]
	Learning Rate: 0.000814803
	LOSS [training: 0.04203237428179638 | validation: 0.0361082634984526]
	TIME [epoch: 146 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04261383074612788		[learning rate: 0.0008089]
	Learning Rate: 0.0008089
	LOSS [training: 0.04261383074612788 | validation: 0.03561010728911348]
	TIME [epoch: 146 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04226194971634952		[learning rate: 0.00080304]
	Learning Rate: 0.000803039
	LOSS [training: 0.04226194971634952 | validation: 0.03578135416063171]
	TIME [epoch: 146 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04238431102914348		[learning rate: 0.00079722]
	Learning Rate: 0.000797221
	LOSS [training: 0.04238431102914348 | validation: 0.03520263960234516]
	TIME [epoch: 146 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0431298126493106		[learning rate: 0.00079145]
	Learning Rate: 0.000791446
	LOSS [training: 0.0431298126493106 | validation: 0.0358073188510155]
	TIME [epoch: 146 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042918703653663716		[learning rate: 0.00078571]
	Learning Rate: 0.000785711
	LOSS [training: 0.042918703653663716 | validation: 0.03558685911669198]
	TIME [epoch: 146 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04268780219727669		[learning rate: 0.00078002]
	Learning Rate: 0.000780019
	LOSS [training: 0.04268780219727669 | validation: 0.03637031506017109]
	TIME [epoch: 145 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04282202087639422		[learning rate: 0.00077437]
	Learning Rate: 0.000774368
	LOSS [training: 0.04282202087639422 | validation: 0.03631842027302813]
	TIME [epoch: 145 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04233615261898895		[learning rate: 0.00076876]
	Learning Rate: 0.000768758
	LOSS [training: 0.04233615261898895 | validation: 0.03522912695414897]
	TIME [epoch: 145 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.0424903835227681		[learning rate: 0.00076319]
	Learning Rate: 0.000763188
	LOSS [training: 0.0424903835227681 | validation: 0.035785552038332405]
	TIME [epoch: 145 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042252836020213985		[learning rate: 0.00075766]
	Learning Rate: 0.000757659
	LOSS [training: 0.042252836020213985 | validation: 0.036548900959836234]
	TIME [epoch: 146 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04290306509085754		[learning rate: 0.00075217]
	Learning Rate: 0.000752169
	LOSS [training: 0.04290306509085754 | validation: 0.03578213973035357]
	TIME [epoch: 146 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04223075272250698		[learning rate: 0.00074672]
	Learning Rate: 0.00074672
	LOSS [training: 0.04223075272250698 | validation: 0.03609773127155828]
	TIME [epoch: 146 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.041989280599806916		[learning rate: 0.00074131]
	Learning Rate: 0.00074131
	LOSS [training: 0.041989280599806916 | validation: 0.03569090942148601]
	TIME [epoch: 146 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04291618090262256		[learning rate: 0.00073594]
	Learning Rate: 0.000735939
	LOSS [training: 0.04291618090262256 | validation: 0.03527114537946719]
	TIME [epoch: 145 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04224436772865975		[learning rate: 0.00073061]
	Learning Rate: 0.000730608
	LOSS [training: 0.04224436772865975 | validation: 0.03514424509850938]
	TIME [epoch: 145 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04249341863347116		[learning rate: 0.00072531]
	Learning Rate: 0.000725314
	LOSS [training: 0.04249341863347116 | validation: 0.035802866365960126]
	TIME [epoch: 145 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04238080662840443		[learning rate: 0.00072006]
	Learning Rate: 0.00072006
	LOSS [training: 0.04238080662840443 | validation: 0.03620462802642828]
	TIME [epoch: 146 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04234491865981741		[learning rate: 0.00071484]
	Learning Rate: 0.000714843
	LOSS [training: 0.04234491865981741 | validation: 0.03614775852515543]
	TIME [epoch: 145 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.043114938126782125		[learning rate: 0.00070966]
	Learning Rate: 0.000709664
	LOSS [training: 0.043114938126782125 | validation: 0.03592263757732997]
	TIME [epoch: 146 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.042305900200912704		[learning rate: 0.00070452]
	Learning Rate: 0.000704522
	LOSS [training: 0.042305900200912704 | validation: 0.03498368604845787]
	TIME [epoch: 146 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04221549352240874		[learning rate: 0.00069942]
	Learning Rate: 0.000699418
	LOSS [training: 0.04221549352240874 | validation: 0.035983293372286486]
	TIME [epoch: 145 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04259956162618422		[learning rate: 0.00069435]
	Learning Rate: 0.000694351
	LOSS [training: 0.04259956162618422 | validation: 0.035482724536579656]
	TIME [epoch: 145 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.04267065486402557		[learning rate: 0.00068932]
	Learning Rate: 0.00068932
	LOSS [training: 0.04267065486402557 | validation: 0.03552448329733794]
	TIME [epoch: 145 sec]
EPOCH 419/1000:
	Training over batches...
