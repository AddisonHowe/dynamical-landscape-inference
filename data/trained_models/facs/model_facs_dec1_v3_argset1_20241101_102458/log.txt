Args:
Namespace(name='model_facs_dec1_v3_argset1', outdir='out/model_training/model_facs_dec1_v3_argset1', training_data='data/facs/facs_dec1_v3/training', validation_data='data/facs/facs_dec1_v3/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=0, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[50, 100, 200, 300], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.05, 0.1, 0.15, 0.5], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2592117882

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 6/6] avg loss: 3.2053833468058137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2053833468058137 | validation: 1.7033050389862499]
	TIME [epoch: 39.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 6/6] avg loss: 2.514979000277687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.514979000277687 | validation: 2.312621654672599]
	TIME [epoch: 11.4 sec]
EPOCH 3/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.8510780988577278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8510780988577278 | validation: 1.1996822928750113]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.378502805183501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.378502805183501 | validation: 0.9032074432783054]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 6/6] avg loss: 1.1457812824806832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1457812824806832 | validation: 1.6772513857734577]
	TIME [epoch: 11.3 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.9895613870003467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9895613870003467 | validation: 0.5965904897559835]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6515494446680293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6515494446680293 | validation: 0.42757044770803593]
	TIME [epoch: 11.4 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.6029239975305701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6029239975305701 | validation: 0.4284818271981461]
	TIME [epoch: 11.3 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.45561020137936853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45561020137936853 | validation: 0.4495388014067239]
	TIME [epoch: 11.3 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.43878043806335243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43878043806335243 | validation: 0.4250552992386085]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.470415074727823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.470415074727823 | validation: 0.3136924125923389]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3995082078164464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3995082078164464 | validation: 0.36024289583491176]
	TIME [epoch: 11.3 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.340402351537247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.340402351537247 | validation: 0.3070522017900494]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.326886332656374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.326886332656374 | validation: 0.23546144146501596]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3143552152126347		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3143552152126347 | validation: 0.3238815096975035]
	TIME [epoch: 11.3 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3351628486352742		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3351628486352742 | validation: 0.24422330193954686]
	TIME [epoch: 11.3 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2961535562673186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2961535562673186 | validation: 0.24787936365103685]
	TIME [epoch: 11.3 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.29288572573746907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.29288572573746907 | validation: 0.2679267972550087]
	TIME [epoch: 11.3 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3337495010165812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3337495010165812 | validation: 0.34976179148023157]
	TIME [epoch: 11.3 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3007672814393911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3007672814393911 | validation: 0.253282393439929]
	TIME [epoch: 11.3 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.283638530630144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.283638530630144 | validation: 0.2702181703969764]
	TIME [epoch: 11.3 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2687621284910365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2687621284910365 | validation: 0.31274860670061544]
	TIME [epoch: 11.3 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.3176173497582375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3176173497582375 | validation: 0.23867736303692383]
	TIME [epoch: 11.3 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2773917436377916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2773917436377916 | validation: 0.23355433781182433]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2638360436955187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2638360436955187 | validation: 0.2478324358236339]
	TIME [epoch: 11.3 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.33659231775903437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.33659231775903437 | validation: 0.2457883255824062]
	TIME [epoch: 11.3 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25914018864777594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25914018864777594 | validation: 0.20928205404789457]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2995921535575741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2995921535575741 | validation: 0.2563468961227803]
	TIME [epoch: 11.3 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24752117074312519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24752117074312519 | validation: 0.25589803122424604]
	TIME [epoch: 11.3 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24018227143595974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24018227143595974 | validation: 0.191036817106854]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2996753630913918		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2996753630913918 | validation: 0.21201400280838492]
	TIME [epoch: 11.3 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24858194586461332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24858194586461332 | validation: 0.18819526259504618]
	TIME [epoch: 11.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23800699450086735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23800699450086735 | validation: 0.2178728681559729]
	TIME [epoch: 11.3 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2601567895851366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2601567895851366 | validation: 0.20092666060718356]
	TIME [epoch: 11.3 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.31088273929479776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31088273929479776 | validation: 0.23096315307667545]
	TIME [epoch: 11.3 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23544150636033426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23544150636033426 | validation: 0.1860229932303618]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23594930973813524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23594930973813524 | validation: 0.3198604077010969]
	TIME [epoch: 11.3 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.27919800769643177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.27919800769643177 | validation: 0.20149286013434314]
	TIME [epoch: 11.3 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23301234246924218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23301234246924218 | validation: 0.25049857575051315]
	TIME [epoch: 11.3 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.26704435024811496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.26704435024811496 | validation: 0.20401816722452995]
	TIME [epoch: 11.3 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2346863006611476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2346863006611476 | validation: 0.20990087946678382]
	TIME [epoch: 11.3 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2313708977573561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2313708977573561 | validation: 0.18951316324448578]
	TIME [epoch: 11.3 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24695917212500518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24695917212500518 | validation: 0.18475635254372821]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2416494670284086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2416494670284086 | validation: 0.22999036919579113]
	TIME [epoch: 11.3 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24829414124072766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24829414124072766 | validation: 0.1834925760420995]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23895604813320173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.23895604813320173 | validation: 0.17680597471630854]
	TIME [epoch: 11.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2438097796067119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2438097796067119 | validation: 0.1825904060200522]
	TIME [epoch: 11.3 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24734540117422188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.24734540117422188 | validation: 0.1887290170512889]
	TIME [epoch: 11.3 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2495713145347013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2495713145347013 | validation: 0.18373193208565483]
	TIME [epoch: 11.3 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2310543006796977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2310543006796977 | validation: 0.20404869845998402]
	TIME [epoch: 11.3 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.236628528116583		[learning rate: 0.0099396]
	Learning Rate: 0.00993959
	LOSS [training: 0.236628528116583 | validation: 0.18761251387448924]
	TIME [epoch: 48.5 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23546098170985327		[learning rate: 0.0098676]
	Learning Rate: 0.00986758
	LOSS [training: 0.23546098170985327 | validation: 0.202791076612242]
	TIME [epoch: 22 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22878005816782435		[learning rate: 0.0097961]
	Learning Rate: 0.00979609
	LOSS [training: 0.22878005816782435 | validation: 0.18172068661427335]
	TIME [epoch: 22 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2577795863643797		[learning rate: 0.0097251]
	Learning Rate: 0.00972511
	LOSS [training: 0.2577795863643797 | validation: 0.2012786472139707]
	TIME [epoch: 21.9 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23879557336690105		[learning rate: 0.0096547]
	Learning Rate: 0.00965466
	LOSS [training: 0.23879557336690105 | validation: 0.22356891749698687]
	TIME [epoch: 22 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2391140989752237		[learning rate: 0.0095847]
	Learning Rate: 0.00958471
	LOSS [training: 0.2391140989752237 | validation: 0.19009122461012193]
	TIME [epoch: 21.9 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.25252536873661496		[learning rate: 0.0095153]
	Learning Rate: 0.00951527
	LOSS [training: 0.25252536873661496 | validation: 0.18587740748147186]
	TIME [epoch: 21.9 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22884253497506032		[learning rate: 0.0094463]
	Learning Rate: 0.00944633
	LOSS [training: 0.22884253497506032 | validation: 0.18837357426955464]
	TIME [epoch: 22 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2454632802069646		[learning rate: 0.0093779]
	Learning Rate: 0.00937789
	LOSS [training: 0.2454632802069646 | validation: 0.262691398094187]
	TIME [epoch: 21.9 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23404904432391305		[learning rate: 0.00931]
	Learning Rate: 0.00930995
	LOSS [training: 0.23404904432391305 | validation: 0.17949070415637042]
	TIME [epoch: 22 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24474468960146803		[learning rate: 0.0092425]
	Learning Rate: 0.0092425
	LOSS [training: 0.24474468960146803 | validation: 0.18418303179414264]
	TIME [epoch: 22 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22724710205500295		[learning rate: 0.0091755]
	Learning Rate: 0.00917554
	LOSS [training: 0.22724710205500295 | validation: 0.20679965086812518]
	TIME [epoch: 22 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23315206292293375		[learning rate: 0.0091091]
	Learning Rate: 0.00910906
	LOSS [training: 0.23315206292293375 | validation: 0.22995976304214233]
	TIME [epoch: 22 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24592845208763783		[learning rate: 0.0090431]
	Learning Rate: 0.00904307
	LOSS [training: 0.24592845208763783 | validation: 0.21631967735109997]
	TIME [epoch: 22 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22694089434766948		[learning rate: 0.0089776]
	Learning Rate: 0.00897755
	LOSS [training: 0.22694089434766948 | validation: 0.1767009757339129]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_65.pth
	Model improved!!!
EPOCH 66/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22970465205456078		[learning rate: 0.0089125]
	Learning Rate: 0.00891251
	LOSS [training: 0.22970465205456078 | validation: 0.17606697698561086]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2447842626584317		[learning rate: 0.0088479]
	Learning Rate: 0.00884794
	LOSS [training: 0.2447842626584317 | validation: 0.1876530836814961]
	TIME [epoch: 22 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23635611852128413		[learning rate: 0.0087838]
	Learning Rate: 0.00878384
	LOSS [training: 0.23635611852128413 | validation: 0.1925926772137939]
	TIME [epoch: 22 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22406595704035004		[learning rate: 0.0087202]
	Learning Rate: 0.0087202
	LOSS [training: 0.22406595704035004 | validation: 0.18776064851571558]
	TIME [epoch: 22 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22991758023743003		[learning rate: 0.008657]
	Learning Rate: 0.00865702
	LOSS [training: 0.22991758023743003 | validation: 0.18348488570061544]
	TIME [epoch: 21.9 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24400037861152035		[learning rate: 0.0085943]
	Learning Rate: 0.0085943
	LOSS [training: 0.24400037861152035 | validation: 0.18054057566899345]
	TIME [epoch: 22 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2289579485096731		[learning rate: 0.008532]
	Learning Rate: 0.00853203
	LOSS [training: 0.2289579485096731 | validation: 0.17756649020113038]
	TIME [epoch: 22 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22130791733123437		[learning rate: 0.0084702]
	Learning Rate: 0.00847022
	LOSS [training: 0.22130791733123437 | validation: 0.18873714613500064]
	TIME [epoch: 22 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21909935474541586		[learning rate: 0.0084089]
	Learning Rate: 0.00840885
	LOSS [training: 0.21909935474541586 | validation: 0.17072530062548186]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2488480910135011		[learning rate: 0.0083479]
	Learning Rate: 0.00834793
	LOSS [training: 0.2488480910135011 | validation: 0.17222951309828588]
	TIME [epoch: 22 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.24815022209728996		[learning rate: 0.0082875]
	Learning Rate: 0.00828745
	LOSS [training: 0.24815022209728996 | validation: 0.1787410548371214]
	TIME [epoch: 22 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22908026038440066		[learning rate: 0.0082274]
	Learning Rate: 0.00822741
	LOSS [training: 0.22908026038440066 | validation: 0.1750388812791281]
	TIME [epoch: 22 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22422784916725455		[learning rate: 0.0081678]
	Learning Rate: 0.0081678
	LOSS [training: 0.22422784916725455 | validation: 0.18716385823363196]
	TIME [epoch: 22 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23270324386713914		[learning rate: 0.0081086]
	Learning Rate: 0.00810863
	LOSS [training: 0.23270324386713914 | validation: 0.1710259882570155]
	TIME [epoch: 22 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22432481628174972		[learning rate: 0.0080499]
	Learning Rate: 0.00804988
	LOSS [training: 0.22432481628174972 | validation: 0.19027346066872766]
	TIME [epoch: 22 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23653697776204763		[learning rate: 0.0079916]
	Learning Rate: 0.00799156
	LOSS [training: 0.23653697776204763 | validation: 0.17434476725735476]
	TIME [epoch: 22 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23334645307966126		[learning rate: 0.0079337]
	Learning Rate: 0.00793366
	LOSS [training: 0.23334645307966126 | validation: 0.2195873463508044]
	TIME [epoch: 22 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22876154360370837		[learning rate: 0.0078762]
	Learning Rate: 0.00787618
	LOSS [training: 0.22876154360370837 | validation: 0.22397572680932595]
	TIME [epoch: 22 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2333557287849842		[learning rate: 0.0078191]
	Learning Rate: 0.00781912
	LOSS [training: 0.2333557287849842 | validation: 0.17540207644981062]
	TIME [epoch: 22 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2288375789412336		[learning rate: 0.0077625]
	Learning Rate: 0.00776247
	LOSS [training: 0.2288375789412336 | validation: 0.23277351429516946]
	TIME [epoch: 21.9 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23050777460427876		[learning rate: 0.0077062]
	Learning Rate: 0.00770623
	LOSS [training: 0.23050777460427876 | validation: 0.19627274698258948]
	TIME [epoch: 22 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22843382481989774		[learning rate: 0.0076504]
	Learning Rate: 0.0076504
	LOSS [training: 0.22843382481989774 | validation: 0.19171751196685732]
	TIME [epoch: 22 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22162679538103267		[learning rate: 0.007595]
	Learning Rate: 0.00759497
	LOSS [training: 0.22162679538103267 | validation: 0.19839837745932304]
	TIME [epoch: 22 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23155754112666202		[learning rate: 0.0075399]
	Learning Rate: 0.00753995
	LOSS [training: 0.23155754112666202 | validation: 0.17876041070070375]
	TIME [epoch: 22 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2300455641576389		[learning rate: 0.0074853]
	Learning Rate: 0.00748532
	LOSS [training: 0.2300455641576389 | validation: 0.16962692222664577]
	TIME [epoch: 22 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23320208926603478		[learning rate: 0.0074311]
	Learning Rate: 0.00743109
	LOSS [training: 0.23320208926603478 | validation: 0.18978479130253417]
	TIME [epoch: 21.9 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2301365484558171		[learning rate: 0.0073773]
	Learning Rate: 0.00737725
	LOSS [training: 0.2301365484558171 | validation: 0.17520335266090575]
	TIME [epoch: 21.9 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22025681353610752		[learning rate: 0.0073238]
	Learning Rate: 0.00732381
	LOSS [training: 0.22025681353610752 | validation: 0.18835514413537527]
	TIME [epoch: 21.9 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2328069492824962		[learning rate: 0.0072707]
	Learning Rate: 0.00727075
	LOSS [training: 0.2328069492824962 | validation: 0.17477196617198554]
	TIME [epoch: 21.9 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2274892639124817		[learning rate: 0.0072181]
	Learning Rate: 0.00721807
	LOSS [training: 0.2274892639124817 | validation: 0.16710116232678413]
	TIME [epoch: 21.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22250685279293028		[learning rate: 0.0071658]
	Learning Rate: 0.00716577
	LOSS [training: 0.22250685279293028 | validation: 0.16732647298840436]
	TIME [epoch: 22 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23669127943765078		[learning rate: 0.0071139]
	Learning Rate: 0.00711386
	LOSS [training: 0.23669127943765078 | validation: 0.16911726866205057]
	TIME [epoch: 22 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22528991835768367		[learning rate: 0.0070623]
	Learning Rate: 0.00706232
	LOSS [training: 0.22528991835768367 | validation: 0.1676076010283493]
	TIME [epoch: 22 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21957465985716282		[learning rate: 0.0070112]
	Learning Rate: 0.00701115
	LOSS [training: 0.21957465985716282 | validation: 0.1988117270334639]
	TIME [epoch: 22 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22370933715143618		[learning rate: 0.0069604]
	Learning Rate: 0.00696036
	LOSS [training: 0.22370933715143618 | validation: 0.1938663247542149]
	TIME [epoch: 22 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2429817628938221		[learning rate: 0.0069099]
	Learning Rate: 0.00690993
	LOSS [training: 0.2429817628938221 | validation: 0.17989036756402618]
	TIME [epoch: 72.3 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23003564577256422		[learning rate: 0.0068599]
	Learning Rate: 0.00685987
	LOSS [training: 0.23003564577256422 | validation: 0.18241835276942028]
	TIME [epoch: 45.9 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22193683651770477		[learning rate: 0.0068102]
	Learning Rate: 0.00681017
	LOSS [training: 0.22193683651770477 | validation: 0.1739020539472354]
	TIME [epoch: 45.9 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2247215927041362		[learning rate: 0.0067608]
	Learning Rate: 0.00676083
	LOSS [training: 0.2247215927041362 | validation: 0.20688129409917688]
	TIME [epoch: 45.9 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23017166856511548		[learning rate: 0.0067118]
	Learning Rate: 0.00671185
	LOSS [training: 0.23017166856511548 | validation: 0.19029460168323614]
	TIME [epoch: 45.9 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22325797869903138		[learning rate: 0.0066632]
	Learning Rate: 0.00666322
	LOSS [training: 0.22325797869903138 | validation: 0.1791079555920835]
	TIME [epoch: 45.9 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22330338978549927		[learning rate: 0.0066149]
	Learning Rate: 0.00661495
	LOSS [training: 0.22330338978549927 | validation: 0.18999933585413714]
	TIME [epoch: 45.9 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23989208561490713		[learning rate: 0.006567]
	Learning Rate: 0.00656702
	LOSS [training: 0.23989208561490713 | validation: 0.16960270817858242]
	TIME [epoch: 45.9 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22217486938828743		[learning rate: 0.0065194]
	Learning Rate: 0.00651944
	LOSS [training: 0.22217486938828743 | validation: 0.17706797853613848]
	TIME [epoch: 45.9 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22213606569300395		[learning rate: 0.0064722]
	Learning Rate: 0.00647221
	LOSS [training: 0.22213606569300395 | validation: 0.17477052448134384]
	TIME [epoch: 45.9 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2219129195046153		[learning rate: 0.0064253]
	Learning Rate: 0.00642532
	LOSS [training: 0.2219129195046153 | validation: 0.19679824901008316]
	TIME [epoch: 45.9 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22413979957393348		[learning rate: 0.0063788]
	Learning Rate: 0.00637877
	LOSS [training: 0.22413979957393348 | validation: 0.17994916919452547]
	TIME [epoch: 45.9 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22324320213049473		[learning rate: 0.0063326]
	Learning Rate: 0.00633255
	LOSS [training: 0.22324320213049473 | validation: 0.17384592276674765]
	TIME [epoch: 45.9 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22158972427132853		[learning rate: 0.0062867]
	Learning Rate: 0.00628668
	LOSS [training: 0.22158972427132853 | validation: 0.1737729689160709]
	TIME [epoch: 46 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23177277584754474		[learning rate: 0.0062411]
	Learning Rate: 0.00624113
	LOSS [training: 0.23177277584754474 | validation: 0.2207212541300144]
	TIME [epoch: 45.9 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22300676006413936		[learning rate: 0.0061959]
	Learning Rate: 0.00619591
	LOSS [training: 0.22300676006413936 | validation: 0.17284099038853196]
	TIME [epoch: 45.9 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22113761334933013		[learning rate: 0.006151]
	Learning Rate: 0.00615102
	LOSS [training: 0.22113761334933013 | validation: 0.17336829613068766]
	TIME [epoch: 45.9 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.219144621802473		[learning rate: 0.0061065]
	Learning Rate: 0.00610646
	LOSS [training: 0.219144621802473 | validation: 0.16823686856728393]
	TIME [epoch: 45.9 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22374239732005763		[learning rate: 0.0060622]
	Learning Rate: 0.00606222
	LOSS [training: 0.22374239732005763 | validation: 0.18023301815171577]
	TIME [epoch: 45.9 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21557114263312002		[learning rate: 0.0060183]
	Learning Rate: 0.0060183
	LOSS [training: 0.21557114263312002 | validation: 0.183717076574279]
	TIME [epoch: 46 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.23125059257443537		[learning rate: 0.0059747]
	Learning Rate: 0.0059747
	LOSS [training: 0.23125059257443537 | validation: 0.16954717006776432]
	TIME [epoch: 45.9 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22912659459041343		[learning rate: 0.0059314]
	Learning Rate: 0.00593141
	LOSS [training: 0.22912659459041343 | validation: 0.16906996820572823]
	TIME [epoch: 45.9 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22153854401920273		[learning rate: 0.0058884]
	Learning Rate: 0.00588844
	LOSS [training: 0.22153854401920273 | validation: 0.1817469632840322]
	TIME [epoch: 46 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2217373493560151		[learning rate: 0.0058458]
	Learning Rate: 0.00584577
	LOSS [training: 0.2217373493560151 | validation: 0.1798082563891055]
	TIME [epoch: 45.9 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22619329273461797		[learning rate: 0.0058034]
	Learning Rate: 0.00580342
	LOSS [training: 0.22619329273461797 | validation: 0.17220985214888135]
	TIME [epoch: 45.9 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2178833197490615		[learning rate: 0.0057614]
	Learning Rate: 0.00576138
	LOSS [training: 0.2178833197490615 | validation: 0.17385809516522444]
	TIME [epoch: 45.9 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22050138847857562		[learning rate: 0.0057196]
	Learning Rate: 0.00571964
	LOSS [training: 0.22050138847857562 | validation: 0.2612094838394106]
	TIME [epoch: 45.9 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2273267509243986		[learning rate: 0.0056782]
	Learning Rate: 0.0056782
	LOSS [training: 0.2273267509243986 | validation: 0.16571990698732986]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_128.pth
	Model improved!!!
EPOCH 129/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21971332936344715		[learning rate: 0.0056371]
	Learning Rate: 0.00563706
	LOSS [training: 0.21971332936344715 | validation: 0.1829953645177275]
	TIME [epoch: 45.8 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21916645717855143		[learning rate: 0.0055962]
	Learning Rate: 0.00559622
	LOSS [training: 0.21916645717855143 | validation: 0.1630830259132982]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22766485930845973		[learning rate: 0.0055557]
	Learning Rate: 0.00555567
	LOSS [training: 0.22766485930845973 | validation: 0.20070915021629654]
	TIME [epoch: 45.9 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2166252644380272		[learning rate: 0.0055154]
	Learning Rate: 0.00551542
	LOSS [training: 0.2166252644380272 | validation: 0.18122954027543053]
	TIME [epoch: 45.9 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21420797695967822		[learning rate: 0.0054755]
	Learning Rate: 0.00547547
	LOSS [training: 0.21420797695967822 | validation: 0.19698252084874515]
	TIME [epoch: 46 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22577460415331285		[learning rate: 0.0054358]
	Learning Rate: 0.0054358
	LOSS [training: 0.22577460415331285 | validation: 0.16891385786397967]
	TIME [epoch: 46 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21911816858296507		[learning rate: 0.0053964]
	Learning Rate: 0.00539641
	LOSS [training: 0.21911816858296507 | validation: 0.16734115899466806]
	TIME [epoch: 45.9 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2231299558110493		[learning rate: 0.0053573]
	Learning Rate: 0.00535732
	LOSS [training: 0.2231299558110493 | validation: 0.18356134470326402]
	TIME [epoch: 46 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22246885306525566		[learning rate: 0.0053185]
	Learning Rate: 0.0053185
	LOSS [training: 0.22246885306525566 | validation: 0.17974904427429328]
	TIME [epoch: 46 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22105746640239768		[learning rate: 0.00528]
	Learning Rate: 0.00527997
	LOSS [training: 0.22105746640239768 | validation: 0.17490838344509257]
	TIME [epoch: 45.9 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21882274674589064		[learning rate: 0.0052417]
	Learning Rate: 0.00524172
	LOSS [training: 0.21882274674589064 | validation: 0.17231780109168587]
	TIME [epoch: 45.9 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21886043042067352		[learning rate: 0.0052037]
	Learning Rate: 0.00520374
	LOSS [training: 0.21886043042067352 | validation: 0.17008671727877483]
	TIME [epoch: 45.9 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22713089758170948		[learning rate: 0.005166]
	Learning Rate: 0.00516604
	LOSS [training: 0.22713089758170948 | validation: 0.1628311208271453]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_141.pth
	Model improved!!!
EPOCH 142/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2180796822316378		[learning rate: 0.0051286]
	Learning Rate: 0.00512861
	LOSS [training: 0.2180796822316378 | validation: 0.17387590215699794]
	TIME [epoch: 45.9 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21861786527727248		[learning rate: 0.0050915]
	Learning Rate: 0.00509146
	LOSS [training: 0.21861786527727248 | validation: 0.17281926926209207]
	TIME [epoch: 45.8 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2192932495695363		[learning rate: 0.0050546]
	Learning Rate: 0.00505457
	LOSS [training: 0.2192932495695363 | validation: 0.17747550446020097]
	TIME [epoch: 45.8 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2112675296578426		[learning rate: 0.0050179]
	Learning Rate: 0.00501795
	LOSS [training: 0.2112675296578426 | validation: 0.1654535363837671]
	TIME [epoch: 45.8 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2290651183297671		[learning rate: 0.0049816]
	Learning Rate: 0.0049816
	LOSS [training: 0.2290651183297671 | validation: 0.16612691648276862]
	TIME [epoch: 45.8 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21073681142080214		[learning rate: 0.0049455]
	Learning Rate: 0.0049455
	LOSS [training: 0.21073681142080214 | validation: 0.18332936718599133]
	TIME [epoch: 45.9 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2140686910067868		[learning rate: 0.0049097]
	Learning Rate: 0.00490967
	LOSS [training: 0.2140686910067868 | validation: 0.17154474142696688]
	TIME [epoch: 45.8 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2127473867785452		[learning rate: 0.0048741]
	Learning Rate: 0.0048741
	LOSS [training: 0.2127473867785452 | validation: 0.1591837823664119]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_149.pth
	Model improved!!!
EPOCH 150/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2191930836242403		[learning rate: 0.0048388]
	Learning Rate: 0.00483879
	LOSS [training: 0.2191930836242403 | validation: 0.1634238754983391]
	TIME [epoch: 46 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21560715022416063		[learning rate: 0.0048037]
	Learning Rate: 0.00480373
	LOSS [training: 0.21560715022416063 | validation: 0.16284342943218064]
	TIME [epoch: 46 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20838179447164293		[learning rate: 0.0047689]
	Learning Rate: 0.00476893
	LOSS [training: 0.20838179447164293 | validation: 0.17441671613700796]
	TIME [epoch: 46 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21636395621554574		[learning rate: 0.0047344]
	Learning Rate: 0.00473438
	LOSS [training: 0.21636395621554574 | validation: 0.1580443052351178]
	TIME [epoch: 46.1 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2152178726231314		[learning rate: 0.0047001]
	Learning Rate: 0.00470008
	LOSS [training: 0.2152178726231314 | validation: 0.19734007265890804]
	TIME [epoch: 45.9 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.22138536058199407		[learning rate: 0.004666]
	Learning Rate: 0.00466603
	LOSS [training: 0.22138536058199407 | validation: 0.1603898251639896]
	TIME [epoch: 45.9 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21269400338482292		[learning rate: 0.0046322]
	Learning Rate: 0.00463222
	LOSS [training: 0.21269400338482292 | validation: 0.178827096494599]
	TIME [epoch: 45.9 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20871813301535547		[learning rate: 0.0045987]
	Learning Rate: 0.00459866
	LOSS [training: 0.20871813301535547 | validation: 0.17396016265480818]
	TIME [epoch: 46 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20987451527846634		[learning rate: 0.0045653]
	Learning Rate: 0.00456535
	LOSS [training: 0.20987451527846634 | validation: 0.17354942165091758]
	TIME [epoch: 45.7 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21788398777442		[learning rate: 0.0045323]
	Learning Rate: 0.00453227
	LOSS [training: 0.21788398777442 | validation: 0.15865942278347317]
	TIME [epoch: 45.8 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21085420829254764		[learning rate: 0.0044994]
	Learning Rate: 0.00449943
	LOSS [training: 0.21085420829254764 | validation: 0.16800904644329545]
	TIME [epoch: 46 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20961772708085827		[learning rate: 0.0044668]
	Learning Rate: 0.00446684
	LOSS [training: 0.20961772708085827 | validation: 0.16193632626019125]
	TIME [epoch: 45.8 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20964947306893836		[learning rate: 0.0044345]
	Learning Rate: 0.00443447
	LOSS [training: 0.20964947306893836 | validation: 0.1612968224571737]
	TIME [epoch: 45.8 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21178220074521462		[learning rate: 0.0044023]
	Learning Rate: 0.00440235
	LOSS [training: 0.21178220074521462 | validation: 0.15579311423268266]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_163.pth
	Model improved!!!
EPOCH 164/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21270189268545944		[learning rate: 0.0043705]
	Learning Rate: 0.00437045
	LOSS [training: 0.21270189268545944 | validation: 0.16223736794037039]
	TIME [epoch: 46 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20910079567095521		[learning rate: 0.0043388]
	Learning Rate: 0.00433879
	LOSS [training: 0.20910079567095521 | validation: 0.156039352132125]
	TIME [epoch: 46 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21568440174701095		[learning rate: 0.0043074]
	Learning Rate: 0.00430735
	LOSS [training: 0.21568440174701095 | validation: 0.1892303488451908]
	TIME [epoch: 45.9 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2084592136601319		[learning rate: 0.0042761]
	Learning Rate: 0.00427615
	LOSS [training: 0.2084592136601319 | validation: 0.15434330076610886]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_167.pth
	Model improved!!!
EPOCH 168/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2066489335117111		[learning rate: 0.0042452]
	Learning Rate: 0.00424517
	LOSS [training: 0.2066489335117111 | validation: 0.15389097039546354]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_168.pth
	Model improved!!!
EPOCH 169/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21078064565742372		[learning rate: 0.0042144]
	Learning Rate: 0.00421441
	LOSS [training: 0.21078064565742372 | validation: 0.17780835172302029]
	TIME [epoch: 46 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20525518112227067		[learning rate: 0.0041839]
	Learning Rate: 0.00418388
	LOSS [training: 0.20525518112227067 | validation: 0.1577698719376687]
	TIME [epoch: 45.9 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21042385929944937		[learning rate: 0.0041536]
	Learning Rate: 0.00415357
	LOSS [training: 0.21042385929944937 | validation: 0.16674032308502268]
	TIME [epoch: 46 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21061730486413963		[learning rate: 0.0041235]
	Learning Rate: 0.00412347
	LOSS [training: 0.21061730486413963 | validation: 0.15075699585790275]
	TIME [epoch: 46 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_172.pth
	Model improved!!!
EPOCH 173/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21700429438175808		[learning rate: 0.0040936]
	Learning Rate: 0.0040936
	LOSS [training: 0.21700429438175808 | validation: 0.18487841162465168]
	TIME [epoch: 45.8 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20743619858866902		[learning rate: 0.0040639]
	Learning Rate: 0.00406394
	LOSS [training: 0.20743619858866902 | validation: 0.20358824740626652]
	TIME [epoch: 45.9 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21281307315075879		[learning rate: 0.0040345]
	Learning Rate: 0.0040345
	LOSS [training: 0.21281307315075879 | validation: 0.15134992182245224]
	TIME [epoch: 45.9 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20611005462386475		[learning rate: 0.0040053]
	Learning Rate: 0.00400527
	LOSS [training: 0.20611005462386475 | validation: 0.17853432773432215]
	TIME [epoch: 45.9 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2106869163334395		[learning rate: 0.0039763]
	Learning Rate: 0.00397625
	LOSS [training: 0.2106869163334395 | validation: 0.1533304941696288]
	TIME [epoch: 45.9 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20908600134920338		[learning rate: 0.0039474]
	Learning Rate: 0.00394744
	LOSS [training: 0.20908600134920338 | validation: 0.18991085041642788]
	TIME [epoch: 45.9 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20829215397038567		[learning rate: 0.0039188]
	Learning Rate: 0.00391884
	LOSS [training: 0.20829215397038567 | validation: 0.16041523345706954]
	TIME [epoch: 45.8 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2045988793068981		[learning rate: 0.0038905]
	Learning Rate: 0.00389045
	LOSS [training: 0.2045988793068981 | validation: 0.15207201279954102]
	TIME [epoch: 45.9 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20363031447874472		[learning rate: 0.0038623]
	Learning Rate: 0.00386227
	LOSS [training: 0.20363031447874472 | validation: 0.15381387061252613]
	TIME [epoch: 45.9 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2087087907738355		[learning rate: 0.0038343]
	Learning Rate: 0.00383428
	LOSS [training: 0.2087087907738355 | validation: 0.17490234942534982]
	TIME [epoch: 45.9 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20869304674423705		[learning rate: 0.0038065]
	Learning Rate: 0.0038065
	LOSS [training: 0.20869304674423705 | validation: 0.15812918452967947]
	TIME [epoch: 45.9 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20384409828411407		[learning rate: 0.0037789]
	Learning Rate: 0.00377893
	LOSS [training: 0.20384409828411407 | validation: 0.15251702464796493]
	TIME [epoch: 45.9 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20191817091651187		[learning rate: 0.0037515]
	Learning Rate: 0.00375155
	LOSS [training: 0.20191817091651187 | validation: 0.1567776332082837]
	TIME [epoch: 45.9 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20811381855446057		[learning rate: 0.0037244]
	Learning Rate: 0.00372437
	LOSS [training: 0.20811381855446057 | validation: 0.1563472916881245]
	TIME [epoch: 45.9 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20318240861437678		[learning rate: 0.0036974]
	Learning Rate: 0.00369739
	LOSS [training: 0.20318240861437678 | validation: 0.15427238196042567]
	TIME [epoch: 45.8 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2011140694260516		[learning rate: 0.0036706]
	Learning Rate: 0.0036706
	LOSS [training: 0.2011140694260516 | validation: 0.15101177892535642]
	TIME [epoch: 45.9 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21159580655372426		[learning rate: 0.003644]
	Learning Rate: 0.003644
	LOSS [training: 0.21159580655372426 | validation: 0.15466340274963225]
	TIME [epoch: 45.9 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20363786114562613		[learning rate: 0.0036176]
	Learning Rate: 0.0036176
	LOSS [training: 0.20363786114562613 | validation: 0.15074993928546893]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_190.pth
	Model improved!!!
EPOCH 191/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21068893123721974		[learning rate: 0.0035914]
	Learning Rate: 0.00359139
	LOSS [training: 0.21068893123721974 | validation: 0.16058581446395018]
	TIME [epoch: 45.9 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20419825000350836		[learning rate: 0.0035654]
	Learning Rate: 0.00356538
	LOSS [training: 0.20419825000350836 | validation: 0.17151798884751263]
	TIME [epoch: 45.8 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20068798924018283		[learning rate: 0.0035395]
	Learning Rate: 0.00353954
	LOSS [training: 0.20068798924018283 | validation: 0.14929538393697922]
	TIME [epoch: 45.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2038557375926265		[learning rate: 0.0035139]
	Learning Rate: 0.0035139
	LOSS [training: 0.2038557375926265 | validation: 0.17457908235032646]
	TIME [epoch: 45.8 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20598640456405795		[learning rate: 0.0034884]
	Learning Rate: 0.00348844
	LOSS [training: 0.20598640456405795 | validation: 0.1552522299790447]
	TIME [epoch: 45.8 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20120367523541507		[learning rate: 0.0034632]
	Learning Rate: 0.00346317
	LOSS [training: 0.20120367523541507 | validation: 0.18213889361428243]
	TIME [epoch: 45.8 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20349826227682233		[learning rate: 0.0034381]
	Learning Rate: 0.00343808
	LOSS [training: 0.20349826227682233 | validation: 0.1504624293242222]
	TIME [epoch: 45.8 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2102642474298835		[learning rate: 0.0034132]
	Learning Rate: 0.00341317
	LOSS [training: 0.2102642474298835 | validation: 0.1694997108140765]
	TIME [epoch: 45.8 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2049826419144988		[learning rate: 0.0033884]
	Learning Rate: 0.00338844
	LOSS [training: 0.2049826419144988 | validation: 0.14680576603119372]
	TIME [epoch: 45.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_199.pth
	Model improved!!!
EPOCH 200/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20664404936877132		[learning rate: 0.0033639]
	Learning Rate: 0.00336389
	LOSS [training: 0.20664404936877132 | validation: 0.1510350592904055]
	TIME [epoch: 46 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20046843046424542		[learning rate: 0.0033395]
	Learning Rate: 0.00333952
	LOSS [training: 0.20046843046424542 | validation: 0.15035711615477843]
	TIME [epoch: 123 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2021548703889792		[learning rate: 0.0033153]
	Learning Rate: 0.00331533
	LOSS [training: 0.2021548703889792 | validation: 0.15709818027694408]
	TIME [epoch: 95.7 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20043531615865007		[learning rate: 0.0032913]
	Learning Rate: 0.00329131
	LOSS [training: 0.20043531615865007 | validation: 0.15068956847557138]
	TIME [epoch: 95.7 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20441335831454135		[learning rate: 0.0032675]
	Learning Rate: 0.00326746
	LOSS [training: 0.20441335831454135 | validation: 0.1480105539594783]
	TIME [epoch: 95.6 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1970796650490938		[learning rate: 0.0032438]
	Learning Rate: 0.00324379
	LOSS [training: 0.1970796650490938 | validation: 0.15634942931716073]
	TIME [epoch: 95.7 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20176657469553858		[learning rate: 0.0032203]
	Learning Rate: 0.00322029
	LOSS [training: 0.20176657469553858 | validation: 0.14788905541743438]
	TIME [epoch: 95.7 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20765577853321682		[learning rate: 0.003197]
	Learning Rate: 0.00319696
	LOSS [training: 0.20765577853321682 | validation: 0.16968015421723923]
	TIME [epoch: 95.7 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20447535539064607		[learning rate: 0.0031738]
	Learning Rate: 0.0031738
	LOSS [training: 0.20447535539064607 | validation: 0.1481057843306495]
	TIME [epoch: 95.7 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20154584070419543		[learning rate: 0.0031508]
	Learning Rate: 0.0031508
	LOSS [training: 0.20154584070419543 | validation: 0.16504705277574794]
	TIME [epoch: 95.6 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2052753469472646		[learning rate: 0.003128]
	Learning Rate: 0.00312797
	LOSS [training: 0.2052753469472646 | validation: 0.15406670098959996]
	TIME [epoch: 95.5 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.200245296471221		[learning rate: 0.0031053]
	Learning Rate: 0.00310531
	LOSS [training: 0.200245296471221 | validation: 0.1770018308615955]
	TIME [epoch: 95.7 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20693162161201675		[learning rate: 0.0030828]
	Learning Rate: 0.00308281
	LOSS [training: 0.20693162161201675 | validation: 0.1604246052106572]
	TIME [epoch: 95.6 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20424674780225519		[learning rate: 0.0030605]
	Learning Rate: 0.00306048
	LOSS [training: 0.20424674780225519 | validation: 0.15184156604144325]
	TIME [epoch: 95.7 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20032349689045403		[learning rate: 0.0030383]
	Learning Rate: 0.00303831
	LOSS [training: 0.20032349689045403 | validation: 0.15009270059504537]
	TIME [epoch: 95.6 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20003973159759783		[learning rate: 0.0030163]
	Learning Rate: 0.00301629
	LOSS [training: 0.20003973159759783 | validation: 0.15016400822923767]
	TIME [epoch: 95.8 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2021440240815624		[learning rate: 0.0029944]
	Learning Rate: 0.00299444
	LOSS [training: 0.2021440240815624 | validation: 0.15644120576481207]
	TIME [epoch: 95.7 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2061404533190528		[learning rate: 0.0029727]
	Learning Rate: 0.00297275
	LOSS [training: 0.2061404533190528 | validation: 0.17237063943119144]
	TIME [epoch: 95.6 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2073163255315931		[learning rate: 0.0029512]
	Learning Rate: 0.00295121
	LOSS [training: 0.2073163255315931 | validation: 0.14883386924012337]
	TIME [epoch: 95.6 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20428392953513894		[learning rate: 0.0029298]
	Learning Rate: 0.00292983
	LOSS [training: 0.20428392953513894 | validation: 0.15283087139089496]
	TIME [epoch: 95.6 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19622783201293267		[learning rate: 0.0029086]
	Learning Rate: 0.0029086
	LOSS [training: 0.19622783201293267 | validation: 0.14937117008692266]
	TIME [epoch: 95.6 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1992535654487845		[learning rate: 0.0028875]
	Learning Rate: 0.00288753
	LOSS [training: 0.1992535654487845 | validation: 0.15313728445357497]
	TIME [epoch: 95.6 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19871816682124913		[learning rate: 0.0028666]
	Learning Rate: 0.00286661
	LOSS [training: 0.19871816682124913 | validation: 0.1578071326152988]
	TIME [epoch: 95.6 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19769324198386487		[learning rate: 0.0028458]
	Learning Rate: 0.00284584
	LOSS [training: 0.19769324198386487 | validation: 0.15738389736432418]
	TIME [epoch: 95.6 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1984468480024729		[learning rate: 0.0028252]
	Learning Rate: 0.00282522
	LOSS [training: 0.1984468480024729 | validation: 0.1507932977166247]
	TIME [epoch: 95.7 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.21057798102938508		[learning rate: 0.0028048]
	Learning Rate: 0.00280475
	LOSS [training: 0.21057798102938508 | validation: 0.147777210713316]
	TIME [epoch: 95.6 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20402278481552127		[learning rate: 0.0027844]
	Learning Rate: 0.00278443
	LOSS [training: 0.20402278481552127 | validation: 0.15326213825346907]
	TIME [epoch: 95.7 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19687336074889547		[learning rate: 0.0027643]
	Learning Rate: 0.00276426
	LOSS [training: 0.19687336074889547 | validation: 0.15043301333424292]
	TIME [epoch: 95.6 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1989010483052516		[learning rate: 0.0027442]
	Learning Rate: 0.00274423
	LOSS [training: 0.1989010483052516 | validation: 0.1492439513283013]
	TIME [epoch: 95.6 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19813279304681333		[learning rate: 0.0027244]
	Learning Rate: 0.00272435
	LOSS [training: 0.19813279304681333 | validation: 0.1514814781288285]
	TIME [epoch: 95.5 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.209339385622571		[learning rate: 0.0027046]
	Learning Rate: 0.00270461
	LOSS [training: 0.209339385622571 | validation: 0.14949688640063513]
	TIME [epoch: 95.6 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19927574323994737		[learning rate: 0.002685]
	Learning Rate: 0.00268502
	LOSS [training: 0.19927574323994737 | validation: 0.1570719850636104]
	TIME [epoch: 95.6 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2001244843088211		[learning rate: 0.0026656]
	Learning Rate: 0.00266557
	LOSS [training: 0.2001244843088211 | validation: 0.150706667806572]
	TIME [epoch: 95.6 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19743950144519065		[learning rate: 0.0026463]
	Learning Rate: 0.00264625
	LOSS [training: 0.19743950144519065 | validation: 0.14863122295137887]
	TIME [epoch: 95.6 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1991177553743916		[learning rate: 0.0026271]
	Learning Rate: 0.00262708
	LOSS [training: 0.1991177553743916 | validation: 0.15305292578458424]
	TIME [epoch: 95.7 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20635075213064544		[learning rate: 0.002608]
	Learning Rate: 0.00260805
	LOSS [training: 0.20635075213064544 | validation: 0.14367775074949757]
	TIME [epoch: 95.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20330469661103834		[learning rate: 0.0025892]
	Learning Rate: 0.00258915
	LOSS [training: 0.20330469661103834 | validation: 0.14691326294087978]
	TIME [epoch: 95.7 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2039493094075914		[learning rate: 0.0025704]
	Learning Rate: 0.0025704
	LOSS [training: 0.2039493094075914 | validation: 0.15035228933124714]
	TIME [epoch: 95.5 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20072056895387028		[learning rate: 0.0025518]
	Learning Rate: 0.00255177
	LOSS [training: 0.20072056895387028 | validation: 0.15631251671123308]
	TIME [epoch: 95.6 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19811033272257594		[learning rate: 0.0025333]
	Learning Rate: 0.00253329
	LOSS [training: 0.19811033272257594 | validation: 0.14638394464655985]
	TIME [epoch: 95.5 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20020887175056742		[learning rate: 0.0025149]
	Learning Rate: 0.00251493
	LOSS [training: 0.20020887175056742 | validation: 0.1703952923760666]
	TIME [epoch: 95.7 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2015477042945285		[learning rate: 0.0024967]
	Learning Rate: 0.00249671
	LOSS [training: 0.2015477042945285 | validation: 0.15479245407705786]
	TIME [epoch: 95.6 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19812969665354183		[learning rate: 0.0024786]
	Learning Rate: 0.00247862
	LOSS [training: 0.19812969665354183 | validation: 0.14934453135290096]
	TIME [epoch: 95.7 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2013573713103943		[learning rate: 0.0024607]
	Learning Rate: 0.00246067
	LOSS [training: 0.2013573713103943 | validation: 0.14770000629942887]
	TIME [epoch: 95.7 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19861925497579103		[learning rate: 0.0024428]
	Learning Rate: 0.00244284
	LOSS [training: 0.19861925497579103 | validation: 0.14579455732315888]
	TIME [epoch: 95.7 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1960520878475197		[learning rate: 0.0024251]
	Learning Rate: 0.00242514
	LOSS [training: 0.1960520878475197 | validation: 0.15306347570678974]
	TIME [epoch: 95.6 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19920332443305735		[learning rate: 0.0024076]
	Learning Rate: 0.00240757
	LOSS [training: 0.19920332443305735 | validation: 0.1574828264135179]
	TIME [epoch: 95.6 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2071073366101305		[learning rate: 0.0023901]
	Learning Rate: 0.00239013
	LOSS [training: 0.2071073366101305 | validation: 0.15261294089174812]
	TIME [epoch: 95.6 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20039693655786803		[learning rate: 0.0023728]
	Learning Rate: 0.00237281
	LOSS [training: 0.20039693655786803 | validation: 0.15670122911967563]
	TIME [epoch: 95.7 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19926156890254074		[learning rate: 0.0023556]
	Learning Rate: 0.00235562
	LOSS [training: 0.19926156890254074 | validation: 0.14988791680633548]
	TIME [epoch: 95.5 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1975685059784507		[learning rate: 0.0023386]
	Learning Rate: 0.00233855
	LOSS [training: 0.1975685059784507 | validation: 0.1515986720895017]
	TIME [epoch: 95.7 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2034041613385125		[learning rate: 0.0023216]
	Learning Rate: 0.00232161
	LOSS [training: 0.2034041613385125 | validation: 0.158048417610473]
	TIME [epoch: 95.7 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2003034212474217		[learning rate: 0.0023048]
	Learning Rate: 0.00230479
	LOSS [training: 0.2003034212474217 | validation: 0.17857488052023368]
	TIME [epoch: 95.8 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20087595927296195		[learning rate: 0.0022881]
	Learning Rate: 0.00228809
	LOSS [training: 0.20087595927296195 | validation: 0.1721411797122745]
	TIME [epoch: 95.7 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1958006412257742		[learning rate: 0.0022715]
	Learning Rate: 0.00227152
	LOSS [training: 0.1958006412257742 | validation: 0.14748621267714265]
	TIME [epoch: 95.7 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2011204596394044		[learning rate: 0.0022551]
	Learning Rate: 0.00225506
	LOSS [training: 0.2011204596394044 | validation: 0.1454223958110262]
	TIME [epoch: 95.8 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19895595894727539		[learning rate: 0.0022387]
	Learning Rate: 0.00223872
	LOSS [training: 0.19895595894727539 | validation: 0.15221700623988244]
	TIME [epoch: 95.7 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2004964327475864		[learning rate: 0.0022225]
	Learning Rate: 0.0022225
	LOSS [training: 0.2004964327475864 | validation: 0.1546050287538932]
	TIME [epoch: 95.7 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20731826708164014		[learning rate: 0.0022064]
	Learning Rate: 0.0022064
	LOSS [training: 0.20731826708164014 | validation: 0.150641275784355]
	TIME [epoch: 95.8 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20171475668921687		[learning rate: 0.0021904]
	Learning Rate: 0.00219041
	LOSS [training: 0.20171475668921687 | validation: 0.1488494298249748]
	TIME [epoch: 95.7 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19607032770780478		[learning rate: 0.0021745]
	Learning Rate: 0.00217455
	LOSS [training: 0.19607032770780478 | validation: 0.1512008399939493]
	TIME [epoch: 95.6 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20183207133848255		[learning rate: 0.0021588]
	Learning Rate: 0.00215879
	LOSS [training: 0.20183207133848255 | validation: 0.14945047508254616]
	TIME [epoch: 95.7 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20171569984545665		[learning rate: 0.0021431]
	Learning Rate: 0.00214315
	LOSS [training: 0.20171569984545665 | validation: 0.1450805453333813]
	TIME [epoch: 95.7 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1978276869421142		[learning rate: 0.0021276]
	Learning Rate: 0.00212762
	LOSS [training: 0.1978276869421142 | validation: 0.1475180544480925]
	TIME [epoch: 95.7 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19746423059369053		[learning rate: 0.0021122]
	Learning Rate: 0.00211221
	LOSS [training: 0.19746423059369053 | validation: 0.14901271797322077]
	TIME [epoch: 95.7 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20138909470425773		[learning rate: 0.0020969]
	Learning Rate: 0.00209691
	LOSS [training: 0.20138909470425773 | validation: 0.152424122100419]
	TIME [epoch: 95.7 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19827015642266158		[learning rate: 0.0020817]
	Learning Rate: 0.00208171
	LOSS [training: 0.19827015642266158 | validation: 0.14992115824793284]
	TIME [epoch: 95.6 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19745876122855943		[learning rate: 0.0020666]
	Learning Rate: 0.00206663
	LOSS [training: 0.19745876122855943 | validation: 0.14683066652249951]
	TIME [epoch: 95.7 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1965966792866776		[learning rate: 0.0020517]
	Learning Rate: 0.00205166
	LOSS [training: 0.1965966792866776 | validation: 0.14307868169939272]
	TIME [epoch: 95.6 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19877061850122166		[learning rate: 0.0020368]
	Learning Rate: 0.0020368
	LOSS [training: 0.19877061850122166 | validation: 0.15572361883847058]
	TIME [epoch: 95.7 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1973918443728422		[learning rate: 0.002022]
	Learning Rate: 0.00202204
	LOSS [training: 0.1973918443728422 | validation: 0.1591208889405853]
	TIME [epoch: 95.7 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19920049997919406		[learning rate: 0.0020074]
	Learning Rate: 0.00200739
	LOSS [training: 0.19920049997919406 | validation: 0.18125527185260715]
	TIME [epoch: 95.5 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2001691014051734		[learning rate: 0.0019928]
	Learning Rate: 0.00199285
	LOSS [training: 0.2001691014051734 | validation: 0.15569674436826036]
	TIME [epoch: 95.6 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1990287863973629		[learning rate: 0.0019784]
	Learning Rate: 0.00197841
	LOSS [training: 0.1990287863973629 | validation: 0.14779094739175191]
	TIME [epoch: 95.6 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19974137933879843		[learning rate: 0.0019641]
	Learning Rate: 0.00196407
	LOSS [training: 0.19974137933879843 | validation: 0.1505698987015598]
	TIME [epoch: 95.7 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1996375526155457		[learning rate: 0.0019498]
	Learning Rate: 0.00194984
	LOSS [training: 0.1996375526155457 | validation: 0.1485494510192382]
	TIME [epoch: 95.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19470415510443653		[learning rate: 0.0019357]
	Learning Rate: 0.00193572
	LOSS [training: 0.19470415510443653 | validation: 0.15043900060121237]
	TIME [epoch: 95.7 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19790085710750369		[learning rate: 0.0019217]
	Learning Rate: 0.00192169
	LOSS [training: 0.19790085710750369 | validation: 0.14785145669697736]
	TIME [epoch: 95.7 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19751506870245775		[learning rate: 0.0019078]
	Learning Rate: 0.00190777
	LOSS [training: 0.19751506870245775 | validation: 0.16320700776471783]
	TIME [epoch: 95.7 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20019908025239716		[learning rate: 0.0018939]
	Learning Rate: 0.00189395
	LOSS [training: 0.20019908025239716 | validation: 0.1523282491076737]
	TIME [epoch: 95.5 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19387179230112214		[learning rate: 0.0018802]
	Learning Rate: 0.00188023
	LOSS [training: 0.19387179230112214 | validation: 0.17452566946697928]
	TIME [epoch: 95.6 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19727940251343243		[learning rate: 0.0018666]
	Learning Rate: 0.00186661
	LOSS [training: 0.19727940251343243 | validation: 0.14683706075021552]
	TIME [epoch: 95.7 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.2006086321702786		[learning rate: 0.0018531]
	Learning Rate: 0.00185308
	LOSS [training: 0.2006086321702786 | validation: 0.14923074799976663]
	TIME [epoch: 95.5 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1960173096916369		[learning rate: 0.0018397]
	Learning Rate: 0.00183966
	LOSS [training: 0.1960173096916369 | validation: 0.14918880787812044]
	TIME [epoch: 95.6 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19768506312576462		[learning rate: 0.0018263]
	Learning Rate: 0.00182633
	LOSS [training: 0.19768506312576462 | validation: 0.17693399661055015]
	TIME [epoch: 95.7 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19842873689513227		[learning rate: 0.0018131]
	Learning Rate: 0.0018131
	LOSS [training: 0.19842873689513227 | validation: 0.15348498887500334]
	TIME [epoch: 95.7 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1972772837690265		[learning rate: 0.0018]
	Learning Rate: 0.00179996
	LOSS [training: 0.1972772837690265 | validation: 0.15065248034295506]
	TIME [epoch: 95.6 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19642922037342744		[learning rate: 0.0017869]
	Learning Rate: 0.00178692
	LOSS [training: 0.19642922037342744 | validation: 0.14608546020787977]
	TIME [epoch: 95.5 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1971686184593868		[learning rate: 0.001774]
	Learning Rate: 0.00177397
	LOSS [training: 0.1971686184593868 | validation: 0.14695096233045496]
	TIME [epoch: 95.5 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19536815896903206		[learning rate: 0.0017611]
	Learning Rate: 0.00176112
	LOSS [training: 0.19536815896903206 | validation: 0.14421637391085562]
	TIME [epoch: 95.6 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19577096981085426		[learning rate: 0.0017484]
	Learning Rate: 0.00174836
	LOSS [training: 0.19577096981085426 | validation: 0.1536347849158378]
	TIME [epoch: 95.4 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19853421747717373		[learning rate: 0.0017357]
	Learning Rate: 0.0017357
	LOSS [training: 0.19853421747717373 | validation: 0.14477313035639178]
	TIME [epoch: 95.6 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1956646700029772		[learning rate: 0.0017231]
	Learning Rate: 0.00172312
	LOSS [training: 0.1956646700029772 | validation: 0.14766401104790275]
	TIME [epoch: 95.6 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19860444599813107		[learning rate: 0.0017106]
	Learning Rate: 0.00171064
	LOSS [training: 0.19860444599813107 | validation: 0.1465242417462333]
	TIME [epoch: 95.5 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19895542492983143		[learning rate: 0.0016982]
	Learning Rate: 0.00169824
	LOSS [training: 0.19895542492983143 | validation: 0.14664203799058417]
	TIME [epoch: 95.6 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19600631843431385		[learning rate: 0.0016859]
	Learning Rate: 0.00168594
	LOSS [training: 0.19600631843431385 | validation: 0.15145100404696066]
	TIME [epoch: 95.6 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19670662082700585		[learning rate: 0.0016737]
	Learning Rate: 0.00167373
	LOSS [training: 0.19670662082700585 | validation: 0.15020369870596487]
	TIME [epoch: 95.7 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1972591489369453		[learning rate: 0.0016616]
	Learning Rate: 0.0016616
	LOSS [training: 0.1972591489369453 | validation: 0.14472092525338826]
	TIME [epoch: 95.6 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19905807999021466		[learning rate: 0.0016496]
	Learning Rate: 0.00164956
	LOSS [training: 0.19905807999021466 | validation: 0.1525730932047156]
	TIME [epoch: 95.6 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19981111994358788		[learning rate: 0.0016376]
	Learning Rate: 0.00163761
	LOSS [training: 0.19981111994358788 | validation: 0.14924593670586314]
	TIME [epoch: 95.7 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19593703364686357		[learning rate: 0.0016257]
	Learning Rate: 0.00162575
	LOSS [training: 0.19593703364686357 | validation: 0.1640700725642897]
	TIME [epoch: 95.6 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19739712157633316		[learning rate: 0.001614]
	Learning Rate: 0.00161397
	LOSS [training: 0.19739712157633316 | validation: 0.14729988853661424]
	TIME [epoch: 222 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19654284385435342		[learning rate: 0.0016023]
	Learning Rate: 0.00160227
	LOSS [training: 0.19654284385435342 | validation: 0.15433484657132598]
	TIME [epoch: 195 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19834477801754832		[learning rate: 0.0015907]
	Learning Rate: 0.00159067
	LOSS [training: 0.19834477801754832 | validation: 0.1477714293813833]
	TIME [epoch: 195 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19715960888585948		[learning rate: 0.0015791]
	Learning Rate: 0.00157914
	LOSS [training: 0.19715960888585948 | validation: 0.14911215327783367]
	TIME [epoch: 195 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19699560717202888		[learning rate: 0.0015677]
	Learning Rate: 0.0015677
	LOSS [training: 0.19699560717202888 | validation: 0.15382733888955577]
	TIME [epoch: 195 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19692757633265515		[learning rate: 0.0015563]
	Learning Rate: 0.00155634
	LOSS [training: 0.19692757633265515 | validation: 0.1591414388696375]
	TIME [epoch: 195 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19661757102893654		[learning rate: 0.0015451]
	Learning Rate: 0.00154507
	LOSS [training: 0.19661757102893654 | validation: 0.16044736080571953]
	TIME [epoch: 195 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1999147615194504		[learning rate: 0.0015339]
	Learning Rate: 0.00153387
	LOSS [training: 0.1999147615194504 | validation: 0.14858748281008957]
	TIME [epoch: 195 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1962952750321624		[learning rate: 0.0015228]
	Learning Rate: 0.00152276
	LOSS [training: 0.1962952750321624 | validation: 0.14548562323544836]
	TIME [epoch: 195 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19434207936663553		[learning rate: 0.0015117]
	Learning Rate: 0.00151173
	LOSS [training: 0.19434207936663553 | validation: 0.1524795941951698]
	TIME [epoch: 195 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19749982892350837		[learning rate: 0.0015008]
	Learning Rate: 0.00150078
	LOSS [training: 0.19749982892350837 | validation: 0.14986005476299938]
	TIME [epoch: 195 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19463932243126703		[learning rate: 0.0014899]
	Learning Rate: 0.0014899
	LOSS [training: 0.19463932243126703 | validation: 0.14960572681392614]
	TIME [epoch: 195 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19713465273006492		[learning rate: 0.0014791]
	Learning Rate: 0.00147911
	LOSS [training: 0.19713465273006492 | validation: 0.15832647282117346]
	TIME [epoch: 195 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19822518502703498		[learning rate: 0.0014684]
	Learning Rate: 0.00146839
	LOSS [training: 0.19822518502703498 | validation: 0.15821375243545371]
	TIME [epoch: 195 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19476142708549735		[learning rate: 0.0014578]
	Learning Rate: 0.00145775
	LOSS [training: 0.19476142708549735 | validation: 0.14526881079558182]
	TIME [epoch: 195 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19728925921267146		[learning rate: 0.0014472]
	Learning Rate: 0.00144719
	LOSS [training: 0.19728925921267146 | validation: 0.1476205234895666]
	TIME [epoch: 195 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1976553408618584		[learning rate: 0.0014367]
	Learning Rate: 0.00143671
	LOSS [training: 0.1976553408618584 | validation: 0.14570057618932278]
	TIME [epoch: 195 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19711601785836433		[learning rate: 0.0014263]
	Learning Rate: 0.0014263
	LOSS [training: 0.19711601785836433 | validation: 0.14332548230575864]
	TIME [epoch: 195 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.20052525392357887		[learning rate: 0.001416]
	Learning Rate: 0.00141597
	LOSS [training: 0.20052525392357887 | validation: 0.14597685514874376]
	TIME [epoch: 195 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1980104724090664		[learning rate: 0.0014057]
	Learning Rate: 0.00140571
	LOSS [training: 0.1980104724090664 | validation: 0.14978874190275673]
	TIME [epoch: 195 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1974256185205572		[learning rate: 0.0013955]
	Learning Rate: 0.00139552
	LOSS [training: 0.1974256185205572 | validation: 0.14741147062157772]
	TIME [epoch: 195 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1982910509960127		[learning rate: 0.0013854]
	Learning Rate: 0.00138541
	LOSS [training: 0.1982910509960127 | validation: 0.14838734754947283]
	TIME [epoch: 195 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19615948819446202		[learning rate: 0.0013754]
	Learning Rate: 0.00137537
	LOSS [training: 0.19615948819446202 | validation: 0.14730632703300284]
	TIME [epoch: 195 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1969499727304215		[learning rate: 0.0013654]
	Learning Rate: 0.00136541
	LOSS [training: 0.1969499727304215 | validation: 0.14684134608276156]
	TIME [epoch: 195 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19683741461546533		[learning rate: 0.0013555]
	Learning Rate: 0.00135552
	LOSS [training: 0.19683741461546533 | validation: 0.14569610847674486]
	TIME [epoch: 195 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1976493864535549		[learning rate: 0.0013457]
	Learning Rate: 0.0013457
	LOSS [training: 0.1976493864535549 | validation: 0.1469718174066125]
	TIME [epoch: 195 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.196320215591968		[learning rate: 0.0013359]
	Learning Rate: 0.00133595
	LOSS [training: 0.196320215591968 | validation: 0.1516813365579765]
	TIME [epoch: 195 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19891582561682683		[learning rate: 0.0013263]
	Learning Rate: 0.00132627
	LOSS [training: 0.19891582561682683 | validation: 0.14548732455308128]
	TIME [epoch: 195 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19765428189913703		[learning rate: 0.0013167]
	Learning Rate: 0.00131666
	LOSS [training: 0.19765428189913703 | validation: 0.1492310593209108]
	TIME [epoch: 195 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19695217739620186		[learning rate: 0.0013071]
	Learning Rate: 0.00130712
	LOSS [training: 0.19695217739620186 | validation: 0.14577778494281105]
	TIME [epoch: 195 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1931722287656731		[learning rate: 0.0012977]
	Learning Rate: 0.00129765
	LOSS [training: 0.1931722287656731 | validation: 0.14651083195397546]
	TIME [epoch: 195 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.197085913715949		[learning rate: 0.0012882]
	Learning Rate: 0.00128825
	LOSS [training: 0.197085913715949 | validation: 0.15281274363676006]
	TIME [epoch: 195 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19647444647102452		[learning rate: 0.0012789]
	Learning Rate: 0.00127892
	LOSS [training: 0.19647444647102452 | validation: 0.1535455462277236]
	TIME [epoch: 195 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19588966217035156		[learning rate: 0.0012697]
	Learning Rate: 0.00126965
	LOSS [training: 0.19588966217035156 | validation: 0.1590408472121764]
	TIME [epoch: 195 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19890946236810436		[learning rate: 0.0012605]
	Learning Rate: 0.00126045
	LOSS [training: 0.19890946236810436 | validation: 0.1480031286479439]
	TIME [epoch: 195 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1962309887947193		[learning rate: 0.0012513]
	Learning Rate: 0.00125132
	LOSS [training: 0.1962309887947193 | validation: 0.1469779940643186]
	TIME [epoch: 195 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1959196902589875		[learning rate: 0.0012423]
	Learning Rate: 0.00124225
	LOSS [training: 0.1959196902589875 | validation: 0.15078859475981446]
	TIME [epoch: 195 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19461918807019082		[learning rate: 0.0012333]
	Learning Rate: 0.00123325
	LOSS [training: 0.19461918807019082 | validation: 0.1473076263754083]
	TIME [epoch: 195 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19721843845155726		[learning rate: 0.0012243]
	Learning Rate: 0.00122432
	LOSS [training: 0.19721843845155726 | validation: 0.1606537606167105]
	TIME [epoch: 195 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.195191845128352		[learning rate: 0.0012154]
	Learning Rate: 0.00121545
	LOSS [training: 0.195191845128352 | validation: 0.14691569118473327]
	TIME [epoch: 195 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19725049805470496		[learning rate: 0.0012066]
	Learning Rate: 0.00120664
	LOSS [training: 0.19725049805470496 | validation: 0.14930091242564497]
	TIME [epoch: 195 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19357557002603898		[learning rate: 0.0011979]
	Learning Rate: 0.0011979
	LOSS [training: 0.19357557002603898 | validation: 0.14580021812819816]
	TIME [epoch: 195 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19706461648286253		[learning rate: 0.0011892]
	Learning Rate: 0.00118922
	LOSS [training: 0.19706461648286253 | validation: 0.14560777270138353]
	TIME [epoch: 195 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19640982340519833		[learning rate: 0.0011806]
	Learning Rate: 0.00118061
	LOSS [training: 0.19640982340519833 | validation: 0.14697903363965886]
	TIME [epoch: 195 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1956701477923869		[learning rate: 0.0011721]
	Learning Rate: 0.00117205
	LOSS [training: 0.1956701477923869 | validation: 0.16427701222789673]
	TIME [epoch: 195 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19922287157665028		[learning rate: 0.0011636]
	Learning Rate: 0.00116356
	LOSS [training: 0.19922287157665028 | validation: 0.1470145213469237]
	TIME [epoch: 195 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19533819132972252		[learning rate: 0.0011551]
	Learning Rate: 0.00115513
	LOSS [training: 0.19533819132972252 | validation: 0.14503209958056357]
	TIME [epoch: 195 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19078377631661844		[learning rate: 0.0011468]
	Learning Rate: 0.00114676
	LOSS [training: 0.19078377631661844 | validation: 0.15236091938509633]
	TIME [epoch: 195 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19528832243098973		[learning rate: 0.0011385]
	Learning Rate: 0.00113845
	LOSS [training: 0.19528832243098973 | validation: 0.1440088730605448]
	TIME [epoch: 195 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1929070572257192		[learning rate: 0.0011302]
	Learning Rate: 0.00113021
	LOSS [training: 0.1929070572257192 | validation: 0.14739409030685718]
	TIME [epoch: 195 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19815457382505833		[learning rate: 0.001122]
	Learning Rate: 0.00112202
	LOSS [training: 0.19815457382505833 | validation: 0.14582327860057367]
	TIME [epoch: 195 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19605852190692416		[learning rate: 0.0011139]
	Learning Rate: 0.00111389
	LOSS [training: 0.19605852190692416 | validation: 0.1449853381750475]
	TIME [epoch: 195 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19309841654515725		[learning rate: 0.0011058]
	Learning Rate: 0.00110582
	LOSS [training: 0.19309841654515725 | validation: 0.14750568457346244]
	TIME [epoch: 195 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19527410727055375		[learning rate: 0.0010978]
	Learning Rate: 0.00109781
	LOSS [training: 0.19527410727055375 | validation: 0.1442510769809255]
	TIME [epoch: 195 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1989891654877546		[learning rate: 0.0010899]
	Learning Rate: 0.00108985
	LOSS [training: 0.1989891654877546 | validation: 0.1527240003352434]
	TIME [epoch: 195 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19761567996869314		[learning rate: 0.001082]
	Learning Rate: 0.00108196
	LOSS [training: 0.19761567996869314 | validation: 0.14880047979454206]
	TIME [epoch: 195 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19714831684843104		[learning rate: 0.0010741]
	Learning Rate: 0.00107412
	LOSS [training: 0.19714831684843104 | validation: 0.1449539356317462]
	TIME [epoch: 195 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19503252334864649		[learning rate: 0.0010663]
	Learning Rate: 0.00106634
	LOSS [training: 0.19503252334864649 | validation: 0.14748643113008356]
	TIME [epoch: 195 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19554337878946604		[learning rate: 0.0010586]
	Learning Rate: 0.00105861
	LOSS [training: 0.19554337878946604 | validation: 0.14675498232359213]
	TIME [epoch: 195 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19647101745154907		[learning rate: 0.0010509]
	Learning Rate: 0.00105094
	LOSS [training: 0.19647101745154907 | validation: 0.1604593984255432]
	TIME [epoch: 195 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19629279872935904		[learning rate: 0.0010433]
	Learning Rate: 0.00104333
	LOSS [training: 0.19629279872935904 | validation: 0.1430009298390185]
	TIME [epoch: 195 sec]
	Saving model to: out/model_training/model_facs_dec1_v3_argset1_20241101_102458/states/model_facs_dec1_v3_argset1_361.pth
	Model improved!!!
EPOCH 362/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19496587254680076		[learning rate: 0.0010358]
	Learning Rate: 0.00103577
	LOSS [training: 0.19496587254680076 | validation: 0.14454148740836043]
	TIME [epoch: 195 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19478260891406088		[learning rate: 0.0010283]
	Learning Rate: 0.00102827
	LOSS [training: 0.19478260891406088 | validation: 0.1468863528816488]
	TIME [epoch: 195 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1928038941653113		[learning rate: 0.0010208]
	Learning Rate: 0.00102082
	LOSS [training: 0.1928038941653113 | validation: 0.14634113754286543]
	TIME [epoch: 195 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1970532802269461		[learning rate: 0.0010134]
	Learning Rate: 0.00101342
	LOSS [training: 0.1970532802269461 | validation: 0.1458365166949813]
	TIME [epoch: 195 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.19573511439538804		[learning rate: 0.0010061]
	Learning Rate: 0.00100608
	LOSS [training: 0.19573511439538804 | validation: 0.1510557794320219]
	TIME [epoch: 195 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 6/6] avg loss: 0.1947895622174098		[learning rate: 0.00099879]
	Learning Rate: 0.000998789
	LOSS [training: 0.1947895622174098 | validation: 0.14368383035480936]
	TIME [epoch: 195 sec]
EPOCH 368/1000:
	Training over batches...
