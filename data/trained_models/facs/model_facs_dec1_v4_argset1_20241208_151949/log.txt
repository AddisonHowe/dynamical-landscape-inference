Args:
Namespace(name='model_facs_dec1_v4_argset1', outdir='out/model_training/model_facs_dec1_v4_argset1', training_data='data/training_data/facs/facs_dec1_v4/training', validation_data='data/training_data/facs/facs_dec1_v4/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=10, batch_size=50, patience=200, min_epochs=10, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=800, ncells_sample=800, model_do_sample=False, dt=0.005, dt_schedule='stepped', dt_schedule_bounds=[100, 300, 500, 700], dt_schedule_scales=[0.5, 0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[1.6738450527191162], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1275003520

Training model...

Saving initial model state to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.2038250707184571		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2038250707184571 | validation: 0.16022786404131806]
	TIME [epoch: 29.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.17041612408459617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.17041612408459617 | validation: 0.1371504180681498]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1494391637941351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1494391637941351 | validation: 0.153110936755815]
	TIME [epoch: 4.13 sec]
EPOCH 4/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.14886097850869282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14886097850869282 | validation: 0.126314842283593]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1459890802287888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1459890802287888 | validation: 0.13645736757130378]
	TIME [epoch: 4.14 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.14356103875938078		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.14356103875938078 | validation: 0.12434557323858499]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.13729142063718933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13729142063718933 | validation: 0.1269420112752536]
	TIME [epoch: 4.15 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.13578338933778675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13578338933778675 | validation: 0.12286050483353829]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.13753095853172484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.13753095853172484 | validation: 0.1242855884602276]
	TIME [epoch: 4.14 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1337866771051869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1337866771051869 | validation: 0.12077578710388322]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1286636458555258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1286636458555258 | validation: 0.1192787328471217]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1263571687975054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1263571687975054 | validation: 0.11749479628156394]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12426325013706103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12426325013706103 | validation: 0.12139268035008006]
	TIME [epoch: 4.14 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12667224798299567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12667224798299567 | validation: 0.11785298690161745]
	TIME [epoch: 4.14 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12705089713890524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12705089713890524 | validation: 0.11919333497773009]
	TIME [epoch: 4.14 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.12015454195501767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.12015454195501767 | validation: 0.11256000338443471]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.11744763083050974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.11744763083050974 | validation: 0.1157242654929543]
	TIME [epoch: 4.12 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1146731230960245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1146731230960245 | validation: 0.111163453629827]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1104024231523359		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1104024231523359 | validation: 0.10554362145311495]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10563437149302814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10563437149302814 | validation: 0.10212801861685439]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10684076865803599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10684076865803599 | validation: 0.11093525708107684]
	TIME [epoch: 4.15 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10344978717249233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10344978717249233 | validation: 0.11317263135302223]
	TIME [epoch: 4.13 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.1006583549876844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.1006583549876844 | validation: 0.10404189728793985]
	TIME [epoch: 4.13 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09428915757938672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09428915757938672 | validation: 0.09615485320947659]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.10331479607534565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.10331479607534565 | validation: 0.09722445490103905]
	TIME [epoch: 4.14 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.09465967401687614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.09465967401687614 | validation: 0.09427260800221633]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08840540494767146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08840540494767146 | validation: 0.08862692586412045]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08056557620591416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08056557620591416 | validation: 0.08679032620342554]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08180131393452332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08180131393452332 | validation: 0.08925298477358608]
	TIME [epoch: 4.13 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.08251186829552065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.08251186829552065 | validation: 0.08843041964062882]
	TIME [epoch: 4.12 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07572911352188849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07572911352188849 | validation: 0.07995421498993067]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06986386740123646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06986386740123646 | validation: 0.07996513353376701]
	TIME [epoch: 4.14 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07195680078429496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07195680078429496 | validation: 0.08130740951498648]
	TIME [epoch: 4.15 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.07055691081733502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.07055691081733502 | validation: 0.07263304246993148]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06636014008233897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06636014008233897 | validation: 0.07358063179403092]
	TIME [epoch: 4.13 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06589502675438717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06589502675438717 | validation: 0.06531301930429119]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05886294465518283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05886294465518283 | validation: 0.07268065960738676]
	TIME [epoch: 4.12 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.06105802578705936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.06105802578705936 | validation: 0.07018736697901272]
	TIME [epoch: 4.13 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.058448547795780986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.058448547795780986 | validation: 0.06577152327885559]
	TIME [epoch: 4.12 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0537591966580663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.0537591966580663 | validation: 0.058402741867791486]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05455017205236043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05455017205236043 | validation: 0.05578225219105226]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.05204977224788864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.05204977224788864 | validation: 0.055530924478862355]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.049745865017387904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.049745865017387904 | validation: 0.055311042387110015]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_43.pth
	Model improved!!!
EPOCH 44/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04922947144188383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04922947144188383 | validation: 0.05301265631762996]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04491914476314884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04491914476314884 | validation: 0.051955560711568906]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04903760253383074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04903760253383074 | validation: 0.052493301015792165]
	TIME [epoch: 4.13 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04719806824839342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04719806824839342 | validation: 0.04862586968322483]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04522533168284343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04522533168284343 | validation: 0.04639180324216361]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04573860861858401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04573860861858401 | validation: 0.04501372691769659]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04702024980322972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.04702024980322972 | validation: 0.045727487565105945]
	TIME [epoch: 4.13 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04359756983736617		[learning rate: 0.0099677]
	Learning Rate: 0.00996774
	LOSS [training: 0.04359756983736617 | validation: 0.048391086166177044]
	TIME [epoch: 4.12 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04226701641814056		[learning rate: 0.0099195]
	Learning Rate: 0.00991953
	LOSS [training: 0.04226701641814056 | validation: 0.04759743781901806]
	TIME [epoch: 4.12 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.042700147768818336		[learning rate: 0.0098716]
	Learning Rate: 0.00987156
	LOSS [training: 0.042700147768818336 | validation: 0.0470384469912728]
	TIME [epoch: 4.12 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04414988659900528		[learning rate: 0.0098238]
	Learning Rate: 0.00982383
	LOSS [training: 0.04414988659900528 | validation: 0.04226123496577635]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.042765020117230344		[learning rate: 0.0097763]
	Learning Rate: 0.00977632
	LOSS [training: 0.042765020117230344 | validation: 0.03826239633305186]
	TIME [epoch: 4.12 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04154288563144987		[learning rate: 0.009729]
	Learning Rate: 0.00972904
	LOSS [training: 0.04154288563144987 | validation: 0.04386240248934251]
	TIME [epoch: 4.13 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.039591787865914684		[learning rate: 0.009682]
	Learning Rate: 0.009682
	LOSS [training: 0.039591787865914684 | validation: 0.042858322069553784]
	TIME [epoch: 4.12 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.042820573610370054		[learning rate: 0.0096352]
	Learning Rate: 0.00963518
	LOSS [training: 0.042820573610370054 | validation: 0.04669379042096853]
	TIME [epoch: 4.13 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04233231508106434		[learning rate: 0.0095886]
	Learning Rate: 0.00958858
	LOSS [training: 0.04233231508106434 | validation: 0.04256566005487487]
	TIME [epoch: 4.12 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.04355869606157701		[learning rate: 0.0095422]
	Learning Rate: 0.00954221
	LOSS [training: 0.04355869606157701 | validation: 0.04286250996574817]
	TIME [epoch: 4.12 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0406646115431305		[learning rate: 0.0094961]
	Learning Rate: 0.00949607
	LOSS [training: 0.0406646115431305 | validation: 0.038996000864241175]
	TIME [epoch: 4.13 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.041729333232178895		[learning rate: 0.0094501]
	Learning Rate: 0.00945015
	LOSS [training: 0.041729333232178895 | validation: 0.03887857403684855]
	TIME [epoch: 4.13 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.038888696517868394		[learning rate: 0.0094044]
	Learning Rate: 0.00940445
	LOSS [training: 0.038888696517868394 | validation: 0.03596797625413596]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0405995453402059		[learning rate: 0.009359]
	Learning Rate: 0.00935897
	LOSS [training: 0.0405995453402059 | validation: 0.03729715896020184]
	TIME [epoch: 4.13 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.036463709078891626		[learning rate: 0.0093137]
	Learning Rate: 0.00931371
	LOSS [training: 0.036463709078891626 | validation: 0.04053774626607473]
	TIME [epoch: 4.13 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.035977369059315124		[learning rate: 0.0092687]
	Learning Rate: 0.00926867
	LOSS [training: 0.035977369059315124 | validation: 0.04024441047170474]
	TIME [epoch: 4.13 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0366079108376017		[learning rate: 0.0092239]
	Learning Rate: 0.00922385
	LOSS [training: 0.0366079108376017 | validation: 0.04136063574015395]
	TIME [epoch: 4.13 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03446243462049323		[learning rate: 0.0091792]
	Learning Rate: 0.00917925
	LOSS [training: 0.03446243462049323 | validation: 0.035232060522294106]
	TIME [epoch: 4.13 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.038179069656498366		[learning rate: 0.0091349]
	Learning Rate: 0.00913486
	LOSS [training: 0.038179069656498366 | validation: 0.039612613205190016]
	TIME [epoch: 4.14 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.037923899100749586		[learning rate: 0.0090907]
	Learning Rate: 0.00909068
	LOSS [training: 0.037923899100749586 | validation: 0.03487408850053385]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_70.pth
	Model improved!!!
EPOCH 71/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03593524806665343		[learning rate: 0.0090467]
	Learning Rate: 0.00904672
	LOSS [training: 0.03593524806665343 | validation: 0.04077399984425128]
	TIME [epoch: 4.14 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.037472944311065674		[learning rate: 0.009003]
	Learning Rate: 0.00900297
	LOSS [training: 0.037472944311065674 | validation: 0.03468449682268135]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_72.pth
	Model improved!!!
EPOCH 73/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.034912270354201635		[learning rate: 0.0089594]
	Learning Rate: 0.00895944
	LOSS [training: 0.034912270354201635 | validation: 0.03791746273322158]
	TIME [epoch: 4.14 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.035719135198456035		[learning rate: 0.0089161]
	Learning Rate: 0.00891611
	LOSS [training: 0.035719135198456035 | validation: 0.03773501464489986]
	TIME [epoch: 4.14 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03442042313640117		[learning rate: 0.008873]
	Learning Rate: 0.00887299
	LOSS [training: 0.03442042313640117 | validation: 0.03607058921134174]
	TIME [epoch: 4.14 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03442006618036735		[learning rate: 0.0088301]
	Learning Rate: 0.00883009
	LOSS [training: 0.03442006618036735 | validation: 0.03850091791502841]
	TIME [epoch: 4.13 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03391168438269435		[learning rate: 0.0087874]
	Learning Rate: 0.00878738
	LOSS [training: 0.03391168438269435 | validation: 0.03789934585302088]
	TIME [epoch: 4.14 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031706495727179894		[learning rate: 0.0087449]
	Learning Rate: 0.00874489
	LOSS [training: 0.031706495727179894 | validation: 0.03456835109757783]
	TIME [epoch: 4.14 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03211704511971405		[learning rate: 0.0087026]
	Learning Rate: 0.0087026
	LOSS [training: 0.03211704511971405 | validation: 0.03399653453185356]
	TIME [epoch: 4.16 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03539911033584769		[learning rate: 0.0086605]
	Learning Rate: 0.00866052
	LOSS [training: 0.03539911033584769 | validation: 0.03444942577241827]
	TIME [epoch: 4.16 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03195664757770848		[learning rate: 0.0086186]
	Learning Rate: 0.00861864
	LOSS [training: 0.03195664757770848 | validation: 0.033531291881748373]
	TIME [epoch: 4.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03127753537677932		[learning rate: 0.008577]
	Learning Rate: 0.00857696
	LOSS [training: 0.03127753537677932 | validation: 0.037498605088984026]
	TIME [epoch: 4.16 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03214496886428637		[learning rate: 0.0085355]
	Learning Rate: 0.00853548
	LOSS [training: 0.03214496886428637 | validation: 0.03616827787863796]
	TIME [epoch: 4.15 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03217462871912308		[learning rate: 0.0084942]
	Learning Rate: 0.00849421
	LOSS [training: 0.03217462871912308 | validation: 0.034541064438774895]
	TIME [epoch: 4.15 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03293000887838458		[learning rate: 0.0084531]
	Learning Rate: 0.00845313
	LOSS [training: 0.03293000887838458 | validation: 0.037016116054225806]
	TIME [epoch: 4.16 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03280803972247507		[learning rate: 0.0084123]
	Learning Rate: 0.00841225
	LOSS [training: 0.03280803972247507 | validation: 0.03326188555206367]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03036063284974383		[learning rate: 0.0083716]
	Learning Rate: 0.00837157
	LOSS [training: 0.03036063284974383 | validation: 0.03481008859971146]
	TIME [epoch: 4.16 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03387450957330108		[learning rate: 0.0083311]
	Learning Rate: 0.00833109
	LOSS [training: 0.03387450957330108 | validation: 0.03548390502476342]
	TIME [epoch: 4.16 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031518400732321455		[learning rate: 0.0082908]
	Learning Rate: 0.0082908
	LOSS [training: 0.031518400732321455 | validation: 0.0338379998053231]
	TIME [epoch: 4.16 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029704825222669155		[learning rate: 0.0082507]
	Learning Rate: 0.00825071
	LOSS [training: 0.029704825222669155 | validation: 0.034536004517872705]
	TIME [epoch: 4.15 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03070905235516942		[learning rate: 0.0082108]
	Learning Rate: 0.00821081
	LOSS [training: 0.03070905235516942 | validation: 0.03377189090945775]
	TIME [epoch: 4.15 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029104523170429122		[learning rate: 0.0081711]
	Learning Rate: 0.0081711
	LOSS [training: 0.029104523170429122 | validation: 0.0344065146065266]
	TIME [epoch: 4.15 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03387244619933963		[learning rate: 0.0081316]
	Learning Rate: 0.00813159
	LOSS [training: 0.03387244619933963 | validation: 0.034334071742517354]
	TIME [epoch: 4.15 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03093424564599442		[learning rate: 0.0080923]
	Learning Rate: 0.00809227
	LOSS [training: 0.03093424564599442 | validation: 0.032399914820126975]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02927686661555086		[learning rate: 0.0080531]
	Learning Rate: 0.00805313
	LOSS [training: 0.02927686661555086 | validation: 0.035050255479302427]
	TIME [epoch: 4.16 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030060499573629374		[learning rate: 0.0080142]
	Learning Rate: 0.00801419
	LOSS [training: 0.030060499573629374 | validation: 0.03243796729699666]
	TIME [epoch: 4.15 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03000844055319038		[learning rate: 0.0079754]
	Learning Rate: 0.00797543
	LOSS [training: 0.03000844055319038 | validation: 0.04033973213069078]
	TIME [epoch: 4.16 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030662448557901973		[learning rate: 0.0079369]
	Learning Rate: 0.00793687
	LOSS [training: 0.030662448557901973 | validation: 0.030568730536585723]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030681888473143293		[learning rate: 0.0078985]
	Learning Rate: 0.00789849
	LOSS [training: 0.030681888473143293 | validation: 0.02995454501780565]
	TIME [epoch: 4.15 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027500376769901955		[learning rate: 0.0078603]
	Learning Rate: 0.00786029
	LOSS [training: 0.027500376769901955 | validation: 0.0316217037208363]
	TIME [epoch: 4.14 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02716433558538472		[learning rate: 0.0078223]
	Learning Rate: 0.00782228
	LOSS [training: 0.02716433558538472 | validation: 0.032396914684359346]
	TIME [epoch: 31.9 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027998757836399924		[learning rate: 0.0077845]
	Learning Rate: 0.00778445
	LOSS [training: 0.027998757836399924 | validation: 0.030604825394244254]
	TIME [epoch: 7.98 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02718834975389786		[learning rate: 0.0077468]
	Learning Rate: 0.00774681
	LOSS [training: 0.02718834975389786 | validation: 0.03459816567073513]
	TIME [epoch: 7.98 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.031230756787504695		[learning rate: 0.0077093]
	Learning Rate: 0.00770935
	LOSS [training: 0.031230756787504695 | validation: 0.03673837122329204]
	TIME [epoch: 7.97 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029967932241580716		[learning rate: 0.0076721]
	Learning Rate: 0.00767206
	LOSS [training: 0.029967932241580716 | validation: 0.03292075935589799]
	TIME [epoch: 7.98 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028796714472966254		[learning rate: 0.007635]
	Learning Rate: 0.00763496
	LOSS [training: 0.028796714472966254 | validation: 0.03254521019835268]
	TIME [epoch: 7.99 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03222752590608796		[learning rate: 0.007598]
	Learning Rate: 0.00759804
	LOSS [training: 0.03222752590608796 | validation: 0.031439291528887796]
	TIME [epoch: 7.99 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.029485926368405985		[learning rate: 0.0075613]
	Learning Rate: 0.0075613
	LOSS [training: 0.029485926368405985 | validation: 0.030576593480323818]
	TIME [epoch: 7.99 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026597834530727473		[learning rate: 0.0075247]
	Learning Rate: 0.00752474
	LOSS [training: 0.026597834530727473 | validation: 0.02975884693843506]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_109.pth
	Model improved!!!
EPOCH 110/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025551304134891983		[learning rate: 0.0074883]
	Learning Rate: 0.00748835
	LOSS [training: 0.025551304134891983 | validation: 0.029783915232161114]
	TIME [epoch: 7.99 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026447381670352214		[learning rate: 0.0074521]
	Learning Rate: 0.00745213
	LOSS [training: 0.026447381670352214 | validation: 0.0311591017466383]
	TIME [epoch: 8 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027328209254775162		[learning rate: 0.0074161]
	Learning Rate: 0.0074161
	LOSS [training: 0.027328209254775162 | validation: 0.03056642802650611]
	TIME [epoch: 7.99 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026718196312256633		[learning rate: 0.0073802]
	Learning Rate: 0.00738023
	LOSS [training: 0.026718196312256633 | validation: 0.030090529412501524]
	TIME [epoch: 7.98 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02598684840268924		[learning rate: 0.0073445]
	Learning Rate: 0.00734454
	LOSS [training: 0.02598684840268924 | validation: 0.029572877646222576]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02788772294681478		[learning rate: 0.007309]
	Learning Rate: 0.00730903
	LOSS [training: 0.02788772294681478 | validation: 0.02984243273863488]
	TIME [epoch: 8 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02694261277120474		[learning rate: 0.0072737]
	Learning Rate: 0.00727368
	LOSS [training: 0.02694261277120474 | validation: 0.0300633988982331]
	TIME [epoch: 7.98 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025919792173053836		[learning rate: 0.0072385]
	Learning Rate: 0.00723851
	LOSS [training: 0.025919792173053836 | validation: 0.030071819712224168]
	TIME [epoch: 7.99 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02633062840333834		[learning rate: 0.0072035]
	Learning Rate: 0.0072035
	LOSS [training: 0.02633062840333834 | validation: 0.03166382949624592]
	TIME [epoch: 7.98 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026262014094952824		[learning rate: 0.0071687]
	Learning Rate: 0.00716867
	LOSS [training: 0.026262014094952824 | validation: 0.031419979912242775]
	TIME [epoch: 7.99 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026705836990500595		[learning rate: 0.007134]
	Learning Rate: 0.007134
	LOSS [training: 0.026705836990500595 | validation: 0.03087396719483047]
	TIME [epoch: 7.99 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02753534950517907		[learning rate: 0.0070995]
	Learning Rate: 0.0070995
	LOSS [training: 0.02753534950517907 | validation: 0.03021734162624913]
	TIME [epoch: 7.98 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0256613677104796		[learning rate: 0.0070652]
	Learning Rate: 0.00706517
	LOSS [training: 0.0256613677104796 | validation: 0.02908873868151748]
	TIME [epoch: 7.99 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028373951524703983		[learning rate: 0.007031]
	Learning Rate: 0.00703101
	LOSS [training: 0.028373951524703983 | validation: 0.036520529783019416]
	TIME [epoch: 8.02 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.03843982051484238		[learning rate: 0.006997]
	Learning Rate: 0.00699701
	LOSS [training: 0.03843982051484238 | validation: 0.02866882422792284]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_124.pth
	Model improved!!!
EPOCH 125/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027884931738201172		[learning rate: 0.0069632]
	Learning Rate: 0.00696317
	LOSS [training: 0.027884931738201172 | validation: 0.030058606649571457]
	TIME [epoch: 8.03 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02648391867043204		[learning rate: 0.0069295]
	Learning Rate: 0.0069295
	LOSS [training: 0.02648391867043204 | validation: 0.028462540949675274]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_126.pth
	Model improved!!!
EPOCH 127/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025512829174399346		[learning rate: 0.006896]
	Learning Rate: 0.00689599
	LOSS [training: 0.025512829174399346 | validation: 0.0308548562571465]
	TIME [epoch: 8.02 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026700998926762153		[learning rate: 0.0068626]
	Learning Rate: 0.00686264
	LOSS [training: 0.026700998926762153 | validation: 0.029754099879717267]
	TIME [epoch: 8.01 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026968842957667202		[learning rate: 0.0068295]
	Learning Rate: 0.00682945
	LOSS [training: 0.026968842957667202 | validation: 0.028769065811301325]
	TIME [epoch: 8.01 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025687498556204332		[learning rate: 0.0067964]
	Learning Rate: 0.00679643
	LOSS [training: 0.025687498556204332 | validation: 0.029200318149954607]
	TIME [epoch: 8.02 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026963136926647608		[learning rate: 0.0067636]
	Learning Rate: 0.00676356
	LOSS [training: 0.026963136926647608 | validation: 0.028632003902091096]
	TIME [epoch: 8.02 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025238469063823345		[learning rate: 0.0067309]
	Learning Rate: 0.00673085
	LOSS [training: 0.025238469063823345 | validation: 0.030299026304777838]
	TIME [epoch: 8.02 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.026807750848366913		[learning rate: 0.0066983]
	Learning Rate: 0.0066983
	LOSS [training: 0.026807750848366913 | validation: 0.031186172955204646]
	TIME [epoch: 8.02 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027086052002170125		[learning rate: 0.0066659]
	Learning Rate: 0.00666591
	LOSS [training: 0.027086052002170125 | validation: 0.029685449175001502]
	TIME [epoch: 8.02 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02668434394074512		[learning rate: 0.0066337]
	Learning Rate: 0.00663368
	LOSS [training: 0.02668434394074512 | validation: 0.027910127516508676]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_135.pth
	Model improved!!!
EPOCH 136/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027972092004247117		[learning rate: 0.0066016]
	Learning Rate: 0.0066016
	LOSS [training: 0.027972092004247117 | validation: 0.030124037265927744]
	TIME [epoch: 7.99 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025128438225445443		[learning rate: 0.0065697]
	Learning Rate: 0.00656967
	LOSS [training: 0.025128438225445443 | validation: 0.028810828874864376]
	TIME [epoch: 7.98 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025537408133556		[learning rate: 0.0065379]
	Learning Rate: 0.0065379
	LOSS [training: 0.025537408133556 | validation: 0.02933911410797274]
	TIME [epoch: 7.99 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027564810326228113		[learning rate: 0.0065063]
	Learning Rate: 0.00650629
	LOSS [training: 0.027564810326228113 | validation: 0.028219381869171167]
	TIME [epoch: 7.99 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02580723413505494		[learning rate: 0.0064748]
	Learning Rate: 0.00647483
	LOSS [training: 0.02580723413505494 | validation: 0.028191001945081187]
	TIME [epoch: 8 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024613045245833038		[learning rate: 0.0064435]
	Learning Rate: 0.00644351
	LOSS [training: 0.024613045245833038 | validation: 0.028830418335415792]
	TIME [epoch: 7.99 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023999532210476446		[learning rate: 0.0064124]
	Learning Rate: 0.00641235
	LOSS [training: 0.023999532210476446 | validation: 0.029822554562925097]
	TIME [epoch: 8 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025443227391851883		[learning rate: 0.0063813]
	Learning Rate: 0.00638135
	LOSS [training: 0.025443227391851883 | validation: 0.030323216983745765]
	TIME [epoch: 7.98 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028799199252962735		[learning rate: 0.0063505]
	Learning Rate: 0.00635049
	LOSS [training: 0.028799199252962735 | validation: 0.02879525691862453]
	TIME [epoch: 7.97 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024638189831128515		[learning rate: 0.0063198]
	Learning Rate: 0.00631978
	LOSS [training: 0.024638189831128515 | validation: 0.02763585891130056]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023860715973589547		[learning rate: 0.0062892]
	Learning Rate: 0.00628922
	LOSS [training: 0.023860715973589547 | validation: 0.029575836847802045]
	TIME [epoch: 7.97 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.027759487033862728		[learning rate: 0.0062588]
	Learning Rate: 0.0062588
	LOSS [training: 0.027759487033862728 | validation: 0.028246001035900258]
	TIME [epoch: 7.98 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02343910516777149		[learning rate: 0.0062285]
	Learning Rate: 0.00622854
	LOSS [training: 0.02343910516777149 | validation: 0.02705785729988916]
	TIME [epoch: 8.02 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_148.pth
	Model improved!!!
EPOCH 149/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02535398271713225		[learning rate: 0.0061984]
	Learning Rate: 0.00619842
	LOSS [training: 0.02535398271713225 | validation: 0.027573824879417938]
	TIME [epoch: 8.02 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025453730895856914		[learning rate: 0.0061684]
	Learning Rate: 0.00616844
	LOSS [training: 0.025453730895856914 | validation: 0.027324284659572016]
	TIME [epoch: 8.02 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02643162020010577		[learning rate: 0.0061386]
	Learning Rate: 0.00613861
	LOSS [training: 0.02643162020010577 | validation: 0.026761127044046578]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_151.pth
	Model improved!!!
EPOCH 152/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023838769895171866		[learning rate: 0.0061089]
	Learning Rate: 0.00610893
	LOSS [training: 0.023838769895171866 | validation: 0.027692974258106174]
	TIME [epoch: 7.98 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024143724905160407		[learning rate: 0.0060794]
	Learning Rate: 0.00607938
	LOSS [training: 0.024143724905160407 | validation: 0.028075962041789342]
	TIME [epoch: 7.97 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02411983189562476		[learning rate: 0.00605]
	Learning Rate: 0.00604999
	LOSS [training: 0.02411983189562476 | validation: 0.028311622229276582]
	TIME [epoch: 7.98 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02408660256716552		[learning rate: 0.0060207]
	Learning Rate: 0.00602073
	LOSS [training: 0.02408660256716552 | validation: 0.029563891353439453]
	TIME [epoch: 7.99 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023800952415863653		[learning rate: 0.0059916]
	Learning Rate: 0.00599161
	LOSS [training: 0.023800952415863653 | validation: 0.027695022281357524]
	TIME [epoch: 7.99 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02480612537255808		[learning rate: 0.0059626]
	Learning Rate: 0.00596264
	LOSS [training: 0.02480612537255808 | validation: 0.02631532015292709]
	TIME [epoch: 8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_157.pth
	Model improved!!!
EPOCH 158/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023144140682934997		[learning rate: 0.0059338]
	Learning Rate: 0.00593381
	LOSS [training: 0.023144140682934997 | validation: 0.027513512515660605]
	TIME [epoch: 7.99 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025399238901835253		[learning rate: 0.0059051]
	Learning Rate: 0.00590511
	LOSS [training: 0.025399238901835253 | validation: 0.02806724256601772]
	TIME [epoch: 7.98 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023535869249695498		[learning rate: 0.0058766]
	Learning Rate: 0.00587655
	LOSS [training: 0.023535869249695498 | validation: 0.02893759582714503]
	TIME [epoch: 7.98 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02502406952816234		[learning rate: 0.0058481]
	Learning Rate: 0.00584814
	LOSS [training: 0.02502406952816234 | validation: 0.02953463174931874]
	TIME [epoch: 7.98 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024563171035501985		[learning rate: 0.0058199]
	Learning Rate: 0.00581986
	LOSS [training: 0.024563171035501985 | validation: 0.029327136514161477]
	TIME [epoch: 7.98 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022837974750902785		[learning rate: 0.0057917]
	Learning Rate: 0.00579171
	LOSS [training: 0.022837974750902785 | validation: 0.0274797996499284]
	TIME [epoch: 7.97 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02313055563315794		[learning rate: 0.0057637]
	Learning Rate: 0.0057637
	LOSS [training: 0.02313055563315794 | validation: 0.027225242405782935]
	TIME [epoch: 7.99 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024186549361801996		[learning rate: 0.0057358]
	Learning Rate: 0.00573583
	LOSS [training: 0.024186549361801996 | validation: 0.026486082979523106]
	TIME [epoch: 7.99 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0234451478878418		[learning rate: 0.0057081]
	Learning Rate: 0.0057081
	LOSS [training: 0.0234451478878418 | validation: 0.0288765344331232]
	TIME [epoch: 7.98 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02314991239652218		[learning rate: 0.0056805]
	Learning Rate: 0.00568049
	LOSS [training: 0.02314991239652218 | validation: 0.02784732662379937]
	TIME [epoch: 7.99 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022063509650809845		[learning rate: 0.005653]
	Learning Rate: 0.00565302
	LOSS [training: 0.022063509650809845 | validation: 0.026656115804949743]
	TIME [epoch: 7.98 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025916951813777133		[learning rate: 0.0056257]
	Learning Rate: 0.00562569
	LOSS [training: 0.025916951813777133 | validation: 0.02983284045975627]
	TIME [epoch: 7.97 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02371714868395027		[learning rate: 0.0055985]
	Learning Rate: 0.00559848
	LOSS [training: 0.02371714868395027 | validation: 0.028576784315552304]
	TIME [epoch: 7.99 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023200042112834652		[learning rate: 0.0055714]
	Learning Rate: 0.00557141
	LOSS [training: 0.023200042112834652 | validation: 0.029913783653720202]
	TIME [epoch: 7.98 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023091384409401366		[learning rate: 0.0055445]
	Learning Rate: 0.00554447
	LOSS [training: 0.023091384409401366 | validation: 0.028629960499832408]
	TIME [epoch: 7.98 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022796653434291794		[learning rate: 0.0055177]
	Learning Rate: 0.00551765
	LOSS [training: 0.022796653434291794 | validation: 0.028161764116942697]
	TIME [epoch: 7.98 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0244617339324902		[learning rate: 0.005491]
	Learning Rate: 0.00549097
	LOSS [training: 0.0244617339324902 | validation: 0.029916225999019223]
	TIME [epoch: 7.99 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0244491115986992		[learning rate: 0.0054644]
	Learning Rate: 0.00546442
	LOSS [training: 0.0244491115986992 | validation: 0.027119607906061355]
	TIME [epoch: 7.98 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022703011180357013		[learning rate: 0.005438]
	Learning Rate: 0.00543799
	LOSS [training: 0.022703011180357013 | validation: 0.027596848390315936]
	TIME [epoch: 7.98 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02245989420819169		[learning rate: 0.0054117]
	Learning Rate: 0.0054117
	LOSS [training: 0.02245989420819169 | validation: 0.028242306910874104]
	TIME [epoch: 7.98 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023474829579697154		[learning rate: 0.0053855]
	Learning Rate: 0.00538553
	LOSS [training: 0.023474829579697154 | validation: 0.02708104576115947]
	TIME [epoch: 7.98 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024788863592236313		[learning rate: 0.0053595]
	Learning Rate: 0.00535948
	LOSS [training: 0.024788863592236313 | validation: 0.02884099557724354]
	TIME [epoch: 7.98 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02696116301969845		[learning rate: 0.0053336]
	Learning Rate: 0.00533356
	LOSS [training: 0.02696116301969845 | validation: 0.026574823685086877]
	TIME [epoch: 7.98 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025115078275357		[learning rate: 0.0053078]
	Learning Rate: 0.00530777
	LOSS [training: 0.025115078275357 | validation: 0.02869639011820303]
	TIME [epoch: 7.99 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023360013211504948		[learning rate: 0.0052821]
	Learning Rate: 0.0052821
	LOSS [training: 0.023360013211504948 | validation: 0.027763526305362825]
	TIME [epoch: 7.99 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024085989684703792		[learning rate: 0.0052566]
	Learning Rate: 0.00525656
	LOSS [training: 0.024085989684703792 | validation: 0.027359707236266965]
	TIME [epoch: 7.99 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02299737166909806		[learning rate: 0.0052311]
	Learning Rate: 0.00523114
	LOSS [training: 0.02299737166909806 | validation: 0.026545027746468542]
	TIME [epoch: 7.99 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023725464985966543		[learning rate: 0.0052058]
	Learning Rate: 0.00520584
	LOSS [training: 0.023725464985966543 | validation: 0.02742036772341606]
	TIME [epoch: 7.99 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023896377222740284		[learning rate: 0.0051807]
	Learning Rate: 0.00518067
	LOSS [training: 0.023896377222740284 | validation: 0.026967968583615724]
	TIME [epoch: 8 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022294038907901437		[learning rate: 0.0051556]
	Learning Rate: 0.00515562
	LOSS [training: 0.022294038907901437 | validation: 0.02762971919102627]
	TIME [epoch: 7.98 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023999900705262023		[learning rate: 0.0051307]
	Learning Rate: 0.00513069
	LOSS [training: 0.023999900705262023 | validation: 0.025733048629090288]
	TIME [epoch: 7.98 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_188.pth
	Model improved!!!
EPOCH 189/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02253286379538035		[learning rate: 0.0051059]
	Learning Rate: 0.00510587
	LOSS [training: 0.02253286379538035 | validation: 0.026700382042356943]
	TIME [epoch: 8.01 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02196645018424696		[learning rate: 0.0050812]
	Learning Rate: 0.00508118
	LOSS [training: 0.02196645018424696 | validation: 0.02642959720797095]
	TIME [epoch: 8.02 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02118460350115535		[learning rate: 0.0050566]
	Learning Rate: 0.00505661
	LOSS [training: 0.02118460350115535 | validation: 0.02710936485237962]
	TIME [epoch: 8.01 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021971294261573026		[learning rate: 0.0050322]
	Learning Rate: 0.00503216
	LOSS [training: 0.021971294261573026 | validation: 0.027300946006159007]
	TIME [epoch: 8.01 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02370197613938238		[learning rate: 0.0050078]
	Learning Rate: 0.00500782
	LOSS [training: 0.02370197613938238 | validation: 0.026473877937468655]
	TIME [epoch: 8.01 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022111696429797417		[learning rate: 0.0049836]
	Learning Rate: 0.00498361
	LOSS [training: 0.022111696429797417 | validation: 0.026877609026056477]
	TIME [epoch: 8.01 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.030992204164010047		[learning rate: 0.0049595]
	Learning Rate: 0.00495951
	LOSS [training: 0.030992204164010047 | validation: 0.03200533162719176]
	TIME [epoch: 8.02 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024334532106491596		[learning rate: 0.0049355]
	Learning Rate: 0.00493552
	LOSS [training: 0.024334532106491596 | validation: 0.027845312482618106]
	TIME [epoch: 8.03 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02234287288490475		[learning rate: 0.0049117]
	Learning Rate: 0.00491166
	LOSS [training: 0.02234287288490475 | validation: 0.025396312039280167]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_197.pth
	Model improved!!!
EPOCH 198/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021688079572243984		[learning rate: 0.0048879]
	Learning Rate: 0.00488791
	LOSS [training: 0.021688079572243984 | validation: 0.025018927674060807]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_198.pth
	Model improved!!!
EPOCH 199/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021013036294529233		[learning rate: 0.0048643]
	Learning Rate: 0.00486427
	LOSS [training: 0.021013036294529233 | validation: 0.025265243119526878]
	TIME [epoch: 8 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022027529733581155		[learning rate: 0.0048407]
	Learning Rate: 0.00484075
	LOSS [training: 0.022027529733581155 | validation: 0.025179382221668312]
	TIME [epoch: 8 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0212526189951945		[learning rate: 0.0048173]
	Learning Rate: 0.00481734
	LOSS [training: 0.0212526189951945 | validation: 0.028702189079305995]
	TIME [epoch: 8 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.025909472830477842		[learning rate: 0.004794]
	Learning Rate: 0.00479404
	LOSS [training: 0.025909472830477842 | validation: 0.026615005028513456]
	TIME [epoch: 8.01 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024288196396168946		[learning rate: 0.0047709]
	Learning Rate: 0.00477086
	LOSS [training: 0.024288196396168946 | validation: 0.024968143888266306]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_203.pth
	Model improved!!!
EPOCH 204/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021029138235983815		[learning rate: 0.0047478]
	Learning Rate: 0.00474779
	LOSS [training: 0.021029138235983815 | validation: 0.026560889600701947]
	TIME [epoch: 8.01 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02097081392387733		[learning rate: 0.0047248]
	Learning Rate: 0.00472483
	LOSS [training: 0.02097081392387733 | validation: 0.02766715156727485]
	TIME [epoch: 8.01 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02240526408531321		[learning rate: 0.004702]
	Learning Rate: 0.00470198
	LOSS [training: 0.02240526408531321 | validation: 0.02574762263673197]
	TIME [epoch: 8.02 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021254779113716305		[learning rate: 0.0046792]
	Learning Rate: 0.00467924
	LOSS [training: 0.021254779113716305 | validation: 0.026312246994177096]
	TIME [epoch: 8.01 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020707723187433046		[learning rate: 0.0046566]
	Learning Rate: 0.00465661
	LOSS [training: 0.020707723187433046 | validation: 0.02445125070040058]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_208.pth
	Model improved!!!
EPOCH 209/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023489763008214423		[learning rate: 0.0046341]
	Learning Rate: 0.00463409
	LOSS [training: 0.023489763008214423 | validation: 0.027518932389972495]
	TIME [epoch: 8 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022984433628763092		[learning rate: 0.0046117]
	Learning Rate: 0.00461168
	LOSS [training: 0.022984433628763092 | validation: 0.026646856852651835]
	TIME [epoch: 8.02 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02070894776718863		[learning rate: 0.0045894]
	Learning Rate: 0.00458938
	LOSS [training: 0.02070894776718863 | validation: 0.026527561958319165]
	TIME [epoch: 8.02 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01996620665336399		[learning rate: 0.0045672]
	Learning Rate: 0.00456719
	LOSS [training: 0.01996620665336399 | validation: 0.024965098833706775]
	TIME [epoch: 8.01 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021337433694765196		[learning rate: 0.0045451]
	Learning Rate: 0.0045451
	LOSS [training: 0.021337433694765196 | validation: 0.02622912319712406]
	TIME [epoch: 8 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021346100510244954		[learning rate: 0.0045231]
	Learning Rate: 0.00452312
	LOSS [training: 0.021346100510244954 | validation: 0.026127511714035365]
	TIME [epoch: 8.01 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02784494357150727		[learning rate: 0.0045013]
	Learning Rate: 0.00450125
	LOSS [training: 0.02784494357150727 | validation: 0.02761142411193362]
	TIME [epoch: 8.01 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021912540889609988		[learning rate: 0.0044795]
	Learning Rate: 0.00447948
	LOSS [training: 0.021912540889609988 | validation: 0.024351877339880906]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_216.pth
	Model improved!!!
EPOCH 217/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020291386586279967		[learning rate: 0.0044578]
	Learning Rate: 0.00445782
	LOSS [training: 0.020291386586279967 | validation: 0.02498969333020708]
	TIME [epoch: 8.01 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02163420406879815		[learning rate: 0.0044363]
	Learning Rate: 0.00443627
	LOSS [training: 0.02163420406879815 | validation: 0.025072862337993097]
	TIME [epoch: 8.01 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020880720563739616		[learning rate: 0.0044148]
	Learning Rate: 0.00441481
	LOSS [training: 0.020880720563739616 | validation: 0.025669600432455805]
	TIME [epoch: 8 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020666893060846292		[learning rate: 0.0043935]
	Learning Rate: 0.00439346
	LOSS [training: 0.020666893060846292 | validation: 0.02678545198061495]
	TIME [epoch: 8.01 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020980899431470582		[learning rate: 0.0043722]
	Learning Rate: 0.00437222
	LOSS [training: 0.020980899431470582 | validation: 0.02498565994205208]
	TIME [epoch: 8.01 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020672132873809024		[learning rate: 0.0043511]
	Learning Rate: 0.00435107
	LOSS [training: 0.020672132873809024 | validation: 0.024574562939525913]
	TIME [epoch: 8.02 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02030787422102028		[learning rate: 0.00433]
	Learning Rate: 0.00433003
	LOSS [training: 0.02030787422102028 | validation: 0.026756994849433512]
	TIME [epoch: 8.02 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021215892514633683		[learning rate: 0.0043091]
	Learning Rate: 0.00430909
	LOSS [training: 0.021215892514633683 | validation: 0.025986508760506132]
	TIME [epoch: 8.02 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022292620364443		[learning rate: 0.0042883]
	Learning Rate: 0.00428826
	LOSS [training: 0.022292620364443 | validation: 0.025301516040349845]
	TIME [epoch: 8.02 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021042024242609602		[learning rate: 0.0042675]
	Learning Rate: 0.00426752
	LOSS [training: 0.021042024242609602 | validation: 0.02437900934202289]
	TIME [epoch: 8.02 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024550861667315082		[learning rate: 0.0042469]
	Learning Rate: 0.00424688
	LOSS [training: 0.024550861667315082 | validation: 0.0288476360412296]
	TIME [epoch: 8.03 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024592588258711717		[learning rate: 0.0042263]
	Learning Rate: 0.00422634
	LOSS [training: 0.024592588258711717 | validation: 0.027560384445610802]
	TIME [epoch: 8.02 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023954409759258614		[learning rate: 0.0042059]
	Learning Rate: 0.00420591
	LOSS [training: 0.023954409759258614 | validation: 0.024926537028796446]
	TIME [epoch: 8.02 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02189652199321851		[learning rate: 0.0041856]
	Learning Rate: 0.00418557
	LOSS [training: 0.02189652199321851 | validation: 0.025846745305592906]
	TIME [epoch: 8.02 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023333687828359064		[learning rate: 0.0041653]
	Learning Rate: 0.00416533
	LOSS [training: 0.023333687828359064 | validation: 0.025893483240882895]
	TIME [epoch: 8.03 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0218217162904696		[learning rate: 0.0041452]
	Learning Rate: 0.00414518
	LOSS [training: 0.0218217162904696 | validation: 0.02461283151420507]
	TIME [epoch: 8.01 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021648064987223742		[learning rate: 0.0041251]
	Learning Rate: 0.00412514
	LOSS [training: 0.021648064987223742 | validation: 0.024982395644542663]
	TIME [epoch: 8.01 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021129285070244013		[learning rate: 0.0041052]
	Learning Rate: 0.00410519
	LOSS [training: 0.021129285070244013 | validation: 0.0233890679522966]
	TIME [epoch: 8.01 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_234.pth
	Model improved!!!
EPOCH 235/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022355864619496443		[learning rate: 0.0040853]
	Learning Rate: 0.00408534
	LOSS [training: 0.022355864619496443 | validation: 0.023566457362176874]
	TIME [epoch: 8.02 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019969711624068995		[learning rate: 0.0040656]
	Learning Rate: 0.00406558
	LOSS [training: 0.019969711624068995 | validation: 0.02393407103056512]
	TIME [epoch: 8.02 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02107746477127698		[learning rate: 0.0040459]
	Learning Rate: 0.00404592
	LOSS [training: 0.02107746477127698 | validation: 0.02571901995968758]
	TIME [epoch: 8.01 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020652024163870453		[learning rate: 0.0040264]
	Learning Rate: 0.00402636
	LOSS [training: 0.020652024163870453 | validation: 0.024314450327200542]
	TIME [epoch: 8 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02033135615819058		[learning rate: 0.0040069]
	Learning Rate: 0.00400689
	LOSS [training: 0.02033135615819058 | validation: 0.025540665515298155]
	TIME [epoch: 8 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021798246993264422		[learning rate: 0.0039875]
	Learning Rate: 0.00398751
	LOSS [training: 0.021798246993264422 | validation: 0.02440475946093511]
	TIME [epoch: 8 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02178091397742646		[learning rate: 0.0039682]
	Learning Rate: 0.00396823
	LOSS [training: 0.02178091397742646 | validation: 0.024294455142428478]
	TIME [epoch: 8.01 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023514496797247642		[learning rate: 0.003949]
	Learning Rate: 0.00394904
	LOSS [training: 0.023514496797247642 | validation: 0.02781763332076484]
	TIME [epoch: 8.01 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02428287112001706		[learning rate: 0.0039299]
	Learning Rate: 0.00392994
	LOSS [training: 0.02428287112001706 | validation: 0.025377554528237516]
	TIME [epoch: 8 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021022150498624548		[learning rate: 0.0039109]
	Learning Rate: 0.00391094
	LOSS [training: 0.021022150498624548 | validation: 0.02413281348218492]
	TIME [epoch: 8 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021652507763278605		[learning rate: 0.003892]
	Learning Rate: 0.00389202
	LOSS [training: 0.021652507763278605 | validation: 0.02415750688504617]
	TIME [epoch: 8 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02268093125136868		[learning rate: 0.0038732]
	Learning Rate: 0.0038732
	LOSS [training: 0.02268093125136868 | validation: 0.024760909514236457]
	TIME [epoch: 8.01 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02142567001055026		[learning rate: 0.0038545]
	Learning Rate: 0.00385447
	LOSS [training: 0.02142567001055026 | validation: 0.026242120330914748]
	TIME [epoch: 8 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0208505908444724		[learning rate: 0.0038358]
	Learning Rate: 0.00383583
	LOSS [training: 0.0208505908444724 | validation: 0.024381301632719076]
	TIME [epoch: 8.01 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021258924450086408		[learning rate: 0.0038173]
	Learning Rate: 0.00381728
	LOSS [training: 0.021258924450086408 | validation: 0.02380377510423569]
	TIME [epoch: 8 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020273087713675947		[learning rate: 0.0037988]
	Learning Rate: 0.00379882
	LOSS [training: 0.020273087713675947 | validation: 0.024445000285157822]
	TIME [epoch: 8 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02100018485603426		[learning rate: 0.0037805]
	Learning Rate: 0.00378045
	LOSS [training: 0.02100018485603426 | validation: 0.025355257209007137]
	TIME [epoch: 8.02 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021113684439864572		[learning rate: 0.0037622]
	Learning Rate: 0.00376217
	LOSS [training: 0.021113684439864572 | validation: 0.02507224372424273]
	TIME [epoch: 8.02 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02602517801538058		[learning rate: 0.003744]
	Learning Rate: 0.00374398
	LOSS [training: 0.02602517801538058 | validation: 0.025666115788674625]
	TIME [epoch: 8.01 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023388889978096017		[learning rate: 0.0037259]
	Learning Rate: 0.00372587
	LOSS [training: 0.023388889978096017 | validation: 0.024504686731881702]
	TIME [epoch: 8.01 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021716049915921094		[learning rate: 0.0037079]
	Learning Rate: 0.00370786
	LOSS [training: 0.021716049915921094 | validation: 0.02436547400279164]
	TIME [epoch: 8.01 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021920967147932773		[learning rate: 0.0036899]
	Learning Rate: 0.00368992
	LOSS [training: 0.021920967147932773 | validation: 0.025232576561243853]
	TIME [epoch: 8.01 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022197275720247222		[learning rate: 0.0036721]
	Learning Rate: 0.00367208
	LOSS [training: 0.022197275720247222 | validation: 0.025118993230554776]
	TIME [epoch: 8 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021249766798524698		[learning rate: 0.0036543]
	Learning Rate: 0.00365432
	LOSS [training: 0.021249766798524698 | validation: 0.02392152592067863]
	TIME [epoch: 8.01 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021782437708341557		[learning rate: 0.0036367]
	Learning Rate: 0.00363665
	LOSS [training: 0.021782437708341557 | validation: 0.027082411787993466]
	TIME [epoch: 8 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02370826165434041		[learning rate: 0.0036191]
	Learning Rate: 0.00361907
	LOSS [training: 0.02370826165434041 | validation: 0.025907277930776147]
	TIME [epoch: 8.01 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.024239776366343224		[learning rate: 0.0036016]
	Learning Rate: 0.00360156
	LOSS [training: 0.024239776366343224 | validation: 0.025317173541260656]
	TIME [epoch: 8.01 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02152494350696711		[learning rate: 0.0035841]
	Learning Rate: 0.00358415
	LOSS [training: 0.02152494350696711 | validation: 0.024932038372213125]
	TIME [epoch: 8.01 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021456460690541305		[learning rate: 0.0035668]
	Learning Rate: 0.00356682
	LOSS [training: 0.021456460690541305 | validation: 0.024297520812776963]
	TIME [epoch: 8 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022310333774597974		[learning rate: 0.0035496]
	Learning Rate: 0.00354957
	LOSS [training: 0.022310333774597974 | validation: 0.025086703026196144]
	TIME [epoch: 8.03 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021090360393067803		[learning rate: 0.0035324]
	Learning Rate: 0.0035324
	LOSS [training: 0.021090360393067803 | validation: 0.025430015228924418]
	TIME [epoch: 8.01 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021520399951138146		[learning rate: 0.0035153]
	Learning Rate: 0.00351532
	LOSS [training: 0.021520399951138146 | validation: 0.024880794333091264]
	TIME [epoch: 8 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022762327873436045		[learning rate: 0.0034983]
	Learning Rate: 0.00349832
	LOSS [training: 0.022762327873436045 | validation: 0.026329971751212516]
	TIME [epoch: 8 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02204237168879583		[learning rate: 0.0034814]
	Learning Rate: 0.0034814
	LOSS [training: 0.02204237168879583 | validation: 0.02575540366206948]
	TIME [epoch: 8 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02190533923507647		[learning rate: 0.0034646]
	Learning Rate: 0.00346457
	LOSS [training: 0.02190533923507647 | validation: 0.025337559478368844]
	TIME [epoch: 8 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0225978424512468		[learning rate: 0.0034478]
	Learning Rate: 0.00344781
	LOSS [training: 0.0225978424512468 | validation: 0.025071807164230228]
	TIME [epoch: 8 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021271686835934053		[learning rate: 0.0034311]
	Learning Rate: 0.00343114
	LOSS [training: 0.021271686835934053 | validation: 0.025249756410439906]
	TIME [epoch: 8 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01996387455204951		[learning rate: 0.0034145]
	Learning Rate: 0.00341455
	LOSS [training: 0.01996387455204951 | validation: 0.026095310951064]
	TIME [epoch: 8 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020578431835722444		[learning rate: 0.003398]
	Learning Rate: 0.00339804
	LOSS [training: 0.020578431835722444 | validation: 0.02591159862668982]
	TIME [epoch: 8 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020809234657453574		[learning rate: 0.0033816]
	Learning Rate: 0.0033816
	LOSS [training: 0.020809234657453574 | validation: 0.024355821312841197]
	TIME [epoch: 8.01 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02158928761032487		[learning rate: 0.0033653]
	Learning Rate: 0.00336525
	LOSS [training: 0.02158928761032487 | validation: 0.02489374906513733]
	TIME [epoch: 8 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02060335247091262		[learning rate: 0.003349]
	Learning Rate: 0.00334898
	LOSS [training: 0.02060335247091262 | validation: 0.02446812934707367]
	TIME [epoch: 8.01 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019815289756594346		[learning rate: 0.0033328]
	Learning Rate: 0.00333278
	LOSS [training: 0.019815289756594346 | validation: 0.025179384816580875]
	TIME [epoch: 8.01 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020343427031929543		[learning rate: 0.0033167]
	Learning Rate: 0.00331667
	LOSS [training: 0.020343427031929543 | validation: 0.02497715499991446]
	TIME [epoch: 8.01 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020983459007271877		[learning rate: 0.0033006]
	Learning Rate: 0.00330063
	LOSS [training: 0.020983459007271877 | validation: 0.02469440564562896]
	TIME [epoch: 8 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019993088198769975		[learning rate: 0.0032847]
	Learning Rate: 0.00328467
	LOSS [training: 0.019993088198769975 | validation: 0.025197347783065996]
	TIME [epoch: 8.01 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02134846090815513		[learning rate: 0.0032688]
	Learning Rate: 0.00326878
	LOSS [training: 0.02134846090815513 | validation: 0.024470246129791536]
	TIME [epoch: 8.01 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020583755702495977		[learning rate: 0.003253]
	Learning Rate: 0.00325297
	LOSS [training: 0.020583755702495977 | validation: 0.024767596967265364]
	TIME [epoch: 8.01 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01986117058187119		[learning rate: 0.0032372]
	Learning Rate: 0.00323724
	LOSS [training: 0.01986117058187119 | validation: 0.024472309606304588]
	TIME [epoch: 8.01 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019056181878182057		[learning rate: 0.0032216]
	Learning Rate: 0.00322159
	LOSS [training: 0.019056181878182057 | validation: 0.024480779228449667]
	TIME [epoch: 8.01 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019157356284282417		[learning rate: 0.003206]
	Learning Rate: 0.00320601
	LOSS [training: 0.019157356284282417 | validation: 0.024530902112483252]
	TIME [epoch: 8.01 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020141630141964514		[learning rate: 0.0031905]
	Learning Rate: 0.00319051
	LOSS [training: 0.020141630141964514 | validation: 0.028467480852382248]
	TIME [epoch: 8.02 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021172243054161165		[learning rate: 0.0031751]
	Learning Rate: 0.00317508
	LOSS [training: 0.021172243054161165 | validation: 0.024539610979389583]
	TIME [epoch: 8.02 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019447577947192974		[learning rate: 0.0031597]
	Learning Rate: 0.00315972
	LOSS [training: 0.019447577947192974 | validation: 0.02416750168852706]
	TIME [epoch: 8 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019292382392938043		[learning rate: 0.0031444]
	Learning Rate: 0.00314444
	LOSS [training: 0.019292382392938043 | validation: 0.02520413383825835]
	TIME [epoch: 8 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020300720529518198		[learning rate: 0.0031292]
	Learning Rate: 0.00312924
	LOSS [training: 0.020300720529518198 | validation: 0.02511066479087445]
	TIME [epoch: 8.01 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01950993919221424		[learning rate: 0.0031141]
	Learning Rate: 0.00311411
	LOSS [training: 0.01950993919221424 | validation: 0.025138537977549596]
	TIME [epoch: 8.01 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0200879175616132		[learning rate: 0.003099]
	Learning Rate: 0.00309905
	LOSS [training: 0.0200879175616132 | validation: 0.02422923907016201]
	TIME [epoch: 8.02 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02094494436895823		[learning rate: 0.0030841]
	Learning Rate: 0.00308406
	LOSS [training: 0.02094494436895823 | validation: 0.024031661523647507]
	TIME [epoch: 8.02 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021961646788976344		[learning rate: 0.0030691]
	Learning Rate: 0.00306915
	LOSS [training: 0.021961646788976344 | validation: 0.02394015098267295]
	TIME [epoch: 8.01 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020716493728066093		[learning rate: 0.0030543]
	Learning Rate: 0.0030543
	LOSS [training: 0.020716493728066093 | validation: 0.0240682064316308]
	TIME [epoch: 8.01 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019178666099273697		[learning rate: 0.0030395]
	Learning Rate: 0.00303953
	LOSS [training: 0.019178666099273697 | validation: 0.024077023306501646]
	TIME [epoch: 8 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02144512218568262		[learning rate: 0.0030248]
	Learning Rate: 0.00302484
	LOSS [training: 0.02144512218568262 | validation: 0.026264076903884864]
	TIME [epoch: 8.01 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0208192366695322		[learning rate: 0.0030102]
	Learning Rate: 0.00301021
	LOSS [training: 0.0208192366695322 | validation: 0.02522096561424214]
	TIME [epoch: 8.02 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018623325856502147		[learning rate: 0.0029957]
	Learning Rate: 0.00299565
	LOSS [training: 0.018623325856502147 | validation: 0.024519670620635887]
	TIME [epoch: 8.01 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019642259182250574		[learning rate: 0.0029812]
	Learning Rate: 0.00298116
	LOSS [training: 0.019642259182250574 | validation: 0.024147696887464237]
	TIME [epoch: 8 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01943136900614985		[learning rate: 0.0029667]
	Learning Rate: 0.00296675
	LOSS [training: 0.01943136900614985 | validation: 0.02474973508270986]
	TIME [epoch: 41 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0184597683358852		[learning rate: 0.0029524]
	Learning Rate: 0.0029524
	LOSS [training: 0.0184597683358852 | validation: 0.02362292300600621]
	TIME [epoch: 16.8 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020531940096647064		[learning rate: 0.0029381]
	Learning Rate: 0.00293812
	LOSS [training: 0.020531940096647064 | validation: 0.023822654737311193]
	TIME [epoch: 16.8 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01969434428140571		[learning rate: 0.0029239]
	Learning Rate: 0.00292392
	LOSS [training: 0.01969434428140571 | validation: 0.024078602545478837]
	TIME [epoch: 16.8 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019226954593645932		[learning rate: 0.0029098]
	Learning Rate: 0.00290978
	LOSS [training: 0.019226954593645932 | validation: 0.025262515871385158]
	TIME [epoch: 16.8 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02035465009084362		[learning rate: 0.0028957]
	Learning Rate: 0.00289571
	LOSS [training: 0.02035465009084362 | validation: 0.025532158345852863]
	TIME [epoch: 16.9 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02072508286027554		[learning rate: 0.0028817]
	Learning Rate: 0.0028817
	LOSS [training: 0.02072508286027554 | validation: 0.024059199015966103]
	TIME [epoch: 16.9 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019651802360947632		[learning rate: 0.0028678]
	Learning Rate: 0.00286777
	LOSS [training: 0.019651802360947632 | validation: 0.02367268791265258]
	TIME [epoch: 16.8 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01914029980029734		[learning rate: 0.0028539]
	Learning Rate: 0.0028539
	LOSS [training: 0.01914029980029734 | validation: 0.025095409372543512]
	TIME [epoch: 16.8 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019420410923460377		[learning rate: 0.0028401]
	Learning Rate: 0.0028401
	LOSS [training: 0.019420410923460377 | validation: 0.024541949555939097]
	TIME [epoch: 16.8 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018082968454505546		[learning rate: 0.0028264]
	Learning Rate: 0.00282636
	LOSS [training: 0.018082968454505546 | validation: 0.024331929479272082]
	TIME [epoch: 16.8 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01832072309360955		[learning rate: 0.0028127]
	Learning Rate: 0.0028127
	LOSS [training: 0.01832072309360955 | validation: 0.0235409838538595]
	TIME [epoch: 16.9 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01936737327652251		[learning rate: 0.0027991]
	Learning Rate: 0.00279909
	LOSS [training: 0.01936737327652251 | validation: 0.02459516754494689]
	TIME [epoch: 16.9 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018360707896947496		[learning rate: 0.0027856]
	Learning Rate: 0.00278556
	LOSS [training: 0.018360707896947496 | validation: 0.02480379342934816]
	TIME [epoch: 16.9 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01864946982316236		[learning rate: 0.0027721]
	Learning Rate: 0.00277209
	LOSS [training: 0.01864946982316236 | validation: 0.023670713742973176]
	TIME [epoch: 16.9 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018970218273308245		[learning rate: 0.0027587]
	Learning Rate: 0.00275868
	LOSS [training: 0.018970218273308245 | validation: 0.023850964478532587]
	TIME [epoch: 16.9 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018923236295150504		[learning rate: 0.0027453]
	Learning Rate: 0.00274534
	LOSS [training: 0.018923236295150504 | validation: 0.024446951074524145]
	TIME [epoch: 16.9 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022121599451547434		[learning rate: 0.0027321]
	Learning Rate: 0.00273207
	LOSS [training: 0.022121599451547434 | validation: 0.024691065813044078]
	TIME [epoch: 16.8 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01981122042637767		[learning rate: 0.0027189]
	Learning Rate: 0.00271885
	LOSS [training: 0.01981122042637767 | validation: 0.025695960424748893]
	TIME [epoch: 16.8 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02043858350636932		[learning rate: 0.0027057]
	Learning Rate: 0.00270571
	LOSS [training: 0.02043858350636932 | validation: 0.02443113754812611]
	TIME [epoch: 16.8 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01968486590437898		[learning rate: 0.0026926]
	Learning Rate: 0.00269262
	LOSS [training: 0.01968486590437898 | validation: 0.023477514337122713]
	TIME [epoch: 16.9 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01945926589275244		[learning rate: 0.0026796]
	Learning Rate: 0.0026796
	LOSS [training: 0.01945926589275244 | validation: 0.030281611584601898]
	TIME [epoch: 16.9 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.032737375098676004		[learning rate: 0.0026666]
	Learning Rate: 0.00266664
	LOSS [training: 0.032737375098676004 | validation: 0.04484464111360711]
	TIME [epoch: 16.8 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.034445841532185106		[learning rate: 0.0026537]
	Learning Rate: 0.00265375
	LOSS [training: 0.034445841532185106 | validation: 0.03868046883269114]
	TIME [epoch: 16.9 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.028910262977343764		[learning rate: 0.0026409]
	Learning Rate: 0.00264091
	LOSS [training: 0.028910262977343764 | validation: 0.03181532103792504]
	TIME [epoch: 16.8 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02385432237916553		[learning rate: 0.0026281]
	Learning Rate: 0.00262814
	LOSS [training: 0.02385432237916553 | validation: 0.02833617190428782]
	TIME [epoch: 16.8 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021592697201153362		[learning rate: 0.0026154]
	Learning Rate: 0.00261543
	LOSS [training: 0.021592697201153362 | validation: 0.025703466707645464]
	TIME [epoch: 16.8 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020094824523256144		[learning rate: 0.0026028]
	Learning Rate: 0.00260279
	LOSS [training: 0.020094824523256144 | validation: 0.026098069847374384]
	TIME [epoch: 16.8 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018729801041967364		[learning rate: 0.0025902]
	Learning Rate: 0.0025902
	LOSS [training: 0.018729801041967364 | validation: 0.024101687874068477]
	TIME [epoch: 16.9 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018942052385381464		[learning rate: 0.0025777]
	Learning Rate: 0.00257767
	LOSS [training: 0.018942052385381464 | validation: 0.023909555784078506]
	TIME [epoch: 16.8 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019242489339178184		[learning rate: 0.0025652]
	Learning Rate: 0.00256521
	LOSS [training: 0.019242489339178184 | validation: 0.02309162335860988]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_331.pth
	Model improved!!!
EPOCH 332/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019024796073595886		[learning rate: 0.0025528]
	Learning Rate: 0.0025528
	LOSS [training: 0.019024796073595886 | validation: 0.024006081341922416]
	TIME [epoch: 16.8 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01934194887196775		[learning rate: 0.0025405]
	Learning Rate: 0.00254046
	LOSS [training: 0.01934194887196775 | validation: 0.024054688367746102]
	TIME [epoch: 16.8 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018401856162845183		[learning rate: 0.0025282]
	Learning Rate: 0.00252817
	LOSS [training: 0.018401856162845183 | validation: 0.02343229451791824]
	TIME [epoch: 16.8 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018212747450417052		[learning rate: 0.0025159]
	Learning Rate: 0.00251595
	LOSS [training: 0.018212747450417052 | validation: 0.02396768312719355]
	TIME [epoch: 16.8 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018746511750086434		[learning rate: 0.0025038]
	Learning Rate: 0.00250378
	LOSS [training: 0.018746511750086434 | validation: 0.024583621918213172]
	TIME [epoch: 16.8 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01857391106354032		[learning rate: 0.0024917]
	Learning Rate: 0.00249167
	LOSS [training: 0.01857391106354032 | validation: 0.024777147622224233]
	TIME [epoch: 16.9 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018823763427529883		[learning rate: 0.0024796]
	Learning Rate: 0.00247962
	LOSS [training: 0.018823763427529883 | validation: 0.024975731807416125]
	TIME [epoch: 16.8 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01838418535658083		[learning rate: 0.0024676]
	Learning Rate: 0.00246763
	LOSS [training: 0.01838418535658083 | validation: 0.024538484215265183]
	TIME [epoch: 16.8 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0193561401875682		[learning rate: 0.0024557]
	Learning Rate: 0.0024557
	LOSS [training: 0.0193561401875682 | validation: 0.024029938350151363]
	TIME [epoch: 16.8 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018941315687348775		[learning rate: 0.0024438]
	Learning Rate: 0.00244383
	LOSS [training: 0.018941315687348775 | validation: 0.02443745903031676]
	TIME [epoch: 16.8 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01808383021868283		[learning rate: 0.002432]
	Learning Rate: 0.00243201
	LOSS [training: 0.01808383021868283 | validation: 0.024241615659154545]
	TIME [epoch: 16.8 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018265962692705487		[learning rate: 0.0024202]
	Learning Rate: 0.00242025
	LOSS [training: 0.018265962692705487 | validation: 0.02460772939494177]
	TIME [epoch: 16.8 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018342063568958067		[learning rate: 0.0024085]
	Learning Rate: 0.00240854
	LOSS [training: 0.018342063568958067 | validation: 0.02363406103777869]
	TIME [epoch: 16.9 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019038675152722673		[learning rate: 0.0023969]
	Learning Rate: 0.0023969
	LOSS [training: 0.019038675152722673 | validation: 0.023723672070827834]
	TIME [epoch: 16.8 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018734133274371605		[learning rate: 0.0023853]
	Learning Rate: 0.0023853
	LOSS [training: 0.018734133274371605 | validation: 0.024525539933621363]
	TIME [epoch: 16.9 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018292388681677468		[learning rate: 0.0023738]
	Learning Rate: 0.00237377
	LOSS [training: 0.018292388681677468 | validation: 0.02405194673000074]
	TIME [epoch: 16.9 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019359253887934764		[learning rate: 0.0023623]
	Learning Rate: 0.00236229
	LOSS [training: 0.019359253887934764 | validation: 0.023021257495864884]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_348.pth
	Model improved!!!
EPOCH 349/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018485801800144346		[learning rate: 0.0023509]
	Learning Rate: 0.00235087
	LOSS [training: 0.018485801800144346 | validation: 0.024052153010550848]
	TIME [epoch: 16.8 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018069575927119684		[learning rate: 0.0023395]
	Learning Rate: 0.0023395
	LOSS [training: 0.018069575927119684 | validation: 0.023102746604054147]
	TIME [epoch: 16.8 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01877086477770021		[learning rate: 0.0023282]
	Learning Rate: 0.00232819
	LOSS [training: 0.01877086477770021 | validation: 0.02298915084892027]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_351.pth
	Model improved!!!
EPOCH 352/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020302308494350035		[learning rate: 0.0023169]
	Learning Rate: 0.00231693
	LOSS [training: 0.020302308494350035 | validation: 0.024456093175266425]
	TIME [epoch: 16.8 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02006892178785996		[learning rate: 0.0023057]
	Learning Rate: 0.00230572
	LOSS [training: 0.02006892178785996 | validation: 0.02707974314271176]
	TIME [epoch: 16.9 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020166118491950796		[learning rate: 0.0022946]
	Learning Rate: 0.00229457
	LOSS [training: 0.020166118491950796 | validation: 0.02349428678447542]
	TIME [epoch: 16.9 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017852414392929266		[learning rate: 0.0022835]
	Learning Rate: 0.00228348
	LOSS [training: 0.017852414392929266 | validation: 0.02360646738208011]
	TIME [epoch: 16.8 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018393017565830883		[learning rate: 0.0022724]
	Learning Rate: 0.00227243
	LOSS [training: 0.018393017565830883 | validation: 0.023323005590169792]
	TIME [epoch: 16.8 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01855292132116018		[learning rate: 0.0022614]
	Learning Rate: 0.00226144
	LOSS [training: 0.01855292132116018 | validation: 0.023418489166778536]
	TIME [epoch: 16.9 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01883218502669185		[learning rate: 0.0022505]
	Learning Rate: 0.00225051
	LOSS [training: 0.01883218502669185 | validation: 0.023076457372291383]
	TIME [epoch: 16.8 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01913794419499602		[learning rate: 0.0022396]
	Learning Rate: 0.00223963
	LOSS [training: 0.01913794419499602 | validation: 0.02359474408618098]
	TIME [epoch: 16.9 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018172480433801725		[learning rate: 0.0022288]
	Learning Rate: 0.0022288
	LOSS [training: 0.018172480433801725 | validation: 0.023510910436815455]
	TIME [epoch: 16.8 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018423661026945034		[learning rate: 0.002218]
	Learning Rate: 0.00221802
	LOSS [training: 0.018423661026945034 | validation: 0.023680820692398723]
	TIME [epoch: 16.8 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018324596445201236		[learning rate: 0.0022073]
	Learning Rate: 0.00220729
	LOSS [training: 0.018324596445201236 | validation: 0.02797350420114157]
	TIME [epoch: 16.8 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0217926351009927		[learning rate: 0.0021966]
	Learning Rate: 0.00219662
	LOSS [training: 0.0217926351009927 | validation: 0.025517165176236967]
	TIME [epoch: 16.9 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019690966922623804		[learning rate: 0.002186]
	Learning Rate: 0.00218599
	LOSS [training: 0.019690966922623804 | validation: 0.023678778868388383]
	TIME [epoch: 16.8 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01918244412170123		[learning rate: 0.0021754]
	Learning Rate: 0.00217542
	LOSS [training: 0.01918244412170123 | validation: 0.023028596969947673]
	TIME [epoch: 16.9 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01935754812617237		[learning rate: 0.0021649]
	Learning Rate: 0.0021649
	LOSS [training: 0.01935754812617237 | validation: 0.023816349246027015]
	TIME [epoch: 16.9 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019377806625127836		[learning rate: 0.0021544]
	Learning Rate: 0.00215443
	LOSS [training: 0.019377806625127836 | validation: 0.025738873607903806]
	TIME [epoch: 16.8 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019806174329765714		[learning rate: 0.002144]
	Learning Rate: 0.00214402
	LOSS [training: 0.019806174329765714 | validation: 0.0245115773854165]
	TIME [epoch: 16.8 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019491183957583577		[learning rate: 0.0021336]
	Learning Rate: 0.00213365
	LOSS [training: 0.019491183957583577 | validation: 0.02421445850262681]
	TIME [epoch: 16.8 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01842389246240932		[learning rate: 0.0021233]
	Learning Rate: 0.00212333
	LOSS [training: 0.01842389246240932 | validation: 0.024249427889295253]
	TIME [epoch: 16.9 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019239173776566035		[learning rate: 0.0021131]
	Learning Rate: 0.00211306
	LOSS [training: 0.019239173776566035 | validation: 0.023551564030635574]
	TIME [epoch: 16.9 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01808089059399773		[learning rate: 0.0021028]
	Learning Rate: 0.00210284
	LOSS [training: 0.01808089059399773 | validation: 0.02470889116614283]
	TIME [epoch: 16.9 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019222528574911055		[learning rate: 0.0020927]
	Learning Rate: 0.00209267
	LOSS [training: 0.019222528574911055 | validation: 0.024121916642050933]
	TIME [epoch: 16.8 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01819124769915838		[learning rate: 0.0020826]
	Learning Rate: 0.00208255
	LOSS [training: 0.01819124769915838 | validation: 0.022500330339663577]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_374.pth
	Model improved!!!
EPOCH 375/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0188454183338583		[learning rate: 0.0020725]
	Learning Rate: 0.00207248
	LOSS [training: 0.0188454183338583 | validation: 0.023898501859538224]
	TIME [epoch: 16.8 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018785793065775738		[learning rate: 0.0020625]
	Learning Rate: 0.00206246
	LOSS [training: 0.018785793065775738 | validation: 0.023875622426813608]
	TIME [epoch: 16.8 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017947722549370465		[learning rate: 0.0020525]
	Learning Rate: 0.00205249
	LOSS [training: 0.017947722549370465 | validation: 0.022354328742719847]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_377.pth
	Model improved!!!
EPOCH 378/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017948736821709544		[learning rate: 0.0020426]
	Learning Rate: 0.00204256
	LOSS [training: 0.017948736821709544 | validation: 0.023539831059973457]
	TIME [epoch: 16.8 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01819595996356981		[learning rate: 0.0020327]
	Learning Rate: 0.00203269
	LOSS [training: 0.01819595996356981 | validation: 0.0235135724225948]
	TIME [epoch: 16.8 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018105204740970073		[learning rate: 0.0020229]
	Learning Rate: 0.00202286
	LOSS [training: 0.018105204740970073 | validation: 0.02391340833848424]
	TIME [epoch: 16.8 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018588497217544717		[learning rate: 0.0020131]
	Learning Rate: 0.00201307
	LOSS [training: 0.018588497217544717 | validation: 0.02206481925086094]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_381.pth
	Model improved!!!
EPOCH 382/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01900972363023685		[learning rate: 0.0020033]
	Learning Rate: 0.00200334
	LOSS [training: 0.01900972363023685 | validation: 0.023106990195285615]
	TIME [epoch: 16.8 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019558773943962823		[learning rate: 0.0019937]
	Learning Rate: 0.00199365
	LOSS [training: 0.019558773943962823 | validation: 0.023221485892069755]
	TIME [epoch: 16.8 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018182223357502907		[learning rate: 0.001984]
	Learning Rate: 0.00198401
	LOSS [training: 0.018182223357502907 | validation: 0.022751128266133857]
	TIME [epoch: 16.8 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018146441437824564		[learning rate: 0.0019744]
	Learning Rate: 0.00197442
	LOSS [training: 0.018146441437824564 | validation: 0.023372876324396368]
	TIME [epoch: 16.8 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019537178351149577		[learning rate: 0.0019649]
	Learning Rate: 0.00196487
	LOSS [training: 0.019537178351149577 | validation: 0.02371329210955111]
	TIME [epoch: 16.8 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019680383637093204		[learning rate: 0.0019554]
	Learning Rate: 0.00195537
	LOSS [training: 0.019680383637093204 | validation: 0.023433272969891634]
	TIME [epoch: 16.9 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019300849007096454		[learning rate: 0.0019459]
	Learning Rate: 0.00194591
	LOSS [training: 0.019300849007096454 | validation: 0.02307890166659718]
	TIME [epoch: 16.8 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01857049461394966		[learning rate: 0.0019365]
	Learning Rate: 0.0019365
	LOSS [training: 0.01857049461394966 | validation: 0.023796990509039894]
	TIME [epoch: 16.8 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019016433921558343		[learning rate: 0.0019271]
	Learning Rate: 0.00192714
	LOSS [training: 0.019016433921558343 | validation: 0.02282486581507603]
	TIME [epoch: 16.8 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018410017805873338		[learning rate: 0.0019178]
	Learning Rate: 0.00191782
	LOSS [training: 0.018410017805873338 | validation: 0.02300395641757746]
	TIME [epoch: 16.8 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018773161076294943		[learning rate: 0.0019085]
	Learning Rate: 0.00190854
	LOSS [training: 0.018773161076294943 | validation: 0.023094308589468187]
	TIME [epoch: 16.8 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01867860319757199		[learning rate: 0.0018993]
	Learning Rate: 0.00189931
	LOSS [training: 0.01867860319757199 | validation: 0.023381971234010087]
	TIME [epoch: 16.8 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01900411002014115		[learning rate: 0.0018901]
	Learning Rate: 0.00189013
	LOSS [training: 0.01900411002014115 | validation: 0.02338099301511436]
	TIME [epoch: 16.8 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018813574984384216		[learning rate: 0.001881]
	Learning Rate: 0.00188099
	LOSS [training: 0.018813574984384216 | validation: 0.021487031441330216]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_395.pth
	Model improved!!!
EPOCH 396/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019027055787988124		[learning rate: 0.0018719]
	Learning Rate: 0.00187189
	LOSS [training: 0.019027055787988124 | validation: 0.02218458955529402]
	TIME [epoch: 16.8 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01901289290989722		[learning rate: 0.0018628]
	Learning Rate: 0.00186284
	LOSS [training: 0.01901289290989722 | validation: 0.021881567156721293]
	TIME [epoch: 16.8 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018674460897168964		[learning rate: 0.0018538]
	Learning Rate: 0.00185383
	LOSS [training: 0.018674460897168964 | validation: 0.02288447860225121]
	TIME [epoch: 16.8 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018807512935455416		[learning rate: 0.0018449]
	Learning Rate: 0.00184487
	LOSS [training: 0.018807512935455416 | validation: 0.02277609377738247]
	TIME [epoch: 16.9 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018959569817184295		[learning rate: 0.0018359]
	Learning Rate: 0.00183594
	LOSS [training: 0.018959569817184295 | validation: 0.021398632786234346]
	TIME [epoch: 16.9 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_400.pth
	Model improved!!!
EPOCH 401/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017750548181717538		[learning rate: 0.0018271]
	Learning Rate: 0.00182707
	LOSS [training: 0.017750548181717538 | validation: 0.023166537368163997]
	TIME [epoch: 16.8 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018229217242861247		[learning rate: 0.0018182]
	Learning Rate: 0.00181823
	LOSS [training: 0.018229217242861247 | validation: 0.021634975443955994]
	TIME [epoch: 16.8 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01733360516135446		[learning rate: 0.0018094]
	Learning Rate: 0.00180944
	LOSS [training: 0.01733360516135446 | validation: 0.022077428006756234]
	TIME [epoch: 16.8 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018923580195473997		[learning rate: 0.0018007]
	Learning Rate: 0.00180069
	LOSS [training: 0.018923580195473997 | validation: 0.02268287976786516]
	TIME [epoch: 16.8 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01721936930905081		[learning rate: 0.001792]
	Learning Rate: 0.00179198
	LOSS [training: 0.01721936930905081 | validation: 0.02184928272424877]
	TIME [epoch: 16.8 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018334254461484324		[learning rate: 0.0017833]
	Learning Rate: 0.00178331
	LOSS [training: 0.018334254461484324 | validation: 0.02282782679097141]
	TIME [epoch: 16.8 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01753394696151905		[learning rate: 0.0017747]
	Learning Rate: 0.00177469
	LOSS [training: 0.01753394696151905 | validation: 0.02177624061900967]
	TIME [epoch: 16.8 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017761571445797753		[learning rate: 0.0017661]
	Learning Rate: 0.00176611
	LOSS [training: 0.017761571445797753 | validation: 0.021301402899866886]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_408.pth
	Model improved!!!
EPOCH 409/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017543242357633507		[learning rate: 0.0017576]
	Learning Rate: 0.00175757
	LOSS [training: 0.017543242357633507 | validation: 0.02216784540684312]
	TIME [epoch: 16.8 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018086730911374676		[learning rate: 0.0017491]
	Learning Rate: 0.00174907
	LOSS [training: 0.018086730911374676 | validation: 0.021608448576904745]
	TIME [epoch: 16.8 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018426300593050355		[learning rate: 0.0017406]
	Learning Rate: 0.00174061
	LOSS [training: 0.018426300593050355 | validation: 0.021116374139909275]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_411.pth
	Model improved!!!
EPOCH 412/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01772123366027535		[learning rate: 0.0017322]
	Learning Rate: 0.00173219
	LOSS [training: 0.01772123366027535 | validation: 0.02141770852139656]
	TIME [epoch: 16.8 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017693071028068583		[learning rate: 0.0017238]
	Learning Rate: 0.00172382
	LOSS [training: 0.017693071028068583 | validation: 0.021992164958015804]
	TIME [epoch: 16.8 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016800525612248183		[learning rate: 0.0017155]
	Learning Rate: 0.00171548
	LOSS [training: 0.016800525612248183 | validation: 0.022011169213448645]
	TIME [epoch: 16.8 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018254534042564594		[learning rate: 0.0017072]
	Learning Rate: 0.00170719
	LOSS [training: 0.018254534042564594 | validation: 0.023008582353286965]
	TIME [epoch: 16.8 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01753200868348099		[learning rate: 0.0016989]
	Learning Rate: 0.00169893
	LOSS [training: 0.01753200868348099 | validation: 0.02110934479707198]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_416.pth
	Model improved!!!
EPOCH 417/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01720971236604604		[learning rate: 0.0016907]
	Learning Rate: 0.00169071
	LOSS [training: 0.01720971236604604 | validation: 0.021330628593934562]
	TIME [epoch: 16.8 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017860021230507995		[learning rate: 0.0016825]
	Learning Rate: 0.00168254
	LOSS [training: 0.017860021230507995 | validation: 0.021241220530097166]
	TIME [epoch: 16.8 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017113231906778312		[learning rate: 0.0016744]
	Learning Rate: 0.0016744
	LOSS [training: 0.017113231906778312 | validation: 0.022381378017853493]
	TIME [epoch: 16.9 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01686246737913064		[learning rate: 0.0016663]
	Learning Rate: 0.0016663
	LOSS [training: 0.01686246737913064 | validation: 0.021927066291899718]
	TIME [epoch: 16.8 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01772983647068116		[learning rate: 0.0016582]
	Learning Rate: 0.00165825
	LOSS [training: 0.01772983647068116 | validation: 0.020882180500905245]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_421.pth
	Model improved!!!
EPOCH 422/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016933125857211864		[learning rate: 0.0016502]
	Learning Rate: 0.00165023
	LOSS [training: 0.016933125857211864 | validation: 0.02168966595402781]
	TIME [epoch: 16.8 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01817314432905873		[learning rate: 0.0016422]
	Learning Rate: 0.00164225
	LOSS [training: 0.01817314432905873 | validation: 0.021950925442938512]
	TIME [epoch: 16.8 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01730133885242404		[learning rate: 0.0016343]
	Learning Rate: 0.00163431
	LOSS [training: 0.01730133885242404 | validation: 0.021359262875308222]
	TIME [epoch: 16.8 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01730214805153851		[learning rate: 0.0016264]
	Learning Rate: 0.0016264
	LOSS [training: 0.01730214805153851 | validation: 0.021576872273903546]
	TIME [epoch: 16.8 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0179835909663698		[learning rate: 0.0016185]
	Learning Rate: 0.00161854
	LOSS [training: 0.0179835909663698 | validation: 0.021561685349845625]
	TIME [epoch: 16.8 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017065430182637665		[learning rate: 0.0016107]
	Learning Rate: 0.00161071
	LOSS [training: 0.017065430182637665 | validation: 0.021919229319424458]
	TIME [epoch: 16.8 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01810988181228376		[learning rate: 0.0016029]
	Learning Rate: 0.00160292
	LOSS [training: 0.01810988181228376 | validation: 0.02213985732492357]
	TIME [epoch: 16.8 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017666114644401626		[learning rate: 0.0015952]
	Learning Rate: 0.00159517
	LOSS [training: 0.017666114644401626 | validation: 0.021072403661182803]
	TIME [epoch: 16.8 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017719698927532553		[learning rate: 0.0015875]
	Learning Rate: 0.00158746
	LOSS [training: 0.017719698927532553 | validation: 0.02231010180252727]
	TIME [epoch: 16.9 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01768854197739644		[learning rate: 0.0015798]
	Learning Rate: 0.00157978
	LOSS [training: 0.01768854197739644 | validation: 0.02182283699576046]
	TIME [epoch: 16.8 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017448302212219016		[learning rate: 0.0015721]
	Learning Rate: 0.00157214
	LOSS [training: 0.017448302212219016 | validation: 0.021968451848728286]
	TIME [epoch: 16.9 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017857051086618805		[learning rate: 0.0015645]
	Learning Rate: 0.00156454
	LOSS [training: 0.017857051086618805 | validation: 0.021172887681359474]
	TIME [epoch: 16.8 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017307324206275353		[learning rate: 0.001557]
	Learning Rate: 0.00155697
	LOSS [training: 0.017307324206275353 | validation: 0.022424288130352854]
	TIME [epoch: 16.8 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01823261215187888		[learning rate: 0.0015494]
	Learning Rate: 0.00154944
	LOSS [training: 0.01823261215187888 | validation: 0.02087184983194779]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_435.pth
	Model improved!!!
EPOCH 436/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017797118300144858		[learning rate: 0.0015419]
	Learning Rate: 0.00154195
	LOSS [training: 0.017797118300144858 | validation: 0.021115680472930734]
	TIME [epoch: 16.8 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017251506976923552		[learning rate: 0.0015345]
	Learning Rate: 0.00153449
	LOSS [training: 0.017251506976923552 | validation: 0.021298618521801524]
	TIME [epoch: 16.8 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016551201345576836		[learning rate: 0.0015271]
	Learning Rate: 0.00152707
	LOSS [training: 0.016551201345576836 | validation: 0.020889994964390386]
	TIME [epoch: 16.8 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017388677935824343		[learning rate: 0.0015197]
	Learning Rate: 0.00151969
	LOSS [training: 0.017388677935824343 | validation: 0.021088913172167226]
	TIME [epoch: 16.8 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017553345706134222		[learning rate: 0.0015123]
	Learning Rate: 0.00151234
	LOSS [training: 0.017553345706134222 | validation: 0.022084672578573532]
	TIME [epoch: 16.8 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017720882736869146		[learning rate: 0.001505]
	Learning Rate: 0.00150503
	LOSS [training: 0.017720882736869146 | validation: 0.021045045047292266]
	TIME [epoch: 16.8 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016824737102533346		[learning rate: 0.0014977]
	Learning Rate: 0.00149775
	LOSS [training: 0.016824737102533346 | validation: 0.020926194611854323]
	TIME [epoch: 16.8 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018502895484293045		[learning rate: 0.0014905]
	Learning Rate: 0.0014905
	LOSS [training: 0.018502895484293045 | validation: 0.022285543281475473]
	TIME [epoch: 16.8 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01864397691227531		[learning rate: 0.0014833]
	Learning Rate: 0.0014833
	LOSS [training: 0.01864397691227531 | validation: 0.02166670189334088]
	TIME [epoch: 16.8 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017733876694997933		[learning rate: 0.0014761]
	Learning Rate: 0.00147612
	LOSS [training: 0.017733876694997933 | validation: 0.021133331309901516]
	TIME [epoch: 16.8 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017915801886427756		[learning rate: 0.001469]
	Learning Rate: 0.00146899
	LOSS [training: 0.017915801886427756 | validation: 0.021900873933004137]
	TIME [epoch: 16.8 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01742941858946873		[learning rate: 0.0014619]
	Learning Rate: 0.00146188
	LOSS [training: 0.01742941858946873 | validation: 0.020791440251110713]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_447.pth
	Model improved!!!
EPOCH 448/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01664029607491349		[learning rate: 0.0014548]
	Learning Rate: 0.00145481
	LOSS [training: 0.01664029607491349 | validation: 0.021118627970980835]
	TIME [epoch: 16.8 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017242681484328115		[learning rate: 0.0014478]
	Learning Rate: 0.00144778
	LOSS [training: 0.017242681484328115 | validation: 0.021625402815373267]
	TIME [epoch: 16.8 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017714324080095163		[learning rate: 0.0014408]
	Learning Rate: 0.00144078
	LOSS [training: 0.017714324080095163 | validation: 0.021393760577448212]
	TIME [epoch: 16.8 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017721291254369827		[learning rate: 0.0014338]
	Learning Rate: 0.00143381
	LOSS [training: 0.017721291254369827 | validation: 0.02169287245151322]
	TIME [epoch: 16.8 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017493365188822396		[learning rate: 0.0014269]
	Learning Rate: 0.00142688
	LOSS [training: 0.017493365188822396 | validation: 0.020679467400833883]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_452.pth
	Model improved!!!
EPOCH 453/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017740563553726458		[learning rate: 0.00142]
	Learning Rate: 0.00141997
	LOSS [training: 0.017740563553726458 | validation: 0.0217342801846869]
	TIME [epoch: 16.8 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017624845477082002		[learning rate: 0.0014131]
	Learning Rate: 0.00141311
	LOSS [training: 0.017624845477082002 | validation: 0.02174342066264186]
	TIME [epoch: 16.8 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017314528865775336		[learning rate: 0.0014063]
	Learning Rate: 0.00140627
	LOSS [training: 0.017314528865775336 | validation: 0.02097847619557928]
	TIME [epoch: 16.8 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017222444979203267		[learning rate: 0.0013995]
	Learning Rate: 0.00139947
	LOSS [training: 0.017222444979203267 | validation: 0.021422521477633988]
	TIME [epoch: 16.8 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01710896703221412		[learning rate: 0.0013927]
	Learning Rate: 0.00139271
	LOSS [training: 0.01710896703221412 | validation: 0.02122059029186557]
	TIME [epoch: 16.8 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017171785587720367		[learning rate: 0.001386]
	Learning Rate: 0.00138597
	LOSS [training: 0.017171785587720367 | validation: 0.021818393194592528]
	TIME [epoch: 16.8 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017698706703781868		[learning rate: 0.0013793]
	Learning Rate: 0.00137927
	LOSS [training: 0.017698706703781868 | validation: 0.021593416219202338]
	TIME [epoch: 16.8 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01764320387895286		[learning rate: 0.0013726]
	Learning Rate: 0.0013726
	LOSS [training: 0.01764320387895286 | validation: 0.02122808985302869]
	TIME [epoch: 16.8 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017930592185466755		[learning rate: 0.001366]
	Learning Rate: 0.00136596
	LOSS [training: 0.017930592185466755 | validation: 0.021182586601560093]
	TIME [epoch: 16.7 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01754694735366854		[learning rate: 0.0013594]
	Learning Rate: 0.00135936
	LOSS [training: 0.01754694735366854 | validation: 0.020900971901152293]
	TIME [epoch: 16.8 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016748415335473863		[learning rate: 0.0013528]
	Learning Rate: 0.00135278
	LOSS [training: 0.016748415335473863 | validation: 0.021532436476322882]
	TIME [epoch: 16.8 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018573234783546166		[learning rate: 0.0013462]
	Learning Rate: 0.00134624
	LOSS [training: 0.018573234783546166 | validation: 0.021732327976421256]
	TIME [epoch: 16.8 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019720655305999705		[learning rate: 0.0013397]
	Learning Rate: 0.00133973
	LOSS [training: 0.019720655305999705 | validation: 0.025197629961442935]
	TIME [epoch: 16.8 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020069017739747914		[learning rate: 0.0013333]
	Learning Rate: 0.00133325
	LOSS [training: 0.020069017739747914 | validation: 0.02261972038629027]
	TIME [epoch: 16.8 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017920744221773647		[learning rate: 0.0013268]
	Learning Rate: 0.0013268
	LOSS [training: 0.017920744221773647 | validation: 0.021252842602604256]
	TIME [epoch: 16.8 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0171610604466013		[learning rate: 0.0013204]
	Learning Rate: 0.00132039
	LOSS [training: 0.0171610604466013 | validation: 0.022998142411725934]
	TIME [epoch: 16.8 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01857428584337088		[learning rate: 0.001314]
	Learning Rate: 0.001314
	LOSS [training: 0.01857428584337088 | validation: 0.021609999447884148]
	TIME [epoch: 16.8 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01851168606999058		[learning rate: 0.0013076]
	Learning Rate: 0.00130765
	LOSS [training: 0.01851168606999058 | validation: 0.02237361293708]
	TIME [epoch: 16.8 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018301725717305137		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.018301725717305137 | validation: 0.02132555022256155]
	TIME [epoch: 16.8 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01773370193463189		[learning rate: 0.001295]
	Learning Rate: 0.00129503
	LOSS [training: 0.01773370193463189 | validation: 0.02125729133627136]
	TIME [epoch: 16.7 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016837750710570618		[learning rate: 0.0012888]
	Learning Rate: 0.00128877
	LOSS [training: 0.016837750710570618 | validation: 0.020575913129679445]
	TIME [epoch: 16.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_473.pth
	Model improved!!!
EPOCH 474/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01635110301819453		[learning rate: 0.0012825]
	Learning Rate: 0.00128254
	LOSS [training: 0.01635110301819453 | validation: 0.02052157405716588]
	TIME [epoch: 16.7 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_474.pth
	Model improved!!!
EPOCH 475/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01700932055665777		[learning rate: 0.0012763]
	Learning Rate: 0.00127634
	LOSS [training: 0.01700932055665777 | validation: 0.020994662505020897]
	TIME [epoch: 16.8 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016544211445677793		[learning rate: 0.0012702]
	Learning Rate: 0.00127016
	LOSS [training: 0.016544211445677793 | validation: 0.022956356114415283]
	TIME [epoch: 16.8 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02110082237837031		[learning rate: 0.001264]
	Learning Rate: 0.00126402
	LOSS [training: 0.02110082237837031 | validation: 0.02940137922670583]
	TIME [epoch: 16.8 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.023018039128251178		[learning rate: 0.0012579]
	Learning Rate: 0.00125791
	LOSS [training: 0.023018039128251178 | validation: 0.027424404659664947]
	TIME [epoch: 16.8 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.022189183702195015		[learning rate: 0.0012518]
	Learning Rate: 0.00125183
	LOSS [training: 0.022189183702195015 | validation: 0.027408312242162683]
	TIME [epoch: 16.8 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02119893117309839		[learning rate: 0.0012458]
	Learning Rate: 0.00124577
	LOSS [training: 0.02119893117309839 | validation: 0.02568879179874203]
	TIME [epoch: 16.8 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02112160921361153		[learning rate: 0.0012397]
	Learning Rate: 0.00123975
	LOSS [training: 0.02112160921361153 | validation: 0.026633850846054283]
	TIME [epoch: 16.8 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.02076371728958552		[learning rate: 0.0012338]
	Learning Rate: 0.00123375
	LOSS [training: 0.02076371728958552 | validation: 0.02554547847120124]
	TIME [epoch: 16.7 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.021497583564159015		[learning rate: 0.0012278]
	Learning Rate: 0.00122779
	LOSS [training: 0.021497583564159015 | validation: 0.024840854243369095]
	TIME [epoch: 16.8 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.020920924647914358		[learning rate: 0.0012218]
	Learning Rate: 0.00122185
	LOSS [training: 0.020920924647914358 | validation: 0.02486252687735609]
	TIME [epoch: 16.8 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.019699748956810054		[learning rate: 0.0012159]
	Learning Rate: 0.00121594
	LOSS [training: 0.019699748956810054 | validation: 0.024056772233661174]
	TIME [epoch: 16.8 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01978372612405584		[learning rate: 0.0012101]
	Learning Rate: 0.00121006
	LOSS [training: 0.01978372612405584 | validation: 0.02419985755053088]
	TIME [epoch: 16.9 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01937066959179785		[learning rate: 0.0012042]
	Learning Rate: 0.00120421
	LOSS [training: 0.01937066959179785 | validation: 0.022682140036572842]
	TIME [epoch: 16.9 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01782966658092303		[learning rate: 0.0011984]
	Learning Rate: 0.00119839
	LOSS [training: 0.01782966658092303 | validation: 0.020855800772442562]
	TIME [epoch: 16.8 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01720920409860922		[learning rate: 0.0011926]
	Learning Rate: 0.00119259
	LOSS [training: 0.01720920409860922 | validation: 0.02113005840112353]
	TIME [epoch: 16.8 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017397127305821755		[learning rate: 0.0011868]
	Learning Rate: 0.00118682
	LOSS [training: 0.017397127305821755 | validation: 0.021000295038365317]
	TIME [epoch: 16.7 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01671004416442339		[learning rate: 0.0011811]
	Learning Rate: 0.00118108
	LOSS [training: 0.01671004416442339 | validation: 0.02041181008300991]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_491.pth
	Model improved!!!
EPOCH 492/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01687936785856449		[learning rate: 0.0011754]
	Learning Rate: 0.00117537
	LOSS [training: 0.01687936785856449 | validation: 0.021594952943369935]
	TIME [epoch: 16.8 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01683137054828315		[learning rate: 0.0011697]
	Learning Rate: 0.00116969
	LOSS [training: 0.01683137054828315 | validation: 0.020893455188944966]
	TIME [epoch: 16.8 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017313246342577044		[learning rate: 0.001164]
	Learning Rate: 0.00116403
	LOSS [training: 0.017313246342577044 | validation: 0.020613903438957085]
	TIME [epoch: 16.8 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016628357568210187		[learning rate: 0.0011584]
	Learning Rate: 0.0011584
	LOSS [training: 0.016628357568210187 | validation: 0.019926235622407446]
	TIME [epoch: 16.8 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_495.pth
	Model improved!!!
EPOCH 496/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016906283241075046		[learning rate: 0.0011528]
	Learning Rate: 0.0011528
	LOSS [training: 0.016906283241075046 | validation: 0.020836612722308374]
	TIME [epoch: 16.8 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01737457044251918		[learning rate: 0.0011472]
	Learning Rate: 0.00114723
	LOSS [training: 0.01737457044251918 | validation: 0.02089255708333308]
	TIME [epoch: 16.8 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01703341589354328		[learning rate: 0.0011417]
	Learning Rate: 0.00114168
	LOSS [training: 0.01703341589354328 | validation: 0.020956017518044216]
	TIME [epoch: 16.8 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017758836319303577		[learning rate: 0.0011362]
	Learning Rate: 0.00113616
	LOSS [training: 0.017758836319303577 | validation: 0.020577809833993706]
	TIME [epoch: 16.8 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016771461863158296		[learning rate: 0.0011307]
	Learning Rate: 0.00113066
	LOSS [training: 0.016771461863158296 | validation: 0.021507669126611405]
	TIME [epoch: 16.8 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01718852349119988		[learning rate: 0.0011252]
	Learning Rate: 0.0011252
	LOSS [training: 0.01718852349119988 | validation: 0.021890891734350885]
	TIME [epoch: 59.4 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.018793114203811977		[learning rate: 0.0011198]
	Learning Rate: 0.00111975
	LOSS [training: 0.018793114203811977 | validation: 0.022193005445030316]
	TIME [epoch: 35.3 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01804153644903262		[learning rate: 0.0011143]
	Learning Rate: 0.00111434
	LOSS [training: 0.01804153644903262 | validation: 0.021410699487068793]
	TIME [epoch: 35.4 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016999578962380652		[learning rate: 0.001109]
	Learning Rate: 0.00110895
	LOSS [training: 0.016999578962380652 | validation: 0.02122117188553528]
	TIME [epoch: 35.3 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017247017146180935		[learning rate: 0.0011036]
	Learning Rate: 0.00110359
	LOSS [training: 0.017247017146180935 | validation: 0.021748199513032168]
	TIME [epoch: 35.4 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017103946088348795		[learning rate: 0.0010983]
	Learning Rate: 0.00109825
	LOSS [training: 0.017103946088348795 | validation: 0.021013781009016658]
	TIME [epoch: 35.3 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017242706472484225		[learning rate: 0.0010929]
	Learning Rate: 0.00109294
	LOSS [training: 0.017242706472484225 | validation: 0.02038803105318936]
	TIME [epoch: 35.3 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016594761429491508		[learning rate: 0.0010877]
	Learning Rate: 0.00108766
	LOSS [training: 0.016594761429491508 | validation: 0.020437892870855918]
	TIME [epoch: 35.3 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016904237587567626		[learning rate: 0.0010824]
	Learning Rate: 0.0010824
	LOSS [training: 0.016904237587567626 | validation: 0.020659570570973566]
	TIME [epoch: 35.3 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017247217459155046		[learning rate: 0.0010772]
	Learning Rate: 0.00107716
	LOSS [training: 0.017247217459155046 | validation: 0.020351908644846903]
	TIME [epoch: 35.4 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01662176585041441		[learning rate: 0.001072]
	Learning Rate: 0.00107195
	LOSS [training: 0.01662176585041441 | validation: 0.020521208465394365]
	TIME [epoch: 35.3 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017000650422388974		[learning rate: 0.0010668]
	Learning Rate: 0.00106677
	LOSS [training: 0.017000650422388974 | validation: 0.021052684072797655]
	TIME [epoch: 35.3 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016601571027312353		[learning rate: 0.0010616]
	Learning Rate: 0.00106161
	LOSS [training: 0.016601571027312353 | validation: 0.020348367502712714]
	TIME [epoch: 35.3 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01702523864680028		[learning rate: 0.0010565]
	Learning Rate: 0.00105648
	LOSS [training: 0.01702523864680028 | validation: 0.02062595388178147]
	TIME [epoch: 35.3 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01699924538927373		[learning rate: 0.0010514]
	Learning Rate: 0.00105137
	LOSS [training: 0.01699924538927373 | validation: 0.02112982797070162]
	TIME [epoch: 35.3 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017268816989785437		[learning rate: 0.0010463]
	Learning Rate: 0.00104628
	LOSS [training: 0.017268816989785437 | validation: 0.020258615636565818]
	TIME [epoch: 35.3 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016075815729557515		[learning rate: 0.0010412]
	Learning Rate: 0.00104122
	LOSS [training: 0.016075815729557515 | validation: 0.02151697573058826]
	TIME [epoch: 35.3 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017130402434292404		[learning rate: 0.0010362]
	Learning Rate: 0.00103619
	LOSS [training: 0.017130402434292404 | validation: 0.02196886552126391]
	TIME [epoch: 35.3 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017310039000013336		[learning rate: 0.0010312]
	Learning Rate: 0.00103118
	LOSS [training: 0.017310039000013336 | validation: 0.02024473666249263]
	TIME [epoch: 35.3 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016976393933695027		[learning rate: 0.0010262]
	Learning Rate: 0.00102619
	LOSS [training: 0.016976393933695027 | validation: 0.02051381072519395]
	TIME [epoch: 35.3 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016370903312962693		[learning rate: 0.0010212]
	Learning Rate: 0.00102123
	LOSS [training: 0.016370903312962693 | validation: 0.021464762002892827]
	TIME [epoch: 35.3 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017401658451838924		[learning rate: 0.0010163]
	Learning Rate: 0.00101629
	LOSS [training: 0.017401658451838924 | validation: 0.022514533495755412]
	TIME [epoch: 35.3 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017449676600080472		[learning rate: 0.0010114]
	Learning Rate: 0.00101138
	LOSS [training: 0.017449676600080472 | validation: 0.021588747699560318]
	TIME [epoch: 35.3 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017077515323594385		[learning rate: 0.0010065]
	Learning Rate: 0.00100648
	LOSS [training: 0.017077515323594385 | validation: 0.02123895706675964]
	TIME [epoch: 35.4 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017012903356173288		[learning rate: 0.0010016]
	Learning Rate: 0.00100162
	LOSS [training: 0.017012903356173288 | validation: 0.02105495987014687]
	TIME [epoch: 35.3 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017445883296948576		[learning rate: 0.00099677]
	Learning Rate: 0.000996773
	LOSS [training: 0.017445883296948576 | validation: 0.020829913363699826]
	TIME [epoch: 35.2 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01644854399022294		[learning rate: 0.00099195]
	Learning Rate: 0.000991953
	LOSS [training: 0.01644854399022294 | validation: 0.020722986283034293]
	TIME [epoch: 35.3 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016601479773364167		[learning rate: 0.00098716]
	Learning Rate: 0.000987156
	LOSS [training: 0.016601479773364167 | validation: 0.020776771299858974]
	TIME [epoch: 35.3 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016131877293945513		[learning rate: 0.00098238]
	Learning Rate: 0.000982383
	LOSS [training: 0.016131877293945513 | validation: 0.021259300522857932]
	TIME [epoch: 35.3 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01646124599851628		[learning rate: 0.00097763]
	Learning Rate: 0.000977632
	LOSS [training: 0.01646124599851628 | validation: 0.021006804644119748]
	TIME [epoch: 35.3 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016346938311720214		[learning rate: 0.0009729]
	Learning Rate: 0.000972904
	LOSS [training: 0.016346938311720214 | validation: 0.020622338264877898]
	TIME [epoch: 35.3 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01611975561607021		[learning rate: 0.0009682]
	Learning Rate: 0.0009682
	LOSS [training: 0.01611975561607021 | validation: 0.02081982546703889]
	TIME [epoch: 35.3 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016128047029653116		[learning rate: 0.00096352]
	Learning Rate: 0.000963518
	LOSS [training: 0.016128047029653116 | validation: 0.02059786595960846]
	TIME [epoch: 35.3 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017105564896239323		[learning rate: 0.00095886]
	Learning Rate: 0.000958858
	LOSS [training: 0.017105564896239323 | validation: 0.021498600235775062]
	TIME [epoch: 35.3 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015832906284055513		[learning rate: 0.00095422]
	Learning Rate: 0.000954221
	LOSS [training: 0.015832906284055513 | validation: 0.02085006243673426]
	TIME [epoch: 35.3 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016575709653649465		[learning rate: 0.00094961]
	Learning Rate: 0.000949607
	LOSS [training: 0.016575709653649465 | validation: 0.021117835373007533]
	TIME [epoch: 35.3 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015501701339859094		[learning rate: 0.00094501]
	Learning Rate: 0.000945015
	LOSS [training: 0.015501701339859094 | validation: 0.021032192484821226]
	TIME [epoch: 35.3 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016395301998478686		[learning rate: 0.00094044]
	Learning Rate: 0.000940445
	LOSS [training: 0.016395301998478686 | validation: 0.019625842686438116]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_538.pth
	Model improved!!!
EPOCH 539/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016330956242025425		[learning rate: 0.0009359]
	Learning Rate: 0.000935897
	LOSS [training: 0.016330956242025425 | validation: 0.020728445965290842]
	TIME [epoch: 35.3 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016287621244121198		[learning rate: 0.00093137]
	Learning Rate: 0.000931371
	LOSS [training: 0.016287621244121198 | validation: 0.02065720368528059]
	TIME [epoch: 35.4 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01659322004791736		[learning rate: 0.00092687]
	Learning Rate: 0.000926867
	LOSS [training: 0.01659322004791736 | validation: 0.020874097364032108]
	TIME [epoch: 35.3 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016356993565675253		[learning rate: 0.00092239]
	Learning Rate: 0.000922385
	LOSS [training: 0.016356993565675253 | validation: 0.02026259447249783]
	TIME [epoch: 35.3 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016533873465832793		[learning rate: 0.00091792]
	Learning Rate: 0.000917924
	LOSS [training: 0.016533873465832793 | validation: 0.02045193031603822]
	TIME [epoch: 35.4 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016587744038499205		[learning rate: 0.00091349]
	Learning Rate: 0.000913486
	LOSS [training: 0.016587744038499205 | validation: 0.019782747169953704]
	TIME [epoch: 35.3 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01643597260795496		[learning rate: 0.00090907]
	Learning Rate: 0.000909068
	LOSS [training: 0.01643597260795496 | validation: 0.021013796796132283]
	TIME [epoch: 35.3 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016600578406856557		[learning rate: 0.00090467]
	Learning Rate: 0.000904672
	LOSS [training: 0.016600578406856557 | validation: 0.020531779254617025]
	TIME [epoch: 35.4 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01665183091634755		[learning rate: 0.0009003]
	Learning Rate: 0.000900297
	LOSS [training: 0.01665183091634755 | validation: 0.020545530261824242]
	TIME [epoch: 35.3 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01647324134245643		[learning rate: 0.00089594]
	Learning Rate: 0.000895943
	LOSS [training: 0.01647324134245643 | validation: 0.020826939961438706]
	TIME [epoch: 35.3 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016374546913909657		[learning rate: 0.00089161]
	Learning Rate: 0.000891611
	LOSS [training: 0.016374546913909657 | validation: 0.021346088241933417]
	TIME [epoch: 35.3 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016489185802437325		[learning rate: 0.0008873]
	Learning Rate: 0.000887299
	LOSS [training: 0.016489185802437325 | validation: 0.020837320378086662]
	TIME [epoch: 35.3 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01674420321354198		[learning rate: 0.00088301]
	Learning Rate: 0.000883009
	LOSS [training: 0.01674420321354198 | validation: 0.021654571992938132]
	TIME [epoch: 35.3 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016568377297759194		[learning rate: 0.00087874]
	Learning Rate: 0.000878738
	LOSS [training: 0.016568377297759194 | validation: 0.020077689271838867]
	TIME [epoch: 35.3 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01603110425249788		[learning rate: 0.00087449]
	Learning Rate: 0.000874489
	LOSS [training: 0.01603110425249788 | validation: 0.02187058835182312]
	TIME [epoch: 35.3 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016975437281335142		[learning rate: 0.00087026]
	Learning Rate: 0.00087026
	LOSS [training: 0.016975437281335142 | validation: 0.02136628213873568]
	TIME [epoch: 35.3 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017301834713095095		[learning rate: 0.00086605]
	Learning Rate: 0.000866052
	LOSS [training: 0.017301834713095095 | validation: 0.021953004676451917]
	TIME [epoch: 35.3 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0169402053307447		[learning rate: 0.00086186]
	Learning Rate: 0.000861864
	LOSS [training: 0.0169402053307447 | validation: 0.020686009894814544]
	TIME [epoch: 35.3 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016972399228220258		[learning rate: 0.0008577]
	Learning Rate: 0.000857696
	LOSS [training: 0.016972399228220258 | validation: 0.020682867020643904]
	TIME [epoch: 35.3 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016832165964637078		[learning rate: 0.00085355]
	Learning Rate: 0.000853548
	LOSS [training: 0.016832165964637078 | validation: 0.0207277230440042]
	TIME [epoch: 35.3 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015865779665213454		[learning rate: 0.00084942]
	Learning Rate: 0.000849421
	LOSS [training: 0.015865779665213454 | validation: 0.020917292959681963]
	TIME [epoch: 35.3 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01634702093607327		[learning rate: 0.00084531]
	Learning Rate: 0.000845313
	LOSS [training: 0.01634702093607327 | validation: 0.02064627046700704]
	TIME [epoch: 35.3 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016553780057441327		[learning rate: 0.00084123]
	Learning Rate: 0.000841225
	LOSS [training: 0.016553780057441327 | validation: 0.020739335375494928]
	TIME [epoch: 35.3 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016774126443515114		[learning rate: 0.00083716]
	Learning Rate: 0.000837157
	LOSS [training: 0.016774126443515114 | validation: 0.02000363276757776]
	TIME [epoch: 35.4 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0163877279534554		[learning rate: 0.00083311]
	Learning Rate: 0.000833109
	LOSS [training: 0.0163877279534554 | validation: 0.02042801671726519]
	TIME [epoch: 35.3 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016339410130009634		[learning rate: 0.00082908]
	Learning Rate: 0.00082908
	LOSS [training: 0.016339410130009634 | validation: 0.020651449385903284]
	TIME [epoch: 35.3 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01639766428193572		[learning rate: 0.00082507]
	Learning Rate: 0.000825071
	LOSS [training: 0.01639766428193572 | validation: 0.02038845424413415]
	TIME [epoch: 35.3 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01667332307558792		[learning rate: 0.00082108]
	Learning Rate: 0.000821081
	LOSS [training: 0.01667332307558792 | validation: 0.021047913756117424]
	TIME [epoch: 35.4 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01638712143392018		[learning rate: 0.00081711]
	Learning Rate: 0.00081711
	LOSS [training: 0.01638712143392018 | validation: 0.02058430464751732]
	TIME [epoch: 35.3 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016938655084229235		[learning rate: 0.00081316]
	Learning Rate: 0.000813159
	LOSS [training: 0.016938655084229235 | validation: 0.020283957818903627]
	TIME [epoch: 35.3 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01680021907653462		[learning rate: 0.00080923]
	Learning Rate: 0.000809226
	LOSS [training: 0.01680021907653462 | validation: 0.021396788062259444]
	TIME [epoch: 35.3 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01657399201338435		[learning rate: 0.00080531]
	Learning Rate: 0.000805313
	LOSS [training: 0.01657399201338435 | validation: 0.02116423955353429]
	TIME [epoch: 35.3 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01629672787063973		[learning rate: 0.00080142]
	Learning Rate: 0.000801419
	LOSS [training: 0.01629672787063973 | validation: 0.020944683403532]
	TIME [epoch: 35.3 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016219894922306556		[learning rate: 0.00079754]
	Learning Rate: 0.000797544
	LOSS [training: 0.016219894922306556 | validation: 0.020568615113846483]
	TIME [epoch: 35.3 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016289974279567524		[learning rate: 0.00079369]
	Learning Rate: 0.000793686
	LOSS [training: 0.016289974279567524 | validation: 0.02018137019389075]
	TIME [epoch: 35.3 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016599645163397053		[learning rate: 0.00078985]
	Learning Rate: 0.000789848
	LOSS [training: 0.016599645163397053 | validation: 0.020499317285973578]
	TIME [epoch: 35.3 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01672658538422006		[learning rate: 0.00078603]
	Learning Rate: 0.000786029
	LOSS [training: 0.01672658538422006 | validation: 0.020615149662456818]
	TIME [epoch: 35.4 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0162658827563964		[learning rate: 0.00078223]
	Learning Rate: 0.000782228
	LOSS [training: 0.0162658827563964 | validation: 0.020370273440988147]
	TIME [epoch: 35.3 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01613803702859117		[learning rate: 0.00077845]
	Learning Rate: 0.000778445
	LOSS [training: 0.01613803702859117 | validation: 0.020719789697185936]
	TIME [epoch: 35.3 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01636925084213093		[learning rate: 0.00077468]
	Learning Rate: 0.000774681
	LOSS [training: 0.01636925084213093 | validation: 0.020751639813055018]
	TIME [epoch: 35.3 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016388738416083095		[learning rate: 0.00077093]
	Learning Rate: 0.000770935
	LOSS [training: 0.016388738416083095 | validation: 0.02019235324604282]
	TIME [epoch: 35.3 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01639323102557993		[learning rate: 0.00076721]
	Learning Rate: 0.000767206
	LOSS [training: 0.01639323102557993 | validation: 0.02024392830227165]
	TIME [epoch: 35.3 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01639777185924413		[learning rate: 0.0007635]
	Learning Rate: 0.000763496
	LOSS [training: 0.01639777185924413 | validation: 0.019824543870262456]
	TIME [epoch: 35.3 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0160504612148675		[learning rate: 0.0007598]
	Learning Rate: 0.000759804
	LOSS [training: 0.0160504612148675 | validation: 0.021031836046480335]
	TIME [epoch: 35.3 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0163590090907449		[learning rate: 0.00075613]
	Learning Rate: 0.00075613
	LOSS [training: 0.0163590090907449 | validation: 0.021030658291431126]
	TIME [epoch: 35.3 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016349402502732837		[learning rate: 0.00075247]
	Learning Rate: 0.000752473
	LOSS [training: 0.016349402502732837 | validation: 0.021624677811943632]
	TIME [epoch: 35.3 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016268878380960555		[learning rate: 0.00074883]
	Learning Rate: 0.000748835
	LOSS [training: 0.016268878380960555 | validation: 0.020508786443745264]
	TIME [epoch: 35.3 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01714517061002763		[learning rate: 0.00074521]
	Learning Rate: 0.000745213
	LOSS [training: 0.01714517061002763 | validation: 0.020653525945786424]
	TIME [epoch: 35.3 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016393121604458567		[learning rate: 0.00074161]
	Learning Rate: 0.00074161
	LOSS [training: 0.016393121604458567 | validation: 0.021188950610923556]
	TIME [epoch: 35.3 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01584029160802092		[learning rate: 0.00073802]
	Learning Rate: 0.000738023
	LOSS [training: 0.01584029160802092 | validation: 0.021091058881186234]
	TIME [epoch: 35.3 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016731822258034452		[learning rate: 0.00073445]
	Learning Rate: 0.000734454
	LOSS [training: 0.016731822258034452 | validation: 0.020730004561912544]
	TIME [epoch: 35.3 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01642272888759154		[learning rate: 0.0007309]
	Learning Rate: 0.000730903
	LOSS [training: 0.01642272888759154 | validation: 0.020761979235294162]
	TIME [epoch: 35.4 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01618263274578476		[learning rate: 0.00072737]
	Learning Rate: 0.000727368
	LOSS [training: 0.01618263274578476 | validation: 0.02079547918303874]
	TIME [epoch: 35.3 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016225814013547713		[learning rate: 0.00072385]
	Learning Rate: 0.000723851
	LOSS [training: 0.016225814013547713 | validation: 0.02052835177441469]
	TIME [epoch: 35.3 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015920464493512237		[learning rate: 0.00072035]
	Learning Rate: 0.00072035
	LOSS [training: 0.015920464493512237 | validation: 0.02049971111662129]
	TIME [epoch: 35.3 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01622943526299092		[learning rate: 0.00071687]
	Learning Rate: 0.000716867
	LOSS [training: 0.01622943526299092 | validation: 0.020341169684856903]
	TIME [epoch: 35.3 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016405505743183543		[learning rate: 0.0007134]
	Learning Rate: 0.0007134
	LOSS [training: 0.016405505743183543 | validation: 0.020822888509885798]
	TIME [epoch: 35.3 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016473543714492195		[learning rate: 0.00070995]
	Learning Rate: 0.00070995
	LOSS [training: 0.016473543714492195 | validation: 0.02102605950361584]
	TIME [epoch: 35.3 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016888955973581962		[learning rate: 0.00070652]
	Learning Rate: 0.000706517
	LOSS [training: 0.016888955973581962 | validation: 0.02146004112617224]
	TIME [epoch: 35.3 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01577476709529776		[learning rate: 0.0007031]
	Learning Rate: 0.000703101
	LOSS [training: 0.01577476709529776 | validation: 0.02117881416884251]
	TIME [epoch: 35.3 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016631536493544014		[learning rate: 0.0006997]
	Learning Rate: 0.000699701
	LOSS [training: 0.016631536493544014 | validation: 0.020569527690185194]
	TIME [epoch: 35.3 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016105310540563605		[learning rate: 0.00069632]
	Learning Rate: 0.000696317
	LOSS [training: 0.016105310540563605 | validation: 0.02085477891125054]
	TIME [epoch: 35.3 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01628827797258536		[learning rate: 0.00069295]
	Learning Rate: 0.00069295
	LOSS [training: 0.01628827797258536 | validation: 0.020428596821440853]
	TIME [epoch: 35.3 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016597618820368414		[learning rate: 0.0006896]
	Learning Rate: 0.000689599
	LOSS [training: 0.016597618820368414 | validation: 0.021196459567968878]
	TIME [epoch: 35.3 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01626872846098171		[learning rate: 0.00068626]
	Learning Rate: 0.000686264
	LOSS [training: 0.01626872846098171 | validation: 0.020483846567767226]
	TIME [epoch: 35.3 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01643561202826167		[learning rate: 0.00068295]
	Learning Rate: 0.000682945
	LOSS [training: 0.01643561202826167 | validation: 0.020867239652205338]
	TIME [epoch: 35.3 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016036411482308204		[learning rate: 0.00067964]
	Learning Rate: 0.000679643
	LOSS [training: 0.016036411482308204 | validation: 0.020462263774291653]
	TIME [epoch: 35.3 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01612430402538589		[learning rate: 0.00067636]
	Learning Rate: 0.000676356
	LOSS [training: 0.01612430402538589 | validation: 0.02141708708196342]
	TIME [epoch: 35.3 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015984264127177388		[learning rate: 0.00067309]
	Learning Rate: 0.000673085
	LOSS [training: 0.015984264127177388 | validation: 0.020905482662096842]
	TIME [epoch: 35.3 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016844615891242323		[learning rate: 0.00066983]
	Learning Rate: 0.00066983
	LOSS [training: 0.016844615891242323 | validation: 0.021259010696357983]
	TIME [epoch: 35.3 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.017585053139348116		[learning rate: 0.00066659]
	Learning Rate: 0.000666591
	LOSS [training: 0.017585053139348116 | validation: 0.021130094793030407]
	TIME [epoch: 35.3 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016310438804265942		[learning rate: 0.00066337]
	Learning Rate: 0.000663368
	LOSS [training: 0.016310438804265942 | validation: 0.02083892612763665]
	TIME [epoch: 35.3 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015952437130390806		[learning rate: 0.00066016]
	Learning Rate: 0.00066016
	LOSS [training: 0.015952437130390806 | validation: 0.02066227548311483]
	TIME [epoch: 35.3 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016014614523352722		[learning rate: 0.00065697]
	Learning Rate: 0.000656967
	LOSS [training: 0.016014614523352722 | validation: 0.020565930213764187]
	TIME [epoch: 35.3 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016309891599976135		[learning rate: 0.00065379]
	Learning Rate: 0.00065379
	LOSS [training: 0.016309891599976135 | validation: 0.02113119564625825]
	TIME [epoch: 35.3 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01621916640306537		[learning rate: 0.00065063]
	Learning Rate: 0.000650629
	LOSS [training: 0.01621916640306537 | validation: 0.020649116006216297]
	TIME [epoch: 35.3 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016643340694993507		[learning rate: 0.00064748]
	Learning Rate: 0.000647482
	LOSS [training: 0.016643340694993507 | validation: 0.021406910207468474]
	TIME [epoch: 35.3 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016580927721658218		[learning rate: 0.00064435]
	Learning Rate: 0.000644351
	LOSS [training: 0.016580927721658218 | validation: 0.02108136183920065]
	TIME [epoch: 35.3 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016436133706811885		[learning rate: 0.00064124]
	Learning Rate: 0.000641235
	LOSS [training: 0.016436133706811885 | validation: 0.020305916204087296]
	TIME [epoch: 35.3 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01645760950007198		[learning rate: 0.00063813]
	Learning Rate: 0.000638134
	LOSS [training: 0.01645760950007198 | validation: 0.020176296881652043]
	TIME [epoch: 35.3 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01643648753433413		[learning rate: 0.00063505]
	Learning Rate: 0.000635049
	LOSS [training: 0.01643648753433413 | validation: 0.020831516278542673]
	TIME [epoch: 35.3 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016233112122160415		[learning rate: 0.00063198]
	Learning Rate: 0.000631978
	LOSS [training: 0.016233112122160415 | validation: 0.019970426083282932]
	TIME [epoch: 35.3 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016091628197703527		[learning rate: 0.00062892]
	Learning Rate: 0.000628922
	LOSS [training: 0.016091628197703527 | validation: 0.020934583175507226]
	TIME [epoch: 35.3 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016418782425524553		[learning rate: 0.00062588]
	Learning Rate: 0.00062588
	LOSS [training: 0.016418782425524553 | validation: 0.020317705405978204]
	TIME [epoch: 35.3 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015787931679229126		[learning rate: 0.00062285]
	Learning Rate: 0.000622853
	LOSS [training: 0.015787931679229126 | validation: 0.020923328913030708]
	TIME [epoch: 35.3 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01624443299586024		[learning rate: 0.00061984]
	Learning Rate: 0.000619842
	LOSS [training: 0.01624443299586024 | validation: 0.020282782550680917]
	TIME [epoch: 35.3 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015871528146949258		[learning rate: 0.00061684]
	Learning Rate: 0.000616844
	LOSS [training: 0.015871528146949258 | validation: 0.02048627112067262]
	TIME [epoch: 35.3 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016020339941792066		[learning rate: 0.00061386]
	Learning Rate: 0.000613861
	LOSS [training: 0.016020339941792066 | validation: 0.01975797827595484]
	TIME [epoch: 35.3 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016040242270849357		[learning rate: 0.00061089]
	Learning Rate: 0.000610893
	LOSS [training: 0.016040242270849357 | validation: 0.02118485258587939]
	TIME [epoch: 35.3 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015812036088515242		[learning rate: 0.00060794]
	Learning Rate: 0.000607938
	LOSS [training: 0.015812036088515242 | validation: 0.020738248355538055]
	TIME [epoch: 35.3 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016611539128868577		[learning rate: 0.000605]
	Learning Rate: 0.000604999
	LOSS [training: 0.016611539128868577 | validation: 0.0210146767465359]
	TIME [epoch: 35.3 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015785842271788763		[learning rate: 0.00060207]
	Learning Rate: 0.000602073
	LOSS [training: 0.015785842271788763 | validation: 0.02092346864012451]
	TIME [epoch: 35.3 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015721721642434076		[learning rate: 0.00059916]
	Learning Rate: 0.000599161
	LOSS [training: 0.015721721642434076 | validation: 0.021668159808093584]
	TIME [epoch: 35.3 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016026353047887132		[learning rate: 0.00059626]
	Learning Rate: 0.000596264
	LOSS [training: 0.016026353047887132 | validation: 0.01993615809880278]
	TIME [epoch: 35.3 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015546849445595113		[learning rate: 0.00059338]
	Learning Rate: 0.000593381
	LOSS [training: 0.015546849445595113 | validation: 0.020175526156963615]
	TIME [epoch: 35.3 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016028276739154596		[learning rate: 0.00059051]
	Learning Rate: 0.000590511
	LOSS [training: 0.016028276739154596 | validation: 0.021116410220493504]
	TIME [epoch: 35.3 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015589298646841138		[learning rate: 0.00058766]
	Learning Rate: 0.000587655
	LOSS [training: 0.015589298646841138 | validation: 0.021362420411312644]
	TIME [epoch: 35.2 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01616332118620509		[learning rate: 0.00058481]
	Learning Rate: 0.000584814
	LOSS [training: 0.01616332118620509 | validation: 0.020711401562804595]
	TIME [epoch: 35.3 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016165349691661477		[learning rate: 0.00058199]
	Learning Rate: 0.000581986
	LOSS [training: 0.016165349691661477 | validation: 0.0215662451902959]
	TIME [epoch: 35.3 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016528409323864235		[learning rate: 0.00057917]
	Learning Rate: 0.000579171
	LOSS [training: 0.016528409323864235 | validation: 0.020560844545826542]
	TIME [epoch: 35.3 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016107395653969757		[learning rate: 0.00057637]
	Learning Rate: 0.00057637
	LOSS [training: 0.016107395653969757 | validation: 0.0205398026666976]
	TIME [epoch: 35.3 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015991666495118045		[learning rate: 0.00057358]
	Learning Rate: 0.000573583
	LOSS [training: 0.015991666495118045 | validation: 0.019343008722072525]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_640.pth
	Model improved!!!
EPOCH 641/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015672544232149657		[learning rate: 0.00057081]
	Learning Rate: 0.000570809
	LOSS [training: 0.015672544232149657 | validation: 0.019878934410890062]
	TIME [epoch: 35.3 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016503257682747904		[learning rate: 0.00056805]
	Learning Rate: 0.000568049
	LOSS [training: 0.016503257682747904 | validation: 0.019290082161732794]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_642.pth
	Model improved!!!
EPOCH 643/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01637382657027647		[learning rate: 0.0005653]
	Learning Rate: 0.000565302
	LOSS [training: 0.01637382657027647 | validation: 0.020148071960987893]
	TIME [epoch: 35.3 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016059931897148366		[learning rate: 0.00056257]
	Learning Rate: 0.000562568
	LOSS [training: 0.016059931897148366 | validation: 0.02046920158748294]
	TIME [epoch: 35.3 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015795836149926246		[learning rate: 0.00055985]
	Learning Rate: 0.000559848
	LOSS [training: 0.015795836149926246 | validation: 0.020051743306697012]
	TIME [epoch: 35.3 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016533997082548994		[learning rate: 0.00055714]
	Learning Rate: 0.000557141
	LOSS [training: 0.016533997082548994 | validation: 0.020046443279820834]
	TIME [epoch: 35.3 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016351146426688716		[learning rate: 0.00055445]
	Learning Rate: 0.000554446
	LOSS [training: 0.016351146426688716 | validation: 0.020293124721890824]
	TIME [epoch: 35.3 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016137210841068308		[learning rate: 0.00055177]
	Learning Rate: 0.000551765
	LOSS [training: 0.016137210841068308 | validation: 0.020073396368507693]
	TIME [epoch: 35.3 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016115377842966527		[learning rate: 0.0005491]
	Learning Rate: 0.000549097
	LOSS [training: 0.016115377842966527 | validation: 0.02008287619690243]
	TIME [epoch: 35.3 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01624035960406449		[learning rate: 0.00054644]
	Learning Rate: 0.000546442
	LOSS [training: 0.01624035960406449 | validation: 0.01927227617272866]
	TIME [epoch: 35.3 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_650.pth
	Model improved!!!
EPOCH 651/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015684223552732142		[learning rate: 0.0005438]
	Learning Rate: 0.000543799
	LOSS [training: 0.015684223552732142 | validation: 0.02140295466792144]
	TIME [epoch: 35.3 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01670107979868893		[learning rate: 0.00054117]
	Learning Rate: 0.000541169
	LOSS [training: 0.01670107979868893 | validation: 0.02119078965087985]
	TIME [epoch: 35.3 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0159957677573469		[learning rate: 0.00053855]
	Learning Rate: 0.000538552
	LOSS [training: 0.0159957677573469 | validation: 0.020824559051703443]
	TIME [epoch: 35.4 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015432120501872518		[learning rate: 0.00053595]
	Learning Rate: 0.000535948
	LOSS [training: 0.015432120501872518 | validation: 0.02098203371726154]
	TIME [epoch: 35.3 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016865362538106568		[learning rate: 0.00053336]
	Learning Rate: 0.000533356
	LOSS [training: 0.016865362538106568 | validation: 0.02050258074677911]
	TIME [epoch: 35.3 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016185465632992783		[learning rate: 0.00053078]
	Learning Rate: 0.000530777
	LOSS [training: 0.016185465632992783 | validation: 0.020585319126949733]
	TIME [epoch: 35.3 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015475768747528281		[learning rate: 0.00052821]
	Learning Rate: 0.00052821
	LOSS [training: 0.015475768747528281 | validation: 0.021116387639661744]
	TIME [epoch: 35.3 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016500774829407556		[learning rate: 0.00052566]
	Learning Rate: 0.000525656
	LOSS [training: 0.016500774829407556 | validation: 0.02085020784498155]
	TIME [epoch: 35.3 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01606752764806972		[learning rate: 0.00052311]
	Learning Rate: 0.000523114
	LOSS [training: 0.01606752764806972 | validation: 0.0205472198489092]
	TIME [epoch: 35.3 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015896655973467552		[learning rate: 0.00052058]
	Learning Rate: 0.000520584
	LOSS [training: 0.015896655973467552 | validation: 0.021589967240280488]
	TIME [epoch: 35.4 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016334529014888785		[learning rate: 0.00051807]
	Learning Rate: 0.000518067
	LOSS [training: 0.016334529014888785 | validation: 0.020687291300922037]
	TIME [epoch: 35.3 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01669796640769193		[learning rate: 0.00051556]
	Learning Rate: 0.000515562
	LOSS [training: 0.01669796640769193 | validation: 0.020823429960999052]
	TIME [epoch: 35.3 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015633167456504504		[learning rate: 0.00051307]
	Learning Rate: 0.000513069
	LOSS [training: 0.015633167456504504 | validation: 0.02078837629843673]
	TIME [epoch: 35.3 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01611888149051102		[learning rate: 0.00051059]
	Learning Rate: 0.000510587
	LOSS [training: 0.01611888149051102 | validation: 0.020454571800189548]
	TIME [epoch: 35.3 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0156472352139615		[learning rate: 0.00050812]
	Learning Rate: 0.000508118
	LOSS [training: 0.0156472352139615 | validation: 0.02031432200556299]
	TIME [epoch: 35.3 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016000826009921466		[learning rate: 0.00050566]
	Learning Rate: 0.000505661
	LOSS [training: 0.016000826009921466 | validation: 0.02032033019337501]
	TIME [epoch: 35.3 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015685426641894276		[learning rate: 0.00050322]
	Learning Rate: 0.000503216
	LOSS [training: 0.015685426641894276 | validation: 0.021082381323293865]
	TIME [epoch: 35.3 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016002475394115406		[learning rate: 0.00050078]
	Learning Rate: 0.000500782
	LOSS [training: 0.016002475394115406 | validation: 0.01998958326777259]
	TIME [epoch: 35.3 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01518657780485224		[learning rate: 0.00049836]
	Learning Rate: 0.000498361
	LOSS [training: 0.01518657780485224 | validation: 0.019881048748436343]
	TIME [epoch: 35.3 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015550798597737786		[learning rate: 0.00049595]
	Learning Rate: 0.000495951
	LOSS [training: 0.015550798597737786 | validation: 0.020540495183514397]
	TIME [epoch: 35.3 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016450745481511295		[learning rate: 0.00049355]
	Learning Rate: 0.000493552
	LOSS [training: 0.016450745481511295 | validation: 0.020208477757935217]
	TIME [epoch: 35.3 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01572373553933286		[learning rate: 0.00049117]
	Learning Rate: 0.000491166
	LOSS [training: 0.01572373553933286 | validation: 0.021002838525636298]
	TIME [epoch: 35.3 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015835886205098567		[learning rate: 0.00048879]
	Learning Rate: 0.000488791
	LOSS [training: 0.015835886205098567 | validation: 0.020618596681761834]
	TIME [epoch: 35.3 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01648625475439015		[learning rate: 0.00048643]
	Learning Rate: 0.000486427
	LOSS [training: 0.01648625475439015 | validation: 0.020986491418816807]
	TIME [epoch: 35.3 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015920274628043476		[learning rate: 0.00048407]
	Learning Rate: 0.000484074
	LOSS [training: 0.015920274628043476 | validation: 0.02050970741632625]
	TIME [epoch: 35.3 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016381612673470408		[learning rate: 0.00048173]
	Learning Rate: 0.000481734
	LOSS [training: 0.016381612673470408 | validation: 0.020301745505758122]
	TIME [epoch: 35.3 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015235946826751548		[learning rate: 0.0004794]
	Learning Rate: 0.000479404
	LOSS [training: 0.015235946826751548 | validation: 0.0206658778176442]
	TIME [epoch: 35.3 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016141451964850197		[learning rate: 0.00047709]
	Learning Rate: 0.000477086
	LOSS [training: 0.016141451964850197 | validation: 0.02094932614817942]
	TIME [epoch: 35.3 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01553264804016874		[learning rate: 0.00047478]
	Learning Rate: 0.000474779
	LOSS [training: 0.01553264804016874 | validation: 0.02042265438632562]
	TIME [epoch: 35.3 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01593799474130042		[learning rate: 0.00047248]
	Learning Rate: 0.000472483
	LOSS [training: 0.01593799474130042 | validation: 0.020377302678431516]
	TIME [epoch: 35.3 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015445159895776711		[learning rate: 0.0004702]
	Learning Rate: 0.000470198
	LOSS [training: 0.015445159895776711 | validation: 0.02026392403326444]
	TIME [epoch: 35.3 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015585812762580179		[learning rate: 0.00046792]
	Learning Rate: 0.000467924
	LOSS [training: 0.015585812762580179 | validation: 0.020809403804899495]
	TIME [epoch: 35.3 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016159393602080217		[learning rate: 0.00046566]
	Learning Rate: 0.000465661
	LOSS [training: 0.016159393602080217 | validation: 0.020402247013021117]
	TIME [epoch: 35.3 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015911344963109458		[learning rate: 0.00046341]
	Learning Rate: 0.000463409
	LOSS [training: 0.015911344963109458 | validation: 0.021523130367458416]
	TIME [epoch: 35.3 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0167474128627588		[learning rate: 0.00046117]
	Learning Rate: 0.000461168
	LOSS [training: 0.0167474128627588 | validation: 0.02076813354185356]
	TIME [epoch: 35.3 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01600949152432495		[learning rate: 0.00045894]
	Learning Rate: 0.000458938
	LOSS [training: 0.01600949152432495 | validation: 0.021189487650695307]
	TIME [epoch: 35.3 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015812051168104628		[learning rate: 0.00045672]
	Learning Rate: 0.000456719
	LOSS [training: 0.015812051168104628 | validation: 0.020863851954865783]
	TIME [epoch: 35.3 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015509322290521788		[learning rate: 0.00045451]
	Learning Rate: 0.00045451
	LOSS [training: 0.015509322290521788 | validation: 0.020417720169300154]
	TIME [epoch: 35.2 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015469509286254799		[learning rate: 0.00045231]
	Learning Rate: 0.000452312
	LOSS [training: 0.015469509286254799 | validation: 0.020500744951253418]
	TIME [epoch: 35.3 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016063772227158057		[learning rate: 0.00045013]
	Learning Rate: 0.000450125
	LOSS [training: 0.016063772227158057 | validation: 0.021037763272068716]
	TIME [epoch: 35.3 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01588601252179443		[learning rate: 0.00044795]
	Learning Rate: 0.000447948
	LOSS [training: 0.01588601252179443 | validation: 0.020431331055108828]
	TIME [epoch: 35.2 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015443163991875055		[learning rate: 0.00044578]
	Learning Rate: 0.000445782
	LOSS [training: 0.015443163991875055 | validation: 0.021269656048926864]
	TIME [epoch: 35.3 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015758491655490363		[learning rate: 0.00044363]
	Learning Rate: 0.000443626
	LOSS [training: 0.015758491655490363 | validation: 0.020098947428804206]
	TIME [epoch: 35.3 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015813302438933554		[learning rate: 0.00044148]
	Learning Rate: 0.000441481
	LOSS [training: 0.015813302438933554 | validation: 0.020181718802805462]
	TIME [epoch: 35.3 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016060501173640444		[learning rate: 0.00043935]
	Learning Rate: 0.000439346
	LOSS [training: 0.016060501173640444 | validation: 0.020012439311292752]
	TIME [epoch: 35.3 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015966192111224815		[learning rate: 0.00043722]
	Learning Rate: 0.000437222
	LOSS [training: 0.015966192111224815 | validation: 0.020564676955783262]
	TIME [epoch: 35.3 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0162336656904384		[learning rate: 0.00043511]
	Learning Rate: 0.000435107
	LOSS [training: 0.0162336656904384 | validation: 0.02018826479347018]
	TIME [epoch: 35.3 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015711654079720416		[learning rate: 0.000433]
	Learning Rate: 0.000433003
	LOSS [training: 0.015711654079720416 | validation: 0.020467646794249585]
	TIME [epoch: 35.3 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015368213944245526		[learning rate: 0.00043091]
	Learning Rate: 0.000430909
	LOSS [training: 0.015368213944245526 | validation: 0.01967192743829027]
	TIME [epoch: 35.3 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015543092886340676		[learning rate: 0.00042883]
	Learning Rate: 0.000428826
	LOSS [training: 0.015543092886340676 | validation: 0.021089943841291675]
	TIME [epoch: 35.3 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015548438653061212		[learning rate: 0.00042675]
	Learning Rate: 0.000426752
	LOSS [training: 0.015548438653061212 | validation: 0.020833430354668406]
	TIME [epoch: 96 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015961043474082327		[learning rate: 0.00042469]
	Learning Rate: 0.000424688
	LOSS [training: 0.015961043474082327 | validation: 0.021204784848151557]
	TIME [epoch: 72.2 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01591888780958595		[learning rate: 0.00042263]
	Learning Rate: 0.000422634
	LOSS [training: 0.01591888780958595 | validation: 0.01986135147486692]
	TIME [epoch: 72.2 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016017073109275585		[learning rate: 0.00042059]
	Learning Rate: 0.000420591
	LOSS [training: 0.016017073109275585 | validation: 0.020314191299940054]
	TIME [epoch: 72.2 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01597672546064841		[learning rate: 0.00041856]
	Learning Rate: 0.000418557
	LOSS [training: 0.01597672546064841 | validation: 0.019682906551111466]
	TIME [epoch: 72.3 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015960483369526265		[learning rate: 0.00041653]
	Learning Rate: 0.000416533
	LOSS [training: 0.015960483369526265 | validation: 0.02052656728873747]
	TIME [epoch: 72.3 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015546871677847185		[learning rate: 0.00041452]
	Learning Rate: 0.000414518
	LOSS [training: 0.015546871677847185 | validation: 0.020885578773242163]
	TIME [epoch: 72.3 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016151887147717356		[learning rate: 0.00041251]
	Learning Rate: 0.000412514
	LOSS [training: 0.016151887147717356 | validation: 0.02047394245470828]
	TIME [epoch: 72.2 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015609822248361016		[learning rate: 0.00041052]
	Learning Rate: 0.000410519
	LOSS [training: 0.015609822248361016 | validation: 0.0198680214107273]
	TIME [epoch: 72.3 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0154222232412779		[learning rate: 0.00040853]
	Learning Rate: 0.000408534
	LOSS [training: 0.0154222232412779 | validation: 0.02012091891295072]
	TIME [epoch: 72.3 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015556934816722254		[learning rate: 0.00040656]
	Learning Rate: 0.000406558
	LOSS [training: 0.015556934816722254 | validation: 0.020293149960576295]
	TIME [epoch: 72.3 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016111950179161685		[learning rate: 0.00040459]
	Learning Rate: 0.000404592
	LOSS [training: 0.016111950179161685 | validation: 0.020590121084831676]
	TIME [epoch: 72.3 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015863088092659065		[learning rate: 0.00040264]
	Learning Rate: 0.000402636
	LOSS [training: 0.015863088092659065 | validation: 0.020360880247122033]
	TIME [epoch: 72.4 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015646673388781965		[learning rate: 0.00040069]
	Learning Rate: 0.000400689
	LOSS [training: 0.015646673388781965 | validation: 0.0204402970807578]
	TIME [epoch: 72.2 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01599395583355045		[learning rate: 0.00039875]
	Learning Rate: 0.000398751
	LOSS [training: 0.01599395583355045 | validation: 0.020786485045577823]
	TIME [epoch: 72.2 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015037846202266584		[learning rate: 0.00039682]
	Learning Rate: 0.000396823
	LOSS [training: 0.015037846202266584 | validation: 0.02028286482680949]
	TIME [epoch: 72.2 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01634832305614942		[learning rate: 0.0003949]
	Learning Rate: 0.000394904
	LOSS [training: 0.01634832305614942 | validation: 0.019537803350384172]
	TIME [epoch: 72.3 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015386511233086696		[learning rate: 0.00039299]
	Learning Rate: 0.000392994
	LOSS [training: 0.015386511233086696 | validation: 0.020137290621345928]
	TIME [epoch: 72.3 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01631092187845618		[learning rate: 0.00039109]
	Learning Rate: 0.000391094
	LOSS [training: 0.01631092187845618 | validation: 0.020816862449739074]
	TIME [epoch: 72.2 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015431387851408839		[learning rate: 0.0003892]
	Learning Rate: 0.000389202
	LOSS [training: 0.015431387851408839 | validation: 0.019788733477180773]
	TIME [epoch: 72.3 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015539102824299779		[learning rate: 0.00038732]
	Learning Rate: 0.00038732
	LOSS [training: 0.015539102824299779 | validation: 0.019577573494837405]
	TIME [epoch: 72.3 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015485705147822437		[learning rate: 0.00038545]
	Learning Rate: 0.000385447
	LOSS [training: 0.015485705147822437 | validation: 0.020672681593602416]
	TIME [epoch: 72.3 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015991429118072095		[learning rate: 0.00038358]
	Learning Rate: 0.000383583
	LOSS [training: 0.015991429118072095 | validation: 0.020085686089443805]
	TIME [epoch: 72.3 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015270934352975206		[learning rate: 0.00038173]
	Learning Rate: 0.000381728
	LOSS [training: 0.015270934352975206 | validation: 0.019997962305437402]
	TIME [epoch: 72.3 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015791343595009846		[learning rate: 0.00037988]
	Learning Rate: 0.000379882
	LOSS [training: 0.015791343595009846 | validation: 0.020985924420495433]
	TIME [epoch: 72.3 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01549729336472676		[learning rate: 0.00037805]
	Learning Rate: 0.000378045
	LOSS [training: 0.01549729336472676 | validation: 0.020660799107886898]
	TIME [epoch: 72.3 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015804211221722708		[learning rate: 0.00037622]
	Learning Rate: 0.000376217
	LOSS [training: 0.015804211221722708 | validation: 0.020528391936083]
	TIME [epoch: 72.2 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015223125977629981		[learning rate: 0.0003744]
	Learning Rate: 0.000374398
	LOSS [training: 0.015223125977629981 | validation: 0.02052930750253926]
	TIME [epoch: 72.3 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01604474331824492		[learning rate: 0.00037259]
	Learning Rate: 0.000372587
	LOSS [training: 0.01604474331824492 | validation: 0.020984507174651876]
	TIME [epoch: 72.2 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01616368700393631		[learning rate: 0.00037079]
	Learning Rate: 0.000370786
	LOSS [training: 0.01616368700393631 | validation: 0.020367211012067617]
	TIME [epoch: 72.2 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01564489809484591		[learning rate: 0.00036899]
	Learning Rate: 0.000368992
	LOSS [training: 0.01564489809484591 | validation: 0.01976408425884527]
	TIME [epoch: 72.3 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0150309169645989		[learning rate: 0.00036721]
	Learning Rate: 0.000367208
	LOSS [training: 0.0150309169645989 | validation: 0.020090394857170846]
	TIME [epoch: 72.4 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014747554225627423		[learning rate: 0.00036543]
	Learning Rate: 0.000365432
	LOSS [training: 0.014747554225627423 | validation: 0.020942550951900726]
	TIME [epoch: 72.3 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015542736365247408		[learning rate: 0.00036367]
	Learning Rate: 0.000363665
	LOSS [training: 0.015542736365247408 | validation: 0.01994579023452102]
	TIME [epoch: 72.3 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01521130477545342		[learning rate: 0.00036191]
	Learning Rate: 0.000361907
	LOSS [training: 0.01521130477545342 | validation: 0.020904055187488516]
	TIME [epoch: 72.3 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015597374505557501		[learning rate: 0.00036016]
	Learning Rate: 0.000360156
	LOSS [training: 0.015597374505557501 | validation: 0.02044371186058644]
	TIME [epoch: 72.3 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016197427589576267		[learning rate: 0.00035841]
	Learning Rate: 0.000358415
	LOSS [training: 0.016197427589576267 | validation: 0.021027769609941054]
	TIME [epoch: 72.3 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016138690404882083		[learning rate: 0.00035668]
	Learning Rate: 0.000356682
	LOSS [training: 0.016138690404882083 | validation: 0.021410847997077664]
	TIME [epoch: 72.3 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01621495247932354		[learning rate: 0.00035496]
	Learning Rate: 0.000354957
	LOSS [training: 0.01621495247932354 | validation: 0.020990732675628624]
	TIME [epoch: 72.3 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015905422424083073		[learning rate: 0.00035324]
	Learning Rate: 0.00035324
	LOSS [training: 0.015905422424083073 | validation: 0.020665570560556186]
	TIME [epoch: 72.3 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01586174540623946		[learning rate: 0.00035153]
	Learning Rate: 0.000351532
	LOSS [training: 0.01586174540623946 | validation: 0.01987958809311307]
	TIME [epoch: 72.3 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015657371932328065		[learning rate: 0.00034983]
	Learning Rate: 0.000349832
	LOSS [training: 0.015657371932328065 | validation: 0.020137770629264622]
	TIME [epoch: 72.2 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016012525595239305		[learning rate: 0.00034814]
	Learning Rate: 0.00034814
	LOSS [training: 0.016012525595239305 | validation: 0.020689696511184116]
	TIME [epoch: 72.3 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016175367057323888		[learning rate: 0.00034646]
	Learning Rate: 0.000346457
	LOSS [training: 0.016175367057323888 | validation: 0.02027486239088328]
	TIME [epoch: 72.3 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0157134763730564		[learning rate: 0.00034478]
	Learning Rate: 0.000344781
	LOSS [training: 0.0157134763730564 | validation: 0.019994797178931028]
	TIME [epoch: 72.2 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015342121284557947		[learning rate: 0.00034311]
	Learning Rate: 0.000343114
	LOSS [training: 0.015342121284557947 | validation: 0.020517670384877156]
	TIME [epoch: 72.3 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015414837764085212		[learning rate: 0.00034145]
	Learning Rate: 0.000341455
	LOSS [training: 0.015414837764085212 | validation: 0.02107045073909126]
	TIME [epoch: 72.3 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015418081230648889		[learning rate: 0.0003398]
	Learning Rate: 0.000339804
	LOSS [training: 0.015418081230648889 | validation: 0.02028765605516507]
	TIME [epoch: 72.3 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015100753820488566		[learning rate: 0.00033816]
	Learning Rate: 0.00033816
	LOSS [training: 0.015100753820488566 | validation: 0.020423851429777883]
	TIME [epoch: 72.3 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01589003087849923		[learning rate: 0.00033653]
	Learning Rate: 0.000336525
	LOSS [training: 0.01589003087849923 | validation: 0.01957194404480989]
	TIME [epoch: 72.3 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015479217347149516		[learning rate: 0.0003349]
	Learning Rate: 0.000334898
	LOSS [training: 0.015479217347149516 | validation: 0.019755885716844536]
	TIME [epoch: 72.2 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015864271302992207		[learning rate: 0.00033328]
	Learning Rate: 0.000333278
	LOSS [training: 0.015864271302992207 | validation: 0.020036264733449844]
	TIME [epoch: 72.3 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01584858642385847		[learning rate: 0.00033167]
	Learning Rate: 0.000331666
	LOSS [training: 0.01584858642385847 | validation: 0.021222278854122884]
	TIME [epoch: 72.3 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01561356241903023		[learning rate: 0.00033006]
	Learning Rate: 0.000330063
	LOSS [training: 0.01561356241903023 | validation: 0.02028174376278974]
	TIME [epoch: 72.3 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01576011671853652		[learning rate: 0.00032847]
	Learning Rate: 0.000328467
	LOSS [training: 0.01576011671853652 | validation: 0.020094842000217338]
	TIME [epoch: 72.3 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01541546319097769		[learning rate: 0.00032688]
	Learning Rate: 0.000326878
	LOSS [training: 0.01541546319097769 | validation: 0.020242298645564382]
	TIME [epoch: 72.3 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01582593564014179		[learning rate: 0.0003253]
	Learning Rate: 0.000325297
	LOSS [training: 0.01582593564014179 | validation: 0.020059111888521244]
	TIME [epoch: 72.3 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01542308973775862		[learning rate: 0.00032372]
	Learning Rate: 0.000323724
	LOSS [training: 0.01542308973775862 | validation: 0.020279004320560862]
	TIME [epoch: 72.3 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015229934917534165		[learning rate: 0.00032216]
	Learning Rate: 0.000322159
	LOSS [training: 0.015229934917534165 | validation: 0.020542027733238898]
	TIME [epoch: 72.3 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015916346371321707		[learning rate: 0.0003206]
	Learning Rate: 0.000320601
	LOSS [training: 0.015916346371321707 | validation: 0.020046394457461838]
	TIME [epoch: 72.3 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01559222637019648		[learning rate: 0.00031905]
	Learning Rate: 0.000319051
	LOSS [training: 0.01559222637019648 | validation: 0.020212757648577537]
	TIME [epoch: 72.3 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015465394767712679		[learning rate: 0.00031751]
	Learning Rate: 0.000317508
	LOSS [training: 0.015465394767712679 | validation: 0.020700639148955053]
	TIME [epoch: 72.3 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015230409921645044		[learning rate: 0.00031597]
	Learning Rate: 0.000315972
	LOSS [training: 0.015230409921645044 | validation: 0.019874887786946457]
	TIME [epoch: 72.3 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015934174685973124		[learning rate: 0.00031444]
	Learning Rate: 0.000314444
	LOSS [training: 0.015934174685973124 | validation: 0.020116779751475817]
	TIME [epoch: 72.3 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015694455909339083		[learning rate: 0.00031292]
	Learning Rate: 0.000312924
	LOSS [training: 0.015694455909339083 | validation: 0.020429971632573613]
	TIME [epoch: 72.2 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01521736529096216		[learning rate: 0.00031141]
	Learning Rate: 0.00031141
	LOSS [training: 0.01521736529096216 | validation: 0.020299371669490456]
	TIME [epoch: 72.3 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015635471357735808		[learning rate: 0.0003099]
	Learning Rate: 0.000309905
	LOSS [training: 0.015635471357735808 | validation: 0.01986105086008956]
	TIME [epoch: 72.3 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015170222036358469		[learning rate: 0.00030841]
	Learning Rate: 0.000308406
	LOSS [training: 0.015170222036358469 | validation: 0.02007368244422086]
	TIME [epoch: 72.3 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015722761230213978		[learning rate: 0.00030691]
	Learning Rate: 0.000306915
	LOSS [training: 0.015722761230213978 | validation: 0.020968110599392964]
	TIME [epoch: 72.3 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015292851966264473		[learning rate: 0.00030543]
	Learning Rate: 0.00030543
	LOSS [training: 0.015292851966264473 | validation: 0.02021589144298925]
	TIME [epoch: 72.2 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015292198410077604		[learning rate: 0.00030395]
	Learning Rate: 0.000303953
	LOSS [training: 0.015292198410077604 | validation: 0.020605423059417316]
	TIME [epoch: 72.3 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015310428572615761		[learning rate: 0.00030248]
	Learning Rate: 0.000302484
	LOSS [training: 0.015310428572615761 | validation: 0.020110968427156994]
	TIME [epoch: 72.2 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015795854657264616		[learning rate: 0.00030102]
	Learning Rate: 0.000301021
	LOSS [training: 0.015795854657264616 | validation: 0.02037162058538979]
	TIME [epoch: 72.3 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015735332609878215		[learning rate: 0.00029957]
	Learning Rate: 0.000299565
	LOSS [training: 0.015735332609878215 | validation: 0.02060552338935311]
	TIME [epoch: 72.3 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01574666594823884		[learning rate: 0.00029812]
	Learning Rate: 0.000298116
	LOSS [training: 0.01574666594823884 | validation: 0.021032293310945874]
	TIME [epoch: 72.3 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01543890560665534		[learning rate: 0.00029667]
	Learning Rate: 0.000296675
	LOSS [training: 0.01543890560665534 | validation: 0.02051097557336939]
	TIME [epoch: 72.3 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015687922360598985		[learning rate: 0.00029524]
	Learning Rate: 0.00029524
	LOSS [training: 0.015687922360598985 | validation: 0.020367020388002356]
	TIME [epoch: 72.3 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015367458699628902		[learning rate: 0.00029381]
	Learning Rate: 0.000293812
	LOSS [training: 0.015367458699628902 | validation: 0.021217796930941793]
	TIME [epoch: 72.3 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015914116019573918		[learning rate: 0.00029239]
	Learning Rate: 0.000292392
	LOSS [training: 0.015914116019573918 | validation: 0.02055625771238111]
	TIME [epoch: 72.3 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015644267828486495		[learning rate: 0.00029098]
	Learning Rate: 0.000290978
	LOSS [training: 0.015644267828486495 | validation: 0.020335874445661446]
	TIME [epoch: 72.3 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01543757142569447		[learning rate: 0.00028957]
	Learning Rate: 0.00028957
	LOSS [training: 0.01543757142569447 | validation: 0.020315844278386376]
	TIME [epoch: 72.4 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015257221718463632		[learning rate: 0.00028817]
	Learning Rate: 0.00028817
	LOSS [training: 0.015257221718463632 | validation: 0.021420398220449114]
	TIME [epoch: 72.3 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015304506406274827		[learning rate: 0.00028678]
	Learning Rate: 0.000286777
	LOSS [training: 0.015304506406274827 | validation: 0.020418725834692054]
	TIME [epoch: 72.4 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015169479896620769		[learning rate: 0.00028539]
	Learning Rate: 0.00028539
	LOSS [training: 0.015169479896620769 | validation: 0.020483584851434138]
	TIME [epoch: 72.3 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015130898040438906		[learning rate: 0.00028401]
	Learning Rate: 0.00028401
	LOSS [training: 0.015130898040438906 | validation: 0.020167668379279326]
	TIME [epoch: 72.3 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015621696911131676		[learning rate: 0.00028264]
	Learning Rate: 0.000282636
	LOSS [training: 0.015621696911131676 | validation: 0.021127453477229396]
	TIME [epoch: 72.3 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01580769075466192		[learning rate: 0.00028127]
	Learning Rate: 0.00028127
	LOSS [training: 0.01580769075466192 | validation: 0.021328467992921124]
	TIME [epoch: 72.3 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015633952512013743		[learning rate: 0.00027991]
	Learning Rate: 0.000279909
	LOSS [training: 0.015633952512013743 | validation: 0.02094743061100476]
	TIME [epoch: 72.4 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01547194236793019		[learning rate: 0.00027856]
	Learning Rate: 0.000278556
	LOSS [training: 0.01547194236793019 | validation: 0.020352217833996742]
	TIME [epoch: 72.3 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015584983110364428		[learning rate: 0.00027721]
	Learning Rate: 0.000277209
	LOSS [training: 0.015584983110364428 | validation: 0.02094618945395493]
	TIME [epoch: 72.4 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016001181220744336		[learning rate: 0.00027587]
	Learning Rate: 0.000275868
	LOSS [training: 0.016001181220744336 | validation: 0.020555421576912904]
	TIME [epoch: 72.3 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015938580893575353		[learning rate: 0.00027453]
	Learning Rate: 0.000274534
	LOSS [training: 0.015938580893575353 | validation: 0.021186100087522797]
	TIME [epoch: 72.3 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0156336876160118		[learning rate: 0.00027321]
	Learning Rate: 0.000273207
	LOSS [training: 0.0156336876160118 | validation: 0.02123101306096235]
	TIME [epoch: 72.3 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01569653971459538		[learning rate: 0.00027189]
	Learning Rate: 0.000271885
	LOSS [training: 0.01569653971459538 | validation: 0.01974285006586268]
	TIME [epoch: 72.3 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015264922675302125		[learning rate: 0.00027057]
	Learning Rate: 0.000270571
	LOSS [training: 0.015264922675302125 | validation: 0.02083269615408509]
	TIME [epoch: 72.3 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01539114776722955		[learning rate: 0.00026926]
	Learning Rate: 0.000269262
	LOSS [training: 0.01539114776722955 | validation: 0.02101687216569692]
	TIME [epoch: 72.2 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015201304621909209		[learning rate: 0.00026796]
	Learning Rate: 0.00026796
	LOSS [training: 0.015201304621909209 | validation: 0.02052879311888021]
	TIME [epoch: 72.3 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015472581996583525		[learning rate: 0.00026666]
	Learning Rate: 0.000266664
	LOSS [training: 0.015472581996583525 | validation: 0.02100022519758456]
	TIME [epoch: 72.3 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015546795899492101		[learning rate: 0.00026537]
	Learning Rate: 0.000265375
	LOSS [training: 0.015546795899492101 | validation: 0.02012791372235709]
	TIME [epoch: 72.2 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015676913355891987		[learning rate: 0.00026409]
	Learning Rate: 0.000264091
	LOSS [training: 0.015676913355891987 | validation: 0.020760169240603244]
	TIME [epoch: 72.3 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.016001089031566527		[learning rate: 0.00026281]
	Learning Rate: 0.000262814
	LOSS [training: 0.016001089031566527 | validation: 0.020264835844304833]
	TIME [epoch: 72.3 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014952410901678282		[learning rate: 0.00026154]
	Learning Rate: 0.000261543
	LOSS [training: 0.014952410901678282 | validation: 0.01975544561748162]
	TIME [epoch: 72.3 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015320915482332616		[learning rate: 0.00026028]
	Learning Rate: 0.000260279
	LOSS [training: 0.015320915482332616 | validation: 0.020511097809334914]
	TIME [epoch: 72.3 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01546699488768657		[learning rate: 0.00025902]
	Learning Rate: 0.00025902
	LOSS [training: 0.01546699488768657 | validation: 0.020794750886990204]
	TIME [epoch: 72.4 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015796817796156604		[learning rate: 0.00025777]
	Learning Rate: 0.000257767
	LOSS [training: 0.015796817796156604 | validation: 0.019838364161451405]
	TIME [epoch: 72.3 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015367808521721094		[learning rate: 0.00025652]
	Learning Rate: 0.000256521
	LOSS [training: 0.015367808521721094 | validation: 0.02055606275962865]
	TIME [epoch: 72.4 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015358774721865143		[learning rate: 0.00025528]
	Learning Rate: 0.00025528
	LOSS [training: 0.015358774721865143 | validation: 0.020237159348241537]
	TIME [epoch: 72.3 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015339820810888338		[learning rate: 0.00025405]
	Learning Rate: 0.000254046
	LOSS [training: 0.015339820810888338 | validation: 0.01951576060305629]
	TIME [epoch: 72.3 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015357128053480181		[learning rate: 0.00025282]
	Learning Rate: 0.000252817
	LOSS [training: 0.015357128053480181 | validation: 0.020629007621833024]
	TIME [epoch: 72.3 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01534482935977325		[learning rate: 0.00025159]
	Learning Rate: 0.000251595
	LOSS [training: 0.01534482935977325 | validation: 0.020375224046076643]
	TIME [epoch: 72.3 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01537483849628271		[learning rate: 0.00025038]
	Learning Rate: 0.000250378
	LOSS [training: 0.01537483849628271 | validation: 0.02011359487638475]
	TIME [epoch: 72.3 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01522702046345982		[learning rate: 0.00024917]
	Learning Rate: 0.000249167
	LOSS [training: 0.01522702046345982 | validation: 0.02154790835838428]
	TIME [epoch: 72.3 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01548341974290218		[learning rate: 0.00024796]
	Learning Rate: 0.000247962
	LOSS [training: 0.01548341974290218 | validation: 0.020368871478969996]
	TIME [epoch: 72.4 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015021651386956816		[learning rate: 0.00024676]
	Learning Rate: 0.000246763
	LOSS [training: 0.015021651386956816 | validation: 0.020295493060739137]
	TIME [epoch: 72.3 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01542274685275654		[learning rate: 0.00024557]
	Learning Rate: 0.00024557
	LOSS [training: 0.01542274685275654 | validation: 0.020198037317358124]
	TIME [epoch: 72.4 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015476627695649468		[learning rate: 0.00024438]
	Learning Rate: 0.000244382
	LOSS [training: 0.015476627695649468 | validation: 0.020588791142491496]
	TIME [epoch: 72.3 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01548957146496871		[learning rate: 0.0002432]
	Learning Rate: 0.000243201
	LOSS [training: 0.01548957146496871 | validation: 0.020486437856432404]
	TIME [epoch: 72.3 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01531039396249389		[learning rate: 0.00024202]
	Learning Rate: 0.000242025
	LOSS [training: 0.01531039396249389 | validation: 0.020450439708519935]
	TIME [epoch: 72.4 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014990993147970415		[learning rate: 0.00024085]
	Learning Rate: 0.000240854
	LOSS [training: 0.014990993147970415 | validation: 0.020659294680892358]
	TIME [epoch: 72.3 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015306151876270914		[learning rate: 0.00023969]
	Learning Rate: 0.00023969
	LOSS [training: 0.015306151876270914 | validation: 0.020208553760920792]
	TIME [epoch: 72.3 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01568928855916931		[learning rate: 0.00023853]
	Learning Rate: 0.00023853
	LOSS [training: 0.01568928855916931 | validation: 0.01944392175187864]
	TIME [epoch: 72.3 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015409752102530512		[learning rate: 0.00023738]
	Learning Rate: 0.000237377
	LOSS [training: 0.015409752102530512 | validation: 0.020259015636719686]
	TIME [epoch: 72.4 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015477637192329882		[learning rate: 0.00023623]
	Learning Rate: 0.000236229
	LOSS [training: 0.015477637192329882 | validation: 0.02068221613174393]
	TIME [epoch: 72.2 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015295708661020991		[learning rate: 0.00023509]
	Learning Rate: 0.000235087
	LOSS [training: 0.015295708661020991 | validation: 0.020441393429288194]
	TIME [epoch: 72.2 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0152372529026193		[learning rate: 0.00023395]
	Learning Rate: 0.00023395
	LOSS [training: 0.0152372529026193 | validation: 0.02051985300754582]
	TIME [epoch: 72.3 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015158661411697763		[learning rate: 0.00023282]
	Learning Rate: 0.000232818
	LOSS [training: 0.015158661411697763 | validation: 0.020732177359489207]
	TIME [epoch: 72.3 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015650132926585406		[learning rate: 0.00023169]
	Learning Rate: 0.000231693
	LOSS [training: 0.015650132926585406 | validation: 0.019612676664069687]
	TIME [epoch: 72.3 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015346196524250613		[learning rate: 0.00023057]
	Learning Rate: 0.000230572
	LOSS [training: 0.015346196524250613 | validation: 0.020504560261995416]
	TIME [epoch: 72.3 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015472938893510403		[learning rate: 0.00022946]
	Learning Rate: 0.000229457
	LOSS [training: 0.015472938893510403 | validation: 0.019611337581107655]
	TIME [epoch: 72.3 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01534143275382137		[learning rate: 0.00022835]
	Learning Rate: 0.000228348
	LOSS [training: 0.01534143275382137 | validation: 0.020541572840478806]
	TIME [epoch: 72.3 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.0153999862724604		[learning rate: 0.00022724]
	Learning Rate: 0.000227243
	LOSS [training: 0.0153999862724604 | validation: 0.020661504709259478]
	TIME [epoch: 72.3 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015358864244349311		[learning rate: 0.00022614]
	Learning Rate: 0.000226144
	LOSS [training: 0.015358864244349311 | validation: 0.020812484869907482]
	TIME [epoch: 72.3 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015512337340715719		[learning rate: 0.00022505]
	Learning Rate: 0.000225051
	LOSS [training: 0.015512337340715719 | validation: 0.01997802858379333]
	TIME [epoch: 72.3 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015463786825588105		[learning rate: 0.00022396]
	Learning Rate: 0.000223963
	LOSS [training: 0.015463786825588105 | validation: 0.020567213751634335]
	TIME [epoch: 72.3 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015283583381415422		[learning rate: 0.00022288]
	Learning Rate: 0.00022288
	LOSS [training: 0.015283583381415422 | validation: 0.019887884352112712]
	TIME [epoch: 72.3 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.01473065741424958		[learning rate: 0.0002218]
	Learning Rate: 0.000221802
	LOSS [training: 0.01473065741424958 | validation: 0.021453350054613667]
	TIME [epoch: 72.3 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015598163494771269		[learning rate: 0.00022073]
	Learning Rate: 0.000220729
	LOSS [training: 0.015598163494771269 | validation: 0.01999997900664396]
	TIME [epoch: 72.3 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015091558147498628		[learning rate: 0.00021966]
	Learning Rate: 0.000219662
	LOSS [training: 0.015091558147498628 | validation: 0.020217111232245618]
	TIME [epoch: 72.4 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014879433926435018		[learning rate: 0.0002186]
	Learning Rate: 0.000218599
	LOSS [training: 0.014879433926435018 | validation: 0.020344561956279074]
	TIME [epoch: 72.3 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015125470045308412		[learning rate: 0.00021754]
	Learning Rate: 0.000217542
	LOSS [training: 0.015125470045308412 | validation: 0.020243198929090923]
	TIME [epoch: 72.3 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015636219936748224		[learning rate: 0.00021649]
	Learning Rate: 0.00021649
	LOSS [training: 0.015636219936748224 | validation: 0.02026057718007739]
	TIME [epoch: 72.3 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015233618929610842		[learning rate: 0.00021544]
	Learning Rate: 0.000215443
	LOSS [training: 0.015233618929610842 | validation: 0.0198106410109806]
	TIME [epoch: 72.3 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015247808995141561		[learning rate: 0.0002144]
	Learning Rate: 0.000214402
	LOSS [training: 0.015247808995141561 | validation: 0.019313033152107178]
	TIME [epoch: 72.4 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015681618733344057		[learning rate: 0.00021336]
	Learning Rate: 0.000213365
	LOSS [training: 0.015681618733344057 | validation: 0.020122092578432626]
	TIME [epoch: 72.3 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015011696126757195		[learning rate: 0.00021233]
	Learning Rate: 0.000212333
	LOSS [training: 0.015011696126757195 | validation: 0.019750892729064818]
	TIME [epoch: 72.3 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015150661321147571		[learning rate: 0.00021131]
	Learning Rate: 0.000211306
	LOSS [training: 0.015150661321147571 | validation: 0.020310640735022936]
	TIME [epoch: 72.3 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.014988474261705137		[learning rate: 0.00021028]
	Learning Rate: 0.000210284
	LOSS [training: 0.014988474261705137 | validation: 0.020769868527388324]
	TIME [epoch: 72.3 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015026536517776549		[learning rate: 0.00020927]
	Learning Rate: 0.000209267
	LOSS [training: 0.015026536517776549 | validation: 0.020825760056018727]
	TIME [epoch: 72.2 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015551529832721627		[learning rate: 0.00020826]
	Learning Rate: 0.000208256
	LOSS [training: 0.015551529832721627 | validation: 0.020568614573363796]
	TIME [epoch: 72.4 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015524522330656305		[learning rate: 0.00020725]
	Learning Rate: 0.000207248
	LOSS [training: 0.015524522330656305 | validation: 0.020829258146745105]
	TIME [epoch: 72.2 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 3/3] avg loss: 0.015238303720036766		[learning rate: 0.00020625]
	Learning Rate: 0.000206246
	LOSS [training: 0.015238303720036766 | validation: 0.019955561157185425]
	TIME [epoch: 72.2 sec]
	Saving model to: out/model_training/model_facs_dec1_v4_argset1_20241208_151949/states/model_facs_dec1_v4_argset1_851.pth
Halted early. No improvement in validation loss for 200 epochs.
Finished training in 23555.108 seconds.
