Args:
Namespace(name='model_phiq_1a_v_klv1', outdir='out/model_training/model_phiq_1a_v_klv1', training_data='data/training_data/basic/data_phiq_1a/training', validation_data='data/training_data/basic/data_phiq_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[100, 250, 500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.01, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3377106652

Training model...

Saving initial model state to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.32195544816153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.32195544816153 | validation: 8.081173546536746]
	TIME [epoch: 423 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.685575155916521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.685575155916521 | validation: 7.4215915313945615]
	TIME [epoch: 6.31 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.475296004383546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.475296004383546 | validation: 7.383783270751895]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.2825012825204505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2825012825204505 | validation: 7.258076182982167]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.1593971763081505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1593971763081505 | validation: 7.167655749258595]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.047098537607072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.047098537607072 | validation: 7.001965300516945]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.8989873679905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8989873679905 | validation: 7.248438310630538]
	TIME [epoch: 6.26 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.304035849688925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.304035849688925 | validation: 7.514692840678009]
	TIME [epoch: 6.25 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.098730878571212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.098730878571212 | validation: 7.173029379067473]
	TIME [epoch: 6.26 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.849739252985637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.849739252985637 | validation: 7.2003598513653735]
	TIME [epoch: 6.26 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.836761724737215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.836761724737215 | validation: 7.158241464538922]
	TIME [epoch: 6.26 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.822887435320622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.822887435320622 | validation: 7.311106971324483]
	TIME [epoch: 6.26 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.913818503380156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.913818503380156 | validation: 7.91881397175251]
	TIME [epoch: 6.26 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.954941499394113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.954941499394113 | validation: 7.50184487733625]
	TIME [epoch: 6.26 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.034888676780594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.034888676780594 | validation: 6.912401551637947]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.637424445393716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.637424445393716 | validation: 6.805148593969788]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_16.pth
	Model improved!!!
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.511219884182795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.511219884182795 | validation: 6.5014589927498285]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.3417001027981605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3417001027981605 | validation: 6.50163504885211]
	TIME [epoch: 6.27 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.217011850837168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.217011850837168 | validation: 6.412161697761272]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.127858208542564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.127858208542564 | validation: 6.224307146627257]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.925793806636942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.925793806636942 | validation: 6.240172107984398]
	TIME [epoch: 6.27 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.918536236601529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.918536236601529 | validation: 5.954863448209469]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.786873383499487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.786873383499487 | validation: 6.170556285478529]
	TIME [epoch: 6.26 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.52157420289483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.52157420289483 | validation: 6.159793756546071]
	TIME [epoch: 6.25 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.576751530412282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.576751530412282 | validation: 6.216697597712908]
	TIME [epoch: 6.25 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.41018465441339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.41018465441339 | validation: 5.6137492233339295]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.226401860061232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.226401860061232 | validation: 5.471547277595279]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.997886822636954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.997886822636954 | validation: 5.42077419426972]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.870812321175128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.870812321175128 | validation: 5.165280436466256]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.731061220445112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.731061220445112 | validation: 4.840709581184134]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.611117246673501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.611117246673501 | validation: 5.342227856550565]
	TIME [epoch: 6.26 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.606835275655326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.606835275655326 | validation: 4.7111023953254225]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.407077359966685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.407077359966685 | validation: 4.851226102567347]
	TIME [epoch: 6.26 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.838960986107669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.838960986107669 | validation: 5.397893380508663]
	TIME [epoch: 6.26 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.70668429503526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.70668429503526 | validation: 4.820400116532515]
	TIME [epoch: 6.26 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.760522132403304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.760522132403304 | validation: 4.558892194529763]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.206033018091447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.206033018091447 | validation: 4.1875669023871005]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.060785339112304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.060785339112304 | validation: 4.328574810675367]
	TIME [epoch: 6.26 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.146465814684909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.146465814684909 | validation: 4.858477962171263]
	TIME [epoch: 6.26 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.220202019301202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220202019301202 | validation: 3.970470021838623]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_40.pth
	Model improved!!!
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9042583927483836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9042583927483836 | validation: 3.899886688872577]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_41.pth
	Model improved!!!
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.778260322122021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.778260322122021 | validation: 3.690117321231374]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_42.pth
	Model improved!!!
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.6535132481451136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6535132481451136 | validation: 4.083174501003896]
	TIME [epoch: 6.25 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.019019909402617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.019019909402617 | validation: 3.6646496979669543]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.6543792609960284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6543792609960284 | validation: 3.623408696667645]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.687198328393772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.687198328393772 | validation: 3.5021882627123073]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.5082785876563882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5082785876563882 | validation: 3.728577281568927]
	TIME [epoch: 6.26 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.585861271106622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.585861271106622 | validation: 3.3127545680631645]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.537260488785368		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.537260488785368 | validation: 3.235817942105797]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3858402660330063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3858402660330063 | validation: 3.3194269807613477]
	TIME [epoch: 6.26 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3900874840286868		[learning rate: 0.0099456]
	Learning Rate: 0.00994561
	LOSS [training: 3.3900874840286868 | validation: 3.186961167179672]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.32680557135742		[learning rate: 0.0098736]
	Learning Rate: 0.00987356
	LOSS [training: 3.32680557135742 | validation: 3.0615788615428663]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.452754626876908		[learning rate: 0.009802]
	Learning Rate: 0.00980202
	LOSS [training: 3.452754626876908 | validation: 3.4362416157892635]
	TIME [epoch: 6.26 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.410602316804406		[learning rate: 0.009731]
	Learning Rate: 0.00973101
	LOSS [training: 3.410602316804406 | validation: 3.3086086701668496]
	TIME [epoch: 6.25 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.286269897765864		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.286269897765864 | validation: 3.053068192223262]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1509841267709517		[learning rate: 0.0095905]
	Learning Rate: 0.00959052
	LOSS [training: 3.1509841267709517 | validation: 3.0619687518620555]
	TIME [epoch: 6.24 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1871693461673987		[learning rate: 0.009521]
	Learning Rate: 0.00952104
	LOSS [training: 3.1871693461673987 | validation: 3.221612237755771]
	TIME [epoch: 6.25 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.4562231595357686		[learning rate: 0.0094521]
	Learning Rate: 0.00945206
	LOSS [training: 3.4562231595357686 | validation: 2.994805014833887]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.494805688470025		[learning rate: 0.0093836]
	Learning Rate: 0.00938358
	LOSS [training: 3.494805688470025 | validation: 4.18600131736711]
	TIME [epoch: 6.25 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.445845403247512		[learning rate: 0.0093156]
	Learning Rate: 0.00931559
	LOSS [training: 3.445845403247512 | validation: 3.1011588177907807]
	TIME [epoch: 6.25 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.271250500635883		[learning rate: 0.0092481]
	Learning Rate: 0.0092481
	LOSS [training: 3.271250500635883 | validation: 3.0714014147172803]
	TIME [epoch: 6.26 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.128239598408137		[learning rate: 0.0091811]
	Learning Rate: 0.0091811
	LOSS [training: 3.128239598408137 | validation: 3.292277347533996]
	TIME [epoch: 6.26 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1405149794049034		[learning rate: 0.0091146]
	Learning Rate: 0.00911458
	LOSS [training: 3.1405149794049034 | validation: 2.9321174710562294]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_63.pth
	Model improved!!!
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.052342351198915		[learning rate: 0.0090485]
	Learning Rate: 0.00904855
	LOSS [training: 3.052342351198915 | validation: 2.9659253821450116]
	TIME [epoch: 6.25 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0638139123613044		[learning rate: 0.008983]
	Learning Rate: 0.00898299
	LOSS [training: 3.0638139123613044 | validation: 3.1192155782113673]
	TIME [epoch: 6.25 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0089280910310947		[learning rate: 0.0089179]
	Learning Rate: 0.00891791
	LOSS [training: 3.0089280910310947 | validation: 2.800802657258812]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8227637902772327		[learning rate: 0.0088533]
	Learning Rate: 0.0088533
	LOSS [training: 2.8227637902772327 | validation: 2.9864245962115845]
	TIME [epoch: 6.26 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.271850130886762		[learning rate: 0.0087892]
	Learning Rate: 0.00878916
	LOSS [training: 4.271850130886762 | validation: 5.848421150109934]
	TIME [epoch: 6.26 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.079359044071565		[learning rate: 0.0087255]
	Learning Rate: 0.00872548
	LOSS [training: 5.079359044071565 | validation: 5.213925685240306]
	TIME [epoch: 6.24 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.304052092278355		[learning rate: 0.0086623]
	Learning Rate: 0.00866227
	LOSS [training: 5.304052092278355 | validation: 4.239596334644002]
	TIME [epoch: 6.25 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.734173924631104		[learning rate: 0.0085995]
	Learning Rate: 0.00859951
	LOSS [training: 4.734173924631104 | validation: 4.1589406018339075]
	TIME [epoch: 6.24 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.098693833941309		[learning rate: 0.0085372]
	Learning Rate: 0.00853721
	LOSS [training: 4.098693833941309 | validation: 3.532447263338055]
	TIME [epoch: 6.24 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.85137394716676		[learning rate: 0.0084754]
	Learning Rate: 0.00847535
	LOSS [training: 3.85137394716676 | validation: 3.8902310635538857]
	TIME [epoch: 6.25 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8110356305382727		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.8110356305382727 | validation: 3.58405087256012]
	TIME [epoch: 6.25 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.619330861531374		[learning rate: 0.008353]
	Learning Rate: 0.00835299
	LOSS [training: 3.619330861531374 | validation: 3.514868747362102]
	TIME [epoch: 6.25 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.616753028004125		[learning rate: 0.0082925]
	Learning Rate: 0.00829248
	LOSS [training: 3.616753028004125 | validation: 3.613663504317892]
	TIME [epoch: 6.24 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.489693525209563		[learning rate: 0.0082324]
	Learning Rate: 0.0082324
	LOSS [training: 3.489693525209563 | validation: 3.311316572868548]
	TIME [epoch: 6.25 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3418585711302713		[learning rate: 0.0081728]
	Learning Rate: 0.00817275
	LOSS [training: 3.3418585711302713 | validation: 3.1714704966449907]
	TIME [epoch: 6.25 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.2410549357977847		[learning rate: 0.0081135]
	Learning Rate: 0.00811354
	LOSS [training: 3.2410549357977847 | validation: 3.088570751768258]
	TIME [epoch: 6.25 sec]
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1635584163018		[learning rate: 0.0080548]
	Learning Rate: 0.00805476
	LOSS [training: 3.1635584163018 | validation: 3.0768107710107753]
	TIME [epoch: 6.24 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.110035624201382		[learning rate: 0.0079964]
	Learning Rate: 0.0079964
	LOSS [training: 3.110035624201382 | validation: 2.9455641733008076]
	TIME [epoch: 6.25 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.058631788291674		[learning rate: 0.0079385]
	Learning Rate: 0.00793847
	LOSS [training: 3.058631788291674 | validation: 2.9132501915677986]
	TIME [epoch: 6.24 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9916933988027186		[learning rate: 0.007881]
	Learning Rate: 0.00788096
	LOSS [training: 2.9916933988027186 | validation: 2.9145162218702914]
	TIME [epoch: 6.25 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.6833589518910714		[learning rate: 0.0078239]
	Learning Rate: 0.00782386
	LOSS [training: 3.6833589518910714 | validation: 3.374101126875148]
	TIME [epoch: 6.26 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.668507298618722		[learning rate: 0.0077672]
	Learning Rate: 0.00776718
	LOSS [training: 3.668507298618722 | validation: 5.037093238297007]
	TIME [epoch: 6.26 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.259837490246232		[learning rate: 0.0077109]
	Learning Rate: 0.0077109
	LOSS [training: 5.259837490246232 | validation: 4.618542669319156]
	TIME [epoch: 6.25 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.306629292755999		[learning rate: 0.007655]
	Learning Rate: 0.00765504
	LOSS [training: 4.306629292755999 | validation: 3.2333601433155152]
	TIME [epoch: 6.25 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.5044882706506204		[learning rate: 0.0075996]
	Learning Rate: 0.00759958
	LOSS [training: 3.5044882706506204 | validation: 3.320416842532534]
	TIME [epoch: 6.25 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3854884673443637		[learning rate: 0.0075445]
	Learning Rate: 0.00754452
	LOSS [training: 3.3854884673443637 | validation: 3.1876447649437036]
	TIME [epoch: 6.24 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.211169613620757		[learning rate: 0.0074899]
	Learning Rate: 0.00748986
	LOSS [training: 3.211169613620757 | validation: 3.0031369816962474]
	TIME [epoch: 6.25 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1283166856049403		[learning rate: 0.0074356]
	Learning Rate: 0.0074356
	LOSS [training: 3.1283166856049403 | validation: 3.0580250946258456]
	TIME [epoch: 6.25 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0375732333725294		[learning rate: 0.0073817]
	Learning Rate: 0.00738173
	LOSS [training: 3.0375732333725294 | validation: 2.875573543420765]
	TIME [epoch: 6.26 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.974406605641399		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 2.974406605641399 | validation: 3.195626344794186]
	TIME [epoch: 6.26 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.114722523871472		[learning rate: 0.0072752]
	Learning Rate: 0.00727515
	LOSS [training: 3.114722523871472 | validation: 2.843478118938692]
	TIME [epoch: 6.26 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8772807002894267		[learning rate: 0.0072224]
	Learning Rate: 0.00722244
	LOSS [training: 2.8772807002894267 | validation: 2.7755841517570925]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8501706451250235		[learning rate: 0.0071701]
	Learning Rate: 0.00717012
	LOSS [training: 2.8501706451250235 | validation: 2.914558007942163]
	TIME [epoch: 6.25 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8952961758611826		[learning rate: 0.0071182]
	Learning Rate: 0.00711817
	LOSS [training: 2.8952961758611826 | validation: 2.7669136277214825]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.75597697583673		[learning rate: 0.0070666]
	Learning Rate: 0.0070666
	LOSS [training: 2.75597697583673 | validation: 2.8796330812235795]
	TIME [epoch: 6.26 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.720171428555827		[learning rate: 0.0070154]
	Learning Rate: 0.0070154
	LOSS [training: 2.720171428555827 | validation: 2.667623498082034]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6737085066398816		[learning rate: 0.0069646]
	Learning Rate: 0.00696458
	LOSS [training: 2.6737085066398816 | validation: 2.5852516989287633]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_100.pth
	Model improved!!!
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9323655393916823		[learning rate: 0.0069141]
	Learning Rate: 0.00691412
	LOSS [training: 2.9323655393916823 | validation: 2.711919508926785]
	TIME [epoch: 444 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.70287765332301		[learning rate: 0.006864]
	Learning Rate: 0.00686403
	LOSS [training: 2.70287765332301 | validation: 2.977630648762954]
	TIME [epoch: 12.4 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.018064265311977		[learning rate: 0.0068143]
	Learning Rate: 0.0068143
	LOSS [training: 3.018064265311977 | validation: 3.1026148999971266]
	TIME [epoch: 12.3 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.84954006236447		[learning rate: 0.0067649]
	Learning Rate: 0.00676493
	LOSS [training: 2.84954006236447 | validation: 2.4498243851755896]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4625672536195458		[learning rate: 0.0067159]
	Learning Rate: 0.00671592
	LOSS [training: 2.4625672536195458 | validation: 2.6283224502297693]
	TIME [epoch: 12.3 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4982664430644803		[learning rate: 0.0066673]
	Learning Rate: 0.00666726
	LOSS [training: 2.4982664430644803 | validation: 2.3846601515632604]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3435759797675546		[learning rate: 0.006619]
	Learning Rate: 0.00661896
	LOSS [training: 2.3435759797675546 | validation: 2.5286713563655816]
	TIME [epoch: 12.3 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5596610103426647		[learning rate: 0.006571]
	Learning Rate: 0.006571
	LOSS [training: 2.5596610103426647 | validation: 2.5338702662261134]
	TIME [epoch: 12.3 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4784165864060057		[learning rate: 0.0065234]
	Learning Rate: 0.00652339
	LOSS [training: 2.4784165864060057 | validation: 2.9835003557423505]
	TIME [epoch: 12.3 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.018995593597091		[learning rate: 0.0064761]
	Learning Rate: 0.00647613
	LOSS [training: 3.018995593597091 | validation: 2.826449606694937]
	TIME [epoch: 12.3 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.71752756352344		[learning rate: 0.0064292]
	Learning Rate: 0.00642921
	LOSS [training: 2.71752756352344 | validation: 3.175179733561679]
	TIME [epoch: 12.3 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.023850069731927		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 3.023850069731927 | validation: 3.2564559822864236]
	TIME [epoch: 12.3 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.895821175621035		[learning rate: 0.0063364]
	Learning Rate: 0.00633639
	LOSS [training: 2.895821175621035 | validation: 2.766439427795057]
	TIME [epoch: 12.3 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6806591747388335		[learning rate: 0.0062905]
	Learning Rate: 0.00629049
	LOSS [training: 2.6806591747388335 | validation: 2.5688231003857895]
	TIME [epoch: 12.3 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4390145988383374		[learning rate: 0.0062449]
	Learning Rate: 0.00624491
	LOSS [training: 2.4390145988383374 | validation: 2.4047933967092563]
	TIME [epoch: 12.3 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.586360312293721		[learning rate: 0.0061997]
	Learning Rate: 0.00619967
	LOSS [training: 2.586360312293721 | validation: 3.094101883378171]
	TIME [epoch: 12.3 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.836150739427376		[learning rate: 0.0061548]
	Learning Rate: 0.00615475
	LOSS [training: 2.836150739427376 | validation: 3.0379853680792985]
	TIME [epoch: 12.3 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.4711342465889787		[learning rate: 0.0061102]
	Learning Rate: 0.00611016
	LOSS [training: 3.4711342465889787 | validation: 3.0429191605883856]
	TIME [epoch: 12.3 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.004282389396961		[learning rate: 0.0060659]
	Learning Rate: 0.00606589
	LOSS [training: 3.004282389396961 | validation: 2.6645388775343255]
	TIME [epoch: 12.3 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5205454293967957		[learning rate: 0.0060219]
	Learning Rate: 0.00602195
	LOSS [training: 2.5205454293967957 | validation: 2.4109071153959523]
	TIME [epoch: 12.3 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.374877109919453		[learning rate: 0.0059783]
	Learning Rate: 0.00597832
	LOSS [training: 2.374877109919453 | validation: 2.4058543363138103]
	TIME [epoch: 12.3 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.319001139749797		[learning rate: 0.005935]
	Learning Rate: 0.005935
	LOSS [training: 2.319001139749797 | validation: 2.2980771401239135]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2756547042298703		[learning rate: 0.005892]
	Learning Rate: 0.00589201
	LOSS [training: 2.2756547042298703 | validation: 2.24631849061214]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_123.pth
	Model improved!!!
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3010392142854537		[learning rate: 0.0058493]
	Learning Rate: 0.00584932
	LOSS [training: 2.3010392142854537 | validation: 3.320141675845157]
	TIME [epoch: 12.3 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0919651139405513		[learning rate: 0.0058069]
	Learning Rate: 0.00580694
	LOSS [training: 3.0919651139405513 | validation: 2.4665168382834928]
	TIME [epoch: 12.3 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.339371793169659		[learning rate: 0.0057649]
	Learning Rate: 0.00576487
	LOSS [training: 2.339371793169659 | validation: 2.345402485777498]
	TIME [epoch: 12.3 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2098988585571067		[learning rate: 0.0057231]
	Learning Rate: 0.0057231
	LOSS [training: 2.2098988585571067 | validation: 2.2163376006252014]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.115680453841237		[learning rate: 0.0056816]
	Learning Rate: 0.00568164
	LOSS [training: 2.115680453841237 | validation: 2.240930773837574]
	TIME [epoch: 12.3 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0929588299003767		[learning rate: 0.0056405]
	Learning Rate: 0.00564048
	LOSS [training: 2.0929588299003767 | validation: 2.2717111538809283]
	TIME [epoch: 12.3 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0393558848296447		[learning rate: 0.0055996]
	Learning Rate: 0.00559961
	LOSS [training: 2.0393558848296447 | validation: 2.2595517095665594]
	TIME [epoch: 12.3 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4487465853944275		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.4487465853944275 | validation: 2.2149402874672797]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_131.pth
	Model improved!!!
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.437100747431667		[learning rate: 0.0055188]
	Learning Rate: 0.00551877
	LOSS [training: 2.437100747431667 | validation: 2.973688064706007]
	TIME [epoch: 12.3 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.684345970268576		[learning rate: 0.0054788]
	Learning Rate: 0.00547878
	LOSS [training: 2.684345970268576 | validation: 2.9624046028830913]
	TIME [epoch: 12.3 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.493131163019903		[learning rate: 0.0054391]
	Learning Rate: 0.00543909
	LOSS [training: 2.493131163019903 | validation: 2.530162867888148]
	TIME [epoch: 12.3 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.7147087038078745		[learning rate: 0.0053997]
	Learning Rate: 0.00539968
	LOSS [training: 2.7147087038078745 | validation: 3.7290168191835744]
	TIME [epoch: 12.3 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.7065541193720697		[learning rate: 0.0053606]
	Learning Rate: 0.00536056
	LOSS [training: 2.7065541193720697 | validation: 2.4118465718672537]
	TIME [epoch: 12.3 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5427632732567345		[learning rate: 0.0053217]
	Learning Rate: 0.00532173
	LOSS [training: 2.5427632732567345 | validation: 2.8994896682537608]
	TIME [epoch: 12.3 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6136590468920833		[learning rate: 0.0052832]
	Learning Rate: 0.00528317
	LOSS [training: 2.6136590468920833 | validation: 2.5757906794834953]
	TIME [epoch: 12.3 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1445088144368176		[learning rate: 0.0052449]
	Learning Rate: 0.0052449
	LOSS [training: 2.1445088144368176 | validation: 2.8036932056562422]
	TIME [epoch: 12.3 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3100155093058388		[learning rate: 0.0052069]
	Learning Rate: 0.0052069
	LOSS [training: 2.3100155093058388 | validation: 2.1220384074954204]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_140.pth
	Model improved!!!
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1409847385775005		[learning rate: 0.0051692]
	Learning Rate: 0.00516917
	LOSS [training: 2.1409847385775005 | validation: 2.2140173346804826]
	TIME [epoch: 12.3 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.196264107499357		[learning rate: 0.0051317]
	Learning Rate: 0.00513172
	LOSS [training: 2.196264107499357 | validation: 2.296692265068687]
	TIME [epoch: 12.3 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0947437533408997		[learning rate: 0.0050945]
	Learning Rate: 0.00509454
	LOSS [training: 2.0947437533408997 | validation: 2.4015692191988594]
	TIME [epoch: 12.3 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.056917504008225		[learning rate: 0.0050576]
	Learning Rate: 0.00505763
	LOSS [training: 2.056917504008225 | validation: 2.644726849796258]
	TIME [epoch: 12.3 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.777006494125088		[learning rate: 0.005021]
	Learning Rate: 0.00502099
	LOSS [training: 2.777006494125088 | validation: 4.266726578166141]
	TIME [epoch: 12.3 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.4294727064545123		[learning rate: 0.0049846]
	Learning Rate: 0.00498461
	LOSS [training: 3.4294727064545123 | validation: 4.424072256093147]
	TIME [epoch: 12.3 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.532796312287714		[learning rate: 0.0049485]
	Learning Rate: 0.0049485
	LOSS [training: 3.532796312287714 | validation: 4.5272875264378785]
	TIME [epoch: 12.3 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.794939558257372		[learning rate: 0.0049126]
	Learning Rate: 0.00491265
	LOSS [training: 3.794939558257372 | validation: 4.567654216348991]
	TIME [epoch: 12.3 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.357273127829376		[learning rate: 0.0048771]
	Learning Rate: 0.00487706
	LOSS [training: 3.357273127829376 | validation: 3.5011255888474913]
	TIME [epoch: 12.3 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8878716995411553		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 2.8878716995411553 | validation: 3.335876033503855]
	TIME [epoch: 12.3 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.894018239754335		[learning rate: 0.0048066]
	Learning Rate: 0.00480665
	LOSS [training: 2.894018239754335 | validation: 4.184807825972716]
	TIME [epoch: 12.3 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.388120759166813		[learning rate: 0.0047718]
	Learning Rate: 0.00477182
	LOSS [training: 4.388120759166813 | validation: 5.605915108872365]
	TIME [epoch: 12.3 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.585027873871958		[learning rate: 0.0047373]
	Learning Rate: 0.00473725
	LOSS [training: 5.585027873871958 | validation: 5.560425300312389]
	TIME [epoch: 12.3 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.240404548458709		[learning rate: 0.0047029]
	Learning Rate: 0.00470293
	LOSS [training: 5.240404548458709 | validation: 5.112941604245753]
	TIME [epoch: 12.3 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.056998147516518		[learning rate: 0.0046689]
	Learning Rate: 0.00466886
	LOSS [training: 5.056998147516518 | validation: 4.616497288973247]
	TIME [epoch: 12.3 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.7819156739892876		[learning rate: 0.004635]
	Learning Rate: 0.00463503
	LOSS [training: 3.7819156739892876 | validation: 3.000324229950814]
	TIME [epoch: 12.3 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.723527870841825		[learning rate: 0.0046015]
	Learning Rate: 0.00460145
	LOSS [training: 2.723527870841825 | validation: 2.6071511812576813]
	TIME [epoch: 12.3 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4950681285429326		[learning rate: 0.0045681]
	Learning Rate: 0.00456811
	LOSS [training: 2.4950681285429326 | validation: 2.519294090642436]
	TIME [epoch: 12.3 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.387153586607837		[learning rate: 0.004535]
	Learning Rate: 0.00453502
	LOSS [training: 2.387153586607837 | validation: 2.406982676314833]
	TIME [epoch: 12.3 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.328434227484826		[learning rate: 0.0045022]
	Learning Rate: 0.00450216
	LOSS [training: 2.328434227484826 | validation: 2.2880528122821575]
	TIME [epoch: 12.3 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.254686622800029		[learning rate: 0.0044695]
	Learning Rate: 0.00446954
	LOSS [training: 2.254686622800029 | validation: 2.295620174705994]
	TIME [epoch: 12.3 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2839266745828826		[learning rate: 0.0044372]
	Learning Rate: 0.00443716
	LOSS [training: 2.2839266745828826 | validation: 2.5319106020475557]
	TIME [epoch: 12.3 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.309162117449735		[learning rate: 0.004405]
	Learning Rate: 0.00440502
	LOSS [training: 2.309162117449735 | validation: 2.4204886076474663]
	TIME [epoch: 12.3 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2081319034825015		[learning rate: 0.0043731]
	Learning Rate: 0.0043731
	LOSS [training: 2.2081319034825015 | validation: 2.156392220804313]
	TIME [epoch: 12.3 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1789940131269354		[learning rate: 0.0043414]
	Learning Rate: 0.00434142
	LOSS [training: 2.1789940131269354 | validation: 2.2414374849635594]
	TIME [epoch: 12.3 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.087102305976504		[learning rate: 0.00431]
	Learning Rate: 0.00430996
	LOSS [training: 2.087102305976504 | validation: 2.220112462449489]
	TIME [epoch: 12.3 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.049409292693965		[learning rate: 0.0042787]
	Learning Rate: 0.00427874
	LOSS [training: 2.049409292693965 | validation: 2.1879439091904382]
	TIME [epoch: 12.3 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0609444038496454		[learning rate: 0.0042477]
	Learning Rate: 0.00424774
	LOSS [training: 2.0609444038496454 | validation: 2.262331941969368]
	TIME [epoch: 12.3 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.958632972133923		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.958632972133923 | validation: 2.0385458017919236]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_169.pth
	Model improved!!!
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.453938587356052		[learning rate: 0.0041864]
	Learning Rate: 0.00418641
	LOSS [training: 2.453938587356052 | validation: 3.9760955310310546]
	TIME [epoch: 12.3 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0344604842023672		[learning rate: 0.0041561]
	Learning Rate: 0.00415608
	LOSS [training: 3.0344604842023672 | validation: 3.198942580842723]
	TIME [epoch: 12.3 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9688110485198553		[learning rate: 0.004126]
	Learning Rate: 0.00412597
	LOSS [training: 2.9688110485198553 | validation: 4.119733295854829]
	TIME [epoch: 12.3 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.205995146407375		[learning rate: 0.0040961]
	Learning Rate: 0.00409608
	LOSS [training: 4.205995146407375 | validation: 4.846957824407349]
	TIME [epoch: 12.3 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.9447155477717684		[learning rate: 0.0040664]
	Learning Rate: 0.0040664
	LOSS [training: 3.9447155477717684 | validation: 3.1196852583907866]
	TIME [epoch: 12.3 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9484328199463805		[learning rate: 0.0040369]
	Learning Rate: 0.00403694
	LOSS [training: 2.9484328199463805 | validation: 2.871453631408508]
	TIME [epoch: 12.3 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.662920055656323		[learning rate: 0.0040077]
	Learning Rate: 0.0040077
	LOSS [training: 2.662920055656323 | validation: 2.4473164496717517]
	TIME [epoch: 12.3 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1673274843533075		[learning rate: 0.0039787]
	Learning Rate: 0.00397866
	LOSS [training: 2.1673274843533075 | validation: 2.1605670777319195]
	TIME [epoch: 12.3 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.034618225953988		[learning rate: 0.0039498]
	Learning Rate: 0.00394983
	LOSS [training: 2.034618225953988 | validation: 2.336835072751427]
	TIME [epoch: 12.3 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1325819268257526		[learning rate: 0.0039212]
	Learning Rate: 0.00392122
	LOSS [training: 2.1325819268257526 | validation: 2.2155297231553512]
	TIME [epoch: 12.3 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.251670223706298		[learning rate: 0.0038928]
	Learning Rate: 0.00389281
	LOSS [training: 2.251670223706298 | validation: 2.8184530894890876]
	TIME [epoch: 12.3 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.369629383120417		[learning rate: 0.0038646]
	Learning Rate: 0.00386461
	LOSS [training: 2.369629383120417 | validation: 2.547452579483343]
	TIME [epoch: 12.3 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.398502979009913		[learning rate: 0.0038366]
	Learning Rate: 0.00383661
	LOSS [training: 2.398502979009913 | validation: 2.658008423433277]
	TIME [epoch: 12.3 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3167503863818792		[learning rate: 0.0038088]
	Learning Rate: 0.00380881
	LOSS [training: 2.3167503863818792 | validation: 2.36143700102063]
	TIME [epoch: 12.3 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0410754646152824		[learning rate: 0.0037812]
	Learning Rate: 0.00378122
	LOSS [training: 2.0410754646152824 | validation: 2.1177377438378087]
	TIME [epoch: 12.3 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0064721576451627		[learning rate: 0.0037538]
	Learning Rate: 0.00375382
	LOSS [training: 2.0064721576451627 | validation: 2.093677217980438]
	TIME [epoch: 12.3 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8953864631109159		[learning rate: 0.0037266]
	Learning Rate: 0.00372663
	LOSS [training: 1.8953864631109159 | validation: 1.9556041347109328]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_186.pth
	Model improved!!!
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8778193941807286		[learning rate: 0.0036996]
	Learning Rate: 0.00369963
	LOSS [training: 1.8778193941807286 | validation: 1.9423858129326543]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_187.pth
	Model improved!!!
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.140878274079314		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.140878274079314 | validation: 3.042421389519511]
	TIME [epoch: 12.3 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6405585772113094		[learning rate: 0.0036462]
	Learning Rate: 0.00364621
	LOSS [training: 2.6405585772113094 | validation: 3.022320195078124]
	TIME [epoch: 12.3 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4199500555516007		[learning rate: 0.0036198]
	Learning Rate: 0.0036198
	LOSS [training: 2.4199500555516007 | validation: 3.3023751895309617]
	TIME [epoch: 12.3 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.91648006449582		[learning rate: 0.0035936]
	Learning Rate: 0.00359357
	LOSS [training: 2.91648006449582 | validation: 2.8621040055414957]
	TIME [epoch: 12.3 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4463618930459217		[learning rate: 0.0035675]
	Learning Rate: 0.00356754
	LOSS [training: 2.4463618930459217 | validation: 2.5507758525385293]
	TIME [epoch: 12.3 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0728586269291007		[learning rate: 0.0035417]
	Learning Rate: 0.00354169
	LOSS [training: 2.0728586269291007 | validation: 2.224058703571857]
	TIME [epoch: 12.3 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9847409904562734		[learning rate: 0.003516]
	Learning Rate: 0.00351603
	LOSS [training: 1.9847409904562734 | validation: 1.9953950919448749]
	TIME [epoch: 12.3 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8946978841308115		[learning rate: 0.0034906]
	Learning Rate: 0.00349056
	LOSS [training: 1.8946978841308115 | validation: 2.0206314843151505]
	TIME [epoch: 12.3 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.92042420398699		[learning rate: 0.0034653]
	Learning Rate: 0.00346527
	LOSS [training: 1.92042420398699 | validation: 2.0894768777610633]
	TIME [epoch: 12.3 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.04057310154715		[learning rate: 0.0034402]
	Learning Rate: 0.00344016
	LOSS [training: 2.04057310154715 | validation: 2.485958498673069]
	TIME [epoch: 12.3 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9721520278237954		[learning rate: 0.0034152]
	Learning Rate: 0.00341524
	LOSS [training: 1.9721520278237954 | validation: 2.1837792304615453]
	TIME [epoch: 12.3 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8380915134551743		[learning rate: 0.0033905]
	Learning Rate: 0.0033905
	LOSS [training: 1.8380915134551743 | validation: 2.1080030849312994]
	TIME [epoch: 12.3 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9160778159256084		[learning rate: 0.0033659]
	Learning Rate: 0.00336593
	LOSS [training: 1.9160778159256084 | validation: 2.1533665501027044]
	TIME [epoch: 12.3 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.810890411021953		[learning rate: 0.0033415]
	Learning Rate: 0.00334155
	LOSS [training: 1.810890411021953 | validation: 1.899419741014166]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_201.pth
	Model improved!!!
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.828102815211759		[learning rate: 0.0033173]
	Learning Rate: 0.00331734
	LOSS [training: 1.828102815211759 | validation: 2.093262805073313]
	TIME [epoch: 12.3 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.060759546381351		[learning rate: 0.0032933]
	Learning Rate: 0.0032933
	LOSS [training: 2.060759546381351 | validation: 2.1375319597083484]
	TIME [epoch: 12.3 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9440080409506377		[learning rate: 0.0032694]
	Learning Rate: 0.00326944
	LOSS [training: 1.9440080409506377 | validation: 2.136228650360497]
	TIME [epoch: 12.3 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.818611599205101		[learning rate: 0.0032458]
	Learning Rate: 0.00324576
	LOSS [training: 1.818611599205101 | validation: 2.18172345402011]
	TIME [epoch: 12.3 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8934383451918202		[learning rate: 0.0032222]
	Learning Rate: 0.00322224
	LOSS [training: 1.8934383451918202 | validation: 2.1952260468454052]
	TIME [epoch: 12.3 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7767758287067612		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.7767758287067612 | validation: 1.9077132555726302]
	TIME [epoch: 12.3 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.715225051880808		[learning rate: 0.0031757]
	Learning Rate: 0.00317572
	LOSS [training: 1.715225051880808 | validation: 2.25637094044641]
	TIME [epoch: 12.3 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.021283338570414		[learning rate: 0.0031527]
	Learning Rate: 0.00315271
	LOSS [training: 2.021283338570414 | validation: 2.7622196837276016]
	TIME [epoch: 12.3 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4010114801503146		[learning rate: 0.0031299]
	Learning Rate: 0.00312987
	LOSS [training: 2.4010114801503146 | validation: 2.192936336105195]
	TIME [epoch: 12.3 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8543312246426915		[learning rate: 0.0031072]
	Learning Rate: 0.00310719
	LOSS [training: 1.8543312246426915 | validation: 2.2092003953314516]
	TIME [epoch: 12.3 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8879238009864898		[learning rate: 0.0030847]
	Learning Rate: 0.00308468
	LOSS [training: 1.8879238009864898 | validation: 2.267263790913174]
	TIME [epoch: 12.3 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8046597884059379		[learning rate: 0.0030623]
	Learning Rate: 0.00306233
	LOSS [training: 1.8046597884059379 | validation: 2.0795360136933496]
	TIME [epoch: 12.3 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8214760363638702		[learning rate: 0.0030401]
	Learning Rate: 0.00304015
	LOSS [training: 1.8214760363638702 | validation: 2.0779139661524972]
	TIME [epoch: 12.3 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7707482726985935		[learning rate: 0.0030181]
	Learning Rate: 0.00301812
	LOSS [training: 1.7707482726985935 | validation: 1.8533424107594048]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_215.pth
	Model improved!!!
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7613501588500684		[learning rate: 0.0029963]
	Learning Rate: 0.00299626
	LOSS [training: 1.7613501588500684 | validation: 2.302595059921136]
	TIME [epoch: 12.3 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9195531297029975		[learning rate: 0.0029745]
	Learning Rate: 0.00297455
	LOSS [training: 1.9195531297029975 | validation: 2.1267125640761244]
	TIME [epoch: 12.3 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0177952241540655		[learning rate: 0.002953]
	Learning Rate: 0.002953
	LOSS [training: 2.0177952241540655 | validation: 2.4321054104749633]
	TIME [epoch: 12.3 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8372862431317387		[learning rate: 0.0029316]
	Learning Rate: 0.0029316
	LOSS [training: 1.8372862431317387 | validation: 1.9497800252454467]
	TIME [epoch: 12.3 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6759343127410617		[learning rate: 0.0029104]
	Learning Rate: 0.00291036
	LOSS [training: 1.6759343127410617 | validation: 1.8200194197506727]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_220.pth
	Model improved!!!
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7643720972437382		[learning rate: 0.0028893]
	Learning Rate: 0.00288928
	LOSS [training: 1.7643720972437382 | validation: 2.187678943997755]
	TIME [epoch: 12.3 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7896143076335822		[learning rate: 0.0028683]
	Learning Rate: 0.00286835
	LOSS [training: 1.7896143076335822 | validation: 1.833311320131513]
	TIME [epoch: 12.3 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6384646497543154		[learning rate: 0.0028476]
	Learning Rate: 0.00284757
	LOSS [training: 1.6384646497543154 | validation: 1.8240110967051466]
	TIME [epoch: 12.3 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6138914250297454		[learning rate: 0.0028269]
	Learning Rate: 0.00282693
	LOSS [training: 1.6138914250297454 | validation: 1.7165966550140945]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_224.pth
	Model improved!!!
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6698643987378583		[learning rate: 0.0028065]
	Learning Rate: 0.00280645
	LOSS [training: 1.6698643987378583 | validation: 2.032349873503809]
	TIME [epoch: 12.3 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7261805096402638		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.7261805096402638 | validation: 2.17500561357802]
	TIME [epoch: 12.3 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8204494468813581		[learning rate: 0.0027659]
	Learning Rate: 0.00276594
	LOSS [training: 1.8204494468813581 | validation: 1.8883549255823224]
	TIME [epoch: 12.3 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0612022728179347		[learning rate: 0.0027459]
	Learning Rate: 0.0027459
	LOSS [training: 2.0612022728179347 | validation: 2.1759291636766673]
	TIME [epoch: 12.3 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6452928722093252		[learning rate: 0.002726]
	Learning Rate: 0.002726
	LOSS [training: 1.6452928722093252 | validation: 2.1751948438402877]
	TIME [epoch: 12.3 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7987373731535126		[learning rate: 0.0027063]
	Learning Rate: 0.00270625
	LOSS [training: 1.7987373731535126 | validation: 1.9071161618151002]
	TIME [epoch: 12.3 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7361149148652473		[learning rate: 0.0026866]
	Learning Rate: 0.00268665
	LOSS [training: 1.7361149148652473 | validation: 2.260611377345615]
	TIME [epoch: 12.3 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.694075544618624		[learning rate: 0.0026672]
	Learning Rate: 0.00266718
	LOSS [training: 1.694075544618624 | validation: 1.9395565920434357]
	TIME [epoch: 12.3 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9405928328762228		[learning rate: 0.0026479]
	Learning Rate: 0.00264786
	LOSS [training: 1.9405928328762228 | validation: 2.2780578861831398]
	TIME [epoch: 12.3 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7970347317393598		[learning rate: 0.0026287]
	Learning Rate: 0.00262867
	LOSS [training: 1.7970347317393598 | validation: 2.1430123122681812]
	TIME [epoch: 12.3 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0472748419297244		[learning rate: 0.0026096]
	Learning Rate: 0.00260963
	LOSS [training: 2.0472748419297244 | validation: 2.094426060396679]
	TIME [epoch: 12.3 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7143348719644211		[learning rate: 0.0025907]
	Learning Rate: 0.00259072
	LOSS [training: 1.7143348719644211 | validation: 1.712705270343371]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_236.pth
	Model improved!!!
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5604132775097548		[learning rate: 0.002572]
	Learning Rate: 0.00257195
	LOSS [training: 1.5604132775097548 | validation: 2.0681863202687487]
	TIME [epoch: 12.3 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7321646178085868		[learning rate: 0.0025533]
	Learning Rate: 0.00255332
	LOSS [training: 1.7321646178085868 | validation: 2.332940605328778]
	TIME [epoch: 12.3 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.865344763954281		[learning rate: 0.0025348]
	Learning Rate: 0.00253482
	LOSS [training: 1.865344763954281 | validation: 2.652877116301964]
	TIME [epoch: 12.3 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1677948063083115		[learning rate: 0.0025165]
	Learning Rate: 0.00251646
	LOSS [training: 2.1677948063083115 | validation: 2.1010888114711337]
	TIME [epoch: 12.3 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6104527182410246		[learning rate: 0.0024982]
	Learning Rate: 0.00249823
	LOSS [training: 1.6104527182410246 | validation: 2.0190498027926465]
	TIME [epoch: 12.3 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6499021098350997		[learning rate: 0.0024801]
	Learning Rate: 0.00248013
	LOSS [training: 1.6499021098350997 | validation: 2.0138551450924487]
	TIME [epoch: 12.3 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6715759165692474		[learning rate: 0.0024622]
	Learning Rate: 0.00246216
	LOSS [training: 1.6715759165692474 | validation: 1.8489080475899233]
	TIME [epoch: 12.3 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6278080861925945		[learning rate: 0.0024443]
	Learning Rate: 0.00244432
	LOSS [training: 1.6278080861925945 | validation: 1.9353814698158098]
	TIME [epoch: 12.3 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5961266910986402		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.5961266910986402 | validation: 1.991540568743087]
	TIME [epoch: 12.3 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1073897207979915		[learning rate: 0.002409]
	Learning Rate: 0.00240903
	LOSS [training: 2.1073897207979915 | validation: 2.5221894986456093]
	TIME [epoch: 12.3 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.756998980876315		[learning rate: 0.0023916]
	Learning Rate: 0.00239158
	LOSS [training: 1.756998980876315 | validation: 1.803699592675074]
	TIME [epoch: 12.3 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.561851055507186		[learning rate: 0.0023742]
	Learning Rate: 0.00237425
	LOSS [training: 1.561851055507186 | validation: 2.0787582645613494]
	TIME [epoch: 12.3 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7271679052874356		[learning rate: 0.002357]
	Learning Rate: 0.00235705
	LOSS [training: 1.7271679052874356 | validation: 1.8061841277049409]
	TIME [epoch: 12.3 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4168341460374534		[learning rate: 0.00234]
	Learning Rate: 0.00233997
	LOSS [training: 1.4168341460374534 | validation: 1.6689920795370108]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_250.pth
	Model improved!!!
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5540141742626818		[learning rate: 0.002323]
	Learning Rate: 0.00232302
	LOSS [training: 1.5540141742626818 | validation: 1.6949365686813957]
	TIME [epoch: 467 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5557283326540976		[learning rate: 0.0023062]
	Learning Rate: 0.00230619
	LOSS [training: 1.5557283326540976 | validation: 1.965079332935665]
	TIME [epoch: 26.4 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8012765600538247		[learning rate: 0.0022895]
	Learning Rate: 0.00228948
	LOSS [training: 1.8012765600538247 | validation: 1.5916053068895728]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_253.pth
	Model improved!!!
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.52194705869044		[learning rate: 0.0022729]
	Learning Rate: 0.00227289
	LOSS [training: 1.52194705869044 | validation: 1.9190009517810505]
	TIME [epoch: 26.3 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5648517548651597		[learning rate: 0.0022564]
	Learning Rate: 0.00225643
	LOSS [training: 1.5648517548651597 | validation: 1.5877997321655626]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_255.pth
	Model improved!!!
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6800200848926186		[learning rate: 0.0022401]
	Learning Rate: 0.00224008
	LOSS [training: 1.6800200848926186 | validation: 2.4047989626942385]
	TIME [epoch: 26.4 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1868760662430615		[learning rate: 0.0022238]
	Learning Rate: 0.00222385
	LOSS [training: 2.1868760662430615 | validation: 2.740966376036037]
	TIME [epoch: 26.4 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.240427283516161		[learning rate: 0.0022077]
	Learning Rate: 0.00220774
	LOSS [training: 2.240427283516161 | validation: 2.3033966183337125]
	TIME [epoch: 26.4 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6951639430296193		[learning rate: 0.0021917]
	Learning Rate: 0.00219174
	LOSS [training: 1.6951639430296193 | validation: 1.6600776652720963]
	TIME [epoch: 26.3 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5321223416517498		[learning rate: 0.0021759]
	Learning Rate: 0.00217586
	LOSS [training: 1.5321223416517498 | validation: 1.9981406180938783]
	TIME [epoch: 26.4 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5176773703311637		[learning rate: 0.0021601]
	Learning Rate: 0.0021601
	LOSS [training: 1.5176773703311637 | validation: 2.1662802364212856]
	TIME [epoch: 26.3 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8215239414072593		[learning rate: 0.0021444]
	Learning Rate: 0.00214445
	LOSS [training: 1.8215239414072593 | validation: 1.6073224296904087]
	TIME [epoch: 26.4 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6590346373398188		[learning rate: 0.0021289]
	Learning Rate: 0.00212891
	LOSS [training: 1.6590346373398188 | validation: 2.4818482628846583]
	TIME [epoch: 26.4 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9821173868286253		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.9821173868286253 | validation: 2.4492474909923647]
	TIME [epoch: 26.3 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7355824302774756		[learning rate: 0.0020982]
	Learning Rate: 0.00209818
	LOSS [training: 1.7355824302774756 | validation: 1.7880552845932633]
	TIME [epoch: 26.3 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3996239346977526		[learning rate: 0.002083]
	Learning Rate: 0.00208298
	LOSS [training: 1.3996239346977526 | validation: 1.5345819707582984]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_266.pth
	Model improved!!!
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4214227868598313		[learning rate: 0.0020679]
	Learning Rate: 0.00206788
	LOSS [training: 1.4214227868598313 | validation: 1.4968500794495128]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_267.pth
	Model improved!!!
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5303537540489476		[learning rate: 0.0020529]
	Learning Rate: 0.0020529
	LOSS [training: 1.5303537540489476 | validation: 1.604143296862617]
	TIME [epoch: 26.4 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3697304908634464		[learning rate: 0.002038]
	Learning Rate: 0.00203803
	LOSS [training: 1.3697304908634464 | validation: 1.7871396685717156]
	TIME [epoch: 26.3 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4637146466693471		[learning rate: 0.0020233]
	Learning Rate: 0.00202326
	LOSS [training: 1.4637146466693471 | validation: 1.526393854488599]
	TIME [epoch: 26.3 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4138310612850236		[learning rate: 0.0020086]
	Learning Rate: 0.00200861
	LOSS [training: 1.4138310612850236 | validation: 1.7545405179522637]
	TIME [epoch: 26.3 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7102289157686197		[learning rate: 0.0019941]
	Learning Rate: 0.00199405
	LOSS [training: 1.7102289157686197 | validation: 2.3191593510604096]
	TIME [epoch: 26.3 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6006085135284014		[learning rate: 0.0019796]
	Learning Rate: 0.00197961
	LOSS [training: 1.6006085135284014 | validation: 1.7500889606151555]
	TIME [epoch: 26.3 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6223094842356933		[learning rate: 0.0019653]
	Learning Rate: 0.00196526
	LOSS [training: 1.6223094842356933 | validation: 2.5741649752436686]
	TIME [epoch: 26.3 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2909082582102145		[learning rate: 0.001951]
	Learning Rate: 0.00195103
	LOSS [training: 2.2909082582102145 | validation: 2.8556296179787592]
	TIME [epoch: 26.3 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5405098836629962		[learning rate: 0.0019369]
	Learning Rate: 0.00193689
	LOSS [training: 2.5405098836629962 | validation: 2.354091652128899]
	TIME [epoch: 26.3 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.912549387453596		[learning rate: 0.0019229]
	Learning Rate: 0.00192286
	LOSS [training: 1.912549387453596 | validation: 1.8054975170615886]
	TIME [epoch: 26.3 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5359111891955393		[learning rate: 0.0019089]
	Learning Rate: 0.00190893
	LOSS [training: 1.5359111891955393 | validation: 1.541525651804292]
	TIME [epoch: 26.3 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5563413946604963		[learning rate: 0.0018951]
	Learning Rate: 0.0018951
	LOSS [training: 1.5563413946604963 | validation: 1.6488318997182494]
	TIME [epoch: 26.3 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.520847454167014		[learning rate: 0.0018814]
	Learning Rate: 0.00188137
	LOSS [training: 1.520847454167014 | validation: 1.6310110738004053]
	TIME [epoch: 26.3 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6517869246264554		[learning rate: 0.0018677]
	Learning Rate: 0.00186774
	LOSS [training: 1.6517869246264554 | validation: 2.264013706226585]
	TIME [epoch: 26.4 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9883376195008133		[learning rate: 0.0018542]
	Learning Rate: 0.00185421
	LOSS [training: 1.9883376195008133 | validation: 2.4955784850135814]
	TIME [epoch: 26.3 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6817158955927085		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.6817158955927085 | validation: 1.7579327241044156]
	TIME [epoch: 26.3 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3897674477147015		[learning rate: 0.0018274]
	Learning Rate: 0.00182744
	LOSS [training: 1.3897674477147015 | validation: 1.6081148339080995]
	TIME [epoch: 26.3 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4347051289967752		[learning rate: 0.0018142]
	Learning Rate: 0.0018142
	LOSS [training: 1.4347051289967752 | validation: 2.134724155554226]
	TIME [epoch: 26.4 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5230511510697615		[learning rate: 0.0018011]
	Learning Rate: 0.00180105
	LOSS [training: 1.5230511510697615 | validation: 1.7176086782103068]
	TIME [epoch: 26.4 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.570840503025772		[learning rate: 0.001788]
	Learning Rate: 0.001788
	LOSS [training: 1.570840503025772 | validation: 2.070683421020682]
	TIME [epoch: 26.4 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0405663238706686		[learning rate: 0.001775]
	Learning Rate: 0.00177505
	LOSS [training: 2.0405663238706686 | validation: 2.216063611256872]
	TIME [epoch: 26.3 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0034295339761576		[learning rate: 0.0017622]
	Learning Rate: 0.00176219
	LOSS [training: 2.0034295339761576 | validation: 1.896998289273165]
	TIME [epoch: 26.4 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6248059120660483		[learning rate: 0.0017494]
	Learning Rate: 0.00174942
	LOSS [training: 1.6248059120660483 | validation: 1.7041233776356504]
	TIME [epoch: 26.3 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.355367383632461		[learning rate: 0.0017367]
	Learning Rate: 0.00173675
	LOSS [training: 1.355367383632461 | validation: 1.5418386734619962]
	TIME [epoch: 26.3 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3701340866094456		[learning rate: 0.0017242]
	Learning Rate: 0.00172417
	LOSS [training: 1.3701340866094456 | validation: 1.8384593376655474]
	TIME [epoch: 26.3 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8480138576396323		[learning rate: 0.0017117]
	Learning Rate: 0.00171167
	LOSS [training: 1.8480138576396323 | validation: 2.6121577001840905]
	TIME [epoch: 26.3 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.697552598185373		[learning rate: 0.0016993]
	Learning Rate: 0.00169927
	LOSS [training: 1.697552598185373 | validation: 1.7067657534005147]
	TIME [epoch: 26.3 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4031823583213368		[learning rate: 0.001687]
	Learning Rate: 0.00168696
	LOSS [training: 1.4031823583213368 | validation: 1.6320683086725651]
	TIME [epoch: 26.4 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5234605698961239		[learning rate: 0.0016747]
	Learning Rate: 0.00167474
	LOSS [training: 1.5234605698961239 | validation: 2.3278135308475387]
	TIME [epoch: 26.3 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7644655447813111		[learning rate: 0.0016626]
	Learning Rate: 0.00166261
	LOSS [training: 1.7644655447813111 | validation: 2.215807009030175]
	TIME [epoch: 26.4 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4940181146401428		[learning rate: 0.0016506]
	Learning Rate: 0.00165056
	LOSS [training: 1.4940181146401428 | validation: 1.8008909900963608]
	TIME [epoch: 26.4 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.471036620867828		[learning rate: 0.0016386]
	Learning Rate: 0.0016386
	LOSS [training: 1.471036620867828 | validation: 1.52010183221397]
	TIME [epoch: 26.3 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.319434816747581		[learning rate: 0.0016267]
	Learning Rate: 0.00162673
	LOSS [training: 1.319434816747581 | validation: 1.4779698113340358]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_300.pth
	Model improved!!!
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4890713233354056		[learning rate: 0.0016149]
	Learning Rate: 0.00161495
	LOSS [training: 1.4890713233354056 | validation: 2.744358548877293]
	TIME [epoch: 26.4 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9343335740797378		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.9343335740797378 | validation: 1.571160901241892]
	TIME [epoch: 26.4 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4515916806345843		[learning rate: 0.0015916]
	Learning Rate: 0.00159163
	LOSS [training: 1.4515916806345843 | validation: 1.4690187948456734]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5072183060507638		[learning rate: 0.0015801]
	Learning Rate: 0.0015801
	LOSS [training: 1.5072183060507638 | validation: 2.3267934289766803]
	TIME [epoch: 26.4 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.59712038419887		[learning rate: 0.0015687]
	Learning Rate: 0.00156865
	LOSS [training: 1.59712038419887 | validation: 1.516030290580696]
	TIME [epoch: 26.4 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4929581370302807		[learning rate: 0.0015573]
	Learning Rate: 0.00155729
	LOSS [training: 1.4929581370302807 | validation: 1.5323693971271437]
	TIME [epoch: 26.3 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4693733587491518		[learning rate: 0.001546]
	Learning Rate: 0.001546
	LOSS [training: 1.4693733587491518 | validation: 1.9868128198047148]
	TIME [epoch: 26.4 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.566475750826576		[learning rate: 0.0015348]
	Learning Rate: 0.0015348
	LOSS [training: 1.566475750826576 | validation: 1.9259775290484993]
	TIME [epoch: 26.4 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3464074659044212		[learning rate: 0.0015237]
	Learning Rate: 0.00152368
	LOSS [training: 1.3464074659044212 | validation: 1.566754091252892]
	TIME [epoch: 26.3 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9789716637749843		[learning rate: 0.0015126]
	Learning Rate: 0.00151264
	LOSS [training: 1.9789716637749843 | validation: 2.3471696925376726]
	TIME [epoch: 26.3 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.934802171074652		[learning rate: 0.0015017]
	Learning Rate: 0.00150169
	LOSS [training: 1.934802171074652 | validation: 1.8608508516143567]
	TIME [epoch: 26.3 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7438219838053644		[learning rate: 0.0014908]
	Learning Rate: 0.00149081
	LOSS [training: 1.7438219838053644 | validation: 2.1525612283921776]
	TIME [epoch: 26.3 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.690718803695607		[learning rate: 0.00148]
	Learning Rate: 0.00148001
	LOSS [training: 1.690718803695607 | validation: 2.73671383726627]
	TIME [epoch: 26.3 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1656702132042995		[learning rate: 0.0014693]
	Learning Rate: 0.00146928
	LOSS [training: 2.1656702132042995 | validation: 2.5334397991171094]
	TIME [epoch: 26.3 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.569874386574122		[learning rate: 0.0014586]
	Learning Rate: 0.00145864
	LOSS [training: 1.569874386574122 | validation: 1.5398680097789055]
	TIME [epoch: 26.3 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3409757912101603		[learning rate: 0.0014481]
	Learning Rate: 0.00144807
	LOSS [training: 1.3409757912101603 | validation: 1.4773040258358403]
	TIME [epoch: 26.3 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2898639557256968		[learning rate: 0.0014376]
	Learning Rate: 0.00143758
	LOSS [training: 1.2898639557256968 | validation: 1.4583971533134066]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_317.pth
	Model improved!!!
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3261385107310852		[learning rate: 0.0014272]
	Learning Rate: 0.00142716
	LOSS [training: 1.3261385107310852 | validation: 1.8110945977351103]
	TIME [epoch: 26.4 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5289349015496978		[learning rate: 0.0014168]
	Learning Rate: 0.00141682
	LOSS [training: 1.5289349015496978 | validation: 1.5753829592292443]
	TIME [epoch: 26.3 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3340207368148969		[learning rate: 0.0014066]
	Learning Rate: 0.00140656
	LOSS [training: 1.3340207368148969 | validation: 1.7526688006606936]
	TIME [epoch: 26.4 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.461857491267777		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.461857491267777 | validation: 1.602074051911579]
	TIME [epoch: 26.3 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6337084037729483		[learning rate: 0.0013863]
	Learning Rate: 0.00138625
	LOSS [training: 1.6337084037729483 | validation: 2.159698852839969]
	TIME [epoch: 26.3 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5145545955875972		[learning rate: 0.0013762]
	Learning Rate: 0.00137621
	LOSS [training: 1.5145545955875972 | validation: 1.5333315141247814]
	TIME [epoch: 26.3 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8099032267638642		[learning rate: 0.0013662]
	Learning Rate: 0.00136624
	LOSS [training: 1.8099032267638642 | validation: 1.8995841500498651]
	TIME [epoch: 26.4 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6640171044210335		[learning rate: 0.0013563]
	Learning Rate: 0.00135634
	LOSS [training: 1.6640171044210335 | validation: 1.558204427364854]
	TIME [epoch: 26.4 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3770151737077105		[learning rate: 0.0013465]
	Learning Rate: 0.00134651
	LOSS [training: 1.3770151737077105 | validation: 1.6029659507559404]
	TIME [epoch: 26.4 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3108833307251544		[learning rate: 0.0013368]
	Learning Rate: 0.00133676
	LOSS [training: 1.3108833307251544 | validation: 1.578946742004653]
	TIME [epoch: 26.4 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4888766556826123		[learning rate: 0.0013271]
	Learning Rate: 0.00132707
	LOSS [training: 1.4888766556826123 | validation: 1.6107903419088603]
	TIME [epoch: 26.4 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.39461131835892		[learning rate: 0.0013175]
	Learning Rate: 0.00131746
	LOSS [training: 1.39461131835892 | validation: 1.5121361569659952]
	TIME [epoch: 26.3 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3016073029708872		[learning rate: 0.0013079]
	Learning Rate: 0.00130791
	LOSS [training: 1.3016073029708872 | validation: 1.4037153330810548]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4510782330559926		[learning rate: 0.0012984]
	Learning Rate: 0.00129844
	LOSS [training: 1.4510782330559926 | validation: 2.018872933159899]
	TIME [epoch: 26.4 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4677251000395517		[learning rate: 0.001289]
	Learning Rate: 0.00128903
	LOSS [training: 1.4677251000395517 | validation: 1.4947461398563688]
	TIME [epoch: 26.3 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.246580180449282		[learning rate: 0.0012797]
	Learning Rate: 0.00127969
	LOSS [training: 1.246580180449282 | validation: 1.5444110539824467]
	TIME [epoch: 26.3 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3168382500515903		[learning rate: 0.0012704]
	Learning Rate: 0.00127042
	LOSS [training: 1.3168382500515903 | validation: 1.3867998943413702]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_334.pth
	Model improved!!!
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3039103634279217		[learning rate: 0.0012612]
	Learning Rate: 0.00126122
	LOSS [training: 1.3039103634279217 | validation: 1.4816422420813828]
	TIME [epoch: 26.4 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2431914537389943		[learning rate: 0.0012521]
	Learning Rate: 0.00125208
	LOSS [training: 1.2431914537389943 | validation: 1.5553653780301326]
	TIME [epoch: 26.3 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3123082330211058		[learning rate: 0.001243]
	Learning Rate: 0.00124301
	LOSS [training: 1.3123082330211058 | validation: 1.6177195241822542]
	TIME [epoch: 26.3 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3191839590352172		[learning rate: 0.001234]
	Learning Rate: 0.001234
	LOSS [training: 1.3191839590352172 | validation: 1.5006238485101027]
	TIME [epoch: 26.3 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2414553649941025		[learning rate: 0.0012251]
	Learning Rate: 0.00122506
	LOSS [training: 1.2414553649941025 | validation: 1.415928959755921]
	TIME [epoch: 26.4 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.302567304097806		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 1.302567304097806 | validation: 1.356183543218744]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_340.pth
	Model improved!!!
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2452942493650925		[learning rate: 0.0012074]
	Learning Rate: 0.00120737
	LOSS [training: 1.2452942493650925 | validation: 1.6624024568967186]
	TIME [epoch: 26.4 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3528769144645096		[learning rate: 0.0011986]
	Learning Rate: 0.00119863
	LOSS [training: 1.3528769144645096 | validation: 1.4310578842914923]
	TIME [epoch: 26.4 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2290664224556962		[learning rate: 0.0011899]
	Learning Rate: 0.00118994
	LOSS [training: 1.2290664224556962 | validation: 1.4081219912195326]
	TIME [epoch: 26.4 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2531276909140605		[learning rate: 0.0011813]
	Learning Rate: 0.00118132
	LOSS [training: 1.2531276909140605 | validation: 1.4841493679797395]
	TIME [epoch: 26.4 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3607938603024998		[learning rate: 0.0011728]
	Learning Rate: 0.00117276
	LOSS [training: 1.3607938603024998 | validation: 1.7913114829387307]
	TIME [epoch: 26.4 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5600456188701517		[learning rate: 0.0011643]
	Learning Rate: 0.00116427
	LOSS [training: 1.5600456188701517 | validation: 1.517499092499822]
	TIME [epoch: 26.4 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2442383092363578		[learning rate: 0.0011558]
	Learning Rate: 0.00115583
	LOSS [training: 1.2442383092363578 | validation: 1.4270131657672136]
	TIME [epoch: 26.4 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.179836760707006		[learning rate: 0.0011475]
	Learning Rate: 0.00114746
	LOSS [training: 1.179836760707006 | validation: 1.3914013531645604]
	TIME [epoch: 26.4 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3301039266755343		[learning rate: 0.0011391]
	Learning Rate: 0.00113914
	LOSS [training: 1.3301039266755343 | validation: 1.6309109443437524]
	TIME [epoch: 26.4 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2771159972115087		[learning rate: 0.0011309]
	Learning Rate: 0.00113089
	LOSS [training: 1.2771159972115087 | validation: 1.434111331971224]
	TIME [epoch: 26.4 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.191216511917317		[learning rate: 0.0011227]
	Learning Rate: 0.0011227
	LOSS [training: 1.191216511917317 | validation: 1.4261760344154903]
	TIME [epoch: 26.4 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.254750483121263		[learning rate: 0.0011146]
	Learning Rate: 0.00111456
	LOSS [training: 1.254750483121263 | validation: 1.3925056852633317]
	TIME [epoch: 26.4 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2180486495004366		[learning rate: 0.0011065]
	Learning Rate: 0.00110649
	LOSS [training: 1.2180486495004366 | validation: 1.936081291886755]
	TIME [epoch: 26.4 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.47548242105783		[learning rate: 0.0010985]
	Learning Rate: 0.00109847
	LOSS [training: 1.47548242105783 | validation: 1.9706992981720397]
	TIME [epoch: 26.4 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4633047225921119		[learning rate: 0.0010905]
	Learning Rate: 0.00109051
	LOSS [training: 1.4633047225921119 | validation: 1.4549615161939018]
	TIME [epoch: 26.4 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2092109899773438		[learning rate: 0.0010826]
	Learning Rate: 0.00108261
	LOSS [training: 1.2092109899773438 | validation: 1.4146881039511872]
	TIME [epoch: 26.4 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2498542995754103		[learning rate: 0.0010748]
	Learning Rate: 0.00107477
	LOSS [training: 1.2498542995754103 | validation: 1.5049498530644323]
	TIME [epoch: 26.4 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2710764566422441		[learning rate: 0.001067]
	Learning Rate: 0.00106698
	LOSS [training: 1.2710764566422441 | validation: 1.3597352715614528]
	TIME [epoch: 26.4 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1533387437059468		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 1.1533387437059468 | validation: 1.3763820659620456]
	TIME [epoch: 26.4 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1836718083016216		[learning rate: 0.0010516]
	Learning Rate: 0.00105158
	LOSS [training: 1.1836718083016216 | validation: 1.416420212524835]
	TIME [epoch: 26.4 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2436882589188438		[learning rate: 0.001044]
	Learning Rate: 0.00104396
	LOSS [training: 1.2436882589188438 | validation: 1.8822461471916136]
	TIME [epoch: 26.4 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5064031874340835		[learning rate: 0.0010364]
	Learning Rate: 0.0010364
	LOSS [training: 1.5064031874340835 | validation: 1.445315327465997]
	TIME [epoch: 26.4 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2147291917691667		[learning rate: 0.0010289]
	Learning Rate: 0.00102889
	LOSS [training: 1.2147291917691667 | validation: 1.3530035211486733]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_363.pth
	Model improved!!!
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2281306280310784		[learning rate: 0.0010214]
	Learning Rate: 0.00102143
	LOSS [training: 1.2281306280310784 | validation: 1.4429423882388752]
	TIME [epoch: 26.4 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.197670332888958		[learning rate: 0.001014]
	Learning Rate: 0.00101403
	LOSS [training: 1.197670332888958 | validation: 1.420259890123717]
	TIME [epoch: 26.3 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1754236467768888		[learning rate: 0.0010067]
	Learning Rate: 0.00100669
	LOSS [training: 1.1754236467768888 | validation: 1.3867927682047716]
	TIME [epoch: 26.4 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1729807558650962		[learning rate: 0.00099939]
	Learning Rate: 0.000999394
	LOSS [training: 1.1729807558650962 | validation: 1.3043553096665734]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_367.pth
	Model improved!!!
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1800370990829379		[learning rate: 0.00099215]
	Learning Rate: 0.000992154
	LOSS [training: 1.1800370990829379 | validation: 1.322949534019231]
	TIME [epoch: 26.4 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2862441060897394		[learning rate: 0.00098497]
	Learning Rate: 0.000984966
	LOSS [training: 1.2862441060897394 | validation: 1.5655083230568558]
	TIME [epoch: 26.4 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2631170887824836		[learning rate: 0.00097783]
	Learning Rate: 0.00097783
	LOSS [training: 1.2631170887824836 | validation: 1.4015732228752162]
	TIME [epoch: 26.3 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.198165614785943		[learning rate: 0.00097075]
	Learning Rate: 0.000970745
	LOSS [training: 1.198165614785943 | validation: 1.4114614044206246]
	TIME [epoch: 26.3 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.241881457031852		[learning rate: 0.00096371]
	Learning Rate: 0.000963712
	LOSS [training: 1.241881457031852 | validation: 1.4826219862516825]
	TIME [epoch: 26.4 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.485685846817761		[learning rate: 0.00095673]
	Learning Rate: 0.00095673
	LOSS [training: 1.485685846817761 | validation: 1.4927555509725434]
	TIME [epoch: 26.4 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.218249576297426		[learning rate: 0.0009498]
	Learning Rate: 0.000949799
	LOSS [training: 1.218249576297426 | validation: 1.3167703993866557]
	TIME [epoch: 26.4 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2609343874749879		[learning rate: 0.00094292]
	Learning Rate: 0.000942918
	LOSS [training: 1.2609343874749879 | validation: 1.762235192580347]
	TIME [epoch: 26.4 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2899661690393263		[learning rate: 0.00093609]
	Learning Rate: 0.000936086
	LOSS [training: 1.2899661690393263 | validation: 1.5361110099866835]
	TIME [epoch: 26.4 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3987879209708292		[learning rate: 0.0009293]
	Learning Rate: 0.000929304
	LOSS [training: 1.3987879209708292 | validation: 2.2754471260069344]
	TIME [epoch: 26.4 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.738275441167333		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 1.738275441167333 | validation: 2.028640025288298]
	TIME [epoch: 26.4 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4663983652380013		[learning rate: 0.00091589]
	Learning Rate: 0.000915888
	LOSS [training: 1.4663983652380013 | validation: 1.36940752959336]
	TIME [epoch: 26.4 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1302633229438426		[learning rate: 0.00090925]
	Learning Rate: 0.000909252
	LOSS [training: 1.1302633229438426 | validation: 1.2973591319081947]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_380.pth
	Model improved!!!
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1418981038026896		[learning rate: 0.00090266]
	Learning Rate: 0.000902664
	LOSS [training: 1.1418981038026896 | validation: 1.3918512293997032]
	TIME [epoch: 26.4 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1939476317326103		[learning rate: 0.00089612]
	Learning Rate: 0.000896125
	LOSS [training: 1.1939476317326103 | validation: 1.4402610424584255]
	TIME [epoch: 26.4 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1451680739750185		[learning rate: 0.00088963]
	Learning Rate: 0.000889632
	LOSS [training: 1.1451680739750185 | validation: 1.3193675679678973]
	TIME [epoch: 26.4 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.142793951335955		[learning rate: 0.00088319]
	Learning Rate: 0.000883187
	LOSS [training: 1.142793951335955 | validation: 1.4569353028018142]
	TIME [epoch: 26.4 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2089421516813774		[learning rate: 0.00087679]
	Learning Rate: 0.000876788
	LOSS [training: 1.2089421516813774 | validation: 1.2775973140284083]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_385.pth
	Model improved!!!
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.135158082793256		[learning rate: 0.00087044]
	Learning Rate: 0.000870436
	LOSS [training: 1.135158082793256 | validation: 1.3359667471674408]
	TIME [epoch: 26.4 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703741881628287		[learning rate: 0.00086413]
	Learning Rate: 0.00086413
	LOSS [training: 1.1703741881628287 | validation: 1.2662863792815824]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_387.pth
	Model improved!!!
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.126129139457523		[learning rate: 0.00085787]
	Learning Rate: 0.000857869
	LOSS [training: 1.126129139457523 | validation: 1.336120451092087]
	TIME [epoch: 26.3 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1416605875985275		[learning rate: 0.00085165]
	Learning Rate: 0.000851654
	LOSS [training: 1.1416605875985275 | validation: 1.2856092109752562]
	TIME [epoch: 26.3 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.10470763010186		[learning rate: 0.00084548]
	Learning Rate: 0.000845484
	LOSS [training: 1.10470763010186 | validation: 1.3234149014934928]
	TIME [epoch: 26.3 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1056102609816167		[learning rate: 0.00083936]
	Learning Rate: 0.000839358
	LOSS [training: 1.1056102609816167 | validation: 1.3002070799851073]
	TIME [epoch: 26.3 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.17887598914585		[learning rate: 0.00083328]
	Learning Rate: 0.000833277
	LOSS [training: 1.17887598914585 | validation: 1.3298571345525634]
	TIME [epoch: 26.3 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.149465277794907		[learning rate: 0.00082724]
	Learning Rate: 0.00082724
	LOSS [training: 1.149465277794907 | validation: 1.5369745378200936]
	TIME [epoch: 26.4 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.291954316744894		[learning rate: 0.00082125]
	Learning Rate: 0.000821247
	LOSS [training: 1.291954316744894 | validation: 1.2523229723379248]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_394.pth
	Model improved!!!
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0698109944251235		[learning rate: 0.0008153]
	Learning Rate: 0.000815297
	LOSS [training: 1.0698109944251235 | validation: 1.3789399042447967]
	TIME [epoch: 26.4 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1487073226768945		[learning rate: 0.00080939]
	Learning Rate: 0.00080939
	LOSS [training: 1.1487073226768945 | validation: 1.3777093356188725]
	TIME [epoch: 26.3 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1781527924768957		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 1.1781527924768957 | validation: 1.2465607290085758]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_397.pth
	Model improved!!!
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0771743996359464		[learning rate: 0.0007977]
	Learning Rate: 0.000797705
	LOSS [training: 1.0771743996359464 | validation: 1.4158596002897421]
	TIME [epoch: 26.4 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4019694814333474		[learning rate: 0.00079193]
	Learning Rate: 0.000791925
	LOSS [training: 1.4019694814333474 | validation: 1.8181276734145042]
	TIME [epoch: 26.3 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.237282377234929		[learning rate: 0.00078619]
	Learning Rate: 0.000786188
	LOSS [training: 1.237282377234929 | validation: 1.3420001898934077]
	TIME [epoch: 26.3 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.091734903519158		[learning rate: 0.00078049]
	Learning Rate: 0.000780492
	LOSS [training: 1.091734903519158 | validation: 1.3662688214668601]
	TIME [epoch: 26.3 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0990174015706078		[learning rate: 0.00077484]
	Learning Rate: 0.000774838
	LOSS [training: 1.0990174015706078 | validation: 1.3026468392940045]
	TIME [epoch: 26.3 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1048679391960046		[learning rate: 0.00076922]
	Learning Rate: 0.000769224
	LOSS [training: 1.1048679391960046 | validation: 1.2813849348583106]
	TIME [epoch: 26.3 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0825449794379411		[learning rate: 0.00076365]
	Learning Rate: 0.000763651
	LOSS [training: 1.0825449794379411 | validation: 1.2276826058641896]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_404.pth
	Model improved!!!
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0371200096079587		[learning rate: 0.00075812]
	Learning Rate: 0.000758118
	LOSS [training: 1.0371200096079587 | validation: 1.1932832106152933]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_405.pth
	Model improved!!!
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272624090052256		[learning rate: 0.00075263]
	Learning Rate: 0.000752626
	LOSS [training: 1.0272624090052256 | validation: 1.2154329002062483]
	TIME [epoch: 26.3 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0349854273771677		[learning rate: 0.00074717]
	Learning Rate: 0.000747173
	LOSS [training: 1.0349854273771677 | validation: 1.2656561259302035]
	TIME [epoch: 26.3 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0372322015789688		[learning rate: 0.00074176]
	Learning Rate: 0.00074176
	LOSS [training: 1.0372322015789688 | validation: 1.2287406296042773]
	TIME [epoch: 26.4 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0899667628427072		[learning rate: 0.00073639]
	Learning Rate: 0.000736386
	LOSS [training: 1.0899667628427072 | validation: 1.2001520430627133]
	TIME [epoch: 26.4 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0616771373073972		[learning rate: 0.00073105]
	Learning Rate: 0.000731051
	LOSS [training: 1.0616771373073972 | validation: 1.2180050710089947]
	TIME [epoch: 26.3 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.056610447038058		[learning rate: 0.00072575]
	Learning Rate: 0.000725754
	LOSS [training: 1.056610447038058 | validation: 1.4844472889168294]
	TIME [epoch: 26.4 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2339238384743667		[learning rate: 0.0007205]
	Learning Rate: 0.000720496
	LOSS [training: 1.2339238384743667 | validation: 1.362939313040724]
	TIME [epoch: 26.3 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0589571523533503		[learning rate: 0.00071528]
	Learning Rate: 0.000715276
	LOSS [training: 1.0589571523533503 | validation: 1.2081734381395597]
	TIME [epoch: 26.3 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0990918229020257		[learning rate: 0.00071009]
	Learning Rate: 0.000710094
	LOSS [training: 1.0990918229020257 | validation: 1.3164657496903467]
	TIME [epoch: 26.4 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0273387051622804		[learning rate: 0.00070495]
	Learning Rate: 0.000704949
	LOSS [training: 1.0273387051622804 | validation: 1.2061287260512519]
	TIME [epoch: 26.4 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0603942864761715		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 1.0603942864761715 | validation: 1.24499946135491]
	TIME [epoch: 26.3 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0385041211978627		[learning rate: 0.00069477]
	Learning Rate: 0.000694772
	LOSS [training: 1.0385041211978627 | validation: 1.2243804833834138]
	TIME [epoch: 26.4 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0756092322426816		[learning rate: 0.00068974]
	Learning Rate: 0.000689738
	LOSS [training: 1.0756092322426816 | validation: 1.201883779884494]
	TIME [epoch: 26.4 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0114358214692785		[learning rate: 0.00068474]
	Learning Rate: 0.000684741
	LOSS [training: 1.0114358214692785 | validation: 1.172834814172923]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_419.pth
	Model improved!!!
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0113513244259895		[learning rate: 0.00067978]
	Learning Rate: 0.00067978
	LOSS [training: 1.0113513244259895 | validation: 1.2950026237921912]
	TIME [epoch: 26.4 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.004971013313279		[learning rate: 0.00067486]
	Learning Rate: 0.000674855
	LOSS [training: 1.004971013313279 | validation: 1.1656238700841801]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_421.pth
	Model improved!!!
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0160566175307981		[learning rate: 0.00066997]
	Learning Rate: 0.000669966
	LOSS [training: 1.0160566175307981 | validation: 1.19757645546911]
	TIME [epoch: 26.4 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.023250940752134		[learning rate: 0.00066511]
	Learning Rate: 0.000665112
	LOSS [training: 1.023250940752134 | validation: 1.3262904982000538]
	TIME [epoch: 26.4 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0027703783622424		[learning rate: 0.00066029]
	Learning Rate: 0.000660293
	LOSS [training: 1.0027703783622424 | validation: 1.1605699719858764]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_424.pth
	Model improved!!!
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9746659559616484		[learning rate: 0.00065551]
	Learning Rate: 0.00065551
	LOSS [training: 0.9746659559616484 | validation: 1.2444324321301827]
	TIME [epoch: 26.4 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0039877510513746		[learning rate: 0.00065076]
	Learning Rate: 0.00065076
	LOSS [training: 1.0039877510513746 | validation: 1.1693500103267562]
	TIME [epoch: 26.3 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0046329027478944		[learning rate: 0.00064605]
	Learning Rate: 0.000646046
	LOSS [training: 1.0046329027478944 | validation: 1.6302212322217406]
	TIME [epoch: 26.4 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.149832672971346		[learning rate: 0.00064137]
	Learning Rate: 0.000641365
	LOSS [training: 1.149832672971346 | validation: 1.146718472720149]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_428.pth
	Model improved!!!
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9905753890000216		[learning rate: 0.00063672]
	Learning Rate: 0.000636718
	LOSS [training: 0.9905753890000216 | validation: 1.204446704202137]
	TIME [epoch: 26.4 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9905240826031043		[learning rate: 0.00063211]
	Learning Rate: 0.000632105
	LOSS [training: 0.9905240826031043 | validation: 1.1153532257671726]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_430.pth
	Model improved!!!
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253686577880709		[learning rate: 0.00062753]
	Learning Rate: 0.000627526
	LOSS [training: 0.9253686577880709 | validation: 1.2082276958256273]
	TIME [epoch: 26.4 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0216976567811775		[learning rate: 0.00062298]
	Learning Rate: 0.000622979
	LOSS [training: 1.0216976567811775 | validation: 1.1481995617101275]
	TIME [epoch: 26.4 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9798955515038736		[learning rate: 0.00061847]
	Learning Rate: 0.000618466
	LOSS [training: 0.9798955515038736 | validation: 1.1435260979609463]
	TIME [epoch: 26.4 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9493255894628596		[learning rate: 0.00061399]
	Learning Rate: 0.000613985
	LOSS [training: 0.9493255894628596 | validation: 1.150713130134331]
	TIME [epoch: 26.4 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9372420088292475		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.9372420088292475 | validation: 1.1784647214737876]
	TIME [epoch: 26.4 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9679847384490863		[learning rate: 0.00060512]
	Learning Rate: 0.000605121
	LOSS [training: 0.9679847384490863 | validation: 1.1815581138355964]
	TIME [epoch: 26.4 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.938063320415632		[learning rate: 0.00060074]
	Learning Rate: 0.000600737
	LOSS [training: 0.938063320415632 | validation: 1.2057519568090234]
	TIME [epoch: 26.4 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9675315794741359		[learning rate: 0.00059638]
	Learning Rate: 0.000596385
	LOSS [training: 0.9675315794741359 | validation: 1.085293607648058]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_438.pth
	Model improved!!!
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9135399178693895		[learning rate: 0.00059206]
	Learning Rate: 0.000592064
	LOSS [training: 0.9135399178693895 | validation: 1.1311700560416513]
	TIME [epoch: 26.3 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9734277072997859		[learning rate: 0.00058777]
	Learning Rate: 0.000587774
	LOSS [training: 0.9734277072997859 | validation: 1.163907438279079]
	TIME [epoch: 26.4 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9336921717677245		[learning rate: 0.00058352]
	Learning Rate: 0.000583516
	LOSS [training: 0.9336921717677245 | validation: 1.1032931152289547]
	TIME [epoch: 26.3 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.917034806200334		[learning rate: 0.00057929]
	Learning Rate: 0.000579288
	LOSS [training: 0.917034806200334 | validation: 1.1322877695038898]
	TIME [epoch: 26.4 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9033599343227672		[learning rate: 0.00057509]
	Learning Rate: 0.000575091
	LOSS [training: 0.9033599343227672 | validation: 1.1117752882628384]
	TIME [epoch: 26.3 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9227507852223156		[learning rate: 0.00057092]
	Learning Rate: 0.000570925
	LOSS [training: 0.9227507852223156 | validation: 1.1540860920111384]
	TIME [epoch: 26.4 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9278432888873066		[learning rate: 0.00056679]
	Learning Rate: 0.000566789
	LOSS [training: 0.9278432888873066 | validation: 1.1390694970278568]
	TIME [epoch: 26.4 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9170949674342419		[learning rate: 0.00056268]
	Learning Rate: 0.000562682
	LOSS [training: 0.9170949674342419 | validation: 1.194208740190056]
	TIME [epoch: 26.4 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9268674297906344		[learning rate: 0.00055861]
	Learning Rate: 0.000558606
	LOSS [training: 0.9268674297906344 | validation: 1.0922381633783116]
	TIME [epoch: 26.4 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984542910573428		[learning rate: 0.00055456]
	Learning Rate: 0.000554559
	LOSS [training: 0.8984542910573428 | validation: 1.2582999629332532]
	TIME [epoch: 26.4 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9674509465748744		[learning rate: 0.00055054]
	Learning Rate: 0.000550541
	LOSS [training: 0.9674509465748744 | validation: 1.094786643978935]
	TIME [epoch: 26.4 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9301245483725129		[learning rate: 0.00054655]
	Learning Rate: 0.000546552
	LOSS [training: 0.9301245483725129 | validation: 1.0785008984468716]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_450.pth
	Model improved!!!
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.893248196476992		[learning rate: 0.00054259]
	Learning Rate: 0.000542592
	LOSS [training: 0.893248196476992 | validation: 1.1385022017159154]
	TIME [epoch: 26.4 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9027796646628768		[learning rate: 0.00053866]
	Learning Rate: 0.000538661
	LOSS [training: 0.9027796646628768 | validation: 1.1068046494654364]
	TIME [epoch: 26.4 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.896598768479646		[learning rate: 0.00053476]
	Learning Rate: 0.000534759
	LOSS [training: 0.896598768479646 | validation: 1.123132880570585]
	TIME [epoch: 26.4 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.901104289226061		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.901104289226061 | validation: 1.0788478430851247]
	TIME [epoch: 26.4 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8816316322722804		[learning rate: 0.00052704]
	Learning Rate: 0.000527038
	LOSS [training: 0.8816316322722804 | validation: 1.0562025444433505]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_455.pth
	Model improved!!!
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8899129229997258		[learning rate: 0.00052322]
	Learning Rate: 0.00052322
	LOSS [training: 0.8899129229997258 | validation: 1.044407860694693]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_456.pth
	Model improved!!!
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8881702239084792		[learning rate: 0.00051943]
	Learning Rate: 0.000519429
	LOSS [training: 0.8881702239084792 | validation: 1.1306854629660743]
	TIME [epoch: 26.4 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8647151135212449		[learning rate: 0.00051567]
	Learning Rate: 0.000515666
	LOSS [training: 0.8647151135212449 | validation: 1.0410971004193947]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_458.pth
	Model improved!!!
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8834090766452984		[learning rate: 0.00051193]
	Learning Rate: 0.00051193
	LOSS [training: 0.8834090766452984 | validation: 1.1037256740283117]
	TIME [epoch: 26.4 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8837106834945911		[learning rate: 0.00050822]
	Learning Rate: 0.000508221
	LOSS [training: 0.8837106834945911 | validation: 1.0653942594485317]
	TIME [epoch: 26.3 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8857508024130357		[learning rate: 0.00050454]
	Learning Rate: 0.000504539
	LOSS [training: 0.8857508024130357 | validation: 1.0869835347765673]
	TIME [epoch: 26.3 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9153835529475373		[learning rate: 0.00050088]
	Learning Rate: 0.000500884
	LOSS [training: 0.9153835529475373 | validation: 1.1011532732943556]
	TIME [epoch: 26.3 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753337078835954		[learning rate: 0.00049725]
	Learning Rate: 0.000497255
	LOSS [training: 0.8753337078835954 | validation: 1.032426366109893]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_463.pth
	Model improved!!!
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8609899372032981		[learning rate: 0.00049365]
	Learning Rate: 0.000493652
	LOSS [training: 0.8609899372032981 | validation: 1.1392398688070648]
	TIME [epoch: 26.4 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8692153435227168		[learning rate: 0.00049008]
	Learning Rate: 0.000490076
	LOSS [training: 0.8692153435227168 | validation: 1.0314412303593743]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_465.pth
	Model improved!!!
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8447415880871103		[learning rate: 0.00048653]
	Learning Rate: 0.000486525
	LOSS [training: 0.8447415880871103 | validation: 1.020542751840832]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_466.pth
	Model improved!!!
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8337721446807174		[learning rate: 0.000483]
	Learning Rate: 0.000483
	LOSS [training: 0.8337721446807174 | validation: 1.0159801152601082]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_467.pth
	Model improved!!!
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8420503747159102		[learning rate: 0.0004795]
	Learning Rate: 0.000479501
	LOSS [training: 0.8420503747159102 | validation: 1.070451389974843]
	TIME [epoch: 26.3 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0258316878309952		[learning rate: 0.00047603]
	Learning Rate: 0.000476027
	LOSS [training: 1.0258316878309952 | validation: 1.047980535182154]
	TIME [epoch: 26.3 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8331172508312705		[learning rate: 0.00047258]
	Learning Rate: 0.000472578
	LOSS [training: 0.8331172508312705 | validation: 1.0296547035523957]
	TIME [epoch: 26.3 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8266000308090924		[learning rate: 0.00046915]
	Learning Rate: 0.000469154
	LOSS [training: 0.8266000308090924 | validation: 1.0354390081741387]
	TIME [epoch: 26.3 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8286691541989804		[learning rate: 0.00046576]
	Learning Rate: 0.000465755
	LOSS [training: 0.8286691541989804 | validation: 1.0500570941575271]
	TIME [epoch: 26.3 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8744362139522455		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.8744362139522455 | validation: 1.0276357434903995]
	TIME [epoch: 26.3 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8964024147889216		[learning rate: 0.00045903]
	Learning Rate: 0.000459031
	LOSS [training: 0.8964024147889216 | validation: 1.0245150202483613]
	TIME [epoch: 26.3 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8771127462175555		[learning rate: 0.00045571]
	Learning Rate: 0.000455706
	LOSS [training: 0.8771127462175555 | validation: 1.1815971120160964]
	TIME [epoch: 26.3 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8734987132366533		[learning rate: 0.0004524]
	Learning Rate: 0.000452404
	LOSS [training: 0.8734987132366533 | validation: 1.0064862766211031]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_476.pth
	Model improved!!!
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.818007994601713		[learning rate: 0.00044913]
	Learning Rate: 0.000449126
	LOSS [training: 0.818007994601713 | validation: 1.0465551589573177]
	TIME [epoch: 26.3 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8506630487458707		[learning rate: 0.00044587]
	Learning Rate: 0.000445872
	LOSS [training: 0.8506630487458707 | validation: 1.0941133342030205]
	TIME [epoch: 26.3 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8684227520706109		[learning rate: 0.00044264]
	Learning Rate: 0.000442642
	LOSS [training: 0.8684227520706109 | validation: 1.0102133269960922]
	TIME [epoch: 26.4 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.815351285890701		[learning rate: 0.00043944]
	Learning Rate: 0.000439435
	LOSS [training: 0.815351285890701 | validation: 1.0333206175936225]
	TIME [epoch: 26.4 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8665146089458109		[learning rate: 0.00043625]
	Learning Rate: 0.000436251
	LOSS [training: 0.8665146089458109 | validation: 1.0273846292081112]
	TIME [epoch: 26.4 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8415707563721175		[learning rate: 0.00043309]
	Learning Rate: 0.000433091
	LOSS [training: 0.8415707563721175 | validation: 1.0245248381378753]
	TIME [epoch: 26.3 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8337049027583481		[learning rate: 0.00042995]
	Learning Rate: 0.000429953
	LOSS [training: 0.8337049027583481 | validation: 1.034376033003333]
	TIME [epoch: 26.3 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8239500136292934		[learning rate: 0.00042684]
	Learning Rate: 0.000426838
	LOSS [training: 0.8239500136292934 | validation: 1.050814972114349]
	TIME [epoch: 26.3 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8532914174381667		[learning rate: 0.00042375]
	Learning Rate: 0.000423746
	LOSS [training: 0.8532914174381667 | validation: 1.0024784273603817]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_485.pth
	Model improved!!!
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440169012462478		[learning rate: 0.00042068]
	Learning Rate: 0.000420676
	LOSS [training: 0.8440169012462478 | validation: 0.9869789789344621]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_486.pth
	Model improved!!!
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.846600387751528		[learning rate: 0.00041763]
	Learning Rate: 0.000417628
	LOSS [training: 0.846600387751528 | validation: 1.0229098696118961]
	TIME [epoch: 26.3 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8172787014149969		[learning rate: 0.0004146]
	Learning Rate: 0.000414602
	LOSS [training: 0.8172787014149969 | validation: 0.9892867809593477]
	TIME [epoch: 26.4 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066931672334852		[learning rate: 0.0004116]
	Learning Rate: 0.000411598
	LOSS [training: 0.8066931672334852 | validation: 1.0057252053378858]
	TIME [epoch: 26.4 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071734300506985		[learning rate: 0.00040862]
	Learning Rate: 0.000408616
	LOSS [training: 0.8071734300506985 | validation: 0.9804706304365187]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_490.pth
	Model improved!!!
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7951396032137975		[learning rate: 0.00040566]
	Learning Rate: 0.000405656
	LOSS [training: 0.7951396032137975 | validation: 1.021379730460229]
	TIME [epoch: 26.3 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104722300254604		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.8104722300254604 | validation: 0.9741821381649085]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_492.pth
	Model improved!!!
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382667839995386		[learning rate: 0.0003998]
	Learning Rate: 0.000399799
	LOSS [training: 0.8382667839995386 | validation: 1.1513669319255366]
	TIME [epoch: 26.4 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9151475893708853		[learning rate: 0.0003969]
	Learning Rate: 0.000396903
	LOSS [training: 0.9151475893708853 | validation: 1.1566677125360094]
	TIME [epoch: 26.4 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8583177264966313		[learning rate: 0.00039403]
	Learning Rate: 0.000394027
	LOSS [training: 0.8583177264966313 | validation: 0.990604289320582]
	TIME [epoch: 26.4 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8181903649958078		[learning rate: 0.00039117]
	Learning Rate: 0.000391173
	LOSS [training: 0.8181903649958078 | validation: 0.9940687829164998]
	TIME [epoch: 26.4 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.797367879321838		[learning rate: 0.00038834]
	Learning Rate: 0.000388339
	LOSS [training: 0.797367879321838 | validation: 1.0408165963987823]
	TIME [epoch: 26.4 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.844095012448886		[learning rate: 0.00038553]
	Learning Rate: 0.000385525
	LOSS [training: 0.844095012448886 | validation: 1.0248072549131488]
	TIME [epoch: 26.4 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.785664138835309		[learning rate: 0.00038273]
	Learning Rate: 0.000382732
	LOSS [training: 0.785664138835309 | validation: 0.9810371311281647]
	TIME [epoch: 26.4 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7814161196346917		[learning rate: 0.00037996]
	Learning Rate: 0.000379959
	LOSS [training: 0.7814161196346917 | validation: 0.9608647061776425]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_500.pth
	Model improved!!!
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.789401474960923		[learning rate: 0.00037721]
	Learning Rate: 0.000377206
	LOSS [training: 0.789401474960923 | validation: 0.9744719855406049]
	TIME [epoch: 495 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012355262641054		[learning rate: 0.00037447]
	Learning Rate: 0.000374474
	LOSS [training: 0.8012355262641054 | validation: 0.9588133772646188]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_502.pth
	Model improved!!!
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838525929863909		[learning rate: 0.00037176]
	Learning Rate: 0.00037176
	LOSS [training: 0.7838525929863909 | validation: 0.9642059906667575]
	TIME [epoch: 55.8 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7858885815358982		[learning rate: 0.00036907]
	Learning Rate: 0.000369067
	LOSS [training: 0.7858885815358982 | validation: 0.987711749199722]
	TIME [epoch: 55.9 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8019866665502317		[learning rate: 0.00036639]
	Learning Rate: 0.000366393
	LOSS [training: 0.8019866665502317 | validation: 0.9543596526075567]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_505.pth
	Model improved!!!
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837404631705196		[learning rate: 0.00036374]
	Learning Rate: 0.000363739
	LOSS [training: 0.7837404631705196 | validation: 0.9844160378081105]
	TIME [epoch: 55.9 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7994331958651433		[learning rate: 0.0003611]
	Learning Rate: 0.000361103
	LOSS [training: 0.7994331958651433 | validation: 1.0187613508641682]
	TIME [epoch: 55.8 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8232283885535185		[learning rate: 0.00035849]
	Learning Rate: 0.000358487
	LOSS [training: 0.8232283885535185 | validation: 1.0060842110252295]
	TIME [epoch: 55.8 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.78975867140583		[learning rate: 0.00035589]
	Learning Rate: 0.00035589
	LOSS [training: 0.78975867140583 | validation: 1.0006846078685743]
	TIME [epoch: 55.8 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966360688621639		[learning rate: 0.00035331]
	Learning Rate: 0.000353312
	LOSS [training: 0.7966360688621639 | validation: 0.9546631952318811]
	TIME [epoch: 55.8 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.764932169598381		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.764932169598381 | validation: 0.9331075729838534]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_511.pth
	Model improved!!!
EPOCH 512/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7822080885027862		[learning rate: 0.00034821]
	Learning Rate: 0.000348211
	LOSS [training: 0.7822080885027862 | validation: 0.9835009227596847]
	TIME [epoch: 55.8 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7815471664984954		[learning rate: 0.00034569]
	Learning Rate: 0.000345688
	LOSS [training: 0.7815471664984954 | validation: 0.959600860963129]
	TIME [epoch: 55.9 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8460566345094489		[learning rate: 0.00034318]
	Learning Rate: 0.000343183
	LOSS [training: 0.8460566345094489 | validation: 0.9620947600413183]
	TIME [epoch: 55.9 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7790076912452775		[learning rate: 0.0003407]
	Learning Rate: 0.000340697
	LOSS [training: 0.7790076912452775 | validation: 0.9824586970026192]
	TIME [epoch: 55.8 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7628442104510242		[learning rate: 0.00033823]
	Learning Rate: 0.000338229
	LOSS [training: 0.7628442104510242 | validation: 0.9595913599330598]
	TIME [epoch: 55.8 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7696174303542092		[learning rate: 0.00033578]
	Learning Rate: 0.000335778
	LOSS [training: 0.7696174303542092 | validation: 0.9409650951913944]
	TIME [epoch: 55.8 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7743347669511211		[learning rate: 0.00033335]
	Learning Rate: 0.000333346
	LOSS [training: 0.7743347669511211 | validation: 0.9269962514450976]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_518.pth
	Model improved!!!
EPOCH 519/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7705439653269445		[learning rate: 0.00033093]
	Learning Rate: 0.000330931
	LOSS [training: 0.7705439653269445 | validation: 1.0058540417630115]
	TIME [epoch: 55.8 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.803128327424916		[learning rate: 0.00032853]
	Learning Rate: 0.000328533
	LOSS [training: 0.803128327424916 | validation: 0.9360582515785878]
	TIME [epoch: 55.8 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7558854239324843		[learning rate: 0.00032615]
	Learning Rate: 0.000326153
	LOSS [training: 0.7558854239324843 | validation: 0.9393709086684567]
	TIME [epoch: 55.8 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8090217526645249		[learning rate: 0.00032379]
	Learning Rate: 0.00032379
	LOSS [training: 0.8090217526645249 | validation: 0.9869430989072937]
	TIME [epoch: 55.8 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758045701419023		[learning rate: 0.00032144]
	Learning Rate: 0.000321444
	LOSS [training: 0.7758045701419023 | validation: 0.9474596125122718]
	TIME [epoch: 55.8 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7747071917127699		[learning rate: 0.00031912]
	Learning Rate: 0.000319115
	LOSS [training: 0.7747071917127699 | validation: 0.9293534899951446]
	TIME [epoch: 55.8 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.763766537779015		[learning rate: 0.0003168]
	Learning Rate: 0.000316803
	LOSS [training: 0.763766537779015 | validation: 0.9450381419548745]
	TIME [epoch: 55.8 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7681110130378452		[learning rate: 0.00031451]
	Learning Rate: 0.000314508
	LOSS [training: 0.7681110130378452 | validation: 0.9542023164783426]
	TIME [epoch: 55.8 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712198064080436		[learning rate: 0.00031223]
	Learning Rate: 0.000312229
	LOSS [training: 0.7712198064080436 | validation: 0.9514570136898748]
	TIME [epoch: 55.8 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7779036168559849		[learning rate: 0.00030997]
	Learning Rate: 0.000309967
	LOSS [training: 0.7779036168559849 | validation: 0.9552209671994845]
	TIME [epoch: 55.8 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7592131530015476		[learning rate: 0.00030772]
	Learning Rate: 0.000307722
	LOSS [training: 0.7592131530015476 | validation: 0.9416675460311885]
	TIME [epoch: 55.8 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7595826689556371		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.7595826689556371 | validation: 0.9425922754160788]
	TIME [epoch: 55.8 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7615649650417966		[learning rate: 0.00030328]
	Learning Rate: 0.000303279
	LOSS [training: 0.7615649650417966 | validation: 0.9213324910359232]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_531.pth
	Model improved!!!
EPOCH 532/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.745183615582142		[learning rate: 0.00030108]
	Learning Rate: 0.000301082
	LOSS [training: 0.745183615582142 | validation: 0.924052968663907]
	TIME [epoch: 55.9 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8158609413683598		[learning rate: 0.0002989]
	Learning Rate: 0.0002989
	LOSS [training: 0.8158609413683598 | validation: 0.99947134428482]
	TIME [epoch: 55.8 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7684964502865872		[learning rate: 0.00029673]
	Learning Rate: 0.000296735
	LOSS [training: 0.7684964502865872 | validation: 0.9421080719443096]
	TIME [epoch: 55.8 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7459856638974438		[learning rate: 0.00029458]
	Learning Rate: 0.000294585
	LOSS [training: 0.7459856638974438 | validation: 0.9433980147968137]
	TIME [epoch: 55.9 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7691967082421758		[learning rate: 0.00029245]
	Learning Rate: 0.000292451
	LOSS [training: 0.7691967082421758 | validation: 0.9455798891558961]
	TIME [epoch: 55.8 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517398352492869		[learning rate: 0.00029033]
	Learning Rate: 0.000290332
	LOSS [training: 0.7517398352492869 | validation: 0.9802486564463542]
	TIME [epoch: 55.8 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7633748903449387		[learning rate: 0.00028823]
	Learning Rate: 0.000288228
	LOSS [training: 0.7633748903449387 | validation: 0.9410639258259548]
	TIME [epoch: 55.8 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526237818893718		[learning rate: 0.00028614]
	Learning Rate: 0.00028614
	LOSS [training: 0.7526237818893718 | validation: 0.9289094883032185]
	TIME [epoch: 55.8 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7548946435001971		[learning rate: 0.00028407]
	Learning Rate: 0.000284067
	LOSS [training: 0.7548946435001971 | validation: 0.9331696559822531]
	TIME [epoch: 55.8 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.738059749735454		[learning rate: 0.00028201]
	Learning Rate: 0.000282009
	LOSS [training: 0.738059749735454 | validation: 0.9285552258360878]
	TIME [epoch: 55.8 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7487580433829379		[learning rate: 0.00027997]
	Learning Rate: 0.000279966
	LOSS [training: 0.7487580433829379 | validation: 0.8930876839071085]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_542.pth
	Model improved!!!
EPOCH 543/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7556432884059359		[learning rate: 0.00027794]
	Learning Rate: 0.000277938
	LOSS [training: 0.7556432884059359 | validation: 0.9110625373558687]
	TIME [epoch: 55.8 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7396240791752724		[learning rate: 0.00027592]
	Learning Rate: 0.000275924
	LOSS [training: 0.7396240791752724 | validation: 0.8910076837560439]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_544.pth
	Model improved!!!
EPOCH 545/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7567553814336531		[learning rate: 0.00027392]
	Learning Rate: 0.000273925
	LOSS [training: 0.7567553814336531 | validation: 0.9121389066183593]
	TIME [epoch: 55.8 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7789842126026711		[learning rate: 0.00027194]
	Learning Rate: 0.00027194
	LOSS [training: 0.7789842126026711 | validation: 0.9491224667813545]
	TIME [epoch: 55.8 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7621434963871141		[learning rate: 0.00026997]
	Learning Rate: 0.00026997
	LOSS [training: 0.7621434963871141 | validation: 0.9632303271221626]
	TIME [epoch: 55.8 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461347853139043		[learning rate: 0.00026801]
	Learning Rate: 0.000268014
	LOSS [training: 0.7461347853139043 | validation: 0.9185996989435441]
	TIME [epoch: 55.8 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7484511122413118		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.7484511122413118 | validation: 0.9315659197245529]
	TIME [epoch: 55.8 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7765515038579842		[learning rate: 0.00026414]
	Learning Rate: 0.000264145
	LOSS [training: 0.7765515038579842 | validation: 0.9472434053687133]
	TIME [epoch: 55.8 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7736156633586436		[learning rate: 0.00026223]
	Learning Rate: 0.000262231
	LOSS [training: 0.7736156633586436 | validation: 0.9482015340285123]
	TIME [epoch: 55.8 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657104675786174		[learning rate: 0.00026033]
	Learning Rate: 0.000260331
	LOSS [training: 0.7657104675786174 | validation: 1.0686480150633222]
	TIME [epoch: 55.8 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8149695079912322		[learning rate: 0.00025845]
	Learning Rate: 0.000258445
	LOSS [training: 0.8149695079912322 | validation: 0.9138737952010019]
	TIME [epoch: 55.8 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.744336427001294		[learning rate: 0.00025657]
	Learning Rate: 0.000256573
	LOSS [training: 0.744336427001294 | validation: 0.9177947818047625]
	TIME [epoch: 55.8 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8242964845936098		[learning rate: 0.00025471]
	Learning Rate: 0.000254714
	LOSS [training: 0.8242964845936098 | validation: 1.0328780819549361]
	TIME [epoch: 55.8 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7963805488797647		[learning rate: 0.00025287]
	Learning Rate: 0.000252869
	LOSS [training: 0.7963805488797647 | validation: 0.9172830500077123]
	TIME [epoch: 55.8 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7221337447076711		[learning rate: 0.00025104]
	Learning Rate: 0.000251037
	LOSS [training: 0.7221337447076711 | validation: 0.9278600322879353]
	TIME [epoch: 55.9 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.718970997196223		[learning rate: 0.00024922]
	Learning Rate: 0.000249218
	LOSS [training: 0.718970997196223 | validation: 0.9007878506186209]
	TIME [epoch: 55.8 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340925354406689		[learning rate: 0.00024741]
	Learning Rate: 0.000247412
	LOSS [training: 0.7340925354406689 | validation: 0.9091902886849204]
	TIME [epoch: 55.8 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277298233328175		[learning rate: 0.00024562]
	Learning Rate: 0.00024562
	LOSS [training: 0.7277298233328175 | validation: 0.9022164004419815]
	TIME [epoch: 55.8 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.73993583466637		[learning rate: 0.00024384]
	Learning Rate: 0.00024384
	LOSS [training: 0.73993583466637 | validation: 0.9114567406729311]
	TIME [epoch: 55.8 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7662735658192001		[learning rate: 0.00024207]
	Learning Rate: 0.000242074
	LOSS [training: 0.7662735658192001 | validation: 0.889677625074341]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_562.pth
	Model improved!!!
EPOCH 563/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.749499668010382		[learning rate: 0.00024032]
	Learning Rate: 0.00024032
	LOSS [training: 0.749499668010382 | validation: 0.9134973778907156]
	TIME [epoch: 55.8 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532669960850612		[learning rate: 0.00023858]
	Learning Rate: 0.000238579
	LOSS [training: 0.7532669960850612 | validation: 0.9083129038471227]
	TIME [epoch: 55.8 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7418865722450536		[learning rate: 0.00023685]
	Learning Rate: 0.00023685
	LOSS [training: 0.7418865722450536 | validation: 0.9437235687538053]
	TIME [epoch: 55.8 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8218735030682162		[learning rate: 0.00023513]
	Learning Rate: 0.000235134
	LOSS [training: 0.8218735030682162 | validation: 1.0373032119644232]
	TIME [epoch: 55.8 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8509036770640163		[learning rate: 0.00023343]
	Learning Rate: 0.000233431
	LOSS [training: 0.8509036770640163 | validation: 0.906208727777847]
	TIME [epoch: 55.8 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7315906185594965		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.7315906185594965 | validation: 0.9021284426068905]
	TIME [epoch: 55.8 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.726918761825241		[learning rate: 0.00023006]
	Learning Rate: 0.000230061
	LOSS [training: 0.726918761825241 | validation: 0.9179871764593989]
	TIME [epoch: 55.8 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8233188869348472		[learning rate: 0.00022839]
	Learning Rate: 0.000228394
	LOSS [training: 0.8233188869348472 | validation: 0.9922297440661345]
	TIME [epoch: 55.8 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7440291205142687		[learning rate: 0.00022674]
	Learning Rate: 0.000226739
	LOSS [training: 0.7440291205142687 | validation: 0.8827735110202148]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_571.pth
	Model improved!!!
EPOCH 572/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.732000929843803		[learning rate: 0.0002251]
	Learning Rate: 0.000225096
	LOSS [training: 0.732000929843803 | validation: 0.9693785614222965]
	TIME [epoch: 55.8 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.777744629896667		[learning rate: 0.00022347]
	Learning Rate: 0.000223466
	LOSS [training: 0.777744629896667 | validation: 0.9627496861980966]
	TIME [epoch: 55.8 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250892810539504		[learning rate: 0.00022185]
	Learning Rate: 0.000221847
	LOSS [training: 0.7250892810539504 | validation: 0.9009248699843722]
	TIME [epoch: 55.8 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390171267377758		[learning rate: 0.00022024]
	Learning Rate: 0.000220239
	LOSS [training: 0.7390171267377758 | validation: 1.0417787332447146]
	TIME [epoch: 55.8 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7534767361874612		[learning rate: 0.00021864]
	Learning Rate: 0.000218644
	LOSS [training: 0.7534767361874612 | validation: 0.902852244527351]
	TIME [epoch: 55.8 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7246851421859057		[learning rate: 0.00021706]
	Learning Rate: 0.00021706
	LOSS [training: 0.7246851421859057 | validation: 0.9113815329080475]
	TIME [epoch: 55.8 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7153032873406091		[learning rate: 0.00021549]
	Learning Rate: 0.000215487
	LOSS [training: 0.7153032873406091 | validation: 0.8959937988750551]
	TIME [epoch: 55.8 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197676410203925		[learning rate: 0.00021393]
	Learning Rate: 0.000213926
	LOSS [training: 0.7197676410203925 | validation: 0.8977566978857243]
	TIME [epoch: 55.8 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282732614008052		[learning rate: 0.00021238]
	Learning Rate: 0.000212376
	LOSS [training: 0.7282732614008052 | validation: 0.8967197321920597]
	TIME [epoch: 55.8 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7138121756047493		[learning rate: 0.00021084]
	Learning Rate: 0.000210837
	LOSS [training: 0.7138121756047493 | validation: 0.9278274945662763]
	TIME [epoch: 55.8 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7844154238530099		[learning rate: 0.00020931]
	Learning Rate: 0.00020931
	LOSS [training: 0.7844154238530099 | validation: 0.9924950642381707]
	TIME [epoch: 55.8 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.751851903396667		[learning rate: 0.00020779]
	Learning Rate: 0.000207793
	LOSS [training: 0.751851903396667 | validation: 0.8830734659410949]
	TIME [epoch: 55.8 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7189688242708799		[learning rate: 0.00020629]
	Learning Rate: 0.000206288
	LOSS [training: 0.7189688242708799 | validation: 0.8813192749525995]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_584.pth
	Model improved!!!
EPOCH 585/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7280702113077804		[learning rate: 0.00020479]
	Learning Rate: 0.000204793
	LOSS [training: 0.7280702113077804 | validation: 0.8966693397158216]
	TIME [epoch: 55.8 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7074078230116241		[learning rate: 0.00020331]
	Learning Rate: 0.00020331
	LOSS [training: 0.7074078230116241 | validation: 0.8858333935080765]
	TIME [epoch: 55.8 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7196011360266288		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.7196011360266288 | validation: 0.89851624493624]
	TIME [epoch: 55.8 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7353044107942064		[learning rate: 0.00020037]
	Learning Rate: 0.000200374
	LOSS [training: 0.7353044107942064 | validation: 0.9183571837733431]
	TIME [epoch: 55.8 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7165477335418834		[learning rate: 0.00019892]
	Learning Rate: 0.000198923
	LOSS [training: 0.7165477335418834 | validation: 0.8810058402766654]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_589.pth
	Model improved!!!
EPOCH 590/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258360462160744		[learning rate: 0.00019748]
	Learning Rate: 0.000197482
	LOSS [training: 0.7258360462160744 | validation: 0.987065440790803]
	TIME [epoch: 55.9 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7501266702840418		[learning rate: 0.00019605]
	Learning Rate: 0.000196051
	LOSS [training: 0.7501266702840418 | validation: 0.8945517298619634]
	TIME [epoch: 55.9 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7059748373762831		[learning rate: 0.00019463]
	Learning Rate: 0.00019463
	LOSS [training: 0.7059748373762831 | validation: 0.8871923817356195]
	TIME [epoch: 55.9 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6994182793794684		[learning rate: 0.00019322]
	Learning Rate: 0.00019322
	LOSS [training: 0.6994182793794684 | validation: 0.8875205040045686]
	TIME [epoch: 55.9 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7132998410898908		[learning rate: 0.00019182]
	Learning Rate: 0.00019182
	LOSS [training: 0.7132998410898908 | validation: 0.885123283725344]
	TIME [epoch: 55.9 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7029507451046647		[learning rate: 0.00019043]
	Learning Rate: 0.000190431
	LOSS [training: 0.7029507451046647 | validation: 0.8824571330374176]
	TIME [epoch: 55.9 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103280442241948		[learning rate: 0.00018905]
	Learning Rate: 0.000189051
	LOSS [training: 0.7103280442241948 | validation: 0.908187873570898]
	TIME [epoch: 55.9 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055647131606998		[learning rate: 0.00018768]
	Learning Rate: 0.000187681
	LOSS [training: 0.7055647131606998 | validation: 0.8837554076592007]
	TIME [epoch: 55.9 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079506313300417		[learning rate: 0.00018632]
	Learning Rate: 0.000186322
	LOSS [training: 0.7079506313300417 | validation: 0.8859319759506661]
	TIME [epoch: 55.9 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000125360013402		[learning rate: 0.00018497]
	Learning Rate: 0.000184972
	LOSS [training: 0.7000125360013402 | validation: 0.8946272421675496]
	TIME [epoch: 55.9 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117767373093857		[learning rate: 0.00018363]
	Learning Rate: 0.000183632
	LOSS [training: 0.7117767373093857 | validation: 0.8666664361063126]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_600.pth
	Model improved!!!
EPOCH 601/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6958736942566278		[learning rate: 0.0001823]
	Learning Rate: 0.000182301
	LOSS [training: 0.6958736942566278 | validation: 0.8938004930749743]
	TIME [epoch: 55.8 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7112159563056053		[learning rate: 0.00018098]
	Learning Rate: 0.00018098
	LOSS [training: 0.7112159563056053 | validation: 0.9353835311174035]
	TIME [epoch: 55.9 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272722326178951		[learning rate: 0.00017967]
	Learning Rate: 0.000179669
	LOSS [training: 0.7272722326178951 | validation: 0.9033644311188695]
	TIME [epoch: 55.9 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7118320742997539		[learning rate: 0.00017837]
	Learning Rate: 0.000178368
	LOSS [training: 0.7118320742997539 | validation: 0.9024823893803107]
	TIME [epoch: 55.9 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.727642543814334		[learning rate: 0.00017708]
	Learning Rate: 0.000177075
	LOSS [training: 0.727642543814334 | validation: 0.8762357351961443]
	TIME [epoch: 55.9 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049369762849591		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.7049369762849591 | validation: 0.8796345510877263]
	TIME [epoch: 55.9 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997686681601157		[learning rate: 0.00017452]
	Learning Rate: 0.000174519
	LOSS [training: 0.6997686681601157 | validation: 0.887920402787387]
	TIME [epoch: 55.9 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6962186009585105		[learning rate: 0.00017325]
	Learning Rate: 0.000173254
	LOSS [training: 0.6962186009585105 | validation: 0.8555957529491965]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_608.pth
	Model improved!!!
EPOCH 609/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7256140307822562		[learning rate: 0.000172]
	Learning Rate: 0.000171999
	LOSS [training: 0.7256140307822562 | validation: 0.8949183548088955]
	TIME [epoch: 55.8 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7084098948981941		[learning rate: 0.00017075]
	Learning Rate: 0.000170753
	LOSS [training: 0.7084098948981941 | validation: 0.9003233173814698]
	TIME [epoch: 55.9 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134003716564448		[learning rate: 0.00016952]
	Learning Rate: 0.000169516
	LOSS [training: 0.7134003716564448 | validation: 0.9154355480238772]
	TIME [epoch: 55.9 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7345854259121224		[learning rate: 0.00016829]
	Learning Rate: 0.000168288
	LOSS [training: 0.7345854259121224 | validation: 0.8824643754476017]
	TIME [epoch: 55.9 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7096436434642737		[learning rate: 0.00016707]
	Learning Rate: 0.000167069
	LOSS [training: 0.7096436434642737 | validation: 0.8750513742870386]
	TIME [epoch: 55.9 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972377729635225		[learning rate: 0.00016586]
	Learning Rate: 0.000165858
	LOSS [training: 0.6972377729635225 | validation: 0.8769466066699841]
	TIME [epoch: 55.9 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.694610865110599		[learning rate: 0.00016466]
	Learning Rate: 0.000164657
	LOSS [training: 0.694610865110599 | validation: 0.8869220993667897]
	TIME [epoch: 55.9 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064481171928501		[learning rate: 0.00016346]
	Learning Rate: 0.000163464
	LOSS [training: 0.7064481171928501 | validation: 0.8700271069855795]
	TIME [epoch: 55.9 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7063106750319423		[learning rate: 0.00016228]
	Learning Rate: 0.000162279
	LOSS [training: 0.7063106750319423 | validation: 0.88440369906683]
	TIME [epoch: 55.9 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7046572341139659		[learning rate: 0.0001611]
	Learning Rate: 0.000161104
	LOSS [training: 0.7046572341139659 | validation: 0.8687383436990027]
	TIME [epoch: 55.9 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7034723725904123		[learning rate: 0.00015994]
	Learning Rate: 0.000159936
	LOSS [training: 0.7034723725904123 | validation: 0.895142307256562]
	TIME [epoch: 55.9 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7119510566797129		[learning rate: 0.00015878]
	Learning Rate: 0.000158778
	LOSS [training: 0.7119510566797129 | validation: 0.8852291646995298]
	TIME [epoch: 55.8 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292995804062942		[learning rate: 0.00015763]
	Learning Rate: 0.000157627
	LOSS [training: 0.7292995804062942 | validation: 0.8541579992574662]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_621.pth
	Model improved!!!
EPOCH 622/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7105012704026615		[learning rate: 0.00015649]
	Learning Rate: 0.000156485
	LOSS [training: 0.7105012704026615 | validation: 0.9058319169021785]
	TIME [epoch: 56 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226890719194716		[learning rate: 0.00015535]
	Learning Rate: 0.000155352
	LOSS [training: 0.7226890719194716 | validation: 0.8887473031324908]
	TIME [epoch: 55.9 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988245599523493		[learning rate: 0.00015423]
	Learning Rate: 0.000154226
	LOSS [training: 0.6988245599523493 | validation: 0.8744486682771306]
	TIME [epoch: 55.9 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.697291058374014		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.697291058374014 | validation: 0.8573263709048746]
	TIME [epoch: 55.9 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7064998611118356		[learning rate: 0.000152]
	Learning Rate: 0.000152
	LOSS [training: 0.7064998611118356 | validation: 0.8577834966029878]
	TIME [epoch: 55.9 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7044118495042013		[learning rate: 0.0001509]
	Learning Rate: 0.000150898
	LOSS [training: 0.7044118495042013 | validation: 0.8870135059072959]
	TIME [epoch: 55.8 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055059120314584		[learning rate: 0.00014981]
	Learning Rate: 0.000149805
	LOSS [training: 0.7055059120314584 | validation: 0.9372580693880791]
	TIME [epoch: 55.9 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7318107183573264		[learning rate: 0.00014872]
	Learning Rate: 0.00014872
	LOSS [training: 0.7318107183573264 | validation: 0.8641360431730202]
	TIME [epoch: 55.8 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6943340380526881		[learning rate: 0.00014764]
	Learning Rate: 0.000147642
	LOSS [training: 0.6943340380526881 | validation: 0.8493786087587454]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_630.pth
	Model improved!!!
EPOCH 631/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6939936571273103		[learning rate: 0.00014657]
	Learning Rate: 0.000146573
	LOSS [training: 0.6939936571273103 | validation: 0.8762761602494378]
	TIME [epoch: 55.9 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6976635605164557		[learning rate: 0.00014551]
	Learning Rate: 0.000145511
	LOSS [training: 0.6976635605164557 | validation: 0.8744202657764046]
	TIME [epoch: 55.9 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6942602893387564		[learning rate: 0.00014446]
	Learning Rate: 0.000144456
	LOSS [training: 0.6942602893387564 | validation: 0.869370726943007]
	TIME [epoch: 55.9 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7103332027191603		[learning rate: 0.00014341]
	Learning Rate: 0.00014341
	LOSS [training: 0.7103332027191603 | validation: 0.8839332186473812]
	TIME [epoch: 55.9 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6908501032899447		[learning rate: 0.00014237]
	Learning Rate: 0.000142371
	LOSS [training: 0.6908501032899447 | validation: 0.8849358802865686]
	TIME [epoch: 55.9 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157255424809736		[learning rate: 0.00014134]
	Learning Rate: 0.000141339
	LOSS [training: 0.7157255424809736 | validation: 0.9305903677298184]
	TIME [epoch: 55.9 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.745383233175883		[learning rate: 0.00014032]
	Learning Rate: 0.000140315
	LOSS [training: 0.745383233175883 | validation: 0.9039833200128482]
	TIME [epoch: 55.9 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7314005205661849		[learning rate: 0.0001393]
	Learning Rate: 0.000139299
	LOSS [training: 0.7314005205661849 | validation: 0.8833212975806839]
	TIME [epoch: 55.9 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6914567076215753		[learning rate: 0.00013829]
	Learning Rate: 0.00013829
	LOSS [training: 0.6914567076215753 | validation: 0.8581353494341679]
	TIME [epoch: 55.9 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6911761422306617		[learning rate: 0.00013729]
	Learning Rate: 0.000137288
	LOSS [training: 0.6911761422306617 | validation: 0.8649942131648002]
	TIME [epoch: 55.9 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944078891252276		[learning rate: 0.00013629]
	Learning Rate: 0.000136293
	LOSS [training: 0.6944078891252276 | validation: 0.8865824822283463]
	TIME [epoch: 55.9 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7087178375079148		[learning rate: 0.00013531]
	Learning Rate: 0.000135306
	LOSS [training: 0.7087178375079148 | validation: 0.8700614320891755]
	TIME [epoch: 55.9 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996831673236132		[learning rate: 0.00013433]
	Learning Rate: 0.000134325
	LOSS [training: 0.6996831673236132 | validation: 0.8561484512849022]
	TIME [epoch: 55.9 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6934344070297075		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.6934344070297075 | validation: 0.8599921916070219]
	TIME [epoch: 55.9 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.684627441372242		[learning rate: 0.00013239]
	Learning Rate: 0.000132386
	LOSS [training: 0.684627441372242 | validation: 0.8648747356640119]
	TIME [epoch: 55.8 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951179115957762		[learning rate: 0.00013143]
	Learning Rate: 0.000131427
	LOSS [training: 0.6951179115957762 | validation: 0.8631466937419403]
	TIME [epoch: 55.8 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.680132100728537		[learning rate: 0.00013047]
	Learning Rate: 0.000130475
	LOSS [training: 0.680132100728537 | validation: 0.8601704877432235]
	TIME [epoch: 55.9 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870906517518349		[learning rate: 0.00012953]
	Learning Rate: 0.000129529
	LOSS [training: 0.6870906517518349 | validation: 0.8675591231211828]
	TIME [epoch: 55.9 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866008992369713		[learning rate: 0.00012859]
	Learning Rate: 0.000128591
	LOSS [training: 0.6866008992369713 | validation: 0.869484455905537]
	TIME [epoch: 55.9 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6870190738761599		[learning rate: 0.00012766]
	Learning Rate: 0.000127659
	LOSS [training: 0.6870190738761599 | validation: 0.8833738772363822]
	TIME [epoch: 55.9 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451145426766408		[learning rate: 0.00012673]
	Learning Rate: 0.000126734
	LOSS [training: 0.7451145426766408 | validation: 0.8905913024619734]
	TIME [epoch: 55.8 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964445584839531		[learning rate: 0.00012582]
	Learning Rate: 0.000125816
	LOSS [training: 0.6964445584839531 | validation: 0.893034665458958]
	TIME [epoch: 55.9 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027643579475702		[learning rate: 0.0001249]
	Learning Rate: 0.000124905
	LOSS [training: 0.7027643579475702 | validation: 0.8820361535218573]
	TIME [epoch: 55.9 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6983901099977778		[learning rate: 0.000124]
	Learning Rate: 0.000124
	LOSS [training: 0.6983901099977778 | validation: 0.9055375770095022]
	TIME [epoch: 55.9 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7023569385915595		[learning rate: 0.0001231]
	Learning Rate: 0.000123101
	LOSS [training: 0.7023569385915595 | validation: 0.8972959011231326]
	TIME [epoch: 55.8 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7037041392713408		[learning rate: 0.00012221]
	Learning Rate: 0.00012221
	LOSS [training: 0.7037041392713408 | validation: 0.8741597314767374]
	TIME [epoch: 55.9 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866190844110686		[learning rate: 0.00012132]
	Learning Rate: 0.000121324
	LOSS [training: 0.6866190844110686 | validation: 0.9217758993696263]
	TIME [epoch: 55.9 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7160538947696987		[learning rate: 0.00012045]
	Learning Rate: 0.000120445
	LOSS [training: 0.7160538947696987 | validation: 0.9356004949004353]
	TIME [epoch: 55.9 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7124284996105357		[learning rate: 0.00011957]
	Learning Rate: 0.000119573
	LOSS [training: 0.7124284996105357 | validation: 0.8900224229152829]
	TIME [epoch: 55.9 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7003986732211762		[learning rate: 0.00011871]
	Learning Rate: 0.000118706
	LOSS [training: 0.7003986732211762 | validation: 0.9081267320717982]
	TIME [epoch: 55.9 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009484863569049		[learning rate: 0.00011785]
	Learning Rate: 0.000117846
	LOSS [training: 0.7009484863569049 | validation: 0.8720316944466155]
	TIME [epoch: 55.9 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.68382023084984		[learning rate: 0.00011699]
	Learning Rate: 0.000116992
	LOSS [training: 0.68382023084984 | validation: 0.9280400505661173]
	TIME [epoch: 55.9 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7321052502214489		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.7321052502214489 | validation: 0.9088449310393927]
	TIME [epoch: 55.9 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7241385923524031		[learning rate: 0.0001153]
	Learning Rate: 0.000115303
	LOSS [training: 0.7241385923524031 | validation: 0.8868186608052604]
	TIME [epoch: 55.9 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6926842388290454		[learning rate: 0.00011447]
	Learning Rate: 0.000114468
	LOSS [training: 0.6926842388290454 | validation: 0.9001536947667448]
	TIME [epoch: 55.9 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.710323567457531		[learning rate: 0.00011364]
	Learning Rate: 0.000113639
	LOSS [training: 0.710323567457531 | validation: 0.9204036307777328]
	TIME [epoch: 55.9 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.697993121691164		[learning rate: 0.00011282]
	Learning Rate: 0.000112815
	LOSS [training: 0.697993121691164 | validation: 0.8734882211297473]
	TIME [epoch: 55.9 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.686545447126052		[learning rate: 0.000112]
	Learning Rate: 0.000111998
	LOSS [training: 0.686545447126052 | validation: 0.906113786260346]
	TIME [epoch: 55.9 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955079188241917		[learning rate: 0.00011119]
	Learning Rate: 0.000111187
	LOSS [training: 0.6955079188241917 | validation: 0.8801260753347435]
	TIME [epoch: 55.9 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031015559963991		[learning rate: 0.00011038]
	Learning Rate: 0.000110381
	LOSS [training: 0.7031015559963991 | validation: 0.8754389228597887]
	TIME [epoch: 55.8 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6860143112066344		[learning rate: 0.00010958]
	Learning Rate: 0.000109581
	LOSS [training: 0.6860143112066344 | validation: 0.843810857968605]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_671.pth
	Model improved!!!
EPOCH 672/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865558015583682		[learning rate: 0.00010879]
	Learning Rate: 0.000108787
	LOSS [training: 0.6865558015583682 | validation: 0.8433690259997505]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_672.pth
	Model improved!!!
EPOCH 673/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876662553764481		[learning rate: 0.000108]
	Learning Rate: 0.000107999
	LOSS [training: 0.6876662553764481 | validation: 0.8757107931401357]
	TIME [epoch: 55.9 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761537355623597		[learning rate: 0.00010722]
	Learning Rate: 0.000107217
	LOSS [training: 0.6761537355623597 | validation: 0.8844843297961725]
	TIME [epoch: 55.9 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049353358019081		[learning rate: 0.00010644]
	Learning Rate: 0.00010644
	LOSS [training: 0.7049353358019081 | validation: 0.8738303739739663]
	TIME [epoch: 55.9 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6867424198809674		[learning rate: 0.00010567]
	Learning Rate: 0.000105669
	LOSS [training: 0.6867424198809674 | validation: 0.866291182847277]
	TIME [epoch: 55.8 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846236879303781		[learning rate: 0.0001049]
	Learning Rate: 0.000104903
	LOSS [training: 0.6846236879303781 | validation: 0.8526503997773651]
	TIME [epoch: 55.9 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773325813871457		[learning rate: 0.00010414]
	Learning Rate: 0.000104143
	LOSS [training: 0.6773325813871457 | validation: 0.8578759851166466]
	TIME [epoch: 55.9 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6783204691283835		[learning rate: 0.00010339]
	Learning Rate: 0.000103389
	LOSS [training: 0.6783204691283835 | validation: 0.8562084937461]
	TIME [epoch: 55.9 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.697278769456357		[learning rate: 0.00010264]
	Learning Rate: 0.00010264
	LOSS [training: 0.697278769456357 | validation: 0.9050691062004551]
	TIME [epoch: 55.9 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.697667507383261		[learning rate: 0.0001019]
	Learning Rate: 0.000101896
	LOSS [training: 0.697667507383261 | validation: 0.8670231896617022]
	TIME [epoch: 55.9 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693850193199284		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.6693850193199284 | validation: 0.8596580794153049]
	TIME [epoch: 55.9 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736122708399632		[learning rate: 0.00010043]
	Learning Rate: 0.000100425
	LOSS [training: 0.6736122708399632 | validation: 0.8483372568696081]
	TIME [epoch: 55.9 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829070444916325		[learning rate: 9.9697e-05]
	Learning Rate: 9.96975e-05
	LOSS [training: 0.6829070444916325 | validation: 0.8283985900888168]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_684.pth
	Model improved!!!
EPOCH 685/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820337032964927		[learning rate: 9.8975e-05]
	Learning Rate: 9.89752e-05
	LOSS [training: 0.6820337032964927 | validation: 0.8467107693128866]
	TIME [epoch: 55.9 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811501816134164		[learning rate: 9.8258e-05]
	Learning Rate: 9.82581e-05
	LOSS [training: 0.6811501816134164 | validation: 0.9178976233660157]
	TIME [epoch: 55.9 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7437227672439357		[learning rate: 9.7546e-05]
	Learning Rate: 9.75463e-05
	LOSS [training: 0.7437227672439357 | validation: 0.8870238490396449]
	TIME [epoch: 55.8 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6921081363918222		[learning rate: 9.684e-05]
	Learning Rate: 9.68396e-05
	LOSS [training: 0.6921081363918222 | validation: 0.8512610896305932]
	TIME [epoch: 55.9 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6851878094071207		[learning rate: 9.6138e-05]
	Learning Rate: 9.61379e-05
	LOSS [training: 0.6851878094071207 | validation: 0.8321767720876616]
	TIME [epoch: 55.9 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813664644354128		[learning rate: 9.5441e-05]
	Learning Rate: 9.54414e-05
	LOSS [training: 0.6813664644354128 | validation: 0.9105523074970632]
	TIME [epoch: 55.9 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7218384144461947		[learning rate: 9.475e-05]
	Learning Rate: 9.475e-05
	LOSS [training: 0.7218384144461947 | validation: 0.8930231317451586]
	TIME [epoch: 55.9 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755491318425407		[learning rate: 9.4064e-05]
	Learning Rate: 9.40635e-05
	LOSS [training: 0.6755491318425407 | validation: 0.8585397834705123]
	TIME [epoch: 55.9 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6843882916165522		[learning rate: 9.3382e-05]
	Learning Rate: 9.3382e-05
	LOSS [training: 0.6843882916165522 | validation: 0.8552178595983165]
	TIME [epoch: 55.9 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6829115607294299		[learning rate: 9.2705e-05]
	Learning Rate: 9.27055e-05
	LOSS [training: 0.6829115607294299 | validation: 0.8557902320303863]
	TIME [epoch: 55.9 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805862692384792		[learning rate: 9.2034e-05]
	Learning Rate: 9.20338e-05
	LOSS [training: 0.6805862692384792 | validation: 0.8544985166518355]
	TIME [epoch: 55.9 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.682494317258802		[learning rate: 9.1367e-05]
	Learning Rate: 9.13671e-05
	LOSS [training: 0.682494317258802 | validation: 0.8602221055373029]
	TIME [epoch: 55.9 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763230498784293		[learning rate: 9.0705e-05]
	Learning Rate: 9.07051e-05
	LOSS [training: 0.6763230498784293 | validation: 0.8449811346456563]
	TIME [epoch: 55.9 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6888424193008807		[learning rate: 9.0048e-05]
	Learning Rate: 9.00479e-05
	LOSS [training: 0.6888424193008807 | validation: 0.871717942627096]
	TIME [epoch: 55.9 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.690347289820581		[learning rate: 8.9396e-05]
	Learning Rate: 8.93955e-05
	LOSS [training: 0.690347289820581 | validation: 0.8270557045530631]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_699.pth
	Model improved!!!
EPOCH 700/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771679157875807		[learning rate: 8.8748e-05]
	Learning Rate: 8.87479e-05
	LOSS [training: 0.6771679157875807 | validation: 0.8475175206227803]
	TIME [epoch: 55.9 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6670426074052		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.6670426074052 | validation: 0.8532167178233117]
	TIME [epoch: 55.9 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6713026535014673		[learning rate: 8.7467e-05]
	Learning Rate: 8.74666e-05
	LOSS [training: 0.6713026535014673 | validation: 0.8473913868035454]
	TIME [epoch: 55.9 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6837425584330628		[learning rate: 8.6833e-05]
	Learning Rate: 8.68329e-05
	LOSS [training: 0.6837425584330628 | validation: 0.8450367510651433]
	TIME [epoch: 55.9 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6849970320548661		[learning rate: 8.6204e-05]
	Learning Rate: 8.62038e-05
	LOSS [training: 0.6849970320548661 | validation: 0.8303839161352251]
	TIME [epoch: 55.9 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6713950604909636		[learning rate: 8.5579e-05]
	Learning Rate: 8.55793e-05
	LOSS [training: 0.6713950604909636 | validation: 0.8423280460092197]
	TIME [epoch: 55.8 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773002792126849		[learning rate: 8.4959e-05]
	Learning Rate: 8.49592e-05
	LOSS [training: 0.6773002792126849 | validation: 0.8637684842531517]
	TIME [epoch: 55.9 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6920709620006141		[learning rate: 8.4344e-05]
	Learning Rate: 8.43437e-05
	LOSS [training: 0.6920709620006141 | validation: 0.8327532517205295]
	TIME [epoch: 55.9 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.669030071818098		[learning rate: 8.3733e-05]
	Learning Rate: 8.37327e-05
	LOSS [training: 0.669030071818098 | validation: 0.861755429419505]
	TIME [epoch: 55.9 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6750796351211767		[learning rate: 8.3126e-05]
	Learning Rate: 8.3126e-05
	LOSS [training: 0.6750796351211767 | validation: 0.8400489320924501]
	TIME [epoch: 55.9 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6841107697686788		[learning rate: 8.2524e-05]
	Learning Rate: 8.25238e-05
	LOSS [training: 0.6841107697686788 | validation: 0.8543741434355856]
	TIME [epoch: 55.9 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.693372947061888		[learning rate: 8.1926e-05]
	Learning Rate: 8.19259e-05
	LOSS [training: 0.693372947061888 | validation: 0.8312702415752717]
	TIME [epoch: 55.9 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671158390555516		[learning rate: 8.1332e-05]
	Learning Rate: 8.13323e-05
	LOSS [training: 0.6671158390555516 | validation: 0.8496221844402012]
	TIME [epoch: 55.9 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664316073688223		[learning rate: 8.0743e-05]
	Learning Rate: 8.07431e-05
	LOSS [training: 0.6664316073688223 | validation: 0.8334868747105322]
	TIME [epoch: 55.9 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821489599245357		[learning rate: 8.0158e-05]
	Learning Rate: 8.01581e-05
	LOSS [training: 0.6821489599245357 | validation: 0.861681668492128]
	TIME [epoch: 55.8 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931455775512839		[learning rate: 7.9577e-05]
	Learning Rate: 7.95774e-05
	LOSS [training: 0.6931455775512839 | validation: 0.8400724395430186]
	TIME [epoch: 55.9 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6662551270596038		[learning rate: 7.9001e-05]
	Learning Rate: 7.90008e-05
	LOSS [training: 0.6662551270596038 | validation: 0.830281050555022]
	TIME [epoch: 55.8 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.672820457744334		[learning rate: 7.8428e-05]
	Learning Rate: 7.84285e-05
	LOSS [training: 0.672820457744334 | validation: 0.8409493209574177]
	TIME [epoch: 55.9 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6747286556725525		[learning rate: 7.786e-05]
	Learning Rate: 7.78603e-05
	LOSS [training: 0.6747286556725525 | validation: 0.8415237235768426]
	TIME [epoch: 55.9 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6707358659370546		[learning rate: 7.7296e-05]
	Learning Rate: 7.72962e-05
	LOSS [training: 0.6707358659370546 | validation: 0.8335053147556546]
	TIME [epoch: 55.8 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6730652107991066		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.6730652107991066 | validation: 0.8355027809867541]
	TIME [epoch: 55.9 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.674697333943208		[learning rate: 7.618e-05]
	Learning Rate: 7.61802e-05
	LOSS [training: 0.674697333943208 | validation: 0.8525613587969296]
	TIME [epoch: 55.9 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6735869368318066		[learning rate: 7.5628e-05]
	Learning Rate: 7.56283e-05
	LOSS [training: 0.6735869368318066 | validation: 0.8486301337500561]
	TIME [epoch: 55.9 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6632630502427524		[learning rate: 7.508e-05]
	Learning Rate: 7.50804e-05
	LOSS [training: 0.6632630502427524 | validation: 0.8552305389602783]
	TIME [epoch: 55.8 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688353016491172		[learning rate: 7.4536e-05]
	Learning Rate: 7.45364e-05
	LOSS [training: 0.6688353016491172 | validation: 0.8629563713527486]
	TIME [epoch: 55.9 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610735671913117		[learning rate: 7.3996e-05]
	Learning Rate: 7.39964e-05
	LOSS [training: 0.6610735671913117 | validation: 0.851326883271267]
	TIME [epoch: 55.8 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680736230892338		[learning rate: 7.346e-05]
	Learning Rate: 7.34603e-05
	LOSS [training: 0.6680736230892338 | validation: 0.8495344485164824]
	TIME [epoch: 55.8 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738391340696857		[learning rate: 7.2928e-05]
	Learning Rate: 7.29281e-05
	LOSS [training: 0.6738391340696857 | validation: 0.8231222867622257]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_727.pth
	Model improved!!!
EPOCH 728/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647661751625366		[learning rate: 7.24e-05]
	Learning Rate: 7.23997e-05
	LOSS [training: 0.6647661751625366 | validation: 0.8423190716648892]
	TIME [epoch: 55.9 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6883435499212613		[learning rate: 7.1875e-05]
	Learning Rate: 7.18752e-05
	LOSS [training: 0.6883435499212613 | validation: 0.8661168465020419]
	TIME [epoch: 55.9 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839627493320528		[learning rate: 7.1354e-05]
	Learning Rate: 7.13545e-05
	LOSS [training: 0.6839627493320528 | validation: 0.8665943390921842]
	TIME [epoch: 55.9 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6805799436266069		[learning rate: 7.0838e-05]
	Learning Rate: 7.08375e-05
	LOSS [training: 0.6805799436266069 | validation: 0.8304160962644356]
	TIME [epoch: 55.9 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650821335572515		[learning rate: 7.0324e-05]
	Learning Rate: 7.03243e-05
	LOSS [training: 0.6650821335572515 | validation: 0.8378318021577704]
	TIME [epoch: 55.9 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704058598992516		[learning rate: 6.9815e-05]
	Learning Rate: 6.98148e-05
	LOSS [training: 0.6704058598992516 | validation: 0.8301314168008075]
	TIME [epoch: 55.9 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589379964313999		[learning rate: 6.9309e-05]
	Learning Rate: 6.9309e-05
	LOSS [training: 0.6589379964313999 | validation: 0.837159021994798]
	TIME [epoch: 55.9 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798638705148449		[learning rate: 6.8807e-05]
	Learning Rate: 6.88069e-05
	LOSS [training: 0.6798638705148449 | validation: 0.8444814039630439]
	TIME [epoch: 55.9 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706424572768854		[learning rate: 6.8308e-05]
	Learning Rate: 6.83084e-05
	LOSS [training: 0.6706424572768854 | validation: 0.8478669580917656]
	TIME [epoch: 55.9 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640984830292012		[learning rate: 6.7813e-05]
	Learning Rate: 6.78134e-05
	LOSS [training: 0.6640984830292012 | validation: 0.8454200066568185]
	TIME [epoch: 55.9 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6624540000252094		[learning rate: 6.7322e-05]
	Learning Rate: 6.73222e-05
	LOSS [training: 0.6624540000252094 | validation: 0.8422268468452339]
	TIME [epoch: 55.9 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6654136268938888		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.6654136268938888 | validation: 0.8215202833264861]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_739.pth
	Model improved!!!
EPOCH 740/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657532898088316		[learning rate: 6.635e-05]
	Learning Rate: 6.63502e-05
	LOSS [training: 0.6657532898088316 | validation: 0.8407583121879398]
	TIME [epoch: 55.9 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.658944026511508		[learning rate: 6.587e-05]
	Learning Rate: 6.58695e-05
	LOSS [training: 0.658944026511508 | validation: 0.8446077365758449]
	TIME [epoch: 55.9 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6595873786809963		[learning rate: 6.5392e-05]
	Learning Rate: 6.53923e-05
	LOSS [training: 0.6595873786809963 | validation: 0.8393823080367857]
	TIME [epoch: 55.9 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.668958687963441		[learning rate: 6.4919e-05]
	Learning Rate: 6.49185e-05
	LOSS [training: 0.668958687963441 | validation: 0.8341376675988394]
	TIME [epoch: 55.9 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667404081296827		[learning rate: 6.4448e-05]
	Learning Rate: 6.44482e-05
	LOSS [training: 0.6667404081296827 | validation: 0.8489985026322968]
	TIME [epoch: 55.8 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6803063347895772		[learning rate: 6.3981e-05]
	Learning Rate: 6.39813e-05
	LOSS [training: 0.6803063347895772 | validation: 0.8931468657880578]
	TIME [epoch: 55.9 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6896923996270926		[learning rate: 6.3518e-05]
	Learning Rate: 6.35177e-05
	LOSS [training: 0.6896923996270926 | validation: 0.8507423943549874]
	TIME [epoch: 55.9 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6717604150396767		[learning rate: 6.3058e-05]
	Learning Rate: 6.30575e-05
	LOSS [training: 0.6717604150396767 | validation: 0.8222546651162645]
	TIME [epoch: 55.9 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739732297546281		[learning rate: 6.2601e-05]
	Learning Rate: 6.26007e-05
	LOSS [training: 0.6739732297546281 | validation: 0.8499668961352589]
	TIME [epoch: 55.9 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6607623635107573		[learning rate: 6.2147e-05]
	Learning Rate: 6.21471e-05
	LOSS [training: 0.6607623635107573 | validation: 0.8314991088296739]
	TIME [epoch: 55.9 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.67424710554239		[learning rate: 6.1697e-05]
	Learning Rate: 6.16969e-05
	LOSS [training: 0.67424710554239 | validation: 0.8359501010550324]
	TIME [epoch: 55.9 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6693818271980552		[learning rate: 6.125e-05]
	Learning Rate: 6.12499e-05
	LOSS [training: 0.6693818271980552 | validation: 0.8317197142006931]
	TIME [epoch: 55.9 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6614739271157049		[learning rate: 6.0806e-05]
	Learning Rate: 6.08061e-05
	LOSS [training: 0.6614739271157049 | validation: 0.8453599929201984]
	TIME [epoch: 55.9 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6687479997962449		[learning rate: 6.0366e-05]
	Learning Rate: 6.03656e-05
	LOSS [training: 0.6687479997962449 | validation: 0.8296298070442686]
	TIME [epoch: 55.9 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6749744044666814		[learning rate: 5.9928e-05]
	Learning Rate: 5.99283e-05
	LOSS [training: 0.6749744044666814 | validation: 0.8365792612714827]
	TIME [epoch: 55.9 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6638539388229633		[learning rate: 5.9494e-05]
	Learning Rate: 5.94941e-05
	LOSS [training: 0.6638539388229633 | validation: 0.8321195454852972]
	TIME [epoch: 55.9 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6615251408909701		[learning rate: 5.9063e-05]
	Learning Rate: 5.90631e-05
	LOSS [training: 0.6615251408909701 | validation: 0.8237030479633941]
	TIME [epoch: 55.9 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6664232004542885		[learning rate: 5.8635e-05]
	Learning Rate: 5.86351e-05
	LOSS [training: 0.6664232004542885 | validation: 0.8447408385174293]
	TIME [epoch: 55.9 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709567004898128		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.6709567004898128 | validation: 0.8361786102521278]
	TIME [epoch: 55.9 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616111680144854		[learning rate: 5.7789e-05]
	Learning Rate: 5.77886e-05
	LOSS [training: 0.6616111680144854 | validation: 0.8452752530977475]
	TIME [epoch: 55.8 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647960904765735		[learning rate: 5.737e-05]
	Learning Rate: 5.73699e-05
	LOSS [training: 0.6647960904765735 | validation: 0.8295999005823684]
	TIME [epoch: 55.8 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6722974595868934		[learning rate: 5.6954e-05]
	Learning Rate: 5.69543e-05
	LOSS [training: 0.6722974595868934 | validation: 0.8303840138523129]
	TIME [epoch: 55.9 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697208619724659		[learning rate: 5.6542e-05]
	Learning Rate: 5.65417e-05
	LOSS [training: 0.6697208619724659 | validation: 0.8418073046011212]
	TIME [epoch: 55.8 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739336992949283		[learning rate: 5.6132e-05]
	Learning Rate: 5.6132e-05
	LOSS [training: 0.6739336992949283 | validation: 0.8425943658974924]
	TIME [epoch: 55.9 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6752901272761473		[learning rate: 5.5725e-05]
	Learning Rate: 5.57253e-05
	LOSS [training: 0.6752901272761473 | validation: 0.8218625826447896]
	TIME [epoch: 55.9 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6758893127365906		[learning rate: 5.5322e-05]
	Learning Rate: 5.53216e-05
	LOSS [training: 0.6758893127365906 | validation: 0.8372842992685099]
	TIME [epoch: 55.9 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739034942761448		[learning rate: 5.4921e-05]
	Learning Rate: 5.49208e-05
	LOSS [training: 0.6739034942761448 | validation: 0.8317402678704817]
	TIME [epoch: 55.9 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6700609073655815		[learning rate: 5.4523e-05]
	Learning Rate: 5.45229e-05
	LOSS [training: 0.6700609073655815 | validation: 0.8306900559273863]
	TIME [epoch: 55.9 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763789484030895		[learning rate: 5.4128e-05]
	Learning Rate: 5.41279e-05
	LOSS [training: 0.6763789484030895 | validation: 0.817861296866096]
	TIME [epoch: 55.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_768.pth
	Model improved!!!
EPOCH 769/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6622351169811873		[learning rate: 5.3736e-05]
	Learning Rate: 5.37357e-05
	LOSS [training: 0.6622351169811873 | validation: 0.8452789961930158]
	TIME [epoch: 55.9 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.651250890528301		[learning rate: 5.3346e-05]
	Learning Rate: 5.33464e-05
	LOSS [training: 0.651250890528301 | validation: 0.8235743594904747]
	TIME [epoch: 56 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6739772365029641		[learning rate: 5.296e-05]
	Learning Rate: 5.29599e-05
	LOSS [training: 0.6739772365029641 | validation: 0.831353121068994]
	TIME [epoch: 55.9 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6668685244809209		[learning rate: 5.2576e-05]
	Learning Rate: 5.25762e-05
	LOSS [training: 0.6668685244809209 | validation: 0.8347815385189012]
	TIME [epoch: 55.9 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6606963607093261		[learning rate: 5.2195e-05]
	Learning Rate: 5.21953e-05
	LOSS [training: 0.6606963607093261 | validation: 0.8404907892022845]
	TIME [epoch: 55.9 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598992169642026		[learning rate: 5.1817e-05]
	Learning Rate: 5.18172e-05
	LOSS [training: 0.6598992169642026 | validation: 0.8318078481946041]
	TIME [epoch: 55.9 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6560955917730944		[learning rate: 5.1442e-05]
	Learning Rate: 5.14418e-05
	LOSS [training: 0.6560955917730944 | validation: 0.8477078304818972]
	TIME [epoch: 55.9 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603242060976136		[learning rate: 5.1069e-05]
	Learning Rate: 5.10691e-05
	LOSS [training: 0.6603242060976136 | validation: 0.8236617224975955]
	TIME [epoch: 55.9 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6712408682333819		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.6712408682333819 | validation: 0.8483755474372029]
	TIME [epoch: 55.9 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683464724672474		[learning rate: 5.0332e-05]
	Learning Rate: 5.03318e-05
	LOSS [training: 0.6683464724672474 | validation: 0.8475189262636613]
	TIME [epoch: 55.8 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866539161429295		[learning rate: 4.9967e-05]
	Learning Rate: 4.99671e-05
	LOSS [training: 0.6866539161429295 | validation: 0.8474317477589428]
	TIME [epoch: 55.8 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760607421069138		[learning rate: 4.9605e-05]
	Learning Rate: 4.96051e-05
	LOSS [training: 0.6760607421069138 | validation: 0.8559873513904162]
	TIME [epoch: 55.8 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6652330875715343		[learning rate: 4.9246e-05]
	Learning Rate: 4.92457e-05
	LOSS [training: 0.6652330875715343 | validation: 0.8301108837933876]
	TIME [epoch: 55.9 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6639542222718147		[learning rate: 4.8889e-05]
	Learning Rate: 4.88889e-05
	LOSS [training: 0.6639542222718147 | validation: 0.8345339231074087]
	TIME [epoch: 55.8 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6586870476346904		[learning rate: 4.8535e-05]
	Learning Rate: 4.85347e-05
	LOSS [training: 0.6586870476346904 | validation: 0.8459428711623702]
	TIME [epoch: 55.8 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6625991646797003		[learning rate: 4.8183e-05]
	Learning Rate: 4.81831e-05
	LOSS [training: 0.6625991646797003 | validation: 0.8404933442382378]
	TIME [epoch: 55.8 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704430246962778		[learning rate: 4.7834e-05]
	Learning Rate: 4.7834e-05
	LOSS [training: 0.6704430246962778 | validation: 0.8261774658450571]
	TIME [epoch: 55.8 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.664781481017723		[learning rate: 4.7487e-05]
	Learning Rate: 4.74875e-05
	LOSS [training: 0.664781481017723 | validation: 0.8259499829126947]
	TIME [epoch: 55.9 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6582100605753254		[learning rate: 4.7143e-05]
	Learning Rate: 4.71434e-05
	LOSS [training: 0.6582100605753254 | validation: 0.8414807869520806]
	TIME [epoch: 55.8 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6700018619968837		[learning rate: 4.6802e-05]
	Learning Rate: 4.68019e-05
	LOSS [training: 0.6700018619968837 | validation: 0.8369211907063538]
	TIME [epoch: 55.8 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6740918005032637		[learning rate: 4.6463e-05]
	Learning Rate: 4.64628e-05
	LOSS [training: 0.6740918005032637 | validation: 0.8356108458281587]
	TIME [epoch: 55.9 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762613641011462		[learning rate: 4.6126e-05]
	Learning Rate: 4.61262e-05
	LOSS [training: 0.6762613641011462 | validation: 0.8302013619385153]
	TIME [epoch: 55.8 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6668773565488153		[learning rate: 4.5792e-05]
	Learning Rate: 4.5792e-05
	LOSS [training: 0.6668773565488153 | validation: 0.830376673805145]
	TIME [epoch: 55.9 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.665276404854771		[learning rate: 4.546e-05]
	Learning Rate: 4.54602e-05
	LOSS [training: 0.665276404854771 | validation: 0.8531932033623005]
	TIME [epoch: 55.8 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616216884415623		[learning rate: 4.5131e-05]
	Learning Rate: 4.51309e-05
	LOSS [training: 0.6616216884415623 | validation: 0.8455140016694203]
	TIME [epoch: 55.8 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6704555090844395		[learning rate: 4.4804e-05]
	Learning Rate: 4.48039e-05
	LOSS [training: 0.6704555090844395 | validation: 0.8472462775955926]
	TIME [epoch: 55.8 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694106229599236		[learning rate: 4.4479e-05]
	Learning Rate: 4.44793e-05
	LOSS [training: 0.6694106229599236 | validation: 0.8416870393631719]
	TIME [epoch: 55.8 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6740719294681085		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.6740719294681085 | validation: 0.8362754110765946]
	TIME [epoch: 55.8 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667211336954778		[learning rate: 4.3837e-05]
	Learning Rate: 4.38371e-05
	LOSS [training: 0.6667211336954778 | validation: 0.8313697397236899]
	TIME [epoch: 55.8 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6602623281375753		[learning rate: 4.352e-05]
	Learning Rate: 4.35195e-05
	LOSS [training: 0.6602623281375753 | validation: 0.8458248200595315]
	TIME [epoch: 55.9 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6566362222545856		[learning rate: 4.3204e-05]
	Learning Rate: 4.32042e-05
	LOSS [training: 0.6566362222545856 | validation: 0.8411938055893307]
	TIME [epoch: 55.8 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545206014450642		[learning rate: 4.2891e-05]
	Learning Rate: 4.28912e-05
	LOSS [training: 0.6545206014450642 | validation: 0.8072742183995509]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_800.pth
	Model improved!!!
EPOCH 801/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6576011183655596		[learning rate: 4.258e-05]
	Learning Rate: 4.25805e-05
	LOSS [training: 0.6576011183655596 | validation: 0.8050659546248937]
	TIME [epoch: 55.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv1_20241205_183101/states/model_phiq_1a_v_klv1_801.pth
	Model improved!!!
EPOCH 802/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6565846022440937		[learning rate: 4.2272e-05]
	Learning Rate: 4.2272e-05
	LOSS [training: 0.6565846022440937 | validation: 0.8221128569220035]
	TIME [epoch: 55.8 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6585317930312999		[learning rate: 4.1966e-05]
	Learning Rate: 4.19657e-05
	LOSS [training: 0.6585317930312999 | validation: 0.8178143695372809]
	TIME [epoch: 55.8 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6633154916995871		[learning rate: 4.1662e-05]
	Learning Rate: 4.16617e-05
	LOSS [training: 0.6633154916995871 | validation: 0.8181293037669166]
	TIME [epoch: 55.8 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575491387921566		[learning rate: 4.136e-05]
	Learning Rate: 4.13599e-05
	LOSS [training: 0.6575491387921566 | validation: 0.8172758936628441]
	TIME [epoch: 55.8 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581252934783002		[learning rate: 4.106e-05]
	Learning Rate: 4.10602e-05
	LOSS [training: 0.6581252934783002 | validation: 0.8116813571915353]
	TIME [epoch: 55.8 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6672750250108841		[learning rate: 4.0763e-05]
	Learning Rate: 4.07627e-05
	LOSS [training: 0.6672750250108841 | validation: 0.8237623610507969]
	TIME [epoch: 55.8 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6537833048130985		[learning rate: 4.0467e-05]
	Learning Rate: 4.04674e-05
	LOSS [training: 0.6537833048130985 | validation: 0.8291798093979112]
	TIME [epoch: 55.8 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6531867559346123		[learning rate: 4.0174e-05]
	Learning Rate: 4.01742e-05
	LOSS [training: 0.6531867559346123 | validation: 0.8373247245920054]
	TIME [epoch: 55.9 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577077601190711		[learning rate: 3.9883e-05]
	Learning Rate: 3.98832e-05
	LOSS [training: 0.6577077601190711 | validation: 0.8338133469709808]
	TIME [epoch: 55.8 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.661495382176262		[learning rate: 3.9594e-05]
	Learning Rate: 3.95942e-05
	LOSS [training: 0.661495382176262 | validation: 0.8342912222085512]
	TIME [epoch: 55.9 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6628800300316481		[learning rate: 3.9307e-05]
	Learning Rate: 3.93073e-05
	LOSS [training: 0.6628800300316481 | validation: 0.824892106367846]
	TIME [epoch: 55.8 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6569521421397112		[learning rate: 3.9023e-05]
	Learning Rate: 3.90226e-05
	LOSS [training: 0.6569521421397112 | validation: 0.8167651990113105]
	TIME [epoch: 55.9 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646694443349626		[learning rate: 3.874e-05]
	Learning Rate: 3.87399e-05
	LOSS [training: 0.6646694443349626 | validation: 0.8243768694676633]
	TIME [epoch: 55.8 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6623507868046625		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.6623507868046625 | validation: 0.8468803376389002]
	TIME [epoch: 55.9 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6638837353759381		[learning rate: 3.8181e-05]
	Learning Rate: 3.81806e-05
	LOSS [training: 0.6638837353759381 | validation: 0.822629158469801]
	TIME [epoch: 55.9 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.65431611924716		[learning rate: 3.7904e-05]
	Learning Rate: 3.79039e-05
	LOSS [training: 0.65431611924716 | validation: 0.8208892417870661]
	TIME [epoch: 55.8 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6467149292606571		[learning rate: 3.7629e-05]
	Learning Rate: 3.76293e-05
	LOSS [training: 0.6467149292606571 | validation: 0.8231478765975284]
	TIME [epoch: 55.9 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640505179047129		[learning rate: 3.7357e-05]
	Learning Rate: 3.73567e-05
	LOSS [training: 0.6640505179047129 | validation: 0.8361773546510716]
	TIME [epoch: 55.8 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515035614369951		[learning rate: 3.7086e-05]
	Learning Rate: 3.70861e-05
	LOSS [training: 0.6515035614369951 | validation: 0.838339852918619]
	TIME [epoch: 55.8 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6523492741587809		[learning rate: 3.6817e-05]
	Learning Rate: 3.68174e-05
	LOSS [training: 0.6523492741587809 | validation: 0.8318304817169553]
	TIME [epoch: 55.9 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6509593900608315		[learning rate: 3.6551e-05]
	Learning Rate: 3.65506e-05
	LOSS [training: 0.6509593900608315 | validation: 0.8312222078239995]
	TIME [epoch: 55.9 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6549000021231425		[learning rate: 3.6286e-05]
	Learning Rate: 3.62858e-05
	LOSS [training: 0.6549000021231425 | validation: 0.830773109346279]
	TIME [epoch: 55.8 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513807671258061		[learning rate: 3.6023e-05]
	Learning Rate: 3.60229e-05
	LOSS [training: 0.6513807671258061 | validation: 0.8287915905924716]
	TIME [epoch: 55.9 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6608915819637176		[learning rate: 3.5762e-05]
	Learning Rate: 3.57619e-05
	LOSS [training: 0.6608915819637176 | validation: 0.8338800173252456]
	TIME [epoch: 55.9 sec]
EPOCH 826/1000:
	Training over batches...
