Args:
Namespace(name='model_phiq_1a_v_klv2', outdir='out/model_training/model_phiq_1a_v_klv2', training_data='data/training_data/data_phiq_1a/training', validation_data='data/training_data/data_phiq_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[100, 250, 500], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.01, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='klv2', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1344888275

Training model...

Saving initial model state to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 4/4] avg loss: 9.141619318138313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.141619318138313 | validation: 9.176582087618389]
	TIME [epoch: 415 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.899103453588491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.899103453588491 | validation: 8.887356492797275]
	TIME [epoch: 6.21 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.425563800761786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.425563800761786 | validation: 8.32366983414968]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.128465382352507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.128465382352507 | validation: 8.210569051444192]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.038447668344173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.038447668344173 | validation: 8.239904827439236]
	TIME [epoch: 6.14 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.013553442697358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.013553442697358 | validation: 8.065829651435232]
	TIME [epoch: 6.14 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.932719346668394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.932719346668394 | validation: 9.503116642479899]
	TIME [epoch: 6.15 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 4/4] avg loss: 9.13799069718529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.13799069718529 | validation: 8.28929147809924]
	TIME [epoch: 6.13 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.286974540476573		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.286974540476573 | validation: 8.119562527506119]
	TIME [epoch: 6.12 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.217639287154253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.217639287154253 | validation: 8.301899707514771]
	TIME [epoch: 6.14 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.78540765083784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.78540765083784 | validation: 8.385625070237628]
	TIME [epoch: 6.13 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.490882646588354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.490882646588354 | validation: 8.015856603815722]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 4/4] avg loss: 8.093855199924633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.093855199924633 | validation: 7.942395432170066]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.91714529529334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.91714529529334 | validation: 7.665925447618974]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.686741373016998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.686741373016998 | validation: 7.609121910836959]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.588774902634343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.588774902634343 | validation: 7.6594060012033305]
	TIME [epoch: 6.12 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.702734374449532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.702734374449532 | validation: 7.789886293851817]
	TIME [epoch: 6.13 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.7367180752698195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7367180752698195 | validation: 7.239276981325436]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 4/4] avg loss: 7.041597183242107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.041597183242107 | validation: 6.879887076968174]
	TIME [epoch: 6.15 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.676668050647349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.676668050647349 | validation: 6.6386659441202]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.4903041731431985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4903041731431985 | validation: 6.415161897735201]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.353574287819569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.353574287819569 | validation: 6.408198574582816]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_22.pth
	Model improved!!!
EPOCH 23/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.256795841422889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.256795841422889 | validation: 6.442774949557434]
	TIME [epoch: 6.12 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.231009584182479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.231009584182479 | validation: 6.279327811496865]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 4/4] avg loss: 6.08955460091357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.08955460091357 | validation: 6.073837273737913]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_25.pth
	Model improved!!!
EPOCH 26/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.966410049421184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966410049421184 | validation: 5.9395191871444055]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_26.pth
	Model improved!!!
EPOCH 27/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.698920312003223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.698920312003223 | validation: 5.781263552025239]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_27.pth
	Model improved!!!
EPOCH 28/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.4881224987309905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4881224987309905 | validation: 5.617415947002782]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_28.pth
	Model improved!!!
EPOCH 29/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.238971837434081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.238971837434081 | validation: 5.543978350309223]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.010908766913885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.010908766913885 | validation: 5.436178212881288]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.997180158778967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.997180158778967 | validation: 5.127193952114595]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.7629035427244775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.7629035427244775 | validation: 4.890562873009253]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_32.pth
	Model improved!!!
EPOCH 33/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.6013065321327495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6013065321327495 | validation: 4.693242119977393]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.420835096612194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.420835096612194 | validation: 4.496010608898125]
	TIME [epoch: 6.14 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.332843265791998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.332843265791998 | validation: 4.492686063700179]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_35.pth
	Model improved!!!
EPOCH 36/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.645888925040554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.645888925040554 | validation: 4.460138408790167]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_36.pth
	Model improved!!!
EPOCH 37/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.182020198394827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.182020198394827 | validation: 4.289127124578312]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.974328294473326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.974328294473326 | validation: 4.231807939954014]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_38.pth
	Model improved!!!
EPOCH 39/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.19160059653883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.19160059653883 | validation: 5.6656383865406585]
	TIME [epoch: 6.13 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.544979656164953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.544979656164953 | validation: 5.487022956289195]
	TIME [epoch: 6.11 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.4365582862796025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4365582862796025 | validation: 4.666119599826496]
	TIME [epoch: 6.11 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 4/4] avg loss: 5.1322590197511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.1322590197511 | validation: 4.5817798544936235]
	TIME [epoch: 6.12 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.58364585901694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.58364585901694 | validation: 4.337459652391488]
	TIME [epoch: 6.12 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.217449111983394		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217449111983394 | validation: 4.281569340608485]
	TIME [epoch: 6.13 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.148409854412978		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.148409854412978 | validation: 4.188828492445423]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_45.pth
	Model improved!!!
EPOCH 46/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.066742665621271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.066742665621271 | validation: 4.100629422585344]
	TIME [epoch: 6.15 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_46.pth
	Model improved!!!
EPOCH 47/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.005869300431586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.005869300431586 | validation: 4.055720631827001]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_47.pth
	Model improved!!!
EPOCH 48/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.980833681169032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.980833681169032 | validation: 3.9885056222863033]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8983645574642996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8983645574642996 | validation: 3.9124905128453467]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.8447713906744836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8447713906744836 | validation: 3.8293797949898374]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_50.pth
	Model improved!!!
EPOCH 51/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.7901964905049743		[learning rate: 0.0099456]
	Learning Rate: 0.00994561
	LOSS [training: 3.7901964905049743 | validation: 3.7751852386356664]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.728899529209321		[learning rate: 0.0098736]
	Learning Rate: 0.00987356
	LOSS [training: 3.728899529209321 | validation: 3.747561780088459]
	TIME [epoch: 6.11 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_52.pth
	Model improved!!!
EPOCH 53/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.690774936466		[learning rate: 0.009802]
	Learning Rate: 0.00980202
	LOSS [training: 3.690774936466 | validation: 3.619147705391053]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.602121589655263		[learning rate: 0.009731]
	Learning Rate: 0.00973101
	LOSS [training: 3.602121589655263 | validation: 3.800936915062561]
	TIME [epoch: 6.14 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.6167526997331505		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.6167526997331505 | validation: 3.6587885920671415]
	TIME [epoch: 6.12 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.7070130656336033		[learning rate: 0.0095905]
	Learning Rate: 0.00959052
	LOSS [training: 3.7070130656336033 | validation: 3.9723269233719143]
	TIME [epoch: 6.13 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.615446748867634		[learning rate: 0.009521]
	Learning Rate: 0.00952104
	LOSS [training: 3.615446748867634 | validation: 3.67925140061764]
	TIME [epoch: 6.12 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.659721380617995		[learning rate: 0.0094521]
	Learning Rate: 0.00945206
	LOSS [training: 3.659721380617995 | validation: 3.387277703891624]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_58.pth
	Model improved!!!
EPOCH 59/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.47370935417817		[learning rate: 0.0093836]
	Learning Rate: 0.00938358
	LOSS [training: 3.47370935417817 | validation: 3.405606291099362]
	TIME [epoch: 6.13 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.4327442236706185		[learning rate: 0.0093156]
	Learning Rate: 0.00931559
	LOSS [training: 3.4327442236706185 | validation: 3.5169817783056123]
	TIME [epoch: 6.13 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.462106159567619		[learning rate: 0.0092481]
	Learning Rate: 0.0092481
	LOSS [training: 3.462106159567619 | validation: 3.325295594671566]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_61.pth
	Model improved!!!
EPOCH 62/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.321894184448439		[learning rate: 0.0091811]
	Learning Rate: 0.0091811
	LOSS [training: 3.321894184448439 | validation: 3.1748053742785167]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_62.pth
	Model improved!!!
EPOCH 63/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.5984310287485415		[learning rate: 0.0091146]
	Learning Rate: 0.00911458
	LOSS [training: 3.5984310287485415 | validation: 3.6144922126988135]
	TIME [epoch: 6.13 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.517874535050843		[learning rate: 0.0090485]
	Learning Rate: 0.00904855
	LOSS [training: 3.517874535050843 | validation: 3.869688815879013]
	TIME [epoch: 6.12 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.408547943744853		[learning rate: 0.008983]
	Learning Rate: 0.00898299
	LOSS [training: 3.408547943744853 | validation: 3.2345803544316736]
	TIME [epoch: 6.13 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.297175155486541		[learning rate: 0.0089179]
	Learning Rate: 0.00891791
	LOSS [training: 3.297175155486541 | validation: 3.154358414154558]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.2230177421032216		[learning rate: 0.0088533]
	Learning Rate: 0.0088533
	LOSS [training: 3.2230177421032216 | validation: 3.132658573528981]
	TIME [epoch: 6.13 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3824950851264797		[learning rate: 0.0087892]
	Learning Rate: 0.00878916
	LOSS [training: 3.3824950851264797 | validation: 3.4173134826916796]
	TIME [epoch: 6.13 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.419795983115728		[learning rate: 0.0087255]
	Learning Rate: 0.00872548
	LOSS [training: 3.419795983115728 | validation: 3.196198277651308]
	TIME [epoch: 6.12 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.269256682412665		[learning rate: 0.0086623]
	Learning Rate: 0.00866227
	LOSS [training: 3.269256682412665 | validation: 3.357314505517528]
	TIME [epoch: 6.13 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.2909805387422857		[learning rate: 0.0085995]
	Learning Rate: 0.00859951
	LOSS [training: 3.2909805387422857 | validation: 3.1895467389169063]
	TIME [epoch: 6.12 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.176442363420909		[learning rate: 0.0085372]
	Learning Rate: 0.00853721
	LOSS [training: 3.176442363420909 | validation: 3.237075103532142]
	TIME [epoch: 6.12 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1987805293384937		[learning rate: 0.0084754]
	Learning Rate: 0.00847535
	LOSS [training: 3.1987805293384937 | validation: 3.0058445915514267]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_73.pth
	Model improved!!!
EPOCH 74/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.114574245237633		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 3.114574245237633 | validation: 2.998473348472688]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.101947894497875		[learning rate: 0.008353]
	Learning Rate: 0.00835299
	LOSS [training: 3.101947894497875 | validation: 3.3875822360023546]
	TIME [epoch: 6.12 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.4272060819644103		[learning rate: 0.0082925]
	Learning Rate: 0.00829248
	LOSS [training: 3.4272060819644103 | validation: 3.2301484271884164]
	TIME [epoch: 6.12 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.343419886172083		[learning rate: 0.0082324]
	Learning Rate: 0.0082324
	LOSS [training: 3.343419886172083 | validation: 3.0346902658452457]
	TIME [epoch: 6.12 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1664149023883903		[learning rate: 0.0081728]
	Learning Rate: 0.00817275
	LOSS [training: 3.1664149023883903 | validation: 3.0809373213703126]
	TIME [epoch: 6.12 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0944796425270313		[learning rate: 0.0081135]
	Learning Rate: 0.00811354
	LOSS [training: 3.0944796425270313 | validation: 2.9950196218607408]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.048372254744547		[learning rate: 0.0080548]
	Learning Rate: 0.00805476
	LOSS [training: 3.048372254744547 | validation: 3.191460245219954]
	TIME [epoch: 6.13 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0681942752897515		[learning rate: 0.0079964]
	Learning Rate: 0.0079964
	LOSS [training: 3.0681942752897515 | validation: 3.489209943048821]
	TIME [epoch: 6.12 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3892092025617377		[learning rate: 0.0079385]
	Learning Rate: 0.00793847
	LOSS [training: 3.3892092025617377 | validation: 3.566611389986956]
	TIME [epoch: 6.11 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.5847479760797345		[learning rate: 0.007881]
	Learning Rate: 0.00788096
	LOSS [training: 3.5847479760797345 | validation: 3.9846467366883775]
	TIME [epoch: 6.12 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.42768823590307		[learning rate: 0.0078239]
	Learning Rate: 0.00782386
	LOSS [training: 4.42768823590307 | validation: 4.470950585691247]
	TIME [epoch: 6.12 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.333538677737527		[learning rate: 0.0077672]
	Learning Rate: 0.00776718
	LOSS [training: 4.333538677737527 | validation: 3.5367176604070467]
	TIME [epoch: 6.12 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.321399655577337		[learning rate: 0.0077109]
	Learning Rate: 0.0077109
	LOSS [training: 4.321399655577337 | validation: 3.2198469226955235]
	TIME [epoch: 6.16 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.28402094752962		[learning rate: 0.007655]
	Learning Rate: 0.00765504
	LOSS [training: 3.28402094752962 | validation: 3.373568009809906]
	TIME [epoch: 6.12 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1974156700954315		[learning rate: 0.0075996]
	Learning Rate: 0.00759958
	LOSS [training: 3.1974156700954315 | validation: 3.144014940193812]
	TIME [epoch: 6.12 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1054054451196254		[learning rate: 0.0075445]
	Learning Rate: 0.00754452
	LOSS [training: 3.1054054451196254 | validation: 2.98286945949679]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_89.pth
	Model improved!!!
EPOCH 90/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0567286341111726		[learning rate: 0.0074899]
	Learning Rate: 0.00748986
	LOSS [training: 3.0567286341111726 | validation: 3.1654790693439105]
	TIME [epoch: 6.12 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0893620178047883		[learning rate: 0.0074356]
	Learning Rate: 0.0074356
	LOSS [training: 3.0893620178047883 | validation: 3.0260628366268993]
	TIME [epoch: 6.12 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0218957879953168		[learning rate: 0.0073817]
	Learning Rate: 0.00738173
	LOSS [training: 3.0218957879953168 | validation: 3.156702699308397]
	TIME [epoch: 6.11 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.1433701293403753		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 3.1433701293403753 | validation: 3.0210906374364153]
	TIME [epoch: 6.12 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.031080378453317		[learning rate: 0.0072752]
	Learning Rate: 0.00727515
	LOSS [training: 3.031080378453317 | validation: 2.8146374111757684]
	TIME [epoch: 6.12 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.951050200514746		[learning rate: 0.0072224]
	Learning Rate: 0.00722244
	LOSS [training: 2.951050200514746 | validation: 3.0009677281460876]
	TIME [epoch: 6.12 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.122804153693279		[learning rate: 0.0071701]
	Learning Rate: 0.00717012
	LOSS [training: 3.122804153693279 | validation: 3.015167632503289]
	TIME [epoch: 6.12 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.955844109016801		[learning rate: 0.0071182]
	Learning Rate: 0.00711817
	LOSS [training: 2.955844109016801 | validation: 2.8176122689339396]
	TIME [epoch: 6.12 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8651359091552067		[learning rate: 0.0070666]
	Learning Rate: 0.0070666
	LOSS [training: 2.8651359091552067 | validation: 2.8522056045882427]
	TIME [epoch: 6.12 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8473129356498927		[learning rate: 0.0070154]
	Learning Rate: 0.0070154
	LOSS [training: 2.8473129356498927 | validation: 2.901937052529693]
	TIME [epoch: 6.12 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.846723319812921		[learning rate: 0.0069646]
	Learning Rate: 0.00696458
	LOSS [training: 2.846723319812921 | validation: 2.961132552359908]
	TIME [epoch: 6.12 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.7272257668251854		[learning rate: 0.0069141]
	Learning Rate: 0.00691412
	LOSS [training: 3.7272257668251854 | validation: 4.193020307654745]
	TIME [epoch: 439 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.967655629266738		[learning rate: 0.006864]
	Learning Rate: 0.00686403
	LOSS [training: 4.967655629266738 | validation: 5.336463406184443]
	TIME [epoch: 12.1 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.941578380125788		[learning rate: 0.0068143]
	Learning Rate: 0.0068143
	LOSS [training: 4.941578380125788 | validation: 4.193375793781348]
	TIME [epoch: 12.1 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 4/4] avg loss: 4.4906679446231905		[learning rate: 0.0067649]
	Learning Rate: 0.00676493
	LOSS [training: 4.4906679446231905 | validation: 3.6064996500935846]
	TIME [epoch: 12.1 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.916847125360145		[learning rate: 0.0067159]
	Learning Rate: 0.00671592
	LOSS [training: 3.916847125360145 | validation: 3.2577045628765093]
	TIME [epoch: 12.1 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3918570521297755		[learning rate: 0.0066673]
	Learning Rate: 0.00666726
	LOSS [training: 3.3918570521297755 | validation: 2.981663346398246]
	TIME [epoch: 12.1 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.116975628853653		[learning rate: 0.006619]
	Learning Rate: 0.00661896
	LOSS [training: 3.116975628853653 | validation: 2.8961951211748582]
	TIME [epoch: 12.1 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.027829395074526		[learning rate: 0.006571]
	Learning Rate: 0.006571
	LOSS [training: 3.027829395074526 | validation: 2.867418483864881]
	TIME [epoch: 12.1 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.979990209466123		[learning rate: 0.0065234]
	Learning Rate: 0.00652339
	LOSS [training: 2.979990209466123 | validation: 2.8387211248697453]
	TIME [epoch: 12.1 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.928091115663201		[learning rate: 0.0064761]
	Learning Rate: 0.00647613
	LOSS [training: 2.928091115663201 | validation: 2.7897526598476086]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_110.pth
	Model improved!!!
EPOCH 111/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.805204061085693		[learning rate: 0.0064292]
	Learning Rate: 0.00642921
	LOSS [training: 2.805204061085693 | validation: 2.8676984043483884]
	TIME [epoch: 12.1 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8308207881652985		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.8308207881652985 | validation: 2.7710327498847795]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_112.pth
	Model improved!!!
EPOCH 113/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6583057742924465		[learning rate: 0.0063364]
	Learning Rate: 0.00633639
	LOSS [training: 2.6583057742924465 | validation: 2.781925772169983]
	TIME [epoch: 12.1 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5921753181743705		[learning rate: 0.0062905]
	Learning Rate: 0.00629049
	LOSS [training: 2.5921753181743705 | validation: 2.6664503762975658]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_114.pth
	Model improved!!!
EPOCH 115/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5549769047929045		[learning rate: 0.0062449]
	Learning Rate: 0.00624491
	LOSS [training: 2.5549769047929045 | validation: 2.6336413867749773]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5653899108148406		[learning rate: 0.0061997]
	Learning Rate: 0.00619967
	LOSS [training: 2.5653899108148406 | validation: 3.4533441141541994]
	TIME [epoch: 12.1 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.9827618047743885		[learning rate: 0.0061548]
	Learning Rate: 0.00615475
	LOSS [training: 2.9827618047743885 | validation: 3.0774978948953424]
	TIME [epoch: 12.1 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.7272905478514864		[learning rate: 0.0061102]
	Learning Rate: 0.00611016
	LOSS [training: 2.7272905478514864 | validation: 2.6040200978152095]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_118.pth
	Model improved!!!
EPOCH 119/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5716144505283873		[learning rate: 0.0060659]
	Learning Rate: 0.00606589
	LOSS [training: 2.5716144505283873 | validation: 2.7017291945309196]
	TIME [epoch: 12.1 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.543316220620311		[learning rate: 0.0060219]
	Learning Rate: 0.00602195
	LOSS [training: 2.543316220620311 | validation: 2.502249605241369]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_120.pth
	Model improved!!!
EPOCH 121/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4614769175087625		[learning rate: 0.0059783]
	Learning Rate: 0.00597832
	LOSS [training: 2.4614769175087625 | validation: 2.5022079262782344]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_121.pth
	Model improved!!!
EPOCH 122/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4039485536806424		[learning rate: 0.005935]
	Learning Rate: 0.005935
	LOSS [training: 2.4039485536806424 | validation: 2.4327463410090595]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_122.pth
	Model improved!!!
EPOCH 123/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.5420495415813487		[learning rate: 0.005892]
	Learning Rate: 0.00589201
	LOSS [training: 2.5420495415813487 | validation: 2.5769535848380025]
	TIME [epoch: 12.1 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.485389631762994		[learning rate: 0.0058493]
	Learning Rate: 0.00584932
	LOSS [training: 2.485389631762994 | validation: 2.4570737706450414]
	TIME [epoch: 12.1 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.34624946585072		[learning rate: 0.0058069]
	Learning Rate: 0.00580694
	LOSS [training: 2.34624946585072 | validation: 2.375002184431778]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_125.pth
	Model improved!!!
EPOCH 126/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3393814510767994		[learning rate: 0.0057649]
	Learning Rate: 0.00576487
	LOSS [training: 2.3393814510767994 | validation: 2.2439925093502606]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_126.pth
	Model improved!!!
EPOCH 127/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1943554784735793		[learning rate: 0.0057231]
	Learning Rate: 0.0057231
	LOSS [training: 2.1943554784735793 | validation: 2.2821503728400234]
	TIME [epoch: 12.1 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.230840122409644		[learning rate: 0.0056816]
	Learning Rate: 0.00568164
	LOSS [training: 2.230840122409644 | validation: 2.787775232743391]
	TIME [epoch: 12.1 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.298061540921884		[learning rate: 0.0056405]
	Learning Rate: 0.00564048
	LOSS [training: 2.298061540921884 | validation: 2.206814677618853]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_129.pth
	Model improved!!!
EPOCH 130/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0400518650496915		[learning rate: 0.0055996]
	Learning Rate: 0.00559961
	LOSS [training: 2.0400518650496915 | validation: 2.119222128074597]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_130.pth
	Model improved!!!
EPOCH 131/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.099003871893549		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 2.099003871893549 | validation: 2.4785886377517135]
	TIME [epoch: 12.1 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.6871891762538365		[learning rate: 0.0055188]
	Learning Rate: 0.00551877
	LOSS [training: 2.6871891762538365 | validation: 2.5011606240220914]
	TIME [epoch: 12.1 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.552672908867779		[learning rate: 0.0054788]
	Learning Rate: 0.00547878
	LOSS [training: 2.552672908867779 | validation: 3.1346523123172725]
	TIME [epoch: 12.1 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8382252614090406		[learning rate: 0.0054391]
	Learning Rate: 0.00543909
	LOSS [training: 2.8382252614090406 | validation: 2.4522596185117838]
	TIME [epoch: 12.1 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.371826811980636		[learning rate: 0.0053997]
	Learning Rate: 0.00539968
	LOSS [training: 2.371826811980636 | validation: 2.3309680912151274]
	TIME [epoch: 12.1 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.201277862128107		[learning rate: 0.0053606]
	Learning Rate: 0.00536056
	LOSS [training: 2.201277862128107 | validation: 2.5636274558769316]
	TIME [epoch: 12.1 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4188333924476284		[learning rate: 0.0053217]
	Learning Rate: 0.00532173
	LOSS [training: 2.4188333924476284 | validation: 2.474417006801886]
	TIME [epoch: 12.1 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.294924905992634		[learning rate: 0.0052832]
	Learning Rate: 0.00528317
	LOSS [training: 2.294924905992634 | validation: 2.2777150300031677]
	TIME [epoch: 12.1 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.126653220980717		[learning rate: 0.0052449]
	Learning Rate: 0.0052449
	LOSS [training: 2.126653220980717 | validation: 2.1662183184999333]
	TIME [epoch: 12.1 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.026789336051383		[learning rate: 0.0052069]
	Learning Rate: 0.0052069
	LOSS [training: 2.026789336051383 | validation: 2.248201883146077]
	TIME [epoch: 12.1 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9631627030032948		[learning rate: 0.0051692]
	Learning Rate: 0.00516917
	LOSS [training: 1.9631627030032948 | validation: 2.2761053574011765]
	TIME [epoch: 12.1 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.376202034398019		[learning rate: 0.0051317]
	Learning Rate: 0.00513172
	LOSS [training: 2.376202034398019 | validation: 2.71403196206986]
	TIME [epoch: 12.1 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.404156815657916		[learning rate: 0.0050945]
	Learning Rate: 0.00509454
	LOSS [training: 2.404156815657916 | validation: 2.755135835678441]
	TIME [epoch: 12.1 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3252029208947746		[learning rate: 0.0050576]
	Learning Rate: 0.00505763
	LOSS [training: 2.3252029208947746 | validation: 2.3668221264217717]
	TIME [epoch: 12.1 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0538676476771993		[learning rate: 0.005021]
	Learning Rate: 0.00502099
	LOSS [training: 2.0538676476771993 | validation: 2.0327451245409316]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_145.pth
	Model improved!!!
EPOCH 146/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9037705191916077		[learning rate: 0.0049846]
	Learning Rate: 0.00498461
	LOSS [training: 1.9037705191916077 | validation: 2.16314837303688]
	TIME [epoch: 12.1 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8333921681352185		[learning rate: 0.0049485]
	Learning Rate: 0.0049485
	LOSS [training: 2.8333921681352185 | validation: 2.5428687443296605]
	TIME [epoch: 12.1 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2175119051857317		[learning rate: 0.0049126]
	Learning Rate: 0.00491265
	LOSS [training: 2.2175119051857317 | validation: 2.0643900467790344]
	TIME [epoch: 12.1 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0021092440209842		[learning rate: 0.0048771]
	Learning Rate: 0.00487706
	LOSS [training: 2.0021092440209842 | validation: 2.1288404535110477]
	TIME [epoch: 12.1 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9052351786184725		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.9052351786184725 | validation: 2.042031269464367]
	TIME [epoch: 12.1 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8541888267403022		[learning rate: 0.0048066]
	Learning Rate: 0.00480665
	LOSS [training: 1.8541888267403022 | validation: 2.384025239364374]
	TIME [epoch: 12.1 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8744981151837488		[learning rate: 0.0047718]
	Learning Rate: 0.00477182
	LOSS [training: 1.8744981151837488 | validation: 1.8905919373830864]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_152.pth
	Model improved!!!
EPOCH 153/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7502051755317793		[learning rate: 0.0047373]
	Learning Rate: 0.00473725
	LOSS [training: 1.7502051755317793 | validation: 2.7274736936501354]
	TIME [epoch: 12.1 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.053138401847565		[learning rate: 0.0047029]
	Learning Rate: 0.00470293
	LOSS [training: 2.053138401847565 | validation: 1.8939116950598258]
	TIME [epoch: 12.1 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7877536093365074		[learning rate: 0.0046689]
	Learning Rate: 0.00466886
	LOSS [training: 1.7877536093365074 | validation: 1.829026437061927]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_155.pth
	Model improved!!!
EPOCH 156/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8226411216404332		[learning rate: 0.004635]
	Learning Rate: 0.00463503
	LOSS [training: 1.8226411216404332 | validation: 2.0444966446817787]
	TIME [epoch: 12.1 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.680565751789997		[learning rate: 0.0046015]
	Learning Rate: 0.00460145
	LOSS [training: 1.680565751789997 | validation: 1.9998591700808235]
	TIME [epoch: 12.1 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.864453445317258		[learning rate: 0.0045681]
	Learning Rate: 0.00456811
	LOSS [training: 1.864453445317258 | validation: 3.4241146856023157]
	TIME [epoch: 12.1 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2095504735361198		[learning rate: 0.004535]
	Learning Rate: 0.00453502
	LOSS [training: 2.2095504735361198 | validation: 1.9782267230828285]
	TIME [epoch: 12.1 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0009226889708165		[learning rate: 0.0045022]
	Learning Rate: 0.00450216
	LOSS [training: 2.0009226889708165 | validation: 2.2268680254058433]
	TIME [epoch: 12.1 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9174773188710414		[learning rate: 0.0044695]
	Learning Rate: 0.00446954
	LOSS [training: 1.9174773188710414 | validation: 2.035462513620759]
	TIME [epoch: 12.1 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7966739431972072		[learning rate: 0.0044372]
	Learning Rate: 0.00443716
	LOSS [training: 1.7966739431972072 | validation: 1.9870041214542873]
	TIME [epoch: 12.1 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6923698309141755		[learning rate: 0.004405]
	Learning Rate: 0.00440502
	LOSS [training: 1.6923698309141755 | validation: 2.2132815420986924]
	TIME [epoch: 12.1 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.161617394026413		[learning rate: 0.0043731]
	Learning Rate: 0.0043731
	LOSS [training: 2.161617394026413 | validation: 2.3065915813489752]
	TIME [epoch: 12.1 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7795044839510803		[learning rate: 0.0043414]
	Learning Rate: 0.00434142
	LOSS [training: 1.7795044839510803 | validation: 2.9060125465716413]
	TIME [epoch: 12.1 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.3749560892588617		[learning rate: 0.00431]
	Learning Rate: 0.00430996
	LOSS [training: 3.3749560892588617 | validation: 3.5072791494907314]
	TIME [epoch: 12.1 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.8840033075679146		[learning rate: 0.0042787]
	Learning Rate: 0.00427874
	LOSS [training: 2.8840033075679146 | validation: 2.8368004191355527]
	TIME [epoch: 12.1 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4206535539678304		[learning rate: 0.0042477]
	Learning Rate: 0.00424774
	LOSS [training: 2.4206535539678304 | validation: 2.4964606247157834]
	TIME [epoch: 12.1 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.014974060316984		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.014974060316984 | validation: 1.9979405860470039]
	TIME [epoch: 12.1 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7359438702873233		[learning rate: 0.0041864]
	Learning Rate: 0.00418641
	LOSS [training: 1.7359438702873233 | validation: 1.8722568484089406]
	TIME [epoch: 12.1 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6670762575439655		[learning rate: 0.0041561]
	Learning Rate: 0.00415608
	LOSS [training: 1.6670762575439655 | validation: 1.8516049028534363]
	TIME [epoch: 12.1 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0242376729758256		[learning rate: 0.004126]
	Learning Rate: 0.00412597
	LOSS [training: 2.0242376729758256 | validation: 3.0842747024566]
	TIME [epoch: 12.1 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4162336213176756		[learning rate: 0.0040961]
	Learning Rate: 0.00409608
	LOSS [training: 2.4162336213176756 | validation: 2.7802845864117525]
	TIME [epoch: 12.1 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.477228031121106		[learning rate: 0.0040664]
	Learning Rate: 0.0040664
	LOSS [training: 2.477228031121106 | validation: 2.31220043632676]
	TIME [epoch: 12.1 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8740296431517227		[learning rate: 0.0040369]
	Learning Rate: 0.00403694
	LOSS [training: 1.8740296431517227 | validation: 1.764191222408331]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_175.pth
	Model improved!!!
EPOCH 176/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7281364219777933		[learning rate: 0.0040077]
	Learning Rate: 0.0040077
	LOSS [training: 1.7281364219777933 | validation: 1.8065940718305922]
	TIME [epoch: 12.1 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0837441404917714		[learning rate: 0.0039787]
	Learning Rate: 0.00397866
	LOSS [training: 2.0837441404917714 | validation: 3.2761130882679117]
	TIME [epoch: 12.1 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.564896556154101		[learning rate: 0.0039498]
	Learning Rate: 0.00394983
	LOSS [training: 2.564896556154101 | validation: 2.9359601540554507]
	TIME [epoch: 12.1 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1950328639259054		[learning rate: 0.0039212]
	Learning Rate: 0.00392122
	LOSS [training: 2.1950328639259054 | validation: 1.9668103178545628]
	TIME [epoch: 12.1 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8646663504399836		[learning rate: 0.0038928]
	Learning Rate: 0.00389281
	LOSS [training: 1.8646663504399836 | validation: 2.119317482624224]
	TIME [epoch: 12.1 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.656535941681062		[learning rate: 0.0038646]
	Learning Rate: 0.00386461
	LOSS [training: 1.656535941681062 | validation: 1.7470970143051054]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_181.pth
	Model improved!!!
EPOCH 182/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5833057541852367		[learning rate: 0.0038366]
	Learning Rate: 0.00383661
	LOSS [training: 1.5833057541852367 | validation: 1.931460931093519]
	TIME [epoch: 12.1 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8322629161401642		[learning rate: 0.0038088]
	Learning Rate: 0.00380881
	LOSS [training: 1.8322629161401642 | validation: 2.34392951304861]
	TIME [epoch: 12.1 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2766576631231246		[learning rate: 0.0037812]
	Learning Rate: 0.00378122
	LOSS [training: 2.2766576631231246 | validation: 2.5940150252734417]
	TIME [epoch: 12.1 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.044906444283983		[learning rate: 0.0037538]
	Learning Rate: 0.00375382
	LOSS [training: 2.044906444283983 | validation: 2.649650174543025]
	TIME [epoch: 12.1 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.061748144337353		[learning rate: 0.0037266]
	Learning Rate: 0.00372663
	LOSS [training: 2.061748144337353 | validation: 2.6670659065096554]
	TIME [epoch: 12.1 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.80783899960382		[learning rate: 0.0036996]
	Learning Rate: 0.00369963
	LOSS [training: 1.80783899960382 | validation: 1.8693349983151064]
	TIME [epoch: 12.1 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.012499782374562		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.012499782374562 | validation: 2.363851859694381]
	TIME [epoch: 12.1 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8878848163577864		[learning rate: 0.0036462]
	Learning Rate: 0.00364621
	LOSS [training: 1.8878848163577864 | validation: 1.8966399225812123]
	TIME [epoch: 12.1 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6100028244244091		[learning rate: 0.0036198]
	Learning Rate: 0.0036198
	LOSS [training: 1.6100028244244091 | validation: 2.025305255325305]
	TIME [epoch: 12.1 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6341371457955611		[learning rate: 0.0035936]
	Learning Rate: 0.00359357
	LOSS [training: 1.6341371457955611 | validation: 2.3160239748168863]
	TIME [epoch: 12.1 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.674245445953164		[learning rate: 0.0035675]
	Learning Rate: 0.00356754
	LOSS [training: 1.674245445953164 | validation: 1.9697604873188763]
	TIME [epoch: 12.1 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.566382720036479		[learning rate: 0.0035417]
	Learning Rate: 0.00354169
	LOSS [training: 1.566382720036479 | validation: 1.9495982137762455]
	TIME [epoch: 12.1 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6989224594359285		[learning rate: 0.003516]
	Learning Rate: 0.00351603
	LOSS [training: 1.6989224594359285 | validation: 1.6903631461412374]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_194.pth
	Model improved!!!
EPOCH 195/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6039672186792229		[learning rate: 0.0034906]
	Learning Rate: 0.00349056
	LOSS [training: 1.6039672186792229 | validation: 1.8805929687133385]
	TIME [epoch: 12.1 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.724322318421177		[learning rate: 0.0034653]
	Learning Rate: 0.00346527
	LOSS [training: 1.724322318421177 | validation: 2.3571433341329957]
	TIME [epoch: 12.1 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8784465245969928		[learning rate: 0.0034402]
	Learning Rate: 0.00344016
	LOSS [training: 1.8784465245969928 | validation: 2.077224957528507]
	TIME [epoch: 12.1 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7435845036141633		[learning rate: 0.0034152]
	Learning Rate: 0.00341524
	LOSS [training: 1.7435845036141633 | validation: 1.7739137266753837]
	TIME [epoch: 12.1 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8648050918993389		[learning rate: 0.0033905]
	Learning Rate: 0.0033905
	LOSS [training: 1.8648050918993389 | validation: 2.435869188035271]
	TIME [epoch: 12.1 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.8640991772784643		[learning rate: 0.0033659]
	Learning Rate: 0.00336593
	LOSS [training: 1.8640991772784643 | validation: 2.307176952721335]
	TIME [epoch: 12.1 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0647950339476946		[learning rate: 0.0033415]
	Learning Rate: 0.00334155
	LOSS [training: 2.0647950339476946 | validation: 2.4888445417883736]
	TIME [epoch: 12.1 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.046505786964372		[learning rate: 0.0033173]
	Learning Rate: 0.00331734
	LOSS [training: 2.046505786964372 | validation: 1.9236802074941077]
	TIME [epoch: 12.1 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5355818418348477		[learning rate: 0.0032933]
	Learning Rate: 0.0032933
	LOSS [training: 1.5355818418348477 | validation: 1.8950024922606863]
	TIME [epoch: 12.1 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7205942186368233		[learning rate: 0.0032694]
	Learning Rate: 0.00326944
	LOSS [training: 1.7205942186368233 | validation: 2.079336487395408]
	TIME [epoch: 12.1 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7860843076002653		[learning rate: 0.0032458]
	Learning Rate: 0.00324576
	LOSS [training: 1.7860843076002653 | validation: 2.145024178670499]
	TIME [epoch: 12.1 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6235627867382496		[learning rate: 0.0032222]
	Learning Rate: 0.00322224
	LOSS [training: 1.6235627867382496 | validation: 1.7634772574734896]
	TIME [epoch: 12.1 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4717790894528004		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.4717790894528004 | validation: 1.7051070988646573]
	TIME [epoch: 12.1 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.589612725059725		[learning rate: 0.0031757]
	Learning Rate: 0.00317572
	LOSS [training: 1.589612725059725 | validation: 1.7510055238632227]
	TIME [epoch: 12.1 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5158242232306351		[learning rate: 0.0031527]
	Learning Rate: 0.00315271
	LOSS [training: 1.5158242232306351 | validation: 1.6336338308743028]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_209.pth
	Model improved!!!
EPOCH 210/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5027092227857337		[learning rate: 0.0031299]
	Learning Rate: 0.00312987
	LOSS [training: 1.5027092227857337 | validation: 2.1674891502103066]
	TIME [epoch: 12.1 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.0899550329434957		[learning rate: 0.0031072]
	Learning Rate: 0.00310719
	LOSS [training: 2.0899550329434957 | validation: 2.4498565482754158]
	TIME [epoch: 12.1 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.108116009127339		[learning rate: 0.0030847]
	Learning Rate: 0.00308468
	LOSS [training: 2.108116009127339 | validation: 2.9743957344531475]
	TIME [epoch: 12.1 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.361000948308426		[learning rate: 0.0030623]
	Learning Rate: 0.00306233
	LOSS [training: 2.361000948308426 | validation: 2.9836888137041733]
	TIME [epoch: 12.1 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.065412757530101		[learning rate: 0.0030401]
	Learning Rate: 0.00304015
	LOSS [training: 2.065412757530101 | validation: 2.1412451696466843]
	TIME [epoch: 12.1 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6673710709959444		[learning rate: 0.0030181]
	Learning Rate: 0.00301812
	LOSS [training: 1.6673710709959444 | validation: 1.7112715756790822]
	TIME [epoch: 12.1 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4490798193760455		[learning rate: 0.0029963]
	Learning Rate: 0.00299626
	LOSS [training: 1.4490798193760455 | validation: 1.7009221507302095]
	TIME [epoch: 12.1 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6784768913027501		[learning rate: 0.0029745]
	Learning Rate: 0.00297455
	LOSS [training: 1.6784768913027501 | validation: 1.7514574589198912]
	TIME [epoch: 12.1 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4988788470052299		[learning rate: 0.002953]
	Learning Rate: 0.002953
	LOSS [training: 1.4988788470052299 | validation: 1.7309722421956715]
	TIME [epoch: 12.1 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.463106038478426		[learning rate: 0.0029316]
	Learning Rate: 0.0029316
	LOSS [training: 1.463106038478426 | validation: 1.8361267095975702]
	TIME [epoch: 12.1 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4812095860730197		[learning rate: 0.0029104]
	Learning Rate: 0.00291036
	LOSS [training: 1.4812095860730197 | validation: 2.092986732896791]
	TIME [epoch: 12.1 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.378533102534128		[learning rate: 0.0028893]
	Learning Rate: 0.00288928
	LOSS [training: 2.378533102534128 | validation: 2.8964571951143405]
	TIME [epoch: 12.1 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4714368217286777		[learning rate: 0.0028683]
	Learning Rate: 0.00286835
	LOSS [training: 2.4714368217286777 | validation: 3.0699834863949818]
	TIME [epoch: 12.1 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1740044788563595		[learning rate: 0.0028476]
	Learning Rate: 0.00284757
	LOSS [training: 2.1740044788563595 | validation: 1.7698057386860768]
	TIME [epoch: 12.1 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6351638713170638		[learning rate: 0.0028269]
	Learning Rate: 0.00282693
	LOSS [training: 1.6351638713170638 | validation: 1.659868612481358]
	TIME [epoch: 12.1 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6862703509549388		[learning rate: 0.0028065]
	Learning Rate: 0.00280645
	LOSS [training: 1.6862703509549388 | validation: 2.1054507834869107]
	TIME [epoch: 12.1 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6822114701182103		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.6822114701182103 | validation: 1.7062610139447343]
	TIME [epoch: 12.1 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.404858166704805		[learning rate: 0.0027659]
	Learning Rate: 0.00276594
	LOSS [training: 1.404858166704805 | validation: 1.7067079899152167]
	TIME [epoch: 12.1 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4868435855429973		[learning rate: 0.0027459]
	Learning Rate: 0.0027459
	LOSS [training: 1.4868435855429973 | validation: 1.7555497477283435]
	TIME [epoch: 12.1 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5134671482291011		[learning rate: 0.002726]
	Learning Rate: 0.002726
	LOSS [training: 1.5134671482291011 | validation: 1.851016737514384]
	TIME [epoch: 12.1 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4364106289173884		[learning rate: 0.0027063]
	Learning Rate: 0.00270625
	LOSS [training: 1.4364106289173884 | validation: 1.9040462910188285]
	TIME [epoch: 12.1 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4357102867312204		[learning rate: 0.0026866]
	Learning Rate: 0.00268665
	LOSS [training: 1.4357102867312204 | validation: 1.8306113368089858]
	TIME [epoch: 12.1 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4857290012395061		[learning rate: 0.0026672]
	Learning Rate: 0.00266718
	LOSS [training: 1.4857290012395061 | validation: 1.601246425133131]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_232.pth
	Model improved!!!
EPOCH 233/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5900543375405032		[learning rate: 0.0026479]
	Learning Rate: 0.00264786
	LOSS [training: 1.5900543375405032 | validation: 3.0752586463310276]
	TIME [epoch: 12.1 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.225117471838697		[learning rate: 0.0026287]
	Learning Rate: 0.00262867
	LOSS [training: 2.225117471838697 | validation: 1.6769202512948076]
	TIME [epoch: 12.1 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4230027722157916		[learning rate: 0.0026096]
	Learning Rate: 0.00260963
	LOSS [training: 1.4230027722157916 | validation: 1.5463617332572663]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_235.pth
	Model improved!!!
EPOCH 236/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.7020729477881693		[learning rate: 0.0025907]
	Learning Rate: 0.00259072
	LOSS [training: 1.7020729477881693 | validation: 1.5464869592121753]
	TIME [epoch: 12.1 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4266972665557658		[learning rate: 0.002572]
	Learning Rate: 0.00257195
	LOSS [training: 1.4266972665557658 | validation: 2.827714529814468]
	TIME [epoch: 12.1 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.684267806253641		[learning rate: 0.0025533]
	Learning Rate: 0.00255332
	LOSS [training: 2.684267806253641 | validation: 3.411346735263686]
	TIME [epoch: 12.1 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.657563410829571		[learning rate: 0.0025348]
	Learning Rate: 0.00253482
	LOSS [training: 2.657563410829571 | validation: 3.006628598230707]
	TIME [epoch: 12.1 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.138332849674251		[learning rate: 0.0025165]
	Learning Rate: 0.00251646
	LOSS [training: 2.138332849674251 | validation: 2.636252560833806]
	TIME [epoch: 12.1 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.4022269823259195		[learning rate: 0.0024982]
	Learning Rate: 0.00249823
	LOSS [training: 2.4022269823259195 | validation: 3.207362335497727]
	TIME [epoch: 12.1 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.743441638907361		[learning rate: 0.0024801]
	Learning Rate: 0.00248013
	LOSS [training: 2.743441638907361 | validation: 2.829129007064501]
	TIME [epoch: 12.1 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.2210211128016417		[learning rate: 0.0024622]
	Learning Rate: 0.00246216
	LOSS [training: 2.2210211128016417 | validation: 1.732536638180435]
	TIME [epoch: 12.1 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.466699232643058		[learning rate: 0.0024443]
	Learning Rate: 0.00244432
	LOSS [training: 1.466699232643058 | validation: 1.5319663802903558]
	TIME [epoch: 12.1 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_244.pth
	Model improved!!!
EPOCH 245/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3248606428204999		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.3248606428204999 | validation: 1.5459711262260134]
	TIME [epoch: 12.1 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3893924338705315		[learning rate: 0.002409]
	Learning Rate: 0.00240903
	LOSS [training: 1.3893924338705315 | validation: 1.83016852791399]
	TIME [epoch: 12.1 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.9010446532774272		[learning rate: 0.0023916]
	Learning Rate: 0.00239158
	LOSS [training: 1.9010446532774272 | validation: 2.2041442403304323]
	TIME [epoch: 12.1 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1112247280601766		[learning rate: 0.0023742]
	Learning Rate: 0.00237425
	LOSS [training: 2.1112247280601766 | validation: 1.8724475546842319]
	TIME [epoch: 12.1 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5422575440308208		[learning rate: 0.002357]
	Learning Rate: 0.00235705
	LOSS [training: 1.5422575440308208 | validation: 2.7852612962554937]
	TIME [epoch: 12.1 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 4/4] avg loss: 3.0454294358256315		[learning rate: 0.00234]
	Learning Rate: 0.00233997
	LOSS [training: 3.0454294358256315 | validation: 3.0645031550357187]
	TIME [epoch: 12.1 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.7628950113662274		[learning rate: 0.002323]
	Learning Rate: 0.00232302
	LOSS [training: 2.7628950113662274 | validation: 2.8822413031659306]
	TIME [epoch: 458 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1113440185103167		[learning rate: 0.0023062]
	Learning Rate: 0.00230619
	LOSS [training: 2.1113440185103167 | validation: 2.1709729072032227]
	TIME [epoch: 25.9 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6040801013875579		[learning rate: 0.0022895]
	Learning Rate: 0.00228948
	LOSS [training: 1.6040801013875579 | validation: 2.051818795466775]
	TIME [epoch: 25.8 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6537689171751433		[learning rate: 0.0022729]
	Learning Rate: 0.00227289
	LOSS [training: 1.6537689171751433 | validation: 2.4056024155324516]
	TIME [epoch: 25.8 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.1010756335693874		[learning rate: 0.0022564]
	Learning Rate: 0.00225643
	LOSS [training: 2.1010756335693874 | validation: 2.8877051052694136]
	TIME [epoch: 25.8 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.134306384118428		[learning rate: 0.0022401]
	Learning Rate: 0.00224008
	LOSS [training: 2.134306384118428 | validation: 2.7448599246610104]
	TIME [epoch: 25.8 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.3279524082013987		[learning rate: 0.0022238]
	Learning Rate: 0.00222385
	LOSS [training: 2.3279524082013987 | validation: 3.520785501567299]
	TIME [epoch: 25.8 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.154192799829652		[learning rate: 0.0022077]
	Learning Rate: 0.00220774
	LOSS [training: 2.154192799829652 | validation: 2.2643227895382307]
	TIME [epoch: 25.8 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 4/4] avg loss: 2.049009773007532		[learning rate: 0.0021917]
	Learning Rate: 0.00219174
	LOSS [training: 2.049009773007532 | validation: 2.3148743020864697]
	TIME [epoch: 25.8 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6340704493757001		[learning rate: 0.0021759]
	Learning Rate: 0.00217586
	LOSS [training: 1.6340704493757001 | validation: 1.9200682842685404]
	TIME [epoch: 25.8 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4555679191230304		[learning rate: 0.0021601]
	Learning Rate: 0.0021601
	LOSS [training: 1.4555679191230304 | validation: 1.9554848737134227]
	TIME [epoch: 25.8 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.6334172134144573		[learning rate: 0.0021444]
	Learning Rate: 0.00214445
	LOSS [training: 1.6334172134144573 | validation: 2.0766429408555362]
	TIME [epoch: 25.8 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4833027351727812		[learning rate: 0.0021289]
	Learning Rate: 0.00212891
	LOSS [training: 1.4833027351727812 | validation: 1.5543000488520113]
	TIME [epoch: 25.8 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3237705152143235		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.3237705152143235 | validation: 1.6052023464832905]
	TIME [epoch: 25.8 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3565975646801145		[learning rate: 0.0020982]
	Learning Rate: 0.00209818
	LOSS [training: 1.3565975646801145 | validation: 1.5532731098277885]
	TIME [epoch: 25.8 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3776766803560916		[learning rate: 0.002083]
	Learning Rate: 0.00208298
	LOSS [training: 1.3776766803560916 | validation: 1.5781035895647761]
	TIME [epoch: 25.8 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2752178468412863		[learning rate: 0.0020679]
	Learning Rate: 0.00206788
	LOSS [training: 1.2752178468412863 | validation: 1.4414355447352118]
	TIME [epoch: 25.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_267.pth
	Model improved!!!
EPOCH 268/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4188592971948444		[learning rate: 0.0020529]
	Learning Rate: 0.0020529
	LOSS [training: 1.4188592971948444 | validation: 1.6243338718384397]
	TIME [epoch: 25.8 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4252345854444606		[learning rate: 0.002038]
	Learning Rate: 0.00203803
	LOSS [training: 1.4252345854444606 | validation: 1.8385979037347595]
	TIME [epoch: 25.8 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.5233869623120075		[learning rate: 0.0020233]
	Learning Rate: 0.00202326
	LOSS [training: 1.5233869623120075 | validation: 1.4547053572769482]
	TIME [epoch: 25.8 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2961036514896056		[learning rate: 0.0020086]
	Learning Rate: 0.00200861
	LOSS [training: 1.2961036514896056 | validation: 1.5646798480249018]
	TIME [epoch: 25.8 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2691180625956546		[learning rate: 0.0019941]
	Learning Rate: 0.00199405
	LOSS [training: 1.2691180625956546 | validation: 1.5161149368865598]
	TIME [epoch: 25.8 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.4975535275516754		[learning rate: 0.0019796]
	Learning Rate: 0.00197961
	LOSS [training: 1.4975535275516754 | validation: 1.5243402359429596]
	TIME [epoch: 25.8 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.35703541447074		[learning rate: 0.0019653]
	Learning Rate: 0.00196526
	LOSS [training: 1.35703541447074 | validation: 1.5318930974241605]
	TIME [epoch: 25.8 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2855462875183725		[learning rate: 0.001951]
	Learning Rate: 0.00195103
	LOSS [training: 1.2855462875183725 | validation: 1.445248929123664]
	TIME [epoch: 25.8 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3898417866379722		[learning rate: 0.0019369]
	Learning Rate: 0.00193689
	LOSS [training: 1.3898417866379722 | validation: 1.6460408250108294]
	TIME [epoch: 25.8 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.282635197447505		[learning rate: 0.0019229]
	Learning Rate: 0.00192286
	LOSS [training: 1.282635197447505 | validation: 1.5186941677071153]
	TIME [epoch: 25.8 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2831727778676927		[learning rate: 0.0019089]
	Learning Rate: 0.00190893
	LOSS [training: 1.2831727778676927 | validation: 1.6955034275707228]
	TIME [epoch: 25.8 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2514605963492627		[learning rate: 0.0018951]
	Learning Rate: 0.0018951
	LOSS [training: 1.2514605963492627 | validation: 1.4915632968872363]
	TIME [epoch: 25.8 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.246772577354927		[learning rate: 0.0018814]
	Learning Rate: 0.00188137
	LOSS [training: 1.246772577354927 | validation: 1.6330236897027444]
	TIME [epoch: 25.8 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.27530537731442		[learning rate: 0.0018677]
	Learning Rate: 0.00186774
	LOSS [training: 1.27530537731442 | validation: 1.4297857911550498]
	TIME [epoch: 25.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_281.pth
	Model improved!!!
EPOCH 282/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2158358563090685		[learning rate: 0.0018542]
	Learning Rate: 0.00185421
	LOSS [training: 1.2158358563090685 | validation: 1.406539705312258]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_282.pth
	Model improved!!!
EPOCH 283/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1765855823013598		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 1.1765855823013598 | validation: 1.3585784389528195]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_283.pth
	Model improved!!!
EPOCH 284/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.160600287360969		[learning rate: 0.0018274]
	Learning Rate: 0.00182744
	LOSS [training: 1.160600287360969 | validation: 1.3162588736846232]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1651820527712236		[learning rate: 0.0018142]
	Learning Rate: 0.0018142
	LOSS [training: 1.1651820527712236 | validation: 1.8242328902272757]
	TIME [epoch: 25.8 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.277503923444651		[learning rate: 0.0018011]
	Learning Rate: 0.00180105
	LOSS [training: 1.277503923444651 | validation: 1.3542094138894194]
	TIME [epoch: 25.8 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.404513864234316		[learning rate: 0.001788]
	Learning Rate: 0.001788
	LOSS [training: 1.404513864234316 | validation: 1.9131619977269159]
	TIME [epoch: 25.8 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2662897898407224		[learning rate: 0.001775]
	Learning Rate: 0.00177505
	LOSS [training: 1.2662897898407224 | validation: 1.3702365765529656]
	TIME [epoch: 25.8 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1259786109998786		[learning rate: 0.0017622]
	Learning Rate: 0.00176219
	LOSS [training: 1.1259786109998786 | validation: 1.2806177475523104]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_289.pth
	Model improved!!!
EPOCH 290/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.190248854081612		[learning rate: 0.0017494]
	Learning Rate: 0.00174942
	LOSS [training: 1.190248854081612 | validation: 1.2970928084870041]
	TIME [epoch: 25.8 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3858912546767794		[learning rate: 0.0017367]
	Learning Rate: 0.00173675
	LOSS [training: 1.3858912546767794 | validation: 1.4716526023615848]
	TIME [epoch: 25.8 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2046161294787345		[learning rate: 0.0017242]
	Learning Rate: 0.00172417
	LOSS [training: 1.2046161294787345 | validation: 1.341809960690306]
	TIME [epoch: 25.8 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.13399594245598		[learning rate: 0.0017117]
	Learning Rate: 0.00171167
	LOSS [training: 1.13399594245598 | validation: 1.4660565584377934]
	TIME [epoch: 25.8 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2011710628460468		[learning rate: 0.0016993]
	Learning Rate: 0.00169927
	LOSS [training: 1.2011710628460468 | validation: 1.4457329269596308]
	TIME [epoch: 25.8 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0902179727996155		[learning rate: 0.001687]
	Learning Rate: 0.00168696
	LOSS [training: 1.0902179727996155 | validation: 1.362377723790611]
	TIME [epoch: 25.8 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3022154808795254		[learning rate: 0.0016747]
	Learning Rate: 0.00167474
	LOSS [training: 1.3022154808795254 | validation: 1.78130912447755]
	TIME [epoch: 25.8 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.25305743833841		[learning rate: 0.0016626]
	Learning Rate: 0.00166261
	LOSS [training: 1.25305743833841 | validation: 1.564731747077273]
	TIME [epoch: 25.8 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1921358034955967		[learning rate: 0.0016506]
	Learning Rate: 0.00165056
	LOSS [training: 1.1921358034955967 | validation: 1.289992193256382]
	TIME [epoch: 25.8 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1082905400497056		[learning rate: 0.0016386]
	Learning Rate: 0.0016386
	LOSS [training: 1.1082905400497056 | validation: 1.4594187065498865]
	TIME [epoch: 25.8 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.061553581576617		[learning rate: 0.0016267]
	Learning Rate: 0.00162673
	LOSS [training: 1.061553581576617 | validation: 2.249347743214087]
	TIME [epoch: 25.8 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.463133601183408		[learning rate: 0.0016149]
	Learning Rate: 0.00161495
	LOSS [training: 1.463133601183408 | validation: 1.4291784304209463]
	TIME [epoch: 25.8 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.2493864217550006		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 1.2493864217550006 | validation: 1.3956696652746474]
	TIME [epoch: 25.8 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.200946896438842		[learning rate: 0.0015916]
	Learning Rate: 0.00159163
	LOSS [training: 1.200946896438842 | validation: 1.2441224593768068]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_303.pth
	Model improved!!!
EPOCH 304/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0351549298333889		[learning rate: 0.0015801]
	Learning Rate: 0.0015801
	LOSS [training: 1.0351549298333889 | validation: 1.2491001017475893]
	TIME [epoch: 25.8 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0490615546424942		[learning rate: 0.0015687]
	Learning Rate: 0.00156865
	LOSS [training: 1.0490615546424942 | validation: 1.4678535953218343]
	TIME [epoch: 25.8 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.122334784230747		[learning rate: 0.0015573]
	Learning Rate: 0.00155729
	LOSS [training: 1.122334784230747 | validation: 1.2174955425934568]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_306.pth
	Model improved!!!
EPOCH 307/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1184956571837692		[learning rate: 0.001546]
	Learning Rate: 0.001546
	LOSS [training: 1.1184956571837692 | validation: 1.6083476625836592]
	TIME [epoch: 25.8 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.037965168664524		[learning rate: 0.0015348]
	Learning Rate: 0.0015348
	LOSS [training: 1.037965168664524 | validation: 1.3056406168582968]
	TIME [epoch: 25.8 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0457638863949061		[learning rate: 0.0015237]
	Learning Rate: 0.00152368
	LOSS [training: 1.0457638863949061 | validation: 1.3404508644958915]
	TIME [epoch: 25.8 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1458400141247311		[learning rate: 0.0015126]
	Learning Rate: 0.00151264
	LOSS [training: 1.1458400141247311 | validation: 1.289361208366707]
	TIME [epoch: 25.8 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1615132668082169		[learning rate: 0.0015017]
	Learning Rate: 0.00150169
	LOSS [training: 1.1615132668082169 | validation: 1.7692452412359687]
	TIME [epoch: 25.8 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.237227939145858		[learning rate: 0.0014908]
	Learning Rate: 0.00149081
	LOSS [training: 1.237227939145858 | validation: 1.52441889968701]
	TIME [epoch: 25.8 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0368795332017997		[learning rate: 0.00148]
	Learning Rate: 0.00148001
	LOSS [training: 1.0368795332017997 | validation: 1.2557750563835257]
	TIME [epoch: 25.8 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1520677052736366		[learning rate: 0.0014693]
	Learning Rate: 0.00146928
	LOSS [training: 1.1520677052736366 | validation: 1.5350968612076414]
	TIME [epoch: 25.8 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.090230006551026		[learning rate: 0.0014586]
	Learning Rate: 0.00145864
	LOSS [training: 1.090230006551026 | validation: 1.2499343029954502]
	TIME [epoch: 25.8 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0387532741283516		[learning rate: 0.0014481]
	Learning Rate: 0.00144807
	LOSS [training: 1.0387532741283516 | validation: 1.2167040054841274]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_316.pth
	Model improved!!!
EPOCH 317/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0664587332277984		[learning rate: 0.0014376]
	Learning Rate: 0.00143758
	LOSS [training: 1.0664587332277984 | validation: 1.2365593187537107]
	TIME [epoch: 25.8 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0690096647933955		[learning rate: 0.0014272]
	Learning Rate: 0.00142716
	LOSS [training: 1.0690096647933955 | validation: 1.2691345202057702]
	TIME [epoch: 25.8 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0084271345233682		[learning rate: 0.0014168]
	Learning Rate: 0.00141682
	LOSS [training: 1.0084271345233682 | validation: 1.2645897927419079]
	TIME [epoch: 25.8 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0203654108227658		[learning rate: 0.0014066]
	Learning Rate: 0.00140656
	LOSS [training: 1.0203654108227658 | validation: 1.1947547706687407]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_320.pth
	Model improved!!!
EPOCH 321/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0555735605667675		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 1.0555735605667675 | validation: 1.370395514224454]
	TIME [epoch: 25.8 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530885810735842		[learning rate: 0.0013863]
	Learning Rate: 0.00138625
	LOSS [training: 1.0530885810735842 | validation: 1.5244361419360921]
	TIME [epoch: 25.8 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0941898234890295		[learning rate: 0.0013762]
	Learning Rate: 0.00137621
	LOSS [training: 1.0941898234890295 | validation: 1.2467002624840815]
	TIME [epoch: 25.8 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9756302883182555		[learning rate: 0.0013662]
	Learning Rate: 0.00136624
	LOSS [training: 0.9756302883182555 | validation: 1.178586661844056]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_324.pth
	Model improved!!!
EPOCH 325/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9577693019070622		[learning rate: 0.0013563]
	Learning Rate: 0.00135634
	LOSS [training: 0.9577693019070622 | validation: 1.1961614635649795]
	TIME [epoch: 25.8 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9491407375401097		[learning rate: 0.0013465]
	Learning Rate: 0.00134651
	LOSS [training: 0.9491407375401097 | validation: 1.15791952301679]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_326.pth
	Model improved!!!
EPOCH 327/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0394037756144456		[learning rate: 0.0013368]
	Learning Rate: 0.00133676
	LOSS [training: 1.0394037756144456 | validation: 1.2726457734339798]
	TIME [epoch: 25.8 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0748030908277786		[learning rate: 0.0013271]
	Learning Rate: 0.00132707
	LOSS [training: 1.0748030908277786 | validation: 1.254252783686743]
	TIME [epoch: 25.8 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9402508065885504		[learning rate: 0.0013175]
	Learning Rate: 0.00131746
	LOSS [training: 0.9402508065885504 | validation: 1.0884450813172433]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_329.pth
	Model improved!!!
EPOCH 330/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8961335245239663		[learning rate: 0.0013079]
	Learning Rate: 0.00130791
	LOSS [training: 0.8961335245239663 | validation: 1.0749482220767321]
	TIME [epoch: 25.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_330.pth
	Model improved!!!
EPOCH 331/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9148265892370278		[learning rate: 0.0012984]
	Learning Rate: 0.00129844
	LOSS [training: 0.9148265892370278 | validation: 1.1428448743259685]
	TIME [epoch: 25.8 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9672830547736526		[learning rate: 0.001289]
	Learning Rate: 0.00128903
	LOSS [training: 0.9672830547736526 | validation: 1.1471767131236894]
	TIME [epoch: 25.8 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.352515840053016		[learning rate: 0.0012797]
	Learning Rate: 0.00127969
	LOSS [training: 1.352515840053016 | validation: 2.5332318017820104]
	TIME [epoch: 25.8 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.3593145287289714		[learning rate: 0.0012704]
	Learning Rate: 0.00127042
	LOSS [training: 1.3593145287289714 | validation: 1.2122881637384892]
	TIME [epoch: 25.8 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1742465622709288		[learning rate: 0.0012612]
	Learning Rate: 0.00126122
	LOSS [training: 1.1742465622709288 | validation: 1.8904727230545233]
	TIME [epoch: 25.8 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1420845704415186		[learning rate: 0.0012521]
	Learning Rate: 0.00125208
	LOSS [training: 1.1420845704415186 | validation: 1.0974529776470943]
	TIME [epoch: 25.8 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9237484512987161		[learning rate: 0.001243]
	Learning Rate: 0.00124301
	LOSS [training: 0.9237484512987161 | validation: 1.0500126635381668]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_337.pth
	Model improved!!!
EPOCH 338/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9418370500577751		[learning rate: 0.001234]
	Learning Rate: 0.001234
	LOSS [training: 0.9418370500577751 | validation: 1.1246732674813567]
	TIME [epoch: 25.8 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9923695057702258		[learning rate: 0.0012251]
	Learning Rate: 0.00122506
	LOSS [training: 0.9923695057702258 | validation: 1.301501260131888]
	TIME [epoch: 25.9 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9756972439113216		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.9756972439113216 | validation: 1.2624373155241855]
	TIME [epoch: 25.8 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1011699057981363		[learning rate: 0.0012074]
	Learning Rate: 0.00120737
	LOSS [training: 1.1011699057981363 | validation: 1.1657110555866839]
	TIME [epoch: 25.9 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9561796445368389		[learning rate: 0.0011986]
	Learning Rate: 0.00119863
	LOSS [training: 0.9561796445368389 | validation: 1.2521498184672386]
	TIME [epoch: 25.9 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0245218580692328		[learning rate: 0.0011899]
	Learning Rate: 0.00118994
	LOSS [training: 1.0245218580692328 | validation: 1.235044563365515]
	TIME [epoch: 25.8 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9550713255178087		[learning rate: 0.0011813]
	Learning Rate: 0.00118132
	LOSS [training: 0.9550713255178087 | validation: 1.4542983250706283]
	TIME [epoch: 25.9 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347144977502356		[learning rate: 0.0011728]
	Learning Rate: 0.00117276
	LOSS [training: 1.0347144977502356 | validation: 1.267404872671639]
	TIME [epoch: 25.8 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.954863362117489		[learning rate: 0.0011643]
	Learning Rate: 0.00116427
	LOSS [training: 0.954863362117489 | validation: 1.2051371940798936]
	TIME [epoch: 25.8 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.882986540512561		[learning rate: 0.0011558]
	Learning Rate: 0.00115583
	LOSS [training: 0.882986540512561 | validation: 1.3977747031573036]
	TIME [epoch: 25.9 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0000777207771119		[learning rate: 0.0011475]
	Learning Rate: 0.00114746
	LOSS [training: 1.0000777207771119 | validation: 1.1229889207007249]
	TIME [epoch: 25.9 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8935384205785799		[learning rate: 0.0011391]
	Learning Rate: 0.00113914
	LOSS [training: 0.8935384205785799 | validation: 1.1534289419434423]
	TIME [epoch: 25.9 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9515607988537977		[learning rate: 0.0011309]
	Learning Rate: 0.00113089
	LOSS [training: 0.9515607988537977 | validation: 1.3092802926486304]
	TIME [epoch: 25.8 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9896248065505988		[learning rate: 0.0011227]
	Learning Rate: 0.0011227
	LOSS [training: 0.9896248065505988 | validation: 1.0921896473269037]
	TIME [epoch: 25.9 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9298779780680648		[learning rate: 0.0011146]
	Learning Rate: 0.00111456
	LOSS [training: 0.9298779780680648 | validation: 1.0611092786110299]
	TIME [epoch: 25.9 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8943295018319937		[learning rate: 0.0011065]
	Learning Rate: 0.00110649
	LOSS [training: 0.8943295018319937 | validation: 1.0478373640640293]
	TIME [epoch: 25.9 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_353.pth
	Model improved!!!
EPOCH 354/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9264050215491606		[learning rate: 0.0010985]
	Learning Rate: 0.00109847
	LOSS [training: 0.9264050215491606 | validation: 1.1892389660058404]
	TIME [epoch: 25.8 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8756738283783706		[learning rate: 0.0010905]
	Learning Rate: 0.00109051
	LOSS [training: 0.8756738283783706 | validation: 1.0615474767650368]
	TIME [epoch: 25.8 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9850368580937388		[learning rate: 0.0010826]
	Learning Rate: 0.00108261
	LOSS [training: 0.9850368580937388 | validation: 1.160625113477816]
	TIME [epoch: 25.8 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.910028248269657		[learning rate: 0.0010748]
	Learning Rate: 0.00107477
	LOSS [training: 0.910028248269657 | validation: 1.0895943691981202]
	TIME [epoch: 25.8 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8946451924164669		[learning rate: 0.001067]
	Learning Rate: 0.00106698
	LOSS [training: 0.8946451924164669 | validation: 1.135322427334516]
	TIME [epoch: 25.9 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8497019035577681		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.8497019035577681 | validation: 1.1333460026148532]
	TIME [epoch: 25.8 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.0149389905128379		[learning rate: 0.0010516]
	Learning Rate: 0.00105158
	LOSS [training: 1.0149389905128379 | validation: 1.2998628529134666]
	TIME [epoch: 25.8 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9043109500564435		[learning rate: 0.001044]
	Learning Rate: 0.00104396
	LOSS [training: 0.9043109500564435 | validation: 1.2034520392147032]
	TIME [epoch: 25.8 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752304976235867		[learning rate: 0.0010364]
	Learning Rate: 0.0010364
	LOSS [training: 0.8752304976235867 | validation: 1.1793419290867253]
	TIME [epoch: 25.8 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9419549256227364		[learning rate: 0.0010289]
	Learning Rate: 0.00102889
	LOSS [training: 0.9419549256227364 | validation: 1.063321397557474]
	TIME [epoch: 25.8 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8980715883444974		[learning rate: 0.0010214]
	Learning Rate: 0.00102143
	LOSS [training: 0.8980715883444974 | validation: 1.2670670421433945]
	TIME [epoch: 25.8 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9366022540230201		[learning rate: 0.001014]
	Learning Rate: 0.00101403
	LOSS [training: 0.9366022540230201 | validation: 1.1130545605238562]
	TIME [epoch: 25.8 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9274648480394143		[learning rate: 0.0010067]
	Learning Rate: 0.00100669
	LOSS [training: 0.9274648480394143 | validation: 1.1449422607668645]
	TIME [epoch: 25.8 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202295126810276		[learning rate: 0.00099939]
	Learning Rate: 0.000999394
	LOSS [training: 0.9202295126810276 | validation: 1.2171390353072606]
	TIME [epoch: 25.8 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9447759919756551		[learning rate: 0.00099215]
	Learning Rate: 0.000992154
	LOSS [training: 0.9447759919756551 | validation: 1.1742275772529733]
	TIME [epoch: 25.8 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9127699953981644		[learning rate: 0.00098497]
	Learning Rate: 0.000984966
	LOSS [training: 0.9127699953981644 | validation: 1.1477790432789092]
	TIME [epoch: 25.8 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8906604304878146		[learning rate: 0.00097783]
	Learning Rate: 0.00097783
	LOSS [training: 0.8906604304878146 | validation: 1.5201276688210057]
	TIME [epoch: 25.8 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.1871471102662465		[learning rate: 0.00097075]
	Learning Rate: 0.000970745
	LOSS [training: 1.1871471102662465 | validation: 1.2395472434536734]
	TIME [epoch: 25.8 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9292101954783756		[learning rate: 0.00096371]
	Learning Rate: 0.000963712
	LOSS [training: 0.9292101954783756 | validation: 1.109484183664023]
	TIME [epoch: 25.8 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.865458901202711		[learning rate: 0.00095673]
	Learning Rate: 0.00095673
	LOSS [training: 0.865458901202711 | validation: 1.1414470209217575]
	TIME [epoch: 25.8 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8698919665852716		[learning rate: 0.0009498]
	Learning Rate: 0.000949799
	LOSS [training: 0.8698919665852716 | validation: 1.1850850333963605]
	TIME [epoch: 25.8 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9072790483187554		[learning rate: 0.00094292]
	Learning Rate: 0.000942918
	LOSS [training: 0.9072790483187554 | validation: 1.07215390039298]
	TIME [epoch: 25.8 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.916569773347617		[learning rate: 0.00093609]
	Learning Rate: 0.000936086
	LOSS [training: 0.916569773347617 | validation: 1.1101538037970138]
	TIME [epoch: 25.8 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516163759699149		[learning rate: 0.0009293]
	Learning Rate: 0.000929304
	LOSS [training: 0.8516163759699149 | validation: 1.038309620701428]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_377.pth
	Model improved!!!
EPOCH 378/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8960712246171937		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.8960712246171937 | validation: 1.129315148477382]
	TIME [epoch: 25.8 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9554513819688286		[learning rate: 0.00091589]
	Learning Rate: 0.000915888
	LOSS [training: 0.9554513819688286 | validation: 1.090806956122654]
	TIME [epoch: 25.8 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8804242350541049		[learning rate: 0.00090925]
	Learning Rate: 0.000909252
	LOSS [training: 0.8804242350541049 | validation: 1.1786077287242545]
	TIME [epoch: 25.8 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.008335520227064		[learning rate: 0.00090266]
	Learning Rate: 0.000902664
	LOSS [training: 1.008335520227064 | validation: 1.0241681385939843]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_381.pth
	Model improved!!!
EPOCH 382/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8195099297529049		[learning rate: 0.00089612]
	Learning Rate: 0.000896125
	LOSS [training: 0.8195099297529049 | validation: 1.1151008635556718]
	TIME [epoch: 25.8 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8388852496708248		[learning rate: 0.00088963]
	Learning Rate: 0.000889632
	LOSS [training: 0.8388852496708248 | validation: 1.1404284672432983]
	TIME [epoch: 25.8 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534330426524197		[learning rate: 0.00088319]
	Learning Rate: 0.000883187
	LOSS [training: 0.8534330426524197 | validation: 1.0389918691727018]
	TIME [epoch: 25.8 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8274934714563502		[learning rate: 0.00087679]
	Learning Rate: 0.000876788
	LOSS [training: 0.8274934714563502 | validation: 1.033914019086188]
	TIME [epoch: 25.9 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.883936086404723		[learning rate: 0.00087044]
	Learning Rate: 0.000870436
	LOSS [training: 0.883936086404723 | validation: 1.114556452951964]
	TIME [epoch: 25.8 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396151469681588		[learning rate: 0.00086413]
	Learning Rate: 0.00086413
	LOSS [training: 0.8396151469681588 | validation: 1.0403121661350743]
	TIME [epoch: 25.8 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8810344530587102		[learning rate: 0.00085787]
	Learning Rate: 0.000857869
	LOSS [training: 0.8810344530587102 | validation: 1.010362450824589]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_388.pth
	Model improved!!!
EPOCH 389/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8085068957807611		[learning rate: 0.00085165]
	Learning Rate: 0.000851654
	LOSS [training: 0.8085068957807611 | validation: 1.1138567145905622]
	TIME [epoch: 25.8 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9628529819968766		[learning rate: 0.00084548]
	Learning Rate: 0.000845484
	LOSS [training: 0.9628529819968766 | validation: 1.2947747091787227]
	TIME [epoch: 25.8 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8863549636645538		[learning rate: 0.00083936]
	Learning Rate: 0.000839358
	LOSS [training: 0.8863549636645538 | validation: 1.0864946229116865]
	TIME [epoch: 25.8 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826776099448463		[learning rate: 0.00083328]
	Learning Rate: 0.000833277
	LOSS [training: 0.8826776099448463 | validation: 1.0818701667522532]
	TIME [epoch: 25.9 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8408324545084219		[learning rate: 0.00082724]
	Learning Rate: 0.00082724
	LOSS [training: 0.8408324545084219 | validation: 1.1020401711093868]
	TIME [epoch: 25.9 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8025811453550956		[learning rate: 0.00082125]
	Learning Rate: 0.000821247
	LOSS [training: 0.8025811453550956 | validation: 1.0759133097931795]
	TIME [epoch: 25.8 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8279532083943321		[learning rate: 0.0008153]
	Learning Rate: 0.000815297
	LOSS [training: 0.8279532083943321 | validation: 1.0533324351829503]
	TIME [epoch: 25.8 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563620684361231		[learning rate: 0.00080939]
	Learning Rate: 0.00080939
	LOSS [training: 0.8563620684361231 | validation: 1.0013357776596195]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_396.pth
	Model improved!!!
EPOCH 397/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.83547288824316		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.83547288824316 | validation: 1.0261949457134554]
	TIME [epoch: 25.8 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8472644188811125		[learning rate: 0.0007977]
	Learning Rate: 0.000797705
	LOSS [training: 0.8472644188811125 | validation: 1.0304767415090235]
	TIME [epoch: 25.8 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7997532941701075		[learning rate: 0.00079193]
	Learning Rate: 0.000791925
	LOSS [training: 0.7997532941701075 | validation: 1.030942966840239]
	TIME [epoch: 25.8 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.89141271763939		[learning rate: 0.00078619]
	Learning Rate: 0.000786188
	LOSS [training: 0.89141271763939 | validation: 1.0489564652148577]
	TIME [epoch: 25.8 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8296942378426233		[learning rate: 0.00078049]
	Learning Rate: 0.000780492
	LOSS [training: 0.8296942378426233 | validation: 1.08416332316911]
	TIME [epoch: 25.8 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.803213042061256		[learning rate: 0.00077484]
	Learning Rate: 0.000774838
	LOSS [training: 0.803213042061256 | validation: 1.025299144697895]
	TIME [epoch: 25.8 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055093786084767		[learning rate: 0.00076922]
	Learning Rate: 0.000769224
	LOSS [training: 0.8055093786084767 | validation: 0.9812504936266351]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_403.pth
	Model improved!!!
EPOCH 404/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8100562838111081		[learning rate: 0.00076365]
	Learning Rate: 0.000763651
	LOSS [training: 0.8100562838111081 | validation: 1.0223084603403474]
	TIME [epoch: 25.8 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486372597564619		[learning rate: 0.00075812]
	Learning Rate: 0.000758118
	LOSS [training: 0.8486372597564619 | validation: 1.0750470212655934]
	TIME [epoch: 25.8 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.826302969190835		[learning rate: 0.00075263]
	Learning Rate: 0.000752626
	LOSS [training: 0.826302969190835 | validation: 1.3413402049299976]
	TIME [epoch: 25.8 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 4/4] avg loss: 1.024341078975251		[learning rate: 0.00074717]
	Learning Rate: 0.000747173
	LOSS [training: 1.024341078975251 | validation: 1.0029991738674207]
	TIME [epoch: 25.8 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8382823645545268		[learning rate: 0.00074176]
	Learning Rate: 0.00074176
	LOSS [training: 0.8382823645545268 | validation: 0.9797000529485309]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_408.pth
	Model improved!!!
EPOCH 409/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012968918416032		[learning rate: 0.00073639]
	Learning Rate: 0.000736386
	LOSS [training: 0.8012968918416032 | validation: 0.9720617582206892]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_409.pth
	Model improved!!!
EPOCH 410/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.807806595653161		[learning rate: 0.00073105]
	Learning Rate: 0.000731051
	LOSS [training: 0.807806595653161 | validation: 1.045254447668342]
	TIME [epoch: 25.8 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.9851125814356891		[learning rate: 0.00072575]
	Learning Rate: 0.000725754
	LOSS [training: 0.9851125814356891 | validation: 0.9612192021479273]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_411.pth
	Model improved!!!
EPOCH 412/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7961219342996904		[learning rate: 0.0007205]
	Learning Rate: 0.000720496
	LOSS [training: 0.7961219342996904 | validation: 1.006026082709778]
	TIME [epoch: 25.8 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8440693296989646		[learning rate: 0.00071528]
	Learning Rate: 0.000715276
	LOSS [training: 0.8440693296989646 | validation: 1.0692279812957854]
	TIME [epoch: 25.8 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7927133038741457		[learning rate: 0.00071009]
	Learning Rate: 0.000710094
	LOSS [training: 0.7927133038741457 | validation: 1.0345208999348385]
	TIME [epoch: 25.8 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863346147885458		[learning rate: 0.00070495]
	Learning Rate: 0.000704949
	LOSS [training: 0.7863346147885458 | validation: 1.0060622301459428]
	TIME [epoch: 25.8 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8049564201322416		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.8049564201322416 | validation: 1.0201270313987598]
	TIME [epoch: 25.8 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8131706073754126		[learning rate: 0.00069477]
	Learning Rate: 0.000694772
	LOSS [training: 0.8131706073754126 | validation: 0.9718269463476349]
	TIME [epoch: 25.8 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7693728257757942		[learning rate: 0.00068974]
	Learning Rate: 0.000689738
	LOSS [training: 0.7693728257757942 | validation: 1.0701355214858783]
	TIME [epoch: 25.8 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7929468012176375		[learning rate: 0.00068474]
	Learning Rate: 0.000684741
	LOSS [training: 0.7929468012176375 | validation: 0.9952289879474558]
	TIME [epoch: 25.8 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8211729349628982		[learning rate: 0.00067978]
	Learning Rate: 0.00067978
	LOSS [training: 0.8211729349628982 | validation: 1.028086270734199]
	TIME [epoch: 25.8 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8257307299583299		[learning rate: 0.00067486]
	Learning Rate: 0.000674855
	LOSS [training: 0.8257307299583299 | validation: 1.0089402246542367]
	TIME [epoch: 25.8 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8721545629633495		[learning rate: 0.00066997]
	Learning Rate: 0.000669966
	LOSS [training: 0.8721545629633495 | validation: 0.9306045913457259]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_422.pth
	Model improved!!!
EPOCH 423/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8327796922711338		[learning rate: 0.00066511]
	Learning Rate: 0.000665112
	LOSS [training: 0.8327796922711338 | validation: 0.9382745568961064]
	TIME [epoch: 25.8 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8598015527975842		[learning rate: 0.00066029]
	Learning Rate: 0.000660293
	LOSS [training: 0.8598015527975842 | validation: 0.9841317330227601]
	TIME [epoch: 25.8 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790720421404433		[learning rate: 0.00065551]
	Learning Rate: 0.00065551
	LOSS [training: 0.8790720421404433 | validation: 1.0079288284947459]
	TIME [epoch: 25.8 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8075706687789546		[learning rate: 0.00065076]
	Learning Rate: 0.00065076
	LOSS [training: 0.8075706687789546 | validation: 0.9379044464477488]
	TIME [epoch: 25.8 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7987141482604934		[learning rate: 0.00064605]
	Learning Rate: 0.000646046
	LOSS [training: 0.7987141482604934 | validation: 0.8973968509474252]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_427.pth
	Model improved!!!
EPOCH 428/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679832163376787		[learning rate: 0.00064137]
	Learning Rate: 0.000641365
	LOSS [training: 0.7679832163376787 | validation: 0.9402067023685927]
	TIME [epoch: 25.8 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752739335351326		[learning rate: 0.00063672]
	Learning Rate: 0.000636718
	LOSS [training: 0.7752739335351326 | validation: 1.081707482769965]
	TIME [epoch: 25.8 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8847561480677937		[learning rate: 0.00063211]
	Learning Rate: 0.000632105
	LOSS [training: 0.8847561480677937 | validation: 1.0804873790376872]
	TIME [epoch: 25.8 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8428550322388644		[learning rate: 0.00062753]
	Learning Rate: 0.000627526
	LOSS [training: 0.8428550322388644 | validation: 0.9247660585764781]
	TIME [epoch: 25.8 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7612242469202244		[learning rate: 0.00062298]
	Learning Rate: 0.000622979
	LOSS [training: 0.7612242469202244 | validation: 0.9726588456311662]
	TIME [epoch: 25.8 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908796140191596		[learning rate: 0.00061847]
	Learning Rate: 0.000618466
	LOSS [training: 0.7908796140191596 | validation: 0.8650353795016832]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_433.pth
	Model improved!!!
EPOCH 434/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7643640580677349		[learning rate: 0.00061399]
	Learning Rate: 0.000613985
	LOSS [training: 0.7643640580677349 | validation: 0.9771536514372201]
	TIME [epoch: 25.8 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7964624002382614		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.7964624002382614 | validation: 0.9207025923643009]
	TIME [epoch: 25.8 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7410079349961713		[learning rate: 0.00060512]
	Learning Rate: 0.000605121
	LOSS [training: 0.7410079349961713 | validation: 0.9448884908007942]
	TIME [epoch: 25.8 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7434568106342844		[learning rate: 0.00060074]
	Learning Rate: 0.000600737
	LOSS [training: 0.7434568106342844 | validation: 0.9264780343039731]
	TIME [epoch: 25.8 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8045658778050957		[learning rate: 0.00059638]
	Learning Rate: 0.000596385
	LOSS [training: 0.8045658778050957 | validation: 0.9929418188206477]
	TIME [epoch: 25.8 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104354058688727		[learning rate: 0.00059206]
	Learning Rate: 0.000592064
	LOSS [training: 0.8104354058688727 | validation: 0.8935829649884424]
	TIME [epoch: 25.8 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7632480062258792		[learning rate: 0.00058777]
	Learning Rate: 0.000587774
	LOSS [training: 0.7632480062258792 | validation: 0.9310051153102157]
	TIME [epoch: 25.8 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409181365577666		[learning rate: 0.00058352]
	Learning Rate: 0.000583516
	LOSS [training: 0.8409181365577666 | validation: 1.2280557320358327]
	TIME [epoch: 25.8 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8850865601721165		[learning rate: 0.00057929]
	Learning Rate: 0.000579288
	LOSS [training: 0.8850865601721165 | validation: 0.9451329306668207]
	TIME [epoch: 25.8 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7872442842574955		[learning rate: 0.00057509]
	Learning Rate: 0.000575091
	LOSS [training: 0.7872442842574955 | validation: 0.9992333880981499]
	TIME [epoch: 25.8 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7698767835435489		[learning rate: 0.00057092]
	Learning Rate: 0.000570925
	LOSS [training: 0.7698767835435489 | validation: 0.8803875994641962]
	TIME [epoch: 25.8 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.74033021153964		[learning rate: 0.00056679]
	Learning Rate: 0.000566789
	LOSS [training: 0.74033021153964 | validation: 0.894687861708519]
	TIME [epoch: 25.8 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320651912422989		[learning rate: 0.00056268]
	Learning Rate: 0.000562682
	LOSS [training: 0.7320651912422989 | validation: 0.8975752680947193]
	TIME [epoch: 25.8 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325815245578707		[learning rate: 0.00055861]
	Learning Rate: 0.000558606
	LOSS [training: 0.7325815245578707 | validation: 0.9651287927672492]
	TIME [epoch: 25.8 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688864729436393		[learning rate: 0.00055456]
	Learning Rate: 0.000554559
	LOSS [training: 0.7688864729436393 | validation: 0.8755526106854412]
	TIME [epoch: 25.8 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7499491825300003		[learning rate: 0.00055054]
	Learning Rate: 0.000550541
	LOSS [training: 0.7499491825300003 | validation: 0.9227986517767655]
	TIME [epoch: 25.8 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7422976228897064		[learning rate: 0.00054655]
	Learning Rate: 0.000546552
	LOSS [training: 0.7422976228897064 | validation: 0.9127278460620493]
	TIME [epoch: 25.8 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7553910928514298		[learning rate: 0.00054259]
	Learning Rate: 0.000542592
	LOSS [training: 0.7553910928514298 | validation: 1.0046597826862251]
	TIME [epoch: 25.8 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692871608489964		[learning rate: 0.00053866]
	Learning Rate: 0.000538661
	LOSS [training: 0.7692871608489964 | validation: 0.9131019096482749]
	TIME [epoch: 25.8 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912719361345025		[learning rate: 0.00053476]
	Learning Rate: 0.000534759
	LOSS [training: 0.7912719361345025 | validation: 0.9255063600174529]
	TIME [epoch: 25.8 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8318816875163667		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.8318816875163667 | validation: 0.9445328111774584]
	TIME [epoch: 25.8 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7736418093784865		[learning rate: 0.00052704]
	Learning Rate: 0.000527038
	LOSS [training: 0.7736418093784865 | validation: 0.9895307495854976]
	TIME [epoch: 25.8 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640079096752925		[learning rate: 0.00052322]
	Learning Rate: 0.00052322
	LOSS [training: 0.7640079096752925 | validation: 0.9083214923266456]
	TIME [epoch: 25.8 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438251475355557		[learning rate: 0.00051943]
	Learning Rate: 0.000519429
	LOSS [training: 0.7438251475355557 | validation: 0.9399887913907241]
	TIME [epoch: 25.8 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7682921179324687		[learning rate: 0.00051567]
	Learning Rate: 0.000515666
	LOSS [training: 0.7682921179324687 | validation: 0.9029049083620542]
	TIME [epoch: 25.8 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7526378725552478		[learning rate: 0.00051193]
	Learning Rate: 0.00051193
	LOSS [training: 0.7526378725552478 | validation: 0.9284637039926886]
	TIME [epoch: 25.8 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7397483626950875		[learning rate: 0.00050822]
	Learning Rate: 0.000508221
	LOSS [training: 0.7397483626950875 | validation: 0.9062128596066528]
	TIME [epoch: 25.8 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.738915883313726		[learning rate: 0.00050454]
	Learning Rate: 0.000504539
	LOSS [training: 0.738915883313726 | validation: 0.9634613550117338]
	TIME [epoch: 25.8 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7650643426095487		[learning rate: 0.00050088]
	Learning Rate: 0.000500884
	LOSS [training: 0.7650643426095487 | validation: 0.9089510319325256]
	TIME [epoch: 25.8 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426305092135925		[learning rate: 0.00049725]
	Learning Rate: 0.000497255
	LOSS [training: 0.7426305092135925 | validation: 0.9350091812440869]
	TIME [epoch: 25.8 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.721929602567635		[learning rate: 0.00049365]
	Learning Rate: 0.000493652
	LOSS [training: 0.721929602567635 | validation: 0.8786967588721677]
	TIME [epoch: 25.8 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7377914950997806		[learning rate: 0.00049008]
	Learning Rate: 0.000490076
	LOSS [training: 0.7377914950997806 | validation: 0.9121198239918129]
	TIME [epoch: 25.8 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617345374127669		[learning rate: 0.00048653]
	Learning Rate: 0.000486525
	LOSS [training: 0.7617345374127669 | validation: 0.9612368291401254]
	TIME [epoch: 25.8 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635982189944918		[learning rate: 0.000483]
	Learning Rate: 0.000483
	LOSS [training: 0.7635982189944918 | validation: 0.9497073756467943]
	TIME [epoch: 25.8 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7369902215562927		[learning rate: 0.0004795]
	Learning Rate: 0.000479501
	LOSS [training: 0.7369902215562927 | validation: 0.9326446311387344]
	TIME [epoch: 25.8 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338298234326739		[learning rate: 0.00047603]
	Learning Rate: 0.000476027
	LOSS [training: 0.7338298234326739 | validation: 0.8803904581565524]
	TIME [epoch: 25.8 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342493486825977		[learning rate: 0.00047258]
	Learning Rate: 0.000472578
	LOSS [training: 0.7342493486825977 | validation: 0.9223690750924866]
	TIME [epoch: 25.8 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.698132830604512		[learning rate: 0.00046915]
	Learning Rate: 0.000469154
	LOSS [training: 0.698132830604512 | validation: 0.9110129226784276]
	TIME [epoch: 25.8 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.8003494195394064		[learning rate: 0.00046576]
	Learning Rate: 0.000465755
	LOSS [training: 0.8003494195394064 | validation: 1.041453237688963]
	TIME [epoch: 25.8 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7923742227820071		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.7923742227820071 | validation: 0.9958517532472129]
	TIME [epoch: 25.8 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7372325111851386		[learning rate: 0.00045903]
	Learning Rate: 0.000459031
	LOSS [training: 0.7372325111851386 | validation: 1.052630381300602]
	TIME [epoch: 25.8 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7927051916194817		[learning rate: 0.00045571]
	Learning Rate: 0.000455706
	LOSS [training: 0.7927051916194817 | validation: 0.8952292700036275]
	TIME [epoch: 25.8 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7904389826382983		[learning rate: 0.0004524]
	Learning Rate: 0.000452404
	LOSS [training: 0.7904389826382983 | validation: 0.969772781554459]
	TIME [epoch: 25.8 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7446633517035768		[learning rate: 0.00044913]
	Learning Rate: 0.000449126
	LOSS [training: 0.7446633517035768 | validation: 0.8872597348421517]
	TIME [epoch: 25.8 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7706862985607634		[learning rate: 0.00044587]
	Learning Rate: 0.000445872
	LOSS [training: 0.7706862985607634 | validation: 0.8817379829390498]
	TIME [epoch: 25.8 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7270408434905743		[learning rate: 0.00044264]
	Learning Rate: 0.000442642
	LOSS [training: 0.7270408434905743 | validation: 0.9659377674580538]
	TIME [epoch: 25.9 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7577078883798855		[learning rate: 0.00043944]
	Learning Rate: 0.000439435
	LOSS [training: 0.7577078883798855 | validation: 0.9109611250299645]
	TIME [epoch: 25.8 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273739155173964		[learning rate: 0.00043625]
	Learning Rate: 0.000436251
	LOSS [training: 0.7273739155173964 | validation: 0.9588026107730359]
	TIME [epoch: 25.8 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887998947132915		[learning rate: 0.00043309]
	Learning Rate: 0.000433091
	LOSS [training: 0.7887998947132915 | validation: 0.883267489268925]
	TIME [epoch: 25.8 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266420480664728		[learning rate: 0.00042995]
	Learning Rate: 0.000429953
	LOSS [training: 0.7266420480664728 | validation: 0.8957423424238771]
	TIME [epoch: 25.9 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517190030364034		[learning rate: 0.00042684]
	Learning Rate: 0.000426838
	LOSS [training: 0.7517190030364034 | validation: 0.8782215554232102]
	TIME [epoch: 25.8 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7316322142600953		[learning rate: 0.00042375]
	Learning Rate: 0.000423746
	LOSS [training: 0.7316322142600953 | validation: 0.8459792906474928]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_485.pth
	Model improved!!!
EPOCH 486/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474970609872306		[learning rate: 0.00042068]
	Learning Rate: 0.000420676
	LOSS [training: 0.7474970609872306 | validation: 1.0468840219324296]
	TIME [epoch: 25.8 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7357187537398622		[learning rate: 0.00041763]
	Learning Rate: 0.000417628
	LOSS [training: 0.7357187537398622 | validation: 0.9299170235919996]
	TIME [epoch: 25.9 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7079263462959731		[learning rate: 0.0004146]
	Learning Rate: 0.000414602
	LOSS [training: 0.7079263462959731 | validation: 0.9211194100300841]
	TIME [epoch: 25.8 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7808088655643374		[learning rate: 0.0004116]
	Learning Rate: 0.000411598
	LOSS [training: 0.7808088655643374 | validation: 0.9522577309944091]
	TIME [epoch: 25.8 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399137227874245		[learning rate: 0.00040862]
	Learning Rate: 0.000408616
	LOSS [training: 0.7399137227874245 | validation: 1.142043983387477]
	TIME [epoch: 25.8 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7984332958987632		[learning rate: 0.00040566]
	Learning Rate: 0.000405656
	LOSS [training: 0.7984332958987632 | validation: 0.9062511220692877]
	TIME [epoch: 25.8 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704651609117217		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.7704651609117217 | validation: 1.066501017678995]
	TIME [epoch: 25.8 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7741971574506962		[learning rate: 0.0003998]
	Learning Rate: 0.000399799
	LOSS [training: 0.7741971574506962 | validation: 0.8873244929557504]
	TIME [epoch: 25.8 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7201780532341582		[learning rate: 0.0003969]
	Learning Rate: 0.000396903
	LOSS [training: 0.7201780532341582 | validation: 0.8492194011679801]
	TIME [epoch: 25.8 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.742444707447547		[learning rate: 0.00039403]
	Learning Rate: 0.000394027
	LOSS [training: 0.742444707447547 | validation: 0.8899063726039904]
	TIME [epoch: 25.8 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7173863083560525		[learning rate: 0.00039117]
	Learning Rate: 0.000391173
	LOSS [training: 0.7173863083560525 | validation: 0.8890064678405074]
	TIME [epoch: 25.8 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6832578129675883		[learning rate: 0.00038834]
	Learning Rate: 0.000388339
	LOSS [training: 0.6832578129675883 | validation: 0.8676123255929494]
	TIME [epoch: 25.8 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7262557918646277		[learning rate: 0.00038553]
	Learning Rate: 0.000385525
	LOSS [training: 0.7262557918646277 | validation: 0.9769141573299522]
	TIME [epoch: 25.8 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623720095731276		[learning rate: 0.00038273]
	Learning Rate: 0.000382732
	LOSS [training: 0.7623720095731276 | validation: 0.9865001837941971]
	TIME [epoch: 25.8 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7568053974383011		[learning rate: 0.00037996]
	Learning Rate: 0.000379959
	LOSS [training: 0.7568053974383011 | validation: 0.8359192756244188]
	TIME [epoch: 25.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_500.pth
	Model improved!!!
EPOCH 501/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.72817150973097		[learning rate: 0.00037721]
	Learning Rate: 0.000377206
	LOSS [training: 0.72817150973097 | validation: 0.8389297513881316]
	TIME [epoch: 487 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821263759526129		[learning rate: 0.00037447]
	Learning Rate: 0.000374474
	LOSS [training: 0.6821263759526129 | validation: 0.8655291693469547]
	TIME [epoch: 54.9 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927002790812069		[learning rate: 0.00037176]
	Learning Rate: 0.00037176
	LOSS [training: 0.6927002790812069 | validation: 0.8797691460477663]
	TIME [epoch: 54.8 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134474546474243		[learning rate: 0.00036907]
	Learning Rate: 0.000369067
	LOSS [training: 0.7134474546474243 | validation: 0.8927970050127212]
	TIME [epoch: 54.8 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6963450848832219		[learning rate: 0.00036639]
	Learning Rate: 0.000366393
	LOSS [training: 0.6963450848832219 | validation: 0.8380663549235134]
	TIME [epoch: 54.8 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6978171828803696		[learning rate: 0.00036374]
	Learning Rate: 0.000363739
	LOSS [training: 0.6978171828803696 | validation: 0.8865492781003921]
	TIME [epoch: 54.7 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909173821168179		[learning rate: 0.0003611]
	Learning Rate: 0.000361103
	LOSS [training: 0.6909173821168179 | validation: 0.9020378024199672]
	TIME [epoch: 54.7 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7334775288169834		[learning rate: 0.00035849]
	Learning Rate: 0.000358487
	LOSS [training: 0.7334775288169834 | validation: 0.8297388918386425]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_508.pth
	Model improved!!!
EPOCH 509/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937554094411768		[learning rate: 0.00035589]
	Learning Rate: 0.00035589
	LOSS [training: 0.6937554094411768 | validation: 0.8725226346835386]
	TIME [epoch: 54.8 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7024125738951449		[learning rate: 0.00035331]
	Learning Rate: 0.000353312
	LOSS [training: 0.7024125738951449 | validation: 0.8584105132431806]
	TIME [epoch: 54.7 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876795362597821		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.6876795362597821 | validation: 0.8393535143416131]
	TIME [epoch: 54.7 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6908184361802117		[learning rate: 0.00034821]
	Learning Rate: 0.000348211
	LOSS [training: 0.6908184361802117 | validation: 0.8736351924778976]
	TIME [epoch: 54.8 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800290792082203		[learning rate: 0.00034569]
	Learning Rate: 0.000345688
	LOSS [training: 0.6800290792082203 | validation: 0.8853174109087554]
	TIME [epoch: 54.7 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.690650987837627		[learning rate: 0.00034318]
	Learning Rate: 0.000343183
	LOSS [training: 0.690650987837627 | validation: 0.8585186289464414]
	TIME [epoch: 54.8 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7207390398025924		[learning rate: 0.0003407]
	Learning Rate: 0.000340697
	LOSS [training: 0.7207390398025924 | validation: 0.8615089968416947]
	TIME [epoch: 54.7 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968502317105238		[learning rate: 0.00033823]
	Learning Rate: 0.000338229
	LOSS [training: 0.6968502317105238 | validation: 0.8380277657847324]
	TIME [epoch: 54.7 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696094829965926		[learning rate: 0.00033578]
	Learning Rate: 0.000335778
	LOSS [training: 0.6696094829965926 | validation: 0.8344481103427722]
	TIME [epoch: 54.7 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.692473500048814		[learning rate: 0.00033335]
	Learning Rate: 0.000333346
	LOSS [training: 0.692473500048814 | validation: 0.8339530078947871]
	TIME [epoch: 54.7 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.708402179559962		[learning rate: 0.00033093]
	Learning Rate: 0.000330931
	LOSS [training: 0.708402179559962 | validation: 0.870454290274802]
	TIME [epoch: 54.7 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723299853657284		[learning rate: 0.00032853]
	Learning Rate: 0.000328533
	LOSS [training: 0.6723299853657284 | validation: 0.8435349772766974]
	TIME [epoch: 54.7 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342910791289223		[learning rate: 0.00032615]
	Learning Rate: 0.000326153
	LOSS [training: 0.7342910791289223 | validation: 0.9493522257647236]
	TIME [epoch: 54.7 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7231641141818406		[learning rate: 0.00032379]
	Learning Rate: 0.00032379
	LOSS [training: 0.7231641141818406 | validation: 0.8330593772125853]
	TIME [epoch: 54.7 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956306896289983		[learning rate: 0.00032144]
	Learning Rate: 0.000321444
	LOSS [training: 0.6956306896289983 | validation: 0.8109243956998327]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_523.pth
	Model improved!!!
EPOCH 524/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6701701290717436		[learning rate: 0.00031912]
	Learning Rate: 0.000319115
	LOSS [training: 0.6701701290717436 | validation: 0.848456994138984]
	TIME [epoch: 54.7 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361153213477392		[learning rate: 0.0003168]
	Learning Rate: 0.000316803
	LOSS [training: 0.7361153213477392 | validation: 0.8334235405014583]
	TIME [epoch: 54.7 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7179025837286561		[learning rate: 0.00031451]
	Learning Rate: 0.000314508
	LOSS [training: 0.7179025837286561 | validation: 0.8434645943878829]
	TIME [epoch: 54.7 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6681299357211485		[learning rate: 0.00031223]
	Learning Rate: 0.000312229
	LOSS [training: 0.6681299357211485 | validation: 0.8670883514013779]
	TIME [epoch: 54.7 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373662997371085		[learning rate: 0.00030997]
	Learning Rate: 0.000309967
	LOSS [training: 0.7373662997371085 | validation: 0.9176612746284551]
	TIME [epoch: 54.7 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060136475704151		[learning rate: 0.00030772]
	Learning Rate: 0.000307722
	LOSS [training: 0.7060136475704151 | validation: 0.8281638778180249]
	TIME [epoch: 54.7 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6815372286468132		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.6815372286468132 | validation: 0.8609813025181662]
	TIME [epoch: 54.7 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6763864755113415		[learning rate: 0.00030328]
	Learning Rate: 0.000303279
	LOSS [training: 0.6763864755113415 | validation: 0.83567512305571]
	TIME [epoch: 54.7 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6913125807890881		[learning rate: 0.00030108]
	Learning Rate: 0.000301082
	LOSS [training: 0.6913125807890881 | validation: 0.8715185754973513]
	TIME [epoch: 54.7 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762637375257874		[learning rate: 0.0002989]
	Learning Rate: 0.0002989
	LOSS [training: 0.6762637375257874 | validation: 0.8528038692418682]
	TIME [epoch: 54.7 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6935170909888525		[learning rate: 0.00029673]
	Learning Rate: 0.000296735
	LOSS [training: 0.6935170909888525 | validation: 0.8400051150338246]
	TIME [epoch: 54.7 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043634966191837		[learning rate: 0.00029458]
	Learning Rate: 0.000294585
	LOSS [training: 0.7043634966191837 | validation: 0.83083089074022]
	TIME [epoch: 54.7 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930344230221653		[learning rate: 0.00029245]
	Learning Rate: 0.000292451
	LOSS [training: 0.6930344230221653 | validation: 0.8387612043647255]
	TIME [epoch: 54.7 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7011577051873871		[learning rate: 0.00029033]
	Learning Rate: 0.000290332
	LOSS [training: 0.7011577051873871 | validation: 0.89803393075719]
	TIME [epoch: 54.8 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055602830722992		[learning rate: 0.00028823]
	Learning Rate: 0.000288228
	LOSS [training: 0.7055602830722992 | validation: 0.8453535447946137]
	TIME [epoch: 54.7 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954990126525411		[learning rate: 0.00028614]
	Learning Rate: 0.00028614
	LOSS [training: 0.6954990126525411 | validation: 0.8492070838205167]
	TIME [epoch: 54.7 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869278157106796		[learning rate: 0.00028407]
	Learning Rate: 0.000284067
	LOSS [training: 0.6869278157106796 | validation: 0.8369984666721157]
	TIME [epoch: 54.7 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6894782892767604		[learning rate: 0.00028201]
	Learning Rate: 0.000282009
	LOSS [training: 0.6894782892767604 | validation: 0.8983653517389267]
	TIME [epoch: 54.7 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199214707050885		[learning rate: 0.00027997]
	Learning Rate: 0.000279966
	LOSS [training: 0.7199214707050885 | validation: 0.918957792905207]
	TIME [epoch: 54.7 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7091107167642228		[learning rate: 0.00027794]
	Learning Rate: 0.000277938
	LOSS [training: 0.7091107167642228 | validation: 0.814055157317155]
	TIME [epoch: 54.7 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.672621959264893		[learning rate: 0.00027592]
	Learning Rate: 0.000275924
	LOSS [training: 0.672621959264893 | validation: 0.8892727480921527]
	TIME [epoch: 54.7 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6951230725251416		[learning rate: 0.00027392]
	Learning Rate: 0.000273925
	LOSS [training: 0.6951230725251416 | validation: 0.8133686605889381]
	TIME [epoch: 54.7 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811590182595164		[learning rate: 0.00027194]
	Learning Rate: 0.00027194
	LOSS [training: 0.6811590182595164 | validation: 0.8620109884798188]
	TIME [epoch: 54.7 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7292340307925882		[learning rate: 0.00026997]
	Learning Rate: 0.00026997
	LOSS [training: 0.7292340307925882 | validation: 0.8505235130676638]
	TIME [epoch: 54.7 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6786246308259842		[learning rate: 0.00026801]
	Learning Rate: 0.000268014
	LOSS [training: 0.6786246308259842 | validation: 0.8548168387674056]
	TIME [epoch: 54.7 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7057539432379533		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.7057539432379533 | validation: 0.8101549665393266]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_549.pth
	Model improved!!!
EPOCH 550/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6598223480873018		[learning rate: 0.00026414]
	Learning Rate: 0.000264145
	LOSS [training: 0.6598223480873018 | validation: 0.8468303870509941]
	TIME [epoch: 54.7 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692521391383264		[learning rate: 0.00026223]
	Learning Rate: 0.000262231
	LOSS [training: 0.6692521391383264 | validation: 0.8640445695034682]
	TIME [epoch: 54.7 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6949133009933153		[learning rate: 0.00026033]
	Learning Rate: 0.000260331
	LOSS [training: 0.6949133009933153 | validation: 0.8274188029245171]
	TIME [epoch: 54.7 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6702401705134668		[learning rate: 0.00025845]
	Learning Rate: 0.000258445
	LOSS [training: 0.6702401705134668 | validation: 0.848088715774356]
	TIME [epoch: 54.7 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6593721537020095		[learning rate: 0.00025657]
	Learning Rate: 0.000256573
	LOSS [training: 0.6593721537020095 | validation: 0.8467281041268865]
	TIME [epoch: 54.8 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6709810211868366		[learning rate: 0.00025471]
	Learning Rate: 0.000254714
	LOSS [training: 0.6709810211868366 | validation: 0.9007803158374604]
	TIME [epoch: 54.7 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6853760506659261		[learning rate: 0.00025287]
	Learning Rate: 0.000252869
	LOSS [training: 0.6853760506659261 | validation: 0.8318884785060832]
	TIME [epoch: 54.7 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6831324890768217		[learning rate: 0.00025104]
	Learning Rate: 0.000251037
	LOSS [training: 0.6831324890768217 | validation: 0.8495568720291633]
	TIME [epoch: 54.7 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031454048149992		[learning rate: 0.00024922]
	Learning Rate: 0.000249218
	LOSS [training: 0.7031454048149992 | validation: 0.8161426849373836]
	TIME [epoch: 54.7 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6723384567217302		[learning rate: 0.00024741]
	Learning Rate: 0.000247412
	LOSS [training: 0.6723384567217302 | validation: 0.8443331526573837]
	TIME [epoch: 54.7 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809215279118733		[learning rate: 0.00024562]
	Learning Rate: 0.00024562
	LOSS [training: 0.6809215279118733 | validation: 0.8895469914960473]
	TIME [epoch: 54.7 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391881754234594		[learning rate: 0.00024384]
	Learning Rate: 0.00024384
	LOSS [training: 0.7391881754234594 | validation: 0.7964319709473633]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_561.pth
	Model improved!!!
EPOCH 562/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6772924145004617		[learning rate: 0.00024207]
	Learning Rate: 0.000242074
	LOSS [training: 0.6772924145004617 | validation: 0.8180162621890519]
	TIME [epoch: 54.8 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6933410868495966		[learning rate: 0.00024032]
	Learning Rate: 0.00024032
	LOSS [training: 0.6933410868495966 | validation: 0.8402212517467802]
	TIME [epoch: 54.8 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6580019467136897		[learning rate: 0.00023858]
	Learning Rate: 0.000238579
	LOSS [training: 0.6580019467136897 | validation: 0.8449228860759712]
	TIME [epoch: 54.7 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814634245589772		[learning rate: 0.00023685]
	Learning Rate: 0.00023685
	LOSS [training: 0.6814634245589772 | validation: 0.8767890159486724]
	TIME [epoch: 54.7 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.66670051482336		[learning rate: 0.00023513]
	Learning Rate: 0.000235134
	LOSS [training: 0.66670051482336 | validation: 0.8027817734898475]
	TIME [epoch: 54.7 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.665896163807249		[learning rate: 0.00023343]
	Learning Rate: 0.000233431
	LOSS [training: 0.665896163807249 | validation: 0.8122763498933452]
	TIME [epoch: 54.7 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.66973471801496		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.66973471801496 | validation: 0.8423122319596856]
	TIME [epoch: 54.7 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068804952662986		[learning rate: 0.00023006]
	Learning Rate: 0.000230061
	LOSS [training: 0.7068804952662986 | validation: 0.8497332842739844]
	TIME [epoch: 54.7 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213179212615355		[learning rate: 0.00022839]
	Learning Rate: 0.000228394
	LOSS [training: 0.7213179212615355 | validation: 0.8082767624452032]
	TIME [epoch: 54.7 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6708052098610646		[learning rate: 0.00022674]
	Learning Rate: 0.000226739
	LOSS [training: 0.6708052098610646 | validation: 0.8133478434890942]
	TIME [epoch: 54.7 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6834479723726389		[learning rate: 0.0002251]
	Learning Rate: 0.000225096
	LOSS [training: 0.6834479723726389 | validation: 0.9333384630358157]
	TIME [epoch: 54.7 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.7366434594857973		[learning rate: 0.00022347]
	Learning Rate: 0.000223466
	LOSS [training: 0.7366434594857973 | validation: 0.8208182411997503]
	TIME [epoch: 54.7 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597967455547972		[learning rate: 0.00022185]
	Learning Rate: 0.000221847
	LOSS [training: 0.6597967455547972 | validation: 0.8151481055704308]
	TIME [epoch: 54.7 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733536075648101		[learning rate: 0.00022024]
	Learning Rate: 0.000220239
	LOSS [training: 0.6733536075648101 | validation: 0.8217354433880499]
	TIME [epoch: 54.7 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6731139863648786		[learning rate: 0.00021864]
	Learning Rate: 0.000218644
	LOSS [training: 0.6731139863648786 | validation: 0.8308832137746434]
	TIME [epoch: 54.7 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482862373266937		[learning rate: 0.00021706]
	Learning Rate: 0.00021706
	LOSS [training: 0.6482862373266937 | validation: 0.8114644388877748]
	TIME [epoch: 54.7 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683061248268308		[learning rate: 0.00021549]
	Learning Rate: 0.000215487
	LOSS [training: 0.6683061248268308 | validation: 0.8080707824798625]
	TIME [epoch: 54.7 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6657374481377365		[learning rate: 0.00021393]
	Learning Rate: 0.000213926
	LOSS [training: 0.6657374481377365 | validation: 0.8366646086744489]
	TIME [epoch: 54.7 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563482957073186		[learning rate: 0.00021238]
	Learning Rate: 0.000212376
	LOSS [training: 0.6563482957073186 | validation: 0.8207780497619805]
	TIME [epoch: 54.7 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6746337719495954		[learning rate: 0.00021084]
	Learning Rate: 0.000210837
	LOSS [training: 0.6746337719495954 | validation: 0.8069086397548793]
	TIME [epoch: 54.8 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6992958176516352		[learning rate: 0.00020931]
	Learning Rate: 0.00020931
	LOSS [training: 0.6992958176516352 | validation: 0.8629228498144526]
	TIME [epoch: 54.7 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796763652214085		[learning rate: 0.00020779]
	Learning Rate: 0.000207793
	LOSS [training: 0.6796763652214085 | validation: 0.8113509338184703]
	TIME [epoch: 54.8 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6650772480910413		[learning rate: 0.00020629]
	Learning Rate: 0.000206288
	LOSS [training: 0.6650772480910413 | validation: 0.7847533189252923]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_584.pth
	Model improved!!!
EPOCH 585/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6493269729211396		[learning rate: 0.00020479]
	Learning Rate: 0.000204793
	LOSS [training: 0.6493269729211396 | validation: 0.9003034760921564]
	TIME [epoch: 54.8 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6848952645975073		[learning rate: 0.00020331]
	Learning Rate: 0.00020331
	LOSS [training: 0.6848952645975073 | validation: 0.8175132001036861]
	TIME [epoch: 54.7 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791888981198854		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.6791888981198854 | validation: 0.8082765224027697]
	TIME [epoch: 54.7 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6658195374945308		[learning rate: 0.00020037]
	Learning Rate: 0.000200374
	LOSS [training: 0.6658195374945308 | validation: 0.8171317000026761]
	TIME [epoch: 54.8 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.647683501236428		[learning rate: 0.00019892]
	Learning Rate: 0.000198923
	LOSS [training: 0.647683501236428 | validation: 0.8410499373472489]
	TIME [epoch: 54.8 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6675347641716527		[learning rate: 0.00019748]
	Learning Rate: 0.000197482
	LOSS [training: 0.6675347641716527 | validation: 0.8016775120273227]
	TIME [epoch: 54.8 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6440894870313558		[learning rate: 0.00019605]
	Learning Rate: 0.000196051
	LOSS [training: 0.6440894870313558 | validation: 0.8010767086369572]
	TIME [epoch: 54.8 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6338708879360196		[learning rate: 0.00019463]
	Learning Rate: 0.00019463
	LOSS [training: 0.6338708879360196 | validation: 0.812939588049036]
	TIME [epoch: 54.8 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6463600399662535		[learning rate: 0.00019322]
	Learning Rate: 0.00019322
	LOSS [training: 0.6463600399662535 | validation: 0.7935008161567767]
	TIME [epoch: 54.7 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513709270885149		[learning rate: 0.00019182]
	Learning Rate: 0.00019182
	LOSS [training: 0.6513709270885149 | validation: 0.7750789464126296]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_594.pth
	Model improved!!!
EPOCH 595/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6869329154556291		[learning rate: 0.00019043]
	Learning Rate: 0.000190431
	LOSS [training: 0.6869329154556291 | validation: 0.8008881768680618]
	TIME [epoch: 54.8 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411574238270359		[learning rate: 0.00018905]
	Learning Rate: 0.000189051
	LOSS [training: 0.6411574238270359 | validation: 0.7641048080164503]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_596.pth
	Model improved!!!
EPOCH 597/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409868416209537		[learning rate: 0.00018768]
	Learning Rate: 0.000187681
	LOSS [training: 0.6409868416209537 | validation: 0.7692632387583058]
	TIME [epoch: 54.8 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6785739942245099		[learning rate: 0.00018632]
	Learning Rate: 0.000186322
	LOSS [training: 0.6785739942245099 | validation: 0.7928695267451134]
	TIME [epoch: 54.8 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6474561292000919		[learning rate: 0.00018497]
	Learning Rate: 0.000184972
	LOSS [training: 0.6474561292000919 | validation: 0.7713189629871251]
	TIME [epoch: 54.8 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6645826110807214		[learning rate: 0.00018363]
	Learning Rate: 0.000183632
	LOSS [training: 0.6645826110807214 | validation: 0.8139652423396222]
	TIME [epoch: 54.8 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6824444512160509		[learning rate: 0.0001823]
	Learning Rate: 0.000182301
	LOSS [training: 0.6824444512160509 | validation: 0.8138145837585469]
	TIME [epoch: 54.8 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.65070956306187		[learning rate: 0.00018098]
	Learning Rate: 0.00018098
	LOSS [training: 0.65070956306187 | validation: 0.8026760105408202]
	TIME [epoch: 54.8 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6630572629934068		[learning rate: 0.00017967]
	Learning Rate: 0.000179669
	LOSS [training: 0.6630572629934068 | validation: 0.7974947759739989]
	TIME [epoch: 54.8 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6612573223075242		[learning rate: 0.00017837]
	Learning Rate: 0.000178368
	LOSS [training: 0.6612573223075242 | validation: 0.7935593829856029]
	TIME [epoch: 54.8 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6797428791179083		[learning rate: 0.00017708]
	Learning Rate: 0.000177075
	LOSS [training: 0.6797428791179083 | validation: 0.8388095054784863]
	TIME [epoch: 54.8 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555901240127516		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.6555901240127516 | validation: 0.7696139503699206]
	TIME [epoch: 54.8 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6476250239740557		[learning rate: 0.00017452]
	Learning Rate: 0.000174519
	LOSS [training: 0.6476250239740557 | validation: 0.7824657896115264]
	TIME [epoch: 54.8 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430751442514079		[learning rate: 0.00017325]
	Learning Rate: 0.000173254
	LOSS [training: 0.6430751442514079 | validation: 0.7829760218556638]
	TIME [epoch: 54.8 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454230149792228		[learning rate: 0.000172]
	Learning Rate: 0.000171999
	LOSS [training: 0.6454230149792228 | validation: 0.7686290732796914]
	TIME [epoch: 54.8 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6415560191005921		[learning rate: 0.00017075]
	Learning Rate: 0.000170753
	LOSS [training: 0.6415560191005921 | validation: 0.8031347954731451]
	TIME [epoch: 54.8 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470100753147825		[learning rate: 0.00016952]
	Learning Rate: 0.000169516
	LOSS [training: 0.6470100753147825 | validation: 0.7885135849575231]
	TIME [epoch: 54.8 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6637226105229667		[learning rate: 0.00016829]
	Learning Rate: 0.000168288
	LOSS [training: 0.6637226105229667 | validation: 0.8219866096396518]
	TIME [epoch: 54.7 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382120082895403		[learning rate: 0.00016707]
	Learning Rate: 0.000167069
	LOSS [training: 0.6382120082895403 | validation: 0.8028430202899941]
	TIME [epoch: 54.8 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6625708203544409		[learning rate: 0.00016586]
	Learning Rate: 0.000165858
	LOSS [training: 0.6625708203544409 | validation: 0.8199246488960699]
	TIME [epoch: 54.8 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6561452962571847		[learning rate: 0.00016466]
	Learning Rate: 0.000164657
	LOSS [training: 0.6561452962571847 | validation: 0.8054861727532237]
	TIME [epoch: 54.8 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577429984906205		[learning rate: 0.00016346]
	Learning Rate: 0.000163464
	LOSS [training: 0.6577429984906205 | validation: 0.8390265693982657]
	TIME [epoch: 54.8 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683220256011506		[learning rate: 0.00016228]
	Learning Rate: 0.000162279
	LOSS [training: 0.6683220256011506 | validation: 0.7808395401564469]
	TIME [epoch: 54.8 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277852165306823		[learning rate: 0.0001611]
	Learning Rate: 0.000161104
	LOSS [training: 0.6277852165306823 | validation: 0.7910991885939704]
	TIME [epoch: 54.8 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385458807169488		[learning rate: 0.00015994]
	Learning Rate: 0.000159936
	LOSS [training: 0.6385458807169488 | validation: 0.8139090507555629]
	TIME [epoch: 54.8 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526538062869973		[learning rate: 0.00015878]
	Learning Rate: 0.000158778
	LOSS [training: 0.6526538062869973 | validation: 0.8287804649934163]
	TIME [epoch: 54.7 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6501409868497694		[learning rate: 0.00015763]
	Learning Rate: 0.000157627
	LOSS [training: 0.6501409868497694 | validation: 0.8004602860195034]
	TIME [epoch: 54.8 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335098479245167		[learning rate: 0.00015649]
	Learning Rate: 0.000156485
	LOSS [training: 0.6335098479245167 | validation: 0.7672835077501763]
	TIME [epoch: 54.7 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.641448634029571		[learning rate: 0.00015535]
	Learning Rate: 0.000155352
	LOSS [training: 0.641448634029571 | validation: 0.7739829610122155]
	TIME [epoch: 54.8 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.626782694345413		[learning rate: 0.00015423]
	Learning Rate: 0.000154226
	LOSS [training: 0.626782694345413 | validation: 0.7843340809855321]
	TIME [epoch: 54.7 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6339749463172959		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.6339749463172959 | validation: 0.7810456158605575]
	TIME [epoch: 54.7 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6424536732816104		[learning rate: 0.000152]
	Learning Rate: 0.000152
	LOSS [training: 0.6424536732816104 | validation: 0.7875800920501888]
	TIME [epoch: 54.8 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6304894473458582		[learning rate: 0.0001509]
	Learning Rate: 0.000150898
	LOSS [training: 0.6304894473458582 | validation: 0.7919204401946114]
	TIME [epoch: 54.8 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.657219929972757		[learning rate: 0.00014981]
	Learning Rate: 0.000149805
	LOSS [training: 0.657219929972757 | validation: 0.8584961467877268]
	TIME [epoch: 54.8 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6602144270913112		[learning rate: 0.00014872]
	Learning Rate: 0.00014872
	LOSS [training: 0.6602144270913112 | validation: 0.8226105476867682]
	TIME [epoch: 54.8 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6374071891627953		[learning rate: 0.00014764]
	Learning Rate: 0.000147642
	LOSS [training: 0.6374071891627953 | validation: 0.784395223832068]
	TIME [epoch: 54.7 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6321105363034292		[learning rate: 0.00014657]
	Learning Rate: 0.000146573
	LOSS [training: 0.6321105363034292 | validation: 0.7919805627461827]
	TIME [epoch: 54.8 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492022033140619		[learning rate: 0.00014551]
	Learning Rate: 0.000145511
	LOSS [training: 0.6492022033140619 | validation: 0.8286590476044912]
	TIME [epoch: 54.8 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6452420414079038		[learning rate: 0.00014446]
	Learning Rate: 0.000144456
	LOSS [training: 0.6452420414079038 | validation: 0.7970924887465156]
	TIME [epoch: 54.8 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433306087277161		[learning rate: 0.00014341]
	Learning Rate: 0.00014341
	LOSS [training: 0.6433306087277161 | validation: 0.7650518763390382]
	TIME [epoch: 54.7 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422350262122029		[learning rate: 0.00014237]
	Learning Rate: 0.000142371
	LOSS [training: 0.6422350262122029 | validation: 0.823207547187062]
	TIME [epoch: 54.7 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6567917376782915		[learning rate: 0.00014134]
	Learning Rate: 0.000141339
	LOSS [training: 0.6567917376782915 | validation: 0.7965082948867981]
	TIME [epoch: 54.8 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438993350621278		[learning rate: 0.00014032]
	Learning Rate: 0.000140315
	LOSS [training: 0.6438993350621278 | validation: 0.785411985421522]
	TIME [epoch: 54.8 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299125105150405		[learning rate: 0.0001393]
	Learning Rate: 0.000139299
	LOSS [training: 0.6299125105150405 | validation: 0.7551617964004205]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_638.pth
	Model improved!!!
EPOCH 639/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297060791969583		[learning rate: 0.00013829]
	Learning Rate: 0.00013829
	LOSS [training: 0.6297060791969583 | validation: 0.782027000841752]
	TIME [epoch: 54.8 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347951550331902		[learning rate: 0.00013729]
	Learning Rate: 0.000137288
	LOSS [training: 0.6347951550331902 | validation: 0.7775049409951909]
	TIME [epoch: 54.8 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6478644415723029		[learning rate: 0.00013629]
	Learning Rate: 0.000136293
	LOSS [training: 0.6478644415723029 | validation: 0.79825465627372]
	TIME [epoch: 54.8 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6428463412359681		[learning rate: 0.00013531]
	Learning Rate: 0.000135306
	LOSS [training: 0.6428463412359681 | validation: 0.7591813506687886]
	TIME [epoch: 54.8 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6252647180820885		[learning rate: 0.00013433]
	Learning Rate: 0.000134325
	LOSS [training: 0.6252647180820885 | validation: 0.8081204849140853]
	TIME [epoch: 54.8 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491586941000221		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.6491586941000221 | validation: 0.7839508432783395]
	TIME [epoch: 54.8 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6298807112542043		[learning rate: 0.00013239]
	Learning Rate: 0.000132386
	LOSS [training: 0.6298807112542043 | validation: 0.762809086108224]
	TIME [epoch: 54.8 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6270146105205359		[learning rate: 0.00013143]
	Learning Rate: 0.000131427
	LOSS [training: 0.6270146105205359 | validation: 0.7695619586003835]
	TIME [epoch: 54.8 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6417976700301203		[learning rate: 0.00013047]
	Learning Rate: 0.000130475
	LOSS [training: 0.6417976700301203 | validation: 0.7931715382945361]
	TIME [epoch: 54.8 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6334617622017689		[learning rate: 0.00012953]
	Learning Rate: 0.000129529
	LOSS [training: 0.6334617622017689 | validation: 0.795602697133432]
	TIME [epoch: 54.8 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6312650808432656		[learning rate: 0.00012859]
	Learning Rate: 0.000128591
	LOSS [training: 0.6312650808432656 | validation: 0.7953132601166952]
	TIME [epoch: 54.8 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6308122098507599		[learning rate: 0.00012766]
	Learning Rate: 0.000127659
	LOSS [training: 0.6308122098507599 | validation: 0.781827158673513]
	TIME [epoch: 54.7 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277210933456836		[learning rate: 0.00012673]
	Learning Rate: 0.000126734
	LOSS [training: 0.6277210933456836 | validation: 0.7800624005039543]
	TIME [epoch: 54.8 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6581731508940099		[learning rate: 0.00012582]
	Learning Rate: 0.000125816
	LOSS [training: 0.6581731508940099 | validation: 0.8198766619163982]
	TIME [epoch: 54.8 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6559658680920744		[learning rate: 0.0001249]
	Learning Rate: 0.000124905
	LOSS [training: 0.6559658680920744 | validation: 0.7741882080736757]
	TIME [epoch: 54.8 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480761042653795		[learning rate: 0.000124]
	Learning Rate: 0.000124
	LOSS [training: 0.6480761042653795 | validation: 0.7925803294311576]
	TIME [epoch: 54.8 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6454815382420217		[learning rate: 0.0001231]
	Learning Rate: 0.000123101
	LOSS [training: 0.6454815382420217 | validation: 0.7879939960147068]
	TIME [epoch: 54.8 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6215954146358087		[learning rate: 0.00012221]
	Learning Rate: 0.00012221
	LOSS [training: 0.6215954146358087 | validation: 0.7828383770279858]
	TIME [epoch: 54.8 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257450420894131		[learning rate: 0.00012132]
	Learning Rate: 0.000121324
	LOSS [training: 0.6257450420894131 | validation: 0.7954262425085841]
	TIME [epoch: 54.7 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329361591709534		[learning rate: 0.00012045]
	Learning Rate: 0.000120445
	LOSS [training: 0.6329361591709534 | validation: 0.8279082931556702]
	TIME [epoch: 54.7 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485683494240885		[learning rate: 0.00011957]
	Learning Rate: 0.000119573
	LOSS [training: 0.6485683494240885 | validation: 0.7970764559680841]
	TIME [epoch: 54.8 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407827821049884		[learning rate: 0.00011871]
	Learning Rate: 0.000118706
	LOSS [training: 0.6407827821049884 | validation: 0.7896746375612]
	TIME [epoch: 54.8 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283851518752142		[learning rate: 0.00011785]
	Learning Rate: 0.000117846
	LOSS [training: 0.6283851518752142 | validation: 0.780272857424218]
	TIME [epoch: 54.8 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6318744209645086		[learning rate: 0.00011699]
	Learning Rate: 0.000116992
	LOSS [training: 0.6318744209645086 | validation: 0.7809949539711531]
	TIME [epoch: 54.7 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6437651337932236		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.6437651337932236 | validation: 0.7738711917725465]
	TIME [epoch: 54.8 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218263480468627		[learning rate: 0.0001153]
	Learning Rate: 0.000115303
	LOSS [training: 0.6218263480468627 | validation: 0.77240308648191]
	TIME [epoch: 54.7 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217497387481856		[learning rate: 0.00011447]
	Learning Rate: 0.000114468
	LOSS [training: 0.6217497387481856 | validation: 0.7816686365517174]
	TIME [epoch: 54.7 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213046465735881		[learning rate: 0.00011364]
	Learning Rate: 0.000113639
	LOSS [training: 0.6213046465735881 | validation: 0.7698819562582297]
	TIME [epoch: 54.8 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6328912339402235		[learning rate: 0.00011282]
	Learning Rate: 0.000112815
	LOSS [training: 0.6328912339402235 | validation: 0.7944864502249074]
	TIME [epoch: 54.8 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6420747640989933		[learning rate: 0.000112]
	Learning Rate: 0.000111998
	LOSS [training: 0.6420747640989933 | validation: 0.7958181788736829]
	TIME [epoch: 54.8 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.619766920563481		[learning rate: 0.00011119]
	Learning Rate: 0.000111187
	LOSS [training: 0.619766920563481 | validation: 0.7649496228205359]
	TIME [epoch: 54.8 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186530873818442		[learning rate: 0.00011038]
	Learning Rate: 0.000110381
	LOSS [training: 0.6186530873818442 | validation: 0.780074725517669]
	TIME [epoch: 54.8 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.625890592637877		[learning rate: 0.00010958]
	Learning Rate: 0.000109581
	LOSS [training: 0.625890592637877 | validation: 0.7784688048019586]
	TIME [epoch: 54.7 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6430713659000284		[learning rate: 0.00010879]
	Learning Rate: 0.000108787
	LOSS [training: 0.6430713659000284 | validation: 0.7943391613288159]
	TIME [epoch: 54.7 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314059280606956		[learning rate: 0.000108]
	Learning Rate: 0.000107999
	LOSS [training: 0.6314059280606956 | validation: 0.7703932275043637]
	TIME [epoch: 54.7 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111129826047526		[learning rate: 0.00010722]
	Learning Rate: 0.000107217
	LOSS [training: 0.6111129826047526 | validation: 0.8136558082114393]
	TIME [epoch: 54.8 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6610604483376159		[learning rate: 0.00010644]
	Learning Rate: 0.00010644
	LOSS [training: 0.6610604483376159 | validation: 0.803777107722927]
	TIME [epoch: 54.7 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6337557469275645		[learning rate: 0.00010567]
	Learning Rate: 0.000105669
	LOSS [training: 0.6337557469275645 | validation: 0.7711800097357222]
	TIME [epoch: 54.8 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.625661134119033		[learning rate: 0.0001049]
	Learning Rate: 0.000104903
	LOSS [training: 0.625661134119033 | validation: 0.7771283769507978]
	TIME [epoch: 54.7 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6304324409781746		[learning rate: 0.00010414]
	Learning Rate: 0.000104143
	LOSS [training: 0.6304324409781746 | validation: 0.7858238547828507]
	TIME [epoch: 54.8 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309105157691335		[learning rate: 0.00010339]
	Learning Rate: 0.000103389
	LOSS [training: 0.6309105157691335 | validation: 0.8018364919509182]
	TIME [epoch: 54.8 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436927832728686		[learning rate: 0.00010264]
	Learning Rate: 0.00010264
	LOSS [training: 0.6436927832728686 | validation: 0.7860257772042696]
	TIME [epoch: 54.7 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6506598310466185		[learning rate: 0.0001019]
	Learning Rate: 0.000101896
	LOSS [training: 0.6506598310466185 | validation: 0.7916643804111776]
	TIME [epoch: 54.7 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6360103350967531		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.6360103350967531 | validation: 0.7653016692542858]
	TIME [epoch: 54.8 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6317137807579505		[learning rate: 0.00010043]
	Learning Rate: 0.000100425
	LOSS [training: 0.6317137807579505 | validation: 0.765421232270699]
	TIME [epoch: 54.7 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275771027411432		[learning rate: 9.9697e-05]
	Learning Rate: 9.96975e-05
	LOSS [training: 0.6275771027411432 | validation: 0.7700485881049817]
	TIME [epoch: 54.8 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281748057341235		[learning rate: 9.8975e-05]
	Learning Rate: 9.89752e-05
	LOSS [training: 0.6281748057341235 | validation: 0.7774630140953318]
	TIME [epoch: 54.8 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6255675810247929		[learning rate: 9.8258e-05]
	Learning Rate: 9.82581e-05
	LOSS [training: 0.6255675810247929 | validation: 0.7711014285812587]
	TIME [epoch: 54.7 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6295628879063622		[learning rate: 9.7546e-05]
	Learning Rate: 9.75463e-05
	LOSS [training: 0.6295628879063622 | validation: 0.7455613097145014]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_687.pth
	Model improved!!!
EPOCH 688/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221456045296885		[learning rate: 9.684e-05]
	Learning Rate: 9.68396e-05
	LOSS [training: 0.6221456045296885 | validation: 0.7711594300369169]
	TIME [epoch: 54.8 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267345723552848		[learning rate: 9.6138e-05]
	Learning Rate: 9.61379e-05
	LOSS [training: 0.6267345723552848 | validation: 0.7718228982215805]
	TIME [epoch: 54.8 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6326206570659044		[learning rate: 9.5441e-05]
	Learning Rate: 9.54414e-05
	LOSS [training: 0.6326206570659044 | validation: 0.78350267569018]
	TIME [epoch: 54.7 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6176408321333261		[learning rate: 9.475e-05]
	Learning Rate: 9.475e-05
	LOSS [training: 0.6176408321333261 | validation: 0.7871686970380334]
	TIME [epoch: 54.7 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235504520813047		[learning rate: 9.4064e-05]
	Learning Rate: 9.40635e-05
	LOSS [training: 0.6235504520813047 | validation: 0.7995338437980046]
	TIME [epoch: 54.7 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6479487812944845		[learning rate: 9.3382e-05]
	Learning Rate: 9.3382e-05
	LOSS [training: 0.6479487812944845 | validation: 0.8010428217365939]
	TIME [epoch: 54.7 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6286913717062013		[learning rate: 9.2705e-05]
	Learning Rate: 9.27055e-05
	LOSS [training: 0.6286913717062013 | validation: 0.8020181962668198]
	TIME [epoch: 54.7 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6420553024953204		[learning rate: 9.2034e-05]
	Learning Rate: 9.20338e-05
	LOSS [training: 0.6420553024953204 | validation: 0.7796166873217143]
	TIME [epoch: 54.7 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141503108463092		[learning rate: 9.1367e-05]
	Learning Rate: 9.13671e-05
	LOSS [training: 0.6141503108463092 | validation: 0.8003312096991704]
	TIME [epoch: 54.7 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518787157853121		[learning rate: 9.0705e-05]
	Learning Rate: 9.07051e-05
	LOSS [training: 0.6518787157853121 | validation: 0.8093197407947939]
	TIME [epoch: 54.7 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262631565770664		[learning rate: 9.0048e-05]
	Learning Rate: 9.00479e-05
	LOSS [training: 0.6262631565770664 | validation: 0.7747077404931302]
	TIME [epoch: 54.7 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256608651174681		[learning rate: 8.9396e-05]
	Learning Rate: 8.93955e-05
	LOSS [training: 0.6256608651174681 | validation: 0.7854355679378409]
	TIME [epoch: 54.7 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6279308787110227		[learning rate: 8.8748e-05]
	Learning Rate: 8.87479e-05
	LOSS [training: 0.6279308787110227 | validation: 0.7783062117601358]
	TIME [epoch: 54.8 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243471122503063		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.6243471122503063 | validation: 0.7564759401531912]
	TIME [epoch: 54.9 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224373416288457		[learning rate: 8.7467e-05]
	Learning Rate: 8.74666e-05
	LOSS [training: 0.6224373416288457 | validation: 0.7673903430762499]
	TIME [epoch: 54.8 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6185792810711502		[learning rate: 8.6833e-05]
	Learning Rate: 8.68329e-05
	LOSS [training: 0.6185792810711502 | validation: 0.7616556670524604]
	TIME [epoch: 54.8 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243347176578313		[learning rate: 8.6204e-05]
	Learning Rate: 8.62038e-05
	LOSS [training: 0.6243347176578313 | validation: 0.7843701749094244]
	TIME [epoch: 54.8 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6194988202878533		[learning rate: 8.5579e-05]
	Learning Rate: 8.55793e-05
	LOSS [training: 0.6194988202878533 | validation: 0.769579383597338]
	TIME [epoch: 54.8 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329892308787644		[learning rate: 8.4959e-05]
	Learning Rate: 8.49592e-05
	LOSS [training: 0.6329892308787644 | validation: 0.7796418027668]
	TIME [epoch: 54.8 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.61498209578736		[learning rate: 8.4344e-05]
	Learning Rate: 8.43437e-05
	LOSS [training: 0.61498209578736 | validation: 0.7694971130716983]
	TIME [epoch: 54.8 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6257431773132114		[learning rate: 8.3733e-05]
	Learning Rate: 8.37327e-05
	LOSS [training: 0.6257431773132114 | validation: 0.7816276077256272]
	TIME [epoch: 54.8 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472236795760535		[learning rate: 8.3126e-05]
	Learning Rate: 8.3126e-05
	LOSS [training: 0.6472236795760535 | validation: 0.7874313343795267]
	TIME [epoch: 54.8 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275281116040097		[learning rate: 8.2524e-05]
	Learning Rate: 8.25238e-05
	LOSS [training: 0.6275281116040097 | validation: 0.7817066976492539]
	TIME [epoch: 54.7 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391453569988075		[learning rate: 8.1926e-05]
	Learning Rate: 8.19259e-05
	LOSS [training: 0.6391453569988075 | validation: 0.7866653341387712]
	TIME [epoch: 54.7 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.618360360961874		[learning rate: 8.1332e-05]
	Learning Rate: 8.13323e-05
	LOSS [training: 0.618360360961874 | validation: 0.772081463796594]
	TIME [epoch: 54.8 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6187693971433841		[learning rate: 8.0743e-05]
	Learning Rate: 8.07431e-05
	LOSS [training: 0.6187693971433841 | validation: 0.8029641928298443]
	TIME [epoch: 54.7 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6356166778843202		[learning rate: 8.0158e-05]
	Learning Rate: 8.01581e-05
	LOSS [training: 0.6356166778843202 | validation: 0.768974369946295]
	TIME [epoch: 54.8 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6191067499833462		[learning rate: 7.9577e-05]
	Learning Rate: 7.95774e-05
	LOSS [training: 0.6191067499833462 | validation: 0.7571163274772792]
	TIME [epoch: 54.8 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243859712628687		[learning rate: 7.9001e-05]
	Learning Rate: 7.90008e-05
	LOSS [training: 0.6243859712628687 | validation: 0.7789195448524294]
	TIME [epoch: 54.8 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159228102236187		[learning rate: 7.8428e-05]
	Learning Rate: 7.84285e-05
	LOSS [training: 0.6159228102236187 | validation: 0.7619129217626995]
	TIME [epoch: 54.8 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6180865212120606		[learning rate: 7.786e-05]
	Learning Rate: 7.78603e-05
	LOSS [training: 0.6180865212120606 | validation: 0.7598294458968538]
	TIME [epoch: 54.8 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127436350855985		[learning rate: 7.7296e-05]
	Learning Rate: 7.72962e-05
	LOSS [training: 0.6127436350855985 | validation: 0.7844618392323968]
	TIME [epoch: 54.8 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6359914239476614		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.6359914239476614 | validation: 0.7772560986089045]
	TIME [epoch: 54.7 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281323622419595		[learning rate: 7.618e-05]
	Learning Rate: 7.61802e-05
	LOSS [training: 0.6281323622419595 | validation: 0.7554404398882069]
	TIME [epoch: 54.8 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.614331033593584		[learning rate: 7.5628e-05]
	Learning Rate: 7.56283e-05
	LOSS [training: 0.614331033593584 | validation: 0.7739416888690802]
	TIME [epoch: 54.8 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6285526517832991		[learning rate: 7.508e-05]
	Learning Rate: 7.50804e-05
	LOSS [training: 0.6285526517832991 | validation: 0.7603322515053841]
	TIME [epoch: 54.7 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6219459833598835		[learning rate: 7.4536e-05]
	Learning Rate: 7.45364e-05
	LOSS [training: 0.6219459833598835 | validation: 0.7628668016259299]
	TIME [epoch: 54.8 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6188564458501521		[learning rate: 7.3996e-05]
	Learning Rate: 7.39964e-05
	LOSS [training: 0.6188564458501521 | validation: 0.795771097031609]
	TIME [epoch: 54.7 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6448516124434429		[learning rate: 7.346e-05]
	Learning Rate: 7.34603e-05
	LOSS [training: 0.6448516124434429 | validation: 0.8114766081089458]
	TIME [epoch: 54.7 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218212601941152		[learning rate: 7.2928e-05]
	Learning Rate: 7.29281e-05
	LOSS [training: 0.6218212601941152 | validation: 0.7631023336257576]
	TIME [epoch: 54.7 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220104536127823		[learning rate: 7.24e-05]
	Learning Rate: 7.23997e-05
	LOSS [training: 0.6220104536127823 | validation: 0.7698745580345039]
	TIME [epoch: 54.8 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127672108983766		[learning rate: 7.1875e-05]
	Learning Rate: 7.18752e-05
	LOSS [training: 0.6127672108983766 | validation: 0.7597479402338155]
	TIME [epoch: 54.7 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6239142609925673		[learning rate: 7.1354e-05]
	Learning Rate: 7.13545e-05
	LOSS [training: 0.6239142609925673 | validation: 0.7620402676828774]
	TIME [epoch: 54.8 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6179475758591338		[learning rate: 7.0838e-05]
	Learning Rate: 7.08375e-05
	LOSS [training: 0.6179475758591338 | validation: 0.7631143576533423]
	TIME [epoch: 54.7 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186816354245659		[learning rate: 7.0324e-05]
	Learning Rate: 7.03243e-05
	LOSS [training: 0.6186816354245659 | validation: 0.7669802324757174]
	TIME [epoch: 54.8 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121677012464837		[learning rate: 6.9815e-05]
	Learning Rate: 6.98148e-05
	LOSS [training: 0.6121677012464837 | validation: 0.7799677316823465]
	TIME [epoch: 54.7 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229201957771504		[learning rate: 6.9309e-05]
	Learning Rate: 6.9309e-05
	LOSS [training: 0.6229201957771504 | validation: 0.7735978375545705]
	TIME [epoch: 54.7 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291923501261273		[learning rate: 6.8807e-05]
	Learning Rate: 6.88069e-05
	LOSS [training: 0.6291923501261273 | validation: 0.7746519703916428]
	TIME [epoch: 54.7 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218731051289866		[learning rate: 6.8308e-05]
	Learning Rate: 6.83084e-05
	LOSS [training: 0.6218731051289866 | validation: 0.7644644081764278]
	TIME [epoch: 54.8 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128201323310428		[learning rate: 6.7813e-05]
	Learning Rate: 6.78134e-05
	LOSS [training: 0.6128201323310428 | validation: 0.7624404973427583]
	TIME [epoch: 54.8 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207584781881865		[learning rate: 6.7322e-05]
	Learning Rate: 6.73222e-05
	LOSS [training: 0.6207584781881865 | validation: 0.7444061049154359]
	TIME [epoch: 54.7 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_738.pth
	Model improved!!!
EPOCH 739/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122046366561649		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.6122046366561649 | validation: 0.7605328431459669]
	TIME [epoch: 54.7 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6175677745526776		[learning rate: 6.635e-05]
	Learning Rate: 6.63502e-05
	LOSS [training: 0.6175677745526776 | validation: 0.7643221091288523]
	TIME [epoch: 54.8 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162457806547238		[learning rate: 6.587e-05]
	Learning Rate: 6.58695e-05
	LOSS [training: 0.6162457806547238 | validation: 0.7631185279600673]
	TIME [epoch: 54.8 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284596552799547		[learning rate: 6.5392e-05]
	Learning Rate: 6.53923e-05
	LOSS [training: 0.6284596552799547 | validation: 0.765865423938296]
	TIME [epoch: 54.8 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.657734506898735		[learning rate: 6.4919e-05]
	Learning Rate: 6.49185e-05
	LOSS [training: 0.657734506898735 | validation: 0.7410353319700906]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_743.pth
	Model improved!!!
EPOCH 744/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.627093672841645		[learning rate: 6.4448e-05]
	Learning Rate: 6.44482e-05
	LOSS [training: 0.627093672841645 | validation: 0.7601808010496993]
	TIME [epoch: 54.8 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307585131301499		[learning rate: 6.3981e-05]
	Learning Rate: 6.39813e-05
	LOSS [training: 0.6307585131301499 | validation: 0.7511916959266455]
	TIME [epoch: 54.8 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6277390387258996		[learning rate: 6.3518e-05]
	Learning Rate: 6.35177e-05
	LOSS [training: 0.6277390387258996 | validation: 0.7452283534045813]
	TIME [epoch: 54.8 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.611438751339177		[learning rate: 6.3058e-05]
	Learning Rate: 6.30575e-05
	LOSS [training: 0.611438751339177 | validation: 0.7668328427468731]
	TIME [epoch: 54.8 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.615485987407419		[learning rate: 6.2601e-05]
	Learning Rate: 6.26007e-05
	LOSS [training: 0.615485987407419 | validation: 0.7385898338440082]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_748.pth
	Model improved!!!
EPOCH 749/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189352894145904		[learning rate: 6.2147e-05]
	Learning Rate: 6.21471e-05
	LOSS [training: 0.6189352894145904 | validation: 0.7520729704719296]
	TIME [epoch: 54.8 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6129887375828251		[learning rate: 6.1697e-05]
	Learning Rate: 6.16969e-05
	LOSS [training: 0.6129887375828251 | validation: 0.7447627864351922]
	TIME [epoch: 54.8 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159461850599923		[learning rate: 6.125e-05]
	Learning Rate: 6.12499e-05
	LOSS [training: 0.6159461850599923 | validation: 0.7536814533641485]
	TIME [epoch: 54.8 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6111316018134799		[learning rate: 6.0806e-05]
	Learning Rate: 6.08061e-05
	LOSS [training: 0.6111316018134799 | validation: 0.7684494502314289]
	TIME [epoch: 54.8 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6129326129830849		[learning rate: 6.0366e-05]
	Learning Rate: 6.03656e-05
	LOSS [training: 0.6129326129830849 | validation: 0.7745027449166966]
	TIME [epoch: 54.8 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.611603903810357		[learning rate: 5.9928e-05]
	Learning Rate: 5.99283e-05
	LOSS [training: 0.611603903810357 | validation: 0.7572171705621606]
	TIME [epoch: 54.8 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6249811279945886		[learning rate: 5.9494e-05]
	Learning Rate: 5.94941e-05
	LOSS [training: 0.6249811279945886 | validation: 0.7850074164626175]
	TIME [epoch: 54.8 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281312574503637		[learning rate: 5.9063e-05]
	Learning Rate: 5.90631e-05
	LOSS [training: 0.6281312574503637 | validation: 0.7681634155501611]
	TIME [epoch: 54.8 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6335010213811735		[learning rate: 5.8635e-05]
	Learning Rate: 5.86351e-05
	LOSS [training: 0.6335010213811735 | validation: 0.8095963610879224]
	TIME [epoch: 54.8 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466586644319909		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.6466586644319909 | validation: 0.799696434761505]
	TIME [epoch: 54.8 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309943398369735		[learning rate: 5.7789e-05]
	Learning Rate: 5.77886e-05
	LOSS [training: 0.6309943398369735 | validation: 0.7642946379986719]
	TIME [epoch: 54.8 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183023053128687		[learning rate: 5.737e-05]
	Learning Rate: 5.73699e-05
	LOSS [training: 0.6183023053128687 | validation: 0.7585123123528787]
	TIME [epoch: 54.8 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186776498781723		[learning rate: 5.6954e-05]
	Learning Rate: 5.69543e-05
	LOSS [training: 0.6186776498781723 | validation: 0.7576147764802689]
	TIME [epoch: 54.8 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6230334119169562		[learning rate: 5.6542e-05]
	Learning Rate: 5.65417e-05
	LOSS [training: 0.6230334119169562 | validation: 0.7577483854538173]
	TIME [epoch: 54.8 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200132875841736		[learning rate: 5.6132e-05]
	Learning Rate: 5.6132e-05
	LOSS [training: 0.6200132875841736 | validation: 0.7623171554546757]
	TIME [epoch: 54.8 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224141287170134		[learning rate: 5.5725e-05]
	Learning Rate: 5.57253e-05
	LOSS [training: 0.6224141287170134 | validation: 0.7751557901350664]
	TIME [epoch: 54.8 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100637408890178		[learning rate: 5.5322e-05]
	Learning Rate: 5.53216e-05
	LOSS [training: 0.6100637408890178 | validation: 0.7485008900199608]
	TIME [epoch: 54.8 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6102546475299737		[learning rate: 5.4921e-05]
	Learning Rate: 5.49208e-05
	LOSS [training: 0.6102546475299737 | validation: 0.7625101577669542]
	TIME [epoch: 54.8 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6300988887298666		[learning rate: 5.4523e-05]
	Learning Rate: 5.45229e-05
	LOSS [training: 0.6300988887298666 | validation: 0.7761860964396095]
	TIME [epoch: 54.8 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.615520563690073		[learning rate: 5.4128e-05]
	Learning Rate: 5.41279e-05
	LOSS [training: 0.615520563690073 | validation: 0.7587683410148147]
	TIME [epoch: 54.8 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6264461411508885		[learning rate: 5.3736e-05]
	Learning Rate: 5.37357e-05
	LOSS [training: 0.6264461411508885 | validation: 0.7684306516548078]
	TIME [epoch: 54.7 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352277063080858		[learning rate: 5.3346e-05]
	Learning Rate: 5.33464e-05
	LOSS [training: 0.6352277063080858 | validation: 0.7797920609633149]
	TIME [epoch: 54.7 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345870153532517		[learning rate: 5.296e-05]
	Learning Rate: 5.29599e-05
	LOSS [training: 0.6345870153532517 | validation: 0.7876193595423318]
	TIME [epoch: 54.8 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6164904192373291		[learning rate: 5.2576e-05]
	Learning Rate: 5.25762e-05
	LOSS [training: 0.6164904192373291 | validation: 0.7538367647254574]
	TIME [epoch: 54.8 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6105250643678507		[learning rate: 5.2195e-05]
	Learning Rate: 5.21953e-05
	LOSS [training: 0.6105250643678507 | validation: 0.7324478582325628]
	TIME [epoch: 54.8 sec]
	Saving model to: out/model_training/model_phiq_1a_v_klv2_20241205_183101/states/model_phiq_1a_v_klv2_773.pth
	Model improved!!!
EPOCH 774/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6250838495949974		[learning rate: 5.1817e-05]
	Learning Rate: 5.18172e-05
	LOSS [training: 0.6250838495949974 | validation: 0.7451513229120659]
	TIME [epoch: 54.8 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135941810202129		[learning rate: 5.1442e-05]
	Learning Rate: 5.14418e-05
	LOSS [training: 0.6135941810202129 | validation: 0.741874936746011]
	TIME [epoch: 54.8 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6106855181089521		[learning rate: 5.1069e-05]
	Learning Rate: 5.10691e-05
	LOSS [training: 0.6106855181089521 | validation: 0.773492457878415]
	TIME [epoch: 54.8 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138513728715914		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.6138513728715914 | validation: 0.7615601942327455]
	TIME [epoch: 54.8 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6117289704623559		[learning rate: 5.0332e-05]
	Learning Rate: 5.03318e-05
	LOSS [training: 0.6117289704623559 | validation: 0.7582274553676727]
	TIME [epoch: 54.8 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149134781410044		[learning rate: 4.9967e-05]
	Learning Rate: 4.99671e-05
	LOSS [training: 0.6149134781410044 | validation: 0.7614517868539841]
	TIME [epoch: 54.8 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118300380427779		[learning rate: 4.9605e-05]
	Learning Rate: 4.96051e-05
	LOSS [training: 0.6118300380427779 | validation: 0.7454861938162719]
	TIME [epoch: 54.8 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6134286298426057		[learning rate: 4.9246e-05]
	Learning Rate: 4.92457e-05
	LOSS [training: 0.6134286298426057 | validation: 0.7505453147031187]
	TIME [epoch: 54.8 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6143967917658508		[learning rate: 4.8889e-05]
	Learning Rate: 4.88889e-05
	LOSS [training: 0.6143967917658508 | validation: 0.7727633845019977]
	TIME [epoch: 54.8 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253805491988702		[learning rate: 4.8535e-05]
	Learning Rate: 4.85347e-05
	LOSS [training: 0.6253805491988702 | validation: 0.7430480240625998]
	TIME [epoch: 54.8 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131163248771492		[learning rate: 4.8183e-05]
	Learning Rate: 4.81831e-05
	LOSS [training: 0.6131163248771492 | validation: 0.7549543909200719]
	TIME [epoch: 54.8 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142980805595926		[learning rate: 4.7834e-05]
	Learning Rate: 4.7834e-05
	LOSS [training: 0.6142980805595926 | validation: 0.7525684848569899]
	TIME [epoch: 54.8 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6166124314379356		[learning rate: 4.7487e-05]
	Learning Rate: 4.74875e-05
	LOSS [training: 0.6166124314379356 | validation: 0.7471431826259702]
	TIME [epoch: 54.7 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107671776238972		[learning rate: 4.7143e-05]
	Learning Rate: 4.71434e-05
	LOSS [training: 0.6107671776238972 | validation: 0.7521121500956984]
	TIME [epoch: 54.7 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.607636706824419		[learning rate: 4.6802e-05]
	Learning Rate: 4.68019e-05
	LOSS [training: 0.607636706824419 | validation: 0.764702409673877]
	TIME [epoch: 54.7 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.606647161916072		[learning rate: 4.6463e-05]
	Learning Rate: 4.64628e-05
	LOSS [training: 0.606647161916072 | validation: 0.753438345570778]
	TIME [epoch: 54.7 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217599191607002		[learning rate: 4.6126e-05]
	Learning Rate: 4.61262e-05
	LOSS [training: 0.6217599191607002 | validation: 0.780770081210914]
	TIME [epoch: 54.7 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6176005104686639		[learning rate: 4.5792e-05]
	Learning Rate: 4.5792e-05
	LOSS [training: 0.6176005104686639 | validation: 0.7737649401319859]
	TIME [epoch: 54.7 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6114624759078674		[learning rate: 4.546e-05]
	Learning Rate: 4.54602e-05
	LOSS [training: 0.6114624759078674 | validation: 0.7820859739461864]
	TIME [epoch: 54.7 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6142344554979977		[learning rate: 4.5131e-05]
	Learning Rate: 4.51309e-05
	LOSS [training: 0.6142344554979977 | validation: 0.7651174261699563]
	TIME [epoch: 54.7 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.609020686392401		[learning rate: 4.4804e-05]
	Learning Rate: 4.48039e-05
	LOSS [training: 0.609020686392401 | validation: 0.7758589860602729]
	TIME [epoch: 54.7 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6238275514806428		[learning rate: 4.4479e-05]
	Learning Rate: 4.44793e-05
	LOSS [training: 0.6238275514806428 | validation: 0.7664126983712785]
	TIME [epoch: 54.7 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262843330238873		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.6262843330238873 | validation: 0.7629499776124299]
	TIME [epoch: 54.7 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6151666001141651		[learning rate: 4.3837e-05]
	Learning Rate: 4.38371e-05
	LOSS [training: 0.6151666001141651 | validation: 0.7436993863095638]
	TIME [epoch: 54.7 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118794306905342		[learning rate: 4.352e-05]
	Learning Rate: 4.35195e-05
	LOSS [training: 0.6118794306905342 | validation: 0.7478730377889575]
	TIME [epoch: 54.7 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056012690199867		[learning rate: 4.3204e-05]
	Learning Rate: 4.32042e-05
	LOSS [training: 0.6056012690199867 | validation: 0.770962720968011]
	TIME [epoch: 54.7 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6143367952665466		[learning rate: 4.2891e-05]
	Learning Rate: 4.28912e-05
	LOSS [training: 0.6143367952665466 | validation: 0.7632727227229836]
	TIME [epoch: 54.7 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243134766895168		[learning rate: 4.258e-05]
	Learning Rate: 4.25805e-05
	LOSS [training: 0.6243134766895168 | validation: 0.770263210579713]
	TIME [epoch: 54.7 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168980722077602		[learning rate: 4.2272e-05]
	Learning Rate: 4.2272e-05
	LOSS [training: 0.6168980722077602 | validation: 0.755282638375907]
	TIME [epoch: 54.7 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6101606014385439		[learning rate: 4.1966e-05]
	Learning Rate: 4.19657e-05
	LOSS [training: 0.6101606014385439 | validation: 0.7547089451123008]
	TIME [epoch: 54.7 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6210977634607149		[learning rate: 4.1662e-05]
	Learning Rate: 4.16617e-05
	LOSS [training: 0.6210977634607149 | validation: 0.7639837146970643]
	TIME [epoch: 54.7 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123810382583867		[learning rate: 4.136e-05]
	Learning Rate: 4.13599e-05
	LOSS [training: 0.6123810382583867 | validation: 0.7689524433002727]
	TIME [epoch: 54.7 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6167804758170474		[learning rate: 4.106e-05]
	Learning Rate: 4.10602e-05
	LOSS [training: 0.6167804758170474 | validation: 0.7678891717367413]
	TIME [epoch: 54.7 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.609972238943288		[learning rate: 4.0763e-05]
	Learning Rate: 4.07627e-05
	LOSS [training: 0.609972238943288 | validation: 0.7523192840017037]
	TIME [epoch: 54.7 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6107565044872321		[learning rate: 4.0467e-05]
	Learning Rate: 4.04674e-05
	LOSS [training: 0.6107565044872321 | validation: 0.7565960201685029]
	TIME [epoch: 54.8 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074790333421688		[learning rate: 4.0174e-05]
	Learning Rate: 4.01742e-05
	LOSS [training: 0.6074790333421688 | validation: 0.7706691944866726]
	TIME [epoch: 54.7 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6093264571865368		[learning rate: 3.9883e-05]
	Learning Rate: 3.98832e-05
	LOSS [training: 0.6093264571865368 | validation: 0.7565882564152038]
	TIME [epoch: 54.7 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6151139033617967		[learning rate: 3.9594e-05]
	Learning Rate: 3.95942e-05
	LOSS [training: 0.6151139033617967 | validation: 0.7606199632148634]
	TIME [epoch: 54.7 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224724355182744		[learning rate: 3.9307e-05]
	Learning Rate: 3.93073e-05
	LOSS [training: 0.6224724355182744 | validation: 0.7527098545610209]
	TIME [epoch: 54.7 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6088024417163507		[learning rate: 3.9023e-05]
	Learning Rate: 3.90226e-05
	LOSS [training: 0.6088024417163507 | validation: 0.7607426712381868]
	TIME [epoch: 54.8 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168600397527937		[learning rate: 3.874e-05]
	Learning Rate: 3.87399e-05
	LOSS [training: 0.6168600397527937 | validation: 0.7672833212850907]
	TIME [epoch: 54.8 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6132127599825468		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.6132127599825468 | validation: 0.7552546767191164]
	TIME [epoch: 54.7 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039981572486008		[learning rate: 3.8181e-05]
	Learning Rate: 3.81806e-05
	LOSS [training: 0.6039981572486008 | validation: 0.760367171320947]
	TIME [epoch: 54.7 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211070451344735		[learning rate: 3.7904e-05]
	Learning Rate: 3.79039e-05
	LOSS [training: 0.6211070451344735 | validation: 0.7542595157384226]
	TIME [epoch: 54.7 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6052903812583386		[learning rate: 3.7629e-05]
	Learning Rate: 3.76293e-05
	LOSS [training: 0.6052903812583386 | validation: 0.7545355837634375]
	TIME [epoch: 54.7 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137911224634106		[learning rate: 3.7357e-05]
	Learning Rate: 3.73567e-05
	LOSS [training: 0.6137911224634106 | validation: 0.7574044519704171]
	TIME [epoch: 54.7 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6139475243986736		[learning rate: 3.7086e-05]
	Learning Rate: 3.70861e-05
	LOSS [training: 0.6139475243986736 | validation: 0.7827813751899548]
	TIME [epoch: 54.7 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075235936912591		[learning rate: 3.6817e-05]
	Learning Rate: 3.68174e-05
	LOSS [training: 0.6075235936912591 | validation: 0.7637187052168259]
	TIME [epoch: 54.7 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6157202239030893		[learning rate: 3.6551e-05]
	Learning Rate: 3.65506e-05
	LOSS [training: 0.6157202239030893 | validation: 0.7632242382547024]
	TIME [epoch: 54.7 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091247447170393		[learning rate: 3.6286e-05]
	Learning Rate: 3.62858e-05
	LOSS [training: 0.6091247447170393 | validation: 0.7425655449285993]
	TIME [epoch: 54.7 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6097556432959734		[learning rate: 3.6023e-05]
	Learning Rate: 3.60229e-05
	LOSS [training: 0.6097556432959734 | validation: 0.7619654514729095]
	TIME [epoch: 54.7 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.611112252545708		[learning rate: 3.5762e-05]
	Learning Rate: 3.57619e-05
	LOSS [training: 0.611112252545708 | validation: 0.7510022375107634]
	TIME [epoch: 54.7 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6064412091752582		[learning rate: 3.5503e-05]
	Learning Rate: 3.55029e-05
	LOSS [training: 0.6064412091752582 | validation: 0.7511292821399428]
	TIME [epoch: 54.7 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997915145659749		[learning rate: 3.5246e-05]
	Learning Rate: 3.52456e-05
	LOSS [training: 0.5997915145659749 | validation: 0.7446276784049619]
	TIME [epoch: 54.7 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075348391907978		[learning rate: 3.499e-05]
	Learning Rate: 3.49903e-05
	LOSS [training: 0.6075348391907978 | validation: 0.7798554275965491]
	TIME [epoch: 54.7 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6137760896976466		[learning rate: 3.4737e-05]
	Learning Rate: 3.47368e-05
	LOSS [training: 0.6137760896976466 | validation: 0.7416382556451757]
	TIME [epoch: 54.7 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089771499586958		[learning rate: 3.4485e-05]
	Learning Rate: 3.44851e-05
	LOSS [training: 0.6089771499586958 | validation: 0.7607224735635933]
	TIME [epoch: 54.7 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124327444142283		[learning rate: 3.4235e-05]
	Learning Rate: 3.42353e-05
	LOSS [training: 0.6124327444142283 | validation: 0.76514906738979]
	TIME [epoch: 54.7 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068411312407698		[learning rate: 3.3987e-05]
	Learning Rate: 3.39872e-05
	LOSS [training: 0.6068411312407698 | validation: 0.75513823179895]
	TIME [epoch: 54.7 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.611603963960344		[learning rate: 3.3741e-05]
	Learning Rate: 3.3741e-05
	LOSS [training: 0.611603963960344 | validation: 0.7516398588753411]
	TIME [epoch: 54.7 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.6117900702618622		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.6117900702618622 | validation: 0.7599121266827193]
	TIME [epoch: 54.7 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 4/4] avg loss: 0.607452609553122		[learning rate: 3.3254e-05]
	Learning Rate: 3.32539e-05
	LOSS [training: 0.607452609553122 | validation: 0.7628337130572949]
	TIME [epoch: 54.7 sec]
EPOCH 836/1000:
	Training over batches...
