Args:
Namespace(name='model_phi1_4c_v_mmd1', outdir='out/model_training/model_phi1_4c_v_mmd1', training_data='data/training_data/data_phi1_4c/training', validation_data='data/training_data/data_phi1_4c/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 562571547

Training model...

Saving initial model state to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.675774741212965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.675774741212965 | validation: 6.717664281948881]
	TIME [epoch: 183 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.714650578462185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.714650578462185 | validation: 6.4848573554681765]
	TIME [epoch: 2.85 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.5864877176436085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.5864877176436085 | validation: 5.793542125105738]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.925136852158592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.925136852158592 | validation: 5.190702923707134]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.085117191546796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.085117191546796 | validation: 4.400965718299047]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.285085597089411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.285085597089411 | validation: 4.4734691615324]
	TIME [epoch: 2.84 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.416200413678488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.416200413678488 | validation: 4.242048033897296]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.1074067169023705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1074067169023705 | validation: 4.4147150369259895]
	TIME [epoch: 2.84 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.309839515998204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.309839515998204 | validation: 4.311513962597261]
	TIME [epoch: 2.84 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.138732953957797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.138732953957797 | validation: 4.296386157878998]
	TIME [epoch: 2.84 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.2989096035885614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2989096035885614 | validation: 4.248276439572755]
	TIME [epoch: 2.84 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.054092430681644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.054092430681644 | validation: 4.110165130858431]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.009862993461602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.009862993461602 | validation: 4.131851392754855]
	TIME [epoch: 2.81 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.960339884780848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.960339884780848 | validation: 4.057871349420071]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9379054223834378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9379054223834378 | validation: 4.1043395046313105]
	TIME [epoch: 2.84 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9253635054412546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9253635054412546 | validation: 4.026444819176113]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9387420033329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9387420033329 | validation: 4.187348162027883]
	TIME [epoch: 2.83 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.988201301871594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.988201301871594 | validation: 4.1196252541651]
	TIME [epoch: 2.83 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.130314416476299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.130314416476299 | validation: 4.100569799985729]
	TIME [epoch: 2.83 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.913690596767227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.913690596767227 | validation: 3.973667555644017]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.848598573697294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.848598573697294 | validation: 3.9665717762416466]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.826591290451853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.826591290451853 | validation: 3.9597511724894687]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.812032367423292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.812032367423292 | validation: 3.9250502249792705]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.801632768031195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.801632768031195 | validation: 3.9640596092382596]
	TIME [epoch: 2.83 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.797977892807277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.797977892807277 | validation: 3.9035721169171853]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8488896748372325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8488896748372325 | validation: 4.1937500188770205]
	TIME [epoch: 2.83 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.0176275755198185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0176275755198185 | validation: 4.03399814549731]
	TIME [epoch: 2.83 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.057107086249213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.057107086249213 | validation: 3.88917149428317]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7522871293263584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7522871293263584 | validation: 3.9721220636783183]
	TIME [epoch: 2.83 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8051483005817857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8051483005817857 | validation: 3.8798424646015692]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.83633553964183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.83633553964183 | validation: 3.8569082641178642]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7191547082552865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7191547082552865 | validation: 3.8309144065224334]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7004769165840425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7004769165840425 | validation: 3.800430281632959]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.701442583900197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.701442583900197 | validation: 3.8300918975899467]
	TIME [epoch: 2.84 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6956818242582914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6956818242582914 | validation: 3.7795174268111738]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.690039204170951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.690039204170951 | validation: 3.8097595470921615]
	TIME [epoch: 2.83 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6820426951516785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6820426951516785 | validation: 3.7904184270917485]
	TIME [epoch: 2.82 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.697545615086521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.697545615086521 | validation: 3.772794701968718]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6684363596345864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6684363596345864 | validation: 3.8448670580418067]
	TIME [epoch: 2.83 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.722108867960876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.722108867960876 | validation: 3.7955687894444354]
	TIME [epoch: 2.83 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.775328991611865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.775328991611865 | validation: 3.938042530543892]
	TIME [epoch: 2.83 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7812580539055545		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7812580539055545 | validation: 3.7413623331206227]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7069943366992972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7069943366992972 | validation: 3.699122002718731]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.586426028719372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.586426028719372 | validation: 3.7037858938641564]
	TIME [epoch: 2.91 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5819860565197534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5819860565197534 | validation: 3.664299895138381]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5930824025694688		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5930824025694688 | validation: 3.7079519624604504]
	TIME [epoch: 2.83 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5809812259852074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5809812259852074 | validation: 3.6427134254874005]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5725717376615016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5725717376615016 | validation: 3.676519482465051]
	TIME [epoch: 2.83 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5555612434254376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5555612434254376 | validation: 3.624017307350205]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5552354229086793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5552354229086793 | validation: 3.6667078748784903]
	TIME [epoch: 2.83 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5525104442380884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5525104442380884 | validation: 3.6163954728611554]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5569222479032807		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 3.5569222479032807 | validation: 3.6634493477227226]
	TIME [epoch: 2.83 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.540489196835488		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 3.540489196835488 | validation: 3.5963318679085847]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5325101129379175		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 3.5325101129379175 | validation: 3.6092953935826473]
	TIME [epoch: 2.83 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.504313249523333		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 3.504313249523333 | validation: 3.5566764639154855]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.493663620650601		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 3.493663620650601 | validation: 3.5775745845520563]
	TIME [epoch: 2.83 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.47493892461262		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 3.47493892461262 | validation: 3.5378328206352694]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.466904059460594		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 3.466904059460594 | validation: 3.5507681945190885]
	TIME [epoch: 2.83 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.453775654198679		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 3.453775654198679 | validation: 3.5118150198606233]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.44753469338497		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 3.44753469338497 | validation: 3.5386089653262847]
	TIME [epoch: 2.83 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.441720223974918		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 3.441720223974918 | validation: 3.5018107913059]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4435030668173505		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 3.4435030668173505 | validation: 3.5282739799819325]
	TIME [epoch: 2.83 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4360090574967557		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 3.4360090574967557 | validation: 3.492784968528588]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.434922297861129		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 3.434922297861129 | validation: 3.506692926395999]
	TIME [epoch: 2.84 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4161381963394275		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 3.4161381963394275 | validation: 3.4573990721074135]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3888401895634606		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 3.3888401895634606 | validation: 3.4537163753481397]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.374911140112472		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 3.374911140112472 | validation: 3.437783938760663]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3685930159458723		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 3.3685930159458723 | validation: 3.4399070219864534]
	TIME [epoch: 2.83 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.35971952673597		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 3.35971952673597 | validation: 3.4210506836228194]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3580635046949237		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 3.3580635046949237 | validation: 3.4254122432202507]
	TIME [epoch: 2.84 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3457971345142674		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 3.3457971345142674 | validation: 3.3965527367645407]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3403544235528666		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 3.3403544235528666 | validation: 3.4067769683502194]
	TIME [epoch: 2.83 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3291014823046248		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 3.3291014823046248 | validation: 3.3780364765478255]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3180349669329843		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 3.3180349669329843 | validation: 3.379887388800657]
	TIME [epoch: 2.84 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.309156379595687		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 3.309156379595687 | validation: 3.355049759868503]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.300139538294062		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 3.300139538294062 | validation: 3.3597193845982147]
	TIME [epoch: 2.84 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2870544242957527		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 3.2870544242957527 | validation: 3.3416478468767323]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2821992138054985		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 3.2821992138054985 | validation: 3.341941073223781]
	TIME [epoch: 2.84 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2691243476791114		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 3.2691243476791114 | validation: 3.321765880762624]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2609915977564095		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 3.2609915977564095 | validation: 3.3176251254103324]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2522646803914017		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 3.2522646803914017 | validation: 3.305424730253266]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2413761235723313		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 3.2413761235723313 | validation: 3.2978624809129204]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2355026123401185		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 3.2355026123401185 | validation: 3.2838270936034704]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2259611435764413		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 3.2259611435764413 | validation: 3.273098937020062]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2169541573298757		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 3.2169541573298757 | validation: 3.275179378528353]
	TIME [epoch: 2.82 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.214454976968235		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 3.214454976968235 | validation: 3.257419431889352]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2034479872770545		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 3.2034479872770545 | validation: 3.2615227814786936]
	TIME [epoch: 2.82 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.199797480952217		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 3.199797480952217 | validation: 3.2205828611331486]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1718267006111547		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 3.1718267006111547 | validation: 3.2147457288597097]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.153043261718061		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 3.153043261718061 | validation: 3.19611871841835]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1414631461306612		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 3.1414631461306612 | validation: 3.1757928785096072]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1162090662202027		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 3.1162090662202027 | validation: 3.138206306305488]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0885015162413723		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 3.0885015162413723 | validation: 3.1119795183765517]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0439435875186915		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 3.0439435875186915 | validation: 3.0702471840324144]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9949968399621447		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 2.9949968399621447 | validation: 3.2199336922477046]
	TIME [epoch: 2.83 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.198626573714681		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 3.198626573714681 | validation: 3.178787587925583]
	TIME [epoch: 2.83 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.020721856884485		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 3.020721856884485 | validation: 2.9603676432974084]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8787063503126133		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 2.8787063503126133 | validation: 2.8969782262543813]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8454251424383803		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 2.8454251424383803 | validation: 2.8954482741800662]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.7865596404281208		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 2.7865596404281208 | validation: 2.7496470953012113]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.654585074409819		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 2.654585074409819 | validation: 3.78444876720871]
	TIME [epoch: 2.83 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4127344729892366		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 3.4127344729892366 | validation: 2.9099095617513258]
	TIME [epoch: 2.83 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.932317246094434		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 2.932317246094434 | validation: 2.6039904325089385]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.566962721392674		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 2.566962721392674 | validation: 2.562833562546257]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.4506735007278415		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 2.4506735007278415 | validation: 2.543414286660142]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.401000767904		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 2.401000767904 | validation: 2.354848131569685]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.252406430351598		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 2.252406430351598 | validation: 2.1648457331778177]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1327523445237984		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 2.1327523445237984 | validation: 2.0015856951832203]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9891607497037203		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 1.9891607497037203 | validation: 1.8396480152928032]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.842763291113838		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 1.842763291113838 | validation: 1.586485659130213]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6690667028345811		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 1.6690667028345811 | validation: 1.517430779426796]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5051325858626559		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 1.5051325858626559 | validation: 1.5524601841548653]
	TIME [epoch: 2.84 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7652867375267587		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 1.7652867375267587 | validation: 1.7362854458571755]
	TIME [epoch: 2.84 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.7358789977841576		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 1.7358789977841576 | validation: 1.108399606419436]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.227457982480513		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 1.227457982480513 | validation: 1.1085840041122315]
	TIME [epoch: 2.84 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.24949356179181		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 1.24949356179181 | validation: 1.1286286895782685]
	TIME [epoch: 2.84 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1958571242473757		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 1.1958571242473757 | validation: 0.9782616670762698]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0825023434115593		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 1.0825023434115593 | validation: 0.9591528352973082]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.108525319232075		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 1.108525319232075 | validation: 0.9716166546234337]
	TIME [epoch: 2.83 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0884647322072538		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 1.0884647322072538 | validation: 0.9555398018632382]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1467684482670804		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 1.1467684482670804 | validation: 0.9178416716563436]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0460093713021044		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 1.0460093713021044 | validation: 0.8797741738187086]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0064688618919875		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 1.0064688618919875 | validation: 0.8628917552234079]
	TIME [epoch: 2.84 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0109240852575914		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 1.0109240852575914 | validation: 0.923430389829131]
	TIME [epoch: 2.82 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1133848979086058		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 1.1133848979086058 | validation: 0.9366479028581616]
	TIME [epoch: 2.83 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0727159778153408		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 1.0727159778153408 | validation: 0.8336927375199485]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9848442317036376		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.9848442317036376 | validation: 0.8326705645115468]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0018752505513076		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 1.0018752505513076 | validation: 0.8510403986227882]
	TIME [epoch: 2.83 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9727317127532942		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 0.9727317127532942 | validation: 0.8529225329967152]
	TIME [epoch: 2.83 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9865953650958457		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.9865953650958457 | validation: 0.8487216736183797]
	TIME [epoch: 2.83 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0340953250679439		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 1.0340953250679439 | validation: 0.8064475767632779]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9680434418532821		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.9680434418532821 | validation: 0.7931808761656193]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9421137017718922		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 0.9421137017718922 | validation: 0.8557237500022563]
	TIME [epoch: 2.82 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0389921114107872		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 1.0389921114107872 | validation: 0.8703587134387942]
	TIME [epoch: 2.82 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0329792456938738		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 1.0329792456938738 | validation: 0.8944680051487524]
	TIME [epoch: 2.82 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1236316671678936		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 1.1236316671678936 | validation: 0.7963534995049918]
	TIME [epoch: 2.82 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9605859156252765		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.9605859156252765 | validation: 0.8612395978862066]
	TIME [epoch: 2.82 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0180091052290483		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 1.0180091052290483 | validation: 0.7830840292518728]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9306327546456844		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 0.9306327546456844 | validation: 0.7926270349263659]
	TIME [epoch: 2.82 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9262524492985066		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 0.9262524492985066 | validation: 0.7755270860864332]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9295169770105406		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.9295169770105406 | validation: 0.7817652391387857]
	TIME [epoch: 2.82 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9182723443225829		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.9182723443225829 | validation: 0.7741236618433325]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9319142955298565		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 0.9319142955298565 | validation: 0.8089945077232946]
	TIME [epoch: 2.83 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9743204411065034		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 0.9743204411065034 | validation: 0.7901588694576127]
	TIME [epoch: 2.83 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9769375875809685		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 0.9769375875809685 | validation: 0.7592267310447541]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9130173283295071		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.9130173283295071 | validation: 0.758151122962631]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.897787107462467		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.897787107462467 | validation: 0.759277686533764]
	TIME [epoch: 2.83 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8940659660981604		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.8940659660981604 | validation: 0.7636822514218329]
	TIME [epoch: 2.83 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9002470699766315		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.9002470699766315 | validation: 0.730546303598229]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8905484206991369		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.8905484206991369 | validation: 0.7303485502371346]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8801258237421781		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 0.8801258237421781 | validation: 0.7734275976850595]
	TIME [epoch: 2.83 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9234466602660569		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 0.9234466602660569 | validation: 0.7533280182581905]
	TIME [epoch: 2.82 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9288489821688475		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.9288489821688475 | validation: 0.7485710848910115]
	TIME [epoch: 2.82 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9206419761214234		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.9206419761214234 | validation: 0.7196034173170456]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8948201862168363		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.8948201862168363 | validation: 0.7351041031326769]
	TIME [epoch: 2.82 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8862941771939618		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 0.8862941771939618 | validation: 0.7922039489651205]
	TIME [epoch: 2.83 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9796016000577638		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.9796016000577638 | validation: 0.788682247683282]
	TIME [epoch: 2.83 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9352968006245655		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.9352968006245655 | validation: 0.7354735245802173]
	TIME [epoch: 2.82 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9062271405198353		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.9062271405198353 | validation: 0.7299207644043224]
	TIME [epoch: 2.82 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.870793140916689		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.870793140916689 | validation: 0.7467675399139686]
	TIME [epoch: 2.83 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.91374158936178		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.91374158936178 | validation: 0.7925020352806487]
	TIME [epoch: 2.83 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9230000086790859		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 0.9230000086790859 | validation: 0.7748906906540772]
	TIME [epoch: 2.83 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9133918727619034		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.9133918727619034 | validation: 0.7523628989485769]
	TIME [epoch: 2.83 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9688694357704267		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.9688694357704267 | validation: 0.7300433982651484]
	TIME [epoch: 2.83 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8797911800437845		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.8797911800437845 | validation: 0.714755657239116]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8705276826289642		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.8705276826289642 | validation: 0.7232171668503007]
	TIME [epoch: 2.81 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8490002376071448		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.8490002376071448 | validation: 0.7233272328614653]
	TIME [epoch: 2.82 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8736412293536386		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 0.8736412293536386 | validation: 0.7510578830336025]
	TIME [epoch: 2.82 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9534615308619615		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.9534615308619615 | validation: 0.7455597567254378]
	TIME [epoch: 2.82 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9073102445666112		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.9073102445666112 | validation: 0.7145088556243298]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8824700899123465		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.8824700899123465 | validation: 0.7445520869235785]
	TIME [epoch: 2.81 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9486080058562157		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.9486080058562157 | validation: 0.7044350818639818]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8559855524899834		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.8559855524899834 | validation: 0.7149783862720019]
	TIME [epoch: 2.83 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8497627483158807		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.8497627483158807 | validation: 0.7071208571556504]
	TIME [epoch: 2.83 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8547498476908814		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.8547498476908814 | validation: 0.7259260916642044]
	TIME [epoch: 2.83 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8529305484626403		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.8529305484626403 | validation: 0.714877132015189]
	TIME [epoch: 2.83 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8319734775956467		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.8319734775956467 | validation: 0.7392332076591929]
	TIME [epoch: 2.83 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8722918743553447		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.8722918743553447 | validation: 0.8307573998372284]
	TIME [epoch: 2.83 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0088627886767019		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 1.0088627886767019 | validation: 0.7863801329379663]
	TIME [epoch: 2.83 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.891408968170829		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.891408968170829 | validation: 0.6893591771425637]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8576751936674305		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.8576751936674305 | validation: 0.7359414743721836]
	TIME [epoch: 2.83 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9255440269200977		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.9255440269200977 | validation: 0.6953723488469248]
	TIME [epoch: 2.83 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8857762170672296		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 0.8857762170672296 | validation: 0.6514645108894266]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7853158280131507		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.7853158280131507 | validation: 0.7312911055412677]
	TIME [epoch: 2.82 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8154625645026955		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.8154625645026955 | validation: 0.8875826349422777]
	TIME [epoch: 2.83 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9589086828902051		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.9589086828902051 | validation: 1.2228587704961047]
	TIME [epoch: 2.83 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4305823204419756		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 1.4305823204419756 | validation: 0.9095802331755483]
	TIME [epoch: 2.83 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.018808194375921		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 1.018808194375921 | validation: 0.7360312105877699]
	TIME [epoch: 2.83 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.892185467015208		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.892185467015208 | validation: 0.796341862291765]
	TIME [epoch: 2.83 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9011530865692744		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.9011530865692744 | validation: 0.6905926619137648]
	TIME [epoch: 2.83 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8353162239931194		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.8353162239931194 | validation: 0.6951585159300577]
	TIME [epoch: 2.83 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8596354993070845		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.8596354993070845 | validation: 0.6457981407831381]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7882482892315322		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.7882482892315322 | validation: 0.7741270058471286]
	TIME [epoch: 2.82 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9178319423545509		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.9178319423545509 | validation: 0.6963899933400406]
	TIME [epoch: 2.83 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8325032657499102		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 0.8325032657499102 | validation: 0.6396321449317723]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7762360975723991		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.7762360975723991 | validation: 0.6822964160156041]
	TIME [epoch: 2.83 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7484551991998721		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.7484551991998721 | validation: 0.6843300864015297]
	TIME [epoch: 2.83 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7001870449363606		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.7001870449363606 | validation: 0.6097185714719675]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7148719127283133		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.7148719127283133 | validation: 1.015636052297901]
	TIME [epoch: 2.82 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9522514670484081		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.9522514670484081 | validation: 0.9375493508564294]
	TIME [epoch: 2.83 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.1885207766430983		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 1.1885207766430983 | validation: 0.7480317922223687]
	TIME [epoch: 198 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8986926941079068		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.8986926941079068 | validation: 0.6777900566528992]
	TIME [epoch: 6.09 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8365307602376764		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.8365307602376764 | validation: 0.698613262807756]
	TIME [epoch: 6.07 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8250125015816238		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.8250125015816238 | validation: 0.639083503603685]
	TIME [epoch: 6.06 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7770658263884633		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.7770658263884633 | validation: 0.627120499775211]
	TIME [epoch: 6.07 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.788632757423028		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.788632757423028 | validation: 0.6282811868606478]
	TIME [epoch: 6.06 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7604026091892849		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.7604026091892849 | validation: 0.6429271366979709]
	TIME [epoch: 6.06 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7365029288045557		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.7365029288045557 | validation: 0.6136956511804301]
	TIME [epoch: 6.06 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7241320047649794		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.7241320047649794 | validation: 0.6178728284258708]
	TIME [epoch: 6.06 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6611029831414094		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.6611029831414094 | validation: 0.613023644940347]
	TIME [epoch: 6.06 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6308928183812585		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.6308928183812585 | validation: 0.5727752021048539]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6245916573138106		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.6245916573138106 | validation: 0.6575544443689028]
	TIME [epoch: 6.07 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6665723132097177		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.6665723132097177 | validation: 0.922866739111703]
	TIME [epoch: 6.07 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0585719506019273		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 1.0585719506019273 | validation: 0.5845999372640724]
	TIME [epoch: 6.06 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6948285508173706		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.6948285508173706 | validation: 0.7273529398666412]
	TIME [epoch: 6.06 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7701509928754484		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 0.7701509928754484 | validation: 0.6014099457621884]
	TIME [epoch: 6.06 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6725509359118127		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.6725509359118127 | validation: 0.5583224890711439]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6275333819030502		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.6275333819030502 | validation: 0.5849837682828045]
	TIME [epoch: 6.06 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5931414822126766		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.5931414822126766 | validation: 0.5494261921175575]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.58144646950013		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.58144646950013 | validation: 0.552248190709226]
	TIME [epoch: 6.07 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6050055983465827		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.6050055983465827 | validation: 1.2887000661232217]
	TIME [epoch: 6.07 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.214181998083416		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 1.214181998083416 | validation: 0.8229055969752834]
	TIME [epoch: 6.07 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0324064613119601		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 1.0324064613119601 | validation: 0.6191553496363338]
	TIME [epoch: 6.07 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.757935680284088		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.757935680284088 | validation: 0.6905992288708759]
	TIME [epoch: 6.07 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8517271728827762		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.8517271728827762 | validation: 0.6106099157190612]
	TIME [epoch: 6.07 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7371563202090593		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.7371563202090593 | validation: 0.6297859028739078]
	TIME [epoch: 6.07 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7381402936463102		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.7381402936463102 | validation: 0.5747728666503787]
	TIME [epoch: 6.07 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6993001238549971		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.6993001238549971 | validation: 0.5737227958921801]
	TIME [epoch: 6.07 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6289028442133067		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.6289028442133067 | validation: 0.5624625568096212]
	TIME [epoch: 6.06 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5970514338772587		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.5970514338772587 | validation: 0.524365319182726]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5646212197776349		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.5646212197776349 | validation: 0.5084871947435217]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5705267151796857		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.5705267151796857 | validation: 0.7631823931849858]
	TIME [epoch: 6.06 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.720704231615222		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 0.720704231615222 | validation: 0.7440902474587712]
	TIME [epoch: 6.06 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8755030322223653		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.8755030322223653 | validation: 0.5537187517610187]
	TIME [epoch: 6.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6674085095008678		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.6674085095008678 | validation: 0.6584879306717802]
	TIME [epoch: 6.05 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6566234602847668		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.6566234602847668 | validation: 0.5474952037846317]
	TIME [epoch: 6.06 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5809702298980759		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.5809702298980759 | validation: 0.4843323324535339]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5781429916945826		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.5781429916945826 | validation: 0.576547377440585]
	TIME [epoch: 6.07 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5514245513888661		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.5514245513888661 | validation: 0.5092307378722918]
	TIME [epoch: 6.06 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5730574838300123		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.5730574838300123 | validation: 0.6030530873608956]
	TIME [epoch: 6.07 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6264923854705983		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.6264923854705983 | validation: 0.610873851180088]
	TIME [epoch: 6.07 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.713564193189329		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.713564193189329 | validation: 0.4941393304483195]
	TIME [epoch: 6.06 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.618545807144479		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 0.618545807144479 | validation: 0.583304024736948]
	TIME [epoch: 6.06 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.564029243159241		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.564029243159241 | validation: 0.5480872946813776]
	TIME [epoch: 6.07 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5773910348833095		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.5773910348833095 | validation: 0.5605536158614716]
	TIME [epoch: 6.06 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6328144841064882		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.6328144841064882 | validation: 0.5655210431159571]
	TIME [epoch: 6.07 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6536705423034954		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.6536705423034954 | validation: 0.5588469575848594]
	TIME [epoch: 6.07 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5278072624600499		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.5278072624600499 | validation: 0.44646199140999293]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_248.pth
	Model improved!!!
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4893709804974433		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.4893709804974433 | validation: 0.4590222810522795]
	TIME [epoch: 6.07 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47731074830036485		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.47731074830036485 | validation: 0.4618573079550887]
	TIME [epoch: 6.06 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46434963244522437		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.46434963244522437 | validation: 0.41736136661833056]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4615946167034426		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.4615946167034426 | validation: 0.4491507041003521]
	TIME [epoch: 6.07 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4624528416208877		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.4624528416208877 | validation: 0.5228917509533949]
	TIME [epoch: 6.07 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.591096988266		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.591096988266 | validation: 0.7893402142793774]
	TIME [epoch: 6.07 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7306011174733135		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.7306011174733135 | validation: 0.6336582655964641]
	TIME [epoch: 6.07 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.791358506062198		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.791358506062198 | validation: 0.5646669954671748]
	TIME [epoch: 6.08 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7050520600014939		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.7050520600014939 | validation: 0.5346949929012277]
	TIME [epoch: 6.07 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5876813690227605		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.5876813690227605 | validation: 0.5731555400243256]
	TIME [epoch: 6.08 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5398287358211182		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.5398287358211182 | validation: 0.429276885958007]
	TIME [epoch: 6.07 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4377526427235112		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.4377526427235112 | validation: 0.4084975404200886]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46829365867031625		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.46829365867031625 | validation: 0.4102631985953082]
	TIME [epoch: 6.06 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43735334432698386		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.43735334432698386 | validation: 0.6629537455769047]
	TIME [epoch: 6.07 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6013993333788888		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.6013993333788888 | validation: 0.650037968860178]
	TIME [epoch: 6.07 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7972883395663513		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.7972883395663513 | validation: 0.7047254642308697]
	TIME [epoch: 6.08 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9303370017790219		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.9303370017790219 | validation: 0.6167413558507441]
	TIME [epoch: 6.07 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7501077172655951		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.7501077172655951 | validation: 0.5596395300566361]
	TIME [epoch: 6.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5204910925358577		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.5204910925358577 | validation: 0.5602196799616304]
	TIME [epoch: 6.07 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5404048034863539		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.5404048034863539 | validation: 0.5297629505885747]
	TIME [epoch: 6.06 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48021327481062354		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.48021327481062354 | validation: 0.45254079731652175]
	TIME [epoch: 6.07 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5552177432469259		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.5552177432469259 | validation: 0.41294320970893994]
	TIME [epoch: 6.06 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4391052428329627		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.4391052428329627 | validation: 0.5072703467367995]
	TIME [epoch: 6.07 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4575319721437448		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.4575319721437448 | validation: 0.45866601458030964]
	TIME [epoch: 6.07 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48953704026121075		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.48953704026121075 | validation: 0.47990391292673007]
	TIME [epoch: 6.07 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4478746036308165		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.4478746036308165 | validation: 0.42450649880149705]
	TIME [epoch: 6.07 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4480755093519021		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.4480755093519021 | validation: 0.4824571953227807]
	TIME [epoch: 6.06 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4579670236887904		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.4579670236887904 | validation: 0.4375779463266037]
	TIME [epoch: 6.06 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4976376137395354		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.4976376137395354 | validation: 0.378404812743022]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40558417300410027		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.40558417300410027 | validation: 0.5442324375198916]
	TIME [epoch: 6.05 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47063555081725256		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.47063555081725256 | validation: 0.4668622754929597]
	TIME [epoch: 6.06 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5444537649896889		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.5444537649896889 | validation: 0.3470601094363528]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4098126403100132		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.4098126403100132 | validation: 0.5469474581775865]
	TIME [epoch: 6.03 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4594378927618805		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.4594378927618805 | validation: 0.49568605898340734]
	TIME [epoch: 6.03 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5492750560651244		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.5492750560651244 | validation: 0.4070281899403602]
	TIME [epoch: 6.02 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4367124702148937		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.4367124702148937 | validation: 0.34494233069354624]
	TIME [epoch: 6.02 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_284.pth
	Model improved!!!
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37871078048053947		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.37871078048053947 | validation: 0.3556097796636214]
	TIME [epoch: 6.08 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36521093469420396		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.36521093469420396 | validation: 0.365046701856416]
	TIME [epoch: 6.08 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38662136796986646		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.38662136796986646 | validation: 0.3803761090984026]
	TIME [epoch: 6.09 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4406827743137817		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.4406827743137817 | validation: 0.7495601327567192]
	TIME [epoch: 6.08 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6136044645558704		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 0.6136044645558704 | validation: 0.5386751904804371]
	TIME [epoch: 6.07 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6382169954421453		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.6382169954421453 | validation: 0.39066203760091667]
	TIME [epoch: 6.07 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49291616250307885		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.49291616250307885 | validation: 0.4815717010355405]
	TIME [epoch: 6.06 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4320962333462207		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.4320962333462207 | validation: 0.43415163458851735]
	TIME [epoch: 6.05 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44554558824530677		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.44554558824530677 | validation: 0.319674753674553]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_293.pth
	Model improved!!!
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36447413295592257		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.36447413295592257 | validation: 0.4123049963972874]
	TIME [epoch: 6.01 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38488346945616114		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.38488346945616114 | validation: 0.39918978903591407]
	TIME [epoch: 6.02 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4479392510789819		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.4479392510789819 | validation: 0.30280862981051276]
	TIME [epoch: 6.02 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.340786008892358		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.340786008892358 | validation: 0.35466840773271513]
	TIME [epoch: 6.07 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35720471545110805		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.35720471545110805 | validation: 0.3729255226033251]
	TIME [epoch: 6.06 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43324644311223337		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.43324644311223337 | validation: 0.4544815660673071]
	TIME [epoch: 6.07 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4018844746433742		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.4018844746433742 | validation: 0.3575864808658174]
	TIME [epoch: 6.03 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4581333006641208		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.4581333006641208 | validation: 0.3270128619692519]
	TIME [epoch: 6.08 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35293216882303136		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.35293216882303136 | validation: 0.41208353629225897]
	TIME [epoch: 6.08 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3663164634287911		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.3663164634287911 | validation: 0.3416720365185918]
	TIME [epoch: 6.08 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4067847995051481		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.4067847995051481 | validation: 0.39648934710769845]
	TIME [epoch: 6.08 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3338711596449062		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.3338711596449062 | validation: 0.2939135832799412]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33723178521949465		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.33723178521949465 | validation: 0.31695331966819196]
	TIME [epoch: 6.04 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3254968293792036		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.3254968293792036 | validation: 0.31507334391175573]
	TIME [epoch: 6.04 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34234640363079677		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.34234640363079677 | validation: 0.41362622376532787]
	TIME [epoch: 6.03 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42982975252313516		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.42982975252313516 | validation: 0.37138633228992046]
	TIME [epoch: 6.04 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4098073522559236		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.4098073522559236 | validation: 0.3620353474437763]
	TIME [epoch: 6.03 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31393106273655025		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.31393106273655025 | validation: 0.280291559736751]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_311.pth
	Model improved!!!
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34615556280137233		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.34615556280137233 | validation: 0.40255083925445273]
	TIME [epoch: 6.03 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3367731834705881		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.3367731834705881 | validation: 0.37553339931507096]
	TIME [epoch: 6.04 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4680114579330654		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.4680114579330654 | validation: 0.34903324948854964]
	TIME [epoch: 6.04 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32410460803476576		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.32410460803476576 | validation: 0.283090081991738]
	TIME [epoch: 6.04 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2719035792989595		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.2719035792989595 | validation: 0.26313714627780516]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29754029548503186		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.29754029548503186 | validation: 0.584423708476594]
	TIME [epoch: 6.06 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.475315250032971		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.475315250032971 | validation: 0.4671011402356726]
	TIME [epoch: 6.07 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6220201258662182		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.6220201258662182 | validation: 0.4261087773229477]
	TIME [epoch: 6.07 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3841975091812313		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.3841975091812313 | validation: 0.46111212772904775]
	TIME [epoch: 6.04 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3913736776006478		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.3913736776006478 | validation: 0.3626488405649727]
	TIME [epoch: 6.07 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45061691584228586		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.45061691584228586 | validation: 0.3296432970694581]
	TIME [epoch: 6.07 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2906207665037249		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.2906207665037249 | validation: 0.4495844035822434]
	TIME [epoch: 6.06 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39628306828085386		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.39628306828085386 | validation: 0.3054981890160047]
	TIME [epoch: 6.07 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3793590469951789		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.3793590469951789 | validation: 0.28054963530987465]
	TIME [epoch: 6.07 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2944165520238956		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.2944165520238956 | validation: 0.35144627418172786]
	TIME [epoch: 6.06 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31707581037383725		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.31707581037383725 | validation: 0.2613499113654944]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3012259147658453		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.3012259147658453 | validation: 0.30428465511739067]
	TIME [epoch: 6.06 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2657846515497489		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.2657846515497489 | validation: 0.2420541165659579]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2520522137166427		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.2520522137166427 | validation: 0.27524813183493124]
	TIME [epoch: 6.07 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2519939628962798		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.2519939628962798 | validation: 0.22145115738479895]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2828500252140496		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.2828500252140496 | validation: 0.5521457897595188]
	TIME [epoch: 6.07 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3928111904744233		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.3928111904744233 | validation: 0.344338692989956]
	TIME [epoch: 6.07 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3839845816430655		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.3839845816430655 | validation: 0.2607657369644502]
	TIME [epoch: 6.1 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3265290773893616		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.3265290773893616 | validation: 0.4234685041564455]
	TIME [epoch: 6.08 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3214663677397097		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.3214663677397097 | validation: 0.3010278859305695]
	TIME [epoch: 6.07 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3459435465536789		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.3459435465536789 | validation: 0.24327946949346135]
	TIME [epoch: 6.08 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27705754978268643		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.27705754978268643 | validation: 0.4736622870447237]
	TIME [epoch: 6.07 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35573227451277506		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.35573227451277506 | validation: 0.37361691366697936]
	TIME [epoch: 6.07 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3891272665791224		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.3891272665791224 | validation: 0.21767468698612366]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26301712538257693		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.26301712538257693 | validation: 0.34575783421746953]
	TIME [epoch: 6.07 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27922762856449757		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.27922762856449757 | validation: 0.3023715167270069]
	TIME [epoch: 6.07 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3496708440928238		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.3496708440928238 | validation: 0.2724252195824967]
	TIME [epoch: 6.07 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26779479832093617		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.26779479832093617 | validation: 0.24356540826525946]
	TIME [epoch: 6.07 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2304281738422224		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.2304281738422224 | validation: 0.31600314559624665]
	TIME [epoch: 6.06 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24111021604817212		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.24111021604817212 | validation: 0.20135987727446178]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24958937696004782		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.24958937696004782 | validation: 0.3585536857677454]
	TIME [epoch: 6.07 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27105781519772953		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.27105781519772953 | validation: 0.24841011280349737]
	TIME [epoch: 6.08 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29230789077485186		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.29230789077485186 | validation: 0.23037859825389564]
	TIME [epoch: 6.07 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2277559337387262		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.2277559337387262 | validation: 0.3017159198146317]
	TIME [epoch: 6.07 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23089329251277924		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.23089329251277924 | validation: 0.20143852504681303]
	TIME [epoch: 6.08 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2355267464114281		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.2355267464114281 | validation: 0.4367994759466231]
	TIME [epoch: 6.08 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31552703370962254		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.31552703370962254 | validation: 0.30498986971483055]
	TIME [epoch: 6.07 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3600527326465268		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.3600527326465268 | validation: 0.26308139079531306]
	TIME [epoch: 6.07 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2802813119245115		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.2802813119245115 | validation: 0.31233104649939414]
	TIME [epoch: 6.06 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22770281502013567		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.22770281502013567 | validation: 0.23564608243419993]
	TIME [epoch: 6.06 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24465758450404113		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.24465758450404113 | validation: 0.3356010747611554]
	TIME [epoch: 6.06 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2691878862937091		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.2691878862937091 | validation: 0.2406175943331882]
	TIME [epoch: 6.07 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29585237902476913		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.29585237902476913 | validation: 0.31860835386010194]
	TIME [epoch: 6.07 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23751190407432984		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.23751190407432984 | validation: 0.18279554271846166]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20882752184835326		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.20882752184835326 | validation: 0.20717589515804313]
	TIME [epoch: 6.06 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19872341080990516		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.19872341080990516 | validation: 0.25975855069585396]
	TIME [epoch: 6.06 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19660252240103185		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.19660252240103185 | validation: 0.18833430344886962]
	TIME [epoch: 6.06 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2341154367824307		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.2341154367824307 | validation: 0.5024126739979027]
	TIME [epoch: 6.07 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3627374804062319		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.3627374804062319 | validation: 0.3269784411327325]
	TIME [epoch: 6.07 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41392080066371634		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.41392080066371634 | validation: 0.27852179065578125]
	TIME [epoch: 6.07 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37685332212636796		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.37685332212636796 | validation: 0.5015554712662063]
	TIME [epoch: 6.07 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.358242922440775		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.358242922440775 | validation: 0.3472820267080355]
	TIME [epoch: 6.08 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2642144158394165		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.2642144158394165 | validation: 0.192798310473248]
	TIME [epoch: 6.07 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2514930026377179		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.2514930026377179 | validation: 0.30159439257788984]
	TIME [epoch: 6.08 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22756115634079085		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.22756115634079085 | validation: 0.2694106494110376]
	TIME [epoch: 6.07 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2908110083686339		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.2908110083686339 | validation: 0.23035214845529098]
	TIME [epoch: 6.07 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2043218226892979		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.2043218226892979 | validation: 0.1751319163124295]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18778409735611928		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.18778409735611928 | validation: 0.18078932188969427]
	TIME [epoch: 6.07 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1877786267001234		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.1877786267001234 | validation: 0.3074528573948423]
	TIME [epoch: 6.08 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22857274296825691		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.22857274296825691 | validation: 0.24081600818280935]
	TIME [epoch: 6.07 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.277064092402004		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.277064092402004 | validation: 0.19735369160392915]
	TIME [epoch: 6.07 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19109045800751545		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.19109045800751545 | validation: 0.30097241610377284]
	TIME [epoch: 6.07 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21575619052814113		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.21575619052814113 | validation: 0.21953475726201802]
	TIME [epoch: 6.08 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26527304150840414		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.26527304150840414 | validation: 0.24859967453761944]
	TIME [epoch: 6.07 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1951891466101828		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.1951891466101828 | validation: 0.23394200243819152]
	TIME [epoch: 6.07 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1824681564540753		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1824681564540753 | validation: 0.19200491126219177]
	TIME [epoch: 6.07 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1748039714871074		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.1748039714871074 | validation: 0.22709591792645656]
	TIME [epoch: 6.08 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17549807673568182		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.17549807673568182 | validation: 0.15918806766431792]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_384.pth
	Model improved!!!
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19703283601524		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.19703283601524 | validation: 0.5362230224635386]
	TIME [epoch: 6.07 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38109477444291484		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.38109477444291484 | validation: 0.34501023486323956]
	TIME [epoch: 6.07 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4703267856135963		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.4703267856135963 | validation: 0.4039824580354061]
	TIME [epoch: 6.07 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5685915826776384		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.5685915826776384 | validation: 0.3850788668806557]
	TIME [epoch: 6.07 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2689428052060767		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.2689428052060767 | validation: 0.45400498803091366]
	TIME [epoch: 6.07 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30666063908226265		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.30666063908226265 | validation: 0.21841261039664694]
	TIME [epoch: 6.07 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24815395678385208		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.24815395678385208 | validation: 0.18504688872873995]
	TIME [epoch: 6.07 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1856766340221282		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1856766340221282 | validation: 0.2697622667639015]
	TIME [epoch: 6.07 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2073320627410874		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.2073320627410874 | validation: 0.19247963182925237]
	TIME [epoch: 6.07 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2051225565888612		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.2051225565888612 | validation: 0.20723865655354415]
	TIME [epoch: 6.07 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18315823863538086		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.18315823863538086 | validation: 0.18139577656544204]
	TIME [epoch: 6.07 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17424708186619536		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.17424708186619536 | validation: 0.17928721099415462]
	TIME [epoch: 6.09 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17208746555974178		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.17208746555974178 | validation: 0.1816417389342152]
	TIME [epoch: 6.06 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17837347936911072		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.17837347936911072 | validation: 0.17805487177533103]
	TIME [epoch: 6.06 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18369086305084764		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.18369086305084764 | validation: 0.28379476662394143]
	TIME [epoch: 6.06 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21700861836295843		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.21700861836295843 | validation: 0.21244580762854648]
	TIME [epoch: 6.07 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25696715577157114		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.25696715577157114 | validation: 0.17634750098880622]
	TIME [epoch: 6.07 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16703170971186382		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.16703170971186382 | validation: 0.18768698113447213]
	TIME [epoch: 6.07 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1611041751116624		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.1611041751116624 | validation: 0.15835201882193636]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2010040492866618		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.2010040492866618 | validation: 0.3500096981026467]
	TIME [epoch: 6.06 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25056943904595613		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.25056943904595613 | validation: 0.25055090935091334]
	TIME [epoch: 6.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2916094390361881		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.2916094390361881 | validation: 0.165858469243871]
	TIME [epoch: 6.06 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18195570258516056		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.18195570258516056 | validation: 0.40724209730233163]
	TIME [epoch: 6.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28480634710942254		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.28480634710942254 | validation: 0.24219925194582048]
	TIME [epoch: 6.07 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31265964943491087		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.31265964943491087 | validation: 0.20636530526348454]
	TIME [epoch: 6.06 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22092176919346954		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.22092176919346954 | validation: 0.3474746406340185]
	TIME [epoch: 6.07 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25143728291789114		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.25143728291789114 | validation: 0.18329166301632274]
	TIME [epoch: 6.07 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2004771954608053		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.2004771954608053 | validation: 0.15072249933104734]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1705301368057938		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.1705301368057938 | validation: 0.2088679628633802]
	TIME [epoch: 6.04 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16688224413531877		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.16688224413531877 | validation: 0.19041885845077886]
	TIME [epoch: 6.04 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17072125218871875		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.17072125218871875 | validation: 0.19033825346284414]
	TIME [epoch: 6.04 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17822459135473956		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.17822459135473956 | validation: 0.21270573487113453]
	TIME [epoch: 6.06 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1890696101827775		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.1890696101827775 | validation: 0.2052865448124971]
	TIME [epoch: 6.07 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1706908944416935		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.1706908944416935 | validation: 0.17115711913216117]
	TIME [epoch: 6.09 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1687320808920387		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.1687320808920387 | validation: 0.22325768074606414]
	TIME [epoch: 6.08 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15996956602001153		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.15996956602001153 | validation: 0.15198229936680258]
	TIME [epoch: 6.07 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1728498488753946		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.1728498488753946 | validation: 0.278487914551436]
	TIME [epoch: 6.07 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19265491174039212		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.19265491174039212 | validation: 0.20159793292850736]
	TIME [epoch: 6.06 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2729935195499217		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.2729935195499217 | validation: 0.327196270879897]
	TIME [epoch: 6.06 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2128846442223756		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.2128846442223756 | validation: 0.28044750399148777]
	TIME [epoch: 6.07 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20161269227947018		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.20161269227947018 | validation: 0.26931081580830607]
	TIME [epoch: 6.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3528428820188501		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.3528428820188501 | validation: 0.27607485824865524]
	TIME [epoch: 6.07 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19398658047851414		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.19398658047851414 | validation: 0.47821996868019867]
	TIME [epoch: 6.07 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34177514746848175		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.34177514746848175 | validation: 0.24667671448512196]
	TIME [epoch: 6.07 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29960586415884505		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.29960586415884505 | validation: 0.3902274682928698]
	TIME [epoch: 6.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2963190440536217		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.2963190440536217 | validation: 0.3895631543871654]
	TIME [epoch: 6.07 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24907962171148926		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.24907962171148926 | validation: 0.159724743883508]
	TIME [epoch: 6.06 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1710099214400104		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.1710099214400104 | validation: 0.17949598230600683]
	TIME [epoch: 6.06 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16040323019823624		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.16040323019823624 | validation: 0.20674434392654817]
	TIME [epoch: 6.07 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15759164997521438		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.15759164997521438 | validation: 0.15272752440700482]
	TIME [epoch: 6.08 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1532006379630807		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.1532006379630807 | validation: 0.1683370665155612]
	TIME [epoch: 6.08 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15248148422041718		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.15248148422041718 | validation: 0.14807142801681142]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15317859708311907		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.15317859708311907 | validation: 0.23723809868915313]
	TIME [epoch: 6.06 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15744376961243908		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.15744376961243908 | validation: 0.15462399832683238]
	TIME [epoch: 6.06 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1580757168107311		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.1580757168107311 | validation: 0.19424623279800313]
	TIME [epoch: 6.06 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1638810341485233		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.1638810341485233 | validation: 0.14755463800608942]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_440.pth
	Model improved!!!
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15893378820047482		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.15893378820047482 | validation: 0.3520310749095268]
	TIME [epoch: 6.08 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22130743190998392		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.22130743190998392 | validation: 0.20419461959195837]
	TIME [epoch: 6.08 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22091830670482776		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.22091830670482776 | validation: 0.15365311436189152]
	TIME [epoch: 6.08 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14673710489688283		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.14673710489688283 | validation: 0.25007844914829386]
	TIME [epoch: 6.09 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17165081450600247		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.17165081450600247 | validation: 0.17859010429927383]
	TIME [epoch: 6.08 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19336057019137898		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.19336057019137898 | validation: 0.17755110514826447]
	TIME [epoch: 6.09 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14797682040155624		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.14797682040155624 | validation: 0.22314129839996533]
	TIME [epoch: 6.03 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1601092628392896		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.1601092628392896 | validation: 0.14895993750648964]
	TIME [epoch: 6.03 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17988584666605514		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.17988584666605514 | validation: 0.3406640919433037]
	TIME [epoch: 6.04 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20236650075128418		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.20236650075128418 | validation: 0.15929963862617239]
	TIME [epoch: 6.04 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16663404835032353		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.16663404835032353 | validation: 0.17757642316516892]
	TIME [epoch: 6.04 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17167056019270344		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.17167056019270344 | validation: 0.1817360513304015]
	TIME [epoch: 6.04 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1622411844363142		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.1622411844363142 | validation: 0.1979590234529307]
	TIME [epoch: 6.03 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15832755742041765		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.15832755742041765 | validation: 0.13236544595244942]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1643263210340978		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.1643263210340978 | validation: 0.29665174088714513]
	TIME [epoch: 6.07 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19100360929289012		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.19100360929289012 | validation: 0.1542740068948496]
	TIME [epoch: 6.07 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1813945904579843		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.1813945904579843 | validation: 0.1710095563115408]
	TIME [epoch: 6.06 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14008798702456027		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.14008798702456027 | validation: 0.13413186259093296]
	TIME [epoch: 6.06 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.142561729013846		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.142561729013846 | validation: 0.17225703663793376]
	TIME [epoch: 6.06 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13883479761560025		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.13883479761560025 | validation: 0.15015706512871702]
	TIME [epoch: 6.06 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1349913587753309		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.1349913587753309 | validation: 0.2356648211093753]
	TIME [epoch: 6.07 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15002464033677135		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15002464033677135 | validation: 0.18151645872807934]
	TIME [epoch: 6.07 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22125582658875162		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.22125582658875162 | validation: 0.22038901753564089]
	TIME [epoch: 6.07 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15071577182832024		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.15071577182832024 | validation: 0.16596488183584523]
	TIME [epoch: 6.04 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13672632798791334		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.13672632798791334 | validation: 0.17114142884749384]
	TIME [epoch: 6.03 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14222725484548368		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.14222725484548368 | validation: 0.14758511983599717]
	TIME [epoch: 6.03 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14298788829565717		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.14298788829565717 | validation: 0.23287625663454012]
	TIME [epoch: 6.04 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18662136205092306		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.18662136205092306 | validation: 0.21962423192534317]
	TIME [epoch: 6.04 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.278578828480529		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.278578828480529 | validation: 0.2535923922913061]
	TIME [epoch: 6.04 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16759694384153065		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.16759694384153065 | validation: 0.32333354699509526]
	TIME [epoch: 6.04 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25483960396357547		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.25483960396357547 | validation: 0.19035783740270218]
	TIME [epoch: 6.03 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23955956217671984		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.23955956217671984 | validation: 0.36001236742934156]
	TIME [epoch: 6.03 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21679151799565458		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.21679151799565458 | validation: 0.32130182416512154]
	TIME [epoch: 6.03 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18793895277039036		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.18793895277039036 | validation: 0.152943403440418]
	TIME [epoch: 6.03 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2025351417320153		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.2025351417320153 | validation: 0.1533725288982305]
	TIME [epoch: 6.03 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13885848076717947		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.13885848076717947 | validation: 0.19992388809430345]
	TIME [epoch: 6.03 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14198457780494692		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.14198457780494692 | validation: 0.14735188763622203]
	TIME [epoch: 6.03 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14135349867544267		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.14135349867544267 | validation: 0.15532497136208534]
	TIME [epoch: 6.03 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1289892700644343		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.1289892700644343 | validation: 0.13207914540372784]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13073591158152675		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.13073591158152675 | validation: 0.1426765949355173]
	TIME [epoch: 6.08 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1260199554996073		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.1260199554996073 | validation: 0.16367182093107085]
	TIME [epoch: 6.09 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12968938517229833		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.12968938517229833 | validation: 0.13553496414702368]
	TIME [epoch: 6.04 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12235912787130489		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.12235912787130489 | validation: 0.12904952954218754]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_483.pth
	Model improved!!!
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13332606918165352		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.13332606918165352 | validation: 0.4063778808575338]
	TIME [epoch: 6.04 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2546130646302376		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.2546130646302376 | validation: 0.23180831198406082]
	TIME [epoch: 6.03 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24109146320806873		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.24109146320806873 | validation: 0.13587133895502315]
	TIME [epoch: 6.03 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1661884381077746		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.1661884381077746 | validation: 0.369661149330384]
	TIME [epoch: 6.03 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2545157915349543		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.2545157915349543 | validation: 0.15594421416504553]
	TIME [epoch: 6.03 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16153762408201594		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.16153762408201594 | validation: 0.1324800964693816]
	TIME [epoch: 6.03 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1461752786306986		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.1461752786306986 | validation: 0.1891872861232945]
	TIME [epoch: 6.02 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14193606051877375		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.14193606051877375 | validation: 0.14599015669335672]
	TIME [epoch: 6.02 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1409073465002216		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.1409073465002216 | validation: 0.13115265811409357]
	TIME [epoch: 6.02 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1326701371001375		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.1326701371001375 | validation: 0.16323980846872577]
	TIME [epoch: 6.02 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12613114721814483		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.12613114721814483 | validation: 0.15596483696524854]
	TIME [epoch: 6.02 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13047794454846776		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.13047794454846776 | validation: 0.15264196698863253]
	TIME [epoch: 6.03 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14288465157860464		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.14288465157860464 | validation: 0.15522463619809224]
	TIME [epoch: 6.03 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14164964375596567		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.14164964375596567 | validation: 0.17723781967890476]
	TIME [epoch: 6.03 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13436024076113628		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.13436024076113628 | validation: 0.1260393324983259]
	TIME [epoch: 6.03 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13666239756680623		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.13666239756680623 | validation: 0.1906093311758447]
	TIME [epoch: 6.03 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1338663307642954		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.1338663307642954 | validation: 0.1428105162287796]
	TIME [epoch: 6.03 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15059790673767867		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.15059790673767867 | validation: 0.21465180273410267]
	TIME [epoch: 211 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14507517467846306		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.14507517467846306 | validation: 0.1267096752191004]
	TIME [epoch: 12.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1389403507963463		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.1389403507963463 | validation: 0.20652409631569385]
	TIME [epoch: 12.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1392496622868657		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.1392496622868657 | validation: 0.14763519130051414]
	TIME [epoch: 12.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1470369017247248		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.1470369017247248 | validation: 0.13926839875683208]
	TIME [epoch: 12.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12105461978108846		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.12105461978108846 | validation: 0.201796901372368]
	TIME [epoch: 12.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12959326484098627		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.12959326484098627 | validation: 0.12980684068297]
	TIME [epoch: 12.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12971603474976673		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.12971603474976673 | validation: 0.21999110621139784]
	TIME [epoch: 12.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16017071333251706		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.16017071333251706 | validation: 0.18389424386444556]
	TIME [epoch: 12.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18212894803110216		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.18212894803110216 | validation: 0.15532449775391846]
	TIME [epoch: 12.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12379482919754967		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.12379482919754967 | validation: 0.170012264493611]
	TIME [epoch: 12.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12072296735664768		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.12072296735664768 | validation: 0.12686117972223285]
	TIME [epoch: 12.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13117270500271164		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.13117270500271164 | validation: 0.17556865387069923]
	TIME [epoch: 12.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12686167455458264		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.12686167455458264 | validation: 0.12223778414331506]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14035085898848537		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.14035085898848537 | validation: 0.2105505060166598]
	TIME [epoch: 12.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13828531663337612		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.13828531663337612 | validation: 0.12878999860881254]
	TIME [epoch: 12.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1609211430500776		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.1609211430500776 | validation: 0.240460287839376]
	TIME [epoch: 12.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13539600210198172		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.13539600210198172 | validation: 0.11735471109850637]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12804770091972653		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.12804770091972653 | validation: 0.22757638248216727]
	TIME [epoch: 12.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14082052060492434		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.14082052060492434 | validation: 0.13141655152218729]
	TIME [epoch: 12.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1395827581188468		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.1395827581188468 | validation: 0.22832881799178006]
	TIME [epoch: 12.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14372427065037305		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.14372427065037305 | validation: 0.17513496511765642]
	TIME [epoch: 12.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17288133645488427		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.17288133645488427 | validation: 0.1623045363655931]
	TIME [epoch: 12.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13291608917927206		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.13291608917927206 | validation: 0.1441197733392103]
	TIME [epoch: 12.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11374282482868382		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.11374282482868382 | validation: 0.12444499101917557]
	TIME [epoch: 12.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11182303580194926		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.11182303580194926 | validation: 0.11591232907197735]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_526.pth
	Model improved!!!
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11076981165046		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.11076981165046 | validation: 0.11641253765383233]
	TIME [epoch: 12.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11408858855866372		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.11408858855866372 | validation: 0.18450746805545648]
	TIME [epoch: 12.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11750153684320087		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.11750153684320087 | validation: 0.1377703358130453]
	TIME [epoch: 12.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15389267446683189		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.15389267446683189 | validation: 0.18727125268633515]
	TIME [epoch: 12.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12127118505117931		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.12127118505117931 | validation: 0.10705699372263916]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_531.pth
	Model improved!!!
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11877112223668199		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.11877112223668199 | validation: 0.34653523610370407]
	TIME [epoch: 12.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2036637668409886		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.2036637668409886 | validation: 0.18503716202461404]
	TIME [epoch: 12.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2061858089380175		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.2061858089380175 | validation: 0.13699476785930906]
	TIME [epoch: 12.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14728852754317745		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.14728852754317745 | validation: 0.3226583747372105]
	TIME [epoch: 12.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20128194716347758		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.20128194716347758 | validation: 0.1786332690752171]
	TIME [epoch: 12.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14120704459639044		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.14120704459639044 | validation: 0.12618623104225435]
	TIME [epoch: 12.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13950238617914257		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.13950238617914257 | validation: 0.16874112448400214]
	TIME [epoch: 12.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11658554632366133		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.11658554632366133 | validation: 0.1374360247507203]
	TIME [epoch: 12.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11414588312083077		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.11414588312083077 | validation: 0.1349623400251587]
	TIME [epoch: 12.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10492157317006755		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.10492157317006755 | validation: 0.11645574289976778]
	TIME [epoch: 12.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10684922544013718		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.10684922544013718 | validation: 0.11554033175115493]
	TIME [epoch: 12.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10763330709602861		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.10763330709602861 | validation: 0.16753291203844078]
	TIME [epoch: 12.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11166922193398493		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.11166922193398493 | validation: 0.12429033718321701]
	TIME [epoch: 12.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11233126979356849		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.11233126979356849 | validation: 0.13519974936099818]
	TIME [epoch: 12.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11240552921089146		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.11240552921089146 | validation: 0.12946474804010996]
	TIME [epoch: 12.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11083720611558441		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.11083720611558441 | validation: 0.1685954280134917]
	TIME [epoch: 12.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11659208501735158		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.11659208501735158 | validation: 0.13773756896749628]
	TIME [epoch: 12.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1416200134745381		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.1416200134745381 | validation: 0.17989677411015603]
	TIME [epoch: 12.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12776621014797018		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.12776621014797018 | validation: 0.12901584073154448]
	TIME [epoch: 12.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13850550748563425		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.13850550748563425 | validation: 0.2951744165849429]
	TIME [epoch: 12.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17121242770403114		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.17121242770403114 | validation: 0.1352643878379292]
	TIME [epoch: 12.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13900170245351862		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.13900170245351862 | validation: 0.12730505940406445]
	TIME [epoch: 12.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10690224694401489		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.10690224694401489 | validation: 0.21175356915280147]
	TIME [epoch: 12.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13320756209656115		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.13320756209656115 | validation: 0.12159032832109758]
	TIME [epoch: 12.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13160591078047407		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.13160591078047407 | validation: 0.16286956080824413]
	TIME [epoch: 12.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10977416508532546		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.10977416508532546 | validation: 0.1229550909954855]
	TIME [epoch: 12.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10204093635246586		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.10204093635246586 | validation: 0.14212045350371555]
	TIME [epoch: 12.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11356126874528247		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.11356126874528247 | validation: 0.18833283180486493]
	TIME [epoch: 12.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13771587422850737		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.13771587422850737 | validation: 0.10455012580837818]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12731488098448115		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.12731488098448115 | validation: 0.15517620087613923]
	TIME [epoch: 12.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1019434603312879		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.1019434603312879 | validation: 0.10666288310341734]
	TIME [epoch: 12.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10777291345555325		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.10777291345555325 | validation: 0.14860220767783178]
	TIME [epoch: 12.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10748447823780238		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.10748447823780238 | validation: 0.1523581534918227]
	TIME [epoch: 12.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11634200326600996		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.11634200326600996 | validation: 0.11017408408947618]
	TIME [epoch: 12.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12822977085187146		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.12822977085187146 | validation: 0.21425940653798584]
	TIME [epoch: 12.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1279818151531819		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.1279818151531819 | validation: 0.10012600409350468]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_567.pth
	Model improved!!!
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11747861358771829		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.11747861358771829 | validation: 0.174120427912934]
	TIME [epoch: 12.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10990125848559411		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.10990125848559411 | validation: 0.11522263891303386]
	TIME [epoch: 12.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10709208680059845		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.10709208680059845 | validation: 0.11764607165142521]
	TIME [epoch: 12.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10363626728498786		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.10363626728498786 | validation: 0.11946571741875478]
	TIME [epoch: 12.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10407228548146771		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.10407228548146771 | validation: 0.16742544870873596]
	TIME [epoch: 12.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10530356741747539		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.10530356741747539 | validation: 0.10977927579050423]
	TIME [epoch: 12.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11810059480540527		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.11810059480540527 | validation: 0.4051779545011933]
	TIME [epoch: 12.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2984625584984339		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.2984625584984339 | validation: 0.10433309972334603]
	TIME [epoch: 12.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12737070769693434		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.12737070769693434 | validation: 0.20232395082299748]
	TIME [epoch: 12.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14658535856675747		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.14658535856675747 | validation: 0.16487342723821174]
	TIME [epoch: 12.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1146529074157986		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.1146529074157986 | validation: 0.09531673774418417]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1050692394603459		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.1050692394603459 | validation: 0.11125019252509263]
	TIME [epoch: 12.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10109682678259434		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.10109682678259434 | validation: 0.12176760523780734]
	TIME [epoch: 12.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09924004182956718		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.09924004182956718 | validation: 0.11088616175352495]
	TIME [epoch: 12.8 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09838300799540267		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.09838300799540267 | validation: 0.14641818425955347]
	TIME [epoch: 12.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10299583925576443		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.10299583925576443 | validation: 0.0993790186459423]
	TIME [epoch: 12.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10958602766947423		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.10958602766947423 | validation: 0.24624399464577978]
	TIME [epoch: 12.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13145976485159053		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.13145976485159053 | validation: 0.1091441159816367]
	TIME [epoch: 12.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11395335780973892		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.11395335780973892 | validation: 0.1165948437640728]
	TIME [epoch: 12.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1023471435819485		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.1023471435819485 | validation: 0.1312388582296767]
	TIME [epoch: 12.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09631772221774618		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.09631772221774618 | validation: 0.11445711984657109]
	TIME [epoch: 12.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09802711898648708		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.09802711898648708 | validation: 0.09112834376793069]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10992535786554446		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.10992535786554446 | validation: 0.16639286533888967]
	TIME [epoch: 12.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10326354947071498		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.10326354947071498 | validation: 0.11417443325159007]
	TIME [epoch: 12.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10753404634344808		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.10753404634344808 | validation: 0.18549235648365797]
	TIME [epoch: 12.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11423389392435812		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.11423389392435812 | validation: 0.10072887741060171]
	TIME [epoch: 12.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11141972367167526		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.11141972367167526 | validation: 0.11524871681258837]
	TIME [epoch: 12.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09234396576179658		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.09234396576179658 | validation: 0.2279251569783421]
	TIME [epoch: 12.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12218785866403695		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.12218785866403695 | validation: 0.1121742623641381]
	TIME [epoch: 12.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11637244277041024		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.11637244277041024 | validation: 0.1634752391378262]
	TIME [epoch: 12.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11090065996602402		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.11090065996602402 | validation: 0.1416520437996429]
	TIME [epoch: 12.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10088794602529358		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.10088794602529358 | validation: 0.10928924265402627]
	TIME [epoch: 12.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10100689475680767		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.10100689475680767 | validation: 0.11912223148541656]
	TIME [epoch: 12.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09968454408125708		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.09968454408125708 | validation: 0.14273133987442152]
	TIME [epoch: 12.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11287118282515675		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.11287118282515675 | validation: 0.10291899456802585]
	TIME [epoch: 12.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11954068597707201		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.11954068597707201 | validation: 0.17553596950224973]
	TIME [epoch: 12.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10809667652929741		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.10809667652929741 | validation: 0.09231348737616168]
	TIME [epoch: 12.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10799568987982533		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.10799568987982533 | validation: 0.1407659592303642]
	TIME [epoch: 12.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09444413098208174		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.09444413098208174 | validation: 0.10229343465536772]
	TIME [epoch: 12.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09532427463411117		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.09532427463411117 | validation: 0.13017856160303753]
	TIME [epoch: 12.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09720001642388258		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.09720001642388258 | validation: 0.13426072245076748]
	TIME [epoch: 12.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09561183598302402		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.09561183598302402 | validation: 0.09214479499524386]
	TIME [epoch: 12.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1040373236481597		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.1040373236481597 | validation: 0.16687736388871768]
	TIME [epoch: 12.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09991083643376092		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.09991083643376092 | validation: 0.1061941807601745]
	TIME [epoch: 12.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10840303285352594		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.10840303285352594 | validation: 0.12605019610620205]
	TIME [epoch: 12.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10402072897897106		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.10402072897897106 | validation: 0.15103357473964255]
	TIME [epoch: 12.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10575583056398355		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.10575583056398355 | validation: 0.11644540773610342]
	TIME [epoch: 12.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10038999974201517		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.10038999974201517 | validation: 0.10374895772519324]
	TIME [epoch: 12.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.095353013977278		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.095353013977278 | validation: 0.17593773592726505]
	TIME [epoch: 12.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09624886374636925		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.09624886374636925 | validation: 0.10683959391357888]
	TIME [epoch: 12.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09382584146401131		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.09382584146401131 | validation: 0.13224871051434092]
	TIME [epoch: 12.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10449592482198927		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.10449592482198927 | validation: 0.12556526608541305]
	TIME [epoch: 12.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1351899956846167		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.1351899956846167 | validation: 0.18432538907750806]
	TIME [epoch: 12.8 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11019036153537756		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.11019036153537756 | validation: 0.09800722716881745]
	TIME [epoch: 12.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10094970508743258		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.10094970508743258 | validation: 0.10825558789567094]
	TIME [epoch: 12.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09634978611253192		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.09634978611253192 | validation: 0.15445322860796168]
	TIME [epoch: 12.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09507599802326044		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.09507599802326044 | validation: 0.09680043518709984]
	TIME [epoch: 12.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09382288401016461		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.09382288401016461 | validation: 0.1578335053776858]
	TIME [epoch: 12.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09061942691728962		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.09061942691728962 | validation: 0.10389756793653315]
	TIME [epoch: 12.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09580386975865764		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.09580386975865764 | validation: 0.13304702131857393]
	TIME [epoch: 12.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09690114431207537		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.09690114431207537 | validation: 0.12093479446616065]
	TIME [epoch: 12.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10365220745414706		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.10365220745414706 | validation: 0.14926568227045928]
	TIME [epoch: 12.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11199746576106363		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.11199746576106363 | validation: 0.11271877094520139]
	TIME [epoch: 12.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11650118122334531		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.11650118122334531 | validation: 0.1159639629962122]
	TIME [epoch: 12.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09045021857669902		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.09045021857669902 | validation: 0.15923822606227042]
	TIME [epoch: 12.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09789079220142936		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.09789079220142936 | validation: 0.0939173246504785]
	TIME [epoch: 12.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11477484451458982		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.11477484451458982 | validation: 0.4629031502047622]
	TIME [epoch: 12.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2649092072872684		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.2649092072872684 | validation: 0.3433623934995474]
	TIME [epoch: 12.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1653597684748144		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.1653597684748144 | validation: 0.11825578267291002]
	TIME [epoch: 12.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10988918998058217		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.10988918998058217 | validation: 0.1001211533610422]
	TIME [epoch: 12.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12109275647553229		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.12109275647553229 | validation: 0.12989093801046725]
	TIME [epoch: 12.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09558095739930732		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.09558095739930732 | validation: 0.14525823115841635]
	TIME [epoch: 12.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0897535223075274		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.0897535223075274 | validation: 0.11932846086238187]
	TIME [epoch: 12.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08921553293088871		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.08921553293088871 | validation: 0.10566064981326617]
	TIME [epoch: 12.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08514660010344823		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.08514660010344823 | validation: 0.11636949893839904]
	TIME [epoch: 12.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09005590643295713		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.09005590643295713 | validation: 0.09844689523707105]
	TIME [epoch: 12.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08833918767240814		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.08833918767240814 | validation: 0.10582571251135581]
	TIME [epoch: 12.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08358375330495844		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.08358375330495844 | validation: 0.13109578547134237]
	TIME [epoch: 12.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09033422615251112		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.09033422615251112 | validation: 0.09167411375266667]
	TIME [epoch: 12.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09193601352491391		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.09193601352491391 | validation: 0.12658165958203246]
	TIME [epoch: 12.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08597963603909559		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.08597963603909559 | validation: 0.12603655362384653]
	TIME [epoch: 12.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08518606377067624		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.08518606377067624 | validation: 0.10473112074060112]
	TIME [epoch: 12.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08470935531272591		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.08470935531272591 | validation: 0.10560873197861453]
	TIME [epoch: 12.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08806713843152052		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.08806713843152052 | validation: 0.10248637264961827]
	TIME [epoch: 12.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09113020575295125		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.09113020575295125 | validation: 0.12128889859117711]
	TIME [epoch: 12.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09387485647653218		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.09387485647653218 | validation: 0.11472752948357019]
	TIME [epoch: 12.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09421891915548632		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.09421891915548632 | validation: 0.1855635948798456]
	TIME [epoch: 12.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10573544885268771		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.10573544885268771 | validation: 0.09459822523024847]
	TIME [epoch: 12.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10443291080522805		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.10443291080522805 | validation: 0.1049099551372354]
	TIME [epoch: 12.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08766762512656913		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.08766762512656913 | validation: 0.12712670939370257]
	TIME [epoch: 12.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08896158126401334		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.08896158126401334 | validation: 0.10173914695790105]
	TIME [epoch: 12.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09615162224991183		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.09615162224991183 | validation: 0.0965545156615312]
	TIME [epoch: 12.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08722932216976227		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.08722932216976227 | validation: 0.09563242733613025]
	TIME [epoch: 12.8 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08879481835444875		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.08879481835444875 | validation: 0.1335708503420727]
	TIME [epoch: 12.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09693545503486316		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.09693545503486316 | validation: 0.10758627718932444]
	TIME [epoch: 12.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10006930048124625		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.10006930048124625 | validation: 0.11985241695432017]
	TIME [epoch: 12.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08964277878208207		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.08964277878208207 | validation: 0.10164181411605573]
	TIME [epoch: 12.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08507500345388114		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.08507500345388114 | validation: 0.09317933972248998]
	TIME [epoch: 12.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08140521318444492		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.08140521318444492 | validation: 0.12230576165572599]
	TIME [epoch: 12.8 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08676513074378495		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.08676513074378495 | validation: 0.09399592649641053]
	TIME [epoch: 12.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09186853621526211		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.09186853621526211 | validation: 0.13370901942264085]
	TIME [epoch: 12.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09562939786073325		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.09562939786073325 | validation: 0.12627163033933822]
	TIME [epoch: 12.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10187377676769512		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.10187377676769512 | validation: 0.10932598636394109]
	TIME [epoch: 12.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09044354613641688		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.09044354613641688 | validation: 0.10620241806105922]
	TIME [epoch: 12.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08289169927694708		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.08289169927694708 | validation: 0.1073098308902273]
	TIME [epoch: 12.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08331426666320157		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.08331426666320157 | validation: 0.09027260454092056]
	TIME [epoch: 12.7 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08071944537685562		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.08071944537685562 | validation: 0.10549245279741037]
	TIME [epoch: 12.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07766988874031078		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.07766988874031078 | validation: 0.12643738543526015]
	TIME [epoch: 12.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08288772268138905		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.08288772268138905 | validation: 0.10342336171332916]
	TIME [epoch: 12.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.099361209911558		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.099361209911558 | validation: 0.14301395881693926]
	TIME [epoch: 12.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1265518641077715		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.1265518641077715 | validation: 0.10794826273043562]
	TIME [epoch: 12.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09738333336390849		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.09738333336390849 | validation: 0.14517096503316204]
	TIME [epoch: 12.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08440512028487823		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.08440512028487823 | validation: 0.08123227777783233]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09504008663056335		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.09504008663056335 | validation: 0.1459163558999361]
	TIME [epoch: 12.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0877008842299863		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.0877008842299863 | validation: 0.09143335887201212]
	TIME [epoch: 12.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09134393878302031		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.09134393878302031 | validation: 0.11620575442750587]
	TIME [epoch: 12.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08388037624959704		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.08388037624959704 | validation: 0.09393536517647949]
	TIME [epoch: 12.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0815493922782256		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.0815493922782256 | validation: 0.0960131061234135]
	TIME [epoch: 12.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08013693796791956		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.08013693796791956 | validation: 0.10733389618127981]
	TIME [epoch: 12.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0772278982149147		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.0772278982149147 | validation: 0.12377413921380397]
	TIME [epoch: 12.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08998194271501941		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.08998194271501941 | validation: 0.12095491938702292]
	TIME [epoch: 12.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09231577552838134		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.09231577552838134 | validation: 0.09002183281035986]
	TIME [epoch: 12.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08824114172952627		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.08824114172952627 | validation: 0.14475658908180264]
	TIME [epoch: 12.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09591877453160544		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.09591877453160544 | validation: 0.08558441949479223]
	TIME [epoch: 12.8 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10158358164887972		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.10158358164887972 | validation: 0.14798848811585372]
	TIME [epoch: 12.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08476806142284428		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.08476806142284428 | validation: 0.09438873328393367]
	TIME [epoch: 12.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08097349400174941		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.08097349400174941 | validation: 0.10705926801347679]
	TIME [epoch: 12.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08322945602176088		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.08322945602176088 | validation: 0.1001138140826992]
	TIME [epoch: 12.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07867926951598887		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.07867926951598887 | validation: 0.0987390199209258]
	TIME [epoch: 12.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07688731312669563		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.07688731312669563 | validation: 0.09846459470351392]
	TIME [epoch: 12.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08775616472037254		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.08775616472037254 | validation: 0.12834607434297787]
	TIME [epoch: 12.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08783884502277506		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.08783884502277506 | validation: 0.08701970745441828]
	TIME [epoch: 12.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09815172990001012		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.09815172990001012 | validation: 0.16423307875124504]
	TIME [epoch: 12.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09151395083354764		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.09151395083354764 | validation: 0.08534479526894319]
	TIME [epoch: 12.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0812796169353184		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.0812796169353184 | validation: 0.126223097475063]
	TIME [epoch: 12.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07697111216389914		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.07697111216389914 | validation: 0.08564043795925519]
	TIME [epoch: 12.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07893331364300787		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.07893331364300787 | validation: 0.12472977012879048]
	TIME [epoch: 12.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07848236564251525		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.07848236564251525 | validation: 0.07803066430336608]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07949985868318564		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.07949985868318564 | validation: 0.1299377347236436]
	TIME [epoch: 12.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07814218789090414		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.07814218789090414 | validation: 0.13066448571713454]
	TIME [epoch: 12.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07797406681939884		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.07797406681939884 | validation: 0.08160486103159548]
	TIME [epoch: 12.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08525158241065092		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.08525158241065092 | validation: 0.1618133981206974]
	TIME [epoch: 12.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10464326916230586		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.10464326916230586 | validation: 0.11335157418889552]
	TIME [epoch: 12.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10792105167844428		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.10792105167844428 | validation: 0.09086691418344353]
	TIME [epoch: 12.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07579672892535873		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.07579672892535873 | validation: 0.10121280389449733]
	TIME [epoch: 12.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07547856714742594		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.07547856714742594 | validation: 0.0798749290425091]
	TIME [epoch: 12.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08045659882004653		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.08045659882004653 | validation: 0.11676504495230713]
	TIME [epoch: 12.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07486720470390319		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.07486720470390319 | validation: 0.10553868939256397]
	TIME [epoch: 12.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07902585005000594		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.07902585005000594 | validation: 0.08514893657612743]
	TIME [epoch: 12.8 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08193233178695261		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08193233178695261 | validation: 0.11406908178350053]
	TIME [epoch: 12.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07877711933106263		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.07877711933106263 | validation: 0.09356242940597195]
	TIME [epoch: 12.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07613224756420388		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.07613224756420388 | validation: 0.08776180171617654]
	TIME [epoch: 12.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07383760406828106		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.07383760406828106 | validation: 0.09082100674534632]
	TIME [epoch: 12.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07544376977581452		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.07544376977581452 | validation: 0.09289376269605543]
	TIME [epoch: 12.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07123278800667085		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.07123278800667085 | validation: 0.11578664876767866]
	TIME [epoch: 12.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07491856344613139		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.07491856344613139 | validation: 0.07992080510972036]
	TIME [epoch: 12.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0923919880506461		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.0923919880506461 | validation: 0.15125735113477345]
	TIME [epoch: 12.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11614873301825358		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.11614873301825358 | validation: 0.08753071716958939]
	TIME [epoch: 12.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09632879641745765		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.09632879641745765 | validation: 0.10976915742207836]
	TIME [epoch: 12.8 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06979133529763636		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.06979133529763636 | validation: 0.09677440443477199]
	TIME [epoch: 12.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08472850029539802		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.08472850029539802 | validation: 0.07834412716598223]
	TIME [epoch: 12.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07497610306420815		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.07497610306420815 | validation: 0.10984954231073421]
	TIME [epoch: 12.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07202186191976863		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.07202186191976863 | validation: 0.09633851120020576]
	TIME [epoch: 12.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07317237609191658		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.07317237609191658 | validation: 0.12906536815968783]
	TIME [epoch: 12.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07918534947125125		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.07918534947125125 | validation: 0.07146748185294015]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07793011631106386		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.07793011631106386 | validation: 0.1659722449720702]
	TIME [epoch: 12.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09112244226039812		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.09112244226039812 | validation: 0.07950222552724717]
	TIME [epoch: 12.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07604616332356826		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.07604616332356826 | validation: 0.08903471954011768]
	TIME [epoch: 12.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07835676069973463		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.07835676069973463 | validation: 0.11839513896418902]
	TIME [epoch: 12.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08176703674691627		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.08176703674691627 | validation: 0.08612234361968517]
	TIME [epoch: 12.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.075907181919686		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.075907181919686 | validation: 0.3634265925289708]
	TIME [epoch: 12.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19530085488444848		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.19530085488444848 | validation: 0.1260440262645167]
	TIME [epoch: 12.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08199064243750018		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.08199064243750018 | validation: 0.07600297551906926]
	TIME [epoch: 12.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.096293948997907		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.096293948997907 | validation: 0.08825913931272207]
	TIME [epoch: 12.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0806240495962206		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.0806240495962206 | validation: 0.13280399408815075]
	TIME [epoch: 12.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07377104160926409		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.07377104160926409 | validation: 0.12460378352354107]
	TIME [epoch: 12.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07668455204581696		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.07668455204581696 | validation: 0.08036311908016207]
	TIME [epoch: 12.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07759776920180719		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.07759776920180719 | validation: 0.08982731990205377]
	TIME [epoch: 12.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06993391861389055		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.06993391861389055 | validation: 0.09699836340633611]
	TIME [epoch: 12.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06720923216264099		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.06720923216264099 | validation: 0.08935776001598633]
	TIME [epoch: 12.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06951103284442726		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.06951103284442726 | validation: 0.08696396605813293]
	TIME [epoch: 12.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0669710994902938		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.0669710994902938 | validation: 0.07559191034582807]
	TIME [epoch: 12.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07442160344315628		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.07442160344315628 | validation: 0.10832142858084569]
	TIME [epoch: 12.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07150599563105577		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.07150599563105577 | validation: 0.07209327423374982]
	TIME [epoch: 12.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07848852205288089		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.07848852205288089 | validation: 0.10010155499248766]
	TIME [epoch: 12.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0711363263970638		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.0711363263970638 | validation: 0.10717950468231999]
	TIME [epoch: 12.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07746428356056305		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.07746428356056305 | validation: 0.10743090767388144]
	TIME [epoch: 12.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07224993482546385		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.07224993482546385 | validation: 0.0723947566482502]
	TIME [epoch: 12.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0725656793293661		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.0725656793293661 | validation: 0.0914682107205268]
	TIME [epoch: 12.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06979547001101728		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.06979547001101728 | validation: 0.112209024455629]
	TIME [epoch: 12.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08032736677761441		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.08032736677761441 | validation: 0.10698197533196568]
	TIME [epoch: 12.8 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09963872366992206		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.09963872366992206 | validation: 0.10337399045710916]
	TIME [epoch: 12.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0734716217526974		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.0734716217526974 | validation: 0.13191059315460962]
	TIME [epoch: 12.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0736642113051129		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.0736642113051129 | validation: 0.07420815687173529]
	TIME [epoch: 12.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07779191171161597		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.07779191171161597 | validation: 0.10077609589537069]
	TIME [epoch: 12.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07079610881861623		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.07079610881861623 | validation: 0.10583102014100268]
	TIME [epoch: 12.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07420098165091399		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.07420098165091399 | validation: 0.06795465990703947]
	TIME [epoch: 12.7 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08125756789999876		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.08125756789999876 | validation: 0.13722409543745084]
	TIME [epoch: 12.8 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0766121246845795		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.0766121246845795 | validation: 0.09965770825699267]
	TIME [epoch: 12.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07379451992580116		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.07379451992580116 | validation: 0.08284324862433262]
	TIME [epoch: 12.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07589441438303497		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.07589441438303497 | validation: 0.1106767719711852]
	TIME [epoch: 12.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06864499185302829		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.06864499185302829 | validation: 0.09088203317248807]
	TIME [epoch: 12.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06666834473724512		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.06666834473724512 | validation: 0.07841861504450559]
	TIME [epoch: 12.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07531784920047767		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.07531784920047767 | validation: 0.11394356641760961]
	TIME [epoch: 12.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07219272610819072		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.07219272610819072 | validation: 0.10040237158166505]
	TIME [epoch: 12.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06502902175873473		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.06502902175873473 | validation: 0.08245464359653634]
	TIME [epoch: 12.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06806684383502255		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.06806684383502255 | validation: 0.07963193827878562]
	TIME [epoch: 12.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.073176245006201		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.073176245006201 | validation: 0.12513737518211215]
	TIME [epoch: 12.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08134812454679219		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.08134812454679219 | validation: 0.08518573184508588]
	TIME [epoch: 12.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07818321890528537		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.07818321890528537 | validation: 0.0932135426954324]
	TIME [epoch: 12.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06963679349362499		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.06963679349362499 | validation: 0.07795304589135704]
	TIME [epoch: 12.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06796634934913628		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.06796634934913628 | validation: 0.08921679642201724]
	TIME [epoch: 12.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0687426684231026		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.0687426684231026 | validation: 0.0984525417181657]
	TIME [epoch: 12.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06555966375739708		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.06555966375739708 | validation: 0.0747191689574464]
	TIME [epoch: 12.8 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08466105667703337		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.08466105667703337 | validation: 0.16545284160959126]
	TIME [epoch: 12.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09463774242979608		[learning rate: 0.0007479]
	Learning Rate: 0.000747905
	LOSS [training: 0.09463774242979608 | validation: 0.10226272978778216]
	TIME [epoch: 12.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08322685873838208		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.08322685873838208 | validation: 0.07526314751106351]
	TIME [epoch: 12.8 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06778118068490187		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.06778118068490187 | validation: 0.0985365353218727]
	TIME [epoch: 12.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0691876079185279		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.0691876079185279 | validation: 0.08872008941006766]
	TIME [epoch: 12.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07676569994531358		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.07676569994531358 | validation: 0.08737941410793663]
	TIME [epoch: 12.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07165468491133536		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.07165468491133536 | validation: 0.07440535180408978]
	TIME [epoch: 12.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0694044724319936		[learning rate: 0.00073218]
	Learning Rate: 0.000732176
	LOSS [training: 0.0694044724319936 | validation: 0.11778534055741081]
	TIME [epoch: 12.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07010928032240467		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.07010928032240467 | validation: 0.07594542503060758]
	TIME [epoch: 12.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06880028487128977		[learning rate: 0.00072701]
	Learning Rate: 0.000727007
	LOSS [training: 0.06880028487128977 | validation: 0.10114245530860771]
	TIME [epoch: 12.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06617763313145633		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.06617763313145633 | validation: 0.11665589048917542]
	TIME [epoch: 12.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0672487306459942		[learning rate: 0.00072187]
	Learning Rate: 0.000721874
	LOSS [training: 0.0672487306459942 | validation: 0.07246045351583444]
	TIME [epoch: 12.8 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07167749793413142		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.07167749793413142 | validation: 0.0905897732378255]
	TIME [epoch: 12.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06401260158647665		[learning rate: 0.00071678]
	Learning Rate: 0.000716778
	LOSS [training: 0.06401260158647665 | validation: 0.08936123877126406]
	TIME [epoch: 12.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06416166861116586		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.06416166861116586 | validation: 0.06348631907024305]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_796.pth
	Model improved!!!
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06811272249130734		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.06811272249130734 | validation: 0.14308059189636985]
	TIME [epoch: 12.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07657683612693877		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.07657683612693877 | validation: 0.08674924662447506]
	TIME [epoch: 12.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07794527406065865		[learning rate: 0.00070669]
	Learning Rate: 0.000706693
	LOSS [training: 0.07794527406065865 | validation: 0.09954197306539944]
	TIME [epoch: 12.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08707203617839734		[learning rate: 0.00070419]
	Learning Rate: 0.000704194
	LOSS [training: 0.08707203617839734 | validation: 0.1013279158274638]
	TIME [epoch: 12.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07438923528660016		[learning rate: 0.0007017]
	Learning Rate: 0.000701704
	LOSS [training: 0.07438923528660016 | validation: 0.10339352292587917]
	TIME [epoch: 12.8 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0663444213992908		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.0663444213992908 | validation: 0.07435659760641171]
	TIME [epoch: 12.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07387597584125238		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.07387597584125238 | validation: 0.09689864609138055]
	TIME [epoch: 12.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06812717483434487		[learning rate: 0.00069429]
	Learning Rate: 0.000694286
	LOSS [training: 0.06812717483434487 | validation: 0.08816417282064598]
	TIME [epoch: 12.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0771599378629747		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.0771599378629747 | validation: 0.10544205861596023]
	TIME [epoch: 12.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06882902047147318		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.06882902047147318 | validation: 0.098569785838691]
	TIME [epoch: 12.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06346195833258837		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.06346195833258837 | validation: 0.08824976399954176]
	TIME [epoch: 12.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06385764711442855		[learning rate: 0.00068452]
	Learning Rate: 0.000684518
	LOSS [training: 0.06385764711442855 | validation: 0.08487804827940136]
	TIME [epoch: 12.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06859476178976269		[learning rate: 0.0006821]
	Learning Rate: 0.000682097
	LOSS [training: 0.06859476178976269 | validation: 0.07011066625821538]
	TIME [epoch: 12.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0698509517399606		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.0698509517399606 | validation: 0.14315872848816957]
	TIME [epoch: 12.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0714907497573105		[learning rate: 0.00067728]
	Learning Rate: 0.000677282
	LOSS [training: 0.0714907497573105 | validation: 0.07236279802402938]
	TIME [epoch: 12.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06869253484676949		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.06869253484676949 | validation: 0.09834206080499165]
	TIME [epoch: 12.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0627791617708586		[learning rate: 0.0006725]
	Learning Rate: 0.0006725
	LOSS [training: 0.0627791617708586 | validation: 0.09208278641221469]
	TIME [epoch: 12.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06385777703253404		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.06385777703253404 | validation: 0.10890105616307089]
	TIME [epoch: 12.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06787589932143567		[learning rate: 0.00066775]
	Learning Rate: 0.000667752
	LOSS [training: 0.06787589932143567 | validation: 0.08179851311433493]
	TIME [epoch: 12.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06374771098577846		[learning rate: 0.00066539]
	Learning Rate: 0.000665391
	LOSS [training: 0.06374771098577846 | validation: 0.08260965097419748]
	TIME [epoch: 12.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060588283746202454		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.060588283746202454 | validation: 0.07087706351750178]
	TIME [epoch: 12.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06413764727802274		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.06413764727802274 | validation: 0.11791280048101607]
	TIME [epoch: 12.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06580024321435214		[learning rate: 0.00065836]
	Learning Rate: 0.000658357
	LOSS [training: 0.06580024321435214 | validation: 0.07922267443483501]
	TIME [epoch: 12.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060784010701760344		[learning rate: 0.00065603]
	Learning Rate: 0.000656029
	LOSS [training: 0.060784010701760344 | validation: 0.06920483765741285]
	TIME [epoch: 12.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062051452353512726		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.062051452353512726 | validation: 0.1054498570909964]
	TIME [epoch: 12.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06658042376560565		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.06658042376560565 | validation: 0.076181116112744]
	TIME [epoch: 12.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.069024950276598		[learning rate: 0.00064909]
	Learning Rate: 0.000649094
	LOSS [training: 0.069024950276598 | validation: 0.10154315240844194]
	TIME [epoch: 12.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06293462887390638		[learning rate: 0.0006468]
	Learning Rate: 0.000646799
	LOSS [training: 0.06293462887390638 | validation: 0.07506550594435851]
	TIME [epoch: 12.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06482717779525388		[learning rate: 0.00064451]
	Learning Rate: 0.000644512
	LOSS [training: 0.06482717779525388 | validation: 0.07308104722990948]
	TIME [epoch: 12.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07288488948647862		[learning rate: 0.00064223]
	Learning Rate: 0.000642233
	LOSS [training: 0.07288488948647862 | validation: 0.113569985914871]
	TIME [epoch: 12.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07566011783781258		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.07566011783781258 | validation: 0.10333235226414245]
	TIME [epoch: 12.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06376042466898571		[learning rate: 0.0006377]
	Learning Rate: 0.000637699
	LOSS [training: 0.06376042466898571 | validation: 0.06889573505590843]
	TIME [epoch: 12.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06576425504872871		[learning rate: 0.00063544]
	Learning Rate: 0.000635443
	LOSS [training: 0.06576425504872871 | validation: 0.08885572368241855]
	TIME [epoch: 12.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06284608282524454		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.06284608282524454 | validation: 0.08628714988364905]
	TIME [epoch: 12.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0634323713099257		[learning rate: 0.00063096]
	Learning Rate: 0.000630957
	LOSS [training: 0.0634323713099257 | validation: 0.06693172429766452]
	TIME [epoch: 12.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06360281529541459		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.06360281529541459 | validation: 0.08118727732049619]
	TIME [epoch: 12.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0618463573437216		[learning rate: 0.0006265]
	Learning Rate: 0.000626503
	LOSS [training: 0.0618463573437216 | validation: 0.11504084674887803]
	TIME [epoch: 12.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06593746150958239		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.06593746150958239 | validation: 0.06282562775251058]
	TIME [epoch: 12.7 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_834.pth
	Model improved!!!
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07834078511868618		[learning rate: 0.00062208]
	Learning Rate: 0.00062208
	LOSS [training: 0.07834078511868618 | validation: 0.10950777672118091]
	TIME [epoch: 12.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06614447769617787		[learning rate: 0.00061988]
	Learning Rate: 0.00061988
	LOSS [training: 0.06614447769617787 | validation: 0.09271692495283117]
	TIME [epoch: 12.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06480694361955727		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.06480694361955727 | validation: 0.06997915416529782]
	TIME [epoch: 12.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06909425939279278		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.06909425939279278 | validation: 0.11463498886270061]
	TIME [epoch: 12.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0643985405093884		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.0643985405093884 | validation: 0.0891514292457066]
	TIME [epoch: 12.8 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06596761430029399		[learning rate: 0.00061116]
	Learning Rate: 0.000611158
	LOSS [training: 0.06596761430029399 | validation: 0.0977432230438608]
	TIME [epoch: 12.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06369493072485677		[learning rate: 0.000609]
	Learning Rate: 0.000608997
	LOSS [training: 0.06369493072485677 | validation: 0.06795653023207963]
	TIME [epoch: 12.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06806768192399179		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.06806768192399179 | validation: 0.09503364378844142]
	TIME [epoch: 12.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05837027376105109		[learning rate: 0.0006047]
	Learning Rate: 0.000604698
	LOSS [training: 0.05837027376105109 | validation: 0.09681215260066404]
	TIME [epoch: 12.8 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06180632167523795		[learning rate: 0.00060256]
	Learning Rate: 0.00060256
	LOSS [training: 0.06180632167523795 | validation: 0.0630972565937208]
	TIME [epoch: 12.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06929462718798847		[learning rate: 0.00060043]
	Learning Rate: 0.000600429
	LOSS [training: 0.06929462718798847 | validation: 0.0877541520695206]
	TIME [epoch: 12.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06447300988248929		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.06447300988248929 | validation: 0.0722296214579348]
	TIME [epoch: 12.8 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06174281128180137		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.06174281128180137 | validation: 0.07567793191912826]
	TIME [epoch: 12.8 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060241630617414436		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.060241630617414436 | validation: 0.07645811739273467]
	TIME [epoch: 12.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06033502504298378		[learning rate: 0.00059198]
	Learning Rate: 0.000591981
	LOSS [training: 0.06033502504298378 | validation: 0.09527681813315741]
	TIME [epoch: 12.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0650057821996726		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.0650057821996726 | validation: 0.07375407939965897]
	TIME [epoch: 12.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06294690028556586		[learning rate: 0.0005878]
	Learning Rate: 0.000587802
	LOSS [training: 0.06294690028556586 | validation: 0.09570555979187952]
	TIME [epoch: 12.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06247984340335492		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.06247984340335492 | validation: 0.07849682506275002]
	TIME [epoch: 12.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07133470852767737		[learning rate: 0.00058365]
	Learning Rate: 0.000583652
	LOSS [training: 0.07133470852767737 | validation: 0.10974058232235723]
	TIME [epoch: 12.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07216429595810282		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.07216429595810282 | validation: 0.061060089263387754]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_854.pth
	Model improved!!!
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05791560970735692		[learning rate: 0.00057953]
	Learning Rate: 0.000579531
	LOSS [training: 0.05791560970735692 | validation: 0.08660578667812775]
	TIME [epoch: 12.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06275642746478309		[learning rate: 0.00057748]
	Learning Rate: 0.000577482
	LOSS [training: 0.06275642746478309 | validation: 0.09300998488722734]
	TIME [epoch: 12.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06906431642170206		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.06906431642170206 | validation: 0.07392060994974799]
	TIME [epoch: 12.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06991468780401386		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.06991468780401386 | validation: 0.1218305828726972]
	TIME [epoch: 12.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06410755624222951		[learning rate: 0.00057138]
	Learning Rate: 0.000571377
	LOSS [training: 0.06410755624222951 | validation: 0.08412499809902613]
	TIME [epoch: 12.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05960566544374646		[learning rate: 0.00056936]
	Learning Rate: 0.000569357
	LOSS [training: 0.05960566544374646 | validation: 0.06020912937378129]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06195498911311545		[learning rate: 0.00056734]
	Learning Rate: 0.000567344
	LOSS [training: 0.06195498911311545 | validation: 0.1254467876378866]
	TIME [epoch: 12.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06375475988557304		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.06375475988557304 | validation: 0.06786413413873826]
	TIME [epoch: 12.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05999537316417877		[learning rate: 0.00056334]
	Learning Rate: 0.000563338
	LOSS [training: 0.05999537316417877 | validation: 0.07721038694392914]
	TIME [epoch: 12.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05936257743513215		[learning rate: 0.00056135]
	Learning Rate: 0.000561346
	LOSS [training: 0.05936257743513215 | validation: 0.08461416843501457]
	TIME [epoch: 12.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06116541952676297		[learning rate: 0.00055936]
	Learning Rate: 0.000559361
	LOSS [training: 0.06116541952676297 | validation: 0.07947964019227427]
	TIME [epoch: 12.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05754686965641527		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.05754686965641527 | validation: 0.06604142992307825]
	TIME [epoch: 12.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057423202937954956		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.057423202937954956 | validation: 0.09373860697641571]
	TIME [epoch: 12.8 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05965059030566646		[learning rate: 0.00055345]
	Learning Rate: 0.000553448
	LOSS [training: 0.05965059030566646 | validation: 0.10967556802733658]
	TIME [epoch: 12.8 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0807072148397151		[learning rate: 0.00055149]
	Learning Rate: 0.000551491
	LOSS [training: 0.0807072148397151 | validation: 0.08293858321102497]
	TIME [epoch: 12.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06425489928048977		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.06425489928048977 | validation: 0.06217052065288556]
	TIME [epoch: 12.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062009221944838364		[learning rate: 0.0005476]
	Learning Rate: 0.000547598
	LOSS [training: 0.062009221944838364 | validation: 0.07021156697097827]
	TIME [epoch: 12.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054855109210760665		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.054855109210760665 | validation: 0.11449548975092226]
	TIME [epoch: 12.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06682881823496432		[learning rate: 0.00054373]
	Learning Rate: 0.000543732
	LOSS [training: 0.06682881823496432 | validation: 0.06353865943546375]
	TIME [epoch: 12.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05724174360779493		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.05724174360779493 | validation: 0.10276924944276689]
	TIME [epoch: 12.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06519222727983533		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.06519222727983533 | validation: 0.08435539273549718]
	TIME [epoch: 12.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061785369166930386		[learning rate: 0.00053798]
	Learning Rate: 0.000537984
	LOSS [training: 0.061785369166930386 | validation: 0.07340428842362752]
	TIME [epoch: 12.8 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05661636552876873		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.05661636552876873 | validation: 0.08278165535438624]
	TIME [epoch: 12.8 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05936893477990912		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.05936893477990912 | validation: 0.39447293648844295]
	TIME [epoch: 12.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25646450450767233		[learning rate: 0.0005323]
	Learning Rate: 0.000532297
	LOSS [training: 0.25646450450767233 | validation: 0.1906768789662681]
	TIME [epoch: 12.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13569009454202824		[learning rate: 0.00053041]
	Learning Rate: 0.000530415
	LOSS [training: 0.13569009454202824 | validation: 0.05110511196627729]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_880.pth
	Model improved!!!
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06260467012739027		[learning rate: 0.00052854]
	Learning Rate: 0.000528539
	LOSS [training: 0.06260467012739027 | validation: 0.07742210265004915]
	TIME [epoch: 12.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0800292718505569		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.0800292718505569 | validation: 0.09188304141809576]
	TIME [epoch: 12.8 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06046638672666771		[learning rate: 0.00052481]
	Learning Rate: 0.000524808
	LOSS [training: 0.06046638672666771 | validation: 0.08714694741355078]
	TIME [epoch: 12.8 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0634374257262255		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.0634374257262255 | validation: 0.07024381446658089]
	TIME [epoch: 12.8 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06386299963344283		[learning rate: 0.0005211]
	Learning Rate: 0.000521102
	LOSS [training: 0.06386299963344283 | validation: 0.07344584499889087]
	TIME [epoch: 12.8 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05762175246746537		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.05762175246746537 | validation: 0.08388224534402272]
	TIME [epoch: 12.8 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057715931965604865		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.057715931965604865 | validation: 0.06547580665365273]
	TIME [epoch: 12.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05621224798696818		[learning rate: 0.00051559]
	Learning Rate: 0.000515594
	LOSS [training: 0.05621224798696818 | validation: 0.07330469269168194]
	TIME [epoch: 12.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05571167834022136		[learning rate: 0.00051377]
	Learning Rate: 0.000513771
	LOSS [training: 0.05571167834022136 | validation: 0.08056258812496708]
	TIME [epoch: 12.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05833213286991223		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.05833213286991223 | validation: 0.07033835133054221]
	TIME [epoch: 12.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05499943509236251		[learning rate: 0.00051014]
	Learning Rate: 0.000510144
	LOSS [training: 0.05499943509236251 | validation: 0.05587525109381856]
	TIME [epoch: 12.8 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061137332843659103		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.061137332843659103 | validation: 0.079866614402622]
	TIME [epoch: 12.8 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05631879234772922		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.05631879234772922 | validation: 0.1118202303134736]
	TIME [epoch: 12.8 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06039212700506195		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.06039212700506195 | validation: 0.06236639976459544]
	TIME [epoch: 12.8 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057089223759669724		[learning rate: 0.00050297]
	Learning Rate: 0.000502966
	LOSS [training: 0.057089223759669724 | validation: 0.0725455698134788]
	TIME [epoch: 12.8 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05509172757412971		[learning rate: 0.00050119]
	Learning Rate: 0.000501187
	LOSS [training: 0.05509172757412971 | validation: 0.11883024351689664]
	TIME [epoch: 12.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06697896497891893		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.06697896497891893 | validation: 0.06737648422409884]
	TIME [epoch: 12.8 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05698685316829799		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.05698685316829799 | validation: 0.06069149958215284]
	TIME [epoch: 12.8 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06579864167798125		[learning rate: 0.00049589]
	Learning Rate: 0.000495889
	LOSS [training: 0.06579864167798125 | validation: 0.07573191409956964]
	TIME [epoch: 12.8 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057816328094274734		[learning rate: 0.00049414]
	Learning Rate: 0.000494136
	LOSS [training: 0.057816328094274734 | validation: 0.09104315049279457]
	TIME [epoch: 12.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05574139720173275		[learning rate: 0.00049239]
	Learning Rate: 0.000492388
	LOSS [training: 0.05574139720173275 | validation: 0.08258431822181704]
	TIME [epoch: 12.8 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05822464846393443		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.05822464846393443 | validation: 0.06546554662943349]
	TIME [epoch: 12.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05801776194405152		[learning rate: 0.00048891]
	Learning Rate: 0.000488912
	LOSS [training: 0.05801776194405152 | validation: 0.0774256309183022]
	TIME [epoch: 12.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05727097771164688		[learning rate: 0.00048718]
	Learning Rate: 0.000487183
	LOSS [training: 0.05727097771164688 | validation: 0.09544007824957576]
	TIME [epoch: 12.8 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058448038657353665		[learning rate: 0.00048546]
	Learning Rate: 0.00048546
	LOSS [training: 0.058448038657353665 | validation: 0.07232716543361478]
	TIME [epoch: 12.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057113318950295734		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.057113318950295734 | validation: 0.062033852053199806]
	TIME [epoch: 12.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056165773900227534		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.056165773900227534 | validation: 0.08352676659296684]
	TIME [epoch: 12.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05626191410198526		[learning rate: 0.00048033]
	Learning Rate: 0.000480329
	LOSS [training: 0.05626191410198526 | validation: 0.04964962050326942]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0655348072918903		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.0655348072918903 | validation: 0.09703280782915752]
	TIME [epoch: 12.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06150916475193475		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.06150916475193475 | validation: 0.07174501830356164]
	TIME [epoch: 12.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056154396686816196		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.056154396686816196 | validation: 0.07551916586709828]
	TIME [epoch: 12.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057502713240286794		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.057502713240286794 | validation: 0.081304443167472]
	TIME [epoch: 12.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0575088801484213		[learning rate: 0.0004719]
	Learning Rate: 0.000471896
	LOSS [training: 0.0575088801484213 | validation: 0.07970392265466542]
	TIME [epoch: 12.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05827556618140925		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.05827556618140925 | validation: 0.07328506736744327]
	TIME [epoch: 12.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056592947716315616		[learning rate: 0.00046856]
	Learning Rate: 0.000468564
	LOSS [training: 0.056592947716315616 | validation: 0.07292872339445906]
	TIME [epoch: 12.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05304969706446972		[learning rate: 0.00046691]
	Learning Rate: 0.000466907
	LOSS [training: 0.05304969706446972 | validation: 0.0727100540144796]
	TIME [epoch: 12.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05328558473427845		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.05328558473427845 | validation: 0.07999814267671264]
	TIME [epoch: 12.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05664800054246477		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.05664800054246477 | validation: 0.07201356550062445]
	TIME [epoch: 12.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059333645950832514		[learning rate: 0.00046197]
	Learning Rate: 0.000461972
	LOSS [training: 0.059333645950832514 | validation: 0.07860451657756436]
	TIME [epoch: 12.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06216220841146116		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.06216220841146116 | validation: 0.08696225436656499]
	TIME [epoch: 12.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052354451497072914		[learning rate: 0.00045871]
	Learning Rate: 0.00045871
	LOSS [training: 0.052354451497072914 | validation: 0.057273517218757786]
	TIME [epoch: 12.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061940962851624766		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.061940962851624766 | validation: 0.09529975937696339]
	TIME [epoch: 12.8 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05905335721198443		[learning rate: 0.00045547]
	Learning Rate: 0.000455472
	LOSS [training: 0.05905335721198443 | validation: 0.05571023376630211]
	TIME [epoch: 12.8 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05944325541691274		[learning rate: 0.00045386]
	Learning Rate: 0.000453861
	LOSS [training: 0.05944325541691274 | validation: 0.07306368134499136]
	TIME [epoch: 12.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054365480210846244		[learning rate: 0.00045226]
	Learning Rate: 0.000452256
	LOSS [training: 0.054365480210846244 | validation: 0.10179399748219378]
	TIME [epoch: 12.8 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060218090308933665		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.060218090308933665 | validation: 0.05799040078111953]
	TIME [epoch: 12.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06045995470730579		[learning rate: 0.00044906]
	Learning Rate: 0.000449063
	LOSS [training: 0.06045995470730579 | validation: 0.06508556273476501]
	TIME [epoch: 12.8 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05737109852309224		[learning rate: 0.00044748]
	Learning Rate: 0.000447476
	LOSS [training: 0.05737109852309224 | validation: 0.07403201315300785]
	TIME [epoch: 12.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05390984898407648		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.05390984898407648 | validation: 0.06928725753197128]
	TIME [epoch: 12.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053202107207378745		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.053202107207378745 | validation: 0.07270358807583654]
	TIME [epoch: 12.8 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054710665990938656		[learning rate: 0.00044275]
	Learning Rate: 0.000442745
	LOSS [training: 0.054710665990938656 | validation: 0.08007209268802024]
	TIME [epoch: 12.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05643642183036152		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.05643642183036152 | validation: 0.10820729961425357]
	TIME [epoch: 12.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05877403637750553		[learning rate: 0.00043962]
	Learning Rate: 0.00043962
	LOSS [training: 0.05877403637750553 | validation: 0.05775770617683565]
	TIME [epoch: 12.8 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06328297546320591		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.06328297546320591 | validation: 0.09700469323971997]
	TIME [epoch: 12.8 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051744709965962865		[learning rate: 0.00043652]
	Learning Rate: 0.000436516
	LOSS [training: 0.051744709965962865 | validation: 0.08351313609593206]
	TIME [epoch: 12.8 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05685952535667811		[learning rate: 0.00043497]
	Learning Rate: 0.000434972
	LOSS [training: 0.05685952535667811 | validation: 0.06489004101689937]
	TIME [epoch: 12.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05414688404836838		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.05414688404836838 | validation: 0.06994257807158015]
	TIME [epoch: 12.8 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054238590995106827		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.054238590995106827 | validation: 0.0802884921920087]
	TIME [epoch: 12.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056351542459459725		[learning rate: 0.00043037]
	Learning Rate: 0.000430374
	LOSS [training: 0.056351542459459725 | validation: 0.06639079641604698]
	TIME [epoch: 12.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05587649791578669		[learning rate: 0.00042885]
	Learning Rate: 0.000428852
	LOSS [training: 0.05587649791578669 | validation: 0.07325482494774264]
	TIME [epoch: 12.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06359157051514791		[learning rate: 0.00042734]
	Learning Rate: 0.000427336
	LOSS [training: 0.06359157051514791 | validation: 0.0929462826458589]
	TIME [epoch: 12.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05947140245092016		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.05947140245092016 | validation: 0.05886858901051617]
	TIME [epoch: 12.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05317664825249484		[learning rate: 0.00042432]
	Learning Rate: 0.000424319
	LOSS [training: 0.05317664825249484 | validation: 0.06691622890232038]
	TIME [epoch: 12.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059922105762129696		[learning rate: 0.00042282]
	Learning Rate: 0.000422818
	LOSS [training: 0.059922105762129696 | validation: 0.08292557917180389]
	TIME [epoch: 12.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05407916507679298		[learning rate: 0.00042132]
	Learning Rate: 0.000421323
	LOSS [training: 0.05407916507679298 | validation: 0.07384660046554951]
	TIME [epoch: 12.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05145904989633124		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.05145904989633124 | validation: 0.05852022261395369]
	TIME [epoch: 12.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05490835222041203		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.05490835222041203 | validation: 0.06326496510001527]
	TIME [epoch: 12.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05199214021876752		[learning rate: 0.00041687]
	Learning Rate: 0.000416869
	LOSS [training: 0.05199214021876752 | validation: 0.09151182858234341]
	TIME [epoch: 12.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05582878060100064		[learning rate: 0.0004154]
	Learning Rate: 0.000415395
	LOSS [training: 0.05582878060100064 | validation: 0.05405037580532173]
	TIME [epoch: 12.8 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0535841645973625		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.0535841645973625 | validation: 0.050044724583625556]
	TIME [epoch: 12.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05277558001993304		[learning rate: 0.00041246]
	Learning Rate: 0.000412463
	LOSS [training: 0.05277558001993304 | validation: 0.09721350318276382]
	TIME [epoch: 12.8 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05506556276745332		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.05506556276745332 | validation: 0.06213812300858053]
	TIME [epoch: 12.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05514387944840531		[learning rate: 0.00040955]
	Learning Rate: 0.000409551
	LOSS [training: 0.05514387944840531 | validation: 0.06292023859582883]
	TIME [epoch: 12.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05126673498723592		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.05126673498723592 | validation: 0.07291138056023899]
	TIME [epoch: 12.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05562448104379589		[learning rate: 0.00040666]
	Learning Rate: 0.000406659
	LOSS [training: 0.05562448104379589 | validation: 0.061392711388870924]
	TIME [epoch: 12.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0520336502936574		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.0520336502936574 | validation: 0.056099379044183245]
	TIME [epoch: 12.8 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05040061909225584		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.05040061909225584 | validation: 0.07375605681971885]
	TIME [epoch: 12.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05649143732709695		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.05649143732709695 | validation: 0.15255811428336086]
	TIME [epoch: 12.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10078898801027522		[learning rate: 0.00040094]
	Learning Rate: 0.000400938
	LOSS [training: 0.10078898801027522 | validation: 0.06291374484169962]
	TIME [epoch: 12.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05617879557998734		[learning rate: 0.00039952]
	Learning Rate: 0.00039952
	LOSS [training: 0.05617879557998734 | validation: 0.061315981375876044]
	TIME [epoch: 12.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0646137385252658		[learning rate: 0.00039811]
	Learning Rate: 0.000398107
	LOSS [training: 0.0646137385252658 | validation: 0.07187207512928855]
	TIME [epoch: 12.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05554808028210312		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.05554808028210312 | validation: 0.0830161451827805]
	TIME [epoch: 12.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05517308472230302		[learning rate: 0.0003953]
	Learning Rate: 0.000395297
	LOSS [training: 0.05517308472230302 | validation: 0.06923966969687158]
	TIME [epoch: 12.8 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05273836625836743		[learning rate: 0.0003939]
	Learning Rate: 0.000393899
	LOSS [training: 0.05273836625836743 | validation: 0.05761079756709642]
	TIME [epoch: 12.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055700028390582704		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.055700028390582704 | validation: 0.06793801969494725]
	TIME [epoch: 12.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05138292179619142		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.05138292179619142 | validation: 0.08042161245882183]
	TIME [epoch: 12.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051360760573536626		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.051360760573536626 | validation: 0.06277098677657766]
	TIME [epoch: 12.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05050678541292466		[learning rate: 0.00038836]
	Learning Rate: 0.000388357
	LOSS [training: 0.05050678541292466 | validation: 0.061448464298555175]
	TIME [epoch: 12.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05301458712260232		[learning rate: 0.00038698]
	Learning Rate: 0.000386983
	LOSS [training: 0.05301458712260232 | validation: 0.07795150694990644]
	TIME [epoch: 12.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05090908668171412		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.05090908668171412 | validation: 0.05508612846248842]
	TIME [epoch: 12.8 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05624792581912562		[learning rate: 0.00038425]
	Learning Rate: 0.000384251
	LOSS [training: 0.05624792581912562 | validation: 0.06780432845300226]
	TIME [epoch: 12.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05121037200622327		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.05121037200622327 | validation: 0.06559463257046128]
	TIME [epoch: 12.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05464132422009968		[learning rate: 0.00038154]
	Learning Rate: 0.000381539
	LOSS [training: 0.05464132422009968 | validation: 0.0746476500412647]
	TIME [epoch: 12.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0528061519431435		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.0528061519431435 | validation: 0.054619984075335]
	TIME [epoch: 12.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05300563549709164		[learning rate: 0.00037885]
	Learning Rate: 0.000378845
	LOSS [training: 0.05300563549709164 | validation: 0.06244788960945208]
	TIME [epoch: 12.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05518815920295035		[learning rate: 0.00037751]
	Learning Rate: 0.000377505
	LOSS [training: 0.05518815920295035 | validation: 0.08334889651807871]
	TIME [epoch: 12.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055275509080982825		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.055275509080982825 | validation: 0.07589573933700376]
	TIME [epoch: 12.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05255068429568827		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.05255068429568827 | validation: 0.05322589311923313]
	TIME [epoch: 12.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05357558946708764		[learning rate: 0.00037351]
	Learning Rate: 0.000373515
	LOSS [training: 0.05357558946708764 | validation: 0.07097095907028023]
	TIME [epoch: 12.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053490470112753784		[learning rate: 0.00037219]
	Learning Rate: 0.000372194
	LOSS [training: 0.053490470112753784 | validation: 0.06269286051529475]
	TIME [epoch: 12.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05283026950766525		[learning rate: 0.00037088]
	Learning Rate: 0.000370878
	LOSS [training: 0.05283026950766525 | validation: 0.05651201421319605]
	TIME [epoch: 12.8 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05333659927154557		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.05333659927154557 | validation: 0.07180605609481004]
	TIME [epoch: 12.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05296389022332975		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.05296389022332975 | validation: 0.06447025260982885]
	TIME [epoch: 12.8 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05179812499252915		[learning rate: 0.00036696]
	Learning Rate: 0.000366957
	LOSS [training: 0.05179812499252915 | validation: 0.05881377946477598]
	TIME [epoch: 12.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05166873467644977		[learning rate: 0.00036566]
	Learning Rate: 0.00036566
	LOSS [training: 0.05166873467644977 | validation: 0.06133815585113555]
	TIME [epoch: 12.8 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049684682239626174		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.049684682239626174 | validation: 0.06592636508144184]
	TIME [epoch: 12.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052790139240353015		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.052790139240353015 | validation: 0.06267596813196825]
	TIME [epoch: 12.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05207276982260238		[learning rate: 0.00036179]
	Learning Rate: 0.000361794
	LOSS [training: 0.05207276982260238 | validation: 0.06112820674464046]
	TIME [epoch: 12.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057030881584772215		[learning rate: 0.00036051]
	Learning Rate: 0.000360515
	LOSS [training: 0.057030881584772215 | validation: 0.07962956914860171]
	TIME [epoch: 12.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05257720138570116		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.05257720138570116 | validation: 0.07447872847337783]
	TIME [epoch: 12.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04908245211692721		[learning rate: 0.00035797]
	Learning Rate: 0.00035797
	LOSS [training: 0.04908245211692721 | validation: 0.05919615926201099]
	TIME [epoch: 12.8 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05093254205948698		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.05093254205948698 | validation: 0.05551346165438248]
	TIME [epoch: 12.8 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05426752644573422		[learning rate: 0.00035544]
	Learning Rate: 0.000355442
	LOSS [training: 0.05426752644573422 | validation: 0.07421363458285754]
	TIME [epoch: 12.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05410530766114154		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.05410530766114154 | validation: 0.06505931827340226]
	TIME [epoch: 12.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05394201714080758		[learning rate: 0.00035293]
	Learning Rate: 0.000352933
	LOSS [training: 0.05394201714080758 | validation: 0.0758119617556347]
	TIME [epoch: 12.8 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05451510683926854		[learning rate: 0.00035169]
	Learning Rate: 0.000351685
	LOSS [training: 0.05451510683926854 | validation: 0.1006885130491868]
	TIME [epoch: 12.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05338499292003432		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.05338499292003432 | validation: 0.05365629733933697]
	TIME [epoch: 12.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05254432822373829		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.05254432822373829 | validation: 0.0625194221838265]
	TIME [epoch: 12.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05140188488938386		[learning rate: 0.00034797]
	Learning Rate: 0.000347967
	LOSS [training: 0.05140188488938386 | validation: 0.06315483347794852]
	TIME [epoch: 12.8 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05239583655592504		[learning rate: 0.00034674]
	Learning Rate: 0.000346737
	LOSS [training: 0.05239583655592504 | validation: 0.07713561764320845]
	TIME [epoch: 12.8 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0542646622383223		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.0542646622383223 | validation: 0.09563129492345485]
	TIME [epoch: 201 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053845471227435715		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.053845471227435715 | validation: 0.05696571837189619]
	TIME [epoch: 26.4 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050582212426111196		[learning rate: 0.00034307]
	Learning Rate: 0.000343072
	LOSS [training: 0.050582212426111196 | validation: 0.06496488667483512]
	TIME [epoch: 26.4 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049025921641629465		[learning rate: 0.00034186]
	Learning Rate: 0.000341858
	LOSS [training: 0.049025921641629465 | validation: 0.06396625390304159]
	TIME [epoch: 26.4 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051357121710032025		[learning rate: 0.00034065]
	Learning Rate: 0.000340649
	LOSS [training: 0.051357121710032025 | validation: 0.055713260360312725]
	TIME [epoch: 26.4 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050805408362518685		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.050805408362518685 | validation: 0.06408908792587374]
	TIME [epoch: 26.4 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04981136911767388		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.04981136911767388 | validation: 0.09671606316474853]
	TIME [epoch: 26.4 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052529617102040536		[learning rate: 0.00033705]
	Learning Rate: 0.000337048
	LOSS [training: 0.052529617102040536 | validation: 0.06612562176813926]
	TIME [epoch: 26.4 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04918062524128418		[learning rate: 0.00033586]
	Learning Rate: 0.000335857
	LOSS [training: 0.04918062524128418 | validation: 0.048741863393552576]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_4c_v_mmd1_20241105_161814/states/model_phi1_4c_v_mmd1_1009.pth
	Model improved!!!
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 9901.774 seconds.
