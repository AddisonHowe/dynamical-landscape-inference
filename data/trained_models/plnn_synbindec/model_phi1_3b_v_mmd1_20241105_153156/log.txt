Args:
Namespace(name='model_phi1_3b_v_mmd1', outdir='out/model_training/model_phi1_3b_v_mmd1', training_data='data/training_data/data_phi1_3b/training', validation_data='data/training_data/data_phi1_3b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 366992405

Training model...

Saving initial model state to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.581561205597925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.581561205597925 | validation: 6.574021584768314]
	TIME [epoch: 264 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.483578334383521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.483578334383521 | validation: 6.656368295834351]
	TIME [epoch: 1.42 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.420220787365215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.420220787365215 | validation: 6.414022707546846]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.961575016504252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.961575016504252 | validation: 5.941640164970346]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.13260680092782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.13260680092782 | validation: 6.532101815534762]
	TIME [epoch: 1.41 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.027111093254786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.027111093254786 | validation: 5.4454182179732555]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.68982033783346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.68982033783346 | validation: 6.126072076893559]
	TIME [epoch: 1.41 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.427748830640021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.427748830640021 | validation: 5.767116417448555]
	TIME [epoch: 1.41 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.9675872375457075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9675872375457075 | validation: 5.547651434291973]
	TIME [epoch: 1.41 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.814301951317178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.814301951317178 | validation: 5.303213213728626]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.449153804128764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.449153804128764 | validation: 5.556070476569386]
	TIME [epoch: 1.4 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.5954207582798094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5954207582798094 | validation: 5.283256761651491]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.447485314298659		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.447485314298659 | validation: 5.235570607209195]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.324245158075667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.324245158075667 | validation: 5.306281551899322]
	TIME [epoch: 1.42 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.311277185937346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.311277185937346 | validation: 5.163701645420367]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.251000525096073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.251000525096073 | validation: 5.159468463685349]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.191706719077591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.191706719077591 | validation: 5.15404710077317]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.16249123356964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.16249123356964 | validation: 5.099999212891745]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.129414914686611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.129414914686611 | validation: 5.115774958001264]
	TIME [epoch: 1.41 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.098115079277165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.098115079277165 | validation: 5.079777001219842]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.094055499385643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.094055499385643 | validation: 5.222756989410237]
	TIME [epoch: 1.41 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.193763960550639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193763960550639 | validation: 5.245077284255362]
	TIME [epoch: 1.41 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.26965638789129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.26965638789129 | validation: 5.138830497352765]
	TIME [epoch: 1.41 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.085747948757148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.085747948757148 | validation: 5.015692550408156]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.990850296406671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.990850296406671 | validation: 5.012460354824357]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9789580986895285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9789580986895285 | validation: 5.024426765285522]
	TIME [epoch: 1.41 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.977892529275597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.977892529275597 | validation: 4.9998157298939425]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.951942082663815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.951942082663815 | validation: 4.997024534881089]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9415372637501425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9415372637501425 | validation: 5.025508765799079]
	TIME [epoch: 1.41 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9435028022121754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9435028022121754 | validation: 5.079321825426685]
	TIME [epoch: 1.41 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.035432315550768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.035432315550768 | validation: 5.072825142119455]
	TIME [epoch: 1.41 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.981843975605424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.981843975605424 | validation: 5.04710013181558]
	TIME [epoch: 1.41 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.99331850379415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.99331850379415 | validation: 4.989096798757657]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9096474532285477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9096474532285477 | validation: 4.9235516608855185]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.834444549425605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.834444549425605 | validation: 4.905893672320182]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8110347253352206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8110347253352206 | validation: 4.913206544631411]
	TIME [epoch: 1.41 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8070840952941234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8070840952941234 | validation: 4.9001570607660945]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8092227320385392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8092227320385392 | validation: 4.928747250857118]
	TIME [epoch: 1.4 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8153806200967275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8153806200967275 | validation: 4.939974325970718]
	TIME [epoch: 1.4 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8599725652193917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8599725652193917 | validation: 4.935265371041948]
	TIME [epoch: 1.41 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8184944778905647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8184944778905647 | validation: 4.892376601943262]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7937236818730717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7937236818730717 | validation: 4.867856814868809]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7434722377173433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7434722377173433 | validation: 4.838066652163829]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7210991470249297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7210991470249297 | validation: 4.832692376202333]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7046144718516025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7046144718516025 | validation: 4.81681366407051]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6909509138655925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6909509138655925 | validation: 4.809310871903036]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.682652043081159		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.682652043081159 | validation: 4.798713726195717]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6836360465178934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6836360465178934 | validation: 4.813050608774566]
	TIME [epoch: 1.41 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.690818055132066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.690818055132066 | validation: 4.781432778679562]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.658095627344049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.658095627344049 | validation: 4.773101610204208]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.643087914257124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.643087914257124 | validation: 4.768694171741633]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6662207215164906		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 3.6662207215164906 | validation: 4.847349018745293]
	TIME [epoch: 1.41 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.724897496241256		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 3.724897496241256 | validation: 4.8048067337617475]
	TIME [epoch: 1.41 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7474440739378454		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 3.7474440739378454 | validation: 4.711583355542206]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5795822996734263		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 3.5795822996734263 | validation: 4.731426664813331]
	TIME [epoch: 1.42 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.603592106937877		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 3.603592106937877 | validation: 4.706571138651586]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6087106412115038		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 3.6087106412115038 | validation: 4.679961400294136]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5520954270370244		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 3.5520954270370244 | validation: 4.66953420670949]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.540483208865695		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 3.540483208865695 | validation: 4.641637868456423]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.532238532462734		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 3.532238532462734 | validation: 4.642688088605328]
	TIME [epoch: 1.41 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5190538544820975		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 3.5190538544820975 | validation: 4.624103683990561]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5073416314095267		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 3.5073416314095267 | validation: 4.612683042455276]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.495826896468053		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 3.495826896468053 | validation: 4.593032338613316]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4879326590126425		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 3.4879326590126425 | validation: 4.588730616595598]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4774815335731124		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 3.4774815335731124 | validation: 4.571853142534322]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4686025967758276		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 3.4686025967758276 | validation: 4.563054590444999]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4626912098160676		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 3.4626912098160676 | validation: 4.533536580902262]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.449245953794393		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 3.449245953794393 | validation: 4.539513754975175]
	TIME [epoch: 1.41 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.442723021710794		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 3.442723021710794 | validation: 4.510566637675545]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4306498348303194		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 3.4306498348303194 | validation: 4.5101450967322085]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4214878655242096		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 3.4214878655242096 | validation: 4.471186583256872]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4046274990023164		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 3.4046274990023164 | validation: 4.469884737922733]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3898932881861925		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 3.3898932881861925 | validation: 4.441602775016811]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3739957425419678		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 3.3739957425419678 | validation: 4.428169300577163]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3620997757825637		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 3.3620997757825637 | validation: 4.408651480400501]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3450526870015027		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 3.3450526870015027 | validation: 4.385144247975224]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3365716608664044		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 3.3365716608664044 | validation: 4.364286818794407]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3217655692991084		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 3.3217655692991084 | validation: 4.341488706487626]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3036636530346404		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 3.3036636530346404 | validation: 4.300974273118579]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2875217563226364		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 3.2875217563226364 | validation: 4.2746624481930935]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.266527677656125		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 3.266527677656125 | validation: 4.230911121983292]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2452157138857576		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 3.2452157138857576 | validation: 4.184320617852069]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2109805059700944		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 3.2109805059700944 | validation: 4.058672638663715]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1629510027951895		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 3.1629510027951895 | validation: 3.729851995219167]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.962046613075237		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 2.962046613075237 | validation: 3.863094786172881]
	TIME [epoch: 1.41 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3834446861545677		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 3.3834446861545677 | validation: 3.3319182583347726]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.5935966467382476		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 2.5935966467382476 | validation: 4.33149467438082]
	TIME [epoch: 1.41 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.562567820387394		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 3.562567820387394 | validation: 3.5013869036844625]
	TIME [epoch: 1.4 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.8341275169918343		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 2.8341275169918343 | validation: 2.9642423596683902]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.380191164584693		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 2.380191164584693 | validation: 2.866585751839635]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.3721522466489917		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 2.3721522466489917 | validation: 2.6197821782767523]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.1921282851676485		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 2.1921282851676485 | validation: 2.390413333925428]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.01016431376652		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 2.01016431376652 | validation: 2.210020679951704]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.9201473609784165		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 1.9201473609784165 | validation: 2.06505959224611]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.805653434661963		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 1.805653434661963 | validation: 1.9207526080008828]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.6663628293498471		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 1.6663628293498471 | validation: 1.71623514273035]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.4895207554941339		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 1.4895207554941339 | validation: 1.4905288219273403]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2468909894324158		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 1.2468909894324158 | validation: 1.1520393584801825]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0458870831357765		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 1.0458870831357765 | validation: 1.8831714546809346]
	TIME [epoch: 1.41 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.5277338057902126		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 1.5277338057902126 | validation: 1.3562520304448917]
	TIME [epoch: 1.41 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.467851480288586		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 1.467851480288586 | validation: 1.1194922080979717]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0057529019075566		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 1.0057529019075566 | validation: 1.290391145976736]
	TIME [epoch: 1.41 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0542282791419202		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 1.0542282791419202 | validation: 1.029029194703529]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9573494912489051		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 0.9573494912489051 | validation: 1.0304599970978032]
	TIME [epoch: 1.41 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8807947758116186		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 0.8807947758116186 | validation: 1.0381801757494424]
	TIME [epoch: 1.41 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8812560105748645		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.8812560105748645 | validation: 0.9515537391506943]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8517998397793354		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.8517998397793354 | validation: 0.9416390951921709]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8348507771972482		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 0.8348507771972482 | validation: 0.9442355166130952]
	TIME [epoch: 1.42 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8286514975853482		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 0.8286514975853482 | validation: 0.9256065720167155]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8101204407874819		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.8101204407874819 | validation: 0.882702133991394]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8071853729416912		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 0.8071853729416912 | validation: 0.9094009488398161]
	TIME [epoch: 1.41 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7982964355687304		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.7982964355687304 | validation: 0.8385525577214393]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_112.pth
	Model improved!!!
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8040921619347904		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 0.8040921619347904 | validation: 0.9650557770190498]
	TIME [epoch: 1.41 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8257766461868025		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.8257766461868025 | validation: 0.895915214587895]
	TIME [epoch: 1.41 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8770486003934758		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 0.8770486003934758 | validation: 1.1717780381285465]
	TIME [epoch: 1.41 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9586259729241559		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 0.9586259729241559 | validation: 0.8763747527190555]
	TIME [epoch: 1.41 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8193472566929814		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.8193472566929814 | validation: 0.8320046177204001]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7794330569124508		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.7794330569124508 | validation: 0.8946905155491077]
	TIME [epoch: 1.41 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7896727213331829		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.7896727213331829 | validation: 0.8388977762737039]
	TIME [epoch: 1.41 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8044202155426737		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 0.8044202155426737 | validation: 0.8535689966363194]
	TIME [epoch: 1.41 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7738965875156456		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 0.7738965875156456 | validation: 0.787341251489526]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7679859762523598		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.7679859762523598 | validation: 0.8298564239897536]
	TIME [epoch: 1.41 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7526083435334644		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 0.7526083435334644 | validation: 0.8012504350146019]
	TIME [epoch: 1.41 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7457002733823201		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 0.7457002733823201 | validation: 0.8026903371299987]
	TIME [epoch: 1.41 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7404124648760049		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 0.7404124648760049 | validation: 0.7915751920889958]
	TIME [epoch: 1.41 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7330519683005122		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.7330519683005122 | validation: 0.776372375050835]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7343631580904006		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.7343631580904006 | validation: 0.7722936025511826]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7363853409263373		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 0.7363853409263373 | validation: 0.7722173092886011]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7280770594752878		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 0.7280770594752878 | validation: 0.8182366668783395]
	TIME [epoch: 1.4 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7428193058085205		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.7428193058085205 | validation: 0.9002495441610057]
	TIME [epoch: 1.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8916701169490076		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 0.8916701169490076 | validation: 1.3563602750548764]
	TIME [epoch: 1.41 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0680456574980368		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 1.0680456574980368 | validation: 1.0367874747525574]
	TIME [epoch: 1.41 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9648071157147479		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 0.9648071157147479 | validation: 0.830219372666242]
	TIME [epoch: 1.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8273234572605134		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.8273234572605134 | validation: 0.9055218652084387]
	TIME [epoch: 1.41 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8268263613587634		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 0.8268263613587634 | validation: 0.7889669895074523]
	TIME [epoch: 1.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7460543619840143		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 0.7460543619840143 | validation: 0.7536018836730524]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7342475917778493		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.7342475917778493 | validation: 0.7857746381933026]
	TIME [epoch: 1.41 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7265542759696123		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.7265542759696123 | validation: 0.7534874521285116]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7173914714005887		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 0.7173914714005887 | validation: 0.754714381427982]
	TIME [epoch: 1.41 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7127844933417107		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 0.7127844933417107 | validation: 0.7450514236930665]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.717842994988281		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.717842994988281 | validation: 0.7408746014211836]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7101916939919707		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.7101916939919707 | validation: 0.7365130886417378]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7001708839374259		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 0.7001708839374259 | validation: 0.7262411876203979]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7134360627400852		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 0.7134360627400852 | validation: 0.865741526997846]
	TIME [epoch: 1.41 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.762782040486101		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 0.762782040486101 | validation: 0.7840237596919488]
	TIME [epoch: 1.42 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8002213514711026		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.8002213514711026 | validation: 0.9810754874578216]
	TIME [epoch: 1.41 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8485600444631459		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.8485600444631459 | validation: 0.7921867622984755]
	TIME [epoch: 1.41 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7525183227658631		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.7525183227658631 | validation: 0.7724155839742353]
	TIME [epoch: 1.41 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7453278479520611		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.7453278479520611 | validation: 0.8304323162135305]
	TIME [epoch: 1.41 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7357327838721415		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.7357327838721415 | validation: 0.7276009591247438]
	TIME [epoch: 1.41 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7024852735984995		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 0.7024852735984995 | validation: 0.722205382146206]
	TIME [epoch: 1.42 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6934210230147306		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 0.6934210230147306 | validation: 0.7439442434779044]
	TIME [epoch: 1.41 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6989218691594372		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.6989218691594372 | validation: 0.7191354482056419]
	TIME [epoch: 1.42 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6924181185557587		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.6924181185557587 | validation: 0.7465194978229924]
	TIME [epoch: 1.41 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6992494764112533		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.6992494764112533 | validation: 0.7294787742410231]
	TIME [epoch: 1.41 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7048532316090311		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 0.7048532316090311 | validation: 0.7525857201083129]
	TIME [epoch: 1.41 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.707623224196515		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.707623224196515 | validation: 0.7016942763483353]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7120874675670235		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.7120874675670235 | validation: 0.8567027420087453]
	TIME [epoch: 1.41 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7474969849359638		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.7474969849359638 | validation: 0.7623695399784657]
	TIME [epoch: 1.41 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7596500448790388		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.7596500448790388 | validation: 0.936921586164417]
	TIME [epoch: 1.42 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8168336899025619		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.8168336899025619 | validation: 0.7742963785590935]
	TIME [epoch: 1.41 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7747144677342414		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 0.7747144677342414 | validation: 0.7096041779546778]
	TIME [epoch: 1.41 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6887096226122722		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.6887096226122722 | validation: 0.7479672975566094]
	TIME [epoch: 1.41 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6916899101650518		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.6916899101650518 | validation: 0.7239047585065178]
	TIME [epoch: 1.41 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7078351650977738		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.7078351650977738 | validation: 0.7351073311649321]
	TIME [epoch: 1.41 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6830865162899376		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.6830865162899376 | validation: 0.6893198436746273]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_166.pth
	Model improved!!!
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6587717091993117		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.6587717091993117 | validation: 0.7142053484252059]
	TIME [epoch: 1.41 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6778970143656144		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 0.6778970143656144 | validation: 0.7002081318098158]
	TIME [epoch: 1.41 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6980189485375874		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.6980189485375874 | validation: 0.7915842460207551]
	TIME [epoch: 1.41 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7228179621711479		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.7228179621711479 | validation: 0.7508420019560393]
	TIME [epoch: 1.41 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7434821605684385		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.7434821605684385 | validation: 0.863356154895925]
	TIME [epoch: 1.41 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7545500259665243		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.7545500259665243 | validation: 0.6954772050266194]
	TIME [epoch: 1.41 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6826113165913552		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.6826113165913552 | validation: 0.6837775396910619]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6491964109921976		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.6491964109921976 | validation: 0.7038664357250974]
	TIME [epoch: 1.41 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6550444131864396		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.6550444131864396 | validation: 0.6663074936266389]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6493331810687086		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.6493331810687086 | validation: 0.7234645042287657]
	TIME [epoch: 1.41 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6623577904300625		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.6623577904300625 | validation: 0.6848422193360454]
	TIME [epoch: 1.41 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7017412569945148		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.7017412569945148 | validation: 0.923932755945879]
	TIME [epoch: 1.41 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7861326592315936		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 0.7861326592315936 | validation: 0.6824654390463337]
	TIME [epoch: 1.41 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6806721326440943		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.6806721326440943 | validation: 0.677820302912009]
	TIME [epoch: 1.41 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6538175693354057		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.6538175693354057 | validation: 0.6959708177862622]
	TIME [epoch: 1.41 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6598219735333308		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.6598219735333308 | validation: 0.6619323394227963]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6732813346082795		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 0.6732813346082795 | validation: 0.7546825605464729]
	TIME [epoch: 1.41 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6864646327124987		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.6864646327124987 | validation: 0.6692471264103723]
	TIME [epoch: 1.41 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6709375350998803		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.6709375350998803 | validation: 0.7657021878971162]
	TIME [epoch: 1.42 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6875215030972689		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.6875215030972689 | validation: 0.6585827257322847]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6730347456053477		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.6730347456053477 | validation: 0.6841183406125463]
	TIME [epoch: 1.41 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6489885718020934		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 0.6489885718020934 | validation: 0.6240670607347164]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6193350528308671		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.6193350528308671 | validation: 0.6530322029516265]
	TIME [epoch: 1.41 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6218602867345002		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.6218602867345002 | validation: 0.6358104402209759]
	TIME [epoch: 1.41 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.651905925712475		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.651905925712475 | validation: 0.9837856332890651]
	TIME [epoch: 1.41 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8164143371819952		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.8164143371819952 | validation: 0.712478473546049]
	TIME [epoch: 1.41 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7410893089894262		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.7410893089894262 | validation: 0.6237311343322346]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6338090248702484		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.6338090248702484 | validation: 0.6868689116039615]
	TIME [epoch: 1.41 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6465199482065004		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 0.6465199482065004 | validation: 0.6093534758256279]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6261296989454014		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.6261296989454014 | validation: 0.6222463328488327]
	TIME [epoch: 1.41 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6038122266775436		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.6038122266775436 | validation: 0.6087634030863056]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6075180266237495		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.6075180266237495 | validation: 0.6063398129152673]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_198.pth
	Model improved!!!
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6000905450660597		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.6000905450660597 | validation: 0.6451597363946358]
	TIME [epoch: 1.41 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6062784912100897		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.6062784912100897 | validation: 0.6426848932898717]
	TIME [epoch: 1.41 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.615861238841036		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 0.615861238841036 | validation: 0.6239977412381498]
	TIME [epoch: 274 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6172575076631104		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.6172575076631104 | validation: 0.6468504326935621]
	TIME [epoch: 2.81 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6040796309905495		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.6040796309905495 | validation: 0.6461535540940722]
	TIME [epoch: 2.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6600493718649426		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.6600493718649426 | validation: 1.2042376381294826]
	TIME [epoch: 2.81 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9605066536595877		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.9605066536595877 | validation: 0.5989283563380238]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6162393603933264		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.6162393603933264 | validation: 0.6176317358221554]
	TIME [epoch: 2.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6654691355265352		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.6654691355265352 | validation: 0.7180273510862758]
	TIME [epoch: 2.81 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6603401884820786		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.6603401884820786 | validation: 0.5752265134472178]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5955863183881374		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.5955863183881374 | validation: 0.5901089352992]
	TIME [epoch: 2.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5955155645791697		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.5955155645791697 | validation: 0.6283266219266888]
	TIME [epoch: 2.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5967132282032271		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.5967132282032271 | validation: 0.5640698201595209]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.578888338005541		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.578888338005541 | validation: 0.6267299197714767]
	TIME [epoch: 2.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5782943011820152		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.5782943011820152 | validation: 0.5761139645915277]
	TIME [epoch: 2.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5959014198975614		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.5959014198975614 | validation: 0.7766729349917644]
	TIME [epoch: 2.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6521405930288542		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.6521405930288542 | validation: 0.6536638694217709]
	TIME [epoch: 2.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7126398402134123		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 0.7126398402134123 | validation: 0.620566270815976]
	TIME [epoch: 2.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5949697344353296		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.5949697344353296 | validation: 0.5736218715385326]
	TIME [epoch: 2.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5639422085297932		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.5639422085297932 | validation: 0.5672881561388489]
	TIME [epoch: 2.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5753307949561648		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.5753307949561648 | validation: 0.6021991863672393]
	TIME [epoch: 2.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5683639442128758		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.5683639442128758 | validation: 0.5616797169313215]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5716927839593844		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.5716927839593844 | validation: 0.6033937457996388]
	TIME [epoch: 2.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5546220608003776		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.5546220608003776 | validation: 0.5538517678976236]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_222.pth
	Model improved!!!
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5756279634876862		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 0.5756279634876862 | validation: 0.757097838993202]
	TIME [epoch: 2.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6366863118166086		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.6366863118166086 | validation: 0.6163241249058946]
	TIME [epoch: 2.79 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6527780483180744		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.6527780483180744 | validation: 0.5962635296407994]
	TIME [epoch: 2.79 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5590037920536503		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.5590037920536503 | validation: 0.5394586210418717]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5316626263339964		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.5316626263339964 | validation: 0.5163571717482048]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5291514216383045		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.5291514216383045 | validation: 0.6005657778578926]
	TIME [epoch: 2.81 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5394875980455011		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.5394875980455011 | validation: 0.5205982728937276]
	TIME [epoch: 2.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5751530961168646		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.5751530961168646 | validation: 0.6583520636903071]
	TIME [epoch: 2.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5622627644966686		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.5622627644966686 | validation: 0.4930102470804684]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_231.pth
	Model improved!!!
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5473348171210709		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.5473348171210709 | validation: 0.5411824166264342]
	TIME [epoch: 2.79 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5200405666731446		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 0.5200405666731446 | validation: 0.4884145256139409]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.505216322420512		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.505216322420512 | validation: 0.5153308536516537]
	TIME [epoch: 2.79 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49759072685662586		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.49759072685662586 | validation: 0.48878253896900836]
	TIME [epoch: 2.79 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4872972890165343		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.4872972890165343 | validation: 0.5301461532984894]
	TIME [epoch: 2.79 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4991383896392819		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.4991383896392819 | validation: 0.467145125687102]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5125757452055955		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.5125757452055955 | validation: 0.5525979718360805]
	TIME [epoch: 2.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5040653246497465		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.5040653246497465 | validation: 0.5126485223755136]
	TIME [epoch: 2.81 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5268870679225273		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.5268870679225273 | validation: 0.6567387307386879]
	TIME [epoch: 2.81 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5443693768322819		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.5443693768322819 | validation: 0.49188366501106195]
	TIME [epoch: 2.79 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5420482332922153		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.5420482332922153 | validation: 0.4492836791678217]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45376073660534105		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 0.45376073660534105 | validation: 0.5346318167639968]
	TIME [epoch: 2.79 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47746677393120673		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.47746677393120673 | validation: 0.44479599897037725]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.500750010566236		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.500750010566236 | validation: 0.4352193089786911]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43480724322696673		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.43480724322696673 | validation: 0.4675273114082634]
	TIME [epoch: 2.79 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42856359270960076		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.42856359270960076 | validation: 0.39610591050866484]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43748815396629104		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.43748815396629104 | validation: 0.4745393103929007]
	TIME [epoch: 2.79 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4302772333416887		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.4302772333416887 | validation: 0.40277095852668127]
	TIME [epoch: 2.79 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41327826418582175		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.41327826418582175 | validation: 0.457073836980042]
	TIME [epoch: 2.79 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39969753266866725		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.39969753266866725 | validation: 0.4019574554840176]
	TIME [epoch: 2.79 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42839935106591837		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.42839935106591837 | validation: 0.4146529435325542]
	TIME [epoch: 2.79 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38184689091624224		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.38184689091624224 | validation: 0.4023367469334453]
	TIME [epoch: 2.79 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36660266808086156		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.36660266808086156 | validation: 0.41113139013118993]
	TIME [epoch: 2.79 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3920372926288668		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.3920372926288668 | validation: 0.44568918563497706]
	TIME [epoch: 2.79 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43852838892300433		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.43852838892300433 | validation: 0.39134157829735483]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_256.pth
	Model improved!!!
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36851249604801894		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.36851249604801894 | validation: 0.5019625228056814]
	TIME [epoch: 2.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3775507605969232		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.3775507605969232 | validation: 0.49069357949297443]
	TIME [epoch: 2.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5008431885645602		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.5008431885645602 | validation: 0.36896064638954007]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33855836270488643		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.33855836270488643 | validation: 0.4718601023071167]
	TIME [epoch: 2.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37425629442577857		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.37425629442577857 | validation: 0.3657605022053754]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35535287803699533		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.35535287803699533 | validation: 0.38380176358305307]
	TIME [epoch: 2.81 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3249369836612595		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.3249369836612595 | validation: 0.36750373675651304]
	TIME [epoch: 2.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3445516524520757		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.3445516524520757 | validation: 0.3987577348489981]
	TIME [epoch: 2.81 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3989296024078336		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.3989296024078336 | validation: 0.3876449312672628]
	TIME [epoch: 2.81 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34970387368286515		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.34970387368286515 | validation: 0.43364145081940225]
	TIME [epoch: 2.81 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32519108169013655		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.32519108169013655 | validation: 0.3594939786360537]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3315074577358608		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.3315074577358608 | validation: 0.3564923170331829]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.311657372595217		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.311657372595217 | validation: 0.43154554900650055]
	TIME [epoch: 2.79 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40555018545417676		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.40555018545417676 | validation: 0.3560909460097425]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34578032050106794		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.34578032050106794 | validation: 0.3452627403422889]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.278095116577872		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.278095116577872 | validation: 0.3616485945661241]
	TIME [epoch: 2.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30196236574017044		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.30196236574017044 | validation: 0.3757578771296525]
	TIME [epoch: 2.79 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3806729999613029		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.3806729999613029 | validation: 0.3233487852551849]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27429870249735283		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.27429870249735283 | validation: 0.35937706591706964]
	TIME [epoch: 2.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2943750744399604		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.2943750744399604 | validation: 0.34153482960574755]
	TIME [epoch: 2.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3125387516463558		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.3125387516463558 | validation: 0.35614419864904606]
	TIME [epoch: 2.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30664744863470217		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.30664744863470217 | validation: 0.4296390013793294]
	TIME [epoch: 2.79 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3098641906165068		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.3098641906165068 | validation: 0.34519885549652596]
	TIME [epoch: 2.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3235217191402141		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.3235217191402141 | validation: 0.3216247936986909]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2731427235196863		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.2731427235196863 | validation: 0.353270104321095]
	TIME [epoch: 2.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2558703566099699		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.2558703566099699 | validation: 0.31426015634767224]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2541457003332947		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.2541457003332947 | validation: 0.32756544502560353]
	TIME [epoch: 2.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27535517029079787		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.27535517029079787 | validation: 0.35101340964936567]
	TIME [epoch: 2.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3146183218967742		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.3146183218967742 | validation: 0.36387403188463197]
	TIME [epoch: 2.79 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3379483253700511		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.3379483253700511 | validation: 0.42430946553192384]
	TIME [epoch: 2.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2938776756167124		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.2938776756167124 | validation: 0.3229180006079049]
	TIME [epoch: 2.78 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23834899237402063		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.23834899237402063 | validation: 0.3186343809665537]
	TIME [epoch: 2.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24777499531370958		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 0.24777499531370958 | validation: 0.35626612786002226]
	TIME [epoch: 2.79 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2633248389413012		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.2633248389413012 | validation: 0.42079593476486177]
	TIME [epoch: 2.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43534617172858975		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.43534617172858975 | validation: 0.35928050064067246]
	TIME [epoch: 2.78 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2925037060800527		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.2925037060800527 | validation: 0.39198022104217867]
	TIME [epoch: 2.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30099368815189037		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.30099368815189037 | validation: 0.39408885887026157]
	TIME [epoch: 2.79 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35314903067745057		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.35314903067745057 | validation: 0.3155219718508991]
	TIME [epoch: 2.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2601048049385002		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.2601048049385002 | validation: 0.30815842852243586]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22401981254601183		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.22401981254601183 | validation: 0.3406735895991735]
	TIME [epoch: 2.79 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2507125279131322		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.2507125279131322 | validation: 0.33757552783136924]
	TIME [epoch: 2.79 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.290629072851742		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.290629072851742 | validation: 0.3200745379417362]
	TIME [epoch: 2.79 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2752169698249267		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.2752169698249267 | validation: 0.32607127114642853]
	TIME [epoch: 2.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22692449007543417		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.22692449007543417 | validation: 0.32837101793531676]
	TIME [epoch: 2.79 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2720086927709544		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.2720086927709544 | validation: 0.3371907420252682]
	TIME [epoch: 2.79 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3090766672367006		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.3090766672367006 | validation: 0.30187835393162293]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21665399790105483		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.21665399790105483 | validation: 0.29810254498500227]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21064261483632163		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.21064261483632163 | validation: 0.2983745738794152]
	TIME [epoch: 2.79 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22012176971606978		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.22012176971606978 | validation: 0.32907338175743445]
	TIME [epoch: 2.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2772293869560336		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.2772293869560336 | validation: 0.3359381425678669]
	TIME [epoch: 2.79 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2947307039360836		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.2947307039360836 | validation: 0.29666161416531894]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2476811511799894		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.2476811511799894 | validation: 0.2914657666851838]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_308.pth
	Model improved!!!
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.222819658131147		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.222819658131147 | validation: 0.31418789417610943]
	TIME [epoch: 2.79 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21277888647167584		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.21277888647167584 | validation: 0.29702604081492956]
	TIME [epoch: 2.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24351534121061513		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.24351534121061513 | validation: 0.3243026533841725]
	TIME [epoch: 2.79 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2945785345751175		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.2945785345751175 | validation: 0.33517711443452475]
	TIME [epoch: 2.79 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2309441451956883		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.2309441451956883 | validation: 0.30868549408035717]
	TIME [epoch: 2.79 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26698632444995624		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.26698632444995624 | validation: 0.3290465876356119]
	TIME [epoch: 2.79 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2588371408794155		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.2588371408794155 | validation: 0.28565613688121205]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_315.pth
	Model improved!!!
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1959122687823038		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.1959122687823038 | validation: 0.29491824618816037]
	TIME [epoch: 2.79 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2189156805151719		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.2189156805151719 | validation: 0.3262404548182265]
	TIME [epoch: 2.79 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29244976390167343		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.29244976390167343 | validation: 0.30427089875482005]
	TIME [epoch: 2.79 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26397406487008773		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.26397406487008773 | validation: 0.33116956627001215]
	TIME [epoch: 2.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22858460463388533		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.22858460463388533 | validation: 0.27980118310515606]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20715300721653415		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.20715300721653415 | validation: 0.2935019859723241]
	TIME [epoch: 2.78 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23514121885606606		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.23514121885606606 | validation: 0.28966483329435244]
	TIME [epoch: 2.79 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25139138371927156		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.25139138371927156 | validation: 0.34686041305817744]
	TIME [epoch: 2.79 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24368471158139207		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.24368471158139207 | validation: 0.298825304310465]
	TIME [epoch: 2.79 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2186077432124103		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.2186077432124103 | validation: 0.30359217280048867]
	TIME [epoch: 2.79 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25630332199582617		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.25630332199582617 | validation: 0.3013800815621714]
	TIME [epoch: 2.79 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2523483214547074		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.2523483214547074 | validation: 0.3207280612073379]
	TIME [epoch: 2.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21597202076221636		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.21597202076221636 | validation: 0.2991835634415847]
	TIME [epoch: 2.79 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22308281234956318		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.22308281234956318 | validation: 0.29903898967799875]
	TIME [epoch: 2.79 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25084257482041133		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.25084257482041133 | validation: 0.33794032435812693]
	TIME [epoch: 2.79 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35903571351530844		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.35903571351530844 | validation: 0.35663599392233253]
	TIME [epoch: 2.79 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24931078716673916		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.24931078716673916 | validation: 0.4500064574163427]
	TIME [epoch: 2.79 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3658976664462336		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.3658976664462336 | validation: 0.2910063307692918]
	TIME [epoch: 2.79 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1904822454435471		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.1904822454435471 | validation: 0.2869902235292164]
	TIME [epoch: 2.79 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23639507566487075		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23639507566487075 | validation: 0.27549593834381697]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20509221799994026		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.20509221799994026 | validation: 0.2648681260943886]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_336.pth
	Model improved!!!
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18419109366790337		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.18419109366790337 | validation: 0.26749605510825925]
	TIME [epoch: 2.79 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18578141739281406		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.18578141739281406 | validation: 0.28208380800050636]
	TIME [epoch: 2.79 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20499566279921846		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.20499566279921846 | validation: 0.2735564409837826]
	TIME [epoch: 2.79 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2053073542294689		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.2053073542294689 | validation: 0.28375448411041887]
	TIME [epoch: 2.79 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2380181387737833		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.2380181387737833 | validation: 0.2711860366400004]
	TIME [epoch: 2.78 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18365130765441015		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.18365130765441015 | validation: 0.2632125289826101]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17667465322586764		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.17667465322586764 | validation: 0.2573579631787458]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1801671536754683		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.1801671536754683 | validation: 0.2607083637944488]
	TIME [epoch: 2.79 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18853551705568236		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.18853551705568236 | validation: 0.3062279632115848]
	TIME [epoch: 2.79 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22678026979282173		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.22678026979282173 | validation: 0.28447150498863044]
	TIME [epoch: 2.78 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23439719974785825		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.23439719974785825 | validation: 0.26955109311157505]
	TIME [epoch: 2.79 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19640803356750994		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.19640803356750994 | validation: 0.2533846901003943]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_348.pth
	Model improved!!!
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1855550959767183		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.1855550959767183 | validation: 0.29247394115521524]
	TIME [epoch: 2.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20643631421431444		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.20643631421431444 | validation: 0.27315562442882824]
	TIME [epoch: 2.8 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22206265002159215		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.22206265002159215 | validation: 0.2749236097445843]
	TIME [epoch: 2.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19781833719232111		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.19781833719232111 | validation: 0.2545978414277862]
	TIME [epoch: 2.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20010623171260414		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.20010623171260414 | validation: 0.2988613213783294]
	TIME [epoch: 2.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22478747019406137		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.22478747019406137 | validation: 0.24950107648256958]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18852004088387467		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.18852004088387467 | validation: 0.3793789787266286]
	TIME [epoch: 2.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24138216825845		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.24138216825845 | validation: 0.2594969036673362]
	TIME [epoch: 2.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17391756527219873		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.17391756527219873 | validation: 0.266582617308591]
	TIME [epoch: 2.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20586377058929234		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.20586377058929234 | validation: 0.26472308713659437]
	TIME [epoch: 2.79 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19237874345667627		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.19237874345667627 | validation: 0.2820085019351679]
	TIME [epoch: 2.79 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20630665143874222		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.20630665143874222 | validation: 0.2610205976169977]
	TIME [epoch: 2.79 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19580294970887185		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.19580294970887185 | validation: 0.26633523270502346]
	TIME [epoch: 2.79 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23618755695401328		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.23618755695401328 | validation: 0.24970629223836116]
	TIME [epoch: 2.79 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1687267641616066		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.1687267641616066 | validation: 0.27345648920044735]
	TIME [epoch: 2.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2249836832842035		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.2249836832842035 | validation: 0.2556532581012152]
	TIME [epoch: 2.78 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19629352175182924		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.19629352175182924 | validation: 0.2735685745096957]
	TIME [epoch: 2.78 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2576276969698407		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.2576276969698407 | validation: 0.2267860359571833]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15741771170512542		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.15741771170512542 | validation: 0.23148822316975384]
	TIME [epoch: 2.79 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1620910027187925		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.1620910027187925 | validation: 0.23481980155780394]
	TIME [epoch: 2.79 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1682506458095358		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.1682506458095358 | validation: 0.25047981644225603]
	TIME [epoch: 2.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19872878447980888		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.19872878447980888 | validation: 0.24413413014226923]
	TIME [epoch: 2.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19554266312783367		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.19554266312783367 | validation: 0.23773870885677623]
	TIME [epoch: 3.41 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15845517813156346		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.15845517813156346 | validation: 0.2359796694852948]
	TIME [epoch: 2.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16117374457058922		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.16117374457058922 | validation: 0.23598196085112347]
	TIME [epoch: 2.79 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18271691234934828		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.18271691234934828 | validation: 0.23974676912599585]
	TIME [epoch: 2.78 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1873449897003428		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.1873449897003428 | validation: 0.2533906816994385]
	TIME [epoch: 2.79 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17307252965421743		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.17307252965421743 | validation: 0.24385603550131574]
	TIME [epoch: 2.78 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18056681247235673		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.18056681247235673 | validation: 0.24793970206096977]
	TIME [epoch: 2.78 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17894749214720002		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.17894749214720002 | validation: 0.23717256642716178]
	TIME [epoch: 2.78 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15522981538870467		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.15522981538870467 | validation: 0.29714820474634457]
	TIME [epoch: 2.79 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2212186784889267		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.2212186784889267 | validation: 0.23977589357132884]
	TIME [epoch: 2.78 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17481896031445154		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.17481896031445154 | validation: 0.23993317527894487]
	TIME [epoch: 2.79 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1823960450008103		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1823960450008103 | validation: 0.2826920539905841]
	TIME [epoch: 2.78 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17726005812039272		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.17726005812039272 | validation: 0.22736670367655423]
	TIME [epoch: 2.78 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1610829069664495		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.1610829069664495 | validation: 0.25283814154500683]
	TIME [epoch: 2.78 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21259846725015144		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.21259846725015144 | validation: 0.23845723636191685]
	TIME [epoch: 2.78 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1845359095668497		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.1845359095668497 | validation: 0.2281091769468665]
	TIME [epoch: 2.78 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1449344238198408		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.1449344238198408 | validation: 0.6393789144236095]
	TIME [epoch: 2.78 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43865691236394244		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.43865691236394244 | validation: 0.38093014450028373]
	TIME [epoch: 2.78 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2576668344464975		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.2576668344464975 | validation: 0.2483266010809521]
	TIME [epoch: 2.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18853574972362075		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.18853574972362075 | validation: 0.24559663275318797]
	TIME [epoch: 2.78 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1746414839498781		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.1746414839498781 | validation: 0.3382635367956679]
	TIME [epoch: 2.78 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2568567449678138		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.2568567449678138 | validation: 0.2534713733458202]
	TIME [epoch: 2.78 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18185146422911175		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.18185146422911175 | validation: 0.22411979414128194]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14282397372195552		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.14282397372195552 | validation: 0.22220840886402649]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_394.pth
	Model improved!!!
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1498765055157489		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.1498765055157489 | validation: 0.23262589619296656]
	TIME [epoch: 2.79 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16578298693595947		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.16578298693595947 | validation: 0.22288300052216528]
	TIME [epoch: 2.79 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15409004307751484		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.15409004307751484 | validation: 0.2240465089381949]
	TIME [epoch: 2.79 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16827164174729972		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.16827164174729972 | validation: 0.2131698542749308]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14226118024597809		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.14226118024597809 | validation: 0.23391437251457262]
	TIME [epoch: 2.79 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2112502292124443		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.2112502292124443 | validation: 0.2231438687536197]
	TIME [epoch: 2.79 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1431046797429491		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.1431046797429491 | validation: 0.21376950946905968]
	TIME [epoch: 2.78 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1350019796071523		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.1350019796071523 | validation: 0.21745754606199094]
	TIME [epoch: 2.79 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15778566307383035		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.15778566307383035 | validation: 0.2251648257946336]
	TIME [epoch: 2.78 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15560971930288242		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.15560971930288242 | validation: 0.21731673397070367]
	TIME [epoch: 2.79 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1388585269620093		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.1388585269620093 | validation: 0.21452430991620508]
	TIME [epoch: 2.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15209811151344899		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.15209811151344899 | validation: 0.2151227432138493]
	TIME [epoch: 2.79 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16979991911245546		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.16979991911245546 | validation: 0.22882701422223067]
	TIME [epoch: 2.78 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15070449581962433		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.15070449581962433 | validation: 0.21375201896616472]
	TIME [epoch: 2.79 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14027294081268427		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.14027294081268427 | validation: 0.22594414358389503]
	TIME [epoch: 2.78 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14675331573661438		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.14675331573661438 | validation: 0.3828140491622085]
	TIME [epoch: 2.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5295987974718066		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.5295987974718066 | validation: 0.3098280127272496]
	TIME [epoch: 2.78 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43929681968297096		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.43929681968297096 | validation: 0.21186812137749192]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_412.pth
	Model improved!!!
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1894856817072299		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.1894856817072299 | validation: 0.284373011491156]
	TIME [epoch: 2.81 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2720888551629681		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.2720888551629681 | validation: 0.24437229752289366]
	TIME [epoch: 2.81 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2036176999995983		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.2036176999995983 | validation: 0.21198709911213479]
	TIME [epoch: 2.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16827683367336488		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.16827683367336488 | validation: 0.20843053288078797]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15380489910611903		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.15380489910611903 | validation: 0.22318706090204643]
	TIME [epoch: 2.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16695198139389175		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.16695198139389175 | validation: 0.2059264892722487]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13987058435911087		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.13987058435911087 | validation: 0.19419316083173843]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1527824105383147		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.1527824105383147 | validation: 0.20800283778457712]
	TIME [epoch: 2.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14232226534718564		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.14232226534718564 | validation: 0.19654200784216086]
	TIME [epoch: 2.79 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13249418159655538		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.13249418159655538 | validation: 0.2107924995722099]
	TIME [epoch: 2.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1480595368523737		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.1480595368523737 | validation: 0.1996084440993569]
	TIME [epoch: 2.79 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1416914101200017		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.1416914101200017 | validation: 0.20624853270208088]
	TIME [epoch: 2.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14184183201904232		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.14184183201904232 | validation: 0.2024626335831745]
	TIME [epoch: 2.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13235896974353328		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.13235896974353328 | validation: 0.1975949833887785]
	TIME [epoch: 2.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12558229143776217		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.12558229143776217 | validation: 0.2033604960132825]
	TIME [epoch: 2.79 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12541746968237336		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.12541746968237336 | validation: 0.2062038241049427]
	TIME [epoch: 2.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13584442775662223		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.13584442775662223 | validation: 0.2213764295594409]
	TIME [epoch: 2.79 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15829599122313448		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.15829599122313448 | validation: 0.2087650667027143]
	TIME [epoch: 2.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13937900615273396		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.13937900615273396 | validation: 0.2033083363471464]
	TIME [epoch: 2.8 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12836362966968276		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.12836362966968276 | validation: 0.2191900858651169]
	TIME [epoch: 2.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23125578958542217		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.23125578958542217 | validation: 0.202342198893765]
	TIME [epoch: 2.79 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12307511209198391		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12307511209198391 | validation: 0.20314921971261693]
	TIME [epoch: 2.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12108063066710661		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.12108063066710661 | validation: 0.20844115070400338]
	TIME [epoch: 2.79 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.142388702731161		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.142388702731161 | validation: 0.21789000286067406]
	TIME [epoch: 2.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1421258569209533		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.1421258569209533 | validation: 0.19835880177732804]
	TIME [epoch: 2.79 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1227638045019188		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.1227638045019188 | validation: 0.1995913628256174]
	TIME [epoch: 2.81 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12411674077568172		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.12411674077568172 | validation: 0.22578931678228795]
	TIME [epoch: 2.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15706840341844017		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.15706840341844017 | validation: 0.19475966730179187]
	TIME [epoch: 2.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12889534265027672		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.12889534265027672 | validation: 0.20090462547311724]
	TIME [epoch: 2.79 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12759317394841013		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12759317394841013 | validation: 0.1968979034184234]
	TIME [epoch: 2.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13526623011360753		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.13526623011360753 | validation: 0.220044525612048]
	TIME [epoch: 2.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1324764180997205		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.1324764180997205 | validation: 0.19352380716541356]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12107300222548721		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.12107300222548721 | validation: 0.20775887192640244]
	TIME [epoch: 2.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12660174487152598		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.12660174487152598 | validation: 0.2329302858960105]
	TIME [epoch: 2.8 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2052346638750737		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.2052346638750737 | validation: 0.21549922395968318]
	TIME [epoch: 2.79 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12911689720116182		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.12911689720116182 | validation: 0.20649963015094555]
	TIME [epoch: 2.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1347985615100322		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.1347985615100322 | validation: 0.21935814123694716]
	TIME [epoch: 2.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19313621743181167		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.19313621743181167 | validation: 0.2160570349748764]
	TIME [epoch: 2.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1286108765759876		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.1286108765759876 | validation: 0.19835207516057213]
	TIME [epoch: 2.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1204831938301634		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.1204831938301634 | validation: 0.2694183768233058]
	TIME [epoch: 2.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34181832205737933		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.34181832205737933 | validation: 0.23382888087792192]
	TIME [epoch: 2.8 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2794578035663466		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.2794578035663466 | validation: 0.20298798155076325]
	TIME [epoch: 2.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1282310179352623		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.1282310179352623 | validation: 0.21056378450740554]
	TIME [epoch: 2.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13010760871719956		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.13010760871719956 | validation: 0.19518748369842664]
	TIME [epoch: 2.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15835813635270732		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.15835813635270732 | validation: 0.19309079168194232]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_457.pth
	Model improved!!!
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1163835944933901		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.1163835944933901 | validation: 0.2103722284460402]
	TIME [epoch: 2.78 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12790157808398964		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.12790157808398964 | validation: 0.19156378736089086]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_459.pth
	Model improved!!!
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11281480087001669		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.11281480087001669 | validation: 0.1949444807446545]
	TIME [epoch: 2.79 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11162501451754374		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.11162501451754374 | validation: 0.18247352051745175]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11017376527734182		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.11017376527734182 | validation: 0.19119270088268323]
	TIME [epoch: 2.78 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10618955100327204		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.10618955100327204 | validation: 0.18739855567036545]
	TIME [epoch: 2.78 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10380248322358365		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.10380248322358365 | validation: 0.31016705044371]
	TIME [epoch: 2.78 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2254933310212569		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.2254933310212569 | validation: 0.18143954730277653]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_465.pth
	Model improved!!!
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11510815052976205		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.11510815052976205 | validation: 0.20167090279852082]
	TIME [epoch: 2.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10826683935963015		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.10826683935963015 | validation: 0.1981056167944335]
	TIME [epoch: 2.81 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11067505514689056		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.11067505514689056 | validation: 0.18071764080592861]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1121835404898489		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.1121835404898489 | validation: 0.1984403146050061]
	TIME [epoch: 2.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10945705592236646		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.10945705592236646 | validation: 0.28453145593094054]
	TIME [epoch: 2.78 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19382019712931495		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.19382019712931495 | validation: 0.1900214915474881]
	TIME [epoch: 2.79 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11269709125484426		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.11269709125484426 | validation: 0.18988370116018893]
	TIME [epoch: 2.79 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1110918248875474		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.1110918248875474 | validation: 0.20237280737808605]
	TIME [epoch: 2.78 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11084144644474166		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.11084144644474166 | validation: 0.18443913852868282]
	TIME [epoch: 2.78 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11087022699512204		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.11087022699512204 | validation: 0.1919599800157643]
	TIME [epoch: 2.79 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10819557743858084		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.10819557743858084 | validation: 0.1808766402337532]
	TIME [epoch: 2.79 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11407151092837958		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.11407151092837958 | validation: 0.18681291044455206]
	TIME [epoch: 2.78 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11079049389302263		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.11079049389302263 | validation: 0.19456194515957553]
	TIME [epoch: 2.79 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10966457112129227		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.10966457112129227 | validation: 0.18792126532238557]
	TIME [epoch: 2.78 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12325273715976247		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.12325273715976247 | validation: 0.21709592623335805]
	TIME [epoch: 2.79 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12767837826552272		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.12767837826552272 | validation: 0.17682110651010613]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11433224992038468		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.11433224992038468 | validation: 0.1972790081013801]
	TIME [epoch: 2.79 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12044903999216894		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.12044903999216894 | validation: 0.22686733599700215]
	TIME [epoch: 2.78 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21028312612879493		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.21028312612879493 | validation: 0.17083927666004262]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10553790775541426		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.10553790775541426 | validation: 0.21104082896506693]
	TIME [epoch: 2.79 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15966601918645387		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.15966601918645387 | validation: 0.17767166869442097]
	TIME [epoch: 2.79 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10493270390254157		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.10493270390254157 | validation: 0.18078482952436012]
	TIME [epoch: 2.79 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11493923836642896		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.11493923836642896 | validation: 0.17136028989372817]
	TIME [epoch: 2.79 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10597070463668376		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.10597070463668376 | validation: 0.16265322903151103]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10828899265801725		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.10828899265801725 | validation: 0.1867563068975624]
	TIME [epoch: 2.79 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11714410060110368		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.11714410060110368 | validation: 0.1715530326015273]
	TIME [epoch: 2.78 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10686669465390618		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.10686669465390618 | validation: 0.18851188568909416]
	TIME [epoch: 2.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11278616548667741		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.11278616548667741 | validation: 0.173208661672186]
	TIME [epoch: 2.79 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10089136611983551		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.10089136611983551 | validation: 0.178452956759992]
	TIME [epoch: 2.79 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1120568959367989		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.1120568959367989 | validation: 0.17208350624807395]
	TIME [epoch: 2.79 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11276022638325466		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.11276022638325466 | validation: 0.1783830695826778]
	TIME [epoch: 2.79 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10490850850017643		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.10490850850017643 | validation: 0.17139473651820497]
	TIME [epoch: 2.78 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09987794040026735		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.09987794040026735 | validation: 0.17589241150382287]
	TIME [epoch: 2.79 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10456052118987837		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.10456052118987837 | validation: 0.16333519122616935]
	TIME [epoch: 2.79 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09318093190628357		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.09318093190628357 | validation: 0.15805987763714546]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_500.pth
	Model improved!!!
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09412357669109386		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.09412357669109386 | validation: 0.16763806672737414]
	TIME [epoch: 276 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11896976359218941		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.11896976359218941 | validation: 0.1779445012418165]
	TIME [epoch: 5.99 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09938841769441015		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.09938841769441015 | validation: 0.16369612118312543]
	TIME [epoch: 5.98 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08776675001793598		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.08776675001793598 | validation: 0.1608304004552662]
	TIME [epoch: 5.98 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10338148070387995		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.10338148070387995 | validation: 0.19405369725046562]
	TIME [epoch: 5.98 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11369300003784394		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.11369300003784394 | validation: 0.15434126344615304]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_506.pth
	Model improved!!!
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10532682705580275		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.10532682705580275 | validation: 0.18324450326403616]
	TIME [epoch: 5.98 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11535593256489891		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.11535593256489891 | validation: 0.16619833138754558]
	TIME [epoch: 5.99 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10801723296535937		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.10801723296535937 | validation: 0.1945048719866161]
	TIME [epoch: 5.98 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10561224802554837		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.10561224802554837 | validation: 0.18569264795656226]
	TIME [epoch: 5.99 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1349874968965273		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.1349874968965273 | validation: 0.1715617536004489]
	TIME [epoch: 5.98 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09607699285404381		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.09607699285404381 | validation: 0.1563986339505984]
	TIME [epoch: 5.99 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08901445940524941		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.08901445940524941 | validation: 0.17914254774330365]
	TIME [epoch: 5.99 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11068190647909304		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.11068190647909304 | validation: 0.15411775172143938]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09013531434141202		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.09013531434141202 | validation: 0.19401581085425207]
	TIME [epoch: 6.01 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11117408295396107		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.11117408295396107 | validation: 0.16539972312957182]
	TIME [epoch: 6.02 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11272668094017058		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.11272668094017058 | validation: 0.16609117356531203]
	TIME [epoch: 6.01 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09267826118547672		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.09267826118547672 | validation: 0.18571021255139117]
	TIME [epoch: 6.01 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12665512482800778		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.12665512482800778 | validation: 0.1618086061879398]
	TIME [epoch: 6.01 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0904874557156612		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.0904874557156612 | validation: 0.16116708956715545]
	TIME [epoch: 6.01 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08908311694587429		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.08908311694587429 | validation: 0.16452965069694458]
	TIME [epoch: 6.01 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12183918512245574		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.12183918512245574 | validation: 0.16785898367851548]
	TIME [epoch: 6.02 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09956591942204479		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.09956591942204479 | validation: 0.14953936323741876]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_523.pth
	Model improved!!!
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09086937460421993		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.09086937460421993 | validation: 0.18948412331601514]
	TIME [epoch: 6.01 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11455856356413982		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.11455856356413982 | validation: 0.1567604759519694]
	TIME [epoch: 6.01 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08230151377705436		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.08230151377705436 | validation: 0.19397980754472383]
	TIME [epoch: 6.01 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1147356827641146		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.1147356827641146 | validation: 0.17295645555946115]
	TIME [epoch: 6.02 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11791567598012076		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.11791567598012076 | validation: 0.25433153562255095]
	TIME [epoch: 6.02 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15624536754002397		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.15624536754002397 | validation: 0.18862846155196233]
	TIME [epoch: 5.99 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11094102256220165		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.11094102256220165 | validation: 0.1661071842314042]
	TIME [epoch: 5.98 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09688762224646222		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.09688762224646222 | validation: 0.16590016939207738]
	TIME [epoch: 5.99 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08228631720447296		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.08228631720447296 | validation: 0.16081329619607343]
	TIME [epoch: 5.99 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08957531476861967		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.08957531476861967 | validation: 0.1889308652342961]
	TIME [epoch: 5.99 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12316101065751962		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.12316101065751962 | validation: 0.16210939500931323]
	TIME [epoch: 5.99 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10001813594540872		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.10001813594540872 | validation: 0.1660786997875221]
	TIME [epoch: 5.98 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09627306414513949		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.09627306414513949 | validation: 0.17128589218506154]
	TIME [epoch: 5.99 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10151056665278098		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.10151056665278098 | validation: 0.16532293702265718]
	TIME [epoch: 5.99 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08683347345170937		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.08683347345170937 | validation: 0.15419874141127834]
	TIME [epoch: 5.99 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07987267702181791		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.07987267702181791 | validation: 0.18054181432872257]
	TIME [epoch: 5.99 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1123438123775151		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.1123438123775151 | validation: 0.15232268324114617]
	TIME [epoch: 5.99 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08710479350447711		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.08710479350447711 | validation: 0.15879457869241873]
	TIME [epoch: 6 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0851544518834078		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.0851544518834078 | validation: 0.1595411925150932]
	TIME [epoch: 5.99 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11082435888495074		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.11082435888495074 | validation: 0.19739240249619164]
	TIME [epoch: 5.99 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1241381162754639		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.1241381162754639 | validation: 0.16567131214318398]
	TIME [epoch: 5.99 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08848866291902198		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.08848866291902198 | validation: 0.1702063922698757]
	TIME [epoch: 5.98 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09696854660534397		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.09696854660534397 | validation: 0.15565714916638307]
	TIME [epoch: 5.99 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08204580342420952		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.08204580342420952 | validation: 0.21150248320275225]
	TIME [epoch: 5.99 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1243614232485082		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.1243614232485082 | validation: 0.14974239140544685]
	TIME [epoch: 5.99 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08482476743284402		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.08482476743284402 | validation: 0.16426704345058188]
	TIME [epoch: 5.99 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0973128186080929		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.0973128186080929 | validation: 0.1540035835328728]
	TIME [epoch: 5.98 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08140980741416533		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.08140980741416533 | validation: 0.15913060768210283]
	TIME [epoch: 5.99 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08493458396756985		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.08493458396756985 | validation: 0.15076737703620136]
	TIME [epoch: 5.99 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07700706211595916		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.07700706211595916 | validation: 0.1630655662967175]
	TIME [epoch: 5.99 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09380049168832169		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.09380049168832169 | validation: 0.16030636255252356]
	TIME [epoch: 6.01 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09111193366574888		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.09111193366574888 | validation: 0.15465602422399638]
	TIME [epoch: 5.98 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07870470551126701		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.07870470551126701 | validation: 0.16716205864603392]
	TIME [epoch: 5.99 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08801702716747958		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.08801702716747958 | validation: 0.15140651859439128]
	TIME [epoch: 5.99 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08081312653128901		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.08081312653128901 | validation: 0.14931743142679532]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0753227337719717		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.0753227337719717 | validation: 0.1529383361867107]
	TIME [epoch: 6.01 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07268091948027079		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.07268091948027079 | validation: 0.14750813396584309]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_560.pth
	Model improved!!!
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08031152014944175		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.08031152014944175 | validation: 0.1696772445277616]
	TIME [epoch: 5.97 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10464497177463415		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.10464497177463415 | validation: 0.15958488596014442]
	TIME [epoch: 5.97 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11297594692093518		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.11297594692093518 | validation: 0.16629898515385]
	TIME [epoch: 5.98 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10563244563753628		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.10563244563753628 | validation: 0.1761652599054234]
	TIME [epoch: 5.97 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08311906769128508		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.08311906769128508 | validation: 0.1508043409358474]
	TIME [epoch: 5.97 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07806338023552145		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.07806338023552145 | validation: 0.1465917609023748]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_566.pth
	Model improved!!!
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07293199837846027		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.07293199837846027 | validation: 0.15266743963113966]
	TIME [epoch: 6.01 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07612765632534822		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.07612765632534822 | validation: 0.14916325311100934]
	TIME [epoch: 6 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0762310292075935		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.0762310292075935 | validation: 0.16350534182718568]
	TIME [epoch: 6.01 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09010013872657112		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.09010013872657112 | validation: 0.15912123462356173]
	TIME [epoch: 6.01 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10790547352130471		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.10790547352130471 | validation: 0.1469961491201069]
	TIME [epoch: 6.01 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07756011321564722		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.07756011321564722 | validation: 0.20210775142215712]
	TIME [epoch: 6.01 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12067746077581508		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.12067746077581508 | validation: 0.14665140609626293]
	TIME [epoch: 6.02 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08353198397221133		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.08353198397221133 | validation: 0.1523269940768056]
	TIME [epoch: 6.01 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08641308698827853		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.08641308698827853 | validation: 0.1434185234054922]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_575.pth
	Model improved!!!
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07802167925351232		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.07802167925351232 | validation: 0.14622245783980672]
	TIME [epoch: 6 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07954163337293677		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.07954163337293677 | validation: 0.1374348014199592]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07508275771133809		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.07508275771133809 | validation: 0.15188229536354486]
	TIME [epoch: 5.98 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07272366191321326		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.07272366191321326 | validation: 0.13997375600170292]
	TIME [epoch: 5.99 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07776317109117177		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.07776317109117177 | validation: 0.16041454458046187]
	TIME [epoch: 5.98 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09099805226407692		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.09099805226407692 | validation: 0.1568696031514746]
	TIME [epoch: 5.99 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12085238953991301		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.12085238953991301 | validation: 0.1703197186063103]
	TIME [epoch: 5.98 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13112660757378775		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.13112660757378775 | validation: 0.16841239834482322]
	TIME [epoch: 5.99 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11222463872592499		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.11222463872592499 | validation: 0.1571518482332803]
	TIME [epoch: 5.99 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10695353464176285		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.10695353464176285 | validation: 0.13690082760463151]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07360125720030396		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.07360125720030396 | validation: 0.14664491381914624]
	TIME [epoch: 6 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08254339522414543		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08254339522414543 | validation: 0.12918869624562743]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07588148641555265		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.07588148641555265 | validation: 0.13728695208978806]
	TIME [epoch: 6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07793949048863344		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.07793949048863344 | validation: 0.1244557785185355]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_589.pth
	Model improved!!!
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07094384836584144		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.07094384836584144 | validation: 0.14249730545696052]
	TIME [epoch: 5.98 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07878386400403839		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.07878386400403839 | validation: 0.13265691276358596]
	TIME [epoch: 5.99 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07564683553389066		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.07564683553389066 | validation: 0.15083874310105927]
	TIME [epoch: 5.99 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07383164855559944		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.07383164855559944 | validation: 0.13531555667135595]
	TIME [epoch: 5.99 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07005485875091864		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.07005485875091864 | validation: 0.1399786857762045]
	TIME [epoch: 5.98 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07527578361982416		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.07527578361982416 | validation: 0.1337167961796263]
	TIME [epoch: 5.98 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07860684100445729		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.07860684100445729 | validation: 0.15598633943697277]
	TIME [epoch: 5.98 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07787569444444326		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.07787569444444326 | validation: 0.13470887850684507]
	TIME [epoch: 5.98 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07941425451018992		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.07941425451018992 | validation: 0.14155096387383273]
	TIME [epoch: 5.98 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07328986901001168		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.07328986901001168 | validation: 0.14746075524122684]
	TIME [epoch: 5.97 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07458990199666969		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.07458990199666969 | validation: 0.13783238407696338]
	TIME [epoch: 5.98 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07335727541127758		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.07335727541127758 | validation: 0.12871125102083864]
	TIME [epoch: 6 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07344231625483395		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.07344231625483395 | validation: 0.1462349090769129]
	TIME [epoch: 6.01 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08004274380020256		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.08004274380020256 | validation: 0.1484031876235583]
	TIME [epoch: 6.01 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13320737041265315		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.13320737041265315 | validation: 0.13173393029032052]
	TIME [epoch: 6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07309686374209097		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.07309686374209097 | validation: 0.15455313145175714]
	TIME [epoch: 6.01 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09273005003719494		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.09273005003719494 | validation: 0.13881525043181206]
	TIME [epoch: 6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06958561728231603		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.06958561728231603 | validation: 0.13595874736507316]
	TIME [epoch: 6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07092400550520507		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.07092400550520507 | validation: 0.15334087015896883]
	TIME [epoch: 6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07006513821812313		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.07006513821812313 | validation: 0.1366529614629178]
	TIME [epoch: 5.98 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08115134236117459		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.08115134236117459 | validation: 0.16510556896327305]
	TIME [epoch: 5.98 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08487792788647078		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.08487792788647078 | validation: 0.1259073169416831]
	TIME [epoch: 5.98 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06539419740887362		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.06539419740887362 | validation: 0.13639740656091287]
	TIME [epoch: 5.98 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06683026538460948		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.06683026538460948 | validation: 0.1363966730869596]
	TIME [epoch: 5.98 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0625529356219745		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.0625529356219745 | validation: 0.14017218933241377]
	TIME [epoch: 5.97 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06644976772505806		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.06644976772505806 | validation: 0.1997551440040666]
	TIME [epoch: 5.97 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12057030907578564		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.12057030907578564 | validation: 0.13905359417891153]
	TIME [epoch: 5.98 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07154445516634052		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.07154445516634052 | validation: 0.13999607340900203]
	TIME [epoch: 5.99 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07647456257067518		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.07647456257067518 | validation: 0.1446149700992446]
	TIME [epoch: 5.97 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07588391865213759		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.07588391865213759 | validation: 0.16267594458281126]
	TIME [epoch: 5.98 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0843279730909317		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.0843279730909317 | validation: 0.13559224672738732]
	TIME [epoch: 5.98 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07587762170119422		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.07587762170119422 | validation: 0.13880672470878697]
	TIME [epoch: 5.98 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07038388811827105		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.07038388811827105 | validation: 0.1403347942859767]
	TIME [epoch: 5.98 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06302658163920148		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.06302658163920148 | validation: 0.6450027562617159]
	TIME [epoch: 5.98 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4229732085856358		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.4229732085856358 | validation: 0.7369900860429054]
	TIME [epoch: 5.98 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4774263601326154		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.4774263601326154 | validation: 0.5692079758110016]
	TIME [epoch: 5.98 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.310806942364112		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.310806942364112 | validation: 0.29832444516899426]
	TIME [epoch: 5.98 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1676019383830393		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.1676019383830393 | validation: 0.17340799921079741]
	TIME [epoch: 5.98 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09778064807514017		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.09778064807514017 | validation: 0.17240852252002328]
	TIME [epoch: 5.98 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09351746795578031		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.09351746795578031 | validation: 0.1646517255163926]
	TIME [epoch: 5.98 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08662438951672995		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.08662438951672995 | validation: 0.15954031328929422]
	TIME [epoch: 5.98 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08155996457420418		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.08155996457420418 | validation: 0.16466463660645836]
	TIME [epoch: 5.97 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08541410945340842		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08541410945340842 | validation: 0.1648883772143836]
	TIME [epoch: 5.98 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08034954096518032		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.08034954096518032 | validation: 0.15838299102232178]
	TIME [epoch: 5.98 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0764667361057703		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.0764667361057703 | validation: 0.16101241778184672]
	TIME [epoch: 6 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08299721522661967		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.08299721522661967 | validation: 0.15814054420296111]
	TIME [epoch: 5.99 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07372453471313457		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.07372453471313457 | validation: 0.15392468480426552]
	TIME [epoch: 6.01 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07449791602768731		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.07449791602768731 | validation: 0.14771496257586744]
	TIME [epoch: 6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07127810634772141		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.07127810634772141 | validation: 0.14114247537551744]
	TIME [epoch: 6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0691706897001103		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.0691706897001103 | validation: 0.14592790169167302]
	TIME [epoch: 5.99 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06732312967647643		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.06732312967647643 | validation: 0.1492158591036285]
	TIME [epoch: 5.99 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07000281917174897		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.07000281917174897 | validation: 0.15439644867665547]
	TIME [epoch: 5.98 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0704665431719883		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.0704665431719883 | validation: 0.1608018640594866]
	TIME [epoch: 6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06991718442555149		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.06991718442555149 | validation: 0.14471595757450517]
	TIME [epoch: 5.99 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06665058621294999		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.06665058621294999 | validation: 0.1484002548317807]
	TIME [epoch: 5.99 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06734885306415435		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.06734885306415435 | validation: 0.13437518837856902]
	TIME [epoch: 5.99 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06433468015878546		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.06433468015878546 | validation: 0.1352418258894289]
	TIME [epoch: 5.99 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06781250268770958		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.06781250268770958 | validation: 0.1762039789512923]
	TIME [epoch: 5.98 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29342216799738213		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.29342216799738213 | validation: 0.15953404612326327]
	TIME [epoch: 5.99 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18756839946634618		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.18756839946634618 | validation: 0.14670953875643197]
	TIME [epoch: 5.98 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07822140357406583		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.07822140357406583 | validation: 0.16734303968901185]
	TIME [epoch: 5.99 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09172868341991426		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.09172868341991426 | validation: 0.15024991933226703]
	TIME [epoch: 5.99 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06986365296300796		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.06986365296300796 | validation: 0.1367134836382905]
	TIME [epoch: 5.99 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06649093739260586		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.06649093739260586 | validation: 0.13056416892212902]
	TIME [epoch: 5.99 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06388824847105498		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.06388824847105498 | validation: 0.1419355127991148]
	TIME [epoch: 5.99 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07248397388138868		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.07248397388138868 | validation: 0.13627191252120313]
	TIME [epoch: 5.99 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0664173199877035		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.0664173199877035 | validation: 0.13600474465444173]
	TIME [epoch: 5.99 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07872967908858107		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.07872967908858107 | validation: 0.14437420748176777]
	TIME [epoch: 5.99 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0665750915180006		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.0665750915180006 | validation: 0.153937443713639]
	TIME [epoch: 6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0634138777556799		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.0634138777556799 | validation: 0.13396008817851346]
	TIME [epoch: 6.01 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0614230281300277		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.0614230281300277 | validation: 0.14078895088582866]
	TIME [epoch: 6 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06170979228736546		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.06170979228736546 | validation: 0.14145847897273275]
	TIME [epoch: 5.99 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0679618804625107		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.0679618804625107 | validation: 0.1424502029684694]
	TIME [epoch: 5.99 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06332094831014516		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.06332094831014516 | validation: 0.13836618896296785]
	TIME [epoch: 5.99 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06111890749451332		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.06111890749451332 | validation: 0.1473653966010509]
	TIME [epoch: 5.99 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11730471520200446		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.11730471520200446 | validation: 0.1352886904019604]
	TIME [epoch: 5.99 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06534025170957686		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.06534025170957686 | validation: 0.19238327134315514]
	TIME [epoch: 5.98 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11366893349413389		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.11366893349413389 | validation: 0.12753853310470414]
	TIME [epoch: 5.99 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0621335620369169		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.0621335620369169 | validation: 0.1321288386368606]
	TIME [epoch: 5.99 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05793022742082497		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.05793022742082497 | validation: 0.14309657845384202]
	TIME [epoch: 5.99 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06629183517058093		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.06629183517058093 | validation: 0.12743387808471426]
	TIME [epoch: 5.99 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06241393771723137		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.06241393771723137 | validation: 0.13851397053428802]
	TIME [epoch: 5.99 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07340837001665791		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.07340837001665791 | validation: 0.1419228414019019]
	TIME [epoch: 5.99 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06161976402032321		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.06161976402032321 | validation: 0.1298621205002511]
	TIME [epoch: 6.01 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059659953914615683		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.059659953914615683 | validation: 0.12923598868948824]
	TIME [epoch: 6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06868662627478767		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.06868662627478767 | validation: 0.1227735973208568]
	TIME [epoch: 6.02 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060344651928354656		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.060344651928354656 | validation: 0.1304111004149971]
	TIME [epoch: 5.98 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06181168679244504		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.06181168679244504 | validation: 0.12300134680251869]
	TIME [epoch: 5.98 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06112420886557779		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.06112420886557779 | validation: 0.12553969224917863]
	TIME [epoch: 5.98 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06394484059704574		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.06394484059704574 | validation: 0.11613354617268579]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_679.pth
	Model improved!!!
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05972208815941652		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.05972208815941652 | validation: 0.1312459381329083]
	TIME [epoch: 5.98 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0633996154666352		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.0633996154666352 | validation: 0.1213633352579743]
	TIME [epoch: 5.97 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05927837704643658		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.05927837704643658 | validation: 0.13564462827352156]
	TIME [epoch: 5.97 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06284327385421226		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.06284327385421226 | validation: 0.20963570802821466]
	TIME [epoch: 5.97 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26838212553392565		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.26838212553392565 | validation: 0.16129633295094364]
	TIME [epoch: 5.97 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22244645050884918		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.22244645050884918 | validation: 0.1200749573106009]
	TIME [epoch: 5.97 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07869923006162473		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.07869923006162473 | validation: 0.14274470104031006]
	TIME [epoch: 5.97 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.077874159467547		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.077874159467547 | validation: 0.12320268265150545]
	TIME [epoch: 5.98 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06974902500382295		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.06974902500382295 | validation: 0.11399933401836511]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0647651458082575		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.0647651458082575 | validation: 0.12490208600499053]
	TIME [epoch: 6.01 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06117921492962337		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.06117921492962337 | validation: 0.11428749686100226]
	TIME [epoch: 6.03 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058596749187327525		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.058596749187327525 | validation: 0.12014774391980572]
	TIME [epoch: 5.99 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06298365935160284		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.06298365935160284 | validation: 0.13106432386032837]
	TIME [epoch: 5.98 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07287117205987642		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.07287117205987642 | validation: 0.1126813994371298]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_693.pth
	Model improved!!!
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06221155280977327		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.06221155280977327 | validation: 0.12094891893924951]
	TIME [epoch: 6.01 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05878048330063286		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.05878048330063286 | validation: 0.1209958058982207]
	TIME [epoch: 6.01 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06045756654386161		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.06045756654386161 | validation: 0.1201181771046191]
	TIME [epoch: 6.01 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05754090079563016		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.05754090079563016 | validation: 0.11642138822018425]
	TIME [epoch: 6.01 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059093421466890846		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.059093421466890846 | validation: 0.12603575366704609]
	TIME [epoch: 6.01 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058248188508534894		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.058248188508534894 | validation: 0.11876102822911415]
	TIME [epoch: 6.01 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05584176672386202		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.05584176672386202 | validation: 0.1288581671824887]
	TIME [epoch: 6.01 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05828183460639995		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.05828183460639995 | validation: 0.12427021009375244]
	TIME [epoch: 6.01 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058230280293590064		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.058230280293590064 | validation: 0.12640080841563456]
	TIME [epoch: 6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05785999834118618		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.05785999834118618 | validation: 0.15985115824268092]
	TIME [epoch: 6.01 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08161181413196912		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.08161181413196912 | validation: 0.11267111092601807]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_704.pth
	Model improved!!!
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06130886293049822		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.06130886293049822 | validation: 0.12243122801696038]
	TIME [epoch: 6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06552938458433663		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.06552938458433663 | validation: 0.1317622315775233]
	TIME [epoch: 6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05693632148554276		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.05693632148554276 | validation: 0.10992794004189871]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05940452929388906		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.05940452929388906 | validation: 0.1493306900998532]
	TIME [epoch: 6 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07454619399681692		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.07454619399681692 | validation: 0.12429644286531596]
	TIME [epoch: 6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05915745724224565		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.05915745724224565 | validation: 0.12275282332726256]
	TIME [epoch: 6 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05891869119302697		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.05891869119302697 | validation: 0.12420824097401702]
	TIME [epoch: 6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058928889006607935		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.058928889006607935 | validation: 0.12080538423827077]
	TIME [epoch: 5.99 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059483404186572976		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.059483404186572976 | validation: 0.12300986038708145]
	TIME [epoch: 6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06115636296622685		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.06115636296622685 | validation: 0.11507077063410508]
	TIME [epoch: 5.99 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059273153009799205		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.059273153009799205 | validation: 0.12143783873189769]
	TIME [epoch: 6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06115720381701396		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.06115720381701396 | validation: 0.12095952058687419]
	TIME [epoch: 5.99 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06266113904461187		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.06266113904461187 | validation: 0.1296808461314054]
	TIME [epoch: 5.99 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05791621022053023		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.05791621022053023 | validation: 0.11371888264377172]
	TIME [epoch: 6 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05460633931405384		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.05460633931405384 | validation: 0.12061543369350783]
	TIME [epoch: 6 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06047630795685233		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.06047630795685233 | validation: 0.12560386453847627]
	TIME [epoch: 5.99 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05213871583440767		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.05213871583440767 | validation: 0.14762675035134937]
	TIME [epoch: 5.99 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0747396738541734		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.0747396738541734 | validation: 0.17971922697243414]
	TIME [epoch: 5.99 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17938306234477794		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.17938306234477794 | validation: 0.17557604895626064]
	TIME [epoch: 6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16874582194017382		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.16874582194017382 | validation: 0.12588815994168057]
	TIME [epoch: 5.99 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07609220616997567		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.07609220616997567 | validation: 0.11542740967501884]
	TIME [epoch: 6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0652208525262411		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.0652208525262411 | validation: 0.11345202409027598]
	TIME [epoch: 6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060629044564419275		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.060629044564419275 | validation: 0.11183482336216505]
	TIME [epoch: 6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05999034854360497		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.05999034854360497 | validation: 0.10122978607471522]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_728.pth
	Model improved!!!
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060734095149110344		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.060734095149110344 | validation: 0.10336558911693006]
	TIME [epoch: 6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0629656789904198		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.0629656789904198 | validation: 0.1312159985999965]
	TIME [epoch: 6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0659222275181149		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.0659222275181149 | validation: 0.10862935727218287]
	TIME [epoch: 6.01 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05908210538170283		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.05908210538170283 | validation: 0.10561120743932279]
	TIME [epoch: 6.03 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056541158498485955		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.056541158498485955 | validation: 0.11273481513128597]
	TIME [epoch: 6.01 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058552244469175355		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.058552244469175355 | validation: 0.1048606772757649]
	TIME [epoch: 6.02 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055550874050223395		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.055550874050223395 | validation: 0.11188319766612778]
	TIME [epoch: 6.02 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05830901916249699		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.05830901916249699 | validation: 0.11159015818375245]
	TIME [epoch: 6.01 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05389988051119719		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.05389988051119719 | validation: 0.10886940397757268]
	TIME [epoch: 6.01 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05290514987699447		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.05290514987699447 | validation: 0.10502316648401507]
	TIME [epoch: 5.99 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05607072490375298		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.05607072490375298 | validation: 0.10327867752334648]
	TIME [epoch: 6.01 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05309484429607441		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.05309484429607441 | validation: 0.11361685629708407]
	TIME [epoch: 5.99 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05265499138003912		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.05265499138003912 | validation: 0.10724519535246912]
	TIME [epoch: 6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0506878859940762		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.0506878859940762 | validation: 0.09822997864063404]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05293928485210384		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.05293928485210384 | validation: 0.1122791412577791]
	TIME [epoch: 5.99 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05583664994717705		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.05583664994717705 | validation: 0.10252331315752872]
	TIME [epoch: 5.99 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07970991272501701		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.07970991272501701 | validation: 0.13117575102283024]
	TIME [epoch: 5.99 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0662294181354408		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.0662294181354408 | validation: 0.11015108349460148]
	TIME [epoch: 6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05409860755140504		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.05409860755140504 | validation: 0.10459305570153164]
	TIME [epoch: 6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06385113515428772		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.06385113515428772 | validation: 0.11423886631044518]
	TIME [epoch: 6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060786879744461376		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.060786879744461376 | validation: 0.10451459267201083]
	TIME [epoch: 6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056838551799005876		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.056838551799005876 | validation: 0.10994847615517278]
	TIME [epoch: 6 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057727803320463636		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.057727803320463636 | validation: 0.1077806393857055]
	TIME [epoch: 5.99 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05419819846641415		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.05419819846641415 | validation: 0.10458666550913363]
	TIME [epoch: 5.99 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061768227977786305		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.061768227977786305 | validation: 0.11273322732653145]
	TIME [epoch: 5.99 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05706253368484536		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.05706253368484536 | validation: 0.12463457807596146]
	TIME [epoch: 5.99 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06807632903508265		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.06807632903508265 | validation: 0.09679602711651741]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_755.pth
	Model improved!!!
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05306693388006506		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.05306693388006506 | validation: 0.1297322021753565]
	TIME [epoch: 5.99 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07518450942131125		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.07518450942131125 | validation: 0.0915795655700775]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_757.pth
	Model improved!!!
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05243193927633698		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.05243193927633698 | validation: 0.11413565227456708]
	TIME [epoch: 5.99 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05760070434483861		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.05760070434483861 | validation: 0.10043122942229735]
	TIME [epoch: 5.99 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059387471255485144		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.059387471255485144 | validation: 0.10355427965808671]
	TIME [epoch: 6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051578199749149366		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.051578199749149366 | validation: 0.10704885493136436]
	TIME [epoch: 5.99 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054374003731968656		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.054374003731968656 | validation: 0.11417961207136457]
	TIME [epoch: 6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053850220413323796		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.053850220413323796 | validation: 0.1114396653879951]
	TIME [epoch: 5.99 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058006068905805376		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.058006068905805376 | validation: 0.09725882909577475]
	TIME [epoch: 5.99 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053066667372461025		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.053066667372461025 | validation: 0.10725812906422592]
	TIME [epoch: 6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04960267113530753		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.04960267113530753 | validation: 0.11283786697035172]
	TIME [epoch: 5.99 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05648093315495415		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.05648093315495415 | validation: 0.38585424659765044]
	TIME [epoch: 6 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29532294591339486		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.29532294591339486 | validation: 0.45948733061175057]
	TIME [epoch: 5.99 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3196610764844387		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.3196610764844387 | validation: 0.32090288224065433]
	TIME [epoch: 5.99 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23495439228744502		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.23495439228744502 | validation: 0.1914752426189817]
	TIME [epoch: 5.99 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10977779548227029		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.10977779548227029 | validation: 0.1289649685564441]
	TIME [epoch: 5.99 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06422304253012567		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.06422304253012567 | validation: 0.12938762978299184]
	TIME [epoch: 6 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06331139370598712		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.06331139370598712 | validation: 0.12616267755910907]
	TIME [epoch: 5.99 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05587511171656303		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.05587511171656303 | validation: 0.12106320279469691]
	TIME [epoch: 6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057864383262108014		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.057864383262108014 | validation: 0.12118812591253031]
	TIME [epoch: 6 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05436062545531388		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.05436062545531388 | validation: 0.1175913529790522]
	TIME [epoch: 6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0549703308835521		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.0549703308835521 | validation: 0.1265763221153315]
	TIME [epoch: 5.99 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05487196630803818		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.05487196630803818 | validation: 0.12204227120389424]
	TIME [epoch: 6.01 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06656266989392438		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.06656266989392438 | validation: 0.12159221856382313]
	TIME [epoch: 6 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05755256183227869		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.05755256183227869 | validation: 0.1142091387932386]
	TIME [epoch: 6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05788533622887498		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.05788533622887498 | validation: 0.1169155277417307]
	TIME [epoch: 5.99 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05180654499384557		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.05180654499384557 | validation: 0.11458653690287801]
	TIME [epoch: 6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05932395238542908		[learning rate: 0.0007479]
	Learning Rate: 0.000747905
	LOSS [training: 0.05932395238542908 | validation: 0.11462453309652315]
	TIME [epoch: 6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052528385165983044		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.052528385165983044 | validation: 0.12098102357083902]
	TIME [epoch: 6.01 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054104034723375105		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.054104034723375105 | validation: 0.11688617349121647]
	TIME [epoch: 5.99 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052968114997498095		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.052968114997498095 | validation: 0.11479648928049942]
	TIME [epoch: 6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05885418448755407		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.05885418448755407 | validation: 0.11296932981025704]
	TIME [epoch: 5.99 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04944888583602329		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.04944888583602329 | validation: 0.1188730237330053]
	TIME [epoch: 6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057105859705219565		[learning rate: 0.00073218]
	Learning Rate: 0.000732176
	LOSS [training: 0.057105859705219565 | validation: 0.11719435754207486]
	TIME [epoch: 6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05579789586244065		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.05579789586244065 | validation: 0.11848157231170697]
	TIME [epoch: 6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05360896425964004		[learning rate: 0.00072701]
	Learning Rate: 0.000727007
	LOSS [training: 0.05360896425964004 | validation: 0.11173529101387492]
	TIME [epoch: 6 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05564616297279846		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.05564616297279846 | validation: 0.11188542626482377]
	TIME [epoch: 6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050624623165287645		[learning rate: 0.00072187]
	Learning Rate: 0.000721874
	LOSS [training: 0.050624623165287645 | validation: 0.12117994804670218]
	TIME [epoch: 6 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05757904875311384		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.05757904875311384 | validation: 0.10712919312281353]
	TIME [epoch: 6.01 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05456092680507452		[learning rate: 0.00071678]
	Learning Rate: 0.000716778
	LOSS [training: 0.05456092680507452 | validation: 0.11410405175015007]
	TIME [epoch: 6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0563725858290179		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.0563725858290179 | validation: 0.11752026236515159]
	TIME [epoch: 6.01 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05429072579752846		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.05429072579752846 | validation: 0.10991193732918428]
	TIME [epoch: 6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05223982394748715		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.05223982394748715 | validation: 0.11302786205061573]
	TIME [epoch: 6.01 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05247367371739509		[learning rate: 0.00070669]
	Learning Rate: 0.000706693
	LOSS [training: 0.05247367371739509 | validation: 0.11727080652615217]
	TIME [epoch: 6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057607379406018316		[learning rate: 0.00070419]
	Learning Rate: 0.000704194
	LOSS [training: 0.057607379406018316 | validation: 0.10354089351314442]
	TIME [epoch: 6 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05085116865989886		[learning rate: 0.0007017]
	Learning Rate: 0.000701704
	LOSS [training: 0.05085116865989886 | validation: 0.09489889897777146]
	TIME [epoch: 5.99 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07233518218478169		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.07233518218478169 | validation: 0.10741448540912168]
	TIME [epoch: 6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05295210140085361		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.05295210140085361 | validation: 0.11975933734705153]
	TIME [epoch: 6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06400096238344365		[learning rate: 0.00069429]
	Learning Rate: 0.000694286
	LOSS [training: 0.06400096238344365 | validation: 0.12168172023671452]
	TIME [epoch: 6.01 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05240972545886409		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.05240972545886409 | validation: 0.10908700437631845]
	TIME [epoch: 6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06563309648451283		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.06563309648451283 | validation: 0.12131294963047537]
	TIME [epoch: 6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0648019791774678		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.0648019791774678 | validation: 0.11740767076593467]
	TIME [epoch: 6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05124827608315453		[learning rate: 0.00068452]
	Learning Rate: 0.000684518
	LOSS [training: 0.05124827608315453 | validation: 0.11237234393814784]
	TIME [epoch: 6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053572619449356707		[learning rate: 0.0006821]
	Learning Rate: 0.000682097
	LOSS [training: 0.053572619449356707 | validation: 0.12342440702831617]
	TIME [epoch: 6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060289733106377384		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.060289733106377384 | validation: 0.11256577047461716]
	TIME [epoch: 6.01 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0519984143616783		[learning rate: 0.00067728]
	Learning Rate: 0.000677282
	LOSS [training: 0.0519984143616783 | validation: 0.12439012669323819]
	TIME [epoch: 6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0562480162229693		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.0562480162229693 | validation: 0.11011212011654069]
	TIME [epoch: 6.01 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051632498901677336		[learning rate: 0.0006725]
	Learning Rate: 0.0006725
	LOSS [training: 0.051632498901677336 | validation: 0.11807291754770857]
	TIME [epoch: 6 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05821318813481174		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.05821318813481174 | validation: 0.11136725840276473]
	TIME [epoch: 6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04907931479005405		[learning rate: 0.00066775]
	Learning Rate: 0.000667752
	LOSS [training: 0.04907931479005405 | validation: 0.11777950395674647]
	TIME [epoch: 6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057623456907152155		[learning rate: 0.00066539]
	Learning Rate: 0.000665391
	LOSS [training: 0.057623456907152155 | validation: 0.12330646648931586]
	TIME [epoch: 6.01 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049601095501368		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.049601095501368 | validation: 0.10738055052241718]
	TIME [epoch: 6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04812050650151054		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.04812050650151054 | validation: 0.11366104884717601]
	TIME [epoch: 6.01 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051223412804011444		[learning rate: 0.00065836]
	Learning Rate: 0.000658357
	LOSS [training: 0.051223412804011444 | validation: 0.09995019602477948]
	TIME [epoch: 6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05245539187659121		[learning rate: 0.00065603]
	Learning Rate: 0.000656029
	LOSS [training: 0.05245539187659121 | validation: 0.11140676989929835]
	TIME [epoch: 5.99 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053066920581319676		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.053066920581319676 | validation: 0.10880647386313849]
	TIME [epoch: 6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04700598860461451		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.04700598860461451 | validation: 0.10711204165861946]
	TIME [epoch: 6.01 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049067024866675586		[learning rate: 0.00064909]
	Learning Rate: 0.000649094
	LOSS [training: 0.049067024866675586 | validation: 0.10539037462574181]
	TIME [epoch: 6.01 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.046766533891801604		[learning rate: 0.0006468]
	Learning Rate: 0.000646799
	LOSS [training: 0.046766533891801604 | validation: 0.10114794967602295]
	TIME [epoch: 6.01 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05465209918689956		[learning rate: 0.00064451]
	Learning Rate: 0.000644512
	LOSS [training: 0.05465209918689956 | validation: 0.12027431384014822]
	TIME [epoch: 5.99 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06475393084283232		[learning rate: 0.00064223]
	Learning Rate: 0.000642233
	LOSS [training: 0.06475393084283232 | validation: 0.11359971717043615]
	TIME [epoch: 6.01 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04823355877806604		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.04823355877806604 | validation: 0.10313149987251197]
	TIME [epoch: 5.99 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05266541170525352		[learning rate: 0.0006377]
	Learning Rate: 0.000637699
	LOSS [training: 0.05266541170525352 | validation: 0.11496893193599672]
	TIME [epoch: 6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05442991169935632		[learning rate: 0.00063544]
	Learning Rate: 0.000635443
	LOSS [training: 0.05442991169935632 | validation: 0.11099012868116374]
	TIME [epoch: 6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052478849864034664		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.052478849864034664 | validation: 0.09248649226721226]
	TIME [epoch: 6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052090751528796615		[learning rate: 0.00063096]
	Learning Rate: 0.000630957
	LOSS [training: 0.052090751528796615 | validation: 0.11780028136026109]
	TIME [epoch: 6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059836874085998755		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.059836874085998755 | validation: 0.10964901480498551]
	TIME [epoch: 6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050266070561650354		[learning rate: 0.0006265]
	Learning Rate: 0.000626503
	LOSS [training: 0.050266070561650354 | validation: 0.09403159947698732]
	TIME [epoch: 6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04972136711388182		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.04972136711388182 | validation: 0.10076182396074845]
	TIME [epoch: 6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05361705008739422		[learning rate: 0.00062208]
	Learning Rate: 0.00062208
	LOSS [training: 0.05361705008739422 | validation: 0.10872003372694011]
	TIME [epoch: 6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049833586969777265		[learning rate: 0.00061988]
	Learning Rate: 0.00061988
	LOSS [training: 0.049833586969777265 | validation: 0.11479563627602306]
	TIME [epoch: 6.01 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0536552566356961		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.0536552566356961 | validation: 0.1441980236167316]
	TIME [epoch: 6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08357788497152488		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.08357788497152488 | validation: 0.10739966693388994]
	TIME [epoch: 6.01 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05870031733226238		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.05870031733226238 | validation: 0.11856734395295417]
	TIME [epoch: 5.99 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05923014192418053		[learning rate: 0.00061116]
	Learning Rate: 0.000611158
	LOSS [training: 0.05923014192418053 | validation: 0.10833335239497927]
	TIME [epoch: 5.99 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05034199261930926		[learning rate: 0.000609]
	Learning Rate: 0.000608997
	LOSS [training: 0.05034199261930926 | validation: 0.10775662690868662]
	TIME [epoch: 5.99 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05095784568370063		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.05095784568370063 | validation: 0.10940881071235378]
	TIME [epoch: 5.99 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04883949703184014		[learning rate: 0.0006047]
	Learning Rate: 0.000604698
	LOSS [training: 0.04883949703184014 | validation: 0.1190475852277332]
	TIME [epoch: 5.99 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06878169283628228		[learning rate: 0.00060256]
	Learning Rate: 0.00060256
	LOSS [training: 0.06878169283628228 | validation: 0.11319373526449437]
	TIME [epoch: 6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05336321027996863		[learning rate: 0.00060043]
	Learning Rate: 0.000600429
	LOSS [training: 0.05336321027996863 | validation: 0.12236236527262111]
	TIME [epoch: 6 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05375853583558197		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.05375853583558197 | validation: 0.1042362075131814]
	TIME [epoch: 6.01 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05428376148653216		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.05428376148653216 | validation: 0.10582835240040822]
	TIME [epoch: 6.01 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051595527167120035		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.051595527167120035 | validation: 0.09888358631470856]
	TIME [epoch: 6.01 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05037818025747787		[learning rate: 0.00059198]
	Learning Rate: 0.000591981
	LOSS [training: 0.05037818025747787 | validation: 0.10834690819563796]
	TIME [epoch: 6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04728137124504959		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.04728137124504959 | validation: 0.10634516305648326]
	TIME [epoch: 6.01 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047989077037060276		[learning rate: 0.0005878]
	Learning Rate: 0.000587802
	LOSS [training: 0.047989077037060276 | validation: 0.10555221843697904]
	TIME [epoch: 6.01 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05383381027875807		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.05383381027875807 | validation: 0.10097995058436356]
	TIME [epoch: 6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05216926110463452		[learning rate: 0.00058365]
	Learning Rate: 0.000583652
	LOSS [training: 0.05216926110463452 | validation: 0.11800458478152934]
	TIME [epoch: 6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054125994530918965		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.054125994530918965 | validation: 0.10597085251726893]
	TIME [epoch: 6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04499584351666229		[learning rate: 0.00057953]
	Learning Rate: 0.000579531
	LOSS [training: 0.04499584351666229 | validation: 0.10660260567556108]
	TIME [epoch: 6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0546277323509165		[learning rate: 0.00057748]
	Learning Rate: 0.000577482
	LOSS [training: 0.0546277323509165 | validation: 0.12049176452121238]
	TIME [epoch: 6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06301806376947805		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.06301806376947805 | validation: 0.10635505097874437]
	TIME [epoch: 5.99 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04716301870519169		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.04716301870519169 | validation: 0.09177989545192614]
	TIME [epoch: 6.01 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_153156/states/model_phi1_3b_v_mmd1_858.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 4202.938 seconds.
