Args:
Namespace(name='model_phi1_3b_v_mmd1', outdir='out/model_training/model_phi1_3b_v_mmd1', training_data='data/training_data/basic/data_phi1_3b/training', validation_data='data/training_data/basic/data_phi1_3b/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2480378992

Training model...

Saving initial model state to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.9208722043727064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9208722043727064 | validation: 5.7484788133536044]
	TIME [epoch: 255 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.3741624733511735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3741624733511735 | validation: 5.601170166270113]
	TIME [epoch: 1.45 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.81124788770093		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.81124788770093 | validation: 6.00531129643466]
	TIME [epoch: 1.4 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.388967204047947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.388967204047947 | validation: 5.760668281907064]
	TIME [epoch: 1.4 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.889459357336351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.889459357336351 | validation: 5.209545166163835]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.127655234696771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.127655234696771 | validation: 5.164342842865995]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.217380477326831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217380477326831 | validation: 5.073148622912691]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.037550401481946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.037550401481946 | validation: 5.092730574891615]
	TIME [epoch: 1.41 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9707267572747424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9707267572747424 | validation: 5.07403093986931]
	TIME [epoch: 1.41 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9496044072415577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9496044072415577 | validation: 5.013360955121352]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8973289079110804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8973289079110804 | validation: 4.997125706622166]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8809105525266685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8809105525266685 | validation: 4.988499223567645]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.852646653933275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.852646653933275 | validation: 4.976380238914353]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.834039674178771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.834039674178771 | validation: 4.952313764976096]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.814998935305099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.814998935305099 | validation: 4.945514218291373]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.796431107933311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.796431107933311 | validation: 4.928061747674244]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.778626414316118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.778626414316118 | validation: 4.913970234743946]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7603977862186024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7603977862186024 | validation: 4.9038105103699685]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7452206765935876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7452206765935876 | validation: 4.8867369124429265]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7300904458969506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7300904458969506 | validation: 4.886315734124828]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.721223343236777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.721223343236777 | validation: 4.857913690742593]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7397752593692997		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7397752593692997 | validation: 4.957691240611985]
	TIME [epoch: 1.4 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8123240471527375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8123240471527375 | validation: 4.86478336177276]
	TIME [epoch: 1.4 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.841791471195096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.841791471195096 | validation: 4.787356739258641]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6569477536904778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6569477536904778 | validation: 4.882718527040367]
	TIME [epoch: 1.4 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.730743463354151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.730743463354151 | validation: 4.748608296180405]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.67538896207072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.67538896207072 | validation: 4.713910940652194]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.58358140595124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.58358140595124 | validation: 4.713252341707445]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.577644430820328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.577644430820328 | validation: 4.661604095975482]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.54839380768073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.54839380768073 | validation: 4.631839573565539]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.499886669815305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.499886669815305 | validation: 4.647237310479068]
	TIME [epoch: 1.4 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5143140668631463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5143140668631463 | validation: 4.761128699699852]
	TIME [epoch: 1.4 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.719852320395246		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.719852320395246 | validation: 4.72116458736146]
	TIME [epoch: 1.4 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.652498059709503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.652498059709503 | validation: 4.568012450364087]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4616573932756864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4616573932756864 | validation: 4.5920180282419745]
	TIME [epoch: 1.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5080788197704806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5080788197704806 | validation: 4.512662395811818]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4076009145374657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4076009145374657 | validation: 4.480196992651118]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.399517152313102		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.399517152313102 | validation: 4.466546761995151]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3713584034616204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3713584034616204 | validation: 4.4348830233918894]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3507906196578428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3507906196578428 | validation: 4.4301826779794355]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3377546975043244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3377546975043244 | validation: 4.394458019232794]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3249627753979825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3249627753979825 | validation: 4.408207422086581]
	TIME [epoch: 1.4 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3154577673631844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3154577673631844 | validation: 4.377165902842761]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3258882084339634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3258882084339634 | validation: 4.4050068310582295]
	TIME [epoch: 1.41 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.320688588324483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.320688588324483 | validation: 4.367615368246561]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.341741274098248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.341741274098248 | validation: 4.3552014645565675]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2909642001671684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2909642001671684 | validation: 4.292411330386304]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2592939377610053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2592939377610053 | validation: 4.302763496036607]
	TIME [epoch: 1.4 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.237594640961909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.237594640961909 | validation: 4.261861071071734]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.221659582725384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.221659582725384 | validation: 4.256220456408491]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2103627626822293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2103627626822293 | validation: 4.2309471361330155]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1985340782916376		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 3.1985340782916376 | validation: 4.241929381844385]
	TIME [epoch: 1.4 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2053052562941096		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 3.2053052562941096 | validation: 4.231065259305055]
	TIME [epoch: 1.4 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.243451854391654		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 3.243451854391654 | validation: 4.243094379382194]
	TIME [epoch: 1.41 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2326881641611886		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 3.2326881641611886 | validation: 4.16254732111582]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1861651076697757		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 3.1861651076697757 | validation: 4.132163152008938]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1309449721620006		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 3.1309449721620006 | validation: 4.115905792748889]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.127424542677268		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 3.127424542677268 | validation: 4.084993582584459]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.116730295564869		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 3.116730295564869 | validation: 4.080750410609908]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0999333213214135		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 3.0999333213214135 | validation: 4.047784798253974]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.085366663078553		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 3.085366663078553 | validation: 4.015743381041247]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0700043800944683		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 3.0700043800944683 | validation: 3.9302007095694975]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0506541762852124		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 3.0506541762852124 | validation: 3.7574618073947605]
	TIME [epoch: 1.42 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.9473100976280273		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 2.9473100976280273 | validation: 3.3848338666547635]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.6338368621639576		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 2.6338368621639576 | validation: 2.823219665160074]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.182556034979363		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 2.182556034979363 | validation: 2.191957361224206]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.75496102762487		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 1.75496102762487 | validation: 2.271691470593521]
	TIME [epoch: 1.41 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.2146399837310677		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 2.2146399837310677 | validation: 1.630673588846407]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3647277014343424		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 1.3647277014343424 | validation: 1.2039164372773907]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0784203816167774		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 1.0784203816167774 | validation: 1.1804632063546296]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0305047671945882		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 1.0305047671945882 | validation: 1.12131327002596]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.0130946917565047		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 1.0130946917565047 | validation: 1.1871924596753693]
	TIME [epoch: 1.4 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9782603721301959		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 0.9782603721301959 | validation: 1.0189184016413568]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9676809186744656		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 0.9676809186744656 | validation: 0.9997046623206174]
	TIME [epoch: 1.42 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8585003390243823		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 0.8585003390243823 | validation: 0.9604937502557691]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8313624118049515		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 0.8313624118049515 | validation: 0.9094887848820465]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8075283643511872		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 0.8075283643511872 | validation: 0.8892017542942675]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8024078585086499		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 0.8024078585086499 | validation: 0.8775994829573975]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7920692613714428		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 0.7920692613714428 | validation: 0.8877100720315525]
	TIME [epoch: 1.41 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7924102268387967		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 0.7924102268387967 | validation: 0.8589740682756939]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7923661159194717		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 0.7923661159194717 | validation: 0.9447578217119514]
	TIME [epoch: 1.41 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8351068148161349		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.8351068148161349 | validation: 0.9381250789908917]
	TIME [epoch: 1.41 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9107450044441103		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.9107450044441103 | validation: 0.9531592425057845]
	TIME [epoch: 1.41 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8449151220892134		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 0.8449151220892134 | validation: 0.880436019807514]
	TIME [epoch: 1.41 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8086494127903581		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 0.8086494127903581 | validation: 0.8883110388606403]
	TIME [epoch: 1.41 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8878266161806874		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.8878266161806874 | validation: 1.1487029618658688]
	TIME [epoch: 1.41 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9383877011126771		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.9383877011126771 | validation: 0.8642819198007263]
	TIME [epoch: 1.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8157065923471416		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 0.8157065923471416 | validation: 0.8197234724585908]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7762515820476492		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 0.7762515820476492 | validation: 0.8655963767331873]
	TIME [epoch: 1.41 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7801813516014531		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.7801813516014531 | validation: 0.8127177333530288]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7687000915995859		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 0.7687000915995859 | validation: 0.8141771112919804]
	TIME [epoch: 1.4 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7614872986385669		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.7614872986385669 | validation: 0.8123128789494573]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7637772705853774		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 0.7637772705853774 | validation: 0.8045168496530192]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.773948244840168		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.773948244840168 | validation: 0.8730845166895705]
	TIME [epoch: 1.4 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7982354536340378		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 0.7982354536340378 | validation: 0.9062408699611944]
	TIME [epoch: 1.41 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8456188189183488		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 0.8456188189183488 | validation: 0.9163598120526832]
	TIME [epoch: 1.41 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8464948321451822		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.8464948321451822 | validation: 0.8383582076888756]
	TIME [epoch: 1.4 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7744067749358873		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.7744067749358873 | validation: 0.7901203296839047]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.76032178338605		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 0.76032178338605 | validation: 0.8660976637958288]
	TIME [epoch: 1.41 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7712894619421313		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 0.7712894619421313 | validation: 0.7863970180865899]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7724949389478464		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.7724949389478464 | validation: 0.9182097251042477]
	TIME [epoch: 1.4 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8000032525371359		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.8000032525371359 | validation: 0.8411957003176923]
	TIME [epoch: 1.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8335924802228609		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 0.8335924802228609 | validation: 0.9903053479303682]
	TIME [epoch: 1.4 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8470752841022657		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 0.8470752841022657 | validation: 0.9059039917150091]
	TIME [epoch: 1.4 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8618375243273948		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 0.8618375243273948 | validation: 0.8190459594064446]
	TIME [epoch: 1.4 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.78733117562785		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.78733117562785 | validation: 0.8359867621956995]
	TIME [epoch: 1.4 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7601514694709972		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.7601514694709972 | validation: 0.7753473666421293]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7472742309148543		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 0.7472742309148543 | validation: 0.7989729903602472]
	TIME [epoch: 1.4 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7557635661804392		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 0.7557635661804392 | validation: 0.8145241117983023]
	TIME [epoch: 1.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7565546655484972		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.7565546655484972 | validation: 0.793906947036512]
	TIME [epoch: 1.4 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7617030188626338		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 0.7617030188626338 | validation: 0.842044726104785]
	TIME [epoch: 1.4 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7699312199184375		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.7699312199184375 | validation: 0.8221539347007735]
	TIME [epoch: 1.4 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7685213590229943		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 0.7685213590229943 | validation: 0.8254760953842872]
	TIME [epoch: 1.4 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7702659830004186		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.7702659830004186 | validation: 0.8560025701598368]
	TIME [epoch: 1.4 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7760781271244624		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 0.7760781271244624 | validation: 0.824233570907842]
	TIME [epoch: 1.4 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7990420390169436		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 0.7990420390169436 | validation: 0.9887743336557077]
	TIME [epoch: 1.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8317598414953941		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.8317598414953941 | validation: 0.8496275922388815]
	TIME [epoch: 1.4 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8169366200615423		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.8169366200615423 | validation: 0.8262587675467226]
	TIME [epoch: 1.4 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7489531800226127		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.7489531800226127 | validation: 0.7916236864902935]
	TIME [epoch: 1.4 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7603383494709339		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 0.7603383494709339 | validation: 0.8604389168297537]
	TIME [epoch: 1.4 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7895652606523232		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 0.7895652606523232 | validation: 0.8139357882262881]
	TIME [epoch: 1.41 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7628670353234159		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.7628670353234159 | validation: 0.8285713392439448]
	TIME [epoch: 1.41 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.751634314670719		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 0.751634314670719 | validation: 0.7863374285384501]
	TIME [epoch: 1.41 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7439079151301828		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 0.7439079151301828 | validation: 0.8532504931879153]
	TIME [epoch: 1.4 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7504289587363979		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 0.7504289587363979 | validation: 0.7777337391651848]
	TIME [epoch: 1.41 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7665302094495828		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.7665302094495828 | validation: 0.9144653318263583]
	TIME [epoch: 1.4 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7929664343593357		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.7929664343593357 | validation: 0.7954660471315351]
	TIME [epoch: 1.41 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7764069643767535		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 0.7764069643767535 | validation: 0.7984747891845803]
	TIME [epoch: 1.4 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7370323860504695		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 0.7370323860504695 | validation: 0.8147989259459257]
	TIME [epoch: 1.41 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7279569068440535		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.7279569068440535 | validation: 0.7804353308758706]
	TIME [epoch: 1.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7683476768948766		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 0.7683476768948766 | validation: 0.8899558021108489]
	TIME [epoch: 1.41 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7920258702433871		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.7920258702433871 | validation: 0.7914079879792665]
	TIME [epoch: 1.4 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7507652171010699		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 0.7507652171010699 | validation: 0.790867484115044]
	TIME [epoch: 1.41 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7626501160903425		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.7626501160903425 | validation: 0.8229550575891095]
	TIME [epoch: 1.41 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7551192455808593		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 0.7551192455808593 | validation: 0.7720839087019318]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7413838260903924		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 0.7413838260903924 | validation: 0.7863226447539979]
	TIME [epoch: 1.4 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7204849981285087		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.7204849981285087 | validation: 0.7621249516616656]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7180111169051361		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.7180111169051361 | validation: 0.765592321263935]
	TIME [epoch: 1.4 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7209780052496231		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 0.7209780052496231 | validation: 0.7653248270496027]
	TIME [epoch: 1.41 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.717707296339113		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 0.717707296339113 | validation: 0.7852971677879937]
	TIME [epoch: 1.4 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7455716845123649		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.7455716845123649 | validation: 0.8779879469420682]
	TIME [epoch: 1.41 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8086569299855347		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.8086569299855347 | validation: 0.8105982795058125]
	TIME [epoch: 1.41 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7888465316800055		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 0.7888465316800055 | validation: 0.8279452592435219]
	TIME [epoch: 1.41 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7475585850843743		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 0.7475585850843743 | validation: 0.7518116694588377]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7283606584544033		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 0.7283606584544033 | validation: 0.8207474626518805]
	TIME [epoch: 1.4 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7327669846618449		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.7327669846618449 | validation: 0.7985295810309907]
	TIME [epoch: 1.41 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8006529727372884		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.8006529727372884 | validation: 0.8512230994760753]
	TIME [epoch: 1.41 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7432409777357156		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.7432409777357156 | validation: 0.7286452950840467]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7171101368595366		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.7171101368595366 | validation: 0.7725264166953884]
	TIME [epoch: 1.4 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7102660838059828		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.7102660838059828 | validation: 0.7648479012136143]
	TIME [epoch: 1.4 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7152166810968518		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 0.7152166810968518 | validation: 0.7773398024459154]
	TIME [epoch: 1.4 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7293733316336187		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 0.7293733316336187 | validation: 0.774880911166464]
	TIME [epoch: 1.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.710130921785577		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.710130921785577 | validation: 0.7658491035685202]
	TIME [epoch: 1.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7190400780998595		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.7190400780998595 | validation: 0.8300446622532965]
	TIME [epoch: 1.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7260742343473026		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.7260742343473026 | validation: 0.7650887242607992]
	TIME [epoch: 1.4 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7563652158089533		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 0.7563652158089533 | validation: 0.9970335733055391]
	TIME [epoch: 1.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8329784639547546		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.8329784639547546 | validation: 0.7694400825059229]
	TIME [epoch: 1.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7418651848739893		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.7418651848739893 | validation: 0.7473060333864691]
	TIME [epoch: 1.4 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7075288058421438		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.7075288058421438 | validation: 0.7573012205878741]
	TIME [epoch: 1.4 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6975667899744987		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.6975667899744987 | validation: 0.7010252594308845]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6970207976409611		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.6970207976409611 | validation: 0.7238374209237028]
	TIME [epoch: 1.41 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6867784533357519		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 0.6867784533357519 | validation: 0.7072712457699315]
	TIME [epoch: 1.41 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6748071076236503		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.6748071076236503 | validation: 0.7087469306622634]
	TIME [epoch: 1.41 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6734885763833564		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.6734885763833564 | validation: 0.7269645089762018]
	TIME [epoch: 1.41 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6693910411154248		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.6693910411154248 | validation: 0.725626054585204]
	TIME [epoch: 1.4 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6908706985053147		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.6908706985053147 | validation: 0.8278204313831691]
	TIME [epoch: 1.41 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7796891172605395		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.7796891172605395 | validation: 0.7770118203307123]
	TIME [epoch: 1.41 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8103078836634048		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 0.8103078836634048 | validation: 0.9343114478045053]
	TIME [epoch: 1.41 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7866073542418821		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.7866073542418821 | validation: 0.715457198193461]
	TIME [epoch: 1.41 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7213614219825262		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.7213614219825262 | validation: 0.6714785063028114]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6770272047388063		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.6770272047388063 | validation: 0.7759247683140275]
	TIME [epoch: 1.4 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6912284064012667		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.6912284064012667 | validation: 0.6845981914300152]
	TIME [epoch: 1.4 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7037600909188559		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.7037600909188559 | validation: 0.7291740042791857]
	TIME [epoch: 1.4 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6727512595044869		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.6727512595044869 | validation: 0.6642011596516048]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6544830231255508		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.6544830231255508 | validation: 0.6514015594298577]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6456883060008081		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.6456883060008081 | validation: 0.7349787244916702]
	TIME [epoch: 1.41 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6515055638738484		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.6515055638738484 | validation: 0.670644654687159]
	TIME [epoch: 1.4 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6964152822254106		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.6964152822254106 | validation: 0.8930700725838729]
	TIME [epoch: 1.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.756846739900075		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 0.756846739900075 | validation: 0.7324431946533703]
	TIME [epoch: 1.4 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7768970780342528		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.7768970780342528 | validation: 0.66381245226873]
	TIME [epoch: 1.4 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.681241966278582		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.681241966278582 | validation: 0.7896356021898039]
	TIME [epoch: 1.41 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6993586374337764		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.6993586374337764 | validation: 0.6419196115317655]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6515498423580232		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 0.6515498423580232 | validation: 0.6227282434361898]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6331573875388771		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.6331573875388771 | validation: 0.6878679597458329]
	TIME [epoch: 1.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6379173307093623		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.6379173307093623 | validation: 0.6251921223461261]
	TIME [epoch: 1.41 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6362406082413058		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.6362406082413058 | validation: 0.7054950536164291]
	TIME [epoch: 1.4 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6400359400728652		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.6400359400728652 | validation: 0.6242341820265058]
	TIME [epoch: 1.4 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6419919771044329		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 0.6419919771044329 | validation: 0.7347307962269349]
	TIME [epoch: 1.4 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.656012808807742		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.656012808807742 | validation: 0.660691024590478]
	TIME [epoch: 1.4 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7187000383865976		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.7187000383865976 | validation: 0.6860828454367898]
	TIME [epoch: 1.4 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6675504616188487		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.6675504616188487 | validation: 0.6076988282910633]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6120658278733212		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.6120658278733212 | validation: 0.5755222823367344]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6032680399750538		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.6032680399750538 | validation: 0.6263860570300545]
	TIME [epoch: 1.41 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5943782665140968		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.5943782665140968 | validation: 0.571524164855853]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6000337503492285		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 0.6000337503492285 | validation: 0.7937914332537108]
	TIME [epoch: 1.41 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6634226715713955		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.6634226715713955 | validation: 0.7602755978606964]
	TIME [epoch: 1.41 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7612054485813861		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.7612054485813861 | validation: 0.5538826484970368]
	TIME [epoch: 1.41 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5901867225316262		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.5901867225316262 | validation: 0.7539226464689073]
	TIME [epoch: 1.41 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6618170160290245		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.6618170160290245 | validation: 0.5806514487709293]
	TIME [epoch: 1.42 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6307464758822394		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.6307464758822394 | validation: 0.5258970170417424]
	TIME [epoch: 1.4 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5734398535298391		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 0.5734398535298391 | validation: 0.6639330024059988]
	TIME [epoch: 270 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.607060027597896		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.607060027597896 | validation: 0.5343566136022443]
	TIME [epoch: 2.79 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6056496897632383		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.6056496897632383 | validation: 0.5634469057204878]
	TIME [epoch: 2.78 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5836244057322842		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.5836244057322842 | validation: 0.5767144997409085]
	TIME [epoch: 2.78 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5732031031181949		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.5732031031181949 | validation: 0.5235403587527536]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5536646399794196		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.5536646399794196 | validation: 0.5334559575672717]
	TIME [epoch: 2.78 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.534289846451887		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.534289846451887 | validation: 0.5082236074465785]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5242429922285657		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.5242429922285657 | validation: 0.5141757995999909]
	TIME [epoch: 2.78 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5190975709106324		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.5190975709106324 | validation: 0.4976013727006809]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5207210385968193		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.5207210385968193 | validation: 0.5261752916318442]
	TIME [epoch: 2.77 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5102864826859136		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.5102864826859136 | validation: 0.462817703083406]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_211.pth
	Model improved!!!
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5285957105680912		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.5285957105680912 | validation: 0.6241725407203753]
	TIME [epoch: 2.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.573136231985175		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.573136231985175 | validation: 0.6793437383605829]
	TIME [epoch: 2.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6473934210794307		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.6473934210794307 | validation: 0.4587265842331927]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_214.pth
	Model improved!!!
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5068639239748015		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.5068639239748015 | validation: 0.5238438660121872]
	TIME [epoch: 2.79 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5092462406129183		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 0.5092462406129183 | validation: 0.48295346701564884]
	TIME [epoch: 2.8 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5234050833386045		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.5234050833386045 | validation: 0.5326208185324995]
	TIME [epoch: 2.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5003443925774462		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.5003443925774462 | validation: 0.4260669776580981]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.47593542471238237		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.47593542471238237 | validation: 0.4406913271816924]
	TIME [epoch: 2.78 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46663012756595224		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.46663012756595224 | validation: 0.4503769018921071]
	TIME [epoch: 2.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48628593168680284		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.48628593168680284 | validation: 0.48657725415643693]
	TIME [epoch: 2.78 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5078401684382331		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.5078401684382331 | validation: 0.4936748754587892]
	TIME [epoch: 2.79 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4836381057534879		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 0.4836381057534879 | validation: 0.4130539064364346]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_223.pth
	Model improved!!!
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45126234923293934		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.45126234923293934 | validation: 0.44150428735582015]
	TIME [epoch: 2.78 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43981273742868227		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.43981273742868227 | validation: 0.39652823103546614]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_225.pth
	Model improved!!!
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4246527066355879		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.4246527066355879 | validation: 0.41394111003202677]
	TIME [epoch: 2.78 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4056498525654243		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.4056498525654243 | validation: 0.38779573294269004]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3967750713120409		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.3967750713120409 | validation: 0.37454779530405996]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3994343279798356		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.3994343279798356 | validation: 0.4796458609754831]
	TIME [epoch: 2.79 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4459968591146475		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.4459968591146475 | validation: 0.5514946433280681]
	TIME [epoch: 2.79 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.53572877389806		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.53572877389806 | validation: 0.7152695800941724]
	TIME [epoch: 2.78 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5371305430436404		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.5371305430436404 | validation: 0.35706852096730035]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3862911788821626		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 0.3862911788821626 | validation: 0.47069479232066347]
	TIME [epoch: 2.77 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4557971574673765		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.4557971574673765 | validation: 0.37921034354689315]
	TIME [epoch: 2.77 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37681236252922623		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.37681236252922623 | validation: 0.39465622580516047]
	TIME [epoch: 2.78 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36080072069672225		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.36080072069672225 | validation: 0.34948918868847806]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3536150210521059		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.3536150210521059 | validation: 0.32329376724686176]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3514389505265125		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.3514389505265125 | validation: 0.33619354805843654]
	TIME [epoch: 2.77 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3374059714056131		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.3374059714056131 | validation: 0.32766511531822035]
	TIME [epoch: 2.78 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34008030062023453		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.34008030062023453 | validation: 0.3685973070347779]
	TIME [epoch: 2.77 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3769272474658004		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.3769272474658004 | validation: 0.3664069349535165]
	TIME [epoch: 2.78 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39905013130034106		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.39905013130034106 | validation: 0.45289157840471717]
	TIME [epoch: 2.78 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37382227577723115		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 0.37382227577723115 | validation: 0.5782408593098912]
	TIME [epoch: 2.78 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3983879659140879		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.3983879659140879 | validation: 0.41676254634354115]
	TIME [epoch: 2.78 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3384082631795181		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.3384082631795181 | validation: 0.3356684191998041]
	TIME [epoch: 2.78 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31084373266895854		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.31084373266895854 | validation: 0.4325760270487413]
	TIME [epoch: 2.78 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37901338389411865		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.37901338389411865 | validation: 0.48853634127158263]
	TIME [epoch: 2.78 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4048159662184323		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.4048159662184323 | validation: 0.42337658021214364]
	TIME [epoch: 2.78 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35900832226230434		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.35900832226230434 | validation: 0.31950592555415014]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29605230754035194		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.29605230754035194 | validation: 0.3788682470411674]
	TIME [epoch: 2.77 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31129646632997965		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.31129646632997965 | validation: 0.38134386769498213]
	TIME [epoch: 2.78 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30112770298991537		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.30112770298991537 | validation: 0.3529624172302357]
	TIME [epoch: 2.77 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3086830112698285		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.3086830112698285 | validation: 0.330677475931613]
	TIME [epoch: 2.78 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3154352348244627		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.3154352348244627 | validation: 0.4107117731105504]
	TIME [epoch: 2.78 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3324944299032507		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.3324944299032507 | validation: 0.4644274956117281]
	TIME [epoch: 2.79 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36546489709631885		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.36546489709631885 | validation: 0.3804619662550481]
	TIME [epoch: 2.78 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4159618498813247		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.4159618498813247 | validation: 0.30552220413793113]
	TIME [epoch: 2.77 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2642162654616781		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.2642162654616781 | validation: 0.33841007301838827]
	TIME [epoch: 2.79 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2934051700159643		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.2934051700159643 | validation: 0.31014510322015776]
	TIME [epoch: 2.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.292880579192636		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.292880579192636 | validation: 0.3137425608231461]
	TIME [epoch: 2.79 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27462146189067527		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.27462146189067527 | validation: 0.2995307806586284]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2724748115383605		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.2724748115383605 | validation: 0.32362687609379204]
	TIME [epoch: 2.79 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28871735215890904		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.28871735215890904 | validation: 0.39741448710674554]
	TIME [epoch: 2.78 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35841029337293895		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.35841029337293895 | validation: 0.3940067046615714]
	TIME [epoch: 2.78 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31669957511305635		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.31669957511305635 | validation: 0.3173409097683171]
	TIME [epoch: 2.79 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2749831334031881		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.2749831334031881 | validation: 0.3203822859613566]
	TIME [epoch: 2.78 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2519998073985488		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.2519998073985488 | validation: 0.2819383593658856]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24516540197370387		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.24516540197370387 | validation: 0.28934503263737205]
	TIME [epoch: 2.79 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2387877214621784		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.2387877214621784 | validation: 0.2761830813968687]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23316792934839242		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.23316792934839242 | validation: 0.2747017339120204]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_270.pth
	Model improved!!!
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23004580995258683		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.23004580995258683 | validation: 0.29280493779537553]
	TIME [epoch: 2.78 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2686242419282428		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.2686242419282428 | validation: 0.4182679448201048]
	TIME [epoch: 2.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45157583699375736		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.45157583699375736 | validation: 0.4889572941621387]
	TIME [epoch: 2.79 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3354824412864408		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.3354824412864408 | validation: 0.32393134971477844]
	TIME [epoch: 2.79 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25251069482864114		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.25251069482864114 | validation: 0.3381917989740491]
	TIME [epoch: 2.79 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28645136037992697		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.28645136037992697 | validation: 0.3302274530155167]
	TIME [epoch: 2.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28699939898853943		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.28699939898853943 | validation: 0.2820470992481746]
	TIME [epoch: 2.79 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23775255287066735		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.23775255287066735 | validation: 0.27765138058186645]
	TIME [epoch: 2.79 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22017366255333864		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.22017366255333864 | validation: 0.2840076029403032]
	TIME [epoch: 2.79 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2325571179024837		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.2325571179024837 | validation: 0.3205589582010755]
	TIME [epoch: 2.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3050629215117071		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.3050629215117071 | validation: 0.4114318239301727]
	TIME [epoch: 2.79 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3371273071037843		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.3371273071037843 | validation: 0.2974930206533575]
	TIME [epoch: 2.79 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29624483434175114		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.29624483434175114 | validation: 0.27570125300524306]
	TIME [epoch: 2.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22685089377007306		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.22685089377007306 | validation: 0.3003361287813613]
	TIME [epoch: 2.79 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2284537084790319		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.2284537084790319 | validation: 0.27106676949923253]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21275976913236377		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.21275976913236377 | validation: 0.27172398311471213]
	TIME [epoch: 2.78 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21429339841194794		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.21429339841194794 | validation: 0.2908730820200512]
	TIME [epoch: 2.79 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31754202245117097		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.31754202245117097 | validation: 0.3505327959906872]
	TIME [epoch: 2.78 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3128449120148779		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 0.3128449120148779 | validation: 0.3526052134428371]
	TIME [epoch: 2.78 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26197597324640254		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.26197597324640254 | validation: 0.30133310035162775]
	TIME [epoch: 2.78 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24202772284044552		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.24202772284044552 | validation: 0.25139391233108505]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21744594072134152		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.21744594072134152 | validation: 0.2643240928534141]
	TIME [epoch: 2.79 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20813804346123693		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.20813804346123693 | validation: 0.26725973616883464]
	TIME [epoch: 2.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21219880478681255		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.21219880478681255 | validation: 0.389736415990805]
	TIME [epoch: 2.79 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27368083448334163		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.27368083448334163 | validation: 0.27511238878426186]
	TIME [epoch: 2.79 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2612627913448346		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.2612627913448346 | validation: 0.2874817209106557]
	TIME [epoch: 2.79 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2408360064162796		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.2408360064162796 | validation: 0.29277030853878705]
	TIME [epoch: 2.78 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25719615584969047		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.25719615584969047 | validation: 0.3512375253926958]
	TIME [epoch: 2.79 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3035553064177007		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.3035553064177007 | validation: 0.2675066303060101]
	TIME [epoch: 2.78 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2494687871931123		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.2494687871931123 | validation: 0.26364921862198515]
	TIME [epoch: 2.78 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19853024239468298		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.19853024239468298 | validation: 0.2566072986999348]
	TIME [epoch: 2.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20672958680488346		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.20672958680488346 | validation: 0.25175885035465095]
	TIME [epoch: 2.79 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19182094741655648		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.19182094741655648 | validation: 0.2573319631808807]
	TIME [epoch: 2.79 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1977815181351412		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.1977815181351412 | validation: 0.23502402234110456]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_304.pth
	Model improved!!!
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1907555666748721		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.1907555666748721 | validation: 0.2541888732374477]
	TIME [epoch: 2.79 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25612039864256464		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.25612039864256464 | validation: 0.3254649356785223]
	TIME [epoch: 2.79 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3081378209007508		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.3081378209007508 | validation: 0.4359970475496507]
	TIME [epoch: 2.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3429356533964512		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.3429356533964512 | validation: 0.3725643688315035]
	TIME [epoch: 2.78 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29103323486524746		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.29103323486524746 | validation: 0.24909552989271258]
	TIME [epoch: 2.79 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21698485007710275		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.21698485007710275 | validation: 0.26332329540354543]
	TIME [epoch: 2.78 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19509064081585067		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.19509064081585067 | validation: 0.26712808525471204]
	TIME [epoch: 2.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21424351580913226		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.21424351580913226 | validation: 0.27306995741307105]
	TIME [epoch: 2.78 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2156124132273669		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.2156124132273669 | validation: 0.27782509142188433]
	TIME [epoch: 2.79 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21424060276406848		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.21424060276406848 | validation: 0.25102891296455737]
	TIME [epoch: 2.78 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20221479344320664		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.20221479344320664 | validation: 0.23914386682524258]
	TIME [epoch: 2.79 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18693123395029898		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.18693123395029898 | validation: 0.23413857104458852]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18064847623373503		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.18064847623373503 | validation: 0.23206886904156604]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17925661023182207		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.17925661023182207 | validation: 0.23597947961587407]
	TIME [epoch: 2.78 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18248253406076445		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.18248253406076445 | validation: 0.23494966103458126]
	TIME [epoch: 2.78 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18679891262883908		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.18679891262883908 | validation: 0.28574240097410153]
	TIME [epoch: 2.79 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2531616939077847		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.2531616939077847 | validation: 0.4082075350794952]
	TIME [epoch: 2.77 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34157534179825677		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.34157534179825677 | validation: 0.25978710343443084]
	TIME [epoch: 2.78 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2432123428762435		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.2432123428762435 | validation: 0.2419247540347206]
	TIME [epoch: 2.78 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18004220508065458		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.18004220508065458 | validation: 0.2455323396720929]
	TIME [epoch: 2.78 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18264616434263278		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.18264616434263278 | validation: 0.24097558099612432]
	TIME [epoch: 2.78 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18193434185869778		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.18193434185869778 | validation: 0.28250139391378837]
	TIME [epoch: 2.78 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23959044031331939		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.23959044031331939 | validation: 0.2716425589486501]
	TIME [epoch: 2.79 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26897189304997826		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.26897189304997826 | validation: 0.24384563876864374]
	TIME [epoch: 2.78 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21850234284381373		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.21850234284381373 | validation: 0.23011684968645885]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_329.pth
	Model improved!!!
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18443896910688837		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.18443896910688837 | validation: 0.2161542595660631]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1725981351009617		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.1725981351009617 | validation: 0.32342972313472046]
	TIME [epoch: 2.79 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25388995002023557		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.25388995002023557 | validation: 0.28530878734827775]
	TIME [epoch: 2.79 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2739390691872121		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.2739390691872121 | validation: 0.27315325578090305]
	TIME [epoch: 2.79 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21414616697244854		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.21414616697244854 | validation: 0.29929790626297864]
	TIME [epoch: 2.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23875330738586123		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.23875330738586123 | validation: 0.26794712051798947]
	TIME [epoch: 2.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2274852685581854		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.2274852685581854 | validation: 0.24621168704717222]
	TIME [epoch: 2.79 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21683516742051676		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.21683516742051676 | validation: 0.23058319217307802]
	TIME [epoch: 2.79 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.185509262152656		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.185509262152656 | validation: 0.22684544732271436]
	TIME [epoch: 2.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17077523550643947		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.17077523550643947 | validation: 0.21368175372114973]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_339.pth
	Model improved!!!
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1651112298114704		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.1651112298114704 | validation: 0.21354815446830086]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1687242973907907		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.1687242973907907 | validation: 0.22911629590718416]
	TIME [epoch: 2.78 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18873691587216065		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.18873691587216065 | validation: 0.20725089338380212]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_342.pth
	Model improved!!!
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16132397998725345		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.16132397998725345 | validation: 0.2485943393355119]
	TIME [epoch: 2.79 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1826490457529293		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.1826490457529293 | validation: 0.25219510136345175]
	TIME [epoch: 2.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21462302423982413		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.21462302423982413 | validation: 0.32496345735938803]
	TIME [epoch: 2.79 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2555235642619367		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.2555235642619367 | validation: 0.24003976177407138]
	TIME [epoch: 2.79 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23873761169536742		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.23873761169536742 | validation: 0.21264972243440786]
	TIME [epoch: 2.79 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16132013691480535		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.16132013691480535 | validation: 0.21163429961335192]
	TIME [epoch: 2.79 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1603063671819395		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.1603063671819395 | validation: 0.206639757637344]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15561716910111587		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.15561716910111587 | validation: 0.20825916321795238]
	TIME [epoch: 2.78 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16221540717076685		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.16221540717076685 | validation: 0.2373060937195792]
	TIME [epoch: 2.78 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19870147778089625		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.19870147778089625 | validation: 0.32894400777327704]
	TIME [epoch: 2.78 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2962429579113971		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.2962429579113971 | validation: 0.23880753605882943]
	TIME [epoch: 2.79 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19289948305988439		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.19289948305988439 | validation: 0.21330279857244064]
	TIME [epoch: 2.78 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15441124615093954		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.15441124615093954 | validation: 0.21277742993366197]
	TIME [epoch: 2.79 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15335188812942296		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.15335188812942296 | validation: 0.20973477938669502]
	TIME [epoch: 2.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15811785568414302		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.15811785568414302 | validation: 0.2410985058871205]
	TIME [epoch: 2.79 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1867236249210046		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.1867236249210046 | validation: 0.25656776450802266]
	TIME [epoch: 2.79 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24932385820533357		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.24932385820533357 | validation: 0.2545482032398728]
	TIME [epoch: 2.78 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19432164673339405		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.19432164673339405 | validation: 0.19642122905195442]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15816220255387156		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.15816220255387156 | validation: 0.2360011313980996]
	TIME [epoch: 2.78 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17713301976215498		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.17713301976215498 | validation: 0.2092111072768429]
	TIME [epoch: 2.79 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17681498138631171		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.17681498138631171 | validation: 0.2371741124258172]
	TIME [epoch: 2.79 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16718081839856594		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.16718081839856594 | validation: 0.2089178956650685]
	TIME [epoch: 2.79 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1596721558180343		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.1596721558180343 | validation: 0.21255776409028995]
	TIME [epoch: 2.79 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1695231012086299		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.1695231012086299 | validation: 0.2602976963599927]
	TIME [epoch: 2.79 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20559774438261003		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.20559774438261003 | validation: 0.2482830214947915]
	TIME [epoch: 2.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20670168656578863		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.20670168656578863 | validation: 0.22610547562248684]
	TIME [epoch: 2.79 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19216033331219834		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.19216033331219834 | validation: 0.22017988920729362]
	TIME [epoch: 2.78 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17848100255099902		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.17848100255099902 | validation: 0.2185027583968342]
	TIME [epoch: 2.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17689131837152375		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.17689131837152375 | validation: 0.20430925813592832]
	TIME [epoch: 2.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14629675145033905		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.14629675145033905 | validation: 0.20178113446895252]
	TIME [epoch: 2.79 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14493000106131285		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.14493000106131285 | validation: 0.2339735152469561]
	TIME [epoch: 2.79 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17858920943488543		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.17858920943488543 | validation: 0.2567275868528377]
	TIME [epoch: 2.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22635812654770845		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.22635812654770845 | validation: 0.247901753186368]
	TIME [epoch: 2.79 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1934878288340672		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.1934878288340672 | validation: 0.19888689934594453]
	TIME [epoch: 2.8 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14576673252002947		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.14576673252002947 | validation: 0.18189784338412962]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_377.pth
	Model improved!!!
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13505510876262222		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.13505510876262222 | validation: 0.21127424453797627]
	TIME [epoch: 2.78 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13976765320817677		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.13976765320817677 | validation: 0.1926621306837776]
	TIME [epoch: 2.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13058664844627102		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.13058664844627102 | validation: 0.17676239942653305]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1307437364563743		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.1307437364563743 | validation: 0.16785218790616152]
	TIME [epoch: 2.78 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1319858094217532		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.1319858094217532 | validation: 0.19187985981762767]
	TIME [epoch: 2.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13663671391222088		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.13663671391222088 | validation: 0.19039840413449177]
	TIME [epoch: 2.79 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14260589505946303		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.14260589505946303 | validation: 0.46744193501808023]
	TIME [epoch: 2.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6480816469699079		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.6480816469699079 | validation: 0.38614536369690433]
	TIME [epoch: 2.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5770582041707347		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.5770582041707347 | validation: 0.21815597730593492]
	TIME [epoch: 2.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31032586912797433		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.31032586912797433 | validation: 0.2795974700389053]
	TIME [epoch: 2.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2181636010500177		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.2181636010500177 | validation: 0.28663070739503455]
	TIME [epoch: 2.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19862516395529783		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.19862516395529783 | validation: 0.21269888339123844]
	TIME [epoch: 2.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1585807119611569		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.1585807119611569 | validation: 0.1974616480981306]
	TIME [epoch: 2.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16013596180220177		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.16013596180220177 | validation: 0.20069990314670583]
	TIME [epoch: 2.79 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1544997631774074		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.1544997631774074 | validation: 0.23739191031661103]
	TIME [epoch: 2.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17389698343997487		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.17389698343997487 | validation: 0.22838530656660538]
	TIME [epoch: 2.79 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16863811609465898		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.16863811609465898 | validation: 0.20978569708502454]
	TIME [epoch: 2.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15155799204201262		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.15155799204201262 | validation: 0.18179329691234153]
	TIME [epoch: 2.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13258873484070882		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.13258873484070882 | validation: 0.192258269016468]
	TIME [epoch: 2.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13370934843344157		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.13370934843344157 | validation: 0.1935230211983505]
	TIME [epoch: 2.79 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13617620537216443		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.13617620537216443 | validation: 0.20911092354308558]
	TIME [epoch: 2.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1411016061184975		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.1411016061184975 | validation: 0.21480122895140696]
	TIME [epoch: 2.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15798733437004317		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.15798733437004317 | validation: 0.22376553629046747]
	TIME [epoch: 2.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15829669301024615		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.15829669301024615 | validation: 0.21081040344848323]
	TIME [epoch: 2.78 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18528119306559782		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.18528119306559782 | validation: 0.2764015506933162]
	TIME [epoch: 2.78 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1983678972475852		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.1983678972475852 | validation: 0.18823248914861523]
	TIME [epoch: 2.77 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13626209645708293		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.13626209645708293 | validation: 0.18696112765153014]
	TIME [epoch: 2.78 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12551482029615432		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.12551482029615432 | validation: 0.18627827486696955]
	TIME [epoch: 2.78 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1257841843641455		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.1257841843641455 | validation: 0.1706984563400273]
	TIME [epoch: 2.79 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13264533903232462		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.13264533903232462 | validation: 0.18805675104271613]
	TIME [epoch: 2.78 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14033685515933494		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.14033685515933494 | validation: 0.21857631444360448]
	TIME [epoch: 2.79 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18962485922819		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.18962485922819 | validation: 0.2484374936557937]
	TIME [epoch: 2.79 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18472215442522083		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.18472215442522083 | validation: 0.18317263805044504]
	TIME [epoch: 2.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12848581192027297		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.12848581192027297 | validation: 0.20032209288314673]
	TIME [epoch: 2.79 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1359331360258551		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.1359331360258551 | validation: 0.19759001135904475]
	TIME [epoch: 2.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.151407671593606		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.151407671593606 | validation: 0.2113266887778462]
	TIME [epoch: 2.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16455542806626305		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.16455542806626305 | validation: 0.18273249815515702]
	TIME [epoch: 2.79 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14042875414367842		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.14042875414367842 | validation: 0.17743741450428355]
	TIME [epoch: 2.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12631932418451758		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.12631932418451758 | validation: 0.16633740087524532]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_416.pth
	Model improved!!!
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11294496789378516		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.11294496789378516 | validation: 0.17689794705175255]
	TIME [epoch: 2.79 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12053822364149254		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.12053822364149254 | validation: 0.1956514018851253]
	TIME [epoch: 2.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1601128879005009		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.1601128879005009 | validation: 0.3200363479815776]
	TIME [epoch: 2.78 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49713529454087624		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.49713529454087624 | validation: 0.20759285687217088]
	TIME [epoch: 2.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3491610922746013		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.3491610922746013 | validation: 0.19958445330777186]
	TIME [epoch: 2.79 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14777487186357077		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.14777487186357077 | validation: 0.2189723753125108]
	TIME [epoch: 2.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16159732669444904		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.16159732669444904 | validation: 0.21507712976526305]
	TIME [epoch: 2.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16662900783381573		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.16662900783381573 | validation: 0.19697490213107002]
	TIME [epoch: 2.79 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1437506028224955		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.1437506028224955 | validation: 0.1706798615416856]
	TIME [epoch: 2.79 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14480301559339237		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.14480301559339237 | validation: 0.18015688625377135]
	TIME [epoch: 2.79 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13395691471519647		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.13395691471519647 | validation: 0.18460258696675336]
	TIME [epoch: 2.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12619756302260532		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.12619756302260532 | validation: 0.1790451444802882]
	TIME [epoch: 2.79 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11418284215040693		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.11418284215040693 | validation: 0.1712967487569372]
	TIME [epoch: 2.79 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12476063040651901		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.12476063040651901 | validation: 0.18882806526934945]
	TIME [epoch: 2.79 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15776325108897607		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.15776325108897607 | validation: 0.2285958187292815]
	TIME [epoch: 2.79 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16037873048438842		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.16037873048438842 | validation: 0.18704355995807997]
	TIME [epoch: 2.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1336918845947466		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.1336918845947466 | validation: 0.18053959785037962]
	TIME [epoch: 2.79 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12064082836710066		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.12064082836710066 | validation: 0.1807446671963689]
	TIME [epoch: 2.78 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14405278630304422		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.14405278630304422 | validation: 0.37275457350327523]
	TIME [epoch: 2.78 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2579127744581717		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.2579127744581717 | validation: 0.16076947606105133]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14855555508695042		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.14855555508695042 | validation: 0.15710342899837035]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11997778368560873		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.11997778368560873 | validation: 0.197097476930263]
	TIME [epoch: 2.79 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12846976564357918		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.12846976564357918 | validation: 0.18621386592442682]
	TIME [epoch: 2.79 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13342521941845395		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.13342521941845395 | validation: 0.19518732833470295]
	TIME [epoch: 2.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1271538223255948		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.1271538223255948 | validation: 0.16323740653399837]
	TIME [epoch: 2.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12956370064248326		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.12956370064248326 | validation: 0.15623069893299887]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10563895603346776		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.10563895603346776 | validation: 0.16017286627961608]
	TIME [epoch: 2.79 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10582592778778117		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.10582592778778117 | validation: 0.1662794435044256]
	TIME [epoch: 3.11 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10657140398042046		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.10657140398042046 | validation: 0.15326790558542053]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11020926507893189		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.11020926507893189 | validation: 0.17672146499717517]
	TIME [epoch: 2.79 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11735183676805858		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.11735183676805858 | validation: 0.17874759949201655]
	TIME [epoch: 2.79 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1167684417271603		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.1167684417271603 | validation: 0.2031257542292221]
	TIME [epoch: 2.79 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13489332871591003		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.13489332871591003 | validation: 0.1933294090372562]
	TIME [epoch: 2.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15307013721018675		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.15307013721018675 | validation: 0.23599612958986899]
	TIME [epoch: 2.8 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16374892723548365		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.16374892723548365 | validation: 0.16013652213257248]
	TIME [epoch: 5.29 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13040927083710352		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.13040927083710352 | validation: 0.23066075310656642]
	TIME [epoch: 2.79 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16238704636402165		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.16238704636402165 | validation: 0.17088734113977463]
	TIME [epoch: 2.79 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13948731752057605		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.13948731752057605 | validation: 0.15168119971964777]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09882894015523976		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.09882894015523976 | validation: 0.18586594447342075]
	TIME [epoch: 2.79 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1259912856021369		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.1259912856021369 | validation: 0.16868973615258254]
	TIME [epoch: 2.79 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1128033875757446		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.1128033875757446 | validation: 0.15005976107252988]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_457.pth
	Model improved!!!
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09883998217890684		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.09883998217890684 | validation: 0.16734483374182285]
	TIME [epoch: 2.79 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1063165947329778		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.1063165947329778 | validation: 0.1659931858845889]
	TIME [epoch: 2.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1068037916910108		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.1068037916910108 | validation: 0.1597089362460622]
	TIME [epoch: 2.79 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09970324296152391		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.09970324296152391 | validation: 0.18569087915857851]
	TIME [epoch: 2.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1210698487544721		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.1210698487544721 | validation: 0.19703030889317683]
	TIME [epoch: 2.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14946503783052098		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.14946503783052098 | validation: 0.22745890073604677]
	TIME [epoch: 2.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1486229672909092		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.1486229672909092 | validation: 0.17246331495964023]
	TIME [epoch: 2.8 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13573736611832046		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.13573736611832046 | validation: 0.17058306002579518]
	TIME [epoch: 2.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.102441427057496		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.102441427057496 | validation: 0.15479547953591405]
	TIME [epoch: 2.8 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09276851928153096		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.09276851928153096 | validation: 0.15253195656128543]
	TIME [epoch: 2.79 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11327110292690616		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.11327110292690616 | validation: 0.17423358215554763]
	TIME [epoch: 2.8 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1110288642491476		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.1110288642491476 | validation: 0.15648984109979713]
	TIME [epoch: 2.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10779356235081704		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.10779356235081704 | validation: 0.1564591137595239]
	TIME [epoch: 2.79 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09796859288432011		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.09796859288432011 | validation: 0.14839278232447997]
	TIME [epoch: 2.8 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_471.pth
	Model improved!!!
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09323715423563869		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.09323715423563869 | validation: 0.1534637716639362]
	TIME [epoch: 2.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09199478700566843		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.09199478700566843 | validation: 0.17236134215131121]
	TIME [epoch: 2.79 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12972421293519948		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.12972421293519948 | validation: 0.22050936033619958]
	TIME [epoch: 2.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14426836738806245		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.14426836738806245 | validation: 0.17234273084119728]
	TIME [epoch: 2.79 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10831176570771316		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.10831176570771316 | validation: 0.16138141821290264]
	TIME [epoch: 2.8 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09957904599363364		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.09957904599363364 | validation: 0.14159801696552843]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_477.pth
	Model improved!!!
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09093246031073225		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.09093246031073225 | validation: 0.14901125060353118]
	TIME [epoch: 2.79 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08878462905679965		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.08878462905679965 | validation: 0.16590714987329858]
	TIME [epoch: 2.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1181584550552724		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.1181584550552724 | validation: 0.19275529839585903]
	TIME [epoch: 2.79 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17874771336892775		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.17874771336892775 | validation: 0.18820993693779067]
	TIME [epoch: 2.79 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12569149456403508		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.12569149456403508 | validation: 0.15216021517129918]
	TIME [epoch: 2.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09048706897306515		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.09048706897306515 | validation: 0.15407412060549347]
	TIME [epoch: 2.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11694783108022008		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.11694783108022008 | validation: 0.22353431838013474]
	TIME [epoch: 2.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14618847737278476		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.14618847737278476 | validation: 0.15465809512245887]
	TIME [epoch: 2.8 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09723873315567567		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.09723873315567567 | validation: 0.15002269207707944]
	TIME [epoch: 2.8 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08976791189088434		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.08976791189088434 | validation: 0.15006158694564545]
	TIME [epoch: 2.8 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0913302921424756		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.0913302921424756 | validation: 0.17013148004766593]
	TIME [epoch: 2.79 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.109055836138571		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.109055836138571 | validation: 0.1727512172572468]
	TIME [epoch: 2.79 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12157532680694338		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.12157532680694338 | validation: 0.19864405811182523]
	TIME [epoch: 2.79 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12020725527323085		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.12020725527323085 | validation: 0.14400538516519898]
	TIME [epoch: 2.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10158056280840574		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.10158056280840574 | validation: 0.19316441338331058]
	TIME [epoch: 2.79 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10590728809893142		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.10590728809893142 | validation: 0.1464094762205464]
	TIME [epoch: 2.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10372632065168634		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.10372632065168634 | validation: 0.15107692969823835]
	TIME [epoch: 2.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09111388245874888		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.09111388245874888 | validation: 0.13318169465948976]
	TIME [epoch: 2.79 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0800872950057766		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.0800872950057766 | validation: 0.14195811462612903]
	TIME [epoch: 2.79 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09862664240955249		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.09862664240955249 | validation: 0.18981668322594658]
	TIME [epoch: 2.79 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11074720047311548		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.11074720047311548 | validation: 0.1549622862478745]
	TIME [epoch: 2.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10495805501000069		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.10495805501000069 | validation: 0.1760898939806385]
	TIME [epoch: 2.79 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10042233462901823		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.10042233462901823 | validation: 0.14380398977537098]
	TIME [epoch: 2.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08836226662939467		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.08836226662939467 | validation: 0.15274363126105384]
	TIME [epoch: 274 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08837951075978338		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.08837951075978338 | validation: 0.14970107077037192]
	TIME [epoch: 5.97 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09135362435894752		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.09135362435894752 | validation: 0.14760420586608733]
	TIME [epoch: 5.97 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08863813400911426		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.08863813400911426 | validation: 0.16530040035946383]
	TIME [epoch: 5.96 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1347577547020566		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.1347577547020566 | validation: 0.21272880771107064]
	TIME [epoch: 5.97 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1324735944198404		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1324735944198404 | validation: 0.13407631007720908]
	TIME [epoch: 5.96 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08680191347132939		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.08680191347132939 | validation: 0.1340874335722708]
	TIME [epoch: 5.98 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08781472960029302		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.08781472960029302 | validation: 0.1679956250544941]
	TIME [epoch: 5.96 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10456868125368014		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.10456868125368014 | validation: 0.1472471743341349]
	TIME [epoch: 5.98 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0955681201680143		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.0955681201680143 | validation: 0.13936414888197377]
	TIME [epoch: 5.97 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08446687993291693		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.08446687993291693 | validation: 0.13466646741299823]
	TIME [epoch: 5.96 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07547744783970237		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.07547744783970237 | validation: 0.1194079970380624]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08856922286778562		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.08856922286778562 | validation: 0.16741250139508]
	TIME [epoch: 5.97 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10226063968130779		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.10226063968130779 | validation: 0.1599013577916399]
	TIME [epoch: 5.98 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12214642640483515		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.12214642640483515 | validation: 0.15029194518319822]
	TIME [epoch: 5.97 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09992601087737518		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.09992601087737518 | validation: 0.13250162008291783]
	TIME [epoch: 5.97 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08484717537161302		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.08484717537161302 | validation: 0.14152313491769922]
	TIME [epoch: 5.97 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08762447802301117		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.08762447802301117 | validation: 0.1525944391052643]
	TIME [epoch: 5.98 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10147496962480805		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.10147496962480805 | validation: 0.14270149963776935]
	TIME [epoch: 5.98 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12028929528413809		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.12028929528413809 | validation: 0.17229036114322072]
	TIME [epoch: 5.98 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1154426039888052		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.1154426039888052 | validation: 0.13619180422725222]
	TIME [epoch: 5.96 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07955393787729595		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.07955393787729595 | validation: 0.13306777326986077]
	TIME [epoch: 5.98 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09100038319890853		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.09100038319890853 | validation: 0.17904406216082178]
	TIME [epoch: 5.97 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10789210062329886		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.10789210062329886 | validation: 0.130590050681465]
	TIME [epoch: 5.98 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08718707837131034		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.08718707837131034 | validation: 0.11342041431145994]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_525.pth
	Model improved!!!
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07168721372976813		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.07168721372976813 | validation: 0.12989807833855813]
	TIME [epoch: 5.97 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07541324118371859		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.07541324118371859 | validation: 0.1292303832890249]
	TIME [epoch: 5.96 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07658658165767478		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.07658658165767478 | validation: 0.15413907617626266]
	TIME [epoch: 5.98 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11382069923949807		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.11382069923949807 | validation: 0.17379505647639296]
	TIME [epoch: 5.97 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12098529524725585		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.12098529524725585 | validation: 0.13322058128710765]
	TIME [epoch: 5.97 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08057429712765654		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.08057429712765654 | validation: 0.12242811388394861]
	TIME [epoch: 5.97 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07266580558604983		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.07266580558604983 | validation: 0.14667811442014353]
	TIME [epoch: 5.97 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0924066630184353		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.0924066630184353 | validation: 0.13185023057139814]
	TIME [epoch: 5.97 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08587353150518608		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.08587353150518608 | validation: 0.1291982293244531]
	TIME [epoch: 5.98 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07070303342467148		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.07070303342467148 | validation: 0.11406640754552666]
	TIME [epoch: 5.98 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08673149999154131		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.08673149999154131 | validation: 0.24524423482926988]
	TIME [epoch: 5.97 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17321753442021895		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.17321753442021895 | validation: 0.13213196989764212]
	TIME [epoch: 5.97 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07506168749280416		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.07506168749280416 | validation: 0.13900987684574084]
	TIME [epoch: 5.98 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10693566727423978		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.10693566727423978 | validation: 0.12122941025783068]
	TIME [epoch: 5.98 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07587362929984469		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.07587362929984469 | validation: 0.13333687450819043]
	TIME [epoch: 5.97 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07350366517273589		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.07350366517273589 | validation: 0.12396068257940383]
	TIME [epoch: 5.99 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07122434462548502		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.07122434462548502 | validation: 0.11834611718295707]
	TIME [epoch: 5.97 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06916779836241632		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.06916779836241632 | validation: 0.12459766815742467]
	TIME [epoch: 5.97 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.076192529053724		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.076192529053724 | validation: 0.12759325224284127]
	TIME [epoch: 5.97 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07903756507840697		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.07903756507840697 | validation: 0.14877169104426696]
	TIME [epoch: 5.97 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07889985567704003		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.07889985567704003 | validation: 0.12052490516925607]
	TIME [epoch: 5.98 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07848699861620854		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.07848699861620854 | validation: 0.15281292036519045]
	TIME [epoch: 5.97 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08821674588448332		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.08821674588448332 | validation: 0.13820270661054082]
	TIME [epoch: 5.97 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08352160225172067		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.08352160225172067 | validation: 0.12891705089952818]
	TIME [epoch: 5.97 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07994032946226945		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.07994032946226945 | validation: 0.12674206104737532]
	TIME [epoch: 5.98 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0678932969591526		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.0678932969591526 | validation: 0.115096100572549]
	TIME [epoch: 5.96 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07148165872740682		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.07148165872740682 | validation: 0.10672444654904337]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_552.pth
	Model improved!!!
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07262518087241426		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.07262518087241426 | validation: 0.13917760647707697]
	TIME [epoch: 5.97 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08442290736039222		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.08442290736039222 | validation: 0.1317233202196846]
	TIME [epoch: 5.97 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08260080154452527		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.08260080154452527 | validation: 0.12469018085427153]
	TIME [epoch: 5.97 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08006552203325987		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.08006552203325987 | validation: 0.12054808345828834]
	TIME [epoch: 5.98 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06528294210108106		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.06528294210108106 | validation: 0.13706870675718902]
	TIME [epoch: 5.97 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.133947001434522		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.133947001434522 | validation: 0.14583856979450702]
	TIME [epoch: 5.97 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09260397269378746		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.09260397269378746 | validation: 0.14517200295642949]
	TIME [epoch: 5.96 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09600943745082959		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.09600943745082959 | validation: 0.13910592427176482]
	TIME [epoch: 5.97 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07413336865530752		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.07413336865530752 | validation: 0.11667723837314102]
	TIME [epoch: 5.97 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07999935737447361		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.07999935737447361 | validation: 0.12691203213465335]
	TIME [epoch: 5.98 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07777622490726416		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.07777622490726416 | validation: 0.11987812563931662]
	TIME [epoch: 5.96 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07252775036271665		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.07252775036271665 | validation: 0.15289945858956244]
	TIME [epoch: 5.97 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08875317155599075		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.08875317155599075 | validation: 0.12984152084704811]
	TIME [epoch: 5.97 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09034614176534259		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.09034614176534259 | validation: 0.11899385933102638]
	TIME [epoch: 5.97 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06368264242930415		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.06368264242930415 | validation: 0.1119291967483666]
	TIME [epoch: 5.96 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07066645685755318		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.07066645685755318 | validation: 0.1170585215117837]
	TIME [epoch: 5.98 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06455717031473591		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.06455717031473591 | validation: 0.12818839502173152]
	TIME [epoch: 5.97 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06489746132224963		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.06489746132224963 | validation: 0.11748514366691452]
	TIME [epoch: 5.97 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0655323622328427		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.0655323622328427 | validation: 0.1044365473763881]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061176106471792155		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.061176106471792155 | validation: 0.11852170314171606]
	TIME [epoch: 5.96 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0674066559462975		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.0674066559462975 | validation: 0.12888680218914922]
	TIME [epoch: 5.96 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07869570226029145		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.07869570226029145 | validation: 0.12692179877716864]
	TIME [epoch: 5.96 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08471811029294461		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.08471811029294461 | validation: 0.12514634269281993]
	TIME [epoch: 5.96 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0725998800869701		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.0725998800869701 | validation: 0.10742846639971791]
	TIME [epoch: 5.97 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0708408288026151		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.0708408288026151 | validation: 0.10938387514684762]
	TIME [epoch: 5.96 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06173291759335787		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.06173291759335787 | validation: 0.09951136892329876]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06085197541792194		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.06085197541792194 | validation: 0.1174471942523363]
	TIME [epoch: 6 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06911215463633803		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.06911215463633803 | validation: 0.12872102382525438]
	TIME [epoch: 6 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09577097611063591		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.09577097611063591 | validation: 0.1384824093680528]
	TIME [epoch: 5.99 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08352193747694213		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.08352193747694213 | validation: 0.12464713274930023]
	TIME [epoch: 5.99 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06881484883508071		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.06881484883508071 | validation: 0.11391827917804394]
	TIME [epoch: 6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0692566725900558		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.0692566725900558 | validation: 0.09957585484575493]
	TIME [epoch: 5.99 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06406900065201712		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.06406900065201712 | validation: 0.14836217840961022]
	TIME [epoch: 6 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13201310778739742		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.13201310778739742 | validation: 0.12772365506882247]
	TIME [epoch: 5.99 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08588169848243908		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.08588169848243908 | validation: 0.10761334487867287]
	TIME [epoch: 6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06875383465452316		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.06875383465452316 | validation: 0.10108239646932043]
	TIME [epoch: 5.99 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06691541670144048		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.06691541670144048 | validation: 0.10367480609364395]
	TIME [epoch: 6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058912523868995655		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.058912523868995655 | validation: 0.10696226377814733]
	TIME [epoch: 5.99 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0679524604777825		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.0679524604777825 | validation: 0.11959960407039319]
	TIME [epoch: 5.99 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07958296292905814		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.07958296292905814 | validation: 0.11163603493262692]
	TIME [epoch: 5.99 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06761228427333295		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.06761228427333295 | validation: 0.13171533941877162]
	TIME [epoch: 6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07753853130220587		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.07753853130220587 | validation: 0.1025371611512856]
	TIME [epoch: 5.99 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05496456960399639		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.05496456960399639 | validation: 0.10081300698891416]
	TIME [epoch: 6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05426223537233935		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.05426223537233935 | validation: 0.09387637527125914]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06040561775455835		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.06040561775455835 | validation: 0.11483642231291552]
	TIME [epoch: 5.97 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06224199639932379		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.06224199639932379 | validation: 0.10389830898039079]
	TIME [epoch: 5.98 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06005748282383772		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.06005748282383772 | validation: 0.11824026472625233]
	TIME [epoch: 6 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06812528540187703		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.06812528540187703 | validation: 0.14257401595244823]
	TIME [epoch: 6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09965131960049442		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.09965131960049442 | validation: 0.12916859924658652]
	TIME [epoch: 5.98 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09020079546667548		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.09020079546667548 | validation: 0.1083039423613363]
	TIME [epoch: 5.97 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057145612141891566		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.057145612141891566 | validation: 0.08685337945448546]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06356805218627551		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.06356805218627551 | validation: 0.1033690673031972]
	TIME [epoch: 5.97 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054767960917066295		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.054767960917066295 | validation: 0.10880947966483645]
	TIME [epoch: 5.99 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057749276191786506		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.057749276191786506 | validation: 0.12868802043469954]
	TIME [epoch: 5.98 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06623156533395516		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.06623156533395516 | validation: 0.1050226172639309]
	TIME [epoch: 5.98 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0645742932037126		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.0645742932037126 | validation: 0.12704948510652722]
	TIME [epoch: 5.97 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06899363862764876		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.06899363862764876 | validation: 0.10618229988892586]
	TIME [epoch: 6.06 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06633312796952648		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.06633312796952648 | validation: 0.11777341502750444]
	TIME [epoch: 5.98 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06084803572783434		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.06084803572783434 | validation: 0.11042107789535222]
	TIME [epoch: 5.98 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06341836431720943		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.06341836431720943 | validation: 0.10028505419026015]
	TIME [epoch: 5.98 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059475815538464254		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.059475815538464254 | validation: 0.101508477491623]
	TIME [epoch: 5.98 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05740971083297932		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.05740971083297932 | validation: 0.10834133325754805]
	TIME [epoch: 5.99 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053917907708794344		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.053917907708794344 | validation: 0.10370700587217696]
	TIME [epoch: 5.99 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05345836868737171		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.05345836868737171 | validation: 0.09253932076129237]
	TIME [epoch: 5.99 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05871618011817382		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.05871618011817382 | validation: 0.11654921948248763]
	TIME [epoch: 5.99 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06898421101184475		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.06898421101184475 | validation: 0.10394991866505246]
	TIME [epoch: 5.99 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06736594560052937		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.06736594560052937 | validation: 0.09975104804059504]
	TIME [epoch: 5.99 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05403646695362308		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.05403646695362308 | validation: 0.09271778579598268]
	TIME [epoch: 5.98 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04867936717622699		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.04867936717622699 | validation: 0.0907480101494455]
	TIME [epoch: 5.98 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05084788933445932		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.05084788933445932 | validation: 0.1012929755287181]
	TIME [epoch: 5.98 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05561160779611244		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.05561160779611244 | validation: 0.1254216606243197]
	TIME [epoch: 5.98 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06837569099962428		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.06837569099962428 | validation: 0.11569548410177144]
	TIME [epoch: 5.98 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07918493714942088		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.07918493714942088 | validation: 0.12771879394780797]
	TIME [epoch: 5.98 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07758218392102079		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.07758218392102079 | validation: 0.10075144155469638]
	TIME [epoch: 5.99 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06411986548410382		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.06411986548410382 | validation: 0.08882353982184808]
	TIME [epoch: 5.98 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049997707855608836		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.049997707855608836 | validation: 0.13348903607489868]
	TIME [epoch: 5.98 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08192835241902661		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.08192835241902661 | validation: 0.11967890300617723]
	TIME [epoch: 5.98 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08058818215535223		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.08058818215535223 | validation: 0.09785698575105056]
	TIME [epoch: 5.98 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05662571982554786		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.05662571982554786 | validation: 0.0843925312238684]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05206853355418424		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.05206853355418424 | validation: 0.10436539860030991]
	TIME [epoch: 5.98 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05357629250829437		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.05357629250829437 | validation: 0.10600283372184682]
	TIME [epoch: 5.99 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0523306645886478		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.0523306645886478 | validation: 0.10459878770314171]
	TIME [epoch: 5.99 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06553942122216441		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.06553942122216441 | validation: 0.09661914920229303]
	TIME [epoch: 5.98 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05077921726515003		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.05077921726515003 | validation: 0.08786236326012965]
	TIME [epoch: 5.99 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0499185281393107		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.0499185281393107 | validation: 0.08718546114482428]
	TIME [epoch: 5.99 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04762535103895154		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.04762535103895154 | validation: 0.10088075199482914]
	TIME [epoch: 6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05276721235352846		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.05276721235352846 | validation: 0.09334235815420648]
	TIME [epoch: 5.99 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05721625586463658		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.05721625586463658 | validation: 0.11381820480545551]
	TIME [epoch: 6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05902367668693815		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.05902367668693815 | validation: 0.10851329954282125]
	TIME [epoch: 5.99 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0740234391280879		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.0740234391280879 | validation: 0.12640329273869244]
	TIME [epoch: 6 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09226730831096741		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.09226730831096741 | validation: 0.09199419611968501]
	TIME [epoch: 5.99 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051383101616181044		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.051383101616181044 | validation: 0.07537199364597391]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04741361173305841		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.04741361173305841 | validation: 0.0770826829174039]
	TIME [epoch: 5.96 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04701003024169264		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.04701003024169264 | validation: 0.10321079305402803]
	TIME [epoch: 5.98 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056175900189679155		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.056175900189679155 | validation: 0.085578927933985]
	TIME [epoch: 6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050456852242626964		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.050456852242626964 | validation: 0.08263523413996418]
	TIME [epoch: 5.99 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05014466274407738		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.05014466274407738 | validation: 0.09357016676230012]
	TIME [epoch: 6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04773620389205002		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.04773620389205002 | validation: 0.08377041530282318]
	TIME [epoch: 6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0442589987762785		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.0442589987762785 | validation: 0.0881524909846319]
	TIME [epoch: 5.99 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06561031097027524		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.06561031097027524 | validation: 0.0965970576800028]
	TIME [epoch: 5.99 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06208758563116486		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.06208758563116486 | validation: 0.09428364307361287]
	TIME [epoch: 5.98 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045897501753653654		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.045897501753653654 | validation: 0.08865497860025666]
	TIME [epoch: 5.99 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06258564281212477		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.06258564281212477 | validation: 0.09413627134573706]
	TIME [epoch: 6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05780683911121849		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.05780683911121849 | validation: 0.0973757149187478]
	TIME [epoch: 5.99 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04878861433855002		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.04878861433855002 | validation: 0.10545422762847428]
	TIME [epoch: 5.99 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05813718292526546		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.05813718292526546 | validation: 0.08027301912646953]
	TIME [epoch: 5.99 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051596657652600054		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.051596657652600054 | validation: 0.10007584381626251]
	TIME [epoch: 6 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05108001132620385		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.05108001132620385 | validation: 0.07825063100636585]
	TIME [epoch: 5.98 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047490508419083505		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.047490508419083505 | validation: 0.095026690737073]
	TIME [epoch: 6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04148712948378206		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.04148712948378206 | validation: 0.07353887575791103]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_662.pth
	Model improved!!!
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04302276083615073		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.04302276083615073 | validation: 0.07818565472121222]
	TIME [epoch: 5.97 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041497972472805233		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.041497972472805233 | validation: 0.08281212786144601]
	TIME [epoch: 5.97 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045980663530573535		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.045980663530573535 | validation: 0.08649969309219654]
	TIME [epoch: 5.97 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05802944384380871		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.05802944384380871 | validation: 0.09103953925199645]
	TIME [epoch: 5.96 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048988271691902265		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.048988271691902265 | validation: 0.08696092679688461]
	TIME [epoch: 5.97 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05168197590329198		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.05168197590329198 | validation: 0.09506615137194752]
	TIME [epoch: 5.97 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06487283068237938		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.06487283068237938 | validation: 0.07532980145998638]
	TIME [epoch: 5.98 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04513231640361729		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.04513231640361729 | validation: 0.10615115066453021]
	TIME [epoch: 5.97 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04995115366795152		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.04995115366795152 | validation: 0.08766417933018754]
	TIME [epoch: 5.97 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04479051016528018		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.04479051016528018 | validation: 0.09148386781977454]
	TIME [epoch: 5.97 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05116389362529758		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.05116389362529758 | validation: 0.09968841206933554]
	TIME [epoch: 5.98 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055250862464707444		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.055250862464707444 | validation: 0.0776996194530087]
	TIME [epoch: 5.97 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04663606081584314		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.04663606081584314 | validation: 0.09603323115219103]
	TIME [epoch: 5.98 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051745380719485486		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.051745380719485486 | validation: 0.09133069819121001]
	TIME [epoch: 5.97 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05743237708200253		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.05743237708200253 | validation: 0.08796287848961959]
	TIME [epoch: 5.98 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054458993134446486		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.054458993134446486 | validation: 0.08763284637872992]
	TIME [epoch: 5.98 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03913948657526389		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.03913948657526389 | validation: 0.08467317082613586]
	TIME [epoch: 5.98 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038709022422606994		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.038709022422606994 | validation: 0.08584546010292936]
	TIME [epoch: 5.97 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05491973383505681		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.05491973383505681 | validation: 0.09529683055329008]
	TIME [epoch: 5.98 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047908404899598314		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.047908404899598314 | validation: 0.07976226937067585]
	TIME [epoch: 5.97 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.042168941433524905		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.042168941433524905 | validation: 0.08293768724048084]
	TIME [epoch: 5.98 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0437642660180258		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.0437642660180258 | validation: 0.08069660253715145]
	TIME [epoch: 5.97 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04396255841467991		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.04396255841467991 | validation: 0.08059318650246339]
	TIME [epoch: 5.98 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04968342797573658		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.04968342797573658 | validation: 0.09315914864936255]
	TIME [epoch: 5.97 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047607237418110245		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.047607237418110245 | validation: 0.08963728918668219]
	TIME [epoch: 5.97 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05134381628712477		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.05134381628712477 | validation: 0.07581576229423583]
	TIME [epoch: 5.99 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05225830609892933		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.05225830609892933 | validation: 0.07824449436923996]
	TIME [epoch: 5.98 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04184849824834431		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.04184849824834431 | validation: 0.09238530227061967]
	TIME [epoch: 5.97 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04424644027761006		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.04424644027761006 | validation: 0.09437071525914047]
	TIME [epoch: 5.99 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.050488635023640656		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.050488635023640656 | validation: 0.084287895248519]
	TIME [epoch: 5.98 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06413805543601482		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.06413805543601482 | validation: 0.09356420525635886]
	TIME [epoch: 5.99 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05287070194322846		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.05287070194322846 | validation: 0.08496278197383816]
	TIME [epoch: 5.98 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.043347881856946754		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.043347881856946754 | validation: 0.07019140339151354]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_695.pth
	Model improved!!!
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03626742456366844		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.03626742456366844 | validation: 0.07178919562720266]
	TIME [epoch: 5.99 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038061495936177824		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.038061495936177824 | validation: 0.06066832015132328]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038885910050759954		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.038885910050759954 | validation: 0.08046061317527586]
	TIME [epoch: 5.98 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03469222920829482		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.03469222920829482 | validation: 0.0795347393786744]
	TIME [epoch: 5.99 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03598983753223165		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.03598983753223165 | validation: 0.0704157879575769]
	TIME [epoch: 5.99 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04555998857304486		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.04555998857304486 | validation: 0.09275981296183078]
	TIME [epoch: 5.98 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04743073982515486		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.04743073982515486 | validation: 0.08343469872806702]
	TIME [epoch: 5.98 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045914062768163934		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.045914062768163934 | validation: 0.07317102950845199]
	TIME [epoch: 5.98 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04025397599073429		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.04025397599073429 | validation: 0.08353711799293354]
	TIME [epoch: 5.98 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049440597138498375		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.049440597138498375 | validation: 0.10518973246063955]
	TIME [epoch: 5.96 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07078737640327779		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.07078737640327779 | validation: 0.06409649579369923]
	TIME [epoch: 5.97 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0397938173051646		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.0397938173051646 | validation: 0.06692479792412474]
	TIME [epoch: 5.97 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04031706695354841		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.04031706695354841 | validation: 0.09064789194885475]
	TIME [epoch: 5.97 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05314175093483067		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.05314175093483067 | validation: 0.10968377953619404]
	TIME [epoch: 5.97 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08091009479752855		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.08091009479752855 | validation: 0.07234065744851938]
	TIME [epoch: 5.98 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03371561921072501		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.03371561921072501 | validation: 0.08990098911643357]
	TIME [epoch: 5.97 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04470396770333693		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.04470396770333693 | validation: 0.08026912038785594]
	TIME [epoch: 5.97 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03563703536275226		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.03563703536275226 | validation: 0.07243049882932866]
	TIME [epoch: 5.97 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03608362220912175		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.03608362220912175 | validation: 0.0825191932538468]
	TIME [epoch: 5.97 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03521564272825843		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.03521564272825843 | validation: 0.0697480051785369]
	TIME [epoch: 5.98 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03807749538762944		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.03807749538762944 | validation: 0.06324851198061175]
	TIME [epoch: 5.98 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03605118392041434		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.03605118392041434 | validation: 0.08187643845941239]
	TIME [epoch: 5.97 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.035461561568568216		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.035461561568568216 | validation: 0.09810754175996528]
	TIME [epoch: 5.98 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053463562939375396		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.053463562939375396 | validation: 0.07655803726659077]
	TIME [epoch: 5.97 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051612866431349415		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.051612866431349415 | validation: 0.06942649600832186]
	TIME [epoch: 5.97 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041855568674913156		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.041855568674913156 | validation: 0.08327736588213543]
	TIME [epoch: 5.97 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03684731103202397		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.03684731103202397 | validation: 0.11620650678836573]
	TIME [epoch: 5.97 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10230166892816463		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.10230166892816463 | validation: 0.0634327875278426]
	TIME [epoch: 5.98 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0415714184850101		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.0415714184850101 | validation: 0.0768971331786578]
	TIME [epoch: 5.98 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04159611659691539		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.04159611659691539 | validation: 0.07675579791093919]
	TIME [epoch: 5.98 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0364443093834962		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.0364443093834962 | validation: 0.07399126402000884]
	TIME [epoch: 5.98 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0344118622037427		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.0344118622037427 | validation: 0.058723457825727125]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04032456183634215		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.04032456183634215 | validation: 0.07876510268337183]
	TIME [epoch: 5.97 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058123643835321634		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.058123643835321634 | validation: 0.052859961296324615]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_729.pth
	Model improved!!!
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03423361666678269		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.03423361666678269 | validation: 0.04780704645739763]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_730.pth
	Model improved!!!
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034858635900976605		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.034858635900976605 | validation: 0.07165142933261462]
	TIME [epoch: 5.97 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03671708526238216		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.03671708526238216 | validation: 0.06508373252660123]
	TIME [epoch: 5.98 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03892397566633837		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.03892397566633837 | validation: 0.06582858071108118]
	TIME [epoch: 5.99 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03346796664191663		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.03346796664191663 | validation: 0.06227524460011216]
	TIME [epoch: 5.98 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.035391335239253245		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.035391335239253245 | validation: 0.07288052106969552]
	TIME [epoch: 5.99 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04074350395723183		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.04074350395723183 | validation: 0.06963008140287848]
	TIME [epoch: 5.98 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05905550273354562		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.05905550273354562 | validation: 0.07834337614161228]
	TIME [epoch: 6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04043212420881211		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.04043212420881211 | validation: 0.07377440974107251]
	TIME [epoch: 5.97 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.044569222019667974		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.044569222019667974 | validation: 0.056359754949053445]
	TIME [epoch: 5.98 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03839034213028866		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.03839034213028866 | validation: 0.06428654048719666]
	TIME [epoch: 5.97 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032337612138958395		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.032337612138958395 | validation: 0.0718474763811076]
	TIME [epoch: 5.98 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03770605553894		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.03770605553894 | validation: 0.07686003563866567]
	TIME [epoch: 5.97 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03929476324996463		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.03929476324996463 | validation: 0.06251593182428682]
	TIME [epoch: 5.98 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03533610231411162		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.03533610231411162 | validation: 0.06443042202106948]
	TIME [epoch: 5.97 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033331756172948576		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.033331756172948576 | validation: 0.06581660329704596]
	TIME [epoch: 5.98 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03323935952720836		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.03323935952720836 | validation: 0.05731248535907745]
	TIME [epoch: 5.97 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033803111942611916		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.033803111942611916 | validation: 0.07835227168844144]
	TIME [epoch: 5.98 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03702299359046249		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.03702299359046249 | validation: 0.09208326233001363]
	TIME [epoch: 5.97 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05713769020164722		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.05713769020164722 | validation: 0.054850186703898775]
	TIME [epoch: 5.99 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04462146557781847		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.04462146557781847 | validation: 0.07464070588921783]
	TIME [epoch: 5.97 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03120142361576007		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.03120142361576007 | validation: 0.07372834195030538]
	TIME [epoch: 5.98 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037248688475843166		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.037248688475843166 | validation: 0.07069596300878438]
	TIME [epoch: 5.97 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03441475535789112		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.03441475535789112 | validation: 0.07498293231229369]
	TIME [epoch: 5.98 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.075792107988986		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.075792107988986 | validation: 0.05696237859800277]
	TIME [epoch: 5.97 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057918664830776144		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.057918664830776144 | validation: 0.06901359884762832]
	TIME [epoch: 5.98 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03811289211759133		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.03811289211759133 | validation: 0.08104056617585252]
	TIME [epoch: 5.97 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038252029648595844		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.038252029648595844 | validation: 0.061913541719833515]
	TIME [epoch: 5.97 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03145607503683165		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.03145607503683165 | validation: 0.05339690380284724]
	TIME [epoch: 5.97 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033531965847617265		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.033531965847617265 | validation: 0.05602591301012784]
	TIME [epoch: 5.98 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02974336907740626		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.02974336907740626 | validation: 0.057529900439791594]
	TIME [epoch: 5.97 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029670356461906904		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.029670356461906904 | validation: 0.06872525482795197]
	TIME [epoch: 5.99 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.032938436381022305		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.032938436381022305 | validation: 0.07771237869600639]
	TIME [epoch: 5.98 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05739949650559556		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.05739949650559556 | validation: 0.05356518048328131]
	TIME [epoch: 5.99 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0330468919109719		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.0330468919109719 | validation: 0.06369964388636731]
	TIME [epoch: 5.98 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03380991192046593		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.03380991192046593 | validation: 0.07290926487248943]
	TIME [epoch: 5.98 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034064334852065954		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.034064334852065954 | validation: 0.05754297094911436]
	TIME [epoch: 5.97 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03150046986508071		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.03150046986508071 | validation: 0.060779293454882526]
	TIME [epoch: 5.98 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03222026840419439		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.03222026840419439 | validation: 0.05730133054246942]
	TIME [epoch: 5.97 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03393997306948178		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.03393997306948178 | validation: 0.08734217977371661]
	TIME [epoch: 5.99 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.045549906585043785		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.045549906585043785 | validation: 0.06894837356244692]
	TIME [epoch: 5.98 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030140178368510462		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.030140178368510462 | validation: 0.0579521261206566]
	TIME [epoch: 5.98 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02816312812178076		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.02816312812178076 | validation: 0.06473846321555711]
	TIME [epoch: 5.97 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03307933618363473		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.03307933618363473 | validation: 0.057768783625047754]
	TIME [epoch: 5.97 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03354538594764921		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.03354538594764921 | validation: 0.05862104296343035]
	TIME [epoch: 5.97 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03036862662356665		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.03036862662356665 | validation: 0.060757008595409515]
	TIME [epoch: 5.98 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03024234429472396		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.03024234429472396 | validation: 0.06066937697530122]
	TIME [epoch: 5.97 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03353568911220507		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.03353568911220507 | validation: 0.08221278003739858]
	TIME [epoch: 5.99 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04857205816454146		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.04857205816454146 | validation: 0.06236334577717006]
	TIME [epoch: 5.97 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03840074330090205		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.03840074330090205 | validation: 0.06595358474765987]
	TIME [epoch: 5.97 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030403646862367066		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.030403646862367066 | validation: 0.07018075159616287]
	TIME [epoch: 5.98 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03670007587871998		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.03670007587871998 | validation: 0.06039493552566516]
	TIME [epoch: 5.97 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05070315374191901		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.05070315374191901 | validation: 0.07159569070283042]
	TIME [epoch: 5.97 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03884954421990855		[learning rate: 0.0007479]
	Learning Rate: 0.000747905
	LOSS [training: 0.03884954421990855 | validation: 0.07185614055997498]
	TIME [epoch: 5.97 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03290450083726237		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.03290450083726237 | validation: 0.0635988447092236]
	TIME [epoch: 5.97 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03575060517790138		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.03575060517790138 | validation: 0.058109216063028074]
	TIME [epoch: 5.97 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031106436698304058		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.031106436698304058 | validation: 0.05265607861716679]
	TIME [epoch: 5.97 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02941790874344972		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.02941790874344972 | validation: 0.06447691497063128]
	TIME [epoch: 5.99 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03128297556662612		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.03128297556662612 | validation: 0.06720690748891713]
	TIME [epoch: 5.97 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0341865940562232		[learning rate: 0.00073218]
	Learning Rate: 0.000732176
	LOSS [training: 0.0341865940562232 | validation: 0.05838546129626651]
	TIME [epoch: 5.97 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03313019529747753		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.03313019529747753 | validation: 0.05884597725798009]
	TIME [epoch: 5.98 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028598952179764908		[learning rate: 0.00072701]
	Learning Rate: 0.000727007
	LOSS [training: 0.028598952179764908 | validation: 0.05882005424377604]
	TIME [epoch: 5.98 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02939969471891951		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.02939969471891951 | validation: 0.05617894935049164]
	TIME [epoch: 5.97 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027948257577292104		[learning rate: 0.00072187]
	Learning Rate: 0.000721874
	LOSS [training: 0.027948257577292104 | validation: 0.058582355440164297]
	TIME [epoch: 5.99 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027954101682263612		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.027954101682263612 | validation: 0.05893831053313351]
	TIME [epoch: 5.99 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037398356400863045		[learning rate: 0.00071678]
	Learning Rate: 0.000716778
	LOSS [training: 0.037398356400863045 | validation: 0.09475401784150167]
	TIME [epoch: 5.99 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05481372085553693		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.05481372085553693 | validation: 0.06018162196279936]
	TIME [epoch: 5.98 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02951735199575976		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.02951735199575976 | validation: 0.06235251818865648]
	TIME [epoch: 5.99 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03905562591818712		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.03905562591818712 | validation: 0.0699157888796119]
	TIME [epoch: 5.98 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03297739963786006		[learning rate: 0.00070669]
	Learning Rate: 0.000706693
	LOSS [training: 0.03297739963786006 | validation: 0.05476917153615556]
	TIME [epoch: 5.97 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02634373630701325		[learning rate: 0.00070419]
	Learning Rate: 0.000704194
	LOSS [training: 0.02634373630701325 | validation: 0.06479512127547993]
	TIME [epoch: 5.97 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028801303518059526		[learning rate: 0.0007017]
	Learning Rate: 0.000701704
	LOSS [training: 0.028801303518059526 | validation: 0.062032125180865566]
	TIME [epoch: 5.99 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027652691394386017		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.027652691394386017 | validation: 0.062405766313748126]
	TIME [epoch: 5.99 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024306283115577382		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.024306283115577382 | validation: 0.057300476295942385]
	TIME [epoch: 5.99 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028919418931922333		[learning rate: 0.00069429]
	Learning Rate: 0.000694286
	LOSS [training: 0.028919418931922333 | validation: 0.06545005844902604]
	TIME [epoch: 6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029103831707989195		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.029103831707989195 | validation: 0.052838811184597136]
	TIME [epoch: 5.99 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028968276836245314		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.028968276836245314 | validation: 0.07079312912938865]
	TIME [epoch: 6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.033029188735414994		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.033029188735414994 | validation: 0.07404748455476118]
	TIME [epoch: 6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.041149771160737314		[learning rate: 0.00068452]
	Learning Rate: 0.000684518
	LOSS [training: 0.041149771160737314 | validation: 0.07747930199496611]
	TIME [epoch: 6.01 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04134812520885719		[learning rate: 0.0006821]
	Learning Rate: 0.000682097
	LOSS [training: 0.04134812520885719 | validation: 0.0495041413550846]
	TIME [epoch: 5.99 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02768390412141638		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.02768390412141638 | validation: 0.05146260048959339]
	TIME [epoch: 5.99 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03001617732374423		[learning rate: 0.00067728]
	Learning Rate: 0.000677282
	LOSS [training: 0.03001617732374423 | validation: 0.060608721712335493]
	TIME [epoch: 6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025403467099762444		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.025403467099762444 | validation: 0.053094136905835025]
	TIME [epoch: 5.99 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026592346190191712		[learning rate: 0.0006725]
	Learning Rate: 0.0006725
	LOSS [training: 0.026592346190191712 | validation: 0.06492726302531929]
	TIME [epoch: 5.99 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025103123841280495		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.025103123841280495 | validation: 0.0564396559887987]
	TIME [epoch: 6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02726835942992207		[learning rate: 0.00066775]
	Learning Rate: 0.000667752
	LOSS [training: 0.02726835942992207 | validation: 0.059795095120205394]
	TIME [epoch: 5.99 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028066454477239572		[learning rate: 0.00066539]
	Learning Rate: 0.000665391
	LOSS [training: 0.028066454477239572 | validation: 0.06165226272226463]
	TIME [epoch: 6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02928592191419579		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.02928592191419579 | validation: 0.059528544230972084]
	TIME [epoch: 6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03071633028375092		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.03071633028375092 | validation: 0.05491358930510021]
	TIME [epoch: 6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03188063358998524		[learning rate: 0.00065836]
	Learning Rate: 0.000658357
	LOSS [training: 0.03188063358998524 | validation: 0.05205485129509037]
	TIME [epoch: 5.99 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03036278828273706		[learning rate: 0.00065603]
	Learning Rate: 0.000656029
	LOSS [training: 0.03036278828273706 | validation: 0.05606081764134799]
	TIME [epoch: 6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024446317090719198		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.024446317090719198 | validation: 0.061929799236095776]
	TIME [epoch: 6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03268195414563875		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.03268195414563875 | validation: 0.07846087932551254]
	TIME [epoch: 6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02880532105117334		[learning rate: 0.00064909]
	Learning Rate: 0.000649094
	LOSS [training: 0.02880532105117334 | validation: 0.07939742239411962]
	TIME [epoch: 6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.038597888876785655		[learning rate: 0.0006468]
	Learning Rate: 0.000646799
	LOSS [training: 0.038597888876785655 | validation: 0.07448784219616163]
	TIME [epoch: 6.06 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02802274117076456		[learning rate: 0.00064451]
	Learning Rate: 0.000644512
	LOSS [training: 0.02802274117076456 | validation: 0.04603376239583467]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025230725725512246		[learning rate: 0.00064223]
	Learning Rate: 0.000642233
	LOSS [training: 0.025230725725512246 | validation: 0.0425275106147121]
	TIME [epoch: 5.95 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_826.pth
	Model improved!!!
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024109741342099388		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.024109741342099388 | validation: 0.05403200165269989]
	TIME [epoch: 5.96 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02451885393120154		[learning rate: 0.0006377]
	Learning Rate: 0.000637699
	LOSS [training: 0.02451885393120154 | validation: 0.060696155794960176]
	TIME [epoch: 5.96 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026325624575412442		[learning rate: 0.00063544]
	Learning Rate: 0.000635443
	LOSS [training: 0.026325624575412442 | validation: 0.04955354009676399]
	TIME [epoch: 5.96 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02335112907525053		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.02335112907525053 | validation: 0.05134151639911452]
	TIME [epoch: 5.96 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028549466746520775		[learning rate: 0.00063096]
	Learning Rate: 0.000630957
	LOSS [training: 0.028549466746520775 | validation: 0.058413485965811675]
	TIME [epoch: 5.98 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04397065748565428		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.04397065748565428 | validation: 0.07325222505510542]
	TIME [epoch: 5.99 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03663303070047103		[learning rate: 0.0006265]
	Learning Rate: 0.000626503
	LOSS [training: 0.03663303070047103 | validation: 0.048483312820642846]
	TIME [epoch: 6.01 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024016440614679984		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.024016440614679984 | validation: 0.04982804245329169]
	TIME [epoch: 6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.034922377199103585		[learning rate: 0.00062208]
	Learning Rate: 0.00062208
	LOSS [training: 0.034922377199103585 | validation: 0.06633807390073089]
	TIME [epoch: 6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031587003176039526		[learning rate: 0.00061988]
	Learning Rate: 0.00061988
	LOSS [training: 0.031587003176039526 | validation: 0.04647360326757134]
	TIME [epoch: 5.99 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02536442888172446		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.02536442888172446 | validation: 0.0440828039128772]
	TIME [epoch: 6 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024454323888898895		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.024454323888898895 | validation: 0.04257028052399925]
	TIME [epoch: 6 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023506448977635538		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.023506448977635538 | validation: 0.053481380387999516]
	TIME [epoch: 5.99 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023978253747595383		[learning rate: 0.00061116]
	Learning Rate: 0.000611158
	LOSS [training: 0.023978253747595383 | validation: 0.04613170591284824]
	TIME [epoch: 6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02236248556331211		[learning rate: 0.000609]
	Learning Rate: 0.000608997
	LOSS [training: 0.02236248556331211 | validation: 0.05482305342478627]
	TIME [epoch: 6.01 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02470901597688096		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.02470901597688096 | validation: 0.05146761116210424]
	TIME [epoch: 5.99 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025272563371306137		[learning rate: 0.0006047]
	Learning Rate: 0.000604698
	LOSS [training: 0.025272563371306137 | validation: 0.03698341817630729]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_843.pth
	Model improved!!!
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02693085884249737		[learning rate: 0.00060256]
	Learning Rate: 0.00060256
	LOSS [training: 0.02693085884249737 | validation: 0.05708381537370776]
	TIME [epoch: 5.96 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02541926477512918		[learning rate: 0.00060043]
	Learning Rate: 0.000600429
	LOSS [training: 0.02541926477512918 | validation: 0.04399860269331496]
	TIME [epoch: 5.96 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024450743101967074		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.024450743101967074 | validation: 0.048805749846561754]
	TIME [epoch: 5.95 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023492314134106296		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.023492314134106296 | validation: 0.05504144637395322]
	TIME [epoch: 5.95 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02502449934857647		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.02502449934857647 | validation: 0.05681892192611916]
	TIME [epoch: 5.95 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024380717753173888		[learning rate: 0.00059198]
	Learning Rate: 0.000591981
	LOSS [training: 0.024380717753173888 | validation: 0.04855542173091087]
	TIME [epoch: 5.95 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.026677852600181393		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.026677852600181393 | validation: 0.06077595502112643]
	TIME [epoch: 5.96 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0315036092593562		[learning rate: 0.0005878]
	Learning Rate: 0.000587802
	LOSS [training: 0.0315036092593562 | validation: 0.06466936888232415]
	TIME [epoch: 5.95 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.030073598441780144		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.030073598441780144 | validation: 0.04726400436934765]
	TIME [epoch: 5.95 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022573963943674464		[learning rate: 0.00058365]
	Learning Rate: 0.000583652
	LOSS [training: 0.022573963943674464 | validation: 0.05151987442477423]
	TIME [epoch: 5.99 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02364148667923149		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.02364148667923149 | validation: 0.06460584908363068]
	TIME [epoch: 6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028228798913708726		[learning rate: 0.00057953]
	Learning Rate: 0.000579531
	LOSS [training: 0.028228798913708726 | validation: 0.057531488594312966]
	TIME [epoch: 6.01 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028829785333207424		[learning rate: 0.00057748]
	Learning Rate: 0.000577482
	LOSS [training: 0.028829785333207424 | validation: 0.06596515573546755]
	TIME [epoch: 6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029381647273755373		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.029381647273755373 | validation: 0.05151767640976081]
	TIME [epoch: 6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0299683785945102		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.0299683785945102 | validation: 0.055777279676719686]
	TIME [epoch: 6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023703602658416072		[learning rate: 0.00057138]
	Learning Rate: 0.000571377
	LOSS [training: 0.023703602658416072 | validation: 0.07865110217038669]
	TIME [epoch: 5.99 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051324340700757885		[learning rate: 0.00056936]
	Learning Rate: 0.000569357
	LOSS [training: 0.051324340700757885 | validation: 0.035753976403376866]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_860.pth
	Model improved!!!
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03715748437372554		[learning rate: 0.00056734]
	Learning Rate: 0.000567344
	LOSS [training: 0.03715748437372554 | validation: 0.05312510208562876]
	TIME [epoch: 5.99 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0234858421428281		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.0234858421428281 | validation: 0.05397279054739033]
	TIME [epoch: 5.98 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025407845650942482		[learning rate: 0.00056334]
	Learning Rate: 0.000563338
	LOSS [training: 0.025407845650942482 | validation: 0.04912293180722364]
	TIME [epoch: 5.99 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02273434442986476		[learning rate: 0.00056135]
	Learning Rate: 0.000561346
	LOSS [training: 0.02273434442986476 | validation: 0.04085344631081035]
	TIME [epoch: 5.99 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021831159430849217		[learning rate: 0.00055936]
	Learning Rate: 0.000559361
	LOSS [training: 0.021831159430849217 | validation: 0.04586658963260845]
	TIME [epoch: 5.99 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02424543076418416		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.02424543076418416 | validation: 0.050587151522542784]
	TIME [epoch: 5.99 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027040043134684996		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.027040043134684996 | validation: 0.06392728707106629]
	TIME [epoch: 5.99 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.037609765855269386		[learning rate: 0.00055345]
	Learning Rate: 0.000553448
	LOSS [training: 0.037609765855269386 | validation: 0.04062625323705421]
	TIME [epoch: 5.98 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02760591194315038		[learning rate: 0.00055149]
	Learning Rate: 0.000551491
	LOSS [training: 0.02760591194315038 | validation: 0.05919837805511156]
	TIME [epoch: 5.99 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023701531858435886		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.023701531858435886 | validation: 0.05451808259971996]
	TIME [epoch: 5.99 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025119367974616117		[learning rate: 0.0005476]
	Learning Rate: 0.000547598
	LOSS [training: 0.025119367974616117 | validation: 0.04229187755123481]
	TIME [epoch: 5.99 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024072931040166005		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.024072931040166005 | validation: 0.043668464663143725]
	TIME [epoch: 5.99 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02446949739445497		[learning rate: 0.00054373]
	Learning Rate: 0.000543732
	LOSS [training: 0.02446949739445497 | validation: 0.03664969846666304]
	TIME [epoch: 5.99 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024588100858800314		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.024588100858800314 | validation: 0.05575280575487279]
	TIME [epoch: 5.99 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025840643768632595		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.025840643768632595 | validation: 0.04253054804441301]
	TIME [epoch: 6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02250406217348617		[learning rate: 0.00053798]
	Learning Rate: 0.000537984
	LOSS [training: 0.02250406217348617 | validation: 0.04652025435473831]
	TIME [epoch: 6.01 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0221978598589417		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.0221978598589417 | validation: 0.05151448137238817]
	TIME [epoch: 6 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025623988812447176		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.025623988812447176 | validation: 0.03357162489891077]
	TIME [epoch: 6 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_878.pth
	Model improved!!!
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02904277417001572		[learning rate: 0.0005323]
	Learning Rate: 0.000532297
	LOSS [training: 0.02904277417001572 | validation: 0.05254756902435163]
	TIME [epoch: 5.99 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024597553783815167		[learning rate: 0.00053041]
	Learning Rate: 0.000530415
	LOSS [training: 0.024597553783815167 | validation: 0.04831980439040519]
	TIME [epoch: 6 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02792862426513129		[learning rate: 0.00052854]
	Learning Rate: 0.000528539
	LOSS [training: 0.02792862426513129 | validation: 0.05796242097909642]
	TIME [epoch: 5.99 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02237162830982654		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.02237162830982654 | validation: 0.06341590701939018]
	TIME [epoch: 6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023344688433611992		[learning rate: 0.00052481]
	Learning Rate: 0.000524808
	LOSS [training: 0.023344688433611992 | validation: 0.0736053510632506]
	TIME [epoch: 5.99 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056116508547931564		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.056116508547931564 | validation: 0.043332203258612326]
	TIME [epoch: 6 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.028092585537615174		[learning rate: 0.0005211]
	Learning Rate: 0.000521102
	LOSS [training: 0.028092585537615174 | validation: 0.05450121624824877]
	TIME [epoch: 5.99 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029912081423422627		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.029912081423422627 | validation: 0.0728121115904009]
	TIME [epoch: 6.01 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03169668781882461		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.03169668781882461 | validation: 0.050247684007227705]
	TIME [epoch: 6 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02240818168091467		[learning rate: 0.00051559]
	Learning Rate: 0.000515594
	LOSS [training: 0.02240818168091467 | validation: 0.049703171422173634]
	TIME [epoch: 6 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.027481306794414465		[learning rate: 0.00051377]
	Learning Rate: 0.000513771
	LOSS [training: 0.027481306794414465 | validation: 0.046635485480675865]
	TIME [epoch: 6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022994013085737387		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.022994013085737387 | validation: 0.06299922663775602]
	TIME [epoch: 6 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021657071516757342		[learning rate: 0.00051014]
	Learning Rate: 0.000510144
	LOSS [training: 0.021657071516757342 | validation: 0.03859980449955051]
	TIME [epoch: 6 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019607275026765122		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.019607275026765122 | validation: 0.04441048761467532]
	TIME [epoch: 6 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02130005086648164		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.02130005086648164 | validation: 0.05005897291056676]
	TIME [epoch: 5.99 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021031751822007193		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.021031751822007193 | validation: 0.048871265302877845]
	TIME [epoch: 6 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02003474543363286		[learning rate: 0.00050297]
	Learning Rate: 0.000502966
	LOSS [training: 0.02003474543363286 | validation: 0.050678853813808204]
	TIME [epoch: 5.99 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021483629292227392		[learning rate: 0.00050119]
	Learning Rate: 0.000501187
	LOSS [training: 0.021483629292227392 | validation: 0.04621166435433025]
	TIME [epoch: 5.99 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02245143535830042		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.02245143535830042 | validation: 0.04892625005014372]
	TIME [epoch: 5.99 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019471524047380367		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.019471524047380367 | validation: 0.03893982790507992]
	TIME [epoch: 6 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021661750705795475		[learning rate: 0.00049589]
	Learning Rate: 0.000495889
	LOSS [training: 0.021661750705795475 | validation: 0.052506111868703104]
	TIME [epoch: 6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02400552681543783		[learning rate: 0.00049414]
	Learning Rate: 0.000494136
	LOSS [training: 0.02400552681543783 | validation: 0.04239934446608722]
	TIME [epoch: 6 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022454084910911946		[learning rate: 0.00049239]
	Learning Rate: 0.000492388
	LOSS [training: 0.022454084910911946 | validation: 0.05714430463666407]
	TIME [epoch: 5.96 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02869757212404343		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.02869757212404343 | validation: 0.04295221526656408]
	TIME [epoch: 5.96 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02341113472935194		[learning rate: 0.00048891]
	Learning Rate: 0.000488912
	LOSS [training: 0.02341113472935194 | validation: 0.039492412739738504]
	TIME [epoch: 5.96 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025663757840264326		[learning rate: 0.00048718]
	Learning Rate: 0.000487183
	LOSS [training: 0.025663757840264326 | validation: 0.04813143280905503]
	TIME [epoch: 5.97 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024359394498203707		[learning rate: 0.00048546]
	Learning Rate: 0.00048546
	LOSS [training: 0.024359394498203707 | validation: 0.0482750466643253]
	TIME [epoch: 5.96 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019940735216181348		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.019940735216181348 | validation: 0.055751659413989935]
	TIME [epoch: 5.97 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02205230434271813		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.02205230434271813 | validation: 0.04133206619587058]
	TIME [epoch: 5.96 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020224401981780743		[learning rate: 0.00048033]
	Learning Rate: 0.000480329
	LOSS [training: 0.020224401981780743 | validation: 0.04072398963753052]
	TIME [epoch: 5.97 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018684625531555758		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.018684625531555758 | validation: 0.041170458236236177]
	TIME [epoch: 5.96 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021538439321820712		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.021538439321820712 | validation: 0.05786401446623582]
	TIME [epoch: 5.97 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023141044997262963		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.023141044997262963 | validation: 0.0448984047147977]
	TIME [epoch: 5.96 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0229867737695118		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.0229867737695118 | validation: 0.05062992540055983]
	TIME [epoch: 5.97 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020529801758813655		[learning rate: 0.0004719]
	Learning Rate: 0.000471896
	LOSS [training: 0.020529801758813655 | validation: 0.05082895965032258]
	TIME [epoch: 5.95 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018953741358359345		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.018953741358359345 | validation: 0.05196781799185082]
	TIME [epoch: 5.97 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021495362260172166		[learning rate: 0.00046856]
	Learning Rate: 0.000468564
	LOSS [training: 0.021495362260172166 | validation: 0.05305589649911834]
	TIME [epoch: 5.96 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054721082358096126		[learning rate: 0.00046691]
	Learning Rate: 0.000466907
	LOSS [training: 0.054721082358096126 | validation: 0.04957561472057679]
	TIME [epoch: 5.97 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021167567176930187		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.021167567176930187 | validation: 0.043260762052658656]
	TIME [epoch: 5.96 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023605874344471527		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.023605874344471527 | validation: 0.041808209958965115]
	TIME [epoch: 5.96 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019694157199454602		[learning rate: 0.00046197]
	Learning Rate: 0.000461972
	LOSS [training: 0.019694157199454602 | validation: 0.032483038851496414]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021411288915075977		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.021411288915075977 | validation: 0.03110882384490561]
	TIME [epoch: 5.99 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_920.pth
	Model improved!!!
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021288708276704704		[learning rate: 0.00045871]
	Learning Rate: 0.00045871
	LOSS [training: 0.021288708276704704 | validation: 0.04639905238323522]
	TIME [epoch: 5.97 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019872501543615324		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.019872501543615324 | validation: 0.0463655011402968]
	TIME [epoch: 5.97 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02026806987430999		[learning rate: 0.00045547]
	Learning Rate: 0.000455472
	LOSS [training: 0.02026806987430999 | validation: 0.03188637746143257]
	TIME [epoch: 5.98 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02004698994480363		[learning rate: 0.00045386]
	Learning Rate: 0.000453861
	LOSS [training: 0.02004698994480363 | validation: 0.03848074673252542]
	TIME [epoch: 5.97 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022523959803295225		[learning rate: 0.00045226]
	Learning Rate: 0.000452256
	LOSS [training: 0.022523959803295225 | validation: 0.03529746799289825]
	TIME [epoch: 5.98 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02130730972945649		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.02130730972945649 | validation: 0.04892207291314106]
	TIME [epoch: 5.98 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.022044309396966978		[learning rate: 0.00044906]
	Learning Rate: 0.000449063
	LOSS [training: 0.022044309396966978 | validation: 0.08241459011152692]
	TIME [epoch: 5.98 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.047533666983554074		[learning rate: 0.00044748]
	Learning Rate: 0.000447476
	LOSS [training: 0.047533666983554074 | validation: 0.04300739951048001]
	TIME [epoch: 5.97 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020832868181962897		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.020832868181962897 | validation: 0.04541956665410327]
	TIME [epoch: 5.98 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.029696543827140338		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.029696543827140338 | validation: 0.04946779677371951]
	TIME [epoch: 5.97 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021152684764901557		[learning rate: 0.00044275]
	Learning Rate: 0.000442745
	LOSS [training: 0.021152684764901557 | validation: 0.03930550756630441]
	TIME [epoch: 5.98 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0180736088667601		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.0180736088667601 | validation: 0.04577752250841219]
	TIME [epoch: 5.97 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021775579892334786		[learning rate: 0.00043962]
	Learning Rate: 0.00043962
	LOSS [training: 0.021775579892334786 | validation: 0.05155955691118369]
	TIME [epoch: 5.98 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.031974084865451086		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.031974084865451086 | validation: 0.043582623955719095]
	TIME [epoch: 5.97 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023881532532322385		[learning rate: 0.00043652]
	Learning Rate: 0.000436516
	LOSS [training: 0.023881532532322385 | validation: 0.035557017151788495]
	TIME [epoch: 5.98 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02180600244577738		[learning rate: 0.00043497]
	Learning Rate: 0.000434972
	LOSS [training: 0.02180600244577738 | validation: 0.043858777216239764]
	TIME [epoch: 5.98 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019750043729902834		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.019750043729902834 | validation: 0.04118935128590726]
	TIME [epoch: 5.98 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017497295170675317		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.017497295170675317 | validation: 0.030962528060874885]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_938.pth
	Model improved!!!
EPOCH 939/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01950846841759031		[learning rate: 0.00043037]
	Learning Rate: 0.000430374
	LOSS [training: 0.01950846841759031 | validation: 0.03479448874430462]
	TIME [epoch: 5.98 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01725926324811083		[learning rate: 0.00042885]
	Learning Rate: 0.000428852
	LOSS [training: 0.01725926324811083 | validation: 0.04356617300796848]
	TIME [epoch: 5.98 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019992653180284745		[learning rate: 0.00042734]
	Learning Rate: 0.000427336
	LOSS [training: 0.019992653180284745 | validation: 0.03444481275586302]
	TIME [epoch: 5.99 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0214174846952798		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.0214174846952798 | validation: 0.03714079864592745]
	TIME [epoch: 5.96 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01929785260114828		[learning rate: 0.00042432]
	Learning Rate: 0.000424319
	LOSS [training: 0.01929785260114828 | validation: 0.0470709491935037]
	TIME [epoch: 5.97 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018391411471012288		[learning rate: 0.00042282]
	Learning Rate: 0.000422818
	LOSS [training: 0.018391411471012288 | validation: 0.07766722834802901]
	TIME [epoch: 5.97 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.048377812142443036		[learning rate: 0.00042132]
	Learning Rate: 0.000421323
	LOSS [training: 0.048377812142443036 | validation: 0.04605359447306681]
	TIME [epoch: 5.98 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019128538532504753		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.019128538532504753 | validation: 0.047712454823433094]
	TIME [epoch: 5.97 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.024110365769231337		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.024110365769231337 | validation: 0.03710175043987857]
	TIME [epoch: 5.99 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018612863298444835		[learning rate: 0.00041687]
	Learning Rate: 0.000416869
	LOSS [training: 0.018612863298444835 | validation: 0.03698880570876039]
	TIME [epoch: 5.97 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01937340600866348		[learning rate: 0.0004154]
	Learning Rate: 0.000415395
	LOSS [training: 0.01937340600866348 | validation: 0.030105927510941145]
	TIME [epoch: 5.98 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_949.pth
	Model improved!!!
EPOCH 950/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018905985266825714		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.018905985266825714 | validation: 0.037718413021008215]
	TIME [epoch: 5.98 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018748267950357857		[learning rate: 0.00041246]
	Learning Rate: 0.000412463
	LOSS [training: 0.018748267950357857 | validation: 0.04687786938919256]
	TIME [epoch: 6.85 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02044761454514226		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.02044761454514226 | validation: 0.042521035925033646]
	TIME [epoch: 5.98 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018570740192116682		[learning rate: 0.00040955]
	Learning Rate: 0.000409551
	LOSS [training: 0.018570740192116682 | validation: 0.03804347566200217]
	TIME [epoch: 5.97 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02244044408827679		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.02244044408827679 | validation: 0.05095287635839703]
	TIME [epoch: 5.98 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020463886770705035		[learning rate: 0.00040666]
	Learning Rate: 0.000406659
	LOSS [training: 0.020463886770705035 | validation: 0.034183419509349965]
	TIME [epoch: 5.98 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01802858637750093		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.01802858637750093 | validation: 0.03744358402085969]
	TIME [epoch: 5.97 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019463969419645785		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.019463969419645785 | validation: 0.03647312541396265]
	TIME [epoch: 5.97 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017412449648281557		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.017412449648281557 | validation: 0.03796485383323389]
	TIME [epoch: 5.97 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021103830929522695		[learning rate: 0.00040094]
	Learning Rate: 0.000400938
	LOSS [training: 0.021103830929522695 | validation: 0.045045901491279454]
	TIME [epoch: 5.97 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018216840990352572		[learning rate: 0.00039952]
	Learning Rate: 0.00039952
	LOSS [training: 0.018216840990352572 | validation: 0.04917994420761329]
	TIME [epoch: 5.98 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017595596601627822		[learning rate: 0.00039811]
	Learning Rate: 0.000398107
	LOSS [training: 0.017595596601627822 | validation: 0.037428224062697094]
	TIME [epoch: 5.97 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016813414717331183		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.016813414717331183 | validation: 0.03896293541232006]
	TIME [epoch: 5.98 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018761175296948606		[learning rate: 0.0003953]
	Learning Rate: 0.000395297
	LOSS [training: 0.018761175296948606 | validation: 0.042888504097191776]
	TIME [epoch: 5.97 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018155782943644044		[learning rate: 0.0003939]
	Learning Rate: 0.000393899
	LOSS [training: 0.018155782943644044 | validation: 0.038886273892400014]
	TIME [epoch: 5.98 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01648949872870314		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.01648949872870314 | validation: 0.02177320047762953]
	TIME [epoch: 5.97 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_965.pth
	Model improved!!!
EPOCH 966/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017335277893883706		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.017335277893883706 | validation: 0.03984828164733382]
	TIME [epoch: 5.97 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019010662117139022		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.019010662117139022 | validation: 0.032738338289496786]
	TIME [epoch: 5.98 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019190914896599784		[learning rate: 0.00038836]
	Learning Rate: 0.000388357
	LOSS [training: 0.019190914896599784 | validation: 0.050549945452018755]
	TIME [epoch: 5.97 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016864043079253502		[learning rate: 0.00038698]
	Learning Rate: 0.000386983
	LOSS [training: 0.016864043079253502 | validation: 0.03785225252291174]
	TIME [epoch: 5.98 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019816199599810597		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.019816199599810597 | validation: 0.03269011612690444]
	TIME [epoch: 5.97 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018819177687703203		[learning rate: 0.00038425]
	Learning Rate: 0.000384251
	LOSS [training: 0.018819177687703203 | validation: 0.04149631947409835]
	TIME [epoch: 5.97 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019597876769766355		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.019597876769766355 | validation: 0.04820218638938678]
	TIME [epoch: 5.97 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018430719315342927		[learning rate: 0.00038154]
	Learning Rate: 0.000381539
	LOSS [training: 0.018430719315342927 | validation: 0.04296731692785079]
	TIME [epoch: 5.98 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018538601482300396		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.018538601482300396 | validation: 0.04331671959267876]
	TIME [epoch: 5.97 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01583370409002241		[learning rate: 0.00037885]
	Learning Rate: 0.000378845
	LOSS [training: 0.01583370409002241 | validation: 0.038198202784039126]
	TIME [epoch: 5.99 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018332776362721397		[learning rate: 0.00037751]
	Learning Rate: 0.000377505
	LOSS [training: 0.018332776362721397 | validation: 0.04751185643044492]
	TIME [epoch: 5.97 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019602892481997456		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.019602892481997456 | validation: 0.0411215946149085]
	TIME [epoch: 5.98 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017577382857629886		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.017577382857629886 | validation: 0.03743848593090409]
	TIME [epoch: 5.98 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02196967250397635		[learning rate: 0.00037351]
	Learning Rate: 0.000373515
	LOSS [training: 0.02196967250397635 | validation: 0.03692841548492858]
	TIME [epoch: 5.98 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017252377174048452		[learning rate: 0.00037219]
	Learning Rate: 0.000372194
	LOSS [training: 0.017252377174048452 | validation: 0.046987447848229474]
	TIME [epoch: 5.96 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019532945091642554		[learning rate: 0.00037088]
	Learning Rate: 0.000370878
	LOSS [training: 0.019532945091642554 | validation: 0.03759598601433128]
	TIME [epoch: 5.96 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015852879525043766		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.015852879525043766 | validation: 0.045475257933064075]
	TIME [epoch: 5.97 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016166171111588756		[learning rate: 0.00036826]
	Learning Rate: 0.000368259
	LOSS [training: 0.016166171111588756 | validation: 0.032480728725724654]
	TIME [epoch: 5.97 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02115598751630298		[learning rate: 0.00036696]
	Learning Rate: 0.000366957
	LOSS [training: 0.02115598751630298 | validation: 0.050235506824201186]
	TIME [epoch: 5.98 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020397576700349595		[learning rate: 0.00036566]
	Learning Rate: 0.00036566
	LOSS [training: 0.020397576700349595 | validation: 0.05130671301091763]
	TIME [epoch: 5.99 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.025920453634132593		[learning rate: 0.00036437]
	Learning Rate: 0.000364367
	LOSS [training: 0.025920453634132593 | validation: 0.03600609868329622]
	TIME [epoch: 5.96 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0220480923773172		[learning rate: 0.00036308]
	Learning Rate: 0.000363078
	LOSS [training: 0.0220480923773172 | validation: 0.03778538066061791]
	TIME [epoch: 5.98 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016468260241958323		[learning rate: 0.00036179]
	Learning Rate: 0.000361794
	LOSS [training: 0.016468260241958323 | validation: 0.03626409801766507]
	TIME [epoch: 5.97 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02041158152332125		[learning rate: 0.00036051]
	Learning Rate: 0.000360515
	LOSS [training: 0.02041158152332125 | validation: 0.0464420358473544]
	TIME [epoch: 5.98 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01654133507975258		[learning rate: 0.00035924]
	Learning Rate: 0.00035924
	LOSS [training: 0.01654133507975258 | validation: 0.03116560985463799]
	TIME [epoch: 5.98 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019262381033025133		[learning rate: 0.00035797]
	Learning Rate: 0.00035797
	LOSS [training: 0.019262381033025133 | validation: 0.03950825868157028]
	TIME [epoch: 5.96 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016880526327044666		[learning rate: 0.0003567]
	Learning Rate: 0.000356704
	LOSS [training: 0.016880526327044666 | validation: 0.034047803975496296]
	TIME [epoch: 5.96 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015380255603142504		[learning rate: 0.00035544]
	Learning Rate: 0.000355442
	LOSS [training: 0.015380255603142504 | validation: 0.036850680261323675]
	TIME [epoch: 5.96 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01794359191174512		[learning rate: 0.00035419]
	Learning Rate: 0.000354185
	LOSS [training: 0.01794359191174512 | validation: 0.03078786214852316]
	TIME [epoch: 5.97 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019218862009688562		[learning rate: 0.00035293]
	Learning Rate: 0.000352933
	LOSS [training: 0.019218862009688562 | validation: 0.03551956128508798]
	TIME [epoch: 5.99 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018540403803099875		[learning rate: 0.00035169]
	Learning Rate: 0.000351685
	LOSS [training: 0.018540403803099875 | validation: 0.03862407280622407]
	TIME [epoch: 5.97 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01850594374883211		[learning rate: 0.00035044]
	Learning Rate: 0.000350441
	LOSS [training: 0.01850594374883211 | validation: 0.039727688712954116]
	TIME [epoch: 5.98 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01751645115064406		[learning rate: 0.0003492]
	Learning Rate: 0.000349202
	LOSS [training: 0.01751645115064406 | validation: 0.03647743635480876]
	TIME [epoch: 5.97 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01775458184829414		[learning rate: 0.00034797]
	Learning Rate: 0.000347967
	LOSS [training: 0.01775458184829414 | validation: 0.04353735707940956]
	TIME [epoch: 5.98 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017219484578155992		[learning rate: 0.00034674]
	Learning Rate: 0.000346737
	LOSS [training: 0.017219484578155992 | validation: 0.0354191300407729]
	TIME [epoch: 5.97 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016543809559200883		[learning rate: 0.00034551]
	Learning Rate: 0.000345511
	LOSS [training: 0.016543809559200883 | validation: 0.04340406528152954]
	TIME [epoch: 288 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019663166483137817		[learning rate: 0.00034429]
	Learning Rate: 0.000344289
	LOSS [training: 0.019663166483137817 | validation: 0.030496967466453008]
	TIME [epoch: 12.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018011292721229113		[learning rate: 0.00034307]
	Learning Rate: 0.000343072
	LOSS [training: 0.018011292721229113 | validation: 0.04218496196909095]
	TIME [epoch: 12.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01611619500719793		[learning rate: 0.00034186]
	Learning Rate: 0.000341858
	LOSS [training: 0.01611619500719793 | validation: 0.03758710621614967]
	TIME [epoch: 12.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019111308800927995		[learning rate: 0.00034065]
	Learning Rate: 0.000340649
	LOSS [training: 0.019111308800927995 | validation: 0.03276708004280041]
	TIME [epoch: 12.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015688264026537817		[learning rate: 0.00033944]
	Learning Rate: 0.000339445
	LOSS [training: 0.015688264026537817 | validation: 0.03208707648642095]
	TIME [epoch: 12.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016037155824817965		[learning rate: 0.00033824]
	Learning Rate: 0.000338245
	LOSS [training: 0.016037155824817965 | validation: 0.03382623813740544]
	TIME [epoch: 12.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01893080359690941		[learning rate: 0.00033705]
	Learning Rate: 0.000337048
	LOSS [training: 0.01893080359690941 | validation: 0.041241378343188584]
	TIME [epoch: 12.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020896006918143098		[learning rate: 0.00033586]
	Learning Rate: 0.000335857
	LOSS [training: 0.020896006918143098 | validation: 0.030982819362358652]
	TIME [epoch: 12.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018185841044437746		[learning rate: 0.00033467]
	Learning Rate: 0.000334669
	LOSS [training: 0.018185841044437746 | validation: 0.06620603745642001]
	TIME [epoch: 12.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.03609243929124113		[learning rate: 0.00033349]
	Learning Rate: 0.000333486
	LOSS [training: 0.03609243929124113 | validation: 0.04832928352670435]
	TIME [epoch: 12.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019700586408649808		[learning rate: 0.00033231]
	Learning Rate: 0.000332306
	LOSS [training: 0.019700586408649808 | validation: 0.03870089448078389]
	TIME [epoch: 12.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.023378834687417638		[learning rate: 0.00033113]
	Learning Rate: 0.000331131
	LOSS [training: 0.023378834687417638 | validation: 0.048697824529150946]
	TIME [epoch: 12.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.019127334883717685		[learning rate: 0.00032996]
	Learning Rate: 0.00032996
	LOSS [training: 0.019127334883717685 | validation: 0.0482706264467874]
	TIME [epoch: 12.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.021350741754022996		[learning rate: 0.00032879]
	Learning Rate: 0.000328793
	LOSS [training: 0.021350741754022996 | validation: 0.03289098837719475]
	TIME [epoch: 12.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015918924729261617		[learning rate: 0.00032763]
	Learning Rate: 0.000327631
	LOSS [training: 0.015918924729261617 | validation: 0.033969276674417924]
	TIME [epoch: 12.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017490330014587427		[learning rate: 0.00032647]
	Learning Rate: 0.000326472
	LOSS [training: 0.017490330014587427 | validation: 0.04552578091526584]
	TIME [epoch: 12.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01637001985968738		[learning rate: 0.00032532]
	Learning Rate: 0.000325318
	LOSS [training: 0.01637001985968738 | validation: 0.03883699246644199]
	TIME [epoch: 12.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016349128615408225		[learning rate: 0.00032417]
	Learning Rate: 0.000324167
	LOSS [training: 0.016349128615408225 | validation: 0.03743601050590525]
	TIME [epoch: 12.7 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016752761976606415		[learning rate: 0.00032302]
	Learning Rate: 0.000323021
	LOSS [training: 0.016752761976606415 | validation: 0.03648876440286487]
	TIME [epoch: 12.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.014580639102303236		[learning rate: 0.00032188]
	Learning Rate: 0.000321879
	LOSS [training: 0.014580639102303236 | validation: 0.03802320457217874]
	TIME [epoch: 12.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016808939249968877		[learning rate: 0.00032074]
	Learning Rate: 0.000320741
	LOSS [training: 0.016808939249968877 | validation: 0.02771312020150625]
	TIME [epoch: 12.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015141100549969934		[learning rate: 0.00031961]
	Learning Rate: 0.000319606
	LOSS [training: 0.015141100549969934 | validation: 0.024269999877878725]
	TIME [epoch: 12.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016730929877582065		[learning rate: 0.00031848]
	Learning Rate: 0.000318476
	LOSS [training: 0.016730929877582065 | validation: 0.03771514218144876]
	TIME [epoch: 12.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017303310007546566		[learning rate: 0.00031735]
	Learning Rate: 0.00031735
	LOSS [training: 0.017303310007546566 | validation: 0.036367942051392765]
	TIME [epoch: 12.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.02190707648740908		[learning rate: 0.00031623]
	Learning Rate: 0.000316228
	LOSS [training: 0.02190707648740908 | validation: 0.03007232876178069]
	TIME [epoch: 12.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015415193351680534		[learning rate: 0.00031511]
	Learning Rate: 0.00031511
	LOSS [training: 0.015415193351680534 | validation: 0.03444595281165632]
	TIME [epoch: 12.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01631555795345231		[learning rate: 0.000314]
	Learning Rate: 0.000313995
	LOSS [training: 0.01631555795345231 | validation: 0.02986506742416575]
	TIME [epoch: 12.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017747453762040188		[learning rate: 0.00031288]
	Learning Rate: 0.000312885
	LOSS [training: 0.017747453762040188 | validation: 0.02914422042071905]
	TIME [epoch: 12.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01593272378526183		[learning rate: 0.00031178]
	Learning Rate: 0.000311779
	LOSS [training: 0.01593272378526183 | validation: 0.028617625000074268]
	TIME [epoch: 12.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017915373041367363		[learning rate: 0.00031068]
	Learning Rate: 0.000310676
	LOSS [training: 0.017915373041367363 | validation: 0.04917147569825291]
	TIME [epoch: 12.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016127550232849144		[learning rate: 0.00030958]
	Learning Rate: 0.000309577
	LOSS [training: 0.016127550232849144 | validation: 0.029329333075303044]
	TIME [epoch: 12.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.014553096743568217		[learning rate: 0.00030848]
	Learning Rate: 0.000308483
	LOSS [training: 0.014553096743568217 | validation: 0.03200075409295128]
	TIME [epoch: 12.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015795994463828643		[learning rate: 0.00030739]
	Learning Rate: 0.000307392
	LOSS [training: 0.015795994463828643 | validation: 0.03798852589021963]
	TIME [epoch: 12.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.014881332522537627		[learning rate: 0.0003063]
	Learning Rate: 0.000306305
	LOSS [training: 0.014881332522537627 | validation: 0.0342771322959182]
	TIME [epoch: 12.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018606049748062927		[learning rate: 0.00030522]
	Learning Rate: 0.000305222
	LOSS [training: 0.018606049748062927 | validation: 0.034174531413694156]
	TIME [epoch: 12.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015846633108853005		[learning rate: 0.00030414]
	Learning Rate: 0.000304142
	LOSS [training: 0.015846633108853005 | validation: 0.02675393725355564]
	TIME [epoch: 12.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01727609725694377		[learning rate: 0.00030307]
	Learning Rate: 0.000303067
	LOSS [training: 0.01727609725694377 | validation: 0.04662999387901417]
	TIME [epoch: 12.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020832118921807818		[learning rate: 0.000302]
	Learning Rate: 0.000301995
	LOSS [training: 0.020832118921807818 | validation: 0.03618153947461805]
	TIME [epoch: 12.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016133857079515163		[learning rate: 0.00030093]
	Learning Rate: 0.000300927
	LOSS [training: 0.016133857079515163 | validation: 0.036862317356751266]
	TIME [epoch: 12.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015315500764305537		[learning rate: 0.00029986]
	Learning Rate: 0.000299863
	LOSS [training: 0.015315500764305537 | validation: 0.03771017049416802]
	TIME [epoch: 12.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013958527024548984		[learning rate: 0.0002988]
	Learning Rate: 0.000298803
	LOSS [training: 0.013958527024548984 | validation: 0.044604050811431685]
	TIME [epoch: 12.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017303961662827754		[learning rate: 0.00029775]
	Learning Rate: 0.000297746
	LOSS [training: 0.017303961662827754 | validation: 0.0354179676403523]
	TIME [epoch: 12.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01692340410327051		[learning rate: 0.00029669]
	Learning Rate: 0.000296693
	LOSS [training: 0.01692340410327051 | validation: 0.03259355795221452]
	TIME [epoch: 12.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01587993071800374		[learning rate: 0.00029564]
	Learning Rate: 0.000295644
	LOSS [training: 0.01587993071800374 | validation: 0.028667402681784138]
	TIME [epoch: 12.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01550826622196205		[learning rate: 0.0002946]
	Learning Rate: 0.000294599
	LOSS [training: 0.01550826622196205 | validation: 0.033190752375763]
	TIME [epoch: 12.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013996588174528557		[learning rate: 0.00029356]
	Learning Rate: 0.000293557
	LOSS [training: 0.013996588174528557 | validation: 0.0323972947940447]
	TIME [epoch: 12.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015013331176420551		[learning rate: 0.00029252]
	Learning Rate: 0.000292519
	LOSS [training: 0.015013331176420551 | validation: 0.02550938453206647]
	TIME [epoch: 12.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.013516088490565119		[learning rate: 0.00029148]
	Learning Rate: 0.000291484
	LOSS [training: 0.013516088490565119 | validation: 0.038386468076609254]
	TIME [epoch: 12.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016849294166594		[learning rate: 0.00029045]
	Learning Rate: 0.000290454
	LOSS [training: 0.016849294166594 | validation: 0.03213657508183922]
	TIME [epoch: 12.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016460401707108066		[learning rate: 0.00028943]
	Learning Rate: 0.000289427
	LOSS [training: 0.016460401707108066 | validation: 0.034779874021914695]
	TIME [epoch: 12.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.014708691183471033		[learning rate: 0.0002884]
	Learning Rate: 0.000288403
	LOSS [training: 0.014708691183471033 | validation: 0.04440616555935098]
	TIME [epoch: 12.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01984321824529476		[learning rate: 0.00028738]
	Learning Rate: 0.000287383
	LOSS [training: 0.01984321824529476 | validation: 0.02986651621809726]
	TIME [epoch: 12.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016568199039012913		[learning rate: 0.00028637]
	Learning Rate: 0.000286367
	LOSS [training: 0.016568199039012913 | validation: 0.038879296359342876]
	TIME [epoch: 12.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.015074844025437458		[learning rate: 0.00028535]
	Learning Rate: 0.000285354
	LOSS [training: 0.015074844025437458 | validation: 0.027348145549041792]
	TIME [epoch: 12.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01652335366976107		[learning rate: 0.00028435]
	Learning Rate: 0.000284345
	LOSS [training: 0.01652335366976107 | validation: 0.032686665355120895]
	TIME [epoch: 12.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0142836585922784		[learning rate: 0.00028334]
	Learning Rate: 0.00028334
	LOSS [training: 0.0142836585922784 | validation: 0.03578006818533339]
	TIME [epoch: 12.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018160117130194747		[learning rate: 0.00028234]
	Learning Rate: 0.000282338
	LOSS [training: 0.018160117130194747 | validation: 0.044671003542364786]
	TIME [epoch: 12.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.017822420691783636		[learning rate: 0.00028134]
	Learning Rate: 0.00028134
	LOSS [training: 0.017822420691783636 | validation: 0.03826837878688188]
	TIME [epoch: 12.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.018389871440624216		[learning rate: 0.00028034]
	Learning Rate: 0.000280345
	LOSS [training: 0.018389871440624216 | validation: 0.034293085559172765]
	TIME [epoch: 12.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01614721001211973		[learning rate: 0.00027935]
	Learning Rate: 0.000279353
	LOSS [training: 0.01614721001211973 | validation: 0.035731569940318064]
	TIME [epoch: 12.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.014330736214764103		[learning rate: 0.00027837]
	Learning Rate: 0.000278366
	LOSS [training: 0.014330736214764103 | validation: 0.04963353890307252]
	TIME [epoch: 12.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.020621738334830803		[learning rate: 0.00027738]
	Learning Rate: 0.000277381
	LOSS [training: 0.020621738334830803 | validation: 0.034535022318393165]
	TIME [epoch: 12.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01711115347672527		[learning rate: 0.0002764]
	Learning Rate: 0.0002764
	LOSS [training: 0.01711115347672527 | validation: 0.031321675325407715]
	TIME [epoch: 12.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.01516352405265176		[learning rate: 0.00027542]
	Learning Rate: 0.000275423
	LOSS [training: 0.01516352405265176 | validation: 0.036041548778916764]
	TIME [epoch: 12.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.016550133040226633		[learning rate: 0.00027445]
	Learning Rate: 0.000274449
	LOSS [training: 0.016550133040226633 | validation: 0.030548504221289463]
	TIME [epoch: 12.7 sec]
	Saving model to: out/model_training/model_phi1_3b_v_mmd1_20241105_164252/states/model_phi1_3b_v_mmd1_1066.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 6133.122 seconds.
