Args:
Namespace(name='model_phi1_1a_v_klv1', outdir='out/model_training/model_phi1_1a_v_klv1', training_data='data/training_data/basic/data_phi1_1a/training', validation_data='data/training_data/basic/data_phi1_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', kernel='multiscale', bw_range=None, optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 821116961

Training model...

Saving initial model state to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 12.096131897770107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 12.096131897770107 | validation: 11.760061064293438]
	TIME [epoch: 411 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.244660639493588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.244660639493588 | validation: 11.79410089740122]
	TIME [epoch: 6.32 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.98514183100029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.98514183100029 | validation: 11.930587862840653]
	TIME [epoch: 6.25 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.71258938236761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.71258938236761 | validation: 11.455479689012098]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.349077865704693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.349077865704693 | validation: 11.978228543420904]
	TIME [epoch: 6.26 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.346229898722818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.346229898722818 | validation: 11.384428542454874]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.15982226771019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.15982226771019 | validation: 11.336922670765164]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.880571048105896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.880571048105896 | validation: 11.324127151309524]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.912044485360592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.912044485360592 | validation: 11.18876710800915]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.711415193737244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.711415193737244 | validation: 11.564119709228653]
	TIME [epoch: 6.26 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.719241448837412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.719241448837412 | validation: 11.080185124915287]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.48068981539011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.48068981539011 | validation: 10.936556925466743]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.384398443348864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.384398443348864 | validation: 10.755757737194827]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.298305945526234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.298305945526234 | validation: 10.569066094019362]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.084510436808216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.084510436808216 | validation: 10.530883055382002]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.542187963382826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.542187963382826 | validation: 8.207946356988913]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.817426694514168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.817426694514168 | validation: 8.16480526851466]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.9516224236828625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9516224236828625 | validation: 7.916983980964613]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.0628624585195166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0628624585195166 | validation: 7.748782547876207]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.478539041971938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.478539041971938 | validation: 7.862982723930524]
	TIME [epoch: 6.25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.675589840738462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.675589840738462 | validation: 7.464991738760697]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.871250865432991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.871250865432991 | validation: 7.4057700535798645]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.34545436279738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.34545436279738 | validation: 7.39292821800851]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.177089605888036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.177089605888036 | validation: 7.3729911690666015]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.294563590977521		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.294563590977521 | validation: 7.121444273459632]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.270157185888807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.270157185888807 | validation: 7.154769106897436]
	TIME [epoch: 6.26 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1893399841460175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1893399841460175 | validation: 6.935179743595192]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.066151948377419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.066151948377419 | validation: 6.839370255959503]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.920441977890005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.920441977890005 | validation: 6.542029902047208]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.750429337204894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.750429337204894 | validation: 6.471983003395969]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.877834211995845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.877834211995845 | validation: 6.473905336739049]
	TIME [epoch: 6.26 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.834301524566537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.834301524566537 | validation: 6.464287452873522]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.993161984969841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.993161984969841 | validation: 6.247375018201084]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.769422986568642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.769422986568642 | validation: 6.272622706460714]
	TIME [epoch: 6.25 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.809030907678764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.809030907678764 | validation: 6.310181132628968]
	TIME [epoch: 6.26 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.551182266065365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551182266065365 | validation: 6.082516013537186]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.756836554774974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.756836554774974 | validation: 5.9660349137538145]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.639933085215936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.639933085215936 | validation: 5.829111227279615]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.555624177423223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.555624177423223 | validation: 5.662648344048977]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.394331580014132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.394331580014132 | validation: 5.534038867785479]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.982701989100967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.982701989100967 | validation: 5.3939363330270576]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.308388972658584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.308388972658584 | validation: 5.942567795672794]
	TIME [epoch: 6.26 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.770038968565261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.770038968565261 | validation: 6.0409737032478645]
	TIME [epoch: 6.26 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.975067166304442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.975067166304442 | validation: 6.1304959834111425]
	TIME [epoch: 6.24 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.020294861856739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.020294861856739 | validation: 4.817981987914056]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.024205771208047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.024205771208047 | validation: 4.730988689151165]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.604108088496721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.604108088496721 | validation: 5.688690286534056]
	TIME [epoch: 6.27 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.196904153822291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.196904153822291 | validation: 4.506525988065204]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365868892907825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.365868892907825 | validation: 4.308798079887568]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.081369390800208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.081369390800208 | validation: 4.2655405465680225]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9749920579937883		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.9749920579937883 | validation: 3.9301780457372804]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.966560041369209		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.966560041369209 | validation: 3.7829580008195762]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7595988757033507		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 3.7595988757033507 | validation: 6.40513886064136]
	TIME [epoch: 6.25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.402945275936967		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 4.402945275936967 | validation: 3.6310538351722483]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6447916945060914		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.6447916945060914 | validation: 4.258232807418523]
	TIME [epoch: 6.26 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9678949836502673		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.9678949836502673 | validation: 3.770794093241456]
	TIME [epoch: 6.25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7156185394364067		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.7156185394364067 | validation: 3.425467159366491]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.475042497015947		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.475042497015947 | validation: 3.972585460155121]
	TIME [epoch: 6.24 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.679978710018889		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.679978710018889 | validation: 3.3329826243464513]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239724017081044		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.239724017081044 | validation: 3.1211839793715503]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2323999634188154		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.2323999634188154 | validation: 4.82187446890474]
	TIME [epoch: 6.27 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4472405192711317		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.4472405192711317 | validation: 4.043229303139048]
	TIME [epoch: 6.26 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1256976154088774		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.1256976154088774 | validation: 3.1005661410597964]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9621314678027737		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.9621314678027737 | validation: 2.809763218939996]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8764297242095385		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.8764297242095385 | validation: 3.3853235057983113]
	TIME [epoch: 6.26 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5849967722630374		[learning rate: 0.0094573]
	Learning Rate: 0.00945735
	LOSS [training: 2.5849967722630374 | validation: 2.472229656896212]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6834963347486616		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.6834963347486616 | validation: 2.288100590744893]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.560078922707371		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.560078922707371 | validation: 3.1939831134263743]
	TIME [epoch: 6.27 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6375918207465183		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.6375918207465183 | validation: 3.270032430332079]
	TIME [epoch: 6.26 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.965685808766984		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.965685808766984 | validation: 2.1539447576372535]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8088886287534756		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.8088886287534756 | validation: 2.6155915728531376]
	TIME [epoch: 6.28 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6652703878386887		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.6652703878386887 | validation: 2.771924167575969]
	TIME [epoch: 6.25 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7892654942788306		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.7892654942788306 | validation: 2.546239351728802]
	TIME [epoch: 6.26 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.547404376294291		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.547404376294291 | validation: 2.7108155079641474]
	TIME [epoch: 6.26 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.588778631514282		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.588778631514282 | validation: 2.6010682762120045]
	TIME [epoch: 6.24 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.520713423730955		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.520713423730955 | validation: 2.1764729365051174]
	TIME [epoch: 6.27 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4380530316101208		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.4380530316101208 | validation: 2.842751878427193]
	TIME [epoch: 6.26 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5970044283374896		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.5970044283374896 | validation: 2.5272878501655027]
	TIME [epoch: 6.25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.216271066045157		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.216271066045157 | validation: 2.094755748254092]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.948576689682464		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.948576689682464 | validation: 2.3466455028865956]
	TIME [epoch: 6.26 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.036429179440176		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.036429179440176 | validation: 2.719656078765339]
	TIME [epoch: 6.26 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9604004910761623		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.9604004910761623 | validation: 2.3295824769759603]
	TIME [epoch: 6.25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8872204919772266		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.8872204919772266 | validation: 1.8891921417775615]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9267267524718301		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.9267267524718301 | validation: 2.8973133122329076]
	TIME [epoch: 6.25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.223999604811389		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.223999604811389 | validation: 1.8353490187992647]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7033647425693594		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.7033647425693594 | validation: 2.017664145844245]
	TIME [epoch: 6.26 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7690118605205054		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.7690118605205054 | validation: 2.9680396823923787]
	TIME [epoch: 6.25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0109461300082843		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.0109461300082843 | validation: 1.4903748409269748]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8222785844568317		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.8222785844568317 | validation: 1.8574157594765945]
	TIME [epoch: 6.25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.787982522348278		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.787982522348278 | validation: 1.9296525687851598]
	TIME [epoch: 6.24 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6604255907933578		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.6604255907933578 | validation: 1.6708821314006237]
	TIME [epoch: 6.26 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9174752362340266		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.9174752362340266 | validation: 2.195870596113537]
	TIME [epoch: 6.25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9888189166088912		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.9888189166088912 | validation: 1.92839794473606]
	TIME [epoch: 6.25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.843160449084241		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.843160449084241 | validation: 2.9758462637547622]
	TIME [epoch: 6.27 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.959576543335864		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.959576543335864 | validation: 2.044297922880661]
	TIME [epoch: 6.25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6130841073649045		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.6130841073649045 | validation: 1.49223324043524]
	TIME [epoch: 6.27 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6287175081159173		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.6287175081159173 | validation: 1.7195762870880964]
	TIME [epoch: 6.25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9827869904327948		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9827869904327948 | validation: 2.0992491293996602]
	TIME [epoch: 6.25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6516269741533849		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.6516269741533849 | validation: 1.751853497377069]
	TIME [epoch: 6.25 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7614203652054572		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.7614203652054572 | validation: 1.691493254127702]
	TIME [epoch: 6.24 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.343670806969258		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.343670806969258 | validation: 1.7205551382969593]
	TIME [epoch: 6.27 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7390540255542641		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.7390540255542641 | validation: 2.094856186550247]
	TIME [epoch: 6.25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4857556170363673		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.4857556170363673 | validation: 2.1708616717021996]
	TIME [epoch: 6.25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8466960053048702		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.8466960053048702 | validation: 1.7723127512996528]
	TIME [epoch: 6.26 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3901315673177574		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.3901315673177574 | validation: 2.647763765072269]
	TIME [epoch: 6.25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.840632235829876		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.840632235829876 | validation: 1.2484434571357066]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3894581274356472		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.3894581274356472 | validation: 2.2219846791754305]
	TIME [epoch: 6.25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6556604222307896		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.6556604222307896 | validation: 1.2899693279381554]
	TIME [epoch: 6.25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6257852893245746		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.6257852893245746 | validation: 3.7213547437582175]
	TIME [epoch: 6.26 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4981208487367357		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.4981208487367357 | validation: 1.518576095163462]
	TIME [epoch: 6.25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3472185318365586		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.3472185318365586 | validation: 4.048290269809648]
	TIME [epoch: 6.26 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3036791673560515		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.3036791673560515 | validation: 2.934560719245627]
	TIME [epoch: 6.25 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9016341725768908		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.9016341725768908 | validation: 1.61695796466226]
	TIME [epoch: 6.25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5476665479299994		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.5476665479299994 | validation: 1.3071292277908113]
	TIME [epoch: 6.25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2386622333557407		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.2386622333557407 | validation: 1.5308099367749768]
	TIME [epoch: 6.24 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4150308673864669		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.4150308673864669 | validation: 1.5684072713832524]
	TIME [epoch: 6.25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3936767926910518		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.3936767926910518 | validation: 1.2156748327349824]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24309670776763		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.24309670776763 | validation: 2.0787939472824486]
	TIME [epoch: 6.26 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5431250689960523		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.5431250689960523 | validation: 1.2099945299092303]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2406278938033715		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.2406278938033715 | validation: 3.0817120841740975]
	TIME [epoch: 6.26 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.954099117058073		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.954099117058073 | validation: 1.6072556859610394]
	TIME [epoch: 6.26 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3057752505682438		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.3057752505682438 | validation: 1.3579410094389637]
	TIME [epoch: 6.25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.715282939812687		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.715282939812687 | validation: 1.9832690499056889]
	TIME [epoch: 6.25 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3487773184730554		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.3487773184730554 | validation: 1.6031565342165512]
	TIME [epoch: 6.25 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4146425921091463		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.4146425921091463 | validation: 1.0856211214742317]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1040778358445185		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.1040778358445185 | validation: 2.189665410893708]
	TIME [epoch: 6.27 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484071869829682		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.484071869829682 | validation: 1.4792044945888547]
	TIME [epoch: 6.26 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.288141969883603		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.288141969883603 | validation: 1.5779471237338947]
	TIME [epoch: 6.26 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4312184672061647		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4312184672061647 | validation: 1.518358779309102]
	TIME [epoch: 6.25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4784035338410888		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.4784035338410888 | validation: 2.2613105504885906]
	TIME [epoch: 6.24 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4403260996526703		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.4403260996526703 | validation: 1.5542100595543027]
	TIME [epoch: 6.26 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4721129159505044		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.4721129159505044 | validation: 2.2416263146763615]
	TIME [epoch: 6.25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.035972868876176		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.035972868876176 | validation: 1.6560446506767779]
	TIME [epoch: 6.26 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2701907736464382		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.2701907736464382 | validation: 1.1892849919427717]
	TIME [epoch: 6.26 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2187801224309194		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.2187801224309194 | validation: 1.070677921004834]
	TIME [epoch: 6.26 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1846054117774423		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.1846054117774423 | validation: 0.9587812544360723]
	TIME [epoch: 6.27 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.169275389509161		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.169275389509161 | validation: 1.9710601578769027]
	TIME [epoch: 6.26 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227700536937369		[learning rate: 0.0073282]
	Learning Rate: 0.00732824
	LOSS [training: 2.227700536937369 | validation: 1.7799896037555958]
	TIME [epoch: 6.27 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.48515198302501		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.48515198302501 | validation: 1.4819303160586639]
	TIME [epoch: 6.25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244359506800264		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.244359506800264 | validation: 1.5091331962270282]
	TIME [epoch: 6.25 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2973195090573342		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2973195090573342 | validation: 1.107761349654074]
	TIME [epoch: 6.28 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4659663299636918		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4659663299636918 | validation: 2.317107724811791]
	TIME [epoch: 6.25 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.661786740407833		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.661786740407833 | validation: 1.5852402228783427]
	TIME [epoch: 6.27 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2731904845283926		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.2731904845283926 | validation: 1.2385475046047274]
	TIME [epoch: 6.26 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9664004097052196		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9664004097052196 | validation: 0.9767448380822792]
	TIME [epoch: 6.26 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.491335910533481		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.491335910533481 | validation: 1.0198540099463622]
	TIME [epoch: 6.26 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3473973723434174		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.3473973723434174 | validation: 1.4029266098568995]
	TIME [epoch: 6.25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1668319724150986		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.1668319724150986 | validation: 1.8836897576716423]
	TIME [epoch: 6.27 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.340028774077128		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.340028774077128 | validation: 0.9491039903011105]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1102417509627183		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1102417509627183 | validation: 1.7494059967869495]
	TIME [epoch: 6.25 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2357805615949846		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2357805615949846 | validation: 1.7976202470189682]
	TIME [epoch: 6.27 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.399814915838483		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.399814915838483 | validation: 1.5079530040671858]
	TIME [epoch: 6.24 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1446425524826513		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.1446425524826513 | validation: 1.4433649176452765]
	TIME [epoch: 6.26 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9943990906126171		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.9943990906126171 | validation: 1.0548258406086881]
	TIME [epoch: 6.26 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6405465625905353		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.6405465625905353 | validation: 1.391549020592034]
	TIME [epoch: 6.25 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1869625886219106		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.1869625886219106 | validation: 1.0341536308182735]
	TIME [epoch: 6.26 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.068689236821931		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.068689236821931 | validation: 2.072708301355999]
	TIME [epoch: 6.25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0526800779290997		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.0526800779290997 | validation: 1.206123849770906]
	TIME [epoch: 6.26 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0329827529895912		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.0329827529895912 | validation: 0.9986793187439021]
	TIME [epoch: 6.25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2584842447688045		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.2584842447688045 | validation: 1.2972169749338103]
	TIME [epoch: 6.25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0538257682894825		[learning rate: 0.0067548]
	Learning Rate: 0.00675484
	LOSS [training: 1.0538257682894825 | validation: 1.6676850133517296]
	TIME [epoch: 6.26 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3514153073416726		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.3514153073416726 | validation: 1.1689069352350918]
	TIME [epoch: 6.25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2119421506619439		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.2119421506619439 | validation: 1.1522710969617553]
	TIME [epoch: 6.26 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0778279547210712		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.0778279547210712 | validation: 1.830410046799012]
	TIME [epoch: 6.26 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2557366495178883		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.2557366495178883 | validation: 1.700199046887226]
	TIME [epoch: 6.24 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9558392443380842		[learning rate: 0.0066363]
	Learning Rate: 0.00663626
	LOSS [training: 0.9558392443380842 | validation: 1.0200375116465943]
	TIME [epoch: 6.25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1164178739406831		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1164178739406831 | validation: 1.2362744689709242]
	TIME [epoch: 6.26 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3343430500128164		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.3343430500128164 | validation: 1.9599371288671539]
	TIME [epoch: 6.25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0444721402776347		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.0444721402776347 | validation: 1.2523005601314963]
	TIME [epoch: 6.26 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.086551867876424		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.086551867876424 | validation: 0.8975813571504223]
	TIME [epoch: 6.25 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8852324539045318		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.8852324539045318 | validation: 0.8628877258233214]
	TIME [epoch: 6.28 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2449912976577382		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2449912976577382 | validation: 2.0103168579093262]
	TIME [epoch: 6.25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3028055065860817		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.3028055065860817 | validation: 1.3331020089163985]
	TIME [epoch: 6.26 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8833579990562086		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.8833579990562086 | validation: 1.2654389365315128]
	TIME [epoch: 6.25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9760792765310422		[learning rate: 0.006428]
	Learning Rate: 0.00642802
	LOSS [training: 0.9760792765310422 | validation: 1.341172935147784]
	TIME [epoch: 6.25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1711290859772054		[learning rate: 0.0064053]
	Learning Rate: 0.00640528
	LOSS [training: 1.1711290859772054 | validation: 1.1806364985680768]
	TIME [epoch: 6.26 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.135042573625882		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.135042573625882 | validation: 1.7529585262945113]
	TIME [epoch: 6.25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1319303827641918		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.1319303827641918 | validation: 1.1122949234972879]
	TIME [epoch: 6.26 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.00721283763233		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.00721283763233 | validation: 2.2048274186131938]
	TIME [epoch: 6.25 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528902096261827		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0528902096261827 | validation: 1.8854809233262555]
	TIME [epoch: 6.25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2737341553772326		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.2737341553772326 | validation: 1.8821225395921934]
	TIME [epoch: 6.26 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3419408893759637		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.3419408893759637 | validation: 1.3604522608358838]
	TIME [epoch: 6.25 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1372389230285735		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.1372389230285735 | validation: 1.2384815328606513]
	TIME [epoch: 6.26 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9617119138027695		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9617119138027695 | validation: 1.277422979896294]
	TIME [epoch: 6.25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.995867986603453		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.995867986603453 | validation: 1.1749840166145793]
	TIME [epoch: 6.25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0421173930108867		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.0421173930108867 | validation: 1.0806437993962317]
	TIME [epoch: 6.26 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1307884273086035		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.1307884273086035 | validation: 1.032418037835818]
	TIME [epoch: 6.24 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9573814633879028		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.9573814633879028 | validation: 1.2107575412517995]
	TIME [epoch: 6.26 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0309347295469973		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0309347295469973 | validation: 1.547560388684021]
	TIME [epoch: 6.26 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901741156166747		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9901741156166747 | validation: 1.3020770099914447]
	TIME [epoch: 6.25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0937862758109187		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.0937862758109187 | validation: 0.8631958666728692]
	TIME [epoch: 6.26 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9377101007010148		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.9377101007010148 | validation: 0.8532159964732082]
	TIME [epoch: 6.24 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_192.pth
	Model improved!!!
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052832215490505		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.052832215490505 | validation: 1.530792236706087]
	TIME [epoch: 6.26 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438736813836424		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.438736813836424 | validation: 2.133609799411934]
	TIME [epoch: 6.26 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7702321825429044		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.7702321825429044 | validation: 2.7888626618534786]
	TIME [epoch: 6.25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.635886336423215		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.635886336423215 | validation: 1.3627477778946466]
	TIME [epoch: 6.26 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933195784771684		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.1933195784771684 | validation: 1.4001132966956664]
	TIME [epoch: 6.24 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2217679390669907		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.2217679390669907 | validation: 1.410532078028377]
	TIME [epoch: 6.26 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9298087499244728		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.9298087499244728 | validation: 1.070156638212132]
	TIME [epoch: 6.25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0918888053758833		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0918888053758833 | validation: 1.038441619688314]
	TIME [epoch: 6.24 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684666286271639		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.9684666286271639 | validation: 1.0225279097036721]
	TIME [epoch: 434 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8896823746486695		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8896823746486695 | validation: 0.9839467781641316]
	TIME [epoch: 12.4 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9997618744587784		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9997618744587784 | validation: 1.2821012819281892]
	TIME [epoch: 12.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0429953880060718		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.0429953880060718 | validation: 0.9651156736206539]
	TIME [epoch: 12.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9390920772977785		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.9390920772977785 | validation: 1.3060751795039027]
	TIME [epoch: 12.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0438636208829166		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0438636208829166 | validation: 1.143006469912263]
	TIME [epoch: 12.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8144409485824537		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8144409485824537 | validation: 0.9071146503449268]
	TIME [epoch: 12.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8703313689689416		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8703313689689416 | validation: 1.2323685050833735]
	TIME [epoch: 12.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006380085662641		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.006380085662641 | validation: 1.8310764907037442]
	TIME [epoch: 12.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686675203747804		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.0686675203747804 | validation: 0.7692370374401583]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_210.pth
	Model improved!!!
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135545493601096		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7135545493601096 | validation: 0.8431813393100548]
	TIME [epoch: 12.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1949743512395927		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.1949743512395927 | validation: 1.059437760015512]
	TIME [epoch: 12.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.221683069570396		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.221683069570396 | validation: 1.6192858922954332]
	TIME [epoch: 12.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0392080497290754		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.0392080497290754 | validation: 0.8876315509784471]
	TIME [epoch: 12.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8136160490274427		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8136160490274427 | validation: 0.9786230833654521]
	TIME [epoch: 12.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155860390773221		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.155860390773221 | validation: 0.8505559418579771]
	TIME [epoch: 12.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152312839642368		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8152312839642368 | validation: 0.7109939374742588]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6653711624029275		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.6653711624029275 | validation: 0.6553737282296861]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.666736389276984		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.666736389276984 | validation: 1.4825714199347044]
	TIME [epoch: 12.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8477089775354203		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.8477089775354203 | validation: 0.7844848833764941]
	TIME [epoch: 12.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6419963825658611		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.6419963825658611 | validation: 0.9794667750320112]
	TIME [epoch: 12.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8897370007105757		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.8897370007105757 | validation: 0.7998840422013607]
	TIME [epoch: 12.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8617481649284293		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.8617481649284293 | validation: 1.142431127733497]
	TIME [epoch: 12.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0572538363510904		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.0572538363510904 | validation: 0.9521558680837561]
	TIME [epoch: 12.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7411577669918374		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.7411577669918374 | validation: 0.814537142709965]
	TIME [epoch: 12.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9466937494915847		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.9466937494915847 | validation: 1.2377662037675248]
	TIME [epoch: 12.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92949721471526		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.92949721471526 | validation: 0.6736238928829594]
	TIME [epoch: 12.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5891248568714398		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.5891248568714398 | validation: 1.0959042833586268]
	TIME [epoch: 12.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.88215489994949		[learning rate: 0.0053088]
	Learning Rate: 0.00530884
	LOSS [training: 0.88215489994949 | validation: 0.9070312413122474]
	TIME [epoch: 12.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9052897793127518		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9052897793127518 | validation: 0.6365628899487061]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5942873306384503		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.5942873306384503 | validation: 2.063112884131503]
	TIME [epoch: 12.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4208329051243354		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.4208329051243354 | validation: 1.0871261533395429]
	TIME [epoch: 12.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9589137663222471		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9589137663222471 | validation: 0.8795653440647957]
	TIME [epoch: 12.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8129141127340325		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8129141127340325 | validation: 0.8894724551612783]
	TIME [epoch: 12.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9415244398299567		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.9415244398299567 | validation: 0.9454858880366046]
	TIME [epoch: 12.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7747179165909968		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7747179165909968 | validation: 1.1817830262755367]
	TIME [epoch: 12.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7171064498158931		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.7171064498158931 | validation: 0.9899366014828087]
	TIME [epoch: 12.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7374450409270885		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.7374450409270885 | validation: 1.4429372586206108]
	TIME [epoch: 12.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9850584837176376		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.9850584837176376 | validation: 0.7854928597571583]
	TIME [epoch: 12.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008978691593323		[learning rate: 0.005106]
	Learning Rate: 0.00510595
	LOSS [training: 0.6008978691593323 | validation: 0.5702916400987083]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113542111284568		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7113542111284568 | validation: 0.5290286661190853]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399194241687195		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.6399194241687195 | validation: 0.6210404013234507]
	TIME [epoch: 12.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7472328868075155		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7472328868075155 | validation: 0.7198965852186305]
	TIME [epoch: 12.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507936082270878		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6507936082270878 | validation: 0.624615167582513]
	TIME [epoch: 12.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5990225401493252		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.5990225401493252 | validation: 0.7525574291220258]
	TIME [epoch: 12.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9635435374479022		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.9635435374479022 | validation: 1.0751788075347435]
	TIME [epoch: 12.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7485324902140603		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7485324902140603 | validation: 0.9477770554862168]
	TIME [epoch: 12.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.770564549454124		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.770564549454124 | validation: 1.805086492146447]
	TIME [epoch: 12.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9615535183982774		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.9615535183982774 | validation: 1.0439811614724466]
	TIME [epoch: 12.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9150481093761115		[learning rate: 0.0049282]
	Learning Rate: 0.00492825
	LOSS [training: 0.9150481093761115 | validation: 0.9785028658304779]
	TIME [epoch: 12.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8055332224879842		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8055332224879842 | validation: 0.8796559056836293]
	TIME [epoch: 12.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6373810725721587		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6373810725721587 | validation: 0.7769369311015866]
	TIME [epoch: 12.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7433874179945098		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7433874179945098 | validation: 1.0559757473494495]
	TIME [epoch: 12.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820682010848679		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6820682010848679 | validation: 1.1355146640429146]
	TIME [epoch: 12.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7145208052678025		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7145208052678025 | validation: 0.7756082550655887]
	TIME [epoch: 12.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6397145666741004		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6397145666741004 | validation: 0.9277050680384078]
	TIME [epoch: 12.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6089391852178292		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6089391852178292 | validation: 0.8568947675360435]
	TIME [epoch: 12.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886558073568105		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6886558073568105 | validation: 0.7574167909617923]
	TIME [epoch: 12.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5997516607552533		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.5997516607552533 | validation: 0.5077725437971066]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4850313910696074		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.4850313910696074 | validation: 0.8692891544413127]
	TIME [epoch: 12.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6698193671376382		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6698193671376382 | validation: 0.7531509122727909]
	TIME [epoch: 12.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7066092238571838		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7066092238571838 | validation: 0.6115592383844932]
	TIME [epoch: 12.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099398115418473		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5099398115418473 | validation: 0.8132895627623896]
	TIME [epoch: 12.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5275232664873044		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.5275232664873044 | validation: 0.8860638621011137]
	TIME [epoch: 12.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7149539057560212		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7149539057560212 | validation: 0.8471674003141358]
	TIME [epoch: 12.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092078961457779		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6092078961457779 | validation: 0.5849276810669395]
	TIME [epoch: 12.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6766105928890691		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6766105928890691 | validation: 0.5392477712208844]
	TIME [epoch: 12.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8758176905883635		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8758176905883635 | validation: 0.9388386872289604]
	TIME [epoch: 12.3 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7612552106782459		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7612552106782459 | validation: 1.2164332821955983]
	TIME [epoch: 12.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762823467149486		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6762823467149486 | validation: 0.5526712639743444]
	TIME [epoch: 12.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441822460902213		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5441822460902213 | validation: 0.5972686301554967]
	TIME [epoch: 12.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9148426687056574		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.9148426687056574 | validation: 0.4722254982660663]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_272.pth
	Model improved!!!
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6249982216635714		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6249982216635714 | validation: 0.9869011008998987]
	TIME [epoch: 12.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7720719468563073		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7720719468563073 | validation: 0.692883559377082]
	TIME [epoch: 12.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0026159066807792		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0026159066807792 | validation: 0.9486760753074406]
	TIME [epoch: 12.3 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9839574681859342		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.9839574681859342 | validation: 0.6830007895152234]
	TIME [epoch: 12.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6345994385579757		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6345994385579757 | validation: 0.6610973003447634]
	TIME [epoch: 12.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5276730354009576		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5276730354009576 | validation: 0.9402819280447337]
	TIME [epoch: 12.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7977237566775416		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7977237566775416 | validation: 1.2682357349431128]
	TIME [epoch: 12.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9753737384678953		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.9753737384678953 | validation: 0.8466577335974866]
	TIME [epoch: 12.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013482108039952		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7013482108039952 | validation: 0.8317623258788965]
	TIME [epoch: 12.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7145548249584387		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7145548249584387 | validation: 0.6703622100795693]
	TIME [epoch: 12.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5705641831046804		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5705641831046804 | validation: 0.48427638526763994]
	TIME [epoch: 12.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6400529638469886		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.6400529638469886 | validation: 0.9581645565010655]
	TIME [epoch: 12.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6579331618839063		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.6579331618839063 | validation: 1.0256843312721737]
	TIME [epoch: 12.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678303521773713		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6678303521773713 | validation: 0.5345209673018351]
	TIME [epoch: 12.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6667431358616298		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6667431358616298 | validation: 0.6233801641138936]
	TIME [epoch: 12.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570238131045363		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.570238131045363 | validation: 0.33735589776449215]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6483140541324934		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.6483140541324934 | validation: 1.454649001935333]
	TIME [epoch: 12.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1626631310658304		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.1626631310658304 | validation: 0.7445486496474265]
	TIME [epoch: 12.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200811117081808		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5200811117081808 | validation: 0.42088296550986615]
	TIME [epoch: 12.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7117210037668629		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7117210037668629 | validation: 0.6964890748357297]
	TIME [epoch: 12.3 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5824685444279383		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.5824685444279383 | validation: 0.5184600738743862]
	TIME [epoch: 12.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48198210506175676		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.48198210506175676 | validation: 0.8987348688841392]
	TIME [epoch: 12.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884636175115842		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5884636175115842 | validation: 0.8067763104553374]
	TIME [epoch: 12.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5772871775466882		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5772871775466882 | validation: 0.5289366864652488]
	TIME [epoch: 12.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620235032299683		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5620235032299683 | validation: 0.4787368265858394]
	TIME [epoch: 12.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541034214509664		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.541034214509664 | validation: 0.6780051917230115]
	TIME [epoch: 12.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014142968617745		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5014142968617745 | validation: 0.520809437808772]
	TIME [epoch: 12.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4884654362663766		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.4884654362663766 | validation: 0.7464727743971333]
	TIME [epoch: 12.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5130610608419853		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5130610608419853 | validation: 0.5788777417618401]
	TIME [epoch: 12.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8168669292422523		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.8168669292422523 | validation: 0.5361584829674689]
	TIME [epoch: 12.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4796563882598486		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.4796563882598486 | validation: 0.4717129661542585]
	TIME [epoch: 12.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015198938768373		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.4015198938768373 | validation: 0.400998851337963]
	TIME [epoch: 12.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5802956141966786		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5802956141966786 | validation: 0.8013942242649417]
	TIME [epoch: 12.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.727268892415304		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.727268892415304 | validation: 0.46867772430229065]
	TIME [epoch: 12.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513369833903408		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.4513369833903408 | validation: 0.5131151404158538]
	TIME [epoch: 12.3 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38176995971438354		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.38176995971438354 | validation: 0.7564206388224335]
	TIME [epoch: 12.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9414347060843826		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.9414347060843826 | validation: 0.4567242179302798]
	TIME [epoch: 12.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7872405132197935		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.7872405132197935 | validation: 0.5774571668944439]
	TIME [epoch: 12.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5671671378164751		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.5671671378164751 | validation: 0.8936838039937548]
	TIME [epoch: 12.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6577742244606422		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.6577742244606422 | validation: 0.6933766525875412]
	TIME [epoch: 12.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47184558680453714		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.47184558680453714 | validation: 0.5359811107080479]
	TIME [epoch: 12.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154814969510075		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.4154814969510075 | validation: 0.5567344081608057]
	TIME [epoch: 12.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6310860235352899		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6310860235352899 | validation: 0.45678182462801087]
	TIME [epoch: 12.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929765031911961		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.3929765031911961 | validation: 0.49955768255526123]
	TIME [epoch: 12.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5717316970722026		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5717316970722026 | validation: 0.5548032896398694]
	TIME [epoch: 12.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9085559178506735		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.9085559178506735 | validation: 0.9648413085112442]
	TIME [epoch: 12.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.961731518020662		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.961731518020662 | validation: 0.5544833677842701]
	TIME [epoch: 12.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.660700841164729		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.660700841164729 | validation: 0.7384747418345816]
	TIME [epoch: 12.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6732623652810936		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6732623652810936 | validation: 0.8353958758579059]
	TIME [epoch: 12.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6720637765680839		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6720637765680839 | validation: 0.5769402695708727]
	TIME [epoch: 12.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5668976803909672		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5668976803909672 | validation: 0.8894491703778347]
	TIME [epoch: 12.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7579924320286064		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.7579924320286064 | validation: 0.5706976205054566]
	TIME [epoch: 12.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8518538830211252		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8518538830211252 | validation: 1.2243217735545848]
	TIME [epoch: 12.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431606204745405		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.8431606204745405 | validation: 0.5831355419686776]
	TIME [epoch: 12.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.473460504699251		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.473460504699251 | validation: 0.43635634838612647]
	TIME [epoch: 12.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40556009912112145		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.40556009912112145 | validation: 0.43509497427154975]
	TIME [epoch: 12.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4448008467162715		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.4448008467162715 | validation: 0.4580721866409827]
	TIME [epoch: 12.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821865185474755		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4821865185474755 | validation: 0.8468032989208992]
	TIME [epoch: 12.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474797678114152		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5474797678114152 | validation: 0.5810304125847471]
	TIME [epoch: 12.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46403272452390565		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.46403272452390565 | validation: 0.5047513705246646]
	TIME [epoch: 12.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4332710157814702		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.4332710157814702 | validation: 0.41195472740534417]
	TIME [epoch: 12.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421906590414875		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.6421906590414875 | validation: 0.48901482752059744]
	TIME [epoch: 12.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5983309280641922		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5983309280641922 | validation: 0.752161998750004]
	TIME [epoch: 12.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522091110721884		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.522091110721884 | validation: 0.6285139660685832]
	TIME [epoch: 12.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43753583339553515		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.43753583339553515 | validation: 0.4249242703188494]
	TIME [epoch: 12.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011957744569182		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5011957744569182 | validation: 0.4237198862619765]
	TIME [epoch: 12.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45380665062828196		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.45380665062828196 | validation: 1.178478807692057]
	TIME [epoch: 12.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109427201589619		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5109427201589619 | validation: 0.3246014894902455]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4289865156550159		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.4289865156550159 | validation: 0.8860970503925467]
	TIME [epoch: 12.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724770185705229		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6724770185705229 | validation: 0.5446466725778701]
	TIME [epoch: 12.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4674566265577973		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.4674566265577973 | validation: 0.4421786031608058]
	TIME [epoch: 12.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5948569303465379		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5948569303465379 | validation: 0.5250665551081937]
	TIME [epoch: 12.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685465544368936		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.6685465544368936 | validation: 0.5245226524044584]
	TIME [epoch: 12.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5457403879335199		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5457403879335199 | validation: 0.3546123630420387]
	TIME [epoch: 12.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5281935283054834		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5281935283054834 | validation: 0.9205555671133381]
	TIME [epoch: 12.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5487144993810764		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5487144993810764 | validation: 0.642943515488122]
	TIME [epoch: 12.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4931777749941101		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.4931777749941101 | validation: 0.5299057867106721]
	TIME [epoch: 12.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003855733692913		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5003855733692913 | validation: 0.6040413010461436]
	TIME [epoch: 12.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174435564628346		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4174435564628346 | validation: 0.46717811568624756]
	TIME [epoch: 12.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4635481718643247		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4635481718643247 | validation: 0.5417835119554405]
	TIME [epoch: 12.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3960501781435403		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.3960501781435403 | validation: 0.592051007707525]
	TIME [epoch: 12.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38579253146777065		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.38579253146777065 | validation: 0.5468564006646371]
	TIME [epoch: 12.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41119507812335176		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.41119507812335176 | validation: 0.4207599657164809]
	TIME [epoch: 12.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46587379864123246		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.46587379864123246 | validation: 0.3346299980576028]
	TIME [epoch: 12.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391400036880663		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.3391400036880663 | validation: 0.4981807516590633]
	TIME [epoch: 12.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35621697492770144		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.35621697492770144 | validation: 0.5219906418334802]
	TIME [epoch: 12.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38175187812069505		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.38175187812069505 | validation: 0.3840466721783533]
	TIME [epoch: 12.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130878716372981		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.4130878716372981 | validation: 0.4026407121104135]
	TIME [epoch: 12.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46452525533363026		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.46452525533363026 | validation: 0.5056869618108043]
	TIME [epoch: 12.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47759468975191105		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.47759468975191105 | validation: 0.4557538660821334]
	TIME [epoch: 12.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108089824682691		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6108089824682691 | validation: 0.33666354361157147]
	TIME [epoch: 12.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35679981682193285		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.35679981682193285 | validation: 0.353482630632863]
	TIME [epoch: 12.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39203271859658084		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.39203271859658084 | validation: 0.41077185249387865]
	TIME [epoch: 12.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906206728945672		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.3906206728945672 | validation: 0.5786652400180565]
	TIME [epoch: 12.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4073575618571123		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4073575618571123 | validation: 0.627956856753662]
	TIME [epoch: 12.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48927276179727786		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.48927276179727786 | validation: 0.9369879293531814]
	TIME [epoch: 12.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5531196573859216		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.5531196573859216 | validation: 0.8331491758202826]
	TIME [epoch: 12.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44763171459244144		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.44763171459244144 | validation: 0.6790221910939859]
	TIME [epoch: 12.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258394322407163		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5258394322407163 | validation: 0.6407051117965874]
	TIME [epoch: 12.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5582471756825573		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5582471756825573 | validation: 0.5228964629819512]
	TIME [epoch: 12.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46421257583222614		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.46421257583222614 | validation: 0.8404889691659163]
	TIME [epoch: 12.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574332072648596		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5574332072648596 | validation: 0.4444044064461573]
	TIME [epoch: 12.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.355348913467037		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.355348913467037 | validation: 0.3270498071542016]
	TIME [epoch: 12.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32681074193648435		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.32681074193648435 | validation: 0.6697689749341226]
	TIME [epoch: 12.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171043359783294		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5171043359783294 | validation: 0.8518748000397702]
	TIME [epoch: 12.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48185638864264163		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.48185638864264163 | validation: 0.3113409390343015]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405921226571324		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.3405921226571324 | validation: 0.32453356768751046]
	TIME [epoch: 12.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43915094079180933		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.43915094079180933 | validation: 0.460347429088874]
	TIME [epoch: 12.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3201746759896409		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.3201746759896409 | validation: 0.5551335074855575]
	TIME [epoch: 12.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4018252076410514		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.4018252076410514 | validation: 0.7067071208977076]
	TIME [epoch: 12.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45003944637587795		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.45003944637587795 | validation: 0.28802727055751]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_383.pth
	Model improved!!!
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35596995269685633		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.35596995269685633 | validation: 0.48825407682035615]
	TIME [epoch: 12.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3457620490462336		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.3457620490462336 | validation: 0.39525049612602986]
	TIME [epoch: 12.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3654521346663346		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.3654521346663346 | validation: 0.27300287618012803]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28841940321416765		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.28841940321416765 | validation: 0.2778659622872494]
	TIME [epoch: 12.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056095798059982		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4056095798059982 | validation: 0.5885501764794094]
	TIME [epoch: 12.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4398619420210066		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.4398619420210066 | validation: 0.3890771641010975]
	TIME [epoch: 12.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385485949090241		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5385485949090241 | validation: 0.43602856237219206]
	TIME [epoch: 12.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37225077257637246		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.37225077257637246 | validation: 0.34386816416259536]
	TIME [epoch: 12.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519328771110176		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2519328771110176 | validation: 0.6101747044931727]
	TIME [epoch: 12.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31424718459636314		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.31424718459636314 | validation: 0.3988913380252379]
	TIME [epoch: 12.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4712973109635481		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4712973109635481 | validation: 0.2650737686144624]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_394.pth
	Model improved!!!
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391007526273239		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.3391007526273239 | validation: 0.403064774368568]
	TIME [epoch: 12.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4932869156870786		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.4932869156870786 | validation: 0.7967437928276302]
	TIME [epoch: 12.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834603981385309		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.834603981385309 | validation: 0.9478600135382186]
	TIME [epoch: 12.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517298769493542		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6517298769493542 | validation: 0.672773085230802]
	TIME [epoch: 12.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40694943680923434		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.40694943680923434 | validation: 0.5984511944939803]
	TIME [epoch: 12.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47539930910767525		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.47539930910767525 | validation: 0.5345791815771254]
	TIME [epoch: 12.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3965500458471546		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.3965500458471546 | validation: 0.4226333242215867]
	TIME [epoch: 12.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31205388338091133		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.31205388338091133 | validation: 0.4251417888514575]
	TIME [epoch: 12.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3141389330269331		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.3141389330269331 | validation: 0.31894202705874697]
	TIME [epoch: 12.4 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38547088097899784		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.38547088097899784 | validation: 0.3435482073891137]
	TIME [epoch: 12.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41330974686904925		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.41330974686904925 | validation: 0.26014212586312885]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28070161382809733		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.28070161382809733 | validation: 0.37681184777938165]
	TIME [epoch: 12.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5461659340389646		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5461659340389646 | validation: 0.46682327431107606]
	TIME [epoch: 12.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528178443424887		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.3528178443424887 | validation: 0.29077099881689966]
	TIME [epoch: 12.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28706903870939765		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.28706903870939765 | validation: 0.5106205735335538]
	TIME [epoch: 12.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37462342014834166		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.37462342014834166 | validation: 0.6252140095758072]
	TIME [epoch: 12.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6583340734220174		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.6583340734220174 | validation: 0.7825405336212994]
	TIME [epoch: 12.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3735572729237635		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3735572729237635 | validation: 1.0976163058228532]
	TIME [epoch: 12.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947954082310163		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.6947954082310163 | validation: 0.5553785774771376]
	TIME [epoch: 12.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4313608408125037		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.4313608408125037 | validation: 0.4484737199471011]
	TIME [epoch: 12.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4061812039327969		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.4061812039327969 | validation: 0.47802331482677707]
	TIME [epoch: 12.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3590083078705066		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3590083078705066 | validation: 0.5262009380076689]
	TIME [epoch: 12.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44017855328954153		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.44017855328954153 | validation: 0.33301789470501725]
	TIME [epoch: 12.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521654222508499		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.3521654222508499 | validation: 0.5792108104745737]
	TIME [epoch: 12.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4022534750895239		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4022534750895239 | validation: 0.5898418808895406]
	TIME [epoch: 12.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340698954324923		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.3340698954324923 | validation: 0.2674103305707809]
	TIME [epoch: 12.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25283962415736305		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.25283962415736305 | validation: 0.7915596562991944]
	TIME [epoch: 12.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095693189111074		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.4095693189111074 | validation: 0.27660641678034525]
	TIME [epoch: 12.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31058581691112913		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.31058581691112913 | validation: 0.5553465185495393]
	TIME [epoch: 12.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.364230500590497		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.364230500590497 | validation: 0.24995907636717538]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3228659539805592		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.3228659539805592 | validation: 0.31648209980001596]
	TIME [epoch: 12.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33920814744004896		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.33920814744004896 | validation: 0.457217175989422]
	TIME [epoch: 12.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3959822994444255		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.3959822994444255 | validation: 0.3317364695340234]
	TIME [epoch: 12.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3435737341370237		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3435737341370237 | validation: 0.2834795509465831]
	TIME [epoch: 12.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3615368491155001		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.3615368491155001 | validation: 0.7002650898105836]
	TIME [epoch: 12.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4077408833230933		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.4077408833230933 | validation: 0.5353789167752714]
	TIME [epoch: 12.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45663004431151877		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.45663004431151877 | validation: 0.3251695149601061]
	TIME [epoch: 12.3 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4020064368117411		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4020064368117411 | validation: 0.3242416351972302]
	TIME [epoch: 12.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609248596930753		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.3609248596930753 | validation: 0.5353537263835246]
	TIME [epoch: 12.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.474139088020191		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.474139088020191 | validation: 0.3862804164051021]
	TIME [epoch: 12.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2931319705613847		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.2931319705613847 | validation: 0.3207167797846891]
	TIME [epoch: 12.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3408338595246937		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.3408338595246937 | validation: 0.279775817852955]
	TIME [epoch: 12.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23586725055194688		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.23586725055194688 | validation: 0.26813519005369457]
	TIME [epoch: 12.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4128894696333809		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4128894696333809 | validation: 0.4991268886548387]
	TIME [epoch: 12.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42046569226556		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.42046569226556 | validation: 0.5922227366118342]
	TIME [epoch: 12.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230772363336483		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3230772363336483 | validation: 0.37072363012541454]
	TIME [epoch: 12.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682237394568886		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.2682237394568886 | validation: 0.28489528339203773]
	TIME [epoch: 12.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925866712859482		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.2925866712859482 | validation: 0.5471643698511268]
	TIME [epoch: 12.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3438465400287839		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.3438465400287839 | validation: 0.31700558883566127]
	TIME [epoch: 12.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3142095674191858		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.3142095674191858 | validation: 0.6497244649412319]
	TIME [epoch: 12.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3414380916206239		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3414380916206239 | validation: 0.31852301731820293]
	TIME [epoch: 12.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30384248919910584		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.30384248919910584 | validation: 0.24056436237600065]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2791516345345488		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.2791516345345488 | validation: 0.3897443466375106]
	TIME [epoch: 12.4 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796062242664361		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.2796062242664361 | validation: 0.43969518137328095]
	TIME [epoch: 12.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812313397444931		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.2812313397444931 | validation: 0.32097067533050094]
	TIME [epoch: 12.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41117131590152034		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.41117131590152034 | validation: 0.31839873935067486]
	TIME [epoch: 12.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2986530806980239		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.2986530806980239 | validation: 0.2433786159457279]
	TIME [epoch: 12.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3433202859504042		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3433202859504042 | validation: 0.3533795563069714]
	TIME [epoch: 12.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43516664109636116		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.43516664109636116 | validation: 0.28666165315649367]
	TIME [epoch: 12.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344424345324445		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.2344424345324445 | validation: 0.22269748060654532]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20329607645586673		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.20329607645586673 | validation: 0.5607396122215353]
	TIME [epoch: 12.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27623812064018616		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.27623812064018616 | validation: 0.46242227282183856]
	TIME [epoch: 12.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.324745791810571		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.324745791810571 | validation: 0.17865313070008498]
	TIME [epoch: 12.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_457.pth
	Model improved!!!
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598000047664556		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.3598000047664556 | validation: 0.28969830332032415]
	TIME [epoch: 12.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27787917344218305		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.27787917344218305 | validation: 0.41073703337718603]
	TIME [epoch: 12.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2339230675652959		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.2339230675652959 | validation: 0.3763780681052331]
	TIME [epoch: 12.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3064289174448418		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3064289174448418 | validation: 0.3538444879181188]
	TIME [epoch: 12.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049102929079514		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.3049102929079514 | validation: 0.3772261865165986]
	TIME [epoch: 12.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2521558470974964		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.2521558470974964 | validation: 0.6488341252095786]
	TIME [epoch: 12.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40788353113987413		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.40788353113987413 | validation: 0.36737725233625507]
	TIME [epoch: 12.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007763012363921		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4007763012363921 | validation: 0.2925512312091309]
	TIME [epoch: 12.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333709474634699		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.333709474634699 | validation: 0.47344774584268023]
	TIME [epoch: 12.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25488960965866636		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.25488960965866636 | validation: 0.606965371804532]
	TIME [epoch: 12.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2526781352962212		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.2526781352962212 | validation: 0.3343110067739783]
	TIME [epoch: 12.4 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27929971116485297		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.27929971116485297 | validation: 0.2633413951412774]
	TIME [epoch: 12.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2439795235471125		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.2439795235471125 | validation: 0.253712199111647]
	TIME [epoch: 12.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26076420435905767		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.26076420435905767 | validation: 0.23827786802399936]
	TIME [epoch: 12.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26492040729274224		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.26492040729274224 | validation: 0.3662358768342846]
	TIME [epoch: 12.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24181453183876694		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.24181453183876694 | validation: 0.19623642939289676]
	TIME [epoch: 12.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2397859690546455		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2397859690546455 | validation: 0.29507159896775875]
	TIME [epoch: 12.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861518909255268		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.2861518909255268 | validation: 0.2433368889180555]
	TIME [epoch: 12.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37043221475832655		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.37043221475832655 | validation: 0.23074847892603417]
	TIME [epoch: 12.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811139245448105		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2811139245448105 | validation: 0.19714472819281853]
	TIME [epoch: 12.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26206833706460136		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.26206833706460136 | validation: 0.27135293450361286]
	TIME [epoch: 12.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3009119949972273		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3009119949972273 | validation: 0.4537131983371372]
	TIME [epoch: 12.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935850257439166		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.2935850257439166 | validation: 0.3142217449028779]
	TIME [epoch: 12.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3680803747680511		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.3680803747680511 | validation: 0.3447307445747841]
	TIME [epoch: 12.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26972011488936964		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.26972011488936964 | validation: 0.3917140402180994]
	TIME [epoch: 12.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2919392739532331		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.2919392739532331 | validation: 0.25523823796637846]
	TIME [epoch: 12.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25264920147561687		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.25264920147561687 | validation: 0.1950230060250959]
	TIME [epoch: 12.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.306006063547915		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.306006063547915 | validation: 0.28566085100074373]
	TIME [epoch: 12.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21294254240271682		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.21294254240271682 | validation: 0.23480873716659773]
	TIME [epoch: 12.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106654245094196		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.3106654245094196 | validation: 1.1148641263381687]
	TIME [epoch: 12.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7342093924542671		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.7342093924542671 | validation: 0.2134244328663995]
	TIME [epoch: 12.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623178701452502		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2623178701452502 | validation: 0.19770339514142227]
	TIME [epoch: 12.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25651624643329596		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.25651624643329596 | validation: 0.39670958568577613]
	TIME [epoch: 12.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23515942258061237		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.23515942258061237 | validation: 0.3975734390519005]
	TIME [epoch: 12.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4707948557599229		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4707948557599229 | validation: 0.31137011368080186]
	TIME [epoch: 12.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23975789596559485		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.23975789596559485 | validation: 0.2132502698161869]
	TIME [epoch: 12.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21074330325119087		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.21074330325119087 | validation: 0.32448825655517255]
	TIME [epoch: 12.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563963355382615		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2563963355382615 | validation: 0.26037413666679876]
	TIME [epoch: 12.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24360426077227856		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.24360426077227856 | validation: 0.19057182552753593]
	TIME [epoch: 12.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19128082519893302		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.19128082519893302 | validation: 0.37725763836478554]
	TIME [epoch: 12.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2808102655357159		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.2808102655357159 | validation: 0.30010900558031955]
	TIME [epoch: 12.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24442232483839976		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.24442232483839976 | validation: 0.35934896630030133]
	TIME [epoch: 12.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3125608459579704		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3125608459579704 | validation: 0.2798180815064968]
	TIME [epoch: 12.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21248067972674764		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.21248067972674764 | validation: 0.2553655799928805]
	TIME [epoch: 455 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22763959171122833		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.22763959171122833 | validation: 0.32246961682488]
	TIME [epoch: 26.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27722879549665297		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.27722879549665297 | validation: 0.4226582256390627]
	TIME [epoch: 26.4 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22743422366621505		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.22743422366621505 | validation: 0.2728442750217236]
	TIME [epoch: 26.4 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2777595062031618		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.2777595062031618 | validation: 0.4449384054731604]
	TIME [epoch: 26.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31870611275781346		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.31870611275781346 | validation: 0.24491631408483586]
	TIME [epoch: 26.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292152020915513		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2292152020915513 | validation: 0.23927162317000755]
	TIME [epoch: 26.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18407781044110832		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.18407781044110832 | validation: 0.5163671821494525]
	TIME [epoch: 26.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825258874925767		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2825258874925767 | validation: 0.8490575599919887]
	TIME [epoch: 26.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7800413223663527		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.7800413223663527 | validation: 0.5639698427710064]
	TIME [epoch: 26.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423773542752609		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.4423773542752609 | validation: 0.6296893004587353]
	TIME [epoch: 26.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491252904713525		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.3491252904713525 | validation: 0.2887984474883683]
	TIME [epoch: 26.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19635095856402984		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.19635095856402984 | validation: 0.422964651959021]
	TIME [epoch: 26.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4442847660065849		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.4442847660065849 | validation: 0.2504657109319739]
	TIME [epoch: 26.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644410827970019		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.2644410827970019 | validation: 0.27320272273141555]
	TIME [epoch: 26.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24585061652301762		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.24585061652301762 | validation: 0.1929562607149164]
	TIME [epoch: 26.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2616878492561529		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.2616878492561529 | validation: 0.1856057009709828]
	TIME [epoch: 26.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2657036479877813		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2657036479877813 | validation: 0.2633822902472607]
	TIME [epoch: 26.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2796793236147803		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.2796793236147803 | validation: 0.22074503792234013]
	TIME [epoch: 26.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710546577886544		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.2710546577886544 | validation: 0.23669180961563863]
	TIME [epoch: 26.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25927300274804		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.25927300274804 | validation: 0.3669401156476738]
	TIME [epoch: 26.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2473816879799558		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2473816879799558 | validation: 0.3356004203905224]
	TIME [epoch: 26.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21370441586392255		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.21370441586392255 | validation: 0.2277887356728668]
	TIME [epoch: 26.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23269419161827662		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.23269419161827662 | validation: 0.1972064151779589]
	TIME [epoch: 26.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20821028223275745		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.20821028223275745 | validation: 0.3045402676926398]
	TIME [epoch: 26.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24217037106860703		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.24217037106860703 | validation: 0.2670386069749362]
	TIME [epoch: 26.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1886786353434034		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1886786353434034 | validation: 0.16616959927336133]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442698615756494		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3442698615756494 | validation: 0.19765855454094794]
	TIME [epoch: 26.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26131351197599983		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.26131351197599983 | validation: 0.36151002690602063]
	TIME [epoch: 26.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2985504385475013		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.2985504385475013 | validation: 0.1908038363215701]
	TIME [epoch: 26.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21229443171334642		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.21229443171334642 | validation: 0.17428889642868434]
	TIME [epoch: 26.4 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16831812773717295		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.16831812773717295 | validation: 0.29800305373401]
	TIME [epoch: 26.4 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23837135666156478		[learning rate: 0.0018085]
	Learning Rate: 0.00180846
	LOSS [training: 0.23837135666156478 | validation: 0.254001327262169]
	TIME [epoch: 26.4 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2799408341789006		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.2799408341789006 | validation: 0.541590546116012]
	TIME [epoch: 26.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510628410072231		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.3510628410072231 | validation: 0.5104979091088743]
	TIME [epoch: 26.4 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23272178590456985		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.23272178590456985 | validation: 0.3244326110585364]
	TIME [epoch: 26.4 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19749635511839625		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.19749635511839625 | validation: 0.20862005132156589]
	TIME [epoch: 26.4 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22561985827407854		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.22561985827407854 | validation: 0.2015776287621042]
	TIME [epoch: 26.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1802046074381547		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.1802046074381547 | validation: 0.4225932327419412]
	TIME [epoch: 26.4 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28419817679005743		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.28419817679005743 | validation: 0.1825551409627667]
	TIME [epoch: 26.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.193489694588819		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.193489694588819 | validation: 0.25897815146073]
	TIME [epoch: 26.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44006071912977895		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.44006071912977895 | validation: 0.3173863798015284]
	TIME [epoch: 26.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519189198098644		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2519189198098644 | validation: 0.2687421952233182]
	TIME [epoch: 26.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087841958854865		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3087841958854865 | validation: 0.28237910569086955]
	TIME [epoch: 26.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24032740011396492		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.24032740011396492 | validation: 0.3288209602654897]
	TIME [epoch: 26.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20007338014268153		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.20007338014268153 | validation: 0.1986355038791058]
	TIME [epoch: 26.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17814439756841965		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.17814439756841965 | validation: 0.29937681277642203]
	TIME [epoch: 26.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21868692062609943		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.21868692062609943 | validation: 0.19318498402834983]
	TIME [epoch: 26.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16557696770618388		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.16557696770618388 | validation: 0.4445811663899745]
	TIME [epoch: 26.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37161452363367264		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.37161452363367264 | validation: 0.21526117667084088]
	TIME [epoch: 26.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23729791132387618		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.23729791132387618 | validation: 0.2593749082438805]
	TIME [epoch: 26.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23172891879353785		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.23172891879353785 | validation: 0.35301848249491424]
	TIME [epoch: 26.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2749439223691423		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.2749439223691423 | validation: 0.19879664707933115]
	TIME [epoch: 26.4 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22799864695676658		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.22799864695676658 | validation: 0.16889501874453722]
	TIME [epoch: 26.4 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1784170496316		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.1784170496316 | validation: 0.21288454277865387]
	TIME [epoch: 26.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14756302749608807		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.14756302749608807 | validation: 0.23736300601272511]
	TIME [epoch: 26.4 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23656960541461808		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.23656960541461808 | validation: 0.16732547261048303]
	TIME [epoch: 26.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17003475503573992		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.17003475503573992 | validation: 0.16341559077000248]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_558.pth
	Model improved!!!
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2068951961300844		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2068951961300844 | validation: 0.40398239246490575]
	TIME [epoch: 26.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225050697037661		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.225050697037661 | validation: 0.18252261529260214]
	TIME [epoch: 26.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19997850009625368		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.19997850009625368 | validation: 0.21756286379976625]
	TIME [epoch: 26.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931410904624114		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.1931410904624114 | validation: 0.1615458270560976]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1565032302108063		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.1565032302108063 | validation: 0.32732233340832684]
	TIME [epoch: 26.4 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144005846199424		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2144005846199424 | validation: 0.2569548768682105]
	TIME [epoch: 26.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1570382911398232		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1570382911398232 | validation: 0.284207953398504]
	TIME [epoch: 26.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27179848493053055		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.27179848493053055 | validation: 0.2068728542972601]
	TIME [epoch: 26.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23271310382207308		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.23271310382207308 | validation: 0.16963927184442867]
	TIME [epoch: 26.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21578147830659433		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.21578147830659433 | validation: 0.24679927021164105]
	TIME [epoch: 26.4 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16169250729710694		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.16169250729710694 | validation: 0.28466243756381077]
	TIME [epoch: 26.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20188713029182284		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.20188713029182284 | validation: 0.30546660365263145]
	TIME [epoch: 26.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17762768262045536		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.17762768262045536 | validation: 0.15446596784003788]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010945732563357		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2010945732563357 | validation: 0.17047607292045852]
	TIME [epoch: 26.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15590445229330196		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.15590445229330196 | validation: 0.25931274238566393]
	TIME [epoch: 26.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21676469815381047		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.21676469815381047 | validation: 0.16063786098403243]
	TIME [epoch: 26.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626178355800425		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.1626178355800425 | validation: 0.2839320894787731]
	TIME [epoch: 26.4 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21620193619218003		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.21620193619218003 | validation: 0.2770288790385242]
	TIME [epoch: 26.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17752749266475412		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.17752749266475412 | validation: 0.18155049692386957]
	TIME [epoch: 26.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17165753707582362		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.17165753707582362 | validation: 0.23303170836451692]
	TIME [epoch: 26.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14885373298677979		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.14885373298677979 | validation: 0.18791132241507397]
	TIME [epoch: 26.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13664052317477357		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.13664052317477357 | validation: 0.1642861968769252]
	TIME [epoch: 26.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23403461405504417		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.23403461405504417 | validation: 0.45232611294246317]
	TIME [epoch: 26.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26426238195272866		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.26426238195272866 | validation: 0.1770586613399373]
	TIME [epoch: 26.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15804996073919475		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.15804996073919475 | validation: 0.17105953957983472]
	TIME [epoch: 26.4 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14365960865464936		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.14365960865464936 | validation: 0.14877718793356481]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_584.pth
	Model improved!!!
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12905555949096348		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.12905555949096348 | validation: 0.22290393707013462]
	TIME [epoch: 26.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20719537247845166		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.20719537247845166 | validation: 0.2335451993232292]
	TIME [epoch: 26.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2951769048113644		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.2951769048113644 | validation: 0.24070258548147558]
	TIME [epoch: 26.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20316024948433514		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.20316024948433514 | validation: 0.21700354159672236]
	TIME [epoch: 26.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19231000628528375		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.19231000628528375 | validation: 0.33074524846355796]
	TIME [epoch: 26.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2538024199287578		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2538024199287578 | validation: 0.289447894318732]
	TIME [epoch: 26.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2476791027691304		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.2476791027691304 | validation: 0.31611526054145067]
	TIME [epoch: 26.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18620993421604642		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.18620993421604642 | validation: 0.18870505080800598]
	TIME [epoch: 26.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15713091526197137		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.15713091526197137 | validation: 0.2888190878229353]
	TIME [epoch: 26.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.135127273618023		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.135127273618023 | validation: 0.19490295602762034]
	TIME [epoch: 26.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16735790849738733		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.16735790849738733 | validation: 0.2664877908472069]
	TIME [epoch: 26.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17824900190394405		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.17824900190394405 | validation: 0.20763251001146482]
	TIME [epoch: 26.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16547622031695536		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.16547622031695536 | validation: 0.1614331196784707]
	TIME [epoch: 26.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15675806190915653		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.15675806190915653 | validation: 0.1673932347454669]
	TIME [epoch: 26.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810471875256531		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.1810471875256531 | validation: 0.21336997448223058]
	TIME [epoch: 26.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082403017797274		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2082403017797274 | validation: 0.2110554845955468]
	TIME [epoch: 26.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626415761051997		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.1626415761051997 | validation: 0.21345830419400025]
	TIME [epoch: 26.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19686374161588605		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.19686374161588605 | validation: 0.2713282033498054]
	TIME [epoch: 26.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16706212819216903		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.16706212819216903 | validation: 0.24476875696203793]
	TIME [epoch: 26.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534706041213954		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.1534706041213954 | validation: 0.20210666499467228]
	TIME [epoch: 26.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16252571637863694		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.16252571637863694 | validation: 0.17037781862787688]
	TIME [epoch: 26.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11326369091892842		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.11326369091892842 | validation: 0.12791651383125754]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_606.pth
	Model improved!!!
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18536095332827296		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.18536095332827296 | validation: 0.32728879413721224]
	TIME [epoch: 26.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20322616958661588		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.20322616958661588 | validation: 0.23230823111354537]
	TIME [epoch: 26.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16878951957871718		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.16878951957871718 | validation: 0.2558983113481879]
	TIME [epoch: 26.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18278662423654024		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.18278662423654024 | validation: 0.2483508152249085]
	TIME [epoch: 26.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21599334357542835		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.21599334357542835 | validation: 0.39721645590660815]
	TIME [epoch: 26.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2455037343891201		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.2455037343891201 | validation: 0.24269638907655333]
	TIME [epoch: 26.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16115523277493143		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.16115523277493143 | validation: 0.12608424562570658]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690744740866751		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.1690744740866751 | validation: 0.2252690569748841]
	TIME [epoch: 26.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20035013406479155		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.20035013406479155 | validation: 0.16006275368896236]
	TIME [epoch: 26.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17682150293644597		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.17682150293644597 | validation: 0.2275902921379857]
	TIME [epoch: 26.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16583936487276388		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.16583936487276388 | validation: 0.17990317241067655]
	TIME [epoch: 26.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19805676129304317		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.19805676129304317 | validation: 0.21018809431812963]
	TIME [epoch: 26.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16466560415061499		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.16466560415061499 | validation: 0.2780038536356806]
	TIME [epoch: 26.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18697015666580896		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.18697015666580896 | validation: 0.2244249670776362]
	TIME [epoch: 26.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2167810172680138		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2167810172680138 | validation: 0.22012252700586094]
	TIME [epoch: 26.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19494208478051067		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.19494208478051067 | validation: 0.16786886187329775]
	TIME [epoch: 26.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13312871518629835		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.13312871518629835 | validation: 0.25103319228875964]
	TIME [epoch: 26.4 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15242548507864645		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.15242548507864645 | validation: 0.16493250002018728]
	TIME [epoch: 26.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14211367790653354		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.14211367790653354 | validation: 0.13360967041256802]
	TIME [epoch: 26.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15673112602302175		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.15673112602302175 | validation: 0.21070713932792673]
	TIME [epoch: 26.4 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19676435002433262		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.19676435002433262 | validation: 0.22680277026699008]
	TIME [epoch: 26.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1686122998358582		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1686122998358582 | validation: 0.20133546355149906]
	TIME [epoch: 26.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22570746947634596		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.22570746947634596 | validation: 0.3739320089384761]
	TIME [epoch: 26.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22682189201284786		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.22682189201284786 | validation: 0.2908450365074754]
	TIME [epoch: 26.4 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20033244797939942		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.20033244797939942 | validation: 0.23944380955925326]
	TIME [epoch: 26.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18166005253879314		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.18166005253879314 | validation: 0.18150542499681677]
	TIME [epoch: 26.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1821211773841145		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.1821211773841145 | validation: 0.2471095786842571]
	TIME [epoch: 26.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854053905341751		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.1854053905341751 | validation: 0.1598256443574605]
	TIME [epoch: 26.4 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1958183473460137		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.1958183473460137 | validation: 0.4268428700772146]
	TIME [epoch: 26.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29788014476015395		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.29788014476015395 | validation: 0.18909222439464365]
	TIME [epoch: 26.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21618940842096937		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.21618940842096937 | validation: 0.1807340323200346]
	TIME [epoch: 26.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1740371248375256		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1740371248375256 | validation: 0.315736164558559]
	TIME [epoch: 26.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18043283202563518		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.18043283202563518 | validation: 0.19604665111430286]
	TIME [epoch: 26.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16156557535213414		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16156557535213414 | validation: 0.21926416200641755]
	TIME [epoch: 26.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18526106956011387		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.18526106956011387 | validation: 0.1973471312590938]
	TIME [epoch: 26.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1855348449755705		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.1855348449755705 | validation: 0.21215331375732543]
	TIME [epoch: 26.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2815099674639011		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.2815099674639011 | validation: 0.36976555855588944]
	TIME [epoch: 26.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26748649137965996		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.26748649137965996 | validation: 0.20338608986940193]
	TIME [epoch: 26.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16887458764065705		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.16887458764065705 | validation: 0.11967756730855744]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_645.pth
	Model improved!!!
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1244246824572258		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.1244246824572258 | validation: 0.12265464211756041]
	TIME [epoch: 26.4 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654661063758597		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.10654661063758597 | validation: 0.13966436477276212]
	TIME [epoch: 26.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11647753826603373		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.11647753826603373 | validation: 0.15180862720335392]
	TIME [epoch: 26.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2105724784573917		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2105724784573917 | validation: 0.16077761468623286]
	TIME [epoch: 26.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22787988817312232		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.22787988817312232 | validation: 0.25460055795027137]
	TIME [epoch: 26.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821553462930567		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.14821553462930567 | validation: 0.14798924132741503]
	TIME [epoch: 26.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14477029112879147		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.14477029112879147 | validation: 0.1568042724499121]
	TIME [epoch: 26.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15669658202178605		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.15669658202178605 | validation: 0.17994343121290138]
	TIME [epoch: 26.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650608153112185		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.1650608153112185 | validation: 0.19522818034649667]
	TIME [epoch: 26.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18900527683452503		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.18900527683452503 | validation: 0.19943005488680246]
	TIME [epoch: 26.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21092334878580501		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.21092334878580501 | validation: 0.1780181261862317]
	TIME [epoch: 26.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13046307165971072		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.13046307165971072 | validation: 0.14467999887324115]
	TIME [epoch: 26.4 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17326093248978724		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.17326093248978724 | validation: 0.2672864136043351]
	TIME [epoch: 26.4 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2224282450166054		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.2224282450166054 | validation: 0.19218434601481046]
	TIME [epoch: 26.4 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21582737412453265		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.21582737412453265 | validation: 0.20248139982960328]
	TIME [epoch: 26.4 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24873840421970161		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.24873840421970161 | validation: 0.4637329128436324]
	TIME [epoch: 26.4 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3065847959867073		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3065847959867073 | validation: 0.37569550948643216]
	TIME [epoch: 26.4 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17898026613665236		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.17898026613665236 | validation: 0.18028834432580737]
	TIME [epoch: 26.4 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965292518152247		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.13965292518152247 | validation: 0.11806505243434309]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_664.pth
	Model improved!!!
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12755147936540692		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.12755147936540692 | validation: 0.1987560999468298]
	TIME [epoch: 26.4 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18776737500944907		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.18776737500944907 | validation: 0.18269191188368533]
	TIME [epoch: 26.4 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625546048539664		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1625546048539664 | validation: 0.13739022357599134]
	TIME [epoch: 26.4 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487424720711024		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.12487424720711024 | validation: 0.1868072747325379]
	TIME [epoch: 26.4 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13917995637033057		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.13917995637033057 | validation: 0.23764453175038874]
	TIME [epoch: 26.4 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1912817765298589		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1912817765298589 | validation: 0.14429336836423043]
	TIME [epoch: 26.4 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205358094575629		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1205358094575629 | validation: 0.15764379832763747]
	TIME [epoch: 26.4 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077037532570765		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1077037532570765 | validation: 0.20058631468493476]
	TIME [epoch: 26.4 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2035585069420049		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.2035585069420049 | validation: 0.1589216733044232]
	TIME [epoch: 26.4 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14737784333631593		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.14737784333631593 | validation: 0.20193053733377841]
	TIME [epoch: 26.4 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14256933594215163		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.14256933594215163 | validation: 0.11934001225991427]
	TIME [epoch: 26.4 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16219212191956017		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.16219212191956017 | validation: 0.15276635720821763]
	TIME [epoch: 26.4 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1971085414184943		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.1971085414184943 | validation: 0.1443560021360003]
	TIME [epoch: 26.4 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16884388597981081		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.16884388597981081 | validation: 0.32512687714365635]
	TIME [epoch: 26.4 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22399883370467857		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.22399883370467857 | validation: 0.16359964973469637]
	TIME [epoch: 26.4 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15533617052831905		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.15533617052831905 | validation: 0.10805083337772525]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12321414923553496		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.12321414923553496 | validation: 0.14752387680907683]
	TIME [epoch: 26.4 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415152998950985		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.1415152998950985 | validation: 0.19757266788119043]
	TIME [epoch: 26.4 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16146489774608339		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.16146489774608339 | validation: 0.2544771421439329]
	TIME [epoch: 26.4 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273066995470432		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.2273066995470432 | validation: 0.1588543464006889]
	TIME [epoch: 26.4 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1699764901661417		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.1699764901661417 | validation: 0.29883636498964616]
	TIME [epoch: 26.4 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658170616463287		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.1658170616463287 | validation: 0.26416700187566605]
	TIME [epoch: 26.4 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2003122236865503		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.2003122236865503 | validation: 0.1302834461318532]
	TIME [epoch: 26.4 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12613722926268517		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.12613722926268517 | validation: 0.1269222702851242]
	TIME [epoch: 26.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14272262533942182		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.14272262533942182 | validation: 0.15474291002795398]
	TIME [epoch: 26.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15971048750297173		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15971048750297173 | validation: 0.1862314761449505]
	TIME [epoch: 26.4 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19513284964845468		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.19513284964845468 | validation: 0.23838130836811194]
	TIME [epoch: 26.4 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19645186322329472		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.19645186322329472 | validation: 0.21019132090366088]
	TIME [epoch: 26.4 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17825870595118914		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.17825870595118914 | validation: 0.12760828222274517]
	TIME [epoch: 26.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351968540016753		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.15351968540016753 | validation: 0.18808917938816605]
	TIME [epoch: 26.4 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18144842351223134		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.18144842351223134 | validation: 0.2197170122092492]
	TIME [epoch: 26.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15175925810590418		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.15175925810590418 | validation: 0.17065612108819575]
	TIME [epoch: 26.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14295316498682548		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.14295316498682548 | validation: 0.08856192017852682]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15290599057459126		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.15290599057459126 | validation: 0.22568345521470848]
	TIME [epoch: 26.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21674299067025576		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.21674299067025576 | validation: 0.1860607100855242]
	TIME [epoch: 26.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17400872825262537		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.17400872825262537 | validation: 0.20473373034985515]
	TIME [epoch: 26.4 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1325716892397063		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.1325716892397063 | validation: 0.18682841941460374]
	TIME [epoch: 26.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13065262196012095		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.13065262196012095 | validation: 0.161902342277282]
	TIME [epoch: 26.4 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17787344913816383		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.17787344913816383 | validation: 0.22435611570100594]
	TIME [epoch: 26.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18858308870438667		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.18858308870438667 | validation: 0.16961711278597189]
	TIME [epoch: 26.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18000046099084424		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.18000046099084424 | validation: 0.19379301390390646]
	TIME [epoch: 26.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14961173869917294		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.14961173869917294 | validation: 0.12714872623459517]
	TIME [epoch: 26.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12906006410504745		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.12906006410504745 | validation: 0.13316759236020193]
	TIME [epoch: 26.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1361712556676921		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.1361712556676921 | validation: 0.16073291538033346]
	TIME [epoch: 26.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12963271080155211		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.12963271080155211 | validation: 0.14083162751318054]
	TIME [epoch: 26.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13541748508251095		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.13541748508251095 | validation: 0.15556899880358652]
	TIME [epoch: 26.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1382271017159154		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.1382271017159154 | validation: 0.10900470746146754]
	TIME [epoch: 26.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12651547455109946		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.12651547455109946 | validation: 0.18632107243598756]
	TIME [epoch: 26.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1606999813849973		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.1606999813849973 | validation: 0.20865050243312797]
	TIME [epoch: 26.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15908530190637377		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.15908530190637377 | validation: 0.22502290674990483]
	TIME [epoch: 26.4 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18429063564315856		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.18429063564315856 | validation: 0.14303913842872176]
	TIME [epoch: 26.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13013267810786347		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.13013267810786347 | validation: 0.14856746064322432]
	TIME [epoch: 26.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23199417781838005		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.23199417781838005 | validation: 0.16644367636834032]
	TIME [epoch: 26.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13067186849459822		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.13067186849459822 | validation: 0.1246751467434161]
	TIME [epoch: 26.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1306943939035756		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1306943939035756 | validation: 0.12805822190863458]
	TIME [epoch: 26.4 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12700446874361004		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.12700446874361004 | validation: 0.15481052789908156]
	TIME [epoch: 26.4 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135779786583514		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1135779786583514 | validation: 0.11094268242797051]
	TIME [epoch: 26.4 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10829421271247724		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.10829421271247724 | validation: 0.283673087294145]
	TIME [epoch: 26.4 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19188900269815223		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.19188900269815223 | validation: 0.1487597040503847]
	TIME [epoch: 26.4 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1341990340654281		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.1341990340654281 | validation: 0.1305941515482231]
	TIME [epoch: 26.4 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10142943097599455		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.10142943097599455 | validation: 0.19744667356328083]
	TIME [epoch: 26.4 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12177040269668248		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.12177040269668248 | validation: 0.1458545142949271]
	TIME [epoch: 26.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1338034917456983		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1338034917456983 | validation: 0.1446965370813438]
	TIME [epoch: 26.4 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16617568857541298		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.16617568857541298 | validation: 0.14521634191832342]
	TIME [epoch: 26.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15718516692616735		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.15718516692616735 | validation: 0.18741719764033665]
	TIME [epoch: 26.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15949521504576103		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.15949521504576103 | validation: 0.1841018501877924]
	TIME [epoch: 26.4 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13959199957410398		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.13959199957410398 | validation: 0.18835032542858884]
	TIME [epoch: 26.4 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10950945182662175		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.10950945182662175 | validation: 0.1429119095673922]
	TIME [epoch: 26.4 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11340971646404553		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.11340971646404553 | validation: 0.1502063049998677]
	TIME [epoch: 26.4 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12242342762507137		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.12242342762507137 | validation: 0.16897431436232546]
	TIME [epoch: 26.4 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198483069806528		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14198483069806528 | validation: 0.16362429509766122]
	TIME [epoch: 26.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12192478706237694		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.12192478706237694 | validation: 0.11234019143777349]
	TIME [epoch: 26.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12386619095291546		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.12386619095291546 | validation: 0.12799251122349872]
	TIME [epoch: 26.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22651554540687488		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.22651554540687488 | validation: 0.32061853583579697]
	TIME [epoch: 26.4 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24570574278893595		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.24570574278893595 | validation: 0.19767671738738432]
	TIME [epoch: 26.4 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16796199701255715		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.16796199701255715 | validation: 0.20149840500582666]
	TIME [epoch: 26.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.137316811540602		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.137316811540602 | validation: 0.14271006675169223]
	TIME [epoch: 26.4 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09610301261890891		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.09610301261890891 | validation: 0.13635126287280935]
	TIME [epoch: 26.4 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12384911000430185		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.12384911000430185 | validation: 0.11348007462281318]
	TIME [epoch: 26.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091844221726114		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.091844221726114 | validation: 0.13491175004361122]
	TIME [epoch: 26.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979928074068238		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.0979928074068238 | validation: 0.18834120520234074]
	TIME [epoch: 26.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1219119543112199		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.1219119543112199 | validation: 0.13672950866750697]
	TIME [epoch: 26.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.156147635847114		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.156147635847114 | validation: 0.1540175220562227]
	TIME [epoch: 26.4 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236638230772744		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.11236638230772744 | validation: 0.18007658043569127]
	TIME [epoch: 26.4 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12844698277782052		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.12844698277782052 | validation: 0.20458376358858993]
	TIME [epoch: 26.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13310277721393954		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.13310277721393954 | validation: 0.1262079019435838]
	TIME [epoch: 26.4 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488995054393417		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.11488995054393417 | validation: 0.14210129298898522]
	TIME [epoch: 26.4 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17169480552585342		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.17169480552585342 | validation: 0.21175493350636587]
	TIME [epoch: 26.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17126541716326804		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.17126541716326804 | validation: 0.31195488547600725]
	TIME [epoch: 26.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2053067415417073		[learning rate: 0.00082662]
	Learning Rate: 0.000826624
	LOSS [training: 0.2053067415417073 | validation: 0.1503374946902714]
	TIME [epoch: 26.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15584440022239207		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.15584440022239207 | validation: 0.19872886090474184]
	TIME [epoch: 26.4 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15347999461575976		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.15347999461575976 | validation: 0.2532018370280926]
	TIME [epoch: 26.4 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14299650320635052		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.14299650320635052 | validation: 0.14712532680202892]
	TIME [epoch: 26.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13139579131958706		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.13139579131958706 | validation: 0.1608649454922731]
	TIME [epoch: 26.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.146302796871672		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.146302796871672 | validation: 0.12744330253820463]
	TIME [epoch: 26.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10181988374926336		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.10181988374926336 | validation: 0.11324464057097886]
	TIME [epoch: 26.4 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198545369306367		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.14198545369306367 | validation: 0.2337151629167648]
	TIME [epoch: 26.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550010389328712		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.1550010389328712 | validation: 0.17531698552936265]
	TIME [epoch: 26.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12921904223309263		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.12921904223309263 | validation: 0.14682096735329797]
	TIME [epoch: 26.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13577202204175903		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.13577202204175903 | validation: 0.20274280354397764]
	TIME [epoch: 26.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15689497818217973		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15689497818217973 | validation: 0.14256704724477412]
	TIME [epoch: 26.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18903668195867446		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.18903668195867446 | validation: 0.21590095268284454]
	TIME [epoch: 26.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17549209518098483		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.17549209518098483 | validation: 0.1944546764414028]
	TIME [epoch: 26.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796351346096532		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.15796351346096532 | validation: 0.13065514293736608]
	TIME [epoch: 26.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12459522264032377		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.12459522264032377 | validation: 0.1518965870213254]
	TIME [epoch: 26.4 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13817279682408215		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.13817279682408215 | validation: 0.17187926776076087]
	TIME [epoch: 26.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14198616632564093		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.14198616632564093 | validation: 0.1725845545721349]
	TIME [epoch: 26.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12163220989995528		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.12163220989995528 | validation: 0.12465405799311816]
	TIME [epoch: 26.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258836252569505		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.11258836252569505 | validation: 0.11237994994345624]
	TIME [epoch: 26.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09477449998562282		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.09477449998562282 | validation: 0.1274083502278615]
	TIME [epoch: 26.4 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13620279062037075		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.13620279062037075 | validation: 0.1114937045902008]
	TIME [epoch: 26.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.125808808761385		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.125808808761385 | validation: 0.12525433216919402]
	TIME [epoch: 26.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12847578456874478		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.12847578456874478 | validation: 0.1576469917361418]
	TIME [epoch: 26.4 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14414042009941502		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.14414042009941502 | validation: 0.21259889694597087]
	TIME [epoch: 26.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17126526986179613		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.17126526986179613 | validation: 0.12359006483955318]
	TIME [epoch: 26.4 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1034682142810657		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.1034682142810657 | validation: 0.11214232770708452]
	TIME [epoch: 26.4 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095514014916837		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1095514014916837 | validation: 0.39921569218004493]
	TIME [epoch: 26.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15072759537663627		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.15072759537663627 | validation: 0.11357326899127125]
	TIME [epoch: 26.4 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09478526787147909		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.09478526787147909 | validation: 0.18270087117261988]
	TIME [epoch: 26.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15880824310294459		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.15880824310294459 | validation: 0.10583204300673334]
	TIME [epoch: 26.4 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10598541126999841		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.10598541126999841 | validation: 0.09891623701555527]
	TIME [epoch: 26.4 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14285187998283636		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.14285187998283636 | validation: 0.131764927291415]
	TIME [epoch: 26.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1274099073112909		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.1274099073112909 | validation: 0.13463021462914215]
	TIME [epoch: 26.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011671295298428		[learning rate: 0.00073282]
	Learning Rate: 0.000732825
	LOSS [training: 0.14011671295298428 | validation: 0.10327548651355595]
	TIME [epoch: 26.4 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09821814745331495		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.09821814745331495 | validation: 0.11543808303055611]
	TIME [epoch: 26.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11925329251482811		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.11925329251482811 | validation: 0.08148468651999832]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_790.pth
	Model improved!!!
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10507821146854633		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.10507821146854633 | validation: 0.1295799206215361]
	TIME [epoch: 26.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10169372920105754		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.10169372920105754 | validation: 0.09559057455923708]
	TIME [epoch: 26.4 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09976059241689376		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.09976059241689376 | validation: 0.15760858540753186]
	TIME [epoch: 26.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12776045980599662		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.12776045980599662 | validation: 0.20927924997995273]
	TIME [epoch: 26.4 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13962760616072506		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.13962760616072506 | validation: 0.14524154734208042]
	TIME [epoch: 26.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1036934115357824		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.1036934115357824 | validation: 0.14667601803953603]
	TIME [epoch: 26.4 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08015827271782293		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.08015827271782293 | validation: 0.12620657478457076]
	TIME [epoch: 26.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10800092411337331		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.10800092411337331 | validation: 0.21661874337437562]
	TIME [epoch: 26.4 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17058032495479816		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.17058032495479816 | validation: 0.17270659555906168]
	TIME [epoch: 26.4 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12339049970810534		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.12339049970810534 | validation: 0.1865308935900165]
	TIME [epoch: 26.4 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566156410658817		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.1566156410658817 | validation: 0.10627532221776971]
	TIME [epoch: 26.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11461246067103635		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.11461246067103635 | validation: 0.11188662539822822]
	TIME [epoch: 26.4 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145321865818598		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.1145321865818598 | validation: 0.15935220968368974]
	TIME [epoch: 26.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12579725150049342		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.12579725150049342 | validation: 0.11075022234080101]
	TIME [epoch: 26.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18227726542694853		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.18227726542694853 | validation: 0.20122721691338158]
	TIME [epoch: 26.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15882165813048973		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.15882165813048973 | validation: 0.08551892912862631]
	TIME [epoch: 26.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13868367116597072		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.13868367116597072 | validation: 0.13363039600087248]
	TIME [epoch: 26.4 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09957064773357704		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.09957064773357704 | validation: 0.13465993271931098]
	TIME [epoch: 26.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.129319661830034		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.129319661830034 | validation: 0.1553004402640644]
	TIME [epoch: 26.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1436419690866309		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1436419690866309 | validation: 0.12080784414938468]
	TIME [epoch: 26.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10376862112264892		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.10376862112264892 | validation: 0.08774755841194778]
	TIME [epoch: 26.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12879189879211117		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.12879189879211117 | validation: 0.11837722722270687]
	TIME [epoch: 26.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08874862357976408		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.08874862357976408 | validation: 0.1050002261696926]
	TIME [epoch: 26.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08624585331235347		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.08624585331235347 | validation: 0.1681500105617908]
	TIME [epoch: 26.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15406207200218158		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.15406207200218158 | validation: 0.28734424226613065]
	TIME [epoch: 26.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21955782171225033		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.21955782171225033 | validation: 0.11550658629126916]
	TIME [epoch: 26.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14256470380104352		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.14256470380104352 | validation: 0.11770895988815397]
	TIME [epoch: 26.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10946073747905408		[learning rate: 0.00065894]
	Learning Rate: 0.00065894
	LOSS [training: 0.10946073747905408 | validation: 0.15470192563675386]
	TIME [epoch: 26.4 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1362220412679176		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.1362220412679176 | validation: 0.10666345081384324]
	TIME [epoch: 26.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08053951491349225		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.08053951491349225 | validation: 0.11590739206692541]
	TIME [epoch: 26.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08274544703484558		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.08274544703484558 | validation: 0.11239093755209917]
	TIME [epoch: 26.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09318685312873043		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.09318685312873043 | validation: 0.12147825308245673]
	TIME [epoch: 26.4 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09063070064764017		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.09063070064764017 | validation: 0.1272923761892764]
	TIME [epoch: 26.4 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16802437918018848		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.16802437918018848 | validation: 0.1232268263248435]
	TIME [epoch: 26.4 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09903072549420383		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.09903072549420383 | validation: 0.10604951813799114]
	TIME [epoch: 26.4 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11755766702084301		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.11755766702084301 | validation: 0.11099901060702992]
	TIME [epoch: 26.4 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08637962287834147		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.08637962287834147 | validation: 0.1108745797743627]
	TIME [epoch: 26.4 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0823272439175825		[learning rate: 0.00063601]
	Learning Rate: 0.000636007
	LOSS [training: 0.0823272439175825 | validation: 0.14698909234158203]
	TIME [epoch: 26.4 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118985590030547		[learning rate: 0.00063376]
	Learning Rate: 0.000633758
	LOSS [training: 0.11118985590030547 | validation: 0.10554720773389628]
	TIME [epoch: 26.4 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15310857898440297		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.15310857898440297 | validation: 0.15624254119593695]
	TIME [epoch: 26.4 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12011399629338534		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.12011399629338534 | validation: 0.1076021932840997]
	TIME [epoch: 26.4 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360888907894244		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.09360888907894244 | validation: 0.10247357829138345]
	TIME [epoch: 26.4 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354817336614787		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.08354817336614787 | validation: 0.1234347421350635]
	TIME [epoch: 26.4 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12375092965748		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.12375092965748 | validation: 0.11562885890972845]
	TIME [epoch: 26.4 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11509668553945147		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11509668553945147 | validation: 0.14038087739743882]
	TIME [epoch: 26.4 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16163553797526314		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.16163553797526314 | validation: 0.11157004877162956]
	TIME [epoch: 26.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10228295747001473		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.10228295747001473 | validation: 0.0805399203972844]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10358822572307898		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.10358822572307898 | validation: 0.1509350938523051]
	TIME [epoch: 26.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12440176017476248		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.12440176017476248 | validation: 0.10975648973758315]
	TIME [epoch: 26.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09456069603424705		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.09456069603424705 | validation: 0.11558355499314482]
	TIME [epoch: 26.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08437994759976314		[learning rate: 0.00060738]
	Learning Rate: 0.000607382
	LOSS [training: 0.08437994759976314 | validation: 0.11796503382202242]
	TIME [epoch: 26.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10098699801782765		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.10098699801782765 | validation: 0.08941336046961101]
	TIME [epoch: 26.4 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08266416778294755		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.08266416778294755 | validation: 0.10670987954299915]
	TIME [epoch: 26.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08980892426300977		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.08980892426300977 | validation: 0.08262170269487532]
	TIME [epoch: 26.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08611299723540539		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08611299723540539 | validation: 0.11228485667280465]
	TIME [epoch: 26.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0875008723445819		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.0875008723445819 | validation: 0.09268530044219814]
	TIME [epoch: 26.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09429936414477279		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.09429936414477279 | validation: 0.13358658364776277]
	TIME [epoch: 26.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09925005460807408		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.09925005460807408 | validation: 0.10767396000834108]
	TIME [epoch: 26.4 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08582493995045491		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.08582493995045491 | validation: 0.1192477241964859]
	TIME [epoch: 26.4 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754196739778396		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.13754196739778396 | validation: 0.09318356700643883]
	TIME [epoch: 26.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08989415141478964		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.08989415141478964 | validation: 0.08926916854386507]
	TIME [epoch: 26.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09524706408979669		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.09524706408979669 | validation: 0.13064736800390658]
	TIME [epoch: 26.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09163002323371194		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09163002323371194 | validation: 0.13869466362240016]
	TIME [epoch: 26.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075423265583333		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.13075423265583333 | validation: 0.0859610840885709]
	TIME [epoch: 26.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727108731971846		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.10727108731971846 | validation: 0.11680569599017299]
	TIME [epoch: 26.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07759765490014729		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.07759765490014729 | validation: 0.09279138876849098]
	TIME [epoch: 26.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08362353009636055		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08362353009636055 | validation: 0.11858631008903411]
	TIME [epoch: 26.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08406858375058457		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.08406858375058457 | validation: 0.11496818911408904]
	TIME [epoch: 26.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17569880547085717		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.17569880547085717 | validation: 0.12580762176461582]
	TIME [epoch: 26.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504840485975187		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.11504840485975187 | validation: 0.20483928315485514]
	TIME [epoch: 26.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13766081454505272		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.13766081454505272 | validation: 0.10859190221250184]
	TIME [epoch: 26.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10192040367278908		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.10192040367278908 | validation: 0.11863090505570321]
	TIME [epoch: 26.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09265779729217213		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.09265779729217213 | validation: 0.11713156339047523]
	TIME [epoch: 26.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08528682602512541		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.08528682602512541 | validation: 0.22910063230129302]
	TIME [epoch: 26.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.179521213853351		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.179521213853351 | validation: 0.09779814783274202]
	TIME [epoch: 26.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071551828834957		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.1071551828834957 | validation: 0.1328995829698586]
	TIME [epoch: 26.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12076422486759139		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.12076422486759139 | validation: 0.1240958256824948]
	TIME [epoch: 26.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11302989013750919		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.11302989013750919 | validation: 0.08876094500662904]
	TIME [epoch: 26.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12849589228792013		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.12849589228792013 | validation: 0.24424218100141715]
	TIME [epoch: 26.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1810124140220273		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.1810124140220273 | validation: 0.10767756498933792]
	TIME [epoch: 26.4 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09205360377990313		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.09205360377990313 | validation: 0.10466035225104708]
	TIME [epoch: 26.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13646119709370746		[learning rate: 0.00054421]
	Learning Rate: 0.000544214
	LOSS [training: 0.13646119709370746 | validation: 0.1183824406716508]
	TIME [epoch: 26.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10876405697614575		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.10876405697614575 | validation: 0.09553085380630855]
	TIME [epoch: 26.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09426424069086181		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.09426424069086181 | validation: 0.08168607833612358]
	TIME [epoch: 26.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09371061297315639		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.09371061297315639 | validation: 0.09359847461324705]
	TIME [epoch: 26.4 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1124838810499534		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.1124838810499534 | validation: 0.1175776787953282]
	TIME [epoch: 26.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1238912694560625		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1238912694560625 | validation: 0.1430649043461854]
	TIME [epoch: 26.4 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11780507781342431		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.11780507781342431 | validation: 0.09436332798937141]
	TIME [epoch: 26.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09136978639043149		[learning rate: 0.00053088]
	Learning Rate: 0.000530885
	LOSS [training: 0.09136978639043149 | validation: 0.10464949700226112]
	TIME [epoch: 26.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11870075644974314		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.11870075644974314 | validation: 0.13206049778928247]
	TIME [epoch: 26.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191499086601682		[learning rate: 0.00052714]
	Learning Rate: 0.000527137
	LOSS [training: 0.191499086601682 | validation: 0.12870307961983649]
	TIME [epoch: 26.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09939343567110295		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.09939343567110295 | validation: 0.1124043365455519]
	TIME [epoch: 26.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11535366055863339		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.11535366055863339 | validation: 0.11697963605213427]
	TIME [epoch: 26.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0909189020637089		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.0909189020637089 | validation: 0.08978900749453961]
	TIME [epoch: 26.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07814361483251013		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07814361483251013 | validation: 0.10903667133979913]
	TIME [epoch: 26.4 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08095628133127766		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.08095628133127766 | validation: 0.0830289484471105]
	TIME [epoch: 26.4 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10311951452216114		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.10311951452216114 | validation: 0.21324967398915048]
	TIME [epoch: 26.4 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14664786687515657		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.14664786687515657 | validation: 0.12427449296057512]
	TIME [epoch: 26.4 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385468598211063		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.08385468598211063 | validation: 0.10257137838474244]
	TIME [epoch: 26.4 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08497434534706265		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.08497434534706265 | validation: 0.13249429095481008]
	TIME [epoch: 26.4 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08577330674018634		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.08577330674018634 | validation: 0.11314752290463981]
	TIME [epoch: 26.4 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.121411369417769		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.121411369417769 | validation: 0.1141969357322967]
	TIME [epoch: 26.4 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08881838118600133		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.08881838118600133 | validation: 0.12424375200637926]
	TIME [epoch: 26.4 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08672054513762506		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08672054513762506 | validation: 0.11450210730104671]
	TIME [epoch: 26.4 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955274180181225		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.08955274180181225 | validation: 0.106375420870704]
	TIME [epoch: 26.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09414828870118751		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.09414828870118751 | validation: 0.1567815189441542]
	TIME [epoch: 26.4 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09414902418115809		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.09414902418115809 | validation: 0.10793876092226862]
	TIME [epoch: 26.4 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049230570590718		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.09049230570590718 | validation: 0.1333679196552503]
	TIME [epoch: 26.4 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0799980881536776		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.0799980881536776 | validation: 0.08737971138735388]
	TIME [epoch: 26.4 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08333347346093382		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.08333347346093382 | validation: 0.11923982598582164]
	TIME [epoch: 26.4 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355948111208367		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.11355948111208367 | validation: 0.10906873110231237]
	TIME [epoch: 26.4 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08154688888030485		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.08154688888030485 | validation: 0.11361028706500484]
	TIME [epoch: 26.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810051571311228		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.0810051571311228 | validation: 0.09319401938399689]
	TIME [epoch: 26.4 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07866162846037374		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.07866162846037374 | validation: 0.08521647333420694]
	TIME [epoch: 26.4 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08390325444504249		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08390325444504249 | validation: 0.1648559283298353]
	TIME [epoch: 26.4 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08999804164784045		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.08999804164784045 | validation: 0.08719581355337111]
	TIME [epoch: 26.4 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860350526953328		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06860350526953328 | validation: 0.09737416372414381]
	TIME [epoch: 26.4 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11211350771719497		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11211350771719497 | validation: 0.15299776048431157]
	TIME [epoch: 26.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11067105741406125		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11067105741406125 | validation: 0.09616329912473495]
	TIME [epoch: 26.4 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09744278790562705		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.09744278790562705 | validation: 0.12048678014635704]
	TIME [epoch: 26.4 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11855827292539811		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.11855827292539811 | validation: 0.14958954010681474]
	TIME [epoch: 26.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869364541594779		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.11869364541594779 | validation: 0.10187417940886266]
	TIME [epoch: 26.4 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09904991238438798		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.09904991238438798 | validation: 0.08233064047926245]
	TIME [epoch: 26.4 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08132948014204905		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.08132948014204905 | validation: 0.09753335432550729]
	TIME [epoch: 26.4 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09207837767041215		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.09207837767041215 | validation: 0.10048482560566416]
	TIME [epoch: 26.4 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374682100172108		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.10374682100172108 | validation: 0.10000568283620007]
	TIME [epoch: 26.4 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635455275301392		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.07635455275301392 | validation: 0.08399436793730877]
	TIME [epoch: 26.4 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09031119937916443		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.09031119937916443 | validation: 0.17660595139201724]
	TIME [epoch: 26.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09470678856015133		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.09470678856015133 | validation: 0.10660748985094909]
	TIME [epoch: 26.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07692115582158102		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07692115582158102 | validation: 0.09523636874668938]
	TIME [epoch: 26.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07117756253770507		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07117756253770507 | validation: 0.09710201723913146]
	TIME [epoch: 26.4 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07517687397150886		[learning rate: 0.00045588]
	Learning Rate: 0.000455876
	LOSS [training: 0.07517687397150886 | validation: 0.07669581101460585]
	TIME [epoch: 26.3 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_922.pth
	Model improved!!!
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06970253128365997		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.06970253128365997 | validation: 0.09320302486823778]
	TIME [epoch: 26.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10718385002518191		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.10718385002518191 | validation: 0.10791003367051297]
	TIME [epoch: 26.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09648562625679832		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.09648562625679832 | validation: 0.0724489326849673]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08057102116989037		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.08057102116989037 | validation: 0.15192715656275402]
	TIME [epoch: 26.4 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10304947327000541		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.10304947327000541 | validation: 0.06236996580595938]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_927.pth
	Model improved!!!
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07871107486559946		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.07871107486559946 | validation: 0.08350342706564329]
	TIME [epoch: 26.4 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07326370170683118		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.07326370170683118 | validation: 0.1075608016860568]
	TIME [epoch: 26.4 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10218919853452325		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.10218919853452325 | validation: 0.08301374213116172]
	TIME [epoch: 26.4 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09051241011766872		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.09051241011766872 | validation: 0.13936578107068837]
	TIME [epoch: 26.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09922058256767399		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.09922058256767399 | validation: 0.11421597719824456]
	TIME [epoch: 26.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08124804167985311		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.08124804167985311 | validation: 0.10437753825520013]
	TIME [epoch: 26.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07973171410007053		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07973171410007053 | validation: 0.1141388517677864]
	TIME [epoch: 26.4 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09891305131561343		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09891305131561343 | validation: 0.13724811667413506]
	TIME [epoch: 26.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119209597647906		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.1119209597647906 | validation: 0.10311977375102571]
	TIME [epoch: 26.4 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027778226209745		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07027778226209745 | validation: 0.08988121668751972]
	TIME [epoch: 26.4 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500817532967076		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.07500817532967076 | validation: 0.10147336698517698]
	TIME [epoch: 26.4 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09942093161563637		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.09942093161563637 | validation: 0.06611068664937804]
	TIME [epoch: 26.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06245734630242029		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.06245734630242029 | validation: 0.10667310891852369]
	TIME [epoch: 26.4 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604237040814508		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.08604237040814508 | validation: 0.09866847591822628]
	TIME [epoch: 26.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169901618869123		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.07169901618869123 | validation: 0.07665098679584782]
	TIME [epoch: 26.4 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796078695031969		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.07796078695031969 | validation: 0.11352013211292235]
	TIME [epoch: 26.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271726923372986		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.09271726923372986 | validation: 0.08095578528858395]
	TIME [epoch: 26.4 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08858796601212612		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.08858796601212612 | validation: 0.08714930280699915]
	TIME [epoch: 26.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10768583791176006		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.10768583791176006 | validation: 0.12281916533949977]
	TIME [epoch: 26.4 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918704191990493		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.10918704191990493 | validation: 0.11555467232415223]
	TIME [epoch: 26.4 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09687410333819838		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.09687410333819838 | validation: 0.08967206121063223]
	TIME [epoch: 26.4 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10439519452553131		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.10439519452553131 | validation: 0.08901691325269676]
	TIME [epoch: 26.4 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0965236871254666		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.0965236871254666 | validation: 0.17737836268973833]
	TIME [epoch: 26.4 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14523883901711307		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.14523883901711307 | validation: 0.13570234439951007]
	TIME [epoch: 26.4 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053768002340195		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.1053768002340195 | validation: 0.10896297018505913]
	TIME [epoch: 26.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529932768985661		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.10529932768985661 | validation: 0.09084181126637696]
	TIME [epoch: 26.4 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13004587691683744		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.13004587691683744 | validation: 0.12202123503346267]
	TIME [epoch: 26.4 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10914095156323965		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.10914095156323965 | validation: 0.11459247834593167]
	TIME [epoch: 26.4 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10668232619805432		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.10668232619805432 | validation: 0.14474372155980417]
	TIME [epoch: 26.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09330999516584777		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.09330999516584777 | validation: 0.09672245850230396]
	TIME [epoch: 26.4 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08712418036509816		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08712418036509816 | validation: 0.09963586324235137]
	TIME [epoch: 26.4 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07783159982967003		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07783159982967003 | validation: 0.089233358259778]
	TIME [epoch: 26.4 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09437227731434578		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.09437227731434578 | validation: 0.12248227199561773]
	TIME [epoch: 26.4 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09805660869722795		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.09805660869722795 | validation: 0.1416246058049742]
	TIME [epoch: 26.4 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14882943531934964		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.14882943531934964 | validation: 0.13125192335143895]
	TIME [epoch: 26.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09754464833602369		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.09754464833602369 | validation: 0.09205264051059545]
	TIME [epoch: 26.4 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0990423392337027		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.0990423392337027 | validation: 0.10125197002284211]
	TIME [epoch: 26.4 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0812035858716203		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.0812035858716203 | validation: 0.07411819743031003]
	TIME [epoch: 26.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0716331210293367		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.0716331210293367 | validation: 0.050102960759355546]
	TIME [epoch: 26.4 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_966.pth
	Model improved!!!
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06767299543924071		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.06767299543924071 | validation: 0.06778416489645467]
	TIME [epoch: 26.4 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062193181133656544		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.062193181133656544 | validation: 0.06931078803500647]
	TIME [epoch: 26.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06761766043734403		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.06761766043734403 | validation: 0.06415746764298146]
	TIME [epoch: 26.4 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08272448104957875		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.08272448104957875 | validation: 0.09374648258728284]
	TIME [epoch: 26.4 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07573172222779123		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.07573172222779123 | validation: 0.061748398735490324]
	TIME [epoch: 26.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08635930437225216		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.08635930437225216 | validation: 0.08916008606761644]
	TIME [epoch: 26.4 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07114671039958026		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.07114671039958026 | validation: 0.07568597587429843]
	TIME [epoch: 26.4 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06181434232618046		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.06181434232618046 | validation: 0.06420874089080429]
	TIME [epoch: 26.4 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11223003187630728		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.11223003187630728 | validation: 0.23801464527498517]
	TIME [epoch: 26.4 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16467413097958586		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.16467413097958586 | validation: 0.15779960691403166]
	TIME [epoch: 26.4 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14672408310852295		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.14672408310852295 | validation: 0.1246486867778852]
	TIME [epoch: 26.4 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11878384161157551		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11878384161157551 | validation: 0.16782664697993582]
	TIME [epoch: 26.4 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16616215578843718		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.16616215578843718 | validation: 0.17753665804207655]
	TIME [epoch: 26.4 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14910665441429719		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.14910665441429719 | validation: 0.16464484780455305]
	TIME [epoch: 26.4 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13144008510005475		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.13144008510005475 | validation: 0.16847290540478946]
	TIME [epoch: 26.4 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11546295690652025		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.11546295690652025 | validation: 0.0944244362502002]
	TIME [epoch: 26.4 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08644765399817708		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.08644765399817708 | validation: 0.09513094246827115]
	TIME [epoch: 26.4 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09736981681101446		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.09736981681101446 | validation: 0.10681290564893484]
	TIME [epoch: 26.4 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10621568980578922		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.10621568980578922 | validation: 0.10777007593223559]
	TIME [epoch: 26.4 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.092134741514524		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.092134741514524 | validation: 0.0801388997570067]
	TIME [epoch: 26.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0923438278813614		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.0923438278813614 | validation: 0.09429145841116436]
	TIME [epoch: 26.4 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07807391704054603		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.07807391704054603 | validation: 0.09369911324208728]
	TIME [epoch: 26.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08315743909896117		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.08315743909896117 | validation: 0.07821573966092729]
	TIME [epoch: 26.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453616391035547		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06453616391035547 | validation: 0.07436533077738394]
	TIME [epoch: 26.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06703812801829839		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.06703812801829839 | validation: 0.07304034081525695]
	TIME [epoch: 26.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10577761646369939		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.10577761646369939 | validation: 0.18404870821314334]
	TIME [epoch: 26.4 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11119321446015668		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.11119321446015668 | validation: 0.059150168184540525]
	TIME [epoch: 26.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07457309141860888		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.07457309141860888 | validation: 0.07467314422935051]
	TIME [epoch: 26.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08180278264905413		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.08180278264905413 | validation: 0.11772440770990586]
	TIME [epoch: 26.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09875735747650873		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.09875735747650873 | validation: 0.072324175429486]
	TIME [epoch: 26.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764288873735733		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.0764288873735733 | validation: 0.08205678611519937]
	TIME [epoch: 26.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08595310538281643		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.08595310538281643 | validation: 0.08672471745352028]
	TIME [epoch: 26.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908235487082186		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.08908235487082186 | validation: 0.10541813769954374]
	TIME [epoch: 26.4 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09482547664921276		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.09482547664921276 | validation: 0.10931024532404525]
	TIME [epoch: 26.4 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08587093262175317		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.08587093262175317 | validation: 0.08506173292837653]
	TIME [epoch: 491 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350880374405964		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.07350880374405964 | validation: 0.0870827214348538]
	TIME [epoch: 56.1 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08071856288684133		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.08071856288684133 | validation: 0.0691242447519586]
	TIME [epoch: 55.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058037338795654		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.07058037338795654 | validation: 0.0627894830050838]
	TIME [epoch: 55.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07372678607414472		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.07372678607414472 | validation: 0.10354837389477348]
	TIME [epoch: 55.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08132943403576776		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.08132943403576776 | validation: 0.07231892963741086]
	TIME [epoch: 55.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09325065382442235		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.09325065382442235 | validation: 0.08776523838036293]
	TIME [epoch: 55.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07676785471768871		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.07676785471768871 | validation: 0.08132769422725593]
	TIME [epoch: 55.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06919173473912825		[learning rate: 0.00033497]
	Learning Rate: 0.000334966
	LOSS [training: 0.06919173473912825 | validation: 0.08803415551213789]
	TIME [epoch: 55.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06901493896984895		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.06901493896984895 | validation: 0.1035652288008162]
	TIME [epoch: 55.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16966680670417755		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.16966680670417755 | validation: 0.17140897565431118]
	TIME [epoch: 55.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536618723139672		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.11536618723139672 | validation: 0.07650200112936555]
	TIME [epoch: 55.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07646525334533824		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.07646525334533824 | validation: 0.10427266477803002]
	TIME [epoch: 55.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08888171780440582		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.08888171780440582 | validation: 0.10962656896117562]
	TIME [epoch: 55.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08673370649962528		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.08673370649962528 | validation: 0.09257797742929538]
	TIME [epoch: 55.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08890004771399745		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.08890004771399745 | validation: 0.08615418233822851]
	TIME [epoch: 55.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08731644955311191		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.08731644955311191 | validation: 0.12125747373682058]
	TIME [epoch: 55.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09651934475454131		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.09651934475454131 | validation: 0.10500180497672038]
	TIME [epoch: 55.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0810373818315994		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0810373818315994 | validation: 0.0776113028838798]
	TIME [epoch: 55.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06463082547168358		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.06463082547168358 | validation: 0.07813212867399309]
	TIME [epoch: 55.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0586991044971442		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.0586991044971442 | validation: 0.08634528436306943]
	TIME [epoch: 55.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620932761196896		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.06620932761196896 | validation: 0.06819825706558183]
	TIME [epoch: 55.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06925690111219779		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.06925690111219779 | validation: 0.12111488673613785]
	TIME [epoch: 55.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08512215275051158		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.08512215275051158 | validation: 0.13420537761512383]
	TIME [epoch: 55.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08994293156074337		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.08994293156074337 | validation: 0.07930264670969006]
	TIME [epoch: 55.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468014269417546		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.06468014269417546 | validation: 0.0864624463223686]
	TIME [epoch: 55.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08195299250486424		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.08195299250486424 | validation: 0.0737094185726482]
	TIME [epoch: 55.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06470132424807695		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.06470132424807695 | validation: 0.09854855891334258]
	TIME [epoch: 55.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08094405398059701		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.08094405398059701 | validation: 0.08390314728280804]
	TIME [epoch: 55.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07856278054498625		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07856278054498625 | validation: 0.103192324852559]
	TIME [epoch: 55.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07126212714181923		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.07126212714181923 | validation: 0.09268105522781361]
	TIME [epoch: 55.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07044640529885973		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.07044640529885973 | validation: 0.10027668608954227]
	TIME [epoch: 55.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10490470485363604		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.10490470485363604 | validation: 0.11970568490477514]
	TIME [epoch: 55.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09761031560801532		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.09761031560801532 | validation: 0.0921953236130318]
	TIME [epoch: 55.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06426954759132317		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06426954759132317 | validation: 0.0715474343071364]
	TIME [epoch: 55.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05906810392324758		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.05906810392324758 | validation: 0.07543802629324907]
	TIME [epoch: 55.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641443141832169		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.06641443141832169 | validation: 0.06538203918823696]
	TIME [epoch: 55.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07328739764666105		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.07328739764666105 | validation: 0.09041501714573487]
	TIME [epoch: 55.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08018960421298774		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.08018960421298774 | validation: 0.10179611517650997]
	TIME [epoch: 55.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08788784188349685		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.08788784188349685 | validation: 0.09810031490908835]
	TIME [epoch: 55.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07104906556574375		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07104906556574375 | validation: 0.06802704291665951]
	TIME [epoch: 55.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07225082517586703		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.07225082517586703 | validation: 0.07886038533678141]
	TIME [epoch: 55.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600885734992684		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.07600885734992684 | validation: 0.09815680860725316]
	TIME [epoch: 55.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09041975487915574		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.09041975487915574 | validation: 0.11066350894695459]
	TIME [epoch: 55.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09340350001432098		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.09340350001432098 | validation: 0.09139038742609498]
	TIME [epoch: 55.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820210666695121		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.0820210666695121 | validation: 0.0925305779186148]
	TIME [epoch: 55.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07479198504420516		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07479198504420516 | validation: 0.0828150803271229]
	TIME [epoch: 55.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06356724567827614		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.06356724567827614 | validation: 0.07671843749364651]
	TIME [epoch: 55.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0694812909135238		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0694812909135238 | validation: 0.10298451135798882]
	TIME [epoch: 55.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07697926805069949		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.07697926805069949 | validation: 0.10389648859764108]
	TIME [epoch: 55.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768726850861459		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.0768726850861459 | validation: 0.09063344509486071]
	TIME [epoch: 55.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07158458203437114		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.07158458203437114 | validation: 0.10209940713800744]
	TIME [epoch: 55.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06810340228538496		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06810340228538496 | validation: 0.08476692776939056]
	TIME [epoch: 55.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06790530071463453		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.06790530071463453 | validation: 0.07902402218856056]
	TIME [epoch: 55.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07507197362311577		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.07507197362311577 | validation: 0.08373059435051866]
	TIME [epoch: 55.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07984322393478098		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.07984322393478098 | validation: 0.07271883958633604]
	TIME [epoch: 56 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561569152787135		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.0561569152787135 | validation: 0.06427649866396452]
	TIME [epoch: 55.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07882297034052138		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.07882297034052138 | validation: 0.11467172531099676]
	TIME [epoch: 56 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08580268377087975		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.08580268377087975 | validation: 0.08087169444006322]
	TIME [epoch: 56 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07805252918119013		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.07805252918119013 | validation: 0.09354647126468929]
	TIME [epoch: 56 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07539419394477663		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.07539419394477663 | validation: 0.07007067686071192]
	TIME [epoch: 56 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0831278040600285		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.0831278040600285 | validation: 0.06419824190020483]
	TIME [epoch: 56 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07081429651920738		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.07081429651920738 | validation: 0.06886376011579719]
	TIME [epoch: 56 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08872632292117019		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.08872632292117019 | validation: 0.0951572536629895]
	TIME [epoch: 55.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09676014766879898		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.09676014766879898 | validation: 0.12013077764731611]
	TIME [epoch: 55.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09770280780273687		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.09770280780273687 | validation: 0.1086462806431018]
	TIME [epoch: 55.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0704188424725436		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.0704188424725436 | validation: 0.07961160043320169]
	TIME [epoch: 56 sec]
	Saving model to: out/model_training/model_phi1_1a_v_klv1_20241205_183247/states/model_phi1_1a_v_klv1_1067.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 23672.430 seconds.
