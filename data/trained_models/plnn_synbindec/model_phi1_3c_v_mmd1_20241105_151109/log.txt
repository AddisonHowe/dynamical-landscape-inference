Args:
Namespace(name='model_phi1_3c_v_mmd1', outdir='out/model_training/model_phi1_3c_v_mmd1', training_data='data/training_data/basic/data_phi1_3c/training', validation_data='data/training_data/basic/data_phi1_3c/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4181930181

Training model...

Saving initial model state to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.575506241702331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.575506241702331 | validation: 6.259960338209047]
	TIME [epoch: 267 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 1/1] avg loss: 6.066263853852158		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.066263853852158 | validation: 5.4166022209383735]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.191350869895871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.191350869895871 | validation: 5.444968962613851]
	TIME [epoch: 2.82 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 1/1] avg loss: 5.2644928060503196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2644928060503196 | validation: 4.574564912878028]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.258222947180235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.258222947180235 | validation: 4.59257410365491]
	TIME [epoch: 2.81 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.261862094630021		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.261862094630021 | validation: 4.453022113080215]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.171108340610857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.171108340610857 | validation: 4.462277693730529]
	TIME [epoch: 2.83 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.173710940123907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.173710940123907 | validation: 4.481655892131587]
	TIME [epoch: 2.83 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.173266497150989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.173266497150989 | validation: 4.551409209157597]
	TIME [epoch: 2.83 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.281755996871208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.281755996871208 | validation: 4.342633323191694]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.017164504778624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.017164504778624 | validation: 4.292968004272396]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.975759783264077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.975759783264077 | validation: 4.2843896073939645]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.963367114350075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.963367114350075 | validation: 4.295731844968432]
	TIME [epoch: 2.82 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9797478923715794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9797478923715794 | validation: 4.352443885447302]
	TIME [epoch: 2.82 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.0921452674723415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0921452674723415 | validation: 4.314852413119878]
	TIME [epoch: 2.83 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 1/1] avg loss: 4.004212593756316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.004212593756316 | validation: 4.230504609388048]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.93350648955362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.93350648955362 | validation: 4.172272779180895]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.855964803173512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.855964803173512 | validation: 4.119217155646218]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.826714943938697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.826714943938697 | validation: 4.128652386086722]
	TIME [epoch: 2.84 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8133606344234727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8133606344234727 | validation: 4.123955789097991]
	TIME [epoch: 2.84 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.855484727922377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.855484727922377 | validation: 4.277210903912672]
	TIME [epoch: 2.83 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.9879217162966927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9879217162966927 | validation: 4.190590653282168]
	TIME [epoch: 2.82 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.930702837388441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.930702837388441 | validation: 4.037312761843407]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7282719380676475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7282719380676475 | validation: 3.9416959951170405]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7035608058220055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7035608058220055 | validation: 4.0143987325988455]
	TIME [epoch: 2.82 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7013079638627233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7013079638627233 | validation: 3.9547805246443404]
	TIME [epoch: 2.82 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.7167316726307003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7167316726307003 | validation: 4.111557073670698]
	TIME [epoch: 2.81 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8200634383284773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8200634383284773 | validation: 4.137349569937776]
	TIME [epoch: 2.82 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.8604846106619117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8604846106619117 | validation: 3.893743286766611]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.613853948600972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.613853948600972 | validation: 3.8323790612560007]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6030118063394765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6030118063394765 | validation: 3.8136363494579144]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.576158816120885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.576158816120885 | validation: 3.8265915959032855]
	TIME [epoch: 2.82 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5559592531199575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5559592531199575 | validation: 3.9556684077988304]
	TIME [epoch: 2.82 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6701182890552424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6701182890552424 | validation: 4.0964194943957635]
	TIME [epoch: 2.81 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.82268656000087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.82268656000087 | validation: 3.8403721855307595]
	TIME [epoch: 2.81 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.591016999295979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.591016999295979 | validation: 3.7840028218832518]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5465261514224973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5465261514224973 | validation: 3.9762141566519604]
	TIME [epoch: 2.82 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.703482250981258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.703482250981258 | validation: 3.947081766043516]
	TIME [epoch: 2.82 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6696534298602512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6696534298602512 | validation: 3.6754173531441396]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4437900399064167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4437900399064167 | validation: 3.726637843937875]
	TIME [epoch: 2.82 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4945472899669303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4945472899669303 | validation: 3.956207437025725]
	TIME [epoch: 2.82 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6604341267839433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6604341267839433 | validation: 3.698390012672489]
	TIME [epoch: 2.81 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4468889989811613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4468889989811613 | validation: 3.609863996231868]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.390865762890048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.390865762890048 | validation: 3.6329297637133937]
	TIME [epoch: 2.81 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.386004700941867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.386004700941867 | validation: 3.624203678980374]
	TIME [epoch: 2.81 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.397229315066012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.397229315066012 | validation: 3.8093782741119044]
	TIME [epoch: 2.81 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.527364590652993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.527364590652993 | validation: 3.648101909122353]
	TIME [epoch: 2.82 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4139592745549625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4139592745549625 | validation: 3.619907934303173]
	TIME [epoch: 2.82 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.358382296091894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.358382296091894 | validation: 3.5199056931677717]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.313398877990885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.313398877990885 | validation: 3.560375759510757]
	TIME [epoch: 2.82 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.304403415336351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.304403415336351 | validation: 3.577418193463048]
	TIME [epoch: 2.82 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3614683307756277		[learning rate: 0.0099646]
	Learning Rate: 0.00996464
	LOSS [training: 3.3614683307756277 | validation: 3.7710310653411057]
	TIME [epoch: 2.81 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.4777606607199143		[learning rate: 0.0099294]
	Learning Rate: 0.0099294
	LOSS [training: 3.4777606607199143 | validation: 3.538176786930589]
	TIME [epoch: 2.81 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.3137290979718332		[learning rate: 0.0098943]
	Learning Rate: 0.00989429
	LOSS [training: 3.3137290979718332 | validation: 3.468575914759363]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2360397124010163		[learning rate: 0.0098593]
	Learning Rate: 0.0098593
	LOSS [training: 3.2360397124010163 | validation: 3.4226356019614865]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2169317100790544		[learning rate: 0.0098244]
	Learning Rate: 0.00982444
	LOSS [training: 3.2169317100790544 | validation: 3.4007070668617683]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1883109122208113		[learning rate: 0.0097897]
	Learning Rate: 0.0097897
	LOSS [training: 3.1883109122208113 | validation: 3.3733776666789357]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.162638241576261		[learning rate: 0.0097551]
	Learning Rate: 0.00975508
	LOSS [training: 3.162638241576261 | validation: 3.4218465797511826]
	TIME [epoch: 2.82 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1623125501720573		[learning rate: 0.0097206]
	Learning Rate: 0.00972058
	LOSS [training: 3.1623125501720573 | validation: 3.78512862458783]
	TIME [epoch: 2.82 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.541532399368556		[learning rate: 0.0096862]
	Learning Rate: 0.00968621
	LOSS [training: 3.541532399368556 | validation: 3.4636294138105295]
	TIME [epoch: 2.85 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.231127464828174		[learning rate: 0.009652]
	Learning Rate: 0.00965196
	LOSS [training: 3.231127464828174 | validation: 3.320491724148381]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.114292576343521		[learning rate: 0.0096178]
	Learning Rate: 0.00961783
	LOSS [training: 3.114292576343521 | validation: 3.3760412181774897]
	TIME [epoch: 2.82 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1173881824115997		[learning rate: 0.0095838]
	Learning Rate: 0.00958382
	LOSS [training: 3.1173881824115997 | validation: 3.7625799455098545]
	TIME [epoch: 2.82 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.5382760567466516		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 3.5382760567466516 | validation: 3.367003871950776]
	TIME [epoch: 2.81 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.154737752543678		[learning rate: 0.0095162]
	Learning Rate: 0.00951616
	LOSS [training: 3.154737752543678 | validation: 3.3085842637805145]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.1000966921985595		[learning rate: 0.0094825]
	Learning Rate: 0.0094825
	LOSS [training: 3.1000966921985595 | validation: 3.2663188727436068]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.089461469194734		[learning rate: 0.009449]
	Learning Rate: 0.00944897
	LOSS [training: 3.089461469194734 | validation: 3.9062471764918487]
	TIME [epoch: 2.83 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.6657003855719625		[learning rate: 0.0094156]
	Learning Rate: 0.00941556
	LOSS [training: 3.6657003855719625 | validation: 3.4329571449442797]
	TIME [epoch: 2.82 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.2717116085098223		[learning rate: 0.0093823]
	Learning Rate: 0.00938226
	LOSS [training: 3.2717116085098223 | validation: 3.174435872494491]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.013523200798802		[learning rate: 0.0093491]
	Learning Rate: 0.00934909
	LOSS [training: 3.013523200798802 | validation: 3.1854592812408344]
	TIME [epoch: 2.83 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 1/1] avg loss: 3.0193150216920275		[learning rate: 0.009316]
	Learning Rate: 0.00931603
	LOSS [training: 3.0193150216920275 | validation: 3.078306063994106]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.925507386216667		[learning rate: 0.0092831]
	Learning Rate: 0.00928308
	LOSS [training: 2.925507386216667 | validation: 2.933556984924216]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.832418009137327		[learning rate: 0.0092503]
	Learning Rate: 0.00925026
	LOSS [training: 2.832418009137327 | validation: 2.729460568447315]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.660706483867216		[learning rate: 0.0092175]
	Learning Rate: 0.00921755
	LOSS [training: 2.660706483867216 | validation: 2.2406262613864714]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 1/1] avg loss: 2.122948749752828		[learning rate: 0.009185]
	Learning Rate: 0.00918495
	LOSS [training: 2.122948749752828 | validation: 1.4608431106385062]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.620450068546597		[learning rate: 0.0091525]
	Learning Rate: 0.00915247
	LOSS [training: 1.620450068546597 | validation: 1.2492872069855985]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3167320229336128		[learning rate: 0.0091201]
	Learning Rate: 0.00912011
	LOSS [training: 1.3167320229336128 | validation: 1.1450907943843824]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.3346141615137483		[learning rate: 0.0090879]
	Learning Rate: 0.00908786
	LOSS [training: 1.3346141615137483 | validation: 1.1580949451859823]
	TIME [epoch: 2.82 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 1/1] avg loss: 1.2503808330743345		[learning rate: 0.0090557]
	Learning Rate: 0.00905572
	LOSS [training: 1.2503808330743345 | validation: 0.963322375319158]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9841403666686285		[learning rate: 0.0090237]
	Learning Rate: 0.0090237
	LOSS [training: 0.9841403666686285 | validation: 0.8254535399878243]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8940009706957344		[learning rate: 0.0089918]
	Learning Rate: 0.00899179
	LOSS [training: 0.8940009706957344 | validation: 0.8040336696791903]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9040500948680724		[learning rate: 0.00896]
	Learning Rate: 0.00895999
	LOSS [training: 0.9040500948680724 | validation: 0.7504233289653919]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8155269848667541		[learning rate: 0.0089283]
	Learning Rate: 0.00892831
	LOSS [training: 0.8155269848667541 | validation: 0.7486296615981175]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7495429393156083		[learning rate: 0.0088967]
	Learning Rate: 0.00889674
	LOSS [training: 0.7495429393156083 | validation: 0.7305323591831789]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7382711233687504		[learning rate: 0.0088653]
	Learning Rate: 0.00886528
	LOSS [training: 0.7382711233687504 | validation: 0.7302668340335585]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7372434257100386		[learning rate: 0.0088339]
	Learning Rate: 0.00883393
	LOSS [training: 0.7372434257100386 | validation: 0.7219297685589156]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7145824814647455		[learning rate: 0.0088027]
	Learning Rate: 0.00880269
	LOSS [training: 0.7145824814647455 | validation: 0.7115445721269186]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7209543980718968		[learning rate: 0.0087716]
	Learning Rate: 0.00877156
	LOSS [training: 0.7209543980718968 | validation: 0.7324492851701401]
	TIME [epoch: 2.83 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.733981107108023		[learning rate: 0.0087405]
	Learning Rate: 0.00874054
	LOSS [training: 0.733981107108023 | validation: 0.7707749099544183]
	TIME [epoch: 2.84 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8310878535514526		[learning rate: 0.0087096]
	Learning Rate: 0.00870964
	LOSS [training: 0.8310878535514526 | validation: 0.7713776918264241]
	TIME [epoch: 2.83 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8005734632477399		[learning rate: 0.0086788]
	Learning Rate: 0.00867884
	LOSS [training: 0.8005734632477399 | validation: 0.7214401337279145]
	TIME [epoch: 2.83 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7209765656652729		[learning rate: 0.0086481]
	Learning Rate: 0.00864815
	LOSS [training: 0.7209765656652729 | validation: 0.7158330007423214]
	TIME [epoch: 2.83 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7052281560251302		[learning rate: 0.0086176]
	Learning Rate: 0.00861757
	LOSS [training: 0.7052281560251302 | validation: 0.713102000586551]
	TIME [epoch: 2.83 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7000248485629692		[learning rate: 0.0085871]
	Learning Rate: 0.00858709
	LOSS [training: 0.7000248485629692 | validation: 0.7011961191855486]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6895259417074283		[learning rate: 0.0085567]
	Learning Rate: 0.00855673
	LOSS [training: 0.6895259417074283 | validation: 0.7044234427039953]
	TIME [epoch: 2.84 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6779446121043902		[learning rate: 0.0085265]
	Learning Rate: 0.00852647
	LOSS [training: 0.6779446121043902 | validation: 0.7081260698109911]
	TIME [epoch: 2.84 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6799742748612121		[learning rate: 0.0084963]
	Learning Rate: 0.00849632
	LOSS [training: 0.6799742748612121 | validation: 0.7028833076460899]
	TIME [epoch: 2.83 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6687104570179565		[learning rate: 0.0084663]
	Learning Rate: 0.00846627
	LOSS [training: 0.6687104570179565 | validation: 0.7033510394985772]
	TIME [epoch: 2.84 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6840262709839016		[learning rate: 0.0084363]
	Learning Rate: 0.00843634
	LOSS [training: 0.6840262709839016 | validation: 0.6985363443516351]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6898141554761941		[learning rate: 0.0084065]
	Learning Rate: 0.0084065
	LOSS [training: 0.6898141554761941 | validation: 0.7005426616782393]
	TIME [epoch: 2.83 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6949555159658823		[learning rate: 0.0083768]
	Learning Rate: 0.00837678
	LOSS [training: 0.6949555159658823 | validation: 0.7222339920427925]
	TIME [epoch: 2.81 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7347535461087219		[learning rate: 0.0083472]
	Learning Rate: 0.00834715
	LOSS [training: 0.7347535461087219 | validation: 0.920436203609908]
	TIME [epoch: 2.81 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.9757908037763311		[learning rate: 0.0083176]
	Learning Rate: 0.00831764
	LOSS [training: 0.9757908037763311 | validation: 0.6982718450850574]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7275922626975103		[learning rate: 0.0082882]
	Learning Rate: 0.00828823
	LOSS [training: 0.7275922626975103 | validation: 0.831017901596718]
	TIME [epoch: 2.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8295105951441997		[learning rate: 0.0082589]
	Learning Rate: 0.00825892
	LOSS [training: 0.8295105951441997 | validation: 0.8039314249660529]
	TIME [epoch: 2.9 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8189921334578797		[learning rate: 0.0082297]
	Learning Rate: 0.00822971
	LOSS [training: 0.8189921334578797 | validation: 0.7007993652589047]
	TIME [epoch: 2.81 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7206052430639213		[learning rate: 0.0082006]
	Learning Rate: 0.00820061
	LOSS [training: 0.7206052430639213 | validation: 0.7531322205872137]
	TIME [epoch: 2.82 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7189551885649357		[learning rate: 0.0081716]
	Learning Rate: 0.00817161
	LOSS [training: 0.7189551885649357 | validation: 0.7258979733121085]
	TIME [epoch: 2.82 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.700947487702448		[learning rate: 0.0081427]
	Learning Rate: 0.00814272
	LOSS [training: 0.700947487702448 | validation: 0.7280054701614083]
	TIME [epoch: 2.82 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7221665341426214		[learning rate: 0.0081139]
	Learning Rate: 0.00811392
	LOSS [training: 0.7221665341426214 | validation: 0.6835497995797948]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6615582568186029		[learning rate: 0.0080852]
	Learning Rate: 0.00808523
	LOSS [training: 0.6615582568186029 | validation: 0.7389547733917201]
	TIME [epoch: 2.82 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7424463248764692		[learning rate: 0.0080566]
	Learning Rate: 0.00805664
	LOSS [training: 0.7424463248764692 | validation: 0.714547229417372]
	TIME [epoch: 2.81 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7188519670230076		[learning rate: 0.0080281]
	Learning Rate: 0.00802815
	LOSS [training: 0.7188519670230076 | validation: 0.698697258551987]
	TIME [epoch: 2.81 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6883153824006027		[learning rate: 0.0079998]
	Learning Rate: 0.00799976
	LOSS [training: 0.6883153824006027 | validation: 0.7358009866610291]
	TIME [epoch: 2.81 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7214777197150412		[learning rate: 0.0079715]
	Learning Rate: 0.00797147
	LOSS [training: 0.7214777197150412 | validation: 0.6968816997898619]
	TIME [epoch: 2.81 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6954590258762601		[learning rate: 0.0079433]
	Learning Rate: 0.00794328
	LOSS [training: 0.6954590258762601 | validation: 0.6753093576035515]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6670823559109674		[learning rate: 0.0079152]
	Learning Rate: 0.00791519
	LOSS [training: 0.6670823559109674 | validation: 0.7018302276881633]
	TIME [epoch: 2.83 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6533928686550255		[learning rate: 0.0078872]
	Learning Rate: 0.0078872
	LOSS [training: 0.6533928686550255 | validation: 0.6866864037916142]
	TIME [epoch: 2.83 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6414840073394318		[learning rate: 0.0078593]
	Learning Rate: 0.00785931
	LOSS [training: 0.6414840073394318 | validation: 0.690904458617617]
	TIME [epoch: 2.83 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6416117999698452		[learning rate: 0.0078315]
	Learning Rate: 0.00783152
	LOSS [training: 0.6416117999698452 | validation: 0.697105422570673]
	TIME [epoch: 2.82 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6422337875757108		[learning rate: 0.0078038]
	Learning Rate: 0.00780383
	LOSS [training: 0.6422337875757108 | validation: 0.6743173134273487]
	TIME [epoch: 2.81 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6453168801219336		[learning rate: 0.0077762]
	Learning Rate: 0.00777623
	LOSS [training: 0.6453168801219336 | validation: 0.693385699658353]
	TIME [epoch: 2.83 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6392098361755266		[learning rate: 0.0077487]
	Learning Rate: 0.00774873
	LOSS [training: 0.6392098361755266 | validation: 0.7080633077235436]
	TIME [epoch: 2.83 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6678733389796176		[learning rate: 0.0077213]
	Learning Rate: 0.00772133
	LOSS [training: 0.6678733389796176 | validation: 0.7947834496698845]
	TIME [epoch: 2.83 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8042325034200982		[learning rate: 0.007694]
	Learning Rate: 0.00769403
	LOSS [training: 0.8042325034200982 | validation: 0.6884965191310752]
	TIME [epoch: 2.82 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.698669045757703		[learning rate: 0.0076668]
	Learning Rate: 0.00766682
	LOSS [training: 0.698669045757703 | validation: 0.6858428736280422]
	TIME [epoch: 2.82 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6718074503037663		[learning rate: 0.0076397]
	Learning Rate: 0.00763971
	LOSS [training: 0.6718074503037663 | validation: 0.6634879969481429]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.677797517274689		[learning rate: 0.0076127]
	Learning Rate: 0.0076127
	LOSS [training: 0.677797517274689 | validation: 0.6844289991794319]
	TIME [epoch: 2.83 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6349282422708716		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 0.6349282422708716 | validation: 0.6792383668442441]
	TIME [epoch: 2.83 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6501891354372991		[learning rate: 0.007559]
	Learning Rate: 0.00755895
	LOSS [training: 0.6501891354372991 | validation: 0.698385511688882]
	TIME [epoch: 2.83 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6864498974598368		[learning rate: 0.0075322]
	Learning Rate: 0.00753222
	LOSS [training: 0.6864498974598368 | validation: 0.7125435026022241]
	TIME [epoch: 2.83 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7040184395651743		[learning rate: 0.0075056]
	Learning Rate: 0.00750559
	LOSS [training: 0.7040184395651743 | validation: 0.6915030372976649]
	TIME [epoch: 2.83 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7132763228100767		[learning rate: 0.007479]
	Learning Rate: 0.00747905
	LOSS [training: 0.7132763228100767 | validation: 0.6949365256262822]
	TIME [epoch: 2.83 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6742187149541381		[learning rate: 0.0074526]
	Learning Rate: 0.0074526
	LOSS [training: 0.6742187149541381 | validation: 0.7138583777526141]
	TIME [epoch: 2.83 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6790100515053752		[learning rate: 0.0074262]
	Learning Rate: 0.00742624
	LOSS [training: 0.6790100515053752 | validation: 0.6718697824010132]
	TIME [epoch: 2.82 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6854566080535088		[learning rate: 0.0074]
	Learning Rate: 0.00739998
	LOSS [training: 0.6854566080535088 | validation: 0.6957140861446435]
	TIME [epoch: 2.83 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6310737940981131		[learning rate: 0.0073738]
	Learning Rate: 0.00737382
	LOSS [training: 0.6310737940981131 | validation: 0.7016734305830359]
	TIME [epoch: 2.83 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6296145768252254		[learning rate: 0.0073477]
	Learning Rate: 0.00734774
	LOSS [training: 0.6296145768252254 | validation: 0.6653825773828688]
	TIME [epoch: 2.83 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6518882653267443		[learning rate: 0.0073218]
	Learning Rate: 0.00732176
	LOSS [training: 0.6518882653267443 | validation: 0.6877057806927593]
	TIME [epoch: 2.84 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6420117991657789		[learning rate: 0.0072959]
	Learning Rate: 0.00729587
	LOSS [training: 0.6420117991657789 | validation: 0.7251349435269177]
	TIME [epoch: 2.83 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7570749191882824		[learning rate: 0.0072701]
	Learning Rate: 0.00727007
	LOSS [training: 0.7570749191882824 | validation: 0.8555434574924512]
	TIME [epoch: 2.83 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8340679166166737		[learning rate: 0.0072444]
	Learning Rate: 0.00724436
	LOSS [training: 0.8340679166166737 | validation: 0.6875785639979606]
	TIME [epoch: 2.83 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6610422852507031		[learning rate: 0.0072187]
	Learning Rate: 0.00721874
	LOSS [training: 0.6610422852507031 | validation: 0.7160188575085951]
	TIME [epoch: 2.83 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7132922910427163		[learning rate: 0.0071932]
	Learning Rate: 0.00719322
	LOSS [training: 0.7132922910427163 | validation: 0.725727316015735]
	TIME [epoch: 2.82 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6978384358593729		[learning rate: 0.0071678]
	Learning Rate: 0.00716778
	LOSS [training: 0.6978384358593729 | validation: 0.673651962217352]
	TIME [epoch: 2.83 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6300963584825369		[learning rate: 0.0071424]
	Learning Rate: 0.00714243
	LOSS [training: 0.6300963584825369 | validation: 0.7027960525750588]
	TIME [epoch: 2.82 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6412095819184608		[learning rate: 0.0071172]
	Learning Rate: 0.00711718
	LOSS [training: 0.6412095819184608 | validation: 0.671410882835799]
	TIME [epoch: 2.83 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6276580211621419		[learning rate: 0.007092]
	Learning Rate: 0.00709201
	LOSS [training: 0.6276580211621419 | validation: 0.6709261610984815]
	TIME [epoch: 2.83 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6195538838480669		[learning rate: 0.0070669]
	Learning Rate: 0.00706693
	LOSS [training: 0.6195538838480669 | validation: 0.6719701201977423]
	TIME [epoch: 2.84 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6306688574574983		[learning rate: 0.0070419]
	Learning Rate: 0.00704194
	LOSS [training: 0.6306688574574983 | validation: 0.6946064503978825]
	TIME [epoch: 2.83 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6590755042620358		[learning rate: 0.007017]
	Learning Rate: 0.00701704
	LOSS [training: 0.6590755042620358 | validation: 0.6706383064484461]
	TIME [epoch: 2.82 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7040797549982143		[learning rate: 0.0069922]
	Learning Rate: 0.00699223
	LOSS [training: 0.7040797549982143 | validation: 0.7017984714684027]
	TIME [epoch: 2.82 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6617118724929074		[learning rate: 0.0069675]
	Learning Rate: 0.0069675
	LOSS [training: 0.6617118724929074 | validation: 0.7013901343467741]
	TIME [epoch: 2.83 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6406560422792767		[learning rate: 0.0069429]
	Learning Rate: 0.00694286
	LOSS [training: 0.6406560422792767 | validation: 0.664448556960464]
	TIME [epoch: 2.82 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6327538936623717		[learning rate: 0.0069183]
	Learning Rate: 0.00691831
	LOSS [training: 0.6327538936623717 | validation: 0.6736869208942124]
	TIME [epoch: 2.83 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6149856545366331		[learning rate: 0.0068938]
	Learning Rate: 0.00689385
	LOSS [training: 0.6149856545366331 | validation: 0.6669476363410873]
	TIME [epoch: 2.82 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6246590807649708		[learning rate: 0.0068695]
	Learning Rate: 0.00686947
	LOSS [training: 0.6246590807649708 | validation: 0.7057642912794047]
	TIME [epoch: 2.83 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6897931361519208		[learning rate: 0.0068452]
	Learning Rate: 0.00684518
	LOSS [training: 0.6897931361519208 | validation: 0.6864818358371807]
	TIME [epoch: 2.83 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7492514602749517		[learning rate: 0.006821]
	Learning Rate: 0.00682097
	LOSS [training: 0.7492514602749517 | validation: 0.7407899518462739]
	TIME [epoch: 2.83 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7201938576821469		[learning rate: 0.0067968]
	Learning Rate: 0.00679685
	LOSS [training: 0.7201938576821469 | validation: 0.7225231363285334]
	TIME [epoch: 2.83 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7006914717142996		[learning rate: 0.0067728]
	Learning Rate: 0.00677282
	LOSS [training: 0.7006914717142996 | validation: 0.6519928409880699]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6778842316879994		[learning rate: 0.0067489]
	Learning Rate: 0.00674886
	LOSS [training: 0.6778842316879994 | validation: 0.6508337912054563]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6297925924951739		[learning rate: 0.006725]
	Learning Rate: 0.006725
	LOSS [training: 0.6297925924951739 | validation: 0.7070736817706571]
	TIME [epoch: 2.83 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6465931220331873		[learning rate: 0.0067012]
	Learning Rate: 0.00670122
	LOSS [training: 0.6465931220331873 | validation: 0.6556721269647773]
	TIME [epoch: 2.82 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6064113849014333		[learning rate: 0.0066775]
	Learning Rate: 0.00667752
	LOSS [training: 0.6064113849014333 | validation: 0.6594559799972987]
	TIME [epoch: 2.82 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5946661030521084		[learning rate: 0.0066539]
	Learning Rate: 0.00665391
	LOSS [training: 0.5946661030521084 | validation: 0.6804441925416138]
	TIME [epoch: 2.83 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6242063137298154		[learning rate: 0.0066304]
	Learning Rate: 0.00663038
	LOSS [training: 0.6242063137298154 | validation: 0.6809547738239154]
	TIME [epoch: 2.82 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7014694315172648		[learning rate: 0.0066069]
	Learning Rate: 0.00660693
	LOSS [training: 0.7014694315172648 | validation: 0.7115696358396948]
	TIME [epoch: 2.83 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6922986930446652		[learning rate: 0.0065836]
	Learning Rate: 0.00658357
	LOSS [training: 0.6922986930446652 | validation: 0.7210890579868506]
	TIME [epoch: 2.82 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6432618493443775		[learning rate: 0.0065603]
	Learning Rate: 0.00656029
	LOSS [training: 0.6432618493443775 | validation: 0.6301517060456788]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_170.pth
	Model improved!!!
EPOCH 171/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5819643904746912		[learning rate: 0.0065371]
	Learning Rate: 0.00653709
	LOSS [training: 0.5819643904746912 | validation: 0.6496296374099756]
	TIME [epoch: 2.83 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5783290903827755		[learning rate: 0.006514]
	Learning Rate: 0.00651398
	LOSS [training: 0.5783290903827755 | validation: 0.6672670974758129]
	TIME [epoch: 2.82 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5990128960658824		[learning rate: 0.0064909]
	Learning Rate: 0.00649094
	LOSS [training: 0.5990128960658824 | validation: 0.6285089412113025]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5940030788303134		[learning rate: 0.006468]
	Learning Rate: 0.00646799
	LOSS [training: 0.5940030788303134 | validation: 0.6869491469935571]
	TIME [epoch: 2.82 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6197733540746462		[learning rate: 0.0064451]
	Learning Rate: 0.00644512
	LOSS [training: 0.6197733540746462 | validation: 0.6220478721203917]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6121945230858036		[learning rate: 0.0064223]
	Learning Rate: 0.00642233
	LOSS [training: 0.6121945230858036 | validation: 0.6574083113550432]
	TIME [epoch: 2.83 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.583535403322543		[learning rate: 0.0063996]
	Learning Rate: 0.00639961
	LOSS [training: 0.583535403322543 | validation: 0.6084569475639527]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.582838810844703		[learning rate: 0.006377]
	Learning Rate: 0.00637698
	LOSS [training: 0.582838810844703 | validation: 0.6156538856485727]
	TIME [epoch: 2.82 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5893471990168676		[learning rate: 0.0063544]
	Learning Rate: 0.00635443
	LOSS [training: 0.5893471990168676 | validation: 0.6662168519741515]
	TIME [epoch: 2.83 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7087612400320026		[learning rate: 0.006332]
	Learning Rate: 0.00633196
	LOSS [training: 0.7087612400320026 | validation: 0.7520237778677983]
	TIME [epoch: 2.82 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.8118968731143187		[learning rate: 0.0063096]
	Learning Rate: 0.00630957
	LOSS [training: 0.8118968731143187 | validation: 0.6360847884403932]
	TIME [epoch: 2.83 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5848957007938126		[learning rate: 0.0062873]
	Learning Rate: 0.00628726
	LOSS [training: 0.5848957007938126 | validation: 0.6331804888930342]
	TIME [epoch: 2.81 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6578137284232533		[learning rate: 0.006265]
	Learning Rate: 0.00626503
	LOSS [training: 0.6578137284232533 | validation: 0.654488571689686]
	TIME [epoch: 2.83 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6175312336831195		[learning rate: 0.0062429]
	Learning Rate: 0.00624287
	LOSS [training: 0.6175312336831195 | validation: 0.6510077231368415]
	TIME [epoch: 2.82 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5996093174969337		[learning rate: 0.0062208]
	Learning Rate: 0.0062208
	LOSS [training: 0.5996093174969337 | validation: 0.6541728459764571]
	TIME [epoch: 2.83 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6075968512062633		[learning rate: 0.0061988]
	Learning Rate: 0.0061988
	LOSS [training: 0.6075968512062633 | validation: 0.6458994787178455]
	TIME [epoch: 2.82 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5765637012655468		[learning rate: 0.0061769]
	Learning Rate: 0.00617688
	LOSS [training: 0.5765637012655468 | validation: 0.6027492566189905]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_187.pth
	Model improved!!!
EPOCH 188/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5831637690853938		[learning rate: 0.006155]
	Learning Rate: 0.00615504
	LOSS [training: 0.5831637690853938 | validation: 0.6567514620525798]
	TIME [epoch: 2.83 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5778893314969524		[learning rate: 0.0061333]
	Learning Rate: 0.00613327
	LOSS [training: 0.5778893314969524 | validation: 0.6035596113229463]
	TIME [epoch: 2.83 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.565381799850036		[learning rate: 0.0061116]
	Learning Rate: 0.00611158
	LOSS [training: 0.565381799850036 | validation: 0.623465083014295]
	TIME [epoch: 2.83 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5573394818079446		[learning rate: 0.00609]
	Learning Rate: 0.00608997
	LOSS [training: 0.5573394818079446 | validation: 0.5848591800000581]
	TIME [epoch: 2.82 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_191.pth
	Model improved!!!
EPOCH 192/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5528696228217692		[learning rate: 0.0060684]
	Learning Rate: 0.00606844
	LOSS [training: 0.5528696228217692 | validation: 0.610237760865049]
	TIME [epoch: 2.82 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5454700749726905		[learning rate: 0.006047]
	Learning Rate: 0.00604698
	LOSS [training: 0.5454700749726905 | validation: 0.5938715030146003]
	TIME [epoch: 2.83 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.534634278490596		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.534634278490596 | validation: 0.6011280269126156]
	TIME [epoch: 2.83 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5330887523524627		[learning rate: 0.0060043]
	Learning Rate: 0.00600429
	LOSS [training: 0.5330887523524627 | validation: 0.5751263496189679]
	TIME [epoch: 2.83 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5429113079642847		[learning rate: 0.0059831]
	Learning Rate: 0.00598306
	LOSS [training: 0.5429113079642847 | validation: 0.6365875928017323]
	TIME [epoch: 2.82 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5755429101584525		[learning rate: 0.0059619]
	Learning Rate: 0.0059619
	LOSS [training: 0.5755429101584525 | validation: 0.5988142245006187]
	TIME [epoch: 2.82 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6202814676987128		[learning rate: 0.0059408]
	Learning Rate: 0.00594082
	LOSS [training: 0.6202814676987128 | validation: 0.6093236132061528]
	TIME [epoch: 2.82 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.557785275831668		[learning rate: 0.0059198]
	Learning Rate: 0.00591981
	LOSS [training: 0.557785275831668 | validation: 0.6391857323746735]
	TIME [epoch: 2.82 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5797042308640242		[learning rate: 0.0058989]
	Learning Rate: 0.00589888
	LOSS [training: 0.5797042308640242 | validation: 0.7119501798647692]
	TIME [epoch: 2.83 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.7895576183688415		[learning rate: 0.005878]
	Learning Rate: 0.00587802
	LOSS [training: 0.7895576183688415 | validation: 0.688037467624682]
	TIME [epoch: 276 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6736097645153118		[learning rate: 0.0058572]
	Learning Rate: 0.00585723
	LOSS [training: 0.6736097645153118 | validation: 0.5680455130486678]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.589505933707085		[learning rate: 0.0058365]
	Learning Rate: 0.00583652
	LOSS [training: 0.589505933707085 | validation: 0.6323944116976037]
	TIME [epoch: 6.05 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6013514981196666		[learning rate: 0.0058159]
	Learning Rate: 0.00581588
	LOSS [training: 0.6013514981196666 | validation: 0.6125956430926114]
	TIME [epoch: 6.05 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5531704180804886		[learning rate: 0.0057953]
	Learning Rate: 0.00579531
	LOSS [training: 0.5531704180804886 | validation: 0.6213121473224823]
	TIME [epoch: 6.05 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.54427761844505		[learning rate: 0.0057748]
	Learning Rate: 0.00577482
	LOSS [training: 0.54427761844505 | validation: 0.6054527517257768]
	TIME [epoch: 6.05 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5379302567087823		[learning rate: 0.0057544]
	Learning Rate: 0.0057544
	LOSS [training: 0.5379302567087823 | validation: 0.6112406552981512]
	TIME [epoch: 6.04 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5406334641417613		[learning rate: 0.0057341]
	Learning Rate: 0.00573405
	LOSS [training: 0.5406334641417613 | validation: 0.5814304458119722]
	TIME [epoch: 6.05 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5510799375188055		[learning rate: 0.0057138]
	Learning Rate: 0.00571377
	LOSS [training: 0.5510799375188055 | validation: 0.6079482083297116]
	TIME [epoch: 6.04 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5617558424982438		[learning rate: 0.0056936]
	Learning Rate: 0.00569357
	LOSS [training: 0.5617558424982438 | validation: 0.5775970170417315]
	TIME [epoch: 6.05 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5809929488082678		[learning rate: 0.0056734]
	Learning Rate: 0.00567344
	LOSS [training: 0.5809929488082678 | validation: 0.6342774916966492]
	TIME [epoch: 6.05 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6136784040832121		[learning rate: 0.0056534]
	Learning Rate: 0.00565337
	LOSS [training: 0.6136784040832121 | validation: 0.6171842893728907]
	TIME [epoch: 6.05 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.558364786114337		[learning rate: 0.0056334]
	Learning Rate: 0.00563338
	LOSS [training: 0.558364786114337 | validation: 0.571080179592242]
	TIME [epoch: 6.05 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5306090671444733		[learning rate: 0.0056135]
	Learning Rate: 0.00561346
	LOSS [training: 0.5306090671444733 | validation: 0.6037474993886179]
	TIME [epoch: 6.06 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5264317746343902		[learning rate: 0.0055936]
	Learning Rate: 0.00559361
	LOSS [training: 0.5264317746343902 | validation: 0.5667885287663051]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_215.pth
	Model improved!!!
EPOCH 216/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206605373839327		[learning rate: 0.0055738]
	Learning Rate: 0.00557383
	LOSS [training: 0.5206605373839327 | validation: 0.5732380244171688]
	TIME [epoch: 6.05 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5085268123629814		[learning rate: 0.0055541]
	Learning Rate: 0.00555412
	LOSS [training: 0.5085268123629814 | validation: 0.5646851516321235]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.50246601354703		[learning rate: 0.0055345]
	Learning Rate: 0.00553448
	LOSS [training: 0.50246601354703 | validation: 0.5623141322242311]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_218.pth
	Model improved!!!
EPOCH 219/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5037743140582938		[learning rate: 0.0055149]
	Learning Rate: 0.00551491
	LOSS [training: 0.5037743140582938 | validation: 0.5673495002218294]
	TIME [epoch: 6.05 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5408088802952116		[learning rate: 0.0054954]
	Learning Rate: 0.00549541
	LOSS [training: 0.5408088802952116 | validation: 0.632098419694171]
	TIME [epoch: 6.04 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6745338016822009		[learning rate: 0.005476]
	Learning Rate: 0.00547598
	LOSS [training: 0.6745338016822009 | validation: 0.5937098545624621]
	TIME [epoch: 6.04 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6163383291613588		[learning rate: 0.0054566]
	Learning Rate: 0.00545661
	LOSS [training: 0.6163383291613588 | validation: 0.5830577504828123]
	TIME [epoch: 6.06 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5362594289042325		[learning rate: 0.0054373]
	Learning Rate: 0.00543732
	LOSS [training: 0.5362594289042325 | validation: 0.5693962343058191]
	TIME [epoch: 6.04 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5076272092616547		[learning rate: 0.0054181]
	Learning Rate: 0.00541809
	LOSS [training: 0.5076272092616547 | validation: 0.5737993146645461]
	TIME [epoch: 6.04 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.537576929831176		[learning rate: 0.0053989]
	Learning Rate: 0.00539893
	LOSS [training: 0.537576929831176 | validation: 0.6156204202769122]
	TIME [epoch: 6.05 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5590725757293218		[learning rate: 0.0053798]
	Learning Rate: 0.00537984
	LOSS [training: 0.5590725757293218 | validation: 0.5483053318466182]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5959968637602473		[learning rate: 0.0053608]
	Learning Rate: 0.00536081
	LOSS [training: 0.5959968637602473 | validation: 0.5684633750186642]
	TIME [epoch: 6.05 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5057663476700762		[learning rate: 0.0053419]
	Learning Rate: 0.00534186
	LOSS [training: 0.5057663476700762 | validation: 0.574567570976335]
	TIME [epoch: 6.05 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5006821677877684		[learning rate: 0.005323]
	Learning Rate: 0.00532297
	LOSS [training: 0.5006821677877684 | validation: 0.5440127933349143]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_229.pth
	Model improved!!!
EPOCH 230/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5116038731972166		[learning rate: 0.0053041]
	Learning Rate: 0.00530415
	LOSS [training: 0.5116038731972166 | validation: 0.5875728779417946]
	TIME [epoch: 6.06 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5221301171701836		[learning rate: 0.0052854]
	Learning Rate: 0.00528539
	LOSS [training: 0.5221301171701836 | validation: 0.548471784273333]
	TIME [epoch: 6.07 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5301868340262554		[learning rate: 0.0052667]
	Learning Rate: 0.0052667
	LOSS [training: 0.5301868340262554 | validation: 0.5674400716778129]
	TIME [epoch: 6.07 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5053788716260382		[learning rate: 0.0052481]
	Learning Rate: 0.00524807
	LOSS [training: 0.5053788716260382 | validation: 0.5403297537328294]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5295944800088044		[learning rate: 0.0052295]
	Learning Rate: 0.00522952
	LOSS [training: 0.5295944800088044 | validation: 0.5807503913238156]
	TIME [epoch: 6.06 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5440632630525203		[learning rate: 0.005211]
	Learning Rate: 0.00521102
	LOSS [training: 0.5440632630525203 | validation: 0.5564583771787138]
	TIME [epoch: 6.06 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5285526045305844		[learning rate: 0.0051926]
	Learning Rate: 0.0051926
	LOSS [training: 0.5285526045305844 | validation: 0.5500633606393958]
	TIME [epoch: 6.06 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48153008353172627		[learning rate: 0.0051742]
	Learning Rate: 0.00517423
	LOSS [training: 0.48153008353172627 | validation: 0.5419905771074545]
	TIME [epoch: 6.05 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.484643581031559		[learning rate: 0.0051559]
	Learning Rate: 0.00515594
	LOSS [training: 0.484643581031559 | validation: 0.5470594579071102]
	TIME [epoch: 6.05 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.508233058332963		[learning rate: 0.0051377]
	Learning Rate: 0.00513771
	LOSS [training: 0.508233058332963 | validation: 0.5384103692359303]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5270936861238036		[learning rate: 0.0051195]
	Learning Rate: 0.00511954
	LOSS [training: 0.5270936861238036 | validation: 0.600913830178512]
	TIME [epoch: 6.04 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5898159011191071		[learning rate: 0.0051014]
	Learning Rate: 0.00510143
	LOSS [training: 0.5898159011191071 | validation: 0.5549574932569937]
	TIME [epoch: 6.04 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5560339705578432		[learning rate: 0.0050834]
	Learning Rate: 0.0050834
	LOSS [training: 0.5560339705578432 | validation: 0.5941592713908527]
	TIME [epoch: 6.03 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5351580543234487		[learning rate: 0.0050654]
	Learning Rate: 0.00506542
	LOSS [training: 0.5351580543234487 | validation: 0.5374601784093483]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5215130223767616		[learning rate: 0.0050475]
	Learning Rate: 0.00504751
	LOSS [training: 0.5215130223767616 | validation: 0.5431562726347157]
	TIME [epoch: 6.06 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4825887373107014		[learning rate: 0.0050297]
	Learning Rate: 0.00502966
	LOSS [training: 0.4825887373107014 | validation: 0.5424822887139452]
	TIME [epoch: 6.04 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5011479765363641		[learning rate: 0.0050119]
	Learning Rate: 0.00501187
	LOSS [training: 0.5011479765363641 | validation: 0.5531929136113537]
	TIME [epoch: 6.06 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.49568575583309665		[learning rate: 0.0049941]
	Learning Rate: 0.00499415
	LOSS [training: 0.49568575583309665 | validation: 0.5180254989024119]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.530408050395695		[learning rate: 0.0049765]
	Learning Rate: 0.00497649
	LOSS [training: 0.530408050395695 | validation: 0.5643387360314028]
	TIME [epoch: 6.08 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5035520834585482		[learning rate: 0.0049589]
	Learning Rate: 0.00495889
	LOSS [training: 0.5035520834585482 | validation: 0.5642285572762527]
	TIME [epoch: 6.08 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5560771289007759		[learning rate: 0.0049414]
	Learning Rate: 0.00494136
	LOSS [training: 0.5560771289007759 | validation: 0.6272018331690481]
	TIME [epoch: 6.08 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6123145620007503		[learning rate: 0.0049239]
	Learning Rate: 0.00492388
	LOSS [training: 0.6123145620007503 | validation: 0.5375057852656984]
	TIME [epoch: 6.08 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4960966165957019		[learning rate: 0.0049065]
	Learning Rate: 0.00490647
	LOSS [training: 0.4960966165957019 | validation: 0.5357136695922392]
	TIME [epoch: 6.08 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48244388924112797		[learning rate: 0.0048891]
	Learning Rate: 0.00488912
	LOSS [training: 0.48244388924112797 | validation: 0.5505040810172585]
	TIME [epoch: 6.1 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5005663812347416		[learning rate: 0.0048718]
	Learning Rate: 0.00487183
	LOSS [training: 0.5005663812347416 | validation: 0.5297702348571255]
	TIME [epoch: 6.1 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4856270671438149		[learning rate: 0.0048546]
	Learning Rate: 0.0048546
	LOSS [training: 0.4856270671438149 | validation: 0.5121271928130675]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_255.pth
	Model improved!!!
EPOCH 256/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4728641255169943		[learning rate: 0.0048374]
	Learning Rate: 0.00483744
	LOSS [training: 0.4728641255169943 | validation: 0.560414640273113]
	TIME [epoch: 6.1 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4939228228611522		[learning rate: 0.0048203]
	Learning Rate: 0.00482033
	LOSS [training: 0.4939228228611522 | validation: 0.5297850030098677]
	TIME [epoch: 6.1 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5171083821988308		[learning rate: 0.0048033]
	Learning Rate: 0.00480329
	LOSS [training: 0.5171083821988308 | validation: 0.5739843261930613]
	TIME [epoch: 6.11 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5107856669329223		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.5107856669329223 | validation: 0.5004529268496499]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_259.pth
	Model improved!!!
EPOCH 260/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4846312333763143		[learning rate: 0.0047694]
	Learning Rate: 0.00476938
	LOSS [training: 0.4846312333763143 | validation: 0.5451914059092137]
	TIME [epoch: 6.06 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5024440911289522		[learning rate: 0.0047525]
	Learning Rate: 0.00475251
	LOSS [training: 0.5024440911289522 | validation: 0.5401480067368342]
	TIME [epoch: 6.09 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5218806127333756		[learning rate: 0.0047357]
	Learning Rate: 0.0047357
	LOSS [training: 0.5218806127333756 | validation: 0.5535659047760136]
	TIME [epoch: 6.08 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5206249426910509		[learning rate: 0.004719]
	Learning Rate: 0.00471896
	LOSS [training: 0.5206249426910509 | validation: 0.5072983346837908]
	TIME [epoch: 6.08 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48092844908351495		[learning rate: 0.0047023]
	Learning Rate: 0.00470227
	LOSS [training: 0.48092844908351495 | validation: 0.520742460570086]
	TIME [epoch: 6.06 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46655409661723646		[learning rate: 0.0046856]
	Learning Rate: 0.00468564
	LOSS [training: 0.46655409661723646 | validation: 0.5092475762476747]
	TIME [epoch: 6.08 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4713619565964322		[learning rate: 0.0046691]
	Learning Rate: 0.00466907
	LOSS [training: 0.4713619565964322 | validation: 0.5249454762960094]
	TIME [epoch: 6.07 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4739272811973399		[learning rate: 0.0046526]
	Learning Rate: 0.00465256
	LOSS [training: 0.4739272811973399 | validation: 0.4993584354050654]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4680041607758663		[learning rate: 0.0046361]
	Learning Rate: 0.00463611
	LOSS [training: 0.4680041607758663 | validation: 0.5137730545964787]
	TIME [epoch: 6.05 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.466499122274182		[learning rate: 0.0046197]
	Learning Rate: 0.00461972
	LOSS [training: 0.466499122274182 | validation: 0.5249605325555795]
	TIME [epoch: 6.05 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4794856662099977		[learning rate: 0.0046034]
	Learning Rate: 0.00460338
	LOSS [training: 0.4794856662099977 | validation: 0.5150341602556621]
	TIME [epoch: 6.05 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5032770084968655		[learning rate: 0.0045871]
	Learning Rate: 0.0045871
	LOSS [training: 0.5032770084968655 | validation: 0.5486166425944822]
	TIME [epoch: 6.04 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5120782942258731		[learning rate: 0.0045709]
	Learning Rate: 0.00457088
	LOSS [training: 0.5120782942258731 | validation: 0.5023179211930104]
	TIME [epoch: 6.04 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48117158970842916		[learning rate: 0.0045547]
	Learning Rate: 0.00455472
	LOSS [training: 0.48117158970842916 | validation: 0.5098638470520267]
	TIME [epoch: 6.05 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45848386352445764		[learning rate: 0.0045386]
	Learning Rate: 0.00453861
	LOSS [training: 0.45848386352445764 | validation: 0.4901573811942168]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45527081151467463		[learning rate: 0.0045226]
	Learning Rate: 0.00452256
	LOSS [training: 0.45527081151467463 | validation: 0.5198310964587272]
	TIME [epoch: 6.09 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4807453994180766		[learning rate: 0.0045066]
	Learning Rate: 0.00450657
	LOSS [training: 0.4807453994180766 | validation: 0.5253281590516329]
	TIME [epoch: 6.09 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5197551148833032		[learning rate: 0.0044906]
	Learning Rate: 0.00449063
	LOSS [training: 0.5197551148833032 | validation: 0.5330595823066]
	TIME [epoch: 6.09 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4812453591923074		[learning rate: 0.0044748]
	Learning Rate: 0.00447475
	LOSS [training: 0.4812453591923074 | validation: 0.49303651807725796]
	TIME [epoch: 6.07 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45062422775820765		[learning rate: 0.0044589]
	Learning Rate: 0.00445893
	LOSS [training: 0.45062422775820765 | validation: 0.48632028747757783]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4414924841144696		[learning rate: 0.0044432]
	Learning Rate: 0.00444316
	LOSS [training: 0.4414924841144696 | validation: 0.4930999838084783]
	TIME [epoch: 6.07 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45154688896480155		[learning rate: 0.0044275]
	Learning Rate: 0.00442745
	LOSS [training: 0.45154688896480155 | validation: 0.490408822714522]
	TIME [epoch: 6.08 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4546198240962558		[learning rate: 0.0044118]
	Learning Rate: 0.0044118
	LOSS [training: 0.4546198240962558 | validation: 0.5135981036770317]
	TIME [epoch: 6.08 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4948212944645507		[learning rate: 0.0043962]
	Learning Rate: 0.00439619
	LOSS [training: 0.4948212944645507 | validation: 0.4985293388159258]
	TIME [epoch: 6.09 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.48261187992383114		[learning rate: 0.0043806]
	Learning Rate: 0.00438065
	LOSS [training: 0.48261187992383114 | validation: 0.5278399498448657]
	TIME [epoch: 6.08 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4794999520119073		[learning rate: 0.0043652]
	Learning Rate: 0.00436516
	LOSS [training: 0.4794999520119073 | validation: 0.48856696044096437]
	TIME [epoch: 6.08 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.479782041627733		[learning rate: 0.0043497]
	Learning Rate: 0.00434972
	LOSS [training: 0.479782041627733 | validation: 0.5275652037320079]
	TIME [epoch: 6.08 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46447362611500387		[learning rate: 0.0043343]
	Learning Rate: 0.00433434
	LOSS [training: 0.46447362611500387 | validation: 0.48119275372451065]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_287.pth
	Model improved!!!
EPOCH 288/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44737735058950634		[learning rate: 0.004319]
	Learning Rate: 0.00431901
	LOSS [training: 0.44737735058950634 | validation: 0.49657006168275863]
	TIME [epoch: 6.06 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4506859088090471		[learning rate: 0.0043037]
	Learning Rate: 0.00430374
	LOSS [training: 0.4506859088090471 | validation: 0.4993335117111031]
	TIME [epoch: 6.09 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44858699292965964		[learning rate: 0.0042885]
	Learning Rate: 0.00428852
	LOSS [training: 0.44858699292965964 | validation: 0.4770592960593827]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46225240794159833		[learning rate: 0.0042734]
	Learning Rate: 0.00427336
	LOSS [training: 0.46225240794159833 | validation: 0.5009408197566801]
	TIME [epoch: 6.06 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.43650507757520074		[learning rate: 0.0042582]
	Learning Rate: 0.00425825
	LOSS [training: 0.43650507757520074 | validation: 0.47205929427658566]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4345307207091649		[learning rate: 0.0042432]
	Learning Rate: 0.00424319
	LOSS [training: 0.4345307207091649 | validation: 0.49781743216949564]
	TIME [epoch: 6.06 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45179173223116253		[learning rate: 0.0042282]
	Learning Rate: 0.00422818
	LOSS [training: 0.45179173223116253 | validation: 0.48881215701977326]
	TIME [epoch: 6.06 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4937511783640305		[learning rate: 0.0042132]
	Learning Rate: 0.00421323
	LOSS [training: 0.4937511783640305 | validation: 0.5160871799376553]
	TIME [epoch: 6.07 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4525696101334207		[learning rate: 0.0041983]
	Learning Rate: 0.00419833
	LOSS [training: 0.4525696101334207 | validation: 0.45104047347579485]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4300467107200778		[learning rate: 0.0041835]
	Learning Rate: 0.00418349
	LOSS [training: 0.4300467107200778 | validation: 0.47284058369412335]
	TIME [epoch: 6.06 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4317087795793145		[learning rate: 0.0041687]
	Learning Rate: 0.00416869
	LOSS [training: 0.4317087795793145 | validation: 0.5436367973884038]
	TIME [epoch: 6.05 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4687111294966288		[learning rate: 0.004154]
	Learning Rate: 0.00415395
	LOSS [training: 0.4687111294966288 | validation: 0.5187365772412708]
	TIME [epoch: 6.05 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.5340947004922232		[learning rate: 0.0041393]
	Learning Rate: 0.00413926
	LOSS [training: 0.5340947004922232 | validation: 0.4774251237900437]
	TIME [epoch: 6.05 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4515149007462425		[learning rate: 0.0041246]
	Learning Rate: 0.00412463
	LOSS [training: 0.4515149007462425 | validation: 0.4595382446363894]
	TIME [epoch: 6.08 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42286275291450864		[learning rate: 0.00411]
	Learning Rate: 0.00411004
	LOSS [training: 0.42286275291450864 | validation: 0.4598865898894058]
	TIME [epoch: 6.07 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.419899090394849		[learning rate: 0.0040955]
	Learning Rate: 0.00409551
	LOSS [training: 0.419899090394849 | validation: 0.48920425788106725]
	TIME [epoch: 6.07 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4238795011880906		[learning rate: 0.004081]
	Learning Rate: 0.00408102
	LOSS [training: 0.4238795011880906 | validation: 0.46244445842916004]
	TIME [epoch: 6.08 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4293745558314591		[learning rate: 0.0040666]
	Learning Rate: 0.00406659
	LOSS [training: 0.4293745558314591 | validation: 0.4647402238762693]
	TIME [epoch: 6.07 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42211188780992254		[learning rate: 0.0040522]
	Learning Rate: 0.00405221
	LOSS [training: 0.42211188780992254 | validation: 0.4760888395647591]
	TIME [epoch: 6.05 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4465041186179745		[learning rate: 0.0040379]
	Learning Rate: 0.00403788
	LOSS [training: 0.4465041186179745 | validation: 0.4610027505374037]
	TIME [epoch: 6.07 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42764814514409455		[learning rate: 0.0040236]
	Learning Rate: 0.00402361
	LOSS [training: 0.42764814514409455 | validation: 0.46047862096522146]
	TIME [epoch: 6.04 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4061490523298366		[learning rate: 0.0040094]
	Learning Rate: 0.00400938
	LOSS [training: 0.4061490523298366 | validation: 0.4622182002814079]
	TIME [epoch: 6.07 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42090129471813037		[learning rate: 0.0039952]
	Learning Rate: 0.0039952
	LOSS [training: 0.42090129471813037 | validation: 0.4372156735876129]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46363262792294707		[learning rate: 0.0039811]
	Learning Rate: 0.00398107
	LOSS [training: 0.46363262792294707 | validation: 0.6297073720289144]
	TIME [epoch: 6.07 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6611653781031634		[learning rate: 0.003967]
	Learning Rate: 0.00396699
	LOSS [training: 0.6611653781031634 | validation: 0.45896822089841616]
	TIME [epoch: 6.08 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44020303235453684		[learning rate: 0.003953]
	Learning Rate: 0.00395297
	LOSS [training: 0.44020303235453684 | validation: 0.48146322776327444]
	TIME [epoch: 6.06 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.458565961073852		[learning rate: 0.003939]
	Learning Rate: 0.00393899
	LOSS [training: 0.458565961073852 | validation: 0.4645099626269028]
	TIME [epoch: 6.07 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4120254155446646		[learning rate: 0.0039251]
	Learning Rate: 0.00392506
	LOSS [training: 0.4120254155446646 | validation: 0.4520957876634416]
	TIME [epoch: 6.07 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4100256729191431		[learning rate: 0.0039112]
	Learning Rate: 0.00391118
	LOSS [training: 0.4100256729191431 | validation: 0.46811956557557616]
	TIME [epoch: 6.07 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4069927078039308		[learning rate: 0.0038973]
	Learning Rate: 0.00389735
	LOSS [training: 0.4069927078039308 | validation: 0.4580488379359811]
	TIME [epoch: 6.05 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4103256868435063		[learning rate: 0.0038836]
	Learning Rate: 0.00388357
	LOSS [training: 0.4103256868435063 | validation: 0.44420446586612083]
	TIME [epoch: 6.08 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4016626356278104		[learning rate: 0.0038698]
	Learning Rate: 0.00386983
	LOSS [training: 0.4016626356278104 | validation: 0.4566713042024933]
	TIME [epoch: 6.07 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3993694890014996		[learning rate: 0.0038561]
	Learning Rate: 0.00385615
	LOSS [training: 0.3993694890014996 | validation: 0.4343826290770314]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3952523303830975		[learning rate: 0.0038425]
	Learning Rate: 0.00384251
	LOSS [training: 0.3952523303830975 | validation: 0.44667557610274305]
	TIME [epoch: 6.06 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39610499675841754		[learning rate: 0.0038289]
	Learning Rate: 0.00382893
	LOSS [training: 0.39610499675841754 | validation: 0.44021310539942127]
	TIME [epoch: 6.07 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39336365779515914		[learning rate: 0.0038154]
	Learning Rate: 0.00381539
	LOSS [training: 0.39336365779515914 | validation: 0.4424134270470475]
	TIME [epoch: 6.05 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.392910560701013		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.392910560701013 | validation: 0.42668431298040316]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39373101455477183		[learning rate: 0.0037885]
	Learning Rate: 0.00378845
	LOSS [training: 0.39373101455477183 | validation: 0.46954661030035255]
	TIME [epoch: 6.08 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.41793373453146715		[learning rate: 0.0037751]
	Learning Rate: 0.00377505
	LOSS [training: 0.41793373453146715 | validation: 0.44233516671311934]
	TIME [epoch: 6.08 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4550176109697141		[learning rate: 0.0037617]
	Learning Rate: 0.0037617
	LOSS [training: 0.4550176109697141 | validation: 0.5240176285016082]
	TIME [epoch: 6.08 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4546705472649154		[learning rate: 0.0037484]
	Learning Rate: 0.0037484
	LOSS [training: 0.4546705472649154 | validation: 0.42491740796151634]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3961356990960255		[learning rate: 0.0037351]
	Learning Rate: 0.00373515
	LOSS [training: 0.3961356990960255 | validation: 0.4306180284008164]
	TIME [epoch: 6.09 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3973751162000832		[learning rate: 0.0037219]
	Learning Rate: 0.00372194
	LOSS [training: 0.3973751162000832 | validation: 0.5007933077216619]
	TIME [epoch: 6.08 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4196417849282736		[learning rate: 0.0037088]
	Learning Rate: 0.00370878
	LOSS [training: 0.4196417849282736 | validation: 0.403079013801525]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_331.pth
	Model improved!!!
EPOCH 332/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4125352442938614		[learning rate: 0.0036957]
	Learning Rate: 0.00369566
	LOSS [training: 0.4125352442938614 | validation: 0.43486342667420586]
	TIME [epoch: 6.08 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38863998918668585		[learning rate: 0.0036826]
	Learning Rate: 0.00368259
	LOSS [training: 0.38863998918668585 | validation: 0.4191046869771577]
	TIME [epoch: 6.07 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.39220678359663136		[learning rate: 0.0036696]
	Learning Rate: 0.00366957
	LOSS [training: 0.39220678359663136 | validation: 0.43213017096199335]
	TIME [epoch: 6.09 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4070133898989394		[learning rate: 0.0036566]
	Learning Rate: 0.0036566
	LOSS [training: 0.4070133898989394 | validation: 0.4716391720376856]
	TIME [epoch: 6.07 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.44050166572675975		[learning rate: 0.0036437]
	Learning Rate: 0.00364367
	LOSS [training: 0.44050166572675975 | validation: 0.4411315214638405]
	TIME [epoch: 6.08 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4072500569542837		[learning rate: 0.0036308]
	Learning Rate: 0.00363078
	LOSS [training: 0.4072500569542837 | validation: 0.4187504101739092]
	TIME [epoch: 6.08 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3816586088168996		[learning rate: 0.0036179]
	Learning Rate: 0.00361794
	LOSS [training: 0.3816586088168996 | validation: 0.45874479387827966]
	TIME [epoch: 6.08 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.38204470723792017		[learning rate: 0.0036051]
	Learning Rate: 0.00360515
	LOSS [training: 0.38204470723792017 | validation: 0.4349322358202102]
	TIME [epoch: 6.09 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40454027174059237		[learning rate: 0.0035924]
	Learning Rate: 0.0035924
	LOSS [training: 0.40454027174059237 | validation: 0.4228115969831513]
	TIME [epoch: 6.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4320462738968392		[learning rate: 0.0035797]
	Learning Rate: 0.0035797
	LOSS [training: 0.4320462738968392 | validation: 0.6090521841188927]
	TIME [epoch: 6.09 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.6752145986154184		[learning rate: 0.003567]
	Learning Rate: 0.00356704
	LOSS [training: 0.6752145986154184 | validation: 0.48178679641228506]
	TIME [epoch: 6.09 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45143227481996634		[learning rate: 0.0035544]
	Learning Rate: 0.00355442
	LOSS [training: 0.45143227481996634 | validation: 0.4610443651828357]
	TIME [epoch: 6.09 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.42979153140987325		[learning rate: 0.0035419]
	Learning Rate: 0.00354185
	LOSS [training: 0.42979153140987325 | validation: 0.48318877722687364]
	TIME [epoch: 6.09 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3967429505808096		[learning rate: 0.0035293]
	Learning Rate: 0.00352933
	LOSS [training: 0.3967429505808096 | validation: 0.421303073383546]
	TIME [epoch: 6.09 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3732043308026014		[learning rate: 0.0035169]
	Learning Rate: 0.00351685
	LOSS [training: 0.3732043308026014 | validation: 0.4116273579248384]
	TIME [epoch: 6.09 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3679666735632438		[learning rate: 0.0035044]
	Learning Rate: 0.00350441
	LOSS [training: 0.3679666735632438 | validation: 0.4399710854971961]
	TIME [epoch: 6.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36836992265563806		[learning rate: 0.003492]
	Learning Rate: 0.00349202
	LOSS [training: 0.36836992265563806 | validation: 0.4108351607337635]
	TIME [epoch: 6.09 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36064048705024476		[learning rate: 0.0034797]
	Learning Rate: 0.00347967
	LOSS [training: 0.36064048705024476 | validation: 0.41304786335450516]
	TIME [epoch: 6.09 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3549216000607865		[learning rate: 0.0034674]
	Learning Rate: 0.00346737
	LOSS [training: 0.3549216000607865 | validation: 0.4011606408333089]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_350.pth
	Model improved!!!
EPOCH 351/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3622510080631861		[learning rate: 0.0034551]
	Learning Rate: 0.00345511
	LOSS [training: 0.3622510080631861 | validation: 0.4167400070469629]
	TIME [epoch: 6.11 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35641830903521227		[learning rate: 0.0034429]
	Learning Rate: 0.00344289
	LOSS [training: 0.35641830903521227 | validation: 0.40010748091787396]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35625587220396493		[learning rate: 0.0034307]
	Learning Rate: 0.00343071
	LOSS [training: 0.35625587220396493 | validation: 0.4111055958630287]
	TIME [epoch: 6.08 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3623078704141806		[learning rate: 0.0034186]
	Learning Rate: 0.00341858
	LOSS [training: 0.3623078704141806 | validation: 0.3871818923660298]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3645196245491546		[learning rate: 0.0034065]
	Learning Rate: 0.00340649
	LOSS [training: 0.3645196245491546 | validation: 0.41578608942272854]
	TIME [epoch: 6.09 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3771544132269707		[learning rate: 0.0033944]
	Learning Rate: 0.00339445
	LOSS [training: 0.3771544132269707 | validation: 0.40473534634391695]
	TIME [epoch: 6.09 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35870970620256876		[learning rate: 0.0033824]
	Learning Rate: 0.00338245
	LOSS [training: 0.35870970620256876 | validation: 0.4118384585969591]
	TIME [epoch: 6.09 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3553387973949825		[learning rate: 0.0033705]
	Learning Rate: 0.00337048
	LOSS [training: 0.3553387973949825 | validation: 0.4094918420767615]
	TIME [epoch: 6.09 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36115284402647324		[learning rate: 0.0033586]
	Learning Rate: 0.00335857
	LOSS [training: 0.36115284402647324 | validation: 0.4058081828083154]
	TIME [epoch: 6.08 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3562814752182046		[learning rate: 0.0033467]
	Learning Rate: 0.00334669
	LOSS [training: 0.3562814752182046 | validation: 0.3936157756049371]
	TIME [epoch: 6.09 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.34498742122686266		[learning rate: 0.0033349]
	Learning Rate: 0.00333485
	LOSS [training: 0.34498742122686266 | validation: 0.4166362595310812]
	TIME [epoch: 6.09 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.347206955930475		[learning rate: 0.0033231]
	Learning Rate: 0.00332306
	LOSS [training: 0.347206955930475 | validation: 0.3737045212212536]
	TIME [epoch: 6.09 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_362.pth
	Model improved!!!
EPOCH 363/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4273371117266441		[learning rate: 0.0033113]
	Learning Rate: 0.00331131
	LOSS [training: 0.4273371117266441 | validation: 0.4704713362977033]
	TIME [epoch: 6.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3967829104803748		[learning rate: 0.0032996]
	Learning Rate: 0.0032996
	LOSS [training: 0.3967829104803748 | validation: 0.36026437552442026]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35390143703723476		[learning rate: 0.0032879]
	Learning Rate: 0.00328793
	LOSS [training: 0.35390143703723476 | validation: 0.40974706470477484]
	TIME [epoch: 6.09 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.36024969810921337		[learning rate: 0.0032763]
	Learning Rate: 0.00327631
	LOSS [training: 0.36024969810921337 | validation: 0.4309517264126722]
	TIME [epoch: 6.09 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3657234325917388		[learning rate: 0.0032647]
	Learning Rate: 0.00326472
	LOSS [training: 0.3657234325917388 | validation: 0.36971114395622673]
	TIME [epoch: 6.09 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33814371189794756		[learning rate: 0.0032532]
	Learning Rate: 0.00325318
	LOSS [training: 0.33814371189794756 | validation: 0.376366996848076]
	TIME [epoch: 6.08 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.32992601099122437		[learning rate: 0.0032417]
	Learning Rate: 0.00324167
	LOSS [training: 0.32992601099122437 | validation: 0.4027479260044876]
	TIME [epoch: 6.08 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3367000873714297		[learning rate: 0.0032302]
	Learning Rate: 0.00323021
	LOSS [training: 0.3367000873714297 | validation: 0.44561508100061986]
	TIME [epoch: 6.09 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.40059615480306277		[learning rate: 0.0032188]
	Learning Rate: 0.00321879
	LOSS [training: 0.40059615480306277 | validation: 0.3429187413254706]
	TIME [epoch: 6.1 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_371.pth
	Model improved!!!
EPOCH 372/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46949501509456193		[learning rate: 0.0032074]
	Learning Rate: 0.00320741
	LOSS [training: 0.46949501509456193 | validation: 0.3714812165544902]
	TIME [epoch: 6.09 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3386181284451106		[learning rate: 0.0031961]
	Learning Rate: 0.00319606
	LOSS [training: 0.3386181284451106 | validation: 0.46805290688361556]
	TIME [epoch: 6.09 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.4470079441963921		[learning rate: 0.0031848]
	Learning Rate: 0.00318476
	LOSS [training: 0.4470079441963921 | validation: 0.36848708620207166]
	TIME [epoch: 6.08 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3401526363265207		[learning rate: 0.0031735]
	Learning Rate: 0.0031735
	LOSS [training: 0.3401526363265207 | validation: 0.435136469396873]
	TIME [epoch: 6.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35160696770398864		[learning rate: 0.0031623]
	Learning Rate: 0.00316228
	LOSS [training: 0.35160696770398864 | validation: 0.3525624554396567]
	TIME [epoch: 6.08 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.33102280702317827		[learning rate: 0.0031511]
	Learning Rate: 0.0031511
	LOSS [training: 0.33102280702317827 | validation: 0.3630944736024159]
	TIME [epoch: 6.08 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.314341976303544		[learning rate: 0.00314]
	Learning Rate: 0.00313995
	LOSS [training: 0.314341976303544 | validation: 0.3608952034937009]
	TIME [epoch: 6.07 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3123563404448409		[learning rate: 0.0031288]
	Learning Rate: 0.00312885
	LOSS [training: 0.3123563404448409 | validation: 0.3985841609166808]
	TIME [epoch: 6.08 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3194940138888425		[learning rate: 0.0031178]
	Learning Rate: 0.00311779
	LOSS [training: 0.3194940138888425 | validation: 0.3815446884785619]
	TIME [epoch: 6.08 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31616191628276397		[learning rate: 0.0031068]
	Learning Rate: 0.00310676
	LOSS [training: 0.31616191628276397 | validation: 0.33439474528322644]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31940111864665405		[learning rate: 0.0030958]
	Learning Rate: 0.00309577
	LOSS [training: 0.31940111864665405 | validation: 0.4305253938897915]
	TIME [epoch: 6.05 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3290540085552985		[learning rate: 0.0030848]
	Learning Rate: 0.00308483
	LOSS [training: 0.3290540085552985 | validation: 0.3437956511755449]
	TIME [epoch: 6.05 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3611168983756508		[learning rate: 0.0030739]
	Learning Rate: 0.00307392
	LOSS [training: 0.3611168983756508 | validation: 0.4658144922805109]
	TIME [epoch: 6.05 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37708847155561115		[learning rate: 0.003063]
	Learning Rate: 0.00306305
	LOSS [training: 0.37708847155561115 | validation: 0.3261777281477296]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_385.pth
	Model improved!!!
EPOCH 386/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3186693224660408		[learning rate: 0.0030522]
	Learning Rate: 0.00305222
	LOSS [training: 0.3186693224660408 | validation: 0.32292878504951644]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3160020379926748		[learning rate: 0.0030414]
	Learning Rate: 0.00304142
	LOSS [training: 0.3160020379926748 | validation: 0.4252711652770795]
	TIME [epoch: 6.08 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31733684794074035		[learning rate: 0.0030307]
	Learning Rate: 0.00303067
	LOSS [training: 0.31733684794074035 | validation: 0.3121378991457474]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_388.pth
	Model improved!!!
EPOCH 389/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.31697239041684344		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.31697239041684344 | validation: 0.34185146027101043]
	TIME [epoch: 6.09 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.293175905559456		[learning rate: 0.0030093]
	Learning Rate: 0.00300927
	LOSS [training: 0.293175905559456 | validation: 0.3480492603442886]
	TIME [epoch: 6.08 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28429098579163753		[learning rate: 0.0029986]
	Learning Rate: 0.00299863
	LOSS [training: 0.28429098579163753 | validation: 0.2964573944555317]
	TIME [epoch: 6.08 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_391.pth
	Model improved!!!
EPOCH 392/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3133116794838715		[learning rate: 0.002988]
	Learning Rate: 0.00298803
	LOSS [training: 0.3133116794838715 | validation: 0.369662506626287]
	TIME [epoch: 6.07 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3086445391800164		[learning rate: 0.0029775]
	Learning Rate: 0.00297746
	LOSS [training: 0.3086445391800164 | validation: 0.3012027022755256]
	TIME [epoch: 6.05 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3384889894420673		[learning rate: 0.0029669]
	Learning Rate: 0.00296693
	LOSS [training: 0.3384889894420673 | validation: 0.45207382041557076]
	TIME [epoch: 6.06 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3952699885676559		[learning rate: 0.0029564]
	Learning Rate: 0.00295644
	LOSS [training: 0.3952699885676559 | validation: 0.3079507205521685]
	TIME [epoch: 6.06 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3092885752364491		[learning rate: 0.002946]
	Learning Rate: 0.00294599
	LOSS [training: 0.3092885752364491 | validation: 0.33032151648921726]
	TIME [epoch: 6.07 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2776933265507045		[learning rate: 0.0029356]
	Learning Rate: 0.00293557
	LOSS [training: 0.2776933265507045 | validation: 0.34402337300554897]
	TIME [epoch: 6.07 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2837304980608076		[learning rate: 0.0029252]
	Learning Rate: 0.00292519
	LOSS [training: 0.2837304980608076 | validation: 0.3086061348005995]
	TIME [epoch: 6.07 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.279967844384149		[learning rate: 0.0029148]
	Learning Rate: 0.00291484
	LOSS [training: 0.279967844384149 | validation: 0.31767455270794603]
	TIME [epoch: 6.09 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2664192337699324		[learning rate: 0.0029045]
	Learning Rate: 0.00290454
	LOSS [training: 0.2664192337699324 | validation: 0.3563646754055142]
	TIME [epoch: 6.08 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2718065544842839		[learning rate: 0.0028943]
	Learning Rate: 0.00289427
	LOSS [training: 0.2718065544842839 | validation: 0.3233564271781007]
	TIME [epoch: 6.06 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.29439494452253695		[learning rate: 0.002884]
	Learning Rate: 0.00288403
	LOSS [training: 0.29439494452253695 | validation: 0.4815311242737057]
	TIME [epoch: 6.05 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.35205185565947283		[learning rate: 0.0028738]
	Learning Rate: 0.00287383
	LOSS [training: 0.35205185565947283 | validation: 0.2664338035449733]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_403.pth
	Model improved!!!
EPOCH 404/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2841786209533389		[learning rate: 0.0028637]
	Learning Rate: 0.00286367
	LOSS [training: 0.2841786209533389 | validation: 0.28875551309170194]
	TIME [epoch: 6.06 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2576363030514371		[learning rate: 0.0028535]
	Learning Rate: 0.00285354
	LOSS [training: 0.2576363030514371 | validation: 0.3702236146090901]
	TIME [epoch: 6.06 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2799878260502295		[learning rate: 0.0028435]
	Learning Rate: 0.00284345
	LOSS [training: 0.2799878260502295 | validation: 0.27336238065211615]
	TIME [epoch: 6.06 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2747012411177614		[learning rate: 0.0028334]
	Learning Rate: 0.0028334
	LOSS [training: 0.2747012411177614 | validation: 0.3587791123032434]
	TIME [epoch: 6.06 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26748689329510233		[learning rate: 0.0028234]
	Learning Rate: 0.00282338
	LOSS [training: 0.26748689329510233 | validation: 0.2631890799054003]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2713336471980668		[learning rate: 0.0028134]
	Learning Rate: 0.0028134
	LOSS [training: 0.2713336471980668 | validation: 0.3423591552024222]
	TIME [epoch: 6.07 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2627326475634568		[learning rate: 0.0028034]
	Learning Rate: 0.00280345
	LOSS [training: 0.2627326475634568 | validation: 0.24844703114345335]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2998774623119293		[learning rate: 0.0027935]
	Learning Rate: 0.00279353
	LOSS [training: 0.2998774623119293 | validation: 0.35059936902732053]
	TIME [epoch: 6.05 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2705717422087266		[learning rate: 0.0027837]
	Learning Rate: 0.00278365
	LOSS [training: 0.2705717422087266 | validation: 0.2607863100413938]
	TIME [epoch: 6.06 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.256384877161954		[learning rate: 0.0027738]
	Learning Rate: 0.00277381
	LOSS [training: 0.256384877161954 | validation: 0.3743907240903716]
	TIME [epoch: 6.06 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2739293588788071		[learning rate: 0.002764]
	Learning Rate: 0.002764
	LOSS [training: 0.2739293588788071 | validation: 0.27414687491304984]
	TIME [epoch: 6.06 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.30203863976404816		[learning rate: 0.0027542]
	Learning Rate: 0.00275423
	LOSS [training: 0.30203863976404816 | validation: 0.39156854149421094]
	TIME [epoch: 6.06 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2776706879920048		[learning rate: 0.0027445]
	Learning Rate: 0.00274449
	LOSS [training: 0.2776706879920048 | validation: 0.2499115160870623]
	TIME [epoch: 6.06 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2521733934112701		[learning rate: 0.0027348]
	Learning Rate: 0.00273478
	LOSS [training: 0.2521733934112701 | validation: 0.28766170527994755]
	TIME [epoch: 6.05 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23073635749062185		[learning rate: 0.0027251]
	Learning Rate: 0.00272511
	LOSS [training: 0.23073635749062185 | validation: 0.30583957698441133]
	TIME [epoch: 6.06 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23146680564282762		[learning rate: 0.0027155]
	Learning Rate: 0.00271548
	LOSS [training: 0.23146680564282762 | validation: 0.24860375882225633]
	TIME [epoch: 6.06 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2534483377228305		[learning rate: 0.0027059]
	Learning Rate: 0.00270588
	LOSS [training: 0.2534483377228305 | validation: 0.31907338046845096]
	TIME [epoch: 6.06 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25107833837841753		[learning rate: 0.0026963]
	Learning Rate: 0.00269631
	LOSS [training: 0.25107833837841753 | validation: 0.26170604953067905]
	TIME [epoch: 6.06 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.24838010444436479		[learning rate: 0.0026868]
	Learning Rate: 0.00268677
	LOSS [training: 0.24838010444436479 | validation: 0.2356946563148412]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_422.pth
	Model improved!!!
EPOCH 423/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21961062048014346		[learning rate: 0.0026773]
	Learning Rate: 0.00267727
	LOSS [training: 0.21961062048014346 | validation: 0.3178525398820652]
	TIME [epoch: 6.07 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22231892186957525		[learning rate: 0.0026678]
	Learning Rate: 0.0026678
	LOSS [training: 0.22231892186957525 | validation: 0.24190769560582137]
	TIME [epoch: 6.06 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.25597994924782624		[learning rate: 0.0026584]
	Learning Rate: 0.00265837
	LOSS [training: 0.25597994924782624 | validation: 0.42177450828726404]
	TIME [epoch: 6.07 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.3234422630635032		[learning rate: 0.002649]
	Learning Rate: 0.00264897
	LOSS [training: 0.3234422630635032 | validation: 0.25838897848785664]
	TIME [epoch: 6.06 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2885800177096913		[learning rate: 0.0026396]
	Learning Rate: 0.0026396
	LOSS [training: 0.2885800177096913 | validation: 0.29437295113540696]
	TIME [epoch: 6.06 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21356086829984847		[learning rate: 0.0026303]
	Learning Rate: 0.00263027
	LOSS [training: 0.21356086829984847 | validation: 0.2746839463227895]
	TIME [epoch: 6.06 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2037844457159277		[learning rate: 0.002621]
	Learning Rate: 0.00262097
	LOSS [training: 0.2037844457159277 | validation: 0.2716901965612049]
	TIME [epoch: 6.07 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19942082256528026		[learning rate: 0.0026117]
	Learning Rate: 0.0026117
	LOSS [training: 0.19942082256528026 | validation: 0.2761524024896404]
	TIME [epoch: 6.05 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1970028663288042		[learning rate: 0.0026025]
	Learning Rate: 0.00260246
	LOSS [training: 0.1970028663288042 | validation: 0.2476582855183457]
	TIME [epoch: 6.07 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20188748423151034		[learning rate: 0.0025933]
	Learning Rate: 0.00259326
	LOSS [training: 0.20188748423151034 | validation: 0.2188570738962754]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_432.pth
	Model improved!!!
EPOCH 433/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20123035807804157		[learning rate: 0.0025841]
	Learning Rate: 0.00258409
	LOSS [training: 0.20123035807804157 | validation: 0.3145740065194822]
	TIME [epoch: 6.07 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2253649005360692		[learning rate: 0.002575]
	Learning Rate: 0.00257495
	LOSS [training: 0.2253649005360692 | validation: 0.23896499204733238]
	TIME [epoch: 6.05 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2069841661422177		[learning rate: 0.0025658]
	Learning Rate: 0.00256585
	LOSS [training: 0.2069841661422177 | validation: 0.30373727879881524]
	TIME [epoch: 6.06 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21512549102859826		[learning rate: 0.0025568]
	Learning Rate: 0.00255677
	LOSS [training: 0.21512549102859826 | validation: 0.21208944115045916]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20505304008924463		[learning rate: 0.0025477]
	Learning Rate: 0.00254773
	LOSS [training: 0.20505304008924463 | validation: 0.3296156413030309]
	TIME [epoch: 6.08 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23965758293646566		[learning rate: 0.0025387]
	Learning Rate: 0.00253872
	LOSS [training: 0.23965758293646566 | validation: 0.37347879352627744]
	TIME [epoch: 6.05 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.45787069898015903		[learning rate: 0.0025297]
	Learning Rate: 0.00252975
	LOSS [training: 0.45787069898015903 | validation: 0.39777128147218743]
	TIME [epoch: 6.06 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.26693501158017846		[learning rate: 0.0025208]
	Learning Rate: 0.0025208
	LOSS [training: 0.26693501158017846 | validation: 0.3008311565266294]
	TIME [epoch: 6.08 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22519842635045692		[learning rate: 0.0025119]
	Learning Rate: 0.00251189
	LOSS [training: 0.22519842635045692 | validation: 0.21984970129150694]
	TIME [epoch: 6.07 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22443667388156677		[learning rate: 0.002503]
	Learning Rate: 0.002503
	LOSS [training: 0.22443667388156677 | validation: 0.28752459193111723]
	TIME [epoch: 6.07 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1917168460375862		[learning rate: 0.0024942]
	Learning Rate: 0.00249415
	LOSS [training: 0.1917168460375862 | validation: 0.24231526420857552]
	TIME [epoch: 6.06 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22236295205153744		[learning rate: 0.0024853]
	Learning Rate: 0.00248533
	LOSS [training: 0.22236295205153744 | validation: 0.3063336637037247]
	TIME [epoch: 6.05 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1943683406940387		[learning rate: 0.0024765]
	Learning Rate: 0.00247654
	LOSS [training: 0.1943683406940387 | validation: 0.2026360482816501]
	TIME [epoch: 6.06 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18559024087208648		[learning rate: 0.0024678]
	Learning Rate: 0.00246779
	LOSS [training: 0.18559024087208648 | validation: 0.2948764891837656]
	TIME [epoch: 6.07 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18499682244000049		[learning rate: 0.0024591]
	Learning Rate: 0.00245906
	LOSS [training: 0.18499682244000049 | validation: 0.21474065193315106]
	TIME [epoch: 6.08 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21106014133641388		[learning rate: 0.0024504]
	Learning Rate: 0.00245037
	LOSS [training: 0.21106014133641388 | validation: 0.24194577891930438]
	TIME [epoch: 6.07 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17245335841978193		[learning rate: 0.0024417]
	Learning Rate: 0.0024417
	LOSS [training: 0.17245335841978193 | validation: 0.2377415508732328]
	TIME [epoch: 6.06 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1689811731860107		[learning rate: 0.0024331]
	Learning Rate: 0.00243307
	LOSS [training: 0.1689811731860107 | validation: 0.22037251118602885]
	TIME [epoch: 6.07 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1961136424684363		[learning rate: 0.0024245]
	Learning Rate: 0.00242446
	LOSS [training: 0.1961136424684363 | validation: 0.23683540529919941]
	TIME [epoch: 6.06 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17212477935353962		[learning rate: 0.0024159]
	Learning Rate: 0.00241589
	LOSS [training: 0.17212477935353962 | validation: 0.20698775949116133]
	TIME [epoch: 6.07 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1578512848905049		[learning rate: 0.0024073]
	Learning Rate: 0.00240735
	LOSS [training: 0.1578512848905049 | validation: 0.2186362119444839]
	TIME [epoch: 6.07 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14985633110276708		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.14985633110276708 | validation: 0.19405104132833673]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15991413117195832		[learning rate: 0.0023904]
	Learning Rate: 0.00239035
	LOSS [training: 0.15991413117195832 | validation: 0.3504715022461768]
	TIME [epoch: 6.06 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2287288225867058		[learning rate: 0.0023819]
	Learning Rate: 0.0023819
	LOSS [training: 0.2287288225867058 | validation: 0.429611909875409]
	TIME [epoch: 6.07 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.46416367832321426		[learning rate: 0.0023735]
	Learning Rate: 0.00237347
	LOSS [training: 0.46416367832321426 | validation: 0.40505473601429465]
	TIME [epoch: 6.07 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2791441182599155		[learning rate: 0.0023651]
	Learning Rate: 0.00236508
	LOSS [training: 0.2791441182599155 | validation: 0.2220423601496025]
	TIME [epoch: 6.06 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15911164061237504		[learning rate: 0.0023567]
	Learning Rate: 0.00235672
	LOSS [training: 0.15911164061237504 | validation: 0.1981585444145574]
	TIME [epoch: 6.07 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.191315128887136		[learning rate: 0.0023484]
	Learning Rate: 0.00234838
	LOSS [training: 0.191315128887136 | validation: 0.25837042646830377]
	TIME [epoch: 6.06 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1689475475102909		[learning rate: 0.0023401]
	Learning Rate: 0.00234008
	LOSS [training: 0.1689475475102909 | validation: 0.17993028134661987]
	TIME [epoch: 6.07 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15405475907035135		[learning rate: 0.0023318]
	Learning Rate: 0.00233181
	LOSS [training: 0.15405475907035135 | validation: 0.21557468678646916]
	TIME [epoch: 6.1 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1462070620432138		[learning rate: 0.0023236]
	Learning Rate: 0.00232356
	LOSS [training: 0.1462070620432138 | validation: 0.22925060709004158]
	TIME [epoch: 6.05 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1533242500844009		[learning rate: 0.0023153]
	Learning Rate: 0.00231534
	LOSS [training: 0.1533242500844009 | validation: 0.2124700767314804]
	TIME [epoch: 6.07 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2034985408217478		[learning rate: 0.0023072]
	Learning Rate: 0.00230716
	LOSS [training: 0.2034985408217478 | validation: 0.2785538683334657]
	TIME [epoch: 6.05 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.171489777668967		[learning rate: 0.002299]
	Learning Rate: 0.002299
	LOSS [training: 0.171489777668967 | validation: 0.18363178798793492]
	TIME [epoch: 6.06 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15716330706943007		[learning rate: 0.0022909]
	Learning Rate: 0.00229087
	LOSS [training: 0.15716330706943007 | validation: 0.26710073376956717]
	TIME [epoch: 6.06 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16501776712442953		[learning rate: 0.0022828]
	Learning Rate: 0.00228277
	LOSS [training: 0.16501776712442953 | validation: 0.1765610370282947]
	TIME [epoch: 6.04 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16796460943833139		[learning rate: 0.0022747]
	Learning Rate: 0.00227469
	LOSS [training: 0.16796460943833139 | validation: 0.2591511599126036]
	TIME [epoch: 6.05 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15659144070429684		[learning rate: 0.0022667]
	Learning Rate: 0.00226665
	LOSS [training: 0.15659144070429684 | validation: 0.19424623312789058]
	TIME [epoch: 6.06 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.18389206397691613		[learning rate: 0.0022586]
	Learning Rate: 0.00225864
	LOSS [training: 0.18389206397691613 | validation: 0.3431094630834872]
	TIME [epoch: 6.06 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23085108134698068		[learning rate: 0.0022506]
	Learning Rate: 0.00225065
	LOSS [training: 0.23085108134698068 | validation: 0.2794579320926817]
	TIME [epoch: 6.06 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.27935985945880026		[learning rate: 0.0022427]
	Learning Rate: 0.00224269
	LOSS [training: 0.27935985945880026 | validation: 0.32194126954256747]
	TIME [epoch: 6.05 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19364963953098502		[learning rate: 0.0022348]
	Learning Rate: 0.00223476
	LOSS [training: 0.19364963953098502 | validation: 0.19796334320101172]
	TIME [epoch: 6.06 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1344244830695606		[learning rate: 0.0022269]
	Learning Rate: 0.00222686
	LOSS [training: 0.1344244830695606 | validation: 0.18268693150234713]
	TIME [epoch: 6.05 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14945654708673328		[learning rate: 0.002219]
	Learning Rate: 0.00221898
	LOSS [training: 0.14945654708673328 | validation: 0.22838806792056765]
	TIME [epoch: 6.05 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1551305308737383		[learning rate: 0.0022111]
	Learning Rate: 0.00221114
	LOSS [training: 0.1551305308737383 | validation: 0.25341643866970054]
	TIME [epoch: 6.08 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16702112799484756		[learning rate: 0.0022033]
	Learning Rate: 0.00220332
	LOSS [training: 0.16702112799484756 | validation: 0.20957979392157192]
	TIME [epoch: 6.05 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.22625044916781856		[learning rate: 0.0021955]
	Learning Rate: 0.00219553
	LOSS [training: 0.22625044916781856 | validation: 0.3841680759317827]
	TIME [epoch: 6.06 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.23926540771263874		[learning rate: 0.0021878]
	Learning Rate: 0.00218776
	LOSS [training: 0.23926540771263874 | validation: 0.19446246771597336]
	TIME [epoch: 6.06 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17068270601543722		[learning rate: 0.00218]
	Learning Rate: 0.00218003
	LOSS [training: 0.17068270601543722 | validation: 0.17793622916873275]
	TIME [epoch: 6.05 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13970549001638313		[learning rate: 0.0021723]
	Learning Rate: 0.00217232
	LOSS [training: 0.13970549001638313 | validation: 0.2693674227165104]
	TIME [epoch: 6.05 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16709637899763088		[learning rate: 0.0021646]
	Learning Rate: 0.00216463
	LOSS [training: 0.16709637899763088 | validation: 0.17951509079644098]
	TIME [epoch: 6.05 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1708054521917169		[learning rate: 0.002157]
	Learning Rate: 0.00215698
	LOSS [training: 0.1708054521917169 | validation: 0.19279887130311957]
	TIME [epoch: 6.06 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1301453445249801		[learning rate: 0.0021494]
	Learning Rate: 0.00214935
	LOSS [training: 0.1301453445249801 | validation: 0.17788046874114097]
	TIME [epoch: 6.06 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1327345198792696		[learning rate: 0.0021418]
	Learning Rate: 0.00214175
	LOSS [training: 0.1327345198792696 | validation: 0.2015678294414891]
	TIME [epoch: 6.06 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1424626659487591		[learning rate: 0.0021342]
	Learning Rate: 0.00213418
	LOSS [training: 0.1424626659487591 | validation: 0.2076300633632885]
	TIME [epoch: 6.08 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14984516404424247		[learning rate: 0.0021266]
	Learning Rate: 0.00212663
	LOSS [training: 0.14984516404424247 | validation: 0.18225019975337292]
	TIME [epoch: 6.05 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.156449056246307		[learning rate: 0.0021191]
	Learning Rate: 0.00211911
	LOSS [training: 0.156449056246307 | validation: 0.2922255680182509]
	TIME [epoch: 6.06 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15078765162263527		[learning rate: 0.0021116]
	Learning Rate: 0.00211162
	LOSS [training: 0.15078765162263527 | validation: 0.1863091921067393]
	TIME [epoch: 6.05 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1823513334514824		[learning rate: 0.0021042]
	Learning Rate: 0.00210415
	LOSS [training: 0.1823513334514824 | validation: 0.3251170600767112]
	TIME [epoch: 6.06 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2007986447605024		[learning rate: 0.0020967]
	Learning Rate: 0.00209671
	LOSS [training: 0.2007986447605024 | validation: 0.2213725670024206]
	TIME [epoch: 6.05 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2287972060116963		[learning rate: 0.0020893]
	Learning Rate: 0.0020893
	LOSS [training: 0.2287972060116963 | validation: 0.2325982668431079]
	TIME [epoch: 6.04 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14379691168223052		[learning rate: 0.0020819]
	Learning Rate: 0.00208191
	LOSS [training: 0.14379691168223052 | validation: 0.18150659075501302]
	TIME [epoch: 6.05 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1293507154298889		[learning rate: 0.0020745]
	Learning Rate: 0.00207455
	LOSS [training: 0.1293507154298889 | validation: 0.1692032674569589]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1557412461929452		[learning rate: 0.0020672]
	Learning Rate: 0.00206721
	LOSS [training: 0.1557412461929452 | validation: 0.2874503537565431]
	TIME [epoch: 6.1 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15958829086709356		[learning rate: 0.0020599]
	Learning Rate: 0.0020599
	LOSS [training: 0.15958829086709356 | validation: 0.19840746327648812]
	TIME [epoch: 6.09 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19006448142211924		[learning rate: 0.0020526]
	Learning Rate: 0.00205262
	LOSS [training: 0.19006448142211924 | validation: 0.2758843573403584]
	TIME [epoch: 6.08 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14636845156028794		[learning rate: 0.0020454]
	Learning Rate: 0.00204536
	LOSS [training: 0.14636845156028794 | validation: 0.15146836162885544]
	TIME [epoch: 6.05 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_499.pth
	Model improved!!!
EPOCH 500/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13086068467630022		[learning rate: 0.0020381]
	Learning Rate: 0.00203812
	LOSS [training: 0.13086068467630022 | validation: 0.22224299088067118]
	TIME [epoch: 6.08 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1475157492750971		[learning rate: 0.0020309]
	Learning Rate: 0.00203092
	LOSS [training: 0.1475157492750971 | validation: 0.18625450952766873]
	TIME [epoch: 283 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20111266157854069		[learning rate: 0.0020237]
	Learning Rate: 0.00202374
	LOSS [training: 0.20111266157854069 | validation: 0.3154775475817734]
	TIME [epoch: 12.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1909176401054798		[learning rate: 0.0020166]
	Learning Rate: 0.00201658
	LOSS [training: 0.1909176401054798 | validation: 0.1703205444310946]
	TIME [epoch: 12.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1511209320651966		[learning rate: 0.0020094]
	Learning Rate: 0.00200945
	LOSS [training: 0.1511209320651966 | validation: 0.19616061095399007]
	TIME [epoch: 12.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1243743617001406		[learning rate: 0.0020023]
	Learning Rate: 0.00200234
	LOSS [training: 0.1243743617001406 | validation: 0.19654139148373603]
	TIME [epoch: 12.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1212862970723593		[learning rate: 0.0019953]
	Learning Rate: 0.00199526
	LOSS [training: 0.1212862970723593 | validation: 0.1699469968564173]
	TIME [epoch: 12.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1727082438983719		[learning rate: 0.0019882]
	Learning Rate: 0.00198821
	LOSS [training: 0.1727082438983719 | validation: 0.3430892412056965]
	TIME [epoch: 12.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20049026400080158		[learning rate: 0.0019812]
	Learning Rate: 0.00198118
	LOSS [training: 0.20049026400080158 | validation: 0.1703902683686386]
	TIME [epoch: 12.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1606777819941873		[learning rate: 0.0019742]
	Learning Rate: 0.00197417
	LOSS [training: 0.1606777819941873 | validation: 0.2479249862332562]
	TIME [epoch: 12.9 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1404429097054697		[learning rate: 0.0019672]
	Learning Rate: 0.00196719
	LOSS [training: 0.1404429097054697 | validation: 0.16118309265672406]
	TIME [epoch: 12.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16151032751227326		[learning rate: 0.0019602]
	Learning Rate: 0.00196023
	LOSS [training: 0.16151032751227326 | validation: 0.2269060923250383]
	TIME [epoch: 12.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12784245196506766		[learning rate: 0.0019533]
	Learning Rate: 0.0019533
	LOSS [training: 0.12784245196506766 | validation: 0.16140611731918147]
	TIME [epoch: 12.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11376782634816733		[learning rate: 0.0019464]
	Learning Rate: 0.00194639
	LOSS [training: 0.11376782634816733 | validation: 0.159850575224586]
	TIME [epoch: 13 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13215367300060743		[learning rate: 0.0019395]
	Learning Rate: 0.00193951
	LOSS [training: 0.13215367300060743 | validation: 0.19893402854611783]
	TIME [epoch: 12.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12190085979919464		[learning rate: 0.0019327]
	Learning Rate: 0.00193265
	LOSS [training: 0.12190085979919464 | validation: 0.1611725196840209]
	TIME [epoch: 12.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1467850679002136		[learning rate: 0.0019258]
	Learning Rate: 0.00192582
	LOSS [training: 0.1467850679002136 | validation: 0.2282041943327128]
	TIME [epoch: 12.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1334071762304549		[learning rate: 0.001919]
	Learning Rate: 0.00191901
	LOSS [training: 0.1334071762304549 | validation: 0.18737575562655182]
	TIME [epoch: 12.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17313792196775224		[learning rate: 0.0019122]
	Learning Rate: 0.00191222
	LOSS [training: 0.17313792196775224 | validation: 0.3299560990574623]
	TIME [epoch: 12.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20895575870517036		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.20895575870517036 | validation: 0.1990258037888806]
	TIME [epoch: 12.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2081815850399701		[learning rate: 0.0018987]
	Learning Rate: 0.00189872
	LOSS [training: 0.2081815850399701 | validation: 0.18411084161608576]
	TIME [epoch: 12.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11221255420783571		[learning rate: 0.001892]
	Learning Rate: 0.00189201
	LOSS [training: 0.11221255420783571 | validation: 0.2932458516239956]
	TIME [epoch: 13 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2158001753934664		[learning rate: 0.0018853]
	Learning Rate: 0.00188532
	LOSS [training: 0.2158001753934664 | validation: 0.30547559226579973]
	TIME [epoch: 12.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2992959482778308		[learning rate: 0.0018787]
	Learning Rate: 0.00187865
	LOSS [training: 0.2992959482778308 | validation: 0.2112611223640141]
	TIME [epoch: 13 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15299068300017155		[learning rate: 0.001872]
	Learning Rate: 0.00187201
	LOSS [training: 0.15299068300017155 | validation: 0.2761885784702173]
	TIME [epoch: 12.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1674742088094073		[learning rate: 0.0018654]
	Learning Rate: 0.00186539
	LOSS [training: 0.1674742088094073 | validation: 0.16498329085520275]
	TIME [epoch: 13 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15790885070835495		[learning rate: 0.0018588]
	Learning Rate: 0.00185879
	LOSS [training: 0.15790885070835495 | validation: 0.1883678291199347]
	TIME [epoch: 12.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12114521041656798		[learning rate: 0.0018522]
	Learning Rate: 0.00185222
	LOSS [training: 0.12114521041656798 | validation: 0.17268862223481912]
	TIME [epoch: 12.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10789412033703188		[learning rate: 0.0018457]
	Learning Rate: 0.00184567
	LOSS [training: 0.10789412033703188 | validation: 0.14502088168196367]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_528.pth
	Model improved!!!
EPOCH 529/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12010635935710244		[learning rate: 0.0018391]
	Learning Rate: 0.00183914
	LOSS [training: 0.12010635935710244 | validation: 0.24659767403335545]
	TIME [epoch: 12.9 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13752942281464023		[learning rate: 0.0018326]
	Learning Rate: 0.00183264
	LOSS [training: 0.13752942281464023 | validation: 0.21408450782780775]
	TIME [epoch: 12.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2097363250370069		[learning rate: 0.0018262]
	Learning Rate: 0.00182616
	LOSS [training: 0.2097363250370069 | validation: 0.21189104711206835]
	TIME [epoch: 12.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11319620997395666		[learning rate: 0.0018197]
	Learning Rate: 0.0018197
	LOSS [training: 0.11319620997395666 | validation: 0.17281968908345685]
	TIME [epoch: 12.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10615964689144339		[learning rate: 0.0018133]
	Learning Rate: 0.00181327
	LOSS [training: 0.10615964689144339 | validation: 0.13951363283227014]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12005131536431651		[learning rate: 0.0018069]
	Learning Rate: 0.00180685
	LOSS [training: 0.12005131536431651 | validation: 0.2212550200034279]
	TIME [epoch: 12.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13425058485960625		[learning rate: 0.0018005]
	Learning Rate: 0.00180046
	LOSS [training: 0.13425058485960625 | validation: 0.18926529385960966]
	TIME [epoch: 12.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17792393813538077		[learning rate: 0.0017941]
	Learning Rate: 0.0017941
	LOSS [training: 0.17792393813538077 | validation: 0.2330404610029646]
	TIME [epoch: 12.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12288980893727494		[learning rate: 0.0017878]
	Learning Rate: 0.00178775
	LOSS [training: 0.12288980893727494 | validation: 0.1466161175146868]
	TIME [epoch: 13 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10766534195819973		[learning rate: 0.0017814]
	Learning Rate: 0.00178143
	LOSS [training: 0.10766534195819973 | validation: 0.15971804376138948]
	TIME [epoch: 13 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1000329135205408		[learning rate: 0.0017751]
	Learning Rate: 0.00177513
	LOSS [training: 0.1000329135205408 | validation: 0.14167101939422644]
	TIME [epoch: 12.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0990998986822846		[learning rate: 0.0017689]
	Learning Rate: 0.00176886
	LOSS [training: 0.0990998986822846 | validation: 0.1641106609977285]
	TIME [epoch: 13 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09772341705985733		[learning rate: 0.0017626]
	Learning Rate: 0.0017626
	LOSS [training: 0.09772341705985733 | validation: 0.14923684978814664]
	TIME [epoch: 12.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0934296187048553		[learning rate: 0.0017564]
	Learning Rate: 0.00175637
	LOSS [training: 0.0934296187048553 | validation: 0.13953248654374104]
	TIME [epoch: 12.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09525514360015798		[learning rate: 0.0017502]
	Learning Rate: 0.00175016
	LOSS [training: 0.09525514360015798 | validation: 0.22101037880309038]
	TIME [epoch: 12.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14673186932212232		[learning rate: 0.001744]
	Learning Rate: 0.00174397
	LOSS [training: 0.14673186932212232 | validation: 0.28013022061946036]
	TIME [epoch: 13 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.28391349785628484		[learning rate: 0.0017378]
	Learning Rate: 0.0017378
	LOSS [training: 0.28391349785628484 | validation: 0.31009747651845393]
	TIME [epoch: 12.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.21187661776548602		[learning rate: 0.0017317]
	Learning Rate: 0.00173166
	LOSS [training: 0.21187661776548602 | validation: 0.1704347746655756]
	TIME [epoch: 12.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10757402914480867		[learning rate: 0.0017255]
	Learning Rate: 0.00172553
	LOSS [training: 0.10757402914480867 | validation: 0.14728699606422074]
	TIME [epoch: 12.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1068843268031442		[learning rate: 0.0017194]
	Learning Rate: 0.00171943
	LOSS [training: 0.1068843268031442 | validation: 0.20985080167539666]
	TIME [epoch: 13 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1278143798464732		[learning rate: 0.0017134]
	Learning Rate: 0.00171335
	LOSS [training: 0.1278143798464732 | validation: 0.3878858281453346]
	TIME [epoch: 12.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.37153805121712824		[learning rate: 0.0017073]
	Learning Rate: 0.00170729
	LOSS [training: 0.37153805121712824 | validation: 0.24314381923913064]
	TIME [epoch: 12.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.20749478067475344		[learning rate: 0.0017013]
	Learning Rate: 0.00170125
	LOSS [training: 0.20749478067475344 | validation: 0.20056363851505218]
	TIME [epoch: 12.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1394704069085695		[learning rate: 0.0016952]
	Learning Rate: 0.00169524
	LOSS [training: 0.1394704069085695 | validation: 0.16882430663427705]
	TIME [epoch: 12.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1445471027747929		[learning rate: 0.0016892]
	Learning Rate: 0.00168924
	LOSS [training: 0.1445471027747929 | validation: 0.1734076404360868]
	TIME [epoch: 12.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1036452075432687		[learning rate: 0.0016833]
	Learning Rate: 0.00168327
	LOSS [training: 0.1036452075432687 | validation: 0.14429871339884817]
	TIME [epoch: 12.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10647418984917618		[learning rate: 0.0016773]
	Learning Rate: 0.00167732
	LOSS [training: 0.10647418984917618 | validation: 0.15750572411699537]
	TIME [epoch: 12.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10321899205663346		[learning rate: 0.0016714]
	Learning Rate: 0.00167139
	LOSS [training: 0.10321899205663346 | validation: 0.16463020966266534]
	TIME [epoch: 12.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09527252066504453		[learning rate: 0.0016655]
	Learning Rate: 0.00166548
	LOSS [training: 0.09527252066504453 | validation: 0.1253051731056712]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_557.pth
	Model improved!!!
EPOCH 558/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11193896125220856		[learning rate: 0.0016596]
	Learning Rate: 0.00165959
	LOSS [training: 0.11193896125220856 | validation: 0.25204040597633587]
	TIME [epoch: 12.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1434504675560827		[learning rate: 0.0016537]
	Learning Rate: 0.00165372
	LOSS [training: 0.1434504675560827 | validation: 0.1764693596046889]
	TIME [epoch: 12.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16909155346444155		[learning rate: 0.0016479]
	Learning Rate: 0.00164787
	LOSS [training: 0.16909155346444155 | validation: 0.1694388604888633]
	TIME [epoch: 12.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09924775844935957		[learning rate: 0.001642]
	Learning Rate: 0.00164204
	LOSS [training: 0.09924775844935957 | validation: 0.1736061503988579]
	TIME [epoch: 12.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10340476463766139		[learning rate: 0.0016362]
	Learning Rate: 0.00163624
	LOSS [training: 0.10340476463766139 | validation: 0.14913853942880967]
	TIME [epoch: 12.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1265250800062325		[learning rate: 0.0016305]
	Learning Rate: 0.00163045
	LOSS [training: 0.1265250800062325 | validation: 0.22221261519290267]
	TIME [epoch: 12.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12486054826397627		[learning rate: 0.0016247]
	Learning Rate: 0.00162469
	LOSS [training: 0.12486054826397627 | validation: 0.16973500802297548]
	TIME [epoch: 12.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1673664347236454		[learning rate: 0.0016189]
	Learning Rate: 0.00161894
	LOSS [training: 0.1673664347236454 | validation: 0.2634318912815023]
	TIME [epoch: 12.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15428014145343183		[learning rate: 0.0016132]
	Learning Rate: 0.00161322
	LOSS [training: 0.15428014145343183 | validation: 0.1295000636140354]
	TIME [epoch: 12.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11297848422479984		[learning rate: 0.0016075]
	Learning Rate: 0.00160751
	LOSS [training: 0.11297848422479984 | validation: 0.14691388192927676]
	TIME [epoch: 12.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09056347421238684		[learning rate: 0.0016018]
	Learning Rate: 0.00160183
	LOSS [training: 0.09056347421238684 | validation: 0.1601144921574821]
	TIME [epoch: 12.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09517142409941616		[learning rate: 0.0015962]
	Learning Rate: 0.00159616
	LOSS [training: 0.09517142409941616 | validation: 0.1297627121826897]
	TIME [epoch: 12.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.097996275724186		[learning rate: 0.0015905]
	Learning Rate: 0.00159052
	LOSS [training: 0.097996275724186 | validation: 0.15986612601012193]
	TIME [epoch: 12.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10968013370328045		[learning rate: 0.0015849]
	Learning Rate: 0.00158489
	LOSS [training: 0.10968013370328045 | validation: 0.15819264213179973]
	TIME [epoch: 12.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1557981735019324		[learning rate: 0.0015793]
	Learning Rate: 0.00157929
	LOSS [training: 0.1557981735019324 | validation: 0.28206305871051296]
	TIME [epoch: 12.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17533486915699606		[learning rate: 0.0015737]
	Learning Rate: 0.0015737
	LOSS [training: 0.17533486915699606 | validation: 0.15328548162140487]
	TIME [epoch: 12.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13791041461447118		[learning rate: 0.0015681]
	Learning Rate: 0.00156814
	LOSS [training: 0.13791041461447118 | validation: 0.20695706301519665]
	TIME [epoch: 12.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11333951501341522		[learning rate: 0.0015626]
	Learning Rate: 0.00156259
	LOSS [training: 0.11333951501341522 | validation: 0.1272577082350794]
	TIME [epoch: 12.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09582273307573161		[learning rate: 0.0015571]
	Learning Rate: 0.00155707
	LOSS [training: 0.09582273307573161 | validation: 0.1613924680402543]
	TIME [epoch: 12.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1010667789041666		[learning rate: 0.0015516]
	Learning Rate: 0.00155156
	LOSS [training: 0.1010667789041666 | validation: 0.13932364298168018]
	TIME [epoch: 12.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14112460113233213		[learning rate: 0.0015461]
	Learning Rate: 0.00154608
	LOSS [training: 0.14112460113233213 | validation: 0.18946882747490512]
	TIME [epoch: 12.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1078074048195224		[learning rate: 0.0015406]
	Learning Rate: 0.00154061
	LOSS [training: 0.1078074048195224 | validation: 0.13829919348420927]
	TIME [epoch: 12.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1046923080143702		[learning rate: 0.0015352]
	Learning Rate: 0.00153516
	LOSS [training: 0.1046923080143702 | validation: 0.18087511374797816]
	TIME [epoch: 12.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09703388977513829		[learning rate: 0.0015297]
	Learning Rate: 0.00152973
	LOSS [training: 0.09703388977513829 | validation: 0.12984755412435406]
	TIME [epoch: 12.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11121024973797329		[learning rate: 0.0015243]
	Learning Rate: 0.00152432
	LOSS [training: 0.11121024973797329 | validation: 0.26571559701560393]
	TIME [epoch: 12.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15726943289045575		[learning rate: 0.0015189]
	Learning Rate: 0.00151893
	LOSS [training: 0.15726943289045575 | validation: 0.16336521140149007]
	TIME [epoch: 12.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1647991879426108		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.1647991879426108 | validation: 0.19078175742848813]
	TIME [epoch: 12.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1036932674669906		[learning rate: 0.0015082]
	Learning Rate: 0.00150821
	LOSS [training: 0.1036932674669906 | validation: 0.16188768326385802]
	TIME [epoch: 12.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1205286119421514		[learning rate: 0.0015029]
	Learning Rate: 0.00150288
	LOSS [training: 0.1205286119421514 | validation: 0.15490230000552316]
	TIME [epoch: 12.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12968389205575165		[learning rate: 0.0014976]
	Learning Rate: 0.00149756
	LOSS [training: 0.12968389205575165 | validation: 0.19501757536429545]
	TIME [epoch: 12.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10611004420416947		[learning rate: 0.0014923]
	Learning Rate: 0.00149227
	LOSS [training: 0.10611004420416947 | validation: 0.13618661578375485]
	TIME [epoch: 12.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10894727936670126		[learning rate: 0.001487]
	Learning Rate: 0.00148699
	LOSS [training: 0.10894727936670126 | validation: 0.14162389772636316]
	TIME [epoch: 12.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08955314441742443		[learning rate: 0.0014817]
	Learning Rate: 0.00148173
	LOSS [training: 0.08955314441742443 | validation: 0.136457661592693]
	TIME [epoch: 12.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08203288788368887		[learning rate: 0.0014765]
	Learning Rate: 0.00147649
	LOSS [training: 0.08203288788368887 | validation: 0.12610987749081456]
	TIME [epoch: 12.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10511931408903388		[learning rate: 0.0014713]
	Learning Rate: 0.00147127
	LOSS [training: 0.10511931408903388 | validation: 0.31425037395209005]
	TIME [epoch: 12.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.2037679771016746		[learning rate: 0.0014661]
	Learning Rate: 0.00146607
	LOSS [training: 0.2037679771016746 | validation: 0.18488962689814242]
	TIME [epoch: 12.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1952838651924733		[learning rate: 0.0014609]
	Learning Rate: 0.00146088
	LOSS [training: 0.1952838651924733 | validation: 0.16162848445750516]
	TIME [epoch: 12.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.104736384776696		[learning rate: 0.0014557]
	Learning Rate: 0.00145572
	LOSS [training: 0.104736384776696 | validation: 0.19625710306841615]
	TIME [epoch: 12.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13780017923327664		[learning rate: 0.0014506]
	Learning Rate: 0.00145057
	LOSS [training: 0.13780017923327664 | validation: 0.15629641263206825]
	TIME [epoch: 12.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15250121624280044		[learning rate: 0.0014454]
	Learning Rate: 0.00144544
	LOSS [training: 0.15250121624280044 | validation: 0.19800797461494257]
	TIME [epoch: 12.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1078970791100365		[learning rate: 0.0014403]
	Learning Rate: 0.00144033
	LOSS [training: 0.1078970791100365 | validation: 0.16425548728153316]
	TIME [epoch: 12.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10373497545073872		[learning rate: 0.0014352]
	Learning Rate: 0.00143524
	LOSS [training: 0.10373497545073872 | validation: 0.14452260445937518]
	TIME [epoch: 12.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1527848621269903		[learning rate: 0.0014302]
	Learning Rate: 0.00143016
	LOSS [training: 0.1527848621269903 | validation: 0.2238290898474923]
	TIME [epoch: 12.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11930847963824243		[learning rate: 0.0014251]
	Learning Rate: 0.0014251
	LOSS [training: 0.11930847963824243 | validation: 0.11276120052629049]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_601.pth
	Model improved!!!
EPOCH 602/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09682649381022276		[learning rate: 0.0014201]
	Learning Rate: 0.00142006
	LOSS [training: 0.09682649381022276 | validation: 0.12492678746726452]
	TIME [epoch: 12.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08584845377667788		[learning rate: 0.001415]
	Learning Rate: 0.00141504
	LOSS [training: 0.08584845377667788 | validation: 0.12922820570370983]
	TIME [epoch: 12.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09771527913548735		[learning rate: 0.00141]
	Learning Rate: 0.00141004
	LOSS [training: 0.09771527913548735 | validation: 0.1403061105637715]
	TIME [epoch: 12.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08806770042934697		[learning rate: 0.0014051]
	Learning Rate: 0.00140505
	LOSS [training: 0.08806770042934697 | validation: 0.11213255767853195]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09126783044975728		[learning rate: 0.0014001]
	Learning Rate: 0.00140008
	LOSS [training: 0.09126783044975728 | validation: 0.17137188811946213]
	TIME [epoch: 12.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10125691140207226		[learning rate: 0.0013951]
	Learning Rate: 0.00139513
	LOSS [training: 0.10125691140207226 | validation: 0.21401156134818847]
	TIME [epoch: 12.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.19783935369824907		[learning rate: 0.0013902]
	Learning Rate: 0.0013902
	LOSS [training: 0.19783935369824907 | validation: 0.22895107136823134]
	TIME [epoch: 12.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1344156925856875		[learning rate: 0.0013853]
	Learning Rate: 0.00138528
	LOSS [training: 0.1344156925856875 | validation: 0.1319234316753287]
	TIME [epoch: 12.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08665520237622698		[learning rate: 0.0013804]
	Learning Rate: 0.00138038
	LOSS [training: 0.08665520237622698 | validation: 0.11995908662250568]
	TIME [epoch: 12.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09010817414915354		[learning rate: 0.0013755]
	Learning Rate: 0.0013755
	LOSS [training: 0.09010817414915354 | validation: 0.14804741781662473]
	TIME [epoch: 12.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08517319871921121		[learning rate: 0.0013706]
	Learning Rate: 0.00137064
	LOSS [training: 0.08517319871921121 | validation: 0.11244376919256327]
	TIME [epoch: 12.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09325078699597672		[learning rate: 0.0013658]
	Learning Rate: 0.00136579
	LOSS [training: 0.09325078699597672 | validation: 0.18568345966174757]
	TIME [epoch: 12.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13376346972980732		[learning rate: 0.001361]
	Learning Rate: 0.00136096
	LOSS [training: 0.13376346972980732 | validation: 0.16696176011696007]
	TIME [epoch: 12.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16393058346372472		[learning rate: 0.0013561]
	Learning Rate: 0.00135615
	LOSS [training: 0.16393058346372472 | validation: 0.18568851578465384]
	TIME [epoch: 12.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11179873156933151		[learning rate: 0.0013514]
	Learning Rate: 0.00135135
	LOSS [training: 0.11179873156933151 | validation: 0.16908153106286392]
	TIME [epoch: 12.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11122508330427294		[learning rate: 0.0013466]
	Learning Rate: 0.00134658
	LOSS [training: 0.11122508330427294 | validation: 0.14032222262005953]
	TIME [epoch: 12.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15055652244288736		[learning rate: 0.0013418]
	Learning Rate: 0.00134181
	LOSS [training: 0.15055652244288736 | validation: 0.18816699259135128]
	TIME [epoch: 12.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10845308466061955		[learning rate: 0.0013371]
	Learning Rate: 0.00133707
	LOSS [training: 0.10845308466061955 | validation: 0.1482459591781249]
	TIME [epoch: 12.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09567413650953681		[learning rate: 0.0013323]
	Learning Rate: 0.00133234
	LOSS [training: 0.09567413650953681 | validation: 0.15584786659125352]
	TIME [epoch: 12.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16767751852928744		[learning rate: 0.0013276]
	Learning Rate: 0.00132763
	LOSS [training: 0.16767751852928744 | validation: 0.2694578818967517]
	TIME [epoch: 12.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.16210318991246225		[learning rate: 0.0013229]
	Learning Rate: 0.00132293
	LOSS [training: 0.16210318991246225 | validation: 0.1454731284588817]
	TIME [epoch: 12.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09115714325492932		[learning rate: 0.0013183]
	Learning Rate: 0.00131826
	LOSS [training: 0.09115714325492932 | validation: 0.1238400283389592]
	TIME [epoch: 12.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09894936112208179		[learning rate: 0.0013136]
	Learning Rate: 0.0013136
	LOSS [training: 0.09894936112208179 | validation: 0.1777647135231118]
	TIME [epoch: 12.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10526496030530487		[learning rate: 0.001309]
	Learning Rate: 0.00130895
	LOSS [training: 0.10526496030530487 | validation: 0.1245947170205465]
	TIME [epoch: 12.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11035874269557142		[learning rate: 0.0013043]
	Learning Rate: 0.00130432
	LOSS [training: 0.11035874269557142 | validation: 0.12830518286110598]
	TIME [epoch: 12.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07389296327339535		[learning rate: 0.0012997]
	Learning Rate: 0.00129971
	LOSS [training: 0.07389296327339535 | validation: 0.13279162605308403]
	TIME [epoch: 12.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07775128749038185		[learning rate: 0.0012951]
	Learning Rate: 0.00129511
	LOSS [training: 0.07775128749038185 | validation: 0.10913518724887127]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09108167978567998		[learning rate: 0.0012905]
	Learning Rate: 0.00129053
	LOSS [training: 0.09108167978567998 | validation: 0.22062523749809915]
	TIME [epoch: 12.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.140279788860338		[learning rate: 0.001286]
	Learning Rate: 0.00128597
	LOSS [training: 0.140279788860338 | validation: 0.14342831698178782]
	TIME [epoch: 12.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14467836372271164		[learning rate: 0.0012814]
	Learning Rate: 0.00128142
	LOSS [training: 0.14467836372271164 | validation: 0.16085317561427748]
	TIME [epoch: 12.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08594730465603856		[learning rate: 0.0012769]
	Learning Rate: 0.00127689
	LOSS [training: 0.08594730465603856 | validation: 0.1168423444728351]
	TIME [epoch: 12.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08965546992963877		[learning rate: 0.0012724]
	Learning Rate: 0.00127238
	LOSS [training: 0.08965546992963877 | validation: 0.137768835391166]
	TIME [epoch: 12.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09291159645177859		[learning rate: 0.0012679]
	Learning Rate: 0.00126788
	LOSS [training: 0.09291159645177859 | validation: 0.13678157718635586]
	TIME [epoch: 12.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08597720339900111		[learning rate: 0.0012634]
	Learning Rate: 0.00126339
	LOSS [training: 0.08597720339900111 | validation: 0.10963354550306606]
	TIME [epoch: 12.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11069473272082161		[learning rate: 0.0012589]
	Learning Rate: 0.00125893
	LOSS [training: 0.11069473272082161 | validation: 0.2796366736818104]
	TIME [epoch: 12.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.17254186776203778		[learning rate: 0.0012545]
	Learning Rate: 0.00125447
	LOSS [training: 0.17254186776203778 | validation: 0.13989529732571376]
	TIME [epoch: 12.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13679843953636495		[learning rate: 0.00125]
	Learning Rate: 0.00125004
	LOSS [training: 0.13679843953636495 | validation: 0.127520234455004]
	TIME [epoch: 12.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08441092783663709		[learning rate: 0.0012456]
	Learning Rate: 0.00124562
	LOSS [training: 0.08441092783663709 | validation: 0.19502791843094644]
	TIME [epoch: 12.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12891394919986987		[learning rate: 0.0012412]
	Learning Rate: 0.00124121
	LOSS [training: 0.12891394919986987 | validation: 0.13792956069561774]
	TIME [epoch: 12.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.127205010725639		[learning rate: 0.0012368]
	Learning Rate: 0.00123682
	LOSS [training: 0.127205010725639 | validation: 0.15477858086079085]
	TIME [epoch: 12.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09275896832060591		[learning rate: 0.0012324]
	Learning Rate: 0.00123245
	LOSS [training: 0.09275896832060591 | validation: 0.16911675329041725]
	TIME [epoch: 12.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11125116232630128		[learning rate: 0.0012281]
	Learning Rate: 0.00122809
	LOSS [training: 0.11125116232630128 | validation: 0.1259480586659714]
	TIME [epoch: 12.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12292113152658207		[learning rate: 0.0012237]
	Learning Rate: 0.00122375
	LOSS [training: 0.12292113152658207 | validation: 0.1764887244900312]
	TIME [epoch: 12.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09779653167617579		[learning rate: 0.0012194]
	Learning Rate: 0.00121942
	LOSS [training: 0.09779653167617579 | validation: 0.11511192758972295]
	TIME [epoch: 12.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08560248080714913		[learning rate: 0.0012151]
	Learning Rate: 0.00121511
	LOSS [training: 0.08560248080714913 | validation: 0.11607454461007982]
	TIME [epoch: 12.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07477555896313214		[learning rate: 0.0012108]
	Learning Rate: 0.00121081
	LOSS [training: 0.07477555896313214 | validation: 0.13435533591010318]
	TIME [epoch: 12.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08080980765842145		[learning rate: 0.0012065]
	Learning Rate: 0.00120653
	LOSS [training: 0.08080980765842145 | validation: 0.09890973941505457]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_648.pth
	Model improved!!!
EPOCH 649/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0784914557220203		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.0784914557220203 | validation: 0.15682053408467925]
	TIME [epoch: 12.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08245984064630982		[learning rate: 0.001198]
	Learning Rate: 0.00119801
	LOSS [training: 0.08245984064630982 | validation: 0.10967931635693168]
	TIME [epoch: 12.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09520228700410673		[learning rate: 0.0011938]
	Learning Rate: 0.00119378
	LOSS [training: 0.09520228700410673 | validation: 0.1902225562638259]
	TIME [epoch: 12.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10993910538186308		[learning rate: 0.0011896]
	Learning Rate: 0.00118956
	LOSS [training: 0.10993910538186308 | validation: 0.1860236949154054]
	TIME [epoch: 12.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.172361109230342		[learning rate: 0.0011853]
	Learning Rate: 0.00118535
	LOSS [training: 0.172361109230342 | validation: 0.21473842720564007]
	TIME [epoch: 12.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11306562104979136		[learning rate: 0.0011812]
	Learning Rate: 0.00118116
	LOSS [training: 0.11306562104979136 | validation: 0.1262459783121643]
	TIME [epoch: 12.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07800504688868866		[learning rate: 0.001177]
	Learning Rate: 0.00117698
	LOSS [training: 0.07800504688868866 | validation: 0.1004364103934558]
	TIME [epoch: 12.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08251316196303714		[learning rate: 0.0011728]
	Learning Rate: 0.00117282
	LOSS [training: 0.08251316196303714 | validation: 0.16177948396594166]
	TIME [epoch: 12.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0843488415901717		[learning rate: 0.0011687]
	Learning Rate: 0.00116867
	LOSS [training: 0.0843488415901717 | validation: 0.1012494555959534]
	TIME [epoch: 12.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08626845648588742		[learning rate: 0.0011645]
	Learning Rate: 0.00116454
	LOSS [training: 0.08626845648588742 | validation: 0.14596336064131013]
	TIME [epoch: 12.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09764101460094424		[learning rate: 0.0011604]
	Learning Rate: 0.00116042
	LOSS [training: 0.09764101460094424 | validation: 0.13270656177754328]
	TIME [epoch: 12.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10539940107926513		[learning rate: 0.0011563]
	Learning Rate: 0.00115632
	LOSS [training: 0.10539940107926513 | validation: 0.1294608622809943]
	TIME [epoch: 12.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07221579729069269		[learning rate: 0.0011522]
	Learning Rate: 0.00115223
	LOSS [training: 0.07221579729069269 | validation: 0.14394246729207866]
	TIME [epoch: 12.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1002198928339989		[learning rate: 0.0011482]
	Learning Rate: 0.00114815
	LOSS [training: 0.1002198928339989 | validation: 0.13756565795266879]
	TIME [epoch: 12.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12161745902086427		[learning rate: 0.0011441]
	Learning Rate: 0.00114409
	LOSS [training: 0.12161745902086427 | validation: 0.20345173006912443]
	TIME [epoch: 12.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11010070525753979		[learning rate: 0.00114]
	Learning Rate: 0.00114005
	LOSS [training: 0.11010070525753979 | validation: 0.10754196426440626]
	TIME [epoch: 12.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08768955943901531		[learning rate: 0.001136]
	Learning Rate: 0.00113602
	LOSS [training: 0.08768955943901531 | validation: 0.1741091380167038]
	TIME [epoch: 12.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08625436021058745		[learning rate: 0.001132]
	Learning Rate: 0.001132
	LOSS [training: 0.08625436021058745 | validation: 0.14938263395887294]
	TIME [epoch: 12.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.15918152757090626		[learning rate: 0.001128]
	Learning Rate: 0.001128
	LOSS [training: 0.15918152757090626 | validation: 0.20168487980505967]
	TIME [epoch: 12.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10884980915861142		[learning rate: 0.001124]
	Learning Rate: 0.00112401
	LOSS [training: 0.10884980915861142 | validation: 0.1278097674460907]
	TIME [epoch: 12.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07329732538741636		[learning rate: 0.00112]
	Learning Rate: 0.00112003
	LOSS [training: 0.07329732538741636 | validation: 0.10891100977702953]
	TIME [epoch: 12.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09692395674821891		[learning rate: 0.0011161]
	Learning Rate: 0.00111607
	LOSS [training: 0.09692395674821891 | validation: 0.21647666467645577]
	TIME [epoch: 12.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13538513782775827		[learning rate: 0.0011121]
	Learning Rate: 0.00111213
	LOSS [training: 0.13538513782775827 | validation: 0.13537189403128452]
	TIME [epoch: 12.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14218721536352066		[learning rate: 0.0011082]
	Learning Rate: 0.00110819
	LOSS [training: 0.14218721536352066 | validation: 0.1451742413520822]
	TIME [epoch: 12.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0856831982622306		[learning rate: 0.0011043]
	Learning Rate: 0.00110427
	LOSS [training: 0.0856831982622306 | validation: 0.16773575442537278]
	TIME [epoch: 12.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1032833850748276		[learning rate: 0.0011004]
	Learning Rate: 0.00110037
	LOSS [training: 0.1032833850748276 | validation: 0.12209156499343617]
	TIME [epoch: 12.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12117984304553732		[learning rate: 0.0010965]
	Learning Rate: 0.00109648
	LOSS [training: 0.12117984304553732 | validation: 0.16466942399960016]
	TIME [epoch: 12.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08328244350915061		[learning rate: 0.0010926]
	Learning Rate: 0.0010926
	LOSS [training: 0.08328244350915061 | validation: 0.09937911859992087]
	TIME [epoch: 12.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08196766280918105		[learning rate: 0.0010887]
	Learning Rate: 0.00108874
	LOSS [training: 0.08196766280918105 | validation: 0.12314029869383454]
	TIME [epoch: 12.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07380820033600853		[learning rate: 0.0010849]
	Learning Rate: 0.00108489
	LOSS [training: 0.07380820033600853 | validation: 0.12655074804149968]
	TIME [epoch: 12.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07330072534460853		[learning rate: 0.0010811]
	Learning Rate: 0.00108105
	LOSS [training: 0.07330072534460853 | validation: 0.1057684830050228]
	TIME [epoch: 12.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0712687821602745		[learning rate: 0.0010772]
	Learning Rate: 0.00107723
	LOSS [training: 0.0712687821602745 | validation: 0.10566632432976752]
	TIME [epoch: 12.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08616122677428466		[learning rate: 0.0010734]
	Learning Rate: 0.00107342
	LOSS [training: 0.08616122677428466 | validation: 0.19182444854353237]
	TIME [epoch: 12.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10012250175556765		[learning rate: 0.0010696]
	Learning Rate: 0.00106962
	LOSS [training: 0.10012250175556765 | validation: 0.12235171910173599]
	TIME [epoch: 12.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11292770820285342		[learning rate: 0.0010658]
	Learning Rate: 0.00106584
	LOSS [training: 0.11292770820285342 | validation: 0.12719547385758134]
	TIME [epoch: 12.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07850263468094627		[learning rate: 0.0010621]
	Learning Rate: 0.00106207
	LOSS [training: 0.07850263468094627 | validation: 0.09586703976296583]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_684.pth
	Model improved!!!
EPOCH 685/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06736406054259202		[learning rate: 0.0010583]
	Learning Rate: 0.00105832
	LOSS [training: 0.06736406054259202 | validation: 0.10987866539113199]
	TIME [epoch: 12.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06966247722514758		[learning rate: 0.0010546]
	Learning Rate: 0.00105457
	LOSS [training: 0.06966247722514758 | validation: 0.09265226786603153]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_686.pth
	Model improved!!!
EPOCH 687/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0778353579727223		[learning rate: 0.0010508]
	Learning Rate: 0.00105084
	LOSS [training: 0.0778353579727223 | validation: 0.18132187453380233]
	TIME [epoch: 12.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09917596404484896		[learning rate: 0.0010471]
	Learning Rate: 0.00104713
	LOSS [training: 0.09917596404484896 | validation: 0.15489195268483147]
	TIME [epoch: 12.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.14836470816074884		[learning rate: 0.0010434]
	Learning Rate: 0.00104343
	LOSS [training: 0.14836470816074884 | validation: 0.1882211162887833]
	TIME [epoch: 12.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10604650512360657		[learning rate: 0.0010397]
	Learning Rate: 0.00103974
	LOSS [training: 0.10604650512360657 | validation: 0.13790068461040197]
	TIME [epoch: 12.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0787908801523804		[learning rate: 0.0010361]
	Learning Rate: 0.00103606
	LOSS [training: 0.0787908801523804 | validation: 0.1091204697325901]
	TIME [epoch: 12.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10682083054901653		[learning rate: 0.0010324]
	Learning Rate: 0.0010324
	LOSS [training: 0.10682083054901653 | validation: 0.20141885441519336]
	TIME [epoch: 12.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10248522147019476		[learning rate: 0.0010287]
	Learning Rate: 0.00102874
	LOSS [training: 0.10248522147019476 | validation: 0.10087796459994676]
	TIME [epoch: 12.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07986391670847631		[learning rate: 0.0010251]
	Learning Rate: 0.00102511
	LOSS [training: 0.07986391670847631 | validation: 0.10584784802836458]
	TIME [epoch: 12.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0759277856823242		[learning rate: 0.0010215]
	Learning Rate: 0.00102148
	LOSS [training: 0.0759277856823242 | validation: 0.13644215335207996]
	TIME [epoch: 12.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07801036516298826		[learning rate: 0.0010179]
	Learning Rate: 0.00101787
	LOSS [training: 0.07801036516298826 | validation: 0.09603577186610975]
	TIME [epoch: 12.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07435969344189856		[learning rate: 0.0010143]
	Learning Rate: 0.00101427
	LOSS [training: 0.07435969344189856 | validation: 0.15406073776390106]
	TIME [epoch: 12.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0938185960382808		[learning rate: 0.0010107]
	Learning Rate: 0.00101068
	LOSS [training: 0.0938185960382808 | validation: 0.13559279526713228]
	TIME [epoch: 12.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12406615461957823		[learning rate: 0.0010071]
	Learning Rate: 0.00100711
	LOSS [training: 0.12406615461957823 | validation: 0.12503412670155747]
	TIME [epoch: 12.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0807550472447992		[learning rate: 0.0010035]
	Learning Rate: 0.00100355
	LOSS [training: 0.0807550472447992 | validation: 0.13714339414923904]
	TIME [epoch: 12.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09815907365929341		[learning rate: 0.001]
	Learning Rate: 0.001
	LOSS [training: 0.09815907365929341 | validation: 0.1182006210224279]
	TIME [epoch: 12.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10692496047340991		[learning rate: 0.00099646]
	Learning Rate: 0.000996464
	LOSS [training: 0.10692496047340991 | validation: 0.18078512263077426]
	TIME [epoch: 12.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09734836266558507		[learning rate: 0.00099294]
	Learning Rate: 0.00099294
	LOSS [training: 0.09734836266558507 | validation: 0.10059191710198812]
	TIME [epoch: 12.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07967288081184785		[learning rate: 0.00098943]
	Learning Rate: 0.000989429
	LOSS [training: 0.07967288081184785 | validation: 0.12444314957316052]
	TIME [epoch: 12.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07084064803722613		[learning rate: 0.00098593]
	Learning Rate: 0.00098593
	LOSS [training: 0.07084064803722613 | validation: 0.0971037219951254]
	TIME [epoch: 12.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08227743717930289		[learning rate: 0.00098244]
	Learning Rate: 0.000982444
	LOSS [training: 0.08227743717930289 | validation: 0.17992048619495687]
	TIME [epoch: 12.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10927360233907234		[learning rate: 0.00097897]
	Learning Rate: 0.00097897
	LOSS [training: 0.10927360233907234 | validation: 0.11166040648434868]
	TIME [epoch: 12.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10743546194208912		[learning rate: 0.00097551]
	Learning Rate: 0.000975508
	LOSS [training: 0.10743546194208912 | validation: 0.1411457394488098]
	TIME [epoch: 12.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07928814282180231		[learning rate: 0.00097206]
	Learning Rate: 0.000972058
	LOSS [training: 0.07928814282180231 | validation: 0.10087413003117066]
	TIME [epoch: 12.8 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0672531256244139		[learning rate: 0.00096862]
	Learning Rate: 0.000968621
	LOSS [training: 0.0672531256244139 | validation: 0.10227524746973914]
	TIME [epoch: 12.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06660995827753716		[learning rate: 0.0009652]
	Learning Rate: 0.000965196
	LOSS [training: 0.06660995827753716 | validation: 0.10883316237428074]
	TIME [epoch: 12.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06944899562063013		[learning rate: 0.00096178]
	Learning Rate: 0.000961783
	LOSS [training: 0.06944899562063013 | validation: 0.09449487346421369]
	TIME [epoch: 12.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08474626365654071		[learning rate: 0.00095838]
	Learning Rate: 0.000958382
	LOSS [training: 0.08474626365654071 | validation: 0.215024030376729]
	TIME [epoch: 12.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12118393974586351		[learning rate: 0.00095499]
	Learning Rate: 0.000954993
	LOSS [training: 0.12118393974586351 | validation: 0.11747706800781273]
	TIME [epoch: 12.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0936410201607151		[learning rate: 0.00095162]
	Learning Rate: 0.000951616
	LOSS [training: 0.0936410201607151 | validation: 0.09734419138354278]
	TIME [epoch: 12.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06889936073080921		[learning rate: 0.00094825]
	Learning Rate: 0.000948251
	LOSS [training: 0.06889936073080921 | validation: 0.14620845596167303]
	TIME [epoch: 12.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08592726323527299		[learning rate: 0.0009449]
	Learning Rate: 0.000944897
	LOSS [training: 0.08592726323527299 | validation: 0.12785800545483175]
	TIME [epoch: 12.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11515476783231808		[learning rate: 0.00094156]
	Learning Rate: 0.000941556
	LOSS [training: 0.11515476783231808 | validation: 0.19890567054898065]
	TIME [epoch: 12.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10383418426853347		[learning rate: 0.00093823]
	Learning Rate: 0.000938227
	LOSS [training: 0.10383418426853347 | validation: 0.08939552886184461]
	TIME [epoch: 12.8 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07679459661611517		[learning rate: 0.00093491]
	Learning Rate: 0.000934909
	LOSS [training: 0.07679459661611517 | validation: 0.12682494904778852]
	TIME [epoch: 12.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07303153948737096		[learning rate: 0.0009316]
	Learning Rate: 0.000931603
	LOSS [training: 0.07303153948737096 | validation: 0.09393180166514137]
	TIME [epoch: 12.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07560360312455815		[learning rate: 0.00092831]
	Learning Rate: 0.000928309
	LOSS [training: 0.07560360312455815 | validation: 0.1152200665616619]
	TIME [epoch: 12.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08056526641947993		[learning rate: 0.00092503]
	Learning Rate: 0.000925026
	LOSS [training: 0.08056526641947993 | validation: 0.10185263536560905]
	TIME [epoch: 12.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11045541129844065		[learning rate: 0.00092175]
	Learning Rate: 0.000921755
	LOSS [training: 0.11045541129844065 | validation: 0.1767289089343108]
	TIME [epoch: 12.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09773720210339637		[learning rate: 0.0009185]
	Learning Rate: 0.000918495
	LOSS [training: 0.09773720210339637 | validation: 0.1533275518639953]
	TIME [epoch: 12.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1342920212613228		[learning rate: 0.00091525]
	Learning Rate: 0.000915247
	LOSS [training: 0.1342920212613228 | validation: 0.12265995540259667]
	TIME [epoch: 12.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06848437588406539		[learning rate: 0.00091201]
	Learning Rate: 0.000912011
	LOSS [training: 0.06848437588406539 | validation: 0.14232229224865803]
	TIME [epoch: 12.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07287175316710562		[learning rate: 0.00090879]
	Learning Rate: 0.000908786
	LOSS [training: 0.07287175316710562 | validation: 0.0955721729628184]
	TIME [epoch: 12.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06630602907660052		[learning rate: 0.00090557]
	Learning Rate: 0.000905572
	LOSS [training: 0.06630602907660052 | validation: 0.0950105257646438]
	TIME [epoch: 12.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06497118120805366		[learning rate: 0.00090237]
	Learning Rate: 0.00090237
	LOSS [training: 0.06497118120805366 | validation: 0.11539411679006968]
	TIME [epoch: 12.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06243624954849398		[learning rate: 0.00089918]
	Learning Rate: 0.000899179
	LOSS [training: 0.06243624954849398 | validation: 0.09576401813190133]
	TIME [epoch: 12.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06511799401251292		[learning rate: 0.000896]
	Learning Rate: 0.000895999
	LOSS [training: 0.06511799401251292 | validation: 0.1039908157270123]
	TIME [epoch: 12.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06610023189347394		[learning rate: 0.00089283]
	Learning Rate: 0.000892831
	LOSS [training: 0.06610023189347394 | validation: 0.10285469368593857]
	TIME [epoch: 12.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08559078881317936		[learning rate: 0.00088967]
	Learning Rate: 0.000889674
	LOSS [training: 0.08559078881317936 | validation: 0.16494428738165035]
	TIME [epoch: 12.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08675459381718877		[learning rate: 0.00088653]
	Learning Rate: 0.000886528
	LOSS [training: 0.08675459381718877 | validation: 0.11281390511815786]
	TIME [epoch: 12.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07573055422226317		[learning rate: 0.00088339]
	Learning Rate: 0.000883393
	LOSS [training: 0.07573055422226317 | validation: 0.12431020280685799]
	TIME [epoch: 12.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08537833989758503		[learning rate: 0.00088027]
	Learning Rate: 0.000880269
	LOSS [training: 0.08537833989758503 | validation: 0.10495537661810364]
	TIME [epoch: 12.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10854072180288092		[learning rate: 0.00087716]
	Learning Rate: 0.000877156
	LOSS [training: 0.10854072180288092 | validation: 0.18866071717002272]
	TIME [epoch: 12.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09891627319987556		[learning rate: 0.00087405]
	Learning Rate: 0.000874055
	LOSS [training: 0.09891627319987556 | validation: 0.092439005235018]
	TIME [epoch: 12.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07010664380121416		[learning rate: 0.00087096]
	Learning Rate: 0.000870964
	LOSS [training: 0.07010664380121416 | validation: 0.1100087892355832]
	TIME [epoch: 12.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.073679008948987		[learning rate: 0.00086788]
	Learning Rate: 0.000867884
	LOSS [training: 0.073679008948987 | validation: 0.10041334248659824]
	TIME [epoch: 12.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08975258085569268		[learning rate: 0.00086481]
	Learning Rate: 0.000864815
	LOSS [training: 0.08975258085569268 | validation: 0.17067128780243537]
	TIME [epoch: 12.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09632882066548883		[learning rate: 0.00086176]
	Learning Rate: 0.000861757
	LOSS [training: 0.09632882066548883 | validation: 0.09221911796860055]
	TIME [epoch: 12.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08846283605653779		[learning rate: 0.00085871]
	Learning Rate: 0.000858709
	LOSS [training: 0.08846283605653779 | validation: 0.1417753369857607]
	TIME [epoch: 12.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08679512656309452		[learning rate: 0.00085567]
	Learning Rate: 0.000855673
	LOSS [training: 0.08679512656309452 | validation: 0.09337094121709552]
	TIME [epoch: 12.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06852859698439843		[learning rate: 0.00085265]
	Learning Rate: 0.000852647
	LOSS [training: 0.06852859698439843 | validation: 0.09872245256852247]
	TIME [epoch: 12.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06435640047461477		[learning rate: 0.00084963]
	Learning Rate: 0.000849632
	LOSS [training: 0.06435640047461477 | validation: 0.09647588878980372]
	TIME [epoch: 12.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07231738665847176		[learning rate: 0.00084663]
	Learning Rate: 0.000846627
	LOSS [training: 0.07231738665847176 | validation: 0.16770174582492856]
	TIME [epoch: 12.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09001069003869294		[learning rate: 0.00084363]
	Learning Rate: 0.000843634
	LOSS [training: 0.09001069003869294 | validation: 0.10439236959047903]
	TIME [epoch: 12.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1060453890645426		[learning rate: 0.00084065]
	Learning Rate: 0.00084065
	LOSS [training: 0.1060453890645426 | validation: 0.12785169546817202]
	TIME [epoch: 12.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06758599358229833		[learning rate: 0.00083768]
	Learning Rate: 0.000837678
	LOSS [training: 0.06758599358229833 | validation: 0.11411267084876764]
	TIME [epoch: 12.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06387870716297356		[learning rate: 0.00083472]
	Learning Rate: 0.000834715
	LOSS [training: 0.06387870716297356 | validation: 0.09340709803588387]
	TIME [epoch: 12.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06951827802642266		[learning rate: 0.00083176]
	Learning Rate: 0.000831764
	LOSS [training: 0.06951827802642266 | validation: 0.11892731808597388]
	TIME [epoch: 12.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06411391208494806		[learning rate: 0.00082882]
	Learning Rate: 0.000828823
	LOSS [training: 0.06411391208494806 | validation: 0.09449519528197253]
	TIME [epoch: 12.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07578967821432135		[learning rate: 0.00082589]
	Learning Rate: 0.000825892
	LOSS [training: 0.07578967821432135 | validation: 0.13171270365737425]
	TIME [epoch: 12.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08978849553083898		[learning rate: 0.00082297]
	Learning Rate: 0.000822971
	LOSS [training: 0.08978849553083898 | validation: 0.10756919847288526]
	TIME [epoch: 12.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1066017925622316		[learning rate: 0.00082006]
	Learning Rate: 0.000820061
	LOSS [training: 0.1066017925622316 | validation: 0.16582267814290655]
	TIME [epoch: 12.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08122490073905386		[learning rate: 0.00081716]
	Learning Rate: 0.000817161
	LOSS [training: 0.08122490073905386 | validation: 0.08584152341801506]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_758.pth
	Model improved!!!
EPOCH 759/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06615345233212992		[learning rate: 0.00081427]
	Learning Rate: 0.000814272
	LOSS [training: 0.06615345233212992 | validation: 0.132158511476937]
	TIME [epoch: 12.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07588955594152218		[learning rate: 0.00081139]
	Learning Rate: 0.000811392
	LOSS [training: 0.07588955594152218 | validation: 0.08631641211222957]
	TIME [epoch: 12.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07719911454903838		[learning rate: 0.00080852]
	Learning Rate: 0.000808523
	LOSS [training: 0.07719911454903838 | validation: 0.10991626036062]
	TIME [epoch: 12.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06869492708218149		[learning rate: 0.00080566]
	Learning Rate: 0.000805664
	LOSS [training: 0.06869492708218149 | validation: 0.11835964049207447]
	TIME [epoch: 12.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07007348610085704		[learning rate: 0.00080281]
	Learning Rate: 0.000802815
	LOSS [training: 0.07007348610085704 | validation: 0.09873331330693169]
	TIME [epoch: 12.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09012224984457191		[learning rate: 0.00079998]
	Learning Rate: 0.000799976
	LOSS [training: 0.09012224984457191 | validation: 0.18001894938948523]
	TIME [epoch: 12.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09735889674412647		[learning rate: 0.00079715]
	Learning Rate: 0.000797147
	LOSS [training: 0.09735889674412647 | validation: 0.10420645785812695]
	TIME [epoch: 12.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09451702362402996		[learning rate: 0.00079433]
	Learning Rate: 0.000794328
	LOSS [training: 0.09451702362402996 | validation: 0.11792533325379512]
	TIME [epoch: 12.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0710470737631381		[learning rate: 0.00079152]
	Learning Rate: 0.000791519
	LOSS [training: 0.0710470737631381 | validation: 0.0994044453257417]
	TIME [epoch: 13 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06120997099824654		[learning rate: 0.00078872]
	Learning Rate: 0.00078872
	LOSS [training: 0.06120997099824654 | validation: 0.09782748753206695]
	TIME [epoch: 12.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06159087419944448		[learning rate: 0.00078593]
	Learning Rate: 0.000785931
	LOSS [training: 0.06159087419944448 | validation: 0.10730287146091838]
	TIME [epoch: 12.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061430630167605596		[learning rate: 0.00078315]
	Learning Rate: 0.000783152
	LOSS [training: 0.061430630167605596 | validation: 0.10279037004451622]
	TIME [epoch: 12.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06153987980763056		[learning rate: 0.00078038]
	Learning Rate: 0.000780383
	LOSS [training: 0.06153987980763056 | validation: 0.09858074657512232]
	TIME [epoch: 12.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05959207674007047		[learning rate: 0.00077762]
	Learning Rate: 0.000777623
	LOSS [training: 0.05959207674007047 | validation: 0.09359284522090316]
	TIME [epoch: 12.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05888460118212913		[learning rate: 0.00077487]
	Learning Rate: 0.000774873
	LOSS [training: 0.05888460118212913 | validation: 0.12600124458155704]
	TIME [epoch: 12.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06687026862684171		[learning rate: 0.00077213]
	Learning Rate: 0.000772134
	LOSS [training: 0.06687026862684171 | validation: 0.08767067385069738]
	TIME [epoch: 12.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09273513060275072		[learning rate: 0.0007694]
	Learning Rate: 0.000769403
	LOSS [training: 0.09273513060275072 | validation: 0.19451693147588253]
	TIME [epoch: 12.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12433880105207055		[learning rate: 0.00076668]
	Learning Rate: 0.000766682
	LOSS [training: 0.12433880105207055 | validation: 0.10860446190314295]
	TIME [epoch: 12.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09695150666425553		[learning rate: 0.00076397]
	Learning Rate: 0.000763971
	LOSS [training: 0.09695150666425553 | validation: 0.09734158852196179]
	TIME [epoch: 12.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06332320679305023		[learning rate: 0.00076127]
	Learning Rate: 0.00076127
	LOSS [training: 0.06332320679305023 | validation: 0.12383598069349817]
	TIME [epoch: 12.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07896011390539273		[learning rate: 0.00075858]
	Learning Rate: 0.000758578
	LOSS [training: 0.07896011390539273 | validation: 0.10361998329593602]
	TIME [epoch: 12.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08530771188224509		[learning rate: 0.0007559]
	Learning Rate: 0.000755895
	LOSS [training: 0.08530771188224509 | validation: 0.13209283290806534]
	TIME [epoch: 12.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06360612181438889		[learning rate: 0.00075322]
	Learning Rate: 0.000753222
	LOSS [training: 0.06360612181438889 | validation: 0.08717219303600171]
	TIME [epoch: 12.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07237861424093107		[learning rate: 0.00075056]
	Learning Rate: 0.000750559
	LOSS [training: 0.07237861424093107 | validation: 0.13575753549730743]
	TIME [epoch: 12.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06839389064311359		[learning rate: 0.0007479]
	Learning Rate: 0.000747905
	LOSS [training: 0.06839389064311359 | validation: 0.10867839135635825]
	TIME [epoch: 12.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05903107703577822		[learning rate: 0.00074526]
	Learning Rate: 0.00074526
	LOSS [training: 0.05903107703577822 | validation: 0.09418052601921947]
	TIME [epoch: 12.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06637548242634689		[learning rate: 0.00074262]
	Learning Rate: 0.000742624
	LOSS [training: 0.06637548242634689 | validation: 0.10966385071258343]
	TIME [epoch: 12.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062446802535827545		[learning rate: 0.00074]
	Learning Rate: 0.000739998
	LOSS [training: 0.062446802535827545 | validation: 0.09880970462125976]
	TIME [epoch: 12.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05716538489422298		[learning rate: 0.00073738]
	Learning Rate: 0.000737382
	LOSS [training: 0.05716538489422298 | validation: 0.10148939936707708]
	TIME [epoch: 12.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06529946155307542		[learning rate: 0.00073477]
	Learning Rate: 0.000734774
	LOSS [training: 0.06529946155307542 | validation: 0.10275159912225698]
	TIME [epoch: 12.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09743650974129654		[learning rate: 0.00073218]
	Learning Rate: 0.000732176
	LOSS [training: 0.09743650974129654 | validation: 0.2246983273687999]
	TIME [epoch: 12.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.13922092986953094		[learning rate: 0.00072959]
	Learning Rate: 0.000729587
	LOSS [training: 0.13922092986953094 | validation: 0.09090229016228363]
	TIME [epoch: 12.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07589206434293894		[learning rate: 0.00072701]
	Learning Rate: 0.000727007
	LOSS [training: 0.07589206434293894 | validation: 0.08918971777302652]
	TIME [epoch: 12.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06296905318238466		[learning rate: 0.00072444]
	Learning Rate: 0.000724436
	LOSS [training: 0.06296905318238466 | validation: 0.15539075871243924]
	TIME [epoch: 12.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08964794387711303		[learning rate: 0.00072187]
	Learning Rate: 0.000721874
	LOSS [training: 0.08964794387711303 | validation: 0.12848500837873544]
	TIME [epoch: 12.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.12553904498927465		[learning rate: 0.00071932]
	Learning Rate: 0.000719322
	LOSS [training: 0.12553904498927465 | validation: 0.1374073091094657]
	TIME [epoch: 12.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06805885985636721		[learning rate: 0.00071678]
	Learning Rate: 0.000716778
	LOSS [training: 0.06805885985636721 | validation: 0.13601663396206792]
	TIME [epoch: 12.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06983178414203978		[learning rate: 0.00071424]
	Learning Rate: 0.000714243
	LOSS [training: 0.06983178414203978 | validation: 0.09126935868744568]
	TIME [epoch: 12.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08427675265429936		[learning rate: 0.00071172]
	Learning Rate: 0.000711718
	LOSS [training: 0.08427675265429936 | validation: 0.12653629452491924]
	TIME [epoch: 12.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06781711402316823		[learning rate: 0.0007092]
	Learning Rate: 0.000709201
	LOSS [training: 0.06781711402316823 | validation: 0.12631778597838098]
	TIME [epoch: 12.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06558441026794837		[learning rate: 0.00070669]
	Learning Rate: 0.000706693
	LOSS [training: 0.06558441026794837 | validation: 0.08757833444830596]
	TIME [epoch: 12.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07567626737711022		[learning rate: 0.00070419]
	Learning Rate: 0.000704194
	LOSS [training: 0.07567626737711022 | validation: 0.102230217973722]
	TIME [epoch: 12.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06583566935370393		[learning rate: 0.0007017]
	Learning Rate: 0.000701704
	LOSS [training: 0.06583566935370393 | validation: 0.10911610996987949]
	TIME [epoch: 12.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06290840649292304		[learning rate: 0.00069922]
	Learning Rate: 0.000699222
	LOSS [training: 0.06290840649292304 | validation: 0.09732613427587866]
	TIME [epoch: 12.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061987123297630085		[learning rate: 0.00069675]
	Learning Rate: 0.00069675
	LOSS [training: 0.061987123297630085 | validation: 0.08542381695727524]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06364405053192154		[learning rate: 0.00069429]
	Learning Rate: 0.000694286
	LOSS [training: 0.06364405053192154 | validation: 0.12302397012434518]
	TIME [epoch: 12.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06293970282647238		[learning rate: 0.00069183]
	Learning Rate: 0.000691831
	LOSS [training: 0.06293970282647238 | validation: 0.10005406237201267]
	TIME [epoch: 12.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06657140535129916		[learning rate: 0.00068938]
	Learning Rate: 0.000689385
	LOSS [training: 0.06657140535129916 | validation: 0.1302513394187715]
	TIME [epoch: 12.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0756429858441419		[learning rate: 0.00068695]
	Learning Rate: 0.000686947
	LOSS [training: 0.0756429858441419 | validation: 0.10107315282278169]
	TIME [epoch: 12.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.11605865480591698		[learning rate: 0.00068452]
	Learning Rate: 0.000684518
	LOSS [training: 0.11605865480591698 | validation: 0.15363942428921007]
	TIME [epoch: 12.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07440959411998802		[learning rate: 0.0006821]
	Learning Rate: 0.000682097
	LOSS [training: 0.07440959411998802 | validation: 0.09376959041989484]
	TIME [epoch: 12.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06259024378335168		[learning rate: 0.00067969]
	Learning Rate: 0.000679685
	LOSS [training: 0.06259024378335168 | validation: 0.09397146792108887]
	TIME [epoch: 12.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06610010226883009		[learning rate: 0.00067728]
	Learning Rate: 0.000677282
	LOSS [training: 0.06610010226883009 | validation: 0.12504080032201664]
	TIME [epoch: 12.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06119538913921673		[learning rate: 0.00067489]
	Learning Rate: 0.000674887
	LOSS [training: 0.06119538913921673 | validation: 0.08119309337508873]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_812.pth
	Model improved!!!
EPOCH 813/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06402039295859292		[learning rate: 0.0006725]
	Learning Rate: 0.0006725
	LOSS [training: 0.06402039295859292 | validation: 0.13341485326072494]
	TIME [epoch: 12.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06525316529950516		[learning rate: 0.00067012]
	Learning Rate: 0.000670122
	LOSS [training: 0.06525316529950516 | validation: 0.10774076919933125]
	TIME [epoch: 12.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05900721354577973		[learning rate: 0.00066775]
	Learning Rate: 0.000667752
	LOSS [training: 0.05900721354577973 | validation: 0.08423556353965664]
	TIME [epoch: 12.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05988017390472566		[learning rate: 0.00066539]
	Learning Rate: 0.000665391
	LOSS [training: 0.05988017390472566 | validation: 0.12445840332313324]
	TIME [epoch: 12.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061358205498292094		[learning rate: 0.00066304]
	Learning Rate: 0.000663038
	LOSS [training: 0.061358205498292094 | validation: 0.08372515345532477]
	TIME [epoch: 12.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059163459572547206		[learning rate: 0.00066069]
	Learning Rate: 0.000660694
	LOSS [training: 0.059163459572547206 | validation: 0.12067167327382496]
	TIME [epoch: 12.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07108063644136484		[learning rate: 0.00065836]
	Learning Rate: 0.000658357
	LOSS [training: 0.07108063644136484 | validation: 0.1083207986464362]
	TIME [epoch: 12.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08991680248681297		[learning rate: 0.00065603]
	Learning Rate: 0.000656029
	LOSS [training: 0.08991680248681297 | validation: 0.19475926350885817]
	TIME [epoch: 12.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09434348434051666		[learning rate: 0.00065371]
	Learning Rate: 0.000653709
	LOSS [training: 0.09434348434051666 | validation: 0.09004167466074747]
	TIME [epoch: 12.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06463987693211115		[learning rate: 0.0006514]
	Learning Rate: 0.000651398
	LOSS [training: 0.06463987693211115 | validation: 0.09601483112265806]
	TIME [epoch: 12.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05801396886235564		[learning rate: 0.00064909]
	Learning Rate: 0.000649094
	LOSS [training: 0.05801396886235564 | validation: 0.1285468233032582]
	TIME [epoch: 12.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06781354885044609		[learning rate: 0.0006468]
	Learning Rate: 0.000646799
	LOSS [training: 0.06781354885044609 | validation: 0.08109277844404442]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08312029403579682		[learning rate: 0.00064451]
	Learning Rate: 0.000644512
	LOSS [training: 0.08312029403579682 | validation: 0.13421752428312841]
	TIME [epoch: 12.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06991186245480262		[learning rate: 0.00064223]
	Learning Rate: 0.000642233
	LOSS [training: 0.06991186245480262 | validation: 0.09617132036956681]
	TIME [epoch: 12.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060486700670458		[learning rate: 0.00063996]
	Learning Rate: 0.000639962
	LOSS [training: 0.060486700670458 | validation: 0.08679276459746788]
	TIME [epoch: 12.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054701744945733946		[learning rate: 0.0006377]
	Learning Rate: 0.000637699
	LOSS [training: 0.054701744945733946 | validation: 0.12550898428324456]
	TIME [epoch: 12.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07069074790294648		[learning rate: 0.00063544]
	Learning Rate: 0.000635443
	LOSS [training: 0.07069074790294648 | validation: 0.10005610795557905]
	TIME [epoch: 12.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.1064116805662061		[learning rate: 0.0006332]
	Learning Rate: 0.000633196
	LOSS [training: 0.1064116805662061 | validation: 0.12266236653128758]
	TIME [epoch: 12.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.067763464408432		[learning rate: 0.00063096]
	Learning Rate: 0.000630957
	LOSS [training: 0.067763464408432 | validation: 0.07079272742537006]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05924526167345848		[learning rate: 0.00062873]
	Learning Rate: 0.000628726
	LOSS [training: 0.05924526167345848 | validation: 0.10295043275606429]
	TIME [epoch: 12.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.059856319605526294		[learning rate: 0.0006265]
	Learning Rate: 0.000626503
	LOSS [training: 0.059856319605526294 | validation: 0.0995814531947449]
	TIME [epoch: 12.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05788313642127966		[learning rate: 0.00062429]
	Learning Rate: 0.000624287
	LOSS [training: 0.05788313642127966 | validation: 0.08271938698783483]
	TIME [epoch: 12.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06953644377102888		[learning rate: 0.00062208]
	Learning Rate: 0.00062208
	LOSS [training: 0.06953644377102888 | validation: 0.14070666608838442]
	TIME [epoch: 12.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07459429096148719		[learning rate: 0.00061988]
	Learning Rate: 0.00061988
	LOSS [training: 0.07459429096148719 | validation: 0.10805989383909911]
	TIME [epoch: 12.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0910627592573005		[learning rate: 0.00061769]
	Learning Rate: 0.000617688
	LOSS [training: 0.0910627592573005 | validation: 0.1215580558554005]
	TIME [epoch: 12.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0692357944050625		[learning rate: 0.0006155]
	Learning Rate: 0.000615504
	LOSS [training: 0.0692357944050625 | validation: 0.09878830527458005]
	TIME [epoch: 12.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05332301950487559		[learning rate: 0.00061333]
	Learning Rate: 0.000613327
	LOSS [training: 0.05332301950487559 | validation: 0.07695036187622452]
	TIME [epoch: 12.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06404295402949402		[learning rate: 0.00061116]
	Learning Rate: 0.000611158
	LOSS [training: 0.06404295402949402 | validation: 0.12466582166692182]
	TIME [epoch: 12.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06578471564943834		[learning rate: 0.000609]
	Learning Rate: 0.000608997
	LOSS [training: 0.06578471564943834 | validation: 0.07535928704439453]
	TIME [epoch: 12.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06710510315996107		[learning rate: 0.00060684]
	Learning Rate: 0.000606844
	LOSS [training: 0.06710510315996107 | validation: 0.12763690490495128]
	TIME [epoch: 12.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07132429844259744		[learning rate: 0.0006047]
	Learning Rate: 0.000604698
	LOSS [training: 0.07132429844259744 | validation: 0.09160281933118669]
	TIME [epoch: 12.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07396473440617812		[learning rate: 0.00060256]
	Learning Rate: 0.00060256
	LOSS [training: 0.07396473440617812 | validation: 0.1230120582163482]
	TIME [epoch: 12.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06408799672377213		[learning rate: 0.00060043]
	Learning Rate: 0.000600429
	LOSS [training: 0.06408799672377213 | validation: 0.09232335956345451]
	TIME [epoch: 12.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05655062902606737		[learning rate: 0.00059831]
	Learning Rate: 0.000598306
	LOSS [training: 0.05655062902606737 | validation: 0.08886307521565152]
	TIME [epoch: 12.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06544732584132736		[learning rate: 0.00059619]
	Learning Rate: 0.00059619
	LOSS [training: 0.06544732584132736 | validation: 0.10861297162213478]
	TIME [epoch: 12.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06828298648537517		[learning rate: 0.00059408]
	Learning Rate: 0.000594082
	LOSS [training: 0.06828298648537517 | validation: 0.11705674983104589]
	TIME [epoch: 12.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.10479144379967054		[learning rate: 0.00059198]
	Learning Rate: 0.000591981
	LOSS [training: 0.10479144379967054 | validation: 0.13666089953713595]
	TIME [epoch: 12.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06696587796284874		[learning rate: 0.00058989]
	Learning Rate: 0.000589888
	LOSS [training: 0.06696587796284874 | validation: 0.0810734893723402]
	TIME [epoch: 12.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06096489416660563		[learning rate: 0.0005878]
	Learning Rate: 0.000587802
	LOSS [training: 0.06096489416660563 | validation: 0.11076130091488033]
	TIME [epoch: 12.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06796167803283974		[learning rate: 0.00058572]
	Learning Rate: 0.000585723
	LOSS [training: 0.06796167803283974 | validation: 0.09761988478015338]
	TIME [epoch: 12.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07417644632287643		[learning rate: 0.00058365]
	Learning Rate: 0.000583652
	LOSS [training: 0.07417644632287643 | validation: 0.11156238003632096]
	TIME [epoch: 12.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05493462492377162		[learning rate: 0.00058159]
	Learning Rate: 0.000581588
	LOSS [training: 0.05493462492377162 | validation: 0.0875724833253494]
	TIME [epoch: 12.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06009568113899882		[learning rate: 0.00057953]
	Learning Rate: 0.000579531
	LOSS [training: 0.06009568113899882 | validation: 0.08924727454361225]
	TIME [epoch: 12.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0620681701070812		[learning rate: 0.00057748]
	Learning Rate: 0.000577482
	LOSS [training: 0.0620681701070812 | validation: 0.1415069110139706]
	TIME [epoch: 12.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.062001918637255495		[learning rate: 0.00057544]
	Learning Rate: 0.00057544
	LOSS [training: 0.062001918637255495 | validation: 0.08647475603342956]
	TIME [epoch: 12.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05997851488761242		[learning rate: 0.00057341]
	Learning Rate: 0.000573405
	LOSS [training: 0.05997851488761242 | validation: 0.10480710433869743]
	TIME [epoch: 12.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05663652271868224		[learning rate: 0.00057138]
	Learning Rate: 0.000571377
	LOSS [training: 0.05663652271868224 | validation: 0.11186970778853995]
	TIME [epoch: 12.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056949936294836016		[learning rate: 0.00056936]
	Learning Rate: 0.000569357
	LOSS [training: 0.056949936294836016 | validation: 0.08325063478595546]
	TIME [epoch: 12.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05759206880006689		[learning rate: 0.00056734]
	Learning Rate: 0.000567344
	LOSS [training: 0.05759206880006689 | validation: 0.09957595005961449]
	TIME [epoch: 12.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053539050739020926		[learning rate: 0.00056534]
	Learning Rate: 0.000565337
	LOSS [training: 0.053539050739020926 | validation: 0.09222988417625431]
	TIME [epoch: 12.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0549317982876271		[learning rate: 0.00056334]
	Learning Rate: 0.000563338
	LOSS [training: 0.0549317982876271 | validation: 0.105038523708614]
	TIME [epoch: 12.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054901488443747794		[learning rate: 0.00056135]
	Learning Rate: 0.000561346
	LOSS [training: 0.054901488443747794 | validation: 0.0882557820852691]
	TIME [epoch: 12.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0562817712641623		[learning rate: 0.00055936]
	Learning Rate: 0.000559361
	LOSS [training: 0.0562817712641623 | validation: 0.09264071895746334]
	TIME [epoch: 12.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06538754723886385		[learning rate: 0.00055738]
	Learning Rate: 0.000557383
	LOSS [training: 0.06538754723886385 | validation: 0.15890270589798883]
	TIME [epoch: 12.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.09773269071635866		[learning rate: 0.00055541]
	Learning Rate: 0.000555412
	LOSS [training: 0.09773269071635866 | validation: 0.0928021528324092]
	TIME [epoch: 12.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0877532465110998		[learning rate: 0.00055345]
	Learning Rate: 0.000553448
	LOSS [training: 0.0877532465110998 | validation: 0.1251930532478904]
	TIME [epoch: 12.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06556592425116996		[learning rate: 0.00055149]
	Learning Rate: 0.000551491
	LOSS [training: 0.06556592425116996 | validation: 0.09427859633192733]
	TIME [epoch: 12.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05820038252137846		[learning rate: 0.00054954]
	Learning Rate: 0.000549541
	LOSS [training: 0.05820038252137846 | validation: 0.10184557528387012]
	TIME [epoch: 12.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0579565753855222		[learning rate: 0.0005476]
	Learning Rate: 0.000547598
	LOSS [training: 0.0579565753855222 | validation: 0.10028467733962915]
	TIME [epoch: 12.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057536914903391675		[learning rate: 0.00054566]
	Learning Rate: 0.000545661
	LOSS [training: 0.057536914903391675 | validation: 0.08207416823574143]
	TIME [epoch: 12.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05457985053359693		[learning rate: 0.00054373]
	Learning Rate: 0.000543732
	LOSS [training: 0.05457985053359693 | validation: 0.09512600996276624]
	TIME [epoch: 12.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05334059299786882		[learning rate: 0.00054181]
	Learning Rate: 0.000541809
	LOSS [training: 0.05334059299786882 | validation: 0.08349714459030377]
	TIME [epoch: 12.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.058510791292931755		[learning rate: 0.00053989]
	Learning Rate: 0.000539893
	LOSS [training: 0.058510791292931755 | validation: 0.15977571810277647]
	TIME [epoch: 12.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08405870282463142		[learning rate: 0.00053798]
	Learning Rate: 0.000537984
	LOSS [training: 0.08405870282463142 | validation: 0.09753831865096713]
	TIME [epoch: 12.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0883355437643066		[learning rate: 0.00053608]
	Learning Rate: 0.000536081
	LOSS [training: 0.0883355437643066 | validation: 0.1385705379265723]
	TIME [epoch: 12.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0652149975285817		[learning rate: 0.00053419]
	Learning Rate: 0.000534186
	LOSS [training: 0.0652149975285817 | validation: 0.08964366081437063]
	TIME [epoch: 12.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0647627105724512		[learning rate: 0.0005323]
	Learning Rate: 0.000532297
	LOSS [training: 0.0647627105724512 | validation: 0.07914395445355976]
	TIME [epoch: 12.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06465643776779345		[learning rate: 0.00053041]
	Learning Rate: 0.000530415
	LOSS [training: 0.06465643776779345 | validation: 0.13014571216693369]
	TIME [epoch: 12.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0668612193853644		[learning rate: 0.00052854]
	Learning Rate: 0.000528539
	LOSS [training: 0.0668612193853644 | validation: 0.06904809022204139]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_881.pth
	Model improved!!!
EPOCH 882/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05767631595959192		[learning rate: 0.00052667]
	Learning Rate: 0.00052667
	LOSS [training: 0.05767631595959192 | validation: 0.09096799777693272]
	TIME [epoch: 12.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05533841902180454		[learning rate: 0.00052481]
	Learning Rate: 0.000524808
	LOSS [training: 0.05533841902180454 | validation: 0.09932250849487875]
	TIME [epoch: 12.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055044531588692644		[learning rate: 0.00052295]
	Learning Rate: 0.000522952
	LOSS [training: 0.055044531588692644 | validation: 0.07361743739336768]
	TIME [epoch: 12.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.057936040116945725		[learning rate: 0.0005211]
	Learning Rate: 0.000521102
	LOSS [training: 0.057936040116945725 | validation: 0.135819895886373]
	TIME [epoch: 12.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07399402056415158		[learning rate: 0.00051926]
	Learning Rate: 0.00051926
	LOSS [training: 0.07399402056415158 | validation: 0.0807836669362627]
	TIME [epoch: 12.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08426915058181272		[learning rate: 0.00051742]
	Learning Rate: 0.000517423
	LOSS [training: 0.08426915058181272 | validation: 0.10682338637458116]
	TIME [epoch: 12.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056996211702690584		[learning rate: 0.00051559]
	Learning Rate: 0.000515594
	LOSS [training: 0.056996211702690584 | validation: 0.07622844454178723]
	TIME [epoch: 12.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05455888198449797		[learning rate: 0.00051377]
	Learning Rate: 0.000513771
	LOSS [training: 0.05455888198449797 | validation: 0.07113735282214396]
	TIME [epoch: 12.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06251357259441041		[learning rate: 0.00051195]
	Learning Rate: 0.000511954
	LOSS [training: 0.06251357259441041 | validation: 0.1354568932047677]
	TIME [epoch: 12.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07453443947972481		[learning rate: 0.00051014]
	Learning Rate: 0.000510144
	LOSS [training: 0.07453443947972481 | validation: 0.09411093961111015]
	TIME [epoch: 12.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06634906314134005		[learning rate: 0.00050834]
	Learning Rate: 0.000508339
	LOSS [training: 0.06634906314134005 | validation: 0.1282003769989703]
	TIME [epoch: 12.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0728583843692806		[learning rate: 0.00050654]
	Learning Rate: 0.000506542
	LOSS [training: 0.0728583843692806 | validation: 0.07915696485484691]
	TIME [epoch: 12.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0586922523775694		[learning rate: 0.00050475]
	Learning Rate: 0.000504751
	LOSS [training: 0.0586922523775694 | validation: 0.08281911728547461]
	TIME [epoch: 12.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054737999673803266		[learning rate: 0.00050297]
	Learning Rate: 0.000502966
	LOSS [training: 0.054737999673803266 | validation: 0.09766365290183471]
	TIME [epoch: 12.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05517112826480419		[learning rate: 0.00050119]
	Learning Rate: 0.000501187
	LOSS [training: 0.05517112826480419 | validation: 0.08019980048197677]
	TIME [epoch: 12.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054985612088834034		[learning rate: 0.00049941]
	Learning Rate: 0.000499415
	LOSS [training: 0.054985612088834034 | validation: 0.0836717199631826]
	TIME [epoch: 12.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07682027193812258		[learning rate: 0.00049765]
	Learning Rate: 0.000497649
	LOSS [training: 0.07682027193812258 | validation: 0.15568358716767677]
	TIME [epoch: 12.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08886746384292582		[learning rate: 0.00049589]
	Learning Rate: 0.000495889
	LOSS [training: 0.08886746384292582 | validation: 0.09437163340416525]
	TIME [epoch: 12.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07058357410985386		[learning rate: 0.00049414]
	Learning Rate: 0.000494136
	LOSS [training: 0.07058357410985386 | validation: 0.0805214336974221]
	TIME [epoch: 12.8 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052283311564464176		[learning rate: 0.00049239]
	Learning Rate: 0.000492388
	LOSS [training: 0.052283311564464176 | validation: 0.09833210577822188]
	TIME [epoch: 12.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053365262957962845		[learning rate: 0.00049065]
	Learning Rate: 0.000490647
	LOSS [training: 0.053365262957962845 | validation: 0.08405151282278711]
	TIME [epoch: 12.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05905794486750211		[learning rate: 0.00048891]
	Learning Rate: 0.000488912
	LOSS [training: 0.05905794486750211 | validation: 0.10813075704541948]
	TIME [epoch: 12.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.060692467266455566		[learning rate: 0.00048718]
	Learning Rate: 0.000487183
	LOSS [training: 0.060692467266455566 | validation: 0.09100852024779271]
	TIME [epoch: 12.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05991129225544636		[learning rate: 0.00048546]
	Learning Rate: 0.00048546
	LOSS [training: 0.05991129225544636 | validation: 0.11503985950086629]
	TIME [epoch: 12.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05512153373203645		[learning rate: 0.00048374]
	Learning Rate: 0.000483744
	LOSS [training: 0.05512153373203645 | validation: 0.09610465884435711]
	TIME [epoch: 12.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05235987661172953		[learning rate: 0.00048203]
	Learning Rate: 0.000482033
	LOSS [training: 0.05235987661172953 | validation: 0.089902619146446]
	TIME [epoch: 12.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05236790744716917		[learning rate: 0.00048033]
	Learning Rate: 0.000480329
	LOSS [training: 0.05236790744716917 | validation: 0.07115289833579672]
	TIME [epoch: 12.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05857541973983287		[learning rate: 0.00047863]
	Learning Rate: 0.00047863
	LOSS [training: 0.05857541973983287 | validation: 0.09309532304213848]
	TIME [epoch: 12.8 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05313337126536972		[learning rate: 0.00047694]
	Learning Rate: 0.000476938
	LOSS [training: 0.05313337126536972 | validation: 0.090167194226831]
	TIME [epoch: 12.8 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052263318090766536		[learning rate: 0.00047525]
	Learning Rate: 0.000475251
	LOSS [training: 0.052263318090766536 | validation: 0.09518386956543813]
	TIME [epoch: 12.8 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05406174071854049		[learning rate: 0.00047357]
	Learning Rate: 0.00047357
	LOSS [training: 0.05406174071854049 | validation: 0.07339667019153884]
	TIME [epoch: 12.8 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054171038910368834		[learning rate: 0.0004719]
	Learning Rate: 0.000471896
	LOSS [training: 0.054171038910368834 | validation: 0.1087107180281402]
	TIME [epoch: 12.8 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06116730597818471		[learning rate: 0.00047023]
	Learning Rate: 0.000470227
	LOSS [training: 0.06116730597818471 | validation: 0.09234970233464902]
	TIME [epoch: 12.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07265029050606699		[learning rate: 0.00046856]
	Learning Rate: 0.000468564
	LOSS [training: 0.07265029050606699 | validation: 0.11607678267462651]
	TIME [epoch: 12.8 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06932452495246726		[learning rate: 0.00046691]
	Learning Rate: 0.000466907
	LOSS [training: 0.06932452495246726 | validation: 0.09157287693892313]
	TIME [epoch: 12.8 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06159666091941596		[learning rate: 0.00046526]
	Learning Rate: 0.000465256
	LOSS [training: 0.06159666091941596 | validation: 0.09690243020334532]
	TIME [epoch: 12.8 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04991466095523612		[learning rate: 0.00046361]
	Learning Rate: 0.000463611
	LOSS [training: 0.04991466095523612 | validation: 0.09443074661788395]
	TIME [epoch: 12.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05514451106038291		[learning rate: 0.00046197]
	Learning Rate: 0.000461972
	LOSS [training: 0.05514451106038291 | validation: 0.11105805131534603]
	TIME [epoch: 12.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05546883179248574		[learning rate: 0.00046034]
	Learning Rate: 0.000460338
	LOSS [training: 0.05546883179248574 | validation: 0.0835183789841949]
	TIME [epoch: 12.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06152886922400131		[learning rate: 0.00045871]
	Learning Rate: 0.00045871
	LOSS [training: 0.06152886922400131 | validation: 0.15475429913400754]
	TIME [epoch: 12.8 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08820076325107165		[learning rate: 0.00045709]
	Learning Rate: 0.000457088
	LOSS [training: 0.08820076325107165 | validation: 0.08884785520419458]
	TIME [epoch: 12.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08746986873190726		[learning rate: 0.00045547]
	Learning Rate: 0.000455472
	LOSS [training: 0.08746986873190726 | validation: 0.09775659839222933]
	TIME [epoch: 12.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.054343194969195804		[learning rate: 0.00045386]
	Learning Rate: 0.000453861
	LOSS [training: 0.054343194969195804 | validation: 0.1108148339209729]
	TIME [epoch: 12.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06019006460347862		[learning rate: 0.00045226]
	Learning Rate: 0.000452256
	LOSS [training: 0.06019006460347862 | validation: 0.07910550680299802]
	TIME [epoch: 12.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05670801644340533		[learning rate: 0.00045066]
	Learning Rate: 0.000450657
	LOSS [training: 0.05670801644340533 | validation: 0.0940480112006847]
	TIME [epoch: 12.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05432688137007805		[learning rate: 0.00044906]
	Learning Rate: 0.000449063
	LOSS [training: 0.05432688137007805 | validation: 0.1225856101964325]
	TIME [epoch: 12.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06287574624872966		[learning rate: 0.00044748]
	Learning Rate: 0.000447476
	LOSS [training: 0.06287574624872966 | validation: 0.08862279649445207]
	TIME [epoch: 12.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06223596220332498		[learning rate: 0.00044589]
	Learning Rate: 0.000445893
	LOSS [training: 0.06223596220332498 | validation: 0.08960874577937979]
	TIME [epoch: 12.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05560922694322406		[learning rate: 0.00044432]
	Learning Rate: 0.000444316
	LOSS [training: 0.05560922694322406 | validation: 0.0806829285315096]
	TIME [epoch: 12.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05137169927749881		[learning rate: 0.00044275]
	Learning Rate: 0.000442745
	LOSS [training: 0.05137169927749881 | validation: 0.07292033713099906]
	TIME [epoch: 12.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05736777889706946		[learning rate: 0.00044118]
	Learning Rate: 0.00044118
	LOSS [training: 0.05736777889706946 | validation: 0.09758771329832445]
	TIME [epoch: 12.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05291911654727043		[learning rate: 0.00043962]
	Learning Rate: 0.00043962
	LOSS [training: 0.05291911654727043 | validation: 0.08550680142663608]
	TIME [epoch: 12.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06147877296776415		[learning rate: 0.00043806]
	Learning Rate: 0.000438065
	LOSS [training: 0.06147877296776415 | validation: 0.12988653571691575]
	TIME [epoch: 12.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0679094532021684		[learning rate: 0.00043652]
	Learning Rate: 0.000436516
	LOSS [training: 0.0679094532021684 | validation: 0.07523538210509603]
	TIME [epoch: 12.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05157682348270711		[learning rate: 0.00043497]
	Learning Rate: 0.000434972
	LOSS [training: 0.05157682348270711 | validation: 0.08002845782574708]
	TIME [epoch: 12.8 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05287638404416902		[learning rate: 0.00043343]
	Learning Rate: 0.000433434
	LOSS [training: 0.05287638404416902 | validation: 0.10052627097389935]
	TIME [epoch: 12.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049923764381059756		[learning rate: 0.0004319]
	Learning Rate: 0.000431901
	LOSS [training: 0.049923764381059756 | validation: 0.0980259327411867]
	TIME [epoch: 12.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05571003643345266		[learning rate: 0.00043037]
	Learning Rate: 0.000430374
	LOSS [training: 0.05571003643345266 | validation: 0.0729318597133148]
	TIME [epoch: 12.8 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.055081317111582935		[learning rate: 0.00042885]
	Learning Rate: 0.000428852
	LOSS [training: 0.055081317111582935 | validation: 0.1001359160852825]
	TIME [epoch: 12.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05363104711162601		[learning rate: 0.00042734]
	Learning Rate: 0.000427336
	LOSS [training: 0.05363104711162601 | validation: 0.08566640054502211]
	TIME [epoch: 12.8 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051192256083061605		[learning rate: 0.00042582]
	Learning Rate: 0.000425825
	LOSS [training: 0.051192256083061605 | validation: 0.09051113826154372]
	TIME [epoch: 12.8 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05412110141282316		[learning rate: 0.00042432]
	Learning Rate: 0.000424319
	LOSS [training: 0.05412110141282316 | validation: 0.0921531820590552]
	TIME [epoch: 12.9 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.0577176863687362		[learning rate: 0.00042282]
	Learning Rate: 0.000422818
	LOSS [training: 0.0577176863687362 | validation: 0.10621350490388957]
	TIME [epoch: 12.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05458171529563465		[learning rate: 0.00042132]
	Learning Rate: 0.000421323
	LOSS [training: 0.05458171529563465 | validation: 0.0829385717345382]
	TIME [epoch: 12.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.07110218058343906		[learning rate: 0.00041983]
	Learning Rate: 0.000419833
	LOSS [training: 0.07110218058343906 | validation: 0.18265982624643665]
	TIME [epoch: 12.8 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08555685293974474		[learning rate: 0.00041835]
	Learning Rate: 0.000418349
	LOSS [training: 0.08555685293974474 | validation: 0.08040910647580801]
	TIME [epoch: 12.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.056880419264806685		[learning rate: 0.00041687]
	Learning Rate: 0.000416869
	LOSS [training: 0.056880419264806685 | validation: 0.07501620269948739]
	TIME [epoch: 12.8 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.061172525615313326		[learning rate: 0.0004154]
	Learning Rate: 0.000415395
	LOSS [training: 0.061172525615313326 | validation: 0.12228249643266978]
	TIME [epoch: 12.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06138450678653094		[learning rate: 0.00041393]
	Learning Rate: 0.000413926
	LOSS [training: 0.06138450678653094 | validation: 0.08424939201047497]
	TIME [epoch: 12.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05306535077074033		[learning rate: 0.00041246]
	Learning Rate: 0.000412463
	LOSS [training: 0.05306535077074033 | validation: 0.10178607065238038]
	TIME [epoch: 12.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05546320620541719		[learning rate: 0.000411]
	Learning Rate: 0.000411004
	LOSS [training: 0.05546320620541719 | validation: 0.09528841989296158]
	TIME [epoch: 12.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.052571841067367175		[learning rate: 0.00040955]
	Learning Rate: 0.000409551
	LOSS [training: 0.052571841067367175 | validation: 0.08112044731424384]
	TIME [epoch: 12.8 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05654898615458571		[learning rate: 0.0004081]
	Learning Rate: 0.000408102
	LOSS [training: 0.05654898615458571 | validation: 0.12783673665080572]
	TIME [epoch: 12.8 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06304024657208827		[learning rate: 0.00040666]
	Learning Rate: 0.000406659
	LOSS [training: 0.06304024657208827 | validation: 0.08384365209648656]
	TIME [epoch: 12.8 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06371112763433864		[learning rate: 0.00040522]
	Learning Rate: 0.000405221
	LOSS [training: 0.06371112763433864 | validation: 0.09648543197782447]
	TIME [epoch: 12.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.049742737993088516		[learning rate: 0.00040379]
	Learning Rate: 0.000403788
	LOSS [training: 0.049742737993088516 | validation: 0.10704017087053184]
	TIME [epoch: 12.8 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05271977957185028		[learning rate: 0.00040236]
	Learning Rate: 0.000402361
	LOSS [training: 0.05271977957185028 | validation: 0.08486697288467335]
	TIME [epoch: 12.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05406043985873401		[learning rate: 0.00040094]
	Learning Rate: 0.000400938
	LOSS [training: 0.05406043985873401 | validation: 0.08582548532252499]
	TIME [epoch: 12.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05017477373227964		[learning rate: 0.00039952]
	Learning Rate: 0.00039952
	LOSS [training: 0.05017477373227964 | validation: 0.07982386259425896]
	TIME [epoch: 12.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.053638856622958794		[learning rate: 0.00039811]
	Learning Rate: 0.000398107
	LOSS [training: 0.053638856622958794 | validation: 0.09138570428744405]
	TIME [epoch: 12.8 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05300956409069083		[learning rate: 0.0003967]
	Learning Rate: 0.000396699
	LOSS [training: 0.05300956409069083 | validation: 0.07795843303823397]
	TIME [epoch: 12.8 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05231250101411965		[learning rate: 0.0003953]
	Learning Rate: 0.000395297
	LOSS [training: 0.05231250101411965 | validation: 0.07693573254153344]
	TIME [epoch: 12.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05084949714519487		[learning rate: 0.0003939]
	Learning Rate: 0.000393899
	LOSS [training: 0.05084949714519487 | validation: 0.11604070613422608]
	TIME [epoch: 12.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06248433607669841		[learning rate: 0.00039251]
	Learning Rate: 0.000392506
	LOSS [training: 0.06248433607669841 | validation: 0.10842472291636028]
	TIME [epoch: 12.8 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.08422396639863092		[learning rate: 0.00039112]
	Learning Rate: 0.000391118
	LOSS [training: 0.08422396639863092 | validation: 0.08931477069448542]
	TIME [epoch: 12.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05511285962835677		[learning rate: 0.00038973]
	Learning Rate: 0.000389735
	LOSS [training: 0.05511285962835677 | validation: 0.09607147404679162]
	TIME [epoch: 12.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06457988310893908		[learning rate: 0.00038836]
	Learning Rate: 0.000388357
	LOSS [training: 0.06457988310893908 | validation: 0.0941326904193942]
	TIME [epoch: 12.8 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05356336197842114		[learning rate: 0.00038698]
	Learning Rate: 0.000386983
	LOSS [training: 0.05356336197842114 | validation: 0.1031834774656339]
	TIME [epoch: 12.8 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051633020626795985		[learning rate: 0.00038561]
	Learning Rate: 0.000385615
	LOSS [training: 0.051633020626795985 | validation: 0.07363675472097776]
	TIME [epoch: 12.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051851247456328624		[learning rate: 0.00038425]
	Learning Rate: 0.000384251
	LOSS [training: 0.051851247456328624 | validation: 0.12132460153053369]
	TIME [epoch: 12.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05571653635591082		[learning rate: 0.00038289]
	Learning Rate: 0.000382893
	LOSS [training: 0.05571653635591082 | validation: 0.07919493189399626]
	TIME [epoch: 12.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05687518280517514		[learning rate: 0.00038154]
	Learning Rate: 0.000381539
	LOSS [training: 0.05687518280517514 | validation: 0.13594023582637008]
	TIME [epoch: 12.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06854095940083671		[learning rate: 0.00038019]
	Learning Rate: 0.000380189
	LOSS [training: 0.06854095940083671 | validation: 0.07478830710002476]
	TIME [epoch: 12.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.06373550483067607		[learning rate: 0.00037885]
	Learning Rate: 0.000378845
	LOSS [training: 0.06373550483067607 | validation: 0.11161534147910022]
	TIME [epoch: 12.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05300772313324276		[learning rate: 0.00037751]
	Learning Rate: 0.000377505
	LOSS [training: 0.05300772313324276 | validation: 0.0760903438681731]
	TIME [epoch: 12.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05192388164477102		[learning rate: 0.00037617]
	Learning Rate: 0.00037617
	LOSS [training: 0.05192388164477102 | validation: 0.09352573182817389]
	TIME [epoch: 12.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.051302327480541726		[learning rate: 0.00037484]
	Learning Rate: 0.00037484
	LOSS [training: 0.051302327480541726 | validation: 0.0842000011614928]
	TIME [epoch: 12.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.04941984071646565		[learning rate: 0.00037351]
	Learning Rate: 0.000373515
	LOSS [training: 0.04941984071646565 | validation: 0.08680624389404418]
	TIME [epoch: 12.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05286812907227223		[learning rate: 0.00037219]
	Learning Rate: 0.000372194
	LOSS [training: 0.05286812907227223 | validation: 0.07556193096740665]
	TIME [epoch: 12.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05608758277439378		[learning rate: 0.00037088]
	Learning Rate: 0.000370878
	LOSS [training: 0.05608758277439378 | validation: 0.08677307887329988]
	TIME [epoch: 12.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 1/1] avg loss: 0.05153912281904995		[learning rate: 0.00036957]
	Learning Rate: 0.000369566
	LOSS [training: 0.05153912281904995 | validation: 0.09145947739766698]
	TIME [epoch: 12.9 sec]
	Saving model to: out/model_training/model_phi1_3c_v_mmd1_20241105_151109/states/model_phi1_3c_v_mmd1_982.pth
Halted early. No improvement in validation loss for 100 epochs.
Finished training in 9513.483 seconds.
