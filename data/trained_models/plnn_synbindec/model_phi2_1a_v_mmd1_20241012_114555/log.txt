Args:
Namespace(name='model_phi2_1a_v_mmd1', outdir='out/model_training/model_phi2_1a_v_mmd1', training_data='data/training_data/basic/data_phi2_1a/training', validation_data='data/training_data/basic/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3364728711

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.633520811746425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.633520811746425 | validation: 2.9526161560198076]
	TIME [epoch: 112 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.095697699447989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.095697699447989 | validation: 2.076213157489447]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2688528459344277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2688528459344277 | validation: 1.6272745725890334]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.588180895773808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.588180895773808 | validation: 0.995326353540008]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3565567720568132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3565567720568132 | validation: 0.8018712241824035]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3192236175174445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3192236175174445 | validation: 2.3972938897251055]
	TIME [epoch: 13 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3041749399037523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3041749399037523 | validation: 0.808303539202297]
	TIME [epoch: 13 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1760678717587718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1760678717587718 | validation: 0.515444619003305]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9511291977153079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9511291977153079 | validation: 1.0672401384156625]
	TIME [epoch: 13.1 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7188073170515636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7188073170515636 | validation: 0.6199579148037503]
	TIME [epoch: 13.1 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8486515958245959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8486515958245959 | validation: 0.8030471394530223]
	TIME [epoch: 13 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7846543625774117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7846543625774117 | validation: 0.8247035467228739]
	TIME [epoch: 13.1 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7392058045112224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7392058045112224 | validation: 0.5293218266314279]
	TIME [epoch: 13.1 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994298495947766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5994298495947766 | validation: 0.5401145823081803]
	TIME [epoch: 13 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6083826423282092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6083826423282092 | validation: 0.48898701610016304]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5641339615169081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5641339615169081 | validation: 0.3989440367469053]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535509779984898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.535509779984898 | validation: 0.3657072845412731]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938843309511002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4938843309511002 | validation: 0.34065400963589]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49519789637795253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49519789637795253 | validation: 0.9088550244772917]
	TIME [epoch: 13.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7124980039205019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7124980039205019 | validation: 0.45564890900676236]
	TIME [epoch: 13.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033307797285123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5033307797285123 | validation: 0.3472422727015245]
	TIME [epoch: 13.1 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43017886841099684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43017886841099684 | validation: 0.31889268619161115]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40354362072880645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40354362072880645 | validation: 0.2676111784135803]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40288473513746986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40288473513746986 | validation: 0.2759988099062435]
	TIME [epoch: 13.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4681267288981642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4681267288981642 | validation: 0.3199083072403759]
	TIME [epoch: 13.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42472411678211464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42472411678211464 | validation: 0.29228789570140906]
	TIME [epoch: 13 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523024505854716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.523024505854716 | validation: 0.31540721468624894]
	TIME [epoch: 13.1 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37410090941161955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37410090941161955 | validation: 0.2585801373891856]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3643174010575208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3643174010575208 | validation: 0.22631113279040904]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3448956656312709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3448956656312709 | validation: 0.22351881836397025]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39994062326601276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39994062326601276 | validation: 0.21581692680115797]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3577802719695029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3577802719695029 | validation: 0.24783613064097976]
	TIME [epoch: 13 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544682819335759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3544682819335759 | validation: 0.2035524689623239]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3626827383742949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3626827383742949 | validation: 0.27119216087261633]
	TIME [epoch: 13.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37895138413441715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37895138413441715 | validation: 0.26265022506869806]
	TIME [epoch: 13.1 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35225712476311255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.35225712476311255 | validation: 0.19886737719131786]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3730996489417693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3730996489417693 | validation: 0.27236549925579584]
	TIME [epoch: 13 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343819282369466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3343819282369466 | validation: 0.21033410396125418]
	TIME [epoch: 13.1 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3380582938919375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3380582938919375 | validation: 0.1944669152512044]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31394768524006744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31394768524006744 | validation: 0.18582542906973346]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3184826472722524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3184826472722524 | validation: 0.22303534352192628]
	TIME [epoch: 13 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3547638743884605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3547638743884605 | validation: 0.2074999936483976]
	TIME [epoch: 13.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.312302657738642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.312302657738642 | validation: 0.41039958087227035]
	TIME [epoch: 13 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40214600769396014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.40214600769396014 | validation: 0.25233488607405097]
	TIME [epoch: 13 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369542275331371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3369542275331371 | validation: 0.41293626523411364]
	TIME [epoch: 13 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197167635332409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5197167635332409 | validation: 0.4423648441422675]
	TIME [epoch: 13.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5104192514694882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5104192514694882 | validation: 0.4158308642495756]
	TIME [epoch: 13 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4830076597957859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4830076597957859 | validation: 0.24450262636419567]
	TIME [epoch: 13 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4112323711386454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4112323711386454 | validation: 0.331954982906484]
	TIME [epoch: 13 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4011129953115531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4011129953115531 | validation: 0.2236125559168897]
	TIME [epoch: 13.1 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31377478101137446		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.31377478101137446 | validation: 0.1894350636227833]
	TIME [epoch: 13 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236131283746495		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.5236131283746495 | validation: 0.43973330715239534]
	TIME [epoch: 13 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514279518404085		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.514279518404085 | validation: 0.4374888682029714]
	TIME [epoch: 13 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986369800191374		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.4986369800191374 | validation: 0.42365045733150575]
	TIME [epoch: 13.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4958284739368677		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.4958284739368677 | validation: 0.4221463094499973]
	TIME [epoch: 13 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47808159801184197		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.47808159801184197 | validation: 0.39686364650436534]
	TIME [epoch: 13 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47359317091813663		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.47359317091813663 | validation: 0.267572743708855]
	TIME [epoch: 13 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39619668836112176		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.39619668836112176 | validation: 0.22593039818171876]
	TIME [epoch: 13.1 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32870832287786184		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.32870832287786184 | validation: 0.2776108506529915]
	TIME [epoch: 13 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33974447834529037		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.33974447834529037 | validation: 0.1929502421110334]
	TIME [epoch: 13 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29394346665257043		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.29394346665257043 | validation: 0.18434147734856315]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30545727052384103		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.30545727052384103 | validation: 0.21064291129960996]
	TIME [epoch: 13 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30761862355306857		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.30761862355306857 | validation: 0.2029347188652341]
	TIME [epoch: 13 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3230181213727206		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.3230181213727206 | validation: 0.24131382768329884]
	TIME [epoch: 13 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3723981275585097		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.3723981275585097 | validation: 0.25264665536320063]
	TIME [epoch: 13.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300056928668757		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.300056928668757 | validation: 0.3165318959436061]
	TIME [epoch: 13 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3485718934039809		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.3485718934039809 | validation: 0.22246875595335452]
	TIME [epoch: 13 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29605747690685075		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.29605747690685075 | validation: 0.18174757745086678]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26291446679218866		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.26291446679218866 | validation: 0.19182347817348733]
	TIME [epoch: 13.1 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31121145853303267		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.31121145853303267 | validation: 0.1958202319839021]
	TIME [epoch: 13 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24549187076035972		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.24549187076035972 | validation: 0.161729291099929]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020908652557716		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.2020908652557716 | validation: 0.13198825620677013]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19513365686123535		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.19513365686123535 | validation: 0.13096829187448755]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1729138634062477		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.1729138634062477 | validation: 0.11935434456430062]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17182806788793994		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.17182806788793994 | validation: 0.15580093862981997]
	TIME [epoch: 13 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.194648215222845		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.194648215222845 | validation: 0.16112573613004966]
	TIME [epoch: 13 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1763371825286214		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.1763371825286214 | validation: 0.1524655433736664]
	TIME [epoch: 13 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18683961066590107		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.18683961066590107 | validation: 0.18376023718572354]
	TIME [epoch: 13 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19483807233409356		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.19483807233409356 | validation: 0.19822703483052911]
	TIME [epoch: 13 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16140679669715732		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.16140679669715732 | validation: 0.10618470119421328]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20594470424767775		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.20594470424767775 | validation: 0.14135917493354755]
	TIME [epoch: 13 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842509623828275		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.1842509623828275 | validation: 0.1892615658719957]
	TIME [epoch: 13 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15287744349315283		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.15287744349315283 | validation: 0.18745369549417762]
	TIME [epoch: 13 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13623813939141294		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.13623813939141294 | validation: 0.14442229243562835]
	TIME [epoch: 13.1 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16206161612748754		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.16206161612748754 | validation: 0.11893730805198954]
	TIME [epoch: 13 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033239687071143		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.11033239687071143 | validation: 0.1451773583766995]
	TIME [epoch: 13 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1577553379101304		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.1577553379101304 | validation: 0.14979470352469615]
	TIME [epoch: 13 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10512350767106865		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.10512350767106865 | validation: 0.10509736125394081]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14718964832987713		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.14718964832987713 | validation: 0.1301563931099401]
	TIME [epoch: 13.1 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14217249887156952		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.14217249887156952 | validation: 0.08502508831518157]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10717039889022556		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.10717039889022556 | validation: 0.18060102165845765]
	TIME [epoch: 13 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11926253822335985		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.11926253822335985 | validation: 0.06659417612774175]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09774347488375208		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.09774347488375208 | validation: 0.09708244063689847]
	TIME [epoch: 13.1 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10192031332108989		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.10192031332108989 | validation: 0.2499516570273449]
	TIME [epoch: 13 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1450518497691212		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.1450518497691212 | validation: 0.12889968960160497]
	TIME [epoch: 13.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12765683428645216		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.12765683428645216 | validation: 0.07943480622644629]
	TIME [epoch: 13.1 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10108081301037489		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.10108081301037489 | validation: 0.08138476281348199]
	TIME [epoch: 13 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11869871635211235		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.11869871635211235 | validation: 0.06014132603548124]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09515193762717242		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.09515193762717242 | validation: 0.09653353236935341]
	TIME [epoch: 13.1 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12138362849179601		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.12138362849179601 | validation: 0.06832866955187057]
	TIME [epoch: 13 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09374387808052559		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.09374387808052559 | validation: 0.11029669618989685]
	TIME [epoch: 13 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924987467837052		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.08924987467837052 | validation: 0.049327654910945526]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06928928737736131		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.06928928737736131 | validation: 0.09164011714466798]
	TIME [epoch: 13.1 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13410672243927746		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.13410672243927746 | validation: 0.06293974301826802]
	TIME [epoch: 13 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962154128268512		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.07962154128268512 | validation: 0.08878083559877341]
	TIME [epoch: 13 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07071761068328458		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.07071761068328458 | validation: 0.12660832985628745]
	TIME [epoch: 13 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19778096633632086		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.19778096633632086 | validation: 0.06544982018905081]
	TIME [epoch: 13.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08295349669731786		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.08295349669731786 | validation: 0.05643945173902711]
	TIME [epoch: 13 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058128930951674714		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.058128930951674714 | validation: 0.04155408409440965]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806041839048191		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.13806041839048191 | validation: 0.24377075430085104]
	TIME [epoch: 13.1 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13521355478789457		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.13521355478789457 | validation: 0.07356825901360968]
	TIME [epoch: 13.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801174798749317		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.05801174798749317 | validation: 0.06125357021250717]
	TIME [epoch: 13 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0856078573286814		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.0856078573286814 | validation: 0.055199134166397844]
	TIME [epoch: 13 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07688954302027487		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.07688954302027487 | validation: 0.1174570203947418]
	TIME [epoch: 13.1 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17793700371635654		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.17793700371635654 | validation: 0.09760087861516158]
	TIME [epoch: 13.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08716914553935426		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.08716914553935426 | validation: 0.050623535597906125]
	TIME [epoch: 13 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062017494717090005		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.062017494717090005 | validation: 0.07944701406011531]
	TIME [epoch: 13 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07592647792833278		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.07592647792833278 | validation: 0.1090813296291146]
	TIME [epoch: 13.1 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06453872483178998		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.06453872483178998 | validation: 0.05719570327705641]
	TIME [epoch: 13 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181033371271199		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.1181033371271199 | validation: 0.22717684310614666]
	TIME [epoch: 13.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12957357499235198		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.12957357499235198 | validation: 0.05340934883747869]
	TIME [epoch: 13 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05215306620954434		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.05215306620954434 | validation: 0.05350054413808525]
	TIME [epoch: 13.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06093834813748143		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.06093834813748143 | validation: 0.051087642719612816]
	TIME [epoch: 13 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05605446453706732		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.05605446453706732 | validation: 0.07970181783410255]
	TIME [epoch: 13 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09384588800711634		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.09384588800711634 | validation: 0.05611452291469632]
	TIME [epoch: 13 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058466448595668116		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.058466448595668116 | validation: 0.03942567646901967]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041890017196429735		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.041890017196429735 | validation: 0.03190819777492522]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07312227591658878		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.07312227591658878 | validation: 0.09616283862100011]
	TIME [epoch: 13 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06499604217251459		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.06499604217251459 | validation: 0.04449627494443188]
	TIME [epoch: 13.1 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07182214565120298		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.07182214565120298 | validation: 0.04413608410377176]
	TIME [epoch: 13.1 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05518631383108932		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.05518631383108932 | validation: 0.05758316141780636]
	TIME [epoch: 13 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055252580261164405		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.055252580261164405 | validation: 0.042785758288264614]
	TIME [epoch: 13 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641695284801341		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.06641695284801341 | validation: 0.02919237964443576]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03467652328408292		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.03467652328408292 | validation: 0.03929569010614699]
	TIME [epoch: 13.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07792894301350427		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.07792894301350427 | validation: 0.05188370146985195]
	TIME [epoch: 13.1 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06018258332970871		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.06018258332970871 | validation: 0.04114681630119114]
	TIME [epoch: 13 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04187283796350694		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.04187283796350694 | validation: 0.02976008069712901]
	TIME [epoch: 13.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774700893124178		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.0774700893124178 | validation: 0.047169612329955674]
	TIME [epoch: 13.1 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06320318511155262		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.06320318511155262 | validation: 0.06426894082304897]
	TIME [epoch: 13.1 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05999847968297276		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.05999847968297276 | validation: 0.03318380897933177]
	TIME [epoch: 13 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583611852367571		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.06583611852367571 | validation: 0.03574810973394218]
	TIME [epoch: 13.1 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445106784434969		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.04445106784434969 | validation: 0.033111566892432914]
	TIME [epoch: 13.1 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158329799287398		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.05158329799287398 | validation: 0.04775596984123366]
	TIME [epoch: 13 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0507708012318293		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.0507708012318293 | validation: 0.0482596339796645]
	TIME [epoch: 13.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049662985803657536		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.049662985803657536 | validation: 0.07405376538169167]
	TIME [epoch: 13.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865961975996496		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.06865961975996496 | validation: 0.03677365819657655]
	TIME [epoch: 13.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0376933602319539		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.0376933602319539 | validation: 0.03240106532849425]
	TIME [epoch: 13 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03803111400904668		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.03803111400904668 | validation: 0.06655544079773493]
	TIME [epoch: 13.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05918586872819456		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.05918586872819456 | validation: 0.050396142245055696]
	TIME [epoch: 13.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04011877244783474		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.04011877244783474 | validation: 0.05894725863343693]
	TIME [epoch: 13 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359730939001608		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.06359730939001608 | validation: 0.03710161135055097]
	TIME [epoch: 13 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05099487418260867		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.05099487418260867 | validation: 0.037459846150274485]
	TIME [epoch: 13.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534354997729936		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.04534354997729936 | validation: 0.035015651792981634]
	TIME [epoch: 13.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04801712578665824		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.04801712578665824 | validation: 0.022136113705589495]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038876092046305384		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.038876092046305384 | validation: 0.024575229930437544]
	TIME [epoch: 13.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049509389988886		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.049509389988886 | validation: 0.02585238079128567]
	TIME [epoch: 13.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04265012834939382		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.04265012834939382 | validation: 0.05572234977932853]
	TIME [epoch: 13.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049225072428231056		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.049225072428231056 | validation: 0.030141303808898463]
	TIME [epoch: 13 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03501913379477814		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.03501913379477814 | validation: 0.024913221927430198]
	TIME [epoch: 13 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043521383713117416		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.043521383713117416 | validation: 0.04393210569690317]
	TIME [epoch: 13.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549186893782536		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.04549186893782536 | validation: 0.017554077522133667]
	TIME [epoch: 13 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028392235303708456		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.028392235303708456 | validation: 0.0993128317561249]
	TIME [epoch: 13 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06681770915949461		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.06681770915949461 | validation: 0.02190037778670481]
	TIME [epoch: 13 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02622859504320153		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.02622859504320153 | validation: 0.05504974184361062]
	TIME [epoch: 13.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054559081479189295		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.054559081479189295 | validation: 0.020460201615897823]
	TIME [epoch: 13 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037188136655497826		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.037188136655497826 | validation: 0.0315701662513688]
	TIME [epoch: 13 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042940844824520506		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.042940844824520506 | validation: 0.015290304546151552]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018955315013714495		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.018955315013714495 | validation: 0.0361725851089124]
	TIME [epoch: 13.1 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07632710662046246		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.07632710662046246 | validation: 0.0238220038145387]
	TIME [epoch: 13 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03907453182825469		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.03907453182825469 | validation: 0.036778324823771316]
	TIME [epoch: 13.1 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03742383574562689		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.03742383574562689 | validation: 0.015365251100321761]
	TIME [epoch: 13.1 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03547689875400132		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.03547689875400132 | validation: 0.025617399829231655]
	TIME [epoch: 13.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027627953092796753		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.027627953092796753 | validation: 0.0259255849446721]
	TIME [epoch: 13 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07116582712455302		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.07116582712455302 | validation: 0.04255498768742676]
	TIME [epoch: 13 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04159790832254312		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.04159790832254312 | validation: 0.022023224063428812]
	TIME [epoch: 13.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02504208722899745		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.02504208722899745 | validation: 0.028895492264874374]
	TIME [epoch: 13 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0565071427353858		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.0565071427353858 | validation: 0.02234785637491774]
	TIME [epoch: 13 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024680418207654157		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.024680418207654157 | validation: 0.01416925060713316]
	TIME [epoch: 13.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014556273768230177		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.014556273768230177 | validation: 0.017497632722766693]
	TIME [epoch: 13.1 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207525664021492		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.05207525664021492 | validation: 0.016587220086403173]
	TIME [epoch: 13 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052008252933322535		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.052008252933322535 | validation: 0.03947200823030128]
	TIME [epoch: 13 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023140406057875897		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.023140406057875897 | validation: 0.019167818546669765]
	TIME [epoch: 13.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968283372663112		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.03968283372663112 | validation: 0.018533819763176758]
	TIME [epoch: 13.1 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03608329154139529		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.03608329154139529 | validation: 0.025317893765498395]
	TIME [epoch: 13.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043037453829346345		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.043037453829346345 | validation: 0.018136046460884597]
	TIME [epoch: 13 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02189888768143963		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.02189888768143963 | validation: 0.018196170337645704]
	TIME [epoch: 13.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05471910031678511		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.05471910031678511 | validation: 0.02411160606598428]
	TIME [epoch: 13.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025875514874662893		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.025875514874662893 | validation: 0.015186932635032107]
	TIME [epoch: 13 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03239794839827533		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.03239794839827533 | validation: 0.015286074716144451]
	TIME [epoch: 13 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02382894531616985		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.02382894531616985 | validation: 0.06864063400267753]
	TIME [epoch: 13.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02882589262365133		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.02882589262365133 | validation: 0.01692412165836814]
	TIME [epoch: 13.1 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054072601576382835		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.054072601576382835 | validation: 0.023449176173327528]
	TIME [epoch: 13 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030606278309320417		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.030606278309320417 | validation: 0.025898209200768837]
	TIME [epoch: 13 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023242548145537077		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.023242548145537077 | validation: 0.05431514948586013]
	TIME [epoch: 13.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045005692339557694		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.045005692339557694 | validation: 0.026277764336328408]
	TIME [epoch: 13 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027451679848948148		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.027451679848948148 | validation: 0.02017904279341768]
	TIME [epoch: 13 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02699718286203715		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.02699718286203715 | validation: 0.1270242661023391]
	TIME [epoch: 13 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06279216671540346		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.06279216671540346 | validation: 0.022960251497860268]
	TIME [epoch: 13.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021139550326069328		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.021139550326069328 | validation: 0.02577498534451727]
	TIME [epoch: 13 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289905300014895		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.03289905300014895 | validation: 0.05010255639739164]
	TIME [epoch: 13 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040691861236122846		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.040691861236122846 | validation: 0.02095060381209122]
	TIME [epoch: 122 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026949301595590277		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.026949301595590277 | validation: 0.0345147677767007]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018488341820981694		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.018488341820981694 | validation: 0.012523870791689576]
	TIME [epoch: 25.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04539736841532213		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.04539736841532213 | validation: 0.01496598285304096]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018141439472393044		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.018141439472393044 | validation: 0.03744644271365496]
	TIME [epoch: 25.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02952543463258871		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.02952543463258871 | validation: 0.015965329174756106]
	TIME [epoch: 25 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028567716976576063		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.028567716976576063 | validation: 0.03065744196953117]
	TIME [epoch: 25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03553353241304305		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.03553353241304305 | validation: 0.030117199513145718]
	TIME [epoch: 24.9 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041916086608527824		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.041916086608527824 | validation: 0.018003513560021278]
	TIME [epoch: 25.1 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01712077972747863		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.01712077972747863 | validation: 0.013808355899587031]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03321844835007591		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.03321844835007591 | validation: 0.031787195374501226]
	TIME [epoch: 25 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01772262799837055		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.01772262799837055 | validation: 0.016358960214316737]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017113741339854417		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.017113741339854417 | validation: 0.023217256261278962]
	TIME [epoch: 25 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04565602299300556		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.04565602299300556 | validation: 0.04626019229989986]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02323254007405451		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.02323254007405451 | validation: 0.012674322799836175]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026440402246683363		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.026440402246683363 | validation: 0.022548383386677754]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023281080278900843		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.023281080278900843 | validation: 0.013060735148632074]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019952951790361585		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.019952951790361585 | validation: 0.028587459951467598]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020297635945567646		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.020297635945567646 | validation: 0.019585836654001022]
	TIME [epoch: 25.1 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779888142977769		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.03779888142977769 | validation: 0.01265931564631638]
	TIME [epoch: 25 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017000239739347917		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.017000239739347917 | validation: 0.01906261702501777]
	TIME [epoch: 25.1 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022722014244331304		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.022722014244331304 | validation: 0.023337349251013467]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028935475528325094		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.028935475528325094 | validation: 0.03535946399350813]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02188467783694139		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.02188467783694139 | validation: 0.013325436771352686]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013858913013021952		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.013858913013021952 | validation: 0.025657640402792108]
	TIME [epoch: 25.1 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03155259735618142		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.03155259735618142 | validation: 0.036022080749459874]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03642442448336561		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.03642442448336561 | validation: 0.011470469250565624]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01805977933240934		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.01805977933240934 | validation: 0.02154366326915086]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01696971797707108		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.01696971797707108 | validation: 0.041004960651321136]
	TIME [epoch: 25.1 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030527481779671746		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.030527481779671746 | validation: 0.059811493928722426]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040854099967411274		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.040854099967411274 | validation: 0.014339135924640062]
	TIME [epoch: 25.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0179487536402011		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.0179487536402011 | validation: 0.03179828335755045]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01718091020761672		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.01718091020761672 | validation: 0.013751728781172756]
	TIME [epoch: 25.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03429634764469367		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.03429634764469367 | validation: 0.01950140530348292]
	TIME [epoch: 25 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016627780247348466		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.016627780247348466 | validation: 0.010115684107700217]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_235.pth
	Model improved!!!
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01632665218102415		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.01632665218102415 | validation: 0.03267452460094382]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03880781579084462		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.03880781579084462 | validation: 0.040529520075023015]
	TIME [epoch: 25 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02525916637639237		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.02525916637639237 | validation: 0.013803971080168747]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011896061769498801		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.011896061769498801 | validation: 0.024479008087714194]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03886667717271376		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.03886667717271376 | validation: 0.01709066154793403]
	TIME [epoch: 25 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020688091356144186		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.020688091356144186 | validation: 0.010043857314957053]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011596325318867678		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.011596325318867678 | validation: 0.010017421000779398]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_242.pth
	Model improved!!!
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0248518539642626		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.0248518539642626 | validation: 0.04521679191619605]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03310226069182923		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.03310226069182923 | validation: 0.021565653931973433]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014332251761924372		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.014332251761924372 | validation: 0.011676024164393641]
	TIME [epoch: 25.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010266144927374828		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.010266144927374828 | validation: 0.01040931555917732]
	TIME [epoch: 25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02551154073969963		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.02551154073969963 | validation: 0.029098075297963145]
	TIME [epoch: 25.1 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029884848832536257		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.029884848832536257 | validation: 0.013228787105285026]
	TIME [epoch: 25.1 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02108934676458108		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.02108934676458108 | validation: 0.042528461860239605]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028626822886433624		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.028626822886433624 | validation: 0.008607802425270306]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010027467023418854		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.010027467023418854 | validation: 0.011292192561038604]
	TIME [epoch: 25.1 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01828274434293317		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.01828274434293317 | validation: 0.01232484469549263]
	TIME [epoch: 25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025867954465214782		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.025867954465214782 | validation: 0.03228131032846602]
	TIME [epoch: 25 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01882676598937665		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.01882676598937665 | validation: 0.020521668774240283]
	TIME [epoch: 25 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02602656966732033		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.02602656966732033 | validation: 0.013445426682604227]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014512565867130024		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.014512565867130024 | validation: 0.01801031358733576]
	TIME [epoch: 25 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018131127362523994		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.018131127362523994 | validation: 0.0716839431222576]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05466209134628673		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.05466209134628673 | validation: 0.018132233048367898]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024317091342601		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.024317091342601 | validation: 0.012652967023289906]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01059063835712187		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.01059063835712187 | validation: 0.017935729610156687]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02382842959851834		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.02382842959851834 | validation: 0.01819591677668777]
	TIME [epoch: 25.1 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01378516071502419		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.01378516071502419 | validation: 0.011130714385981098]
	TIME [epoch: 25 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014568535414530428		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.014568535414530428 | validation: 0.02034640198931157]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015233040311014575		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.015233040311014575 | validation: 0.018434563482534912]
	TIME [epoch: 25.1 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021195017186347077		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.021195017186347077 | validation: 0.04723384403251368]
	TIME [epoch: 25 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02022781109151324		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.02022781109151324 | validation: 0.014921019361618066]
	TIME [epoch: 25.1 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027644541308290464		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.027644541308290464 | validation: 0.031817979213108964]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015567007175529017		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.015567007175529017 | validation: 0.007738237606401821]
	TIME [epoch: 25.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009612431132516473		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.009612431132516473 | validation: 0.012607157543795544]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019715959192063877		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.019715959192063877 | validation: 0.023412888964908698]
	TIME [epoch: 25.1 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391187932194812		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.03391187932194812 | validation: 0.012930040749135195]
	TIME [epoch: 25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010496755460695981		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.010496755460695981 | validation: 0.01635134304374693]
	TIME [epoch: 25.1 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012392620626035288		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.012392620626035288 | validation: 0.025627550068555657]
	TIME [epoch: 25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02020023353093765		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.02020023353093765 | validation: 0.00880180405458246]
	TIME [epoch: 25.1 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008868092017702812		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.008868092017702812 | validation: 0.012908322966677824]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01961113238669902		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.01961113238669902 | validation: 0.0392706078253128]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027635947380913177		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.027635947380913177 | validation: 0.02703030347309226]
	TIME [epoch: 25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019486261806263238		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.019486261806263238 | validation: 0.009240520010757236]
	TIME [epoch: 25.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011761543681503752		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.011761543681503752 | validation: 0.022474860156049357]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031757647760419415		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.031757647760419415 | validation: 0.016947553298997352]
	TIME [epoch: 25.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01050783791882047		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.01050783791882047 | validation: 0.012210337935250823]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012443000215936733		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.012443000215936733 | validation: 0.026249213867486496]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016033055983969768		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.016033055983969768 | validation: 0.01110072496800896]
	TIME [epoch: 25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019088579668394935		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.019088579668394935 | validation: 0.013709599303891259]
	TIME [epoch: 25.1 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023768117379917818		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.023768117379917818 | validation: 0.01525560729085619]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014671488850641259		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.014671488850641259 | validation: 0.007646698371713915]
	TIME [epoch: 25.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009106186144054458		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.009106186144054458 | validation: 0.009061762233915246]
	TIME [epoch: 25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022986267809205926		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.022986267809205926 | validation: 0.025486927205159972]
	TIME [epoch: 25.1 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013312351064099023		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.013312351064099023 | validation: 0.007942520309798988]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074794027580369175		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.0074794027580369175 | validation: 0.00917616623255721]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019819446095456442		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.019819446095456442 | validation: 0.012410114467502278]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434414501003559		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.02434414501003559 | validation: 0.016067878615483883]
	TIME [epoch: 25.1 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016366525381717033		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.016366525381717033 | validation: 0.007985952947978684]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00907425240424786		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.00907425240424786 | validation: 0.01400846507227069]
	TIME [epoch: 25.1 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0170033607071936		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.0170033607071936 | validation: 0.017355333931239187]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01383486214719558		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.01383486214719558 | validation: 0.02391374995823258]
	TIME [epoch: 25.1 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020075132414773985		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.020075132414773985 | validation: 0.009254739812958353]
	TIME [epoch: 25 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01070284474341359		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.01070284474341359 | validation: 0.013497790262170076]
	TIME [epoch: 25.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01713268253587175		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.01713268253587175 | validation: 0.009131847642226184]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015920207272279826		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.015920207272279826 | validation: 0.01091133585382587]
	TIME [epoch: 25.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010071277824011245		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.010071277824011245 | validation: 0.04970811378278503]
	TIME [epoch: 25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022015672390362003		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.022015672390362003 | validation: 0.008862506974065076]
	TIME [epoch: 25.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009592013689276079		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.009592013689276079 | validation: 0.007037624574807476]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_303.pth
	Model improved!!!
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022405569529798386		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.022405569529798386 | validation: 0.018068375945431318]
	TIME [epoch: 25.1 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02083303875008656		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.02083303875008656 | validation: 0.013509055560332413]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010270189205794592		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.010270189205794592 | validation: 0.006887652560954707]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011216587164832467		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.011216587164832467 | validation: 0.026871262788364457]
	TIME [epoch: 25 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024558129429783724		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.024558129429783724 | validation: 0.014410721399699022]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007682479706496912		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.007682479706496912 | validation: 0.007012082203646698]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009275785892107261		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.009275785892107261 | validation: 0.023439805188167205]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01429348499403305		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.01429348499403305 | validation: 0.009853034841577755]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02570492828784235		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.02570492828784235 | validation: 0.01176508151719036]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00827615526671516		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.00827615526671516 | validation: 0.0073231111070989445]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007955925063005909		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.007955925063005909 | validation: 0.008365316035354857]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017234609347894614		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.017234609347894614 | validation: 0.01942082678735458]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010294947185745477		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.010294947185745477 | validation: 0.022082029495384334]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021306232118588054		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.021306232118588054 | validation: 0.00896686787794216]
	TIME [epoch: 25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00881068121501555		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.00881068121501555 | validation: 0.009052454258000078]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015568104658324788		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.015568104658324788 | validation: 0.006338964198901032]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_319.pth
	Model improved!!!
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007275631633119247		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.007275631633119247 | validation: 0.005651238129804676]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_320.pth
	Model improved!!!
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01737038297373486		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.01737038297373486 | validation: 0.018404191580081258]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010938257388020465		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.010938257388020465 | validation: 0.009635365514409888]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007890020037348178		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.007890020037348178 | validation: 0.021087053480936896]
	TIME [epoch: 25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012187749885533198		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.012187749885533198 | validation: 0.009505775905165426]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013328727183552047		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.013328727183552047 | validation: 0.010021257273552832]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015489901143174757		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.015489901143174757 | validation: 0.010740561644359676]
	TIME [epoch: 25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010562713343714726		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.010562713343714726 | validation: 0.015904976854140114]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012023838600442503		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.012023838600442503 | validation: 0.016896745221356584]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017108010616427485		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.017108010616427485 | validation: 0.006668337539718966]
	TIME [epoch: 25 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009808948942675103		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.009808948942675103 | validation: 0.01893881274003837]
	TIME [epoch: 25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017378882684589394		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.017378882684589394 | validation: 0.010458238566997811]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00820482903005026		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.00820482903005026 | validation: 0.016506020992127148]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012692387605558847		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.012692387605558847 | validation: 0.008995020456776028]
	TIME [epoch: 25.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0065991189565570455		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.0065991189565570455 | validation: 0.005748004294493835]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01465025988641424		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.01465025988641424 | validation: 0.012399259551245937]
	TIME [epoch: 25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008631724752208761		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.008631724752208761 | validation: 0.00825926660433196]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012416150579660517		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.012416150579660517 | validation: 0.004875963331826587]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008005708940961016		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.008005708940961016 | validation: 0.013120124688997765]
	TIME [epoch: 25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012657784073932827		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.012657784073932827 | validation: 0.018731106896974232]
	TIME [epoch: 25.1 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010973232256890522		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.010973232256890522 | validation: 0.010850111731654694]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009431559751371017		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.009431559751371017 | validation: 0.010348358239943529]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00822131775942558		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.00822131775942558 | validation: 0.01734061499370554]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01525572797792104		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.01525572797792104 | validation: 0.026305956752752893]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01587664052268271		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.01587664052268271 | validation: 0.004440950916577504]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_344.pth
	Model improved!!!
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004813534998228526		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.004813534998228526 | validation: 0.008431999672886485]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008441309829363199		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.008441309829363199 | validation: 0.025559413128625086]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025395362801773465		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.025395362801773465 | validation: 0.01192771292409465]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01314784367656983		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.01314784367656983 | validation: 0.015272966894866059]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00937123303261852		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.00937123303261852 | validation: 0.00771909069203185]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006922949919028677		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.006922949919028677 | validation: 0.006785581161770585]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005616104748770286		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.005616104748770286 | validation: 0.010820991115302266]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008917742474710512		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.008917742474710512 | validation: 0.014067912939998421]
	TIME [epoch: 25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01979850539879018		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.01979850539879018 | validation: 0.011334823404357087]
	TIME [epoch: 25.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007026369481859928		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.007026369481859928 | validation: 0.005589529458526369]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005350317522902893		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.005350317522902893 | validation: 0.014799160361752049]
	TIME [epoch: 25.1 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010007155438807728		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.010007155438807728 | validation: 0.0134915424608683]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01456914245545656		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.01456914245545656 | validation: 0.016369678600829593]
	TIME [epoch: 25.1 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013543797777265852		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.013543797777265852 | validation: 0.008817619692545499]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009943596477138618		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.009943596477138618 | validation: 0.005941064970565201]
	TIME [epoch: 25.1 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006133173011408765		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.006133173011408765 | validation: 0.0036652723307579243]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004165218417942663		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.004165218417942663 | validation: 0.00434785816718849]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019816460347152773		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.019816460347152773 | validation: 0.017245535230800902]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011969633490885059		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.011969633490885059 | validation: 0.006490692676790439]
	TIME [epoch: 25.1 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050465578294247105		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.0050465578294247105 | validation: 0.006927004013428838]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009121166212224604		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.009121166212224604 | validation: 0.005581148138843497]
	TIME [epoch: 25 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004814069001489276		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.004814069001489276 | validation: 0.005194387292108617]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009038574949374713		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.009038574949374713 | validation: 0.005715838239755586]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011863844162813547		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.011863844162813547 | validation: 0.006747248112398967]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069523239402502855		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.0069523239402502855 | validation: 0.007213066690075463]
	TIME [epoch: 25.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008111741612842335		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.008111741612842335 | validation: 0.006725668101393465]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009314051910824551		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.009314051910824551 | validation: 0.00971729481621533]
	TIME [epoch: 25 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070266438247968644		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.0070266438247968644 | validation: 0.006396446513242482]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006896935606769683		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.006896935606769683 | validation: 0.008232216328922924]
	TIME [epoch: 25.1 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010479142955316366		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.010479142955316366 | validation: 0.005747622746254827]
	TIME [epoch: 25 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0051443507901813654		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.0051443507901813654 | validation: 0.0077169796337738785]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007746113923877885		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.007746113923877885 | validation: 0.007704884523512569]
	TIME [epoch: 25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009295869722517757		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.009295869722517757 | validation: 0.008371115616703654]
	TIME [epoch: 25 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007382444552581891		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.007382444552581891 | validation: 0.009735433973013713]
	TIME [epoch: 25 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006989686167377869		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.006989686167377869 | validation: 0.005732846868286116]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008338396076004678		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.008338396076004678 | validation: 0.006549246356705339]
	TIME [epoch: 25.1 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007224000143573766		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.007224000143573766 | validation: 0.010646139043816049]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009092450749584318		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.009092450749584318 | validation: 0.004575722069515168]
	TIME [epoch: 25.1 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007904510965985285		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.007904510965985285 | validation: 0.006642327490639749]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009561713670323239		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.009561713670323239 | validation: 0.005616663930838456]
	TIME [epoch: 25.1 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005839424762226646		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.005839424762226646 | validation: 0.007510809614028292]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008594994606988047		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.008594994606988047 | validation: 0.005052841364441507]
	TIME [epoch: 25.1 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008998471821032989		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.008998471821032989 | validation: 0.014872597396655661]
	TIME [epoch: 25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009273671466725196		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.009273671466725196 | validation: 0.006346598061827773]
	TIME [epoch: 25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004327031430807884		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.004327031430807884 | validation: 0.006099092044085069]
	TIME [epoch: 25 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007246337031193056		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.007246337031193056 | validation: 0.014440979365156079]
	TIME [epoch: 25 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006711161867098636		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.006711161867098636 | validation: 0.005007659255671599]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014314998359829231		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.014314998359829231 | validation: 0.010230585067743329]
	TIME [epoch: 25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008005152093456367		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.008005152093456367 | validation: 0.007559132173110985]
	TIME [epoch: 25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0069781932617507935		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.0069781932617507935 | validation: 0.004918792002554538]
	TIME [epoch: 25 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005437966370268425		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.005437966370268425 | validation: 0.017090774393168338]
	TIME [epoch: 25 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009084383740313437		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.009084383740313437 | validation: 0.005160811731856889]
	TIME [epoch: 25.1 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005956852008865787		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.005956852008865787 | validation: 0.00466088873092972]
	TIME [epoch: 25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010690395925796082		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.010690395925796082 | validation: 0.014525688583253513]
	TIME [epoch: 25 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006551273050514		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.006551273050514 | validation: 0.005312017806277986]
	TIME [epoch: 25 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004160730814364095		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.004160730814364095 | validation: 0.005085755858420016]
	TIME [epoch: 25 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007676868997754758		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.007676868997754758 | validation: 0.007044144516271691]
	TIME [epoch: 25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0070414606750476725		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.0070414606750476725 | validation: 0.003185739659226349]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_402.pth
	Model improved!!!
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009315208518712686		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.009315208518712686 | validation: 0.006030299122077214]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006777828981240569		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.006777828981240569 | validation: 0.00857732158712648]
	TIME [epoch: 25.1 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007880133198664258		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.007880133198664258 | validation: 0.006146873481287382]
	TIME [epoch: 25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01382878872976767		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.01382878872976767 | validation: 0.005278876737298081]
	TIME [epoch: 25.1 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037350350133620387		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.0037350350133620387 | validation: 0.00408195598099315]
	TIME [epoch: 25 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024476609055759566		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.0024476609055759566 | validation: 0.003459046269575719]
	TIME [epoch: 25.1 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006558177016519896		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.006558177016519896 | validation: 0.012909649132025997]
	TIME [epoch: 25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00971191305368627		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.00971191305368627 | validation: 0.005813421486308338]
	TIME [epoch: 25.1 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044634097951468076		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.0044634097951468076 | validation: 0.005603587450858254]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036393505860856015		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.0036393505860856015 | validation: 0.004184724404071436]
	TIME [epoch: 25.1 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014011214847959048		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.014011214847959048 | validation: 0.007452516617796178]
	TIME [epoch: 25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004942116321223169		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.004942116321223169 | validation: 0.004077132229673013]
	TIME [epoch: 25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004853381130156589		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.004853381130156589 | validation: 0.013499991522301998]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006225003646329796		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.006225003646329796 | validation: 0.0037088278760237523]
	TIME [epoch: 25.1 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005515073120861674		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.005515073120861674 | validation: 0.028321118605094252]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020449082938217802		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.020449082938217802 | validation: 0.004579293666560101]
	TIME [epoch: 25.1 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038254245064969364		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.0038254245064969364 | validation: 0.003031782204600331]
	TIME [epoch: 25.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004035989899712638		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.004035989899712638 | validation: 0.006336306920290389]
	TIME [epoch: 25.1 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005264603984056583		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.005264603984056583 | validation: 0.0030043642139443117]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00243609745991774		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.00243609745991774 | validation: 0.0037867308319726517]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004886598432583414		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.004886598432583414 | validation: 0.010343941776355132]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008773469336952925		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.008773469336952925 | validation: 0.006355081595199401]
	TIME [epoch: 25 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006662651403641481		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.006662651403641481 | validation: 0.0034217727063559997]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038642400564994264		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.0038642400564994264 | validation: 0.010987733003911423]
	TIME [epoch: 25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.009905387128844418		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.009905387128844418 | validation: 0.004308562421823542]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036705510162732104		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.0036705510162732104 | validation: 0.004179188180899734]
	TIME [epoch: 25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0048962903429411436		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.0048962903429411436 | validation: 0.006023300332738573]
	TIME [epoch: 25 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003777253740965031		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.003777253740965031 | validation: 0.00963314656841033]
	TIME [epoch: 25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00822559998551868		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.00822559998551868 | validation: 0.005069646468170092]
	TIME [epoch: 25 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00606464489858633		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.00606464489858633 | validation: 0.00487806639745286]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032381539875904674		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.0032381539875904674 | validation: 0.004028218663689504]
	TIME [epoch: 25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006261652944749807		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.006261652944749807 | validation: 0.006204903219402397]
	TIME [epoch: 25 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004704720298372132		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.004704720298372132 | validation: 0.004615240383355158]
	TIME [epoch: 25 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007846629186642699		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.007846629186642699 | validation: 0.004161475201222365]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0074774841680939515		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.0074774841680939515 | validation: 0.005703450005213029]
	TIME [epoch: 25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004250086071407607		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.004250086071407607 | validation: 0.004613868167996303]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006828397502672419		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.006828397502672419 | validation: 0.0052985524412239955]
	TIME [epoch: 25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005117404871850563		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.005117404871850563 | validation: 0.005264444058814555]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0200418707009037		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.0200418707009037 | validation: 0.005515696356142167]
	TIME [epoch: 25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005958299393305665		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.005958299393305665 | validation: 0.003682665336463784]
	TIME [epoch: 25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0033654177813448		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.0033654177813448 | validation: 0.0024510340522232855]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006321529214921135		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.006321529214921135 | validation: 0.004405811845381763]
	TIME [epoch: 25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007376439862851417		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.007376439862851417 | validation: 0.0032761508077691214]
	TIME [epoch: 25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002950929819483394		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.002950929819483394 | validation: 0.0032526529300729587]
	TIME [epoch: 25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005492344072526184		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.005492344072526184 | validation: 0.006045165826416779]
	TIME [epoch: 25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036483767091292545		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.0036483767091292545 | validation: 0.004271443120630746]
	TIME [epoch: 25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020414271329692122		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.020414271329692122 | validation: 0.031336234162851764]
	TIME [epoch: 25.1 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027084225760158284		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.027084225760158284 | validation: 0.004609150741080611]
	TIME [epoch: 25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006940944824720282		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.006940944824720282 | validation: 0.004689429587406937]
	TIME [epoch: 25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003958080031669409		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.003958080031669409 | validation: 0.0037466615186262774]
	TIME [epoch: 25 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004372916161892998		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.004372916161892998 | validation: 0.005895706917866313]
	TIME [epoch: 25 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005389907300581821		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.005389907300581821 | validation: 0.005214658027972126]
	TIME [epoch: 25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003578119426107724		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.003578119426107724 | validation: 0.0033426366726998]
	TIME [epoch: 25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004212086614830603		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.004212086614830603 | validation: 0.0032200049745896835]
	TIME [epoch: 25 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043071366517188694		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.0043071366517188694 | validation: 0.01252175771031471]
	TIME [epoch: 25.1 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064334679220166835		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.0064334679220166835 | validation: 0.0033970446864100817]
	TIME [epoch: 25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00256560458831687		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.00256560458831687 | validation: 0.003312923185259874]
	TIME [epoch: 25.1 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00432037564200901		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.00432037564200901 | validation: 0.003839678438171146]
	TIME [epoch: 25 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045034799468519635		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.0045034799468519635 | validation: 0.0035631402881394336]
	TIME [epoch: 25 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00235386950199606		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.00235386950199606 | validation: 0.003623817368719538]
	TIME [epoch: 25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01756000553801528		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.01756000553801528 | validation: 0.009931228323323348]
	TIME [epoch: 25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004605884308358997		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.004605884308358997 | validation: 0.004026797718723396]
	TIME [epoch: 25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03428511048427799		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.03428511048427799 | validation: 0.009994874123942558]
	TIME [epoch: 25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007806506076617146		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.007806506076617146 | validation: 0.004871984254653355]
	TIME [epoch: 25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031644424057397213		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.0031644424057397213 | validation: 0.0037483933365549107]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021493233210659614		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.0021493233210659614 | validation: 0.001779002227784354]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_468.pth
	Model improved!!!
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002660972197034821		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.002660972197034821 | validation: 0.008330041168336352]
	TIME [epoch: 25.1 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005937769724386056		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.005937769724386056 | validation: 0.0054157766978878905]
	TIME [epoch: 25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002715844068689439		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.002715844068689439 | validation: 0.002831516930306994]
	TIME [epoch: 25 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034516156224900013		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.0034516156224900013 | validation: 0.003954798248233297]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044331295696443725		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.0044331295696443725 | validation: 0.005823062572702715]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0064294447476915175		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.0064294447476915175 | validation: 0.017050028728389583]
	TIME [epoch: 25 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010009208267899158		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.010009208267899158 | validation: 0.0037330135683733183]
	TIME [epoch: 25.1 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029101070886090956		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.0029101070886090956 | validation: 0.002963163212503561]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005824729407257747		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.005824729407257747 | validation: 0.004048435577421822]
	TIME [epoch: 25.1 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003106596943416087		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.003106596943416087 | validation: 0.004815681341717023]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006960376413056849		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.006960376413056849 | validation: 0.004628716271851413]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0035212949900056837		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.0035212949900056837 | validation: 0.00452407857752417]
	TIME [epoch: 25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032458038728631336		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.0032458038728631336 | validation: 0.004612797400999442]
	TIME [epoch: 25.1 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006114842322388021		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.006114842322388021 | validation: 0.003495132068557387]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004254018804823987		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.004254018804823987 | validation: 0.0037509527462981484]
	TIME [epoch: 25.1 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0053367827068049765		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.0053367827068049765 | validation: 0.0035110594593922937]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002003281155898492		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.002003281155898492 | validation: 0.004235833326185634]
	TIME [epoch: 25 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006771289399115277		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.006771289399115277 | validation: 0.011222085887293433]
	TIME [epoch: 25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006617960965381826		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.006617960965381826 | validation: 0.0025239096046671666]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004257573772066127		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.004257573772066127 | validation: 0.0036475764309956324]
	TIME [epoch: 25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037417801172877786		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.0037417801172877786 | validation: 0.0026015096006736273]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034014710157839914		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.0034014710157839914 | validation: 0.003758489350841396]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002282934546314405		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.002282934546314405 | validation: 0.0018486105306955458]
	TIME [epoch: 25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005169720843144162		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.005169720843144162 | validation: 0.00842275298941975]
	TIME [epoch: 25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007906073960993083		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.007906073960993083 | validation: 0.002726473956581191]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017405010891580388		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.0017405010891580388 | validation: 0.001682272347218082]
	TIME [epoch: 25 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_494.pth
	Model improved!!!
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002866493512560476		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.002866493512560476 | validation: 0.005226717385326078]
	TIME [epoch: 25.1 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006393847194157676		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.006393847194157676 | validation: 0.009959747288826658]
	TIME [epoch: 25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006053445488118614		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.006053445488118614 | validation: 0.0010325629751706548]
	TIME [epoch: 24.9 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001987134945337193		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.001987134945337193 | validation: 0.002449232862661405]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024499549914903307		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.0024499549914903307 | validation: 0.004622719893548561]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036116095365316945		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.0036116095365316945 | validation: 0.002304201115212105]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020101651073138422		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.0020101651073138422 | validation: 0.005132942963425273]
	TIME [epoch: 146 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00899564717906137		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.00899564717906137 | validation: 0.0038297693382617704]
	TIME [epoch: 49.5 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0038437123594907336		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.0038437123594907336 | validation: 0.0031123467589753177]
	TIME [epoch: 49.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029051117316031315		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.0029051117316031315 | validation: 0.003396690859411686]
	TIME [epoch: 49.5 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002792106139996851		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.002792106139996851 | validation: 0.0031029446225552945]
	TIME [epoch: 49.5 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025413621892547704		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.0025413621892547704 | validation: 0.004941596181128983]
	TIME [epoch: 49.5 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034309273920903926		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.0034309273920903926 | validation: 0.01005507208677274]
	TIME [epoch: 49.5 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007457024073376123		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.007457024073376123 | validation: 0.0032982089687272256]
	TIME [epoch: 49.5 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002660462229473998		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.002660462229473998 | validation: 0.004572372337218761]
	TIME [epoch: 49.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003293657874576922		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.003293657874576922 | validation: 0.0012239346460100138]
	TIME [epoch: 49.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004168854624057536		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.004168854624057536 | validation: 0.007809361194489222]
	TIME [epoch: 49.4 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004162402486486071		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.004162402486486071 | validation: 0.0025603120804111807]
	TIME [epoch: 49.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0039249750355558576		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.0039249750355558576 | validation: 0.029696717572669007]
	TIME [epoch: 49.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03565035474158595		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.03565035474158595 | validation: 0.006385428532288891]
	TIME [epoch: 49.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0045641731416340495		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.0045641731416340495 | validation: 0.002106344558063025]
	TIME [epoch: 49.5 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022834315197113953		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.0022834315197113953 | validation: 0.0024143464578471616]
	TIME [epoch: 49.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018106390003209349		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.0018106390003209349 | validation: 0.0026035001427715835]
	TIME [epoch: 49.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027849672687693065		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.0027849672687693065 | validation: 0.0021304889367201128]
	TIME [epoch: 49.4 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017730803446652423		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.0017730803446652423 | validation: 0.002622941629700771]
	TIME [epoch: 49.5 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031077853002517437		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.0031077853002517437 | validation: 0.0025662080885745725]
	TIME [epoch: 49.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020297378165411565		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.0020297378165411565 | validation: 0.0027244290532380784]
	TIME [epoch: 49.5 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031054686825396057		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.0031054686825396057 | validation: 0.004436117627694916]
	TIME [epoch: 49.5 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002528198742943956		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.002528198742943956 | validation: 0.0016768933689571938]
	TIME [epoch: 49.5 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0050593230679801425		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.0050593230679801425 | validation: 0.007156320771562485]
	TIME [epoch: 49.5 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004583817870886874		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.004583817870886874 | validation: 0.0021130886243480346]
	TIME [epoch: 49.4 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002630325548072305		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.002630325548072305 | validation: 0.002100131692017539]
	TIME [epoch: 49.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002207995091177614		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.002207995091177614 | validation: 0.0025344923918550863]
	TIME [epoch: 49.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021592716713194023		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.0021592716713194023 | validation: 0.002236596134070493]
	TIME [epoch: 49.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017097766334798867		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.0017097766334798867 | validation: 0.008517586248497374]
	TIME [epoch: 49.5 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006945370650611654		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.006945370650611654 | validation: 0.0037278064767906995]
	TIME [epoch: 49.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025494222065457865		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.0025494222065457865 | validation: 0.002001880643827447]
	TIME [epoch: 49.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0027697197699694835		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.0027697197699694835 | validation: 0.0011894234153998528]
	TIME [epoch: 49.5 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004044053385630804		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.004044053385630804 | validation: 0.002306332943589936]
	TIME [epoch: 49.5 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019474975312983797		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.0019474975312983797 | validation: 0.0042316709794305365]
	TIME [epoch: 49.5 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020833935744083943		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.0020833935744083943 | validation: 0.002502391019109821]
	TIME [epoch: 49.5 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.006293218693417164		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.006293218693417164 | validation: 0.0031089797697050853]
	TIME [epoch: 49.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003022911956473062		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.003022911956473062 | validation: 0.0037174076421775505]
	TIME [epoch: 49.6 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018101335548442482		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.0018101335548442482 | validation: 0.002623784041751134]
	TIME [epoch: 49.5 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028107054822030706		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.0028107054822030706 | validation: 0.0026102731043279185]
	TIME [epoch: 49.5 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002339834640088714		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.002339834640088714 | validation: 0.0012500516021813554]
	TIME [epoch: 49.5 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002164630112762386		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.002164630112762386 | validation: 0.001167929539318759]
	TIME [epoch: 49.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002349431041737189		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.002349431041737189 | validation: 0.004810045830184829]
	TIME [epoch: 49.5 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002564708033529997		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.002564708033529997 | validation: 0.026730048053193765]
	TIME [epoch: 49.5 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018700729632016497		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.018700729632016497 | validation: 0.0034728850553942003]
	TIME [epoch: 49.5 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024198943530138297		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.0024198943530138297 | validation: 0.004431772122316453]
	TIME [epoch: 49.5 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002185435955033096		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.002185435955033096 | validation: 0.0020301397218102767]
	TIME [epoch: 49.5 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003299417949613859		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.003299417949613859 | validation: 0.0024197830186374397]
	TIME [epoch: 49.5 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018280578609605489		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.0018280578609605489 | validation: 0.0025363838570841213]
	TIME [epoch: 49.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007078751981740287		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.007078751981740287 | validation: 0.013704030497680007]
	TIME [epoch: 49.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.007554077805462379		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.007554077805462379 | validation: 0.0025568315481690907]
	TIME [epoch: 49.4 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01279394341491203		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.01279394341491203 | validation: 0.0043475134605775664]
	TIME [epoch: 49.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004060769655216878		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.004060769655216878 | validation: 0.002893231497967409]
	TIME [epoch: 49.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025301289209767354		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.0025301289209767354 | validation: 0.002057481265118528]
	TIME [epoch: 49.5 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022319984998253575		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.0022319984998253575 | validation: 0.003099176874532844]
	TIME [epoch: 49.5 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031121957436207512		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.0031121957436207512 | validation: 0.00263209421639715]
	TIME [epoch: 49.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022895191951765996		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.0022895191951765996 | validation: 0.0032374469946481856]
	TIME [epoch: 49.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030350417868865963		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.0030350417868865963 | validation: 0.001611589635121734]
	TIME [epoch: 49.5 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004645626010340706		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.004645626010340706 | validation: 0.003862655601806324]
	TIME [epoch: 49.5 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0037891259160527154		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.0037891259160527154 | validation: 0.004403994459094746]
	TIME [epoch: 49.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002530600287874593		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.002530600287874593 | validation: 0.0013084459371017548]
	TIME [epoch: 49.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014172625885642022		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.0014172625885642022 | validation: 0.0018838316106408834]
	TIME [epoch: 49.5 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025799198927864485		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.0025799198927864485 | validation: 0.0036281082768792883]
	TIME [epoch: 49.5 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002422603886388943		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.002422603886388943 | validation: 0.0018116837041070317]
	TIME [epoch: 49.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004275243387508778		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.004275243387508778 | validation: 0.0024607144174733707]
	TIME [epoch: 49.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013776429261121651		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.0013776429261121651 | validation: 0.0019136335152846202]
	TIME [epoch: 49.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024763953741080078		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.0024763953741080078 | validation: 0.0042445503211804795]
	TIME [epoch: 49.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003822894792179745		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.003822894792179745 | validation: 0.005559870104198056]
	TIME [epoch: 49.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002905911563932451		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.002905911563932451 | validation: 0.001996610516279554]
	TIME [epoch: 49.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016627246376338498		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.0016627246376338498 | validation: 0.0029960324479718836]
	TIME [epoch: 49.5 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019833040455120585		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0019833040455120585 | validation: 0.003423195717687356]
	TIME [epoch: 49.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018433951517095866		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.0018433951517095866 | validation: 0.0008477707625735791]
	TIME [epoch: 49.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_571.pth
	Model improved!!!
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003014295297009032		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.003014295297009032 | validation: 0.0018251980864721234]
	TIME [epoch: 49.5 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0073434681797094475		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.0073434681797094475 | validation: 0.0022023504672739483]
	TIME [epoch: 49.5 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019130667848164878		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.0019130667848164878 | validation: 0.002655424868270357]
	TIME [epoch: 49.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00558307114724624		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.00558307114724624 | validation: 0.0068324997939728325]
	TIME [epoch: 49.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0044135393413897266		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.0044135393413897266 | validation: 0.0031614056267537374]
	TIME [epoch: 49.5 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016256636835831097		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0016256636835831097 | validation: 0.0012705651465461515]
	TIME [epoch: 49.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025500454639638386		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.0025500454639638386 | validation: 0.0019715073576915543]
	TIME [epoch: 49.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019123326498305968		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.0019123326498305968 | validation: 0.0021345976646300986]
	TIME [epoch: 49.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019707166279157484		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.0019707166279157484 | validation: 0.0014132427357878494]
	TIME [epoch: 49.5 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00146958019338353		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.00146958019338353 | validation: 0.0017736387619947138]
	TIME [epoch: 49.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003813838583063032		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.003813838583063032 | validation: 0.002932006482191876]
	TIME [epoch: 49.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002794562835495764		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.002794562835495764 | validation: 0.0022521495051220125]
	TIME [epoch: 49.6 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002542449122434018		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.002542449122434018 | validation: 0.0026569069344882248]
	TIME [epoch: 49.5 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00216347315219019		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.00216347315219019 | validation: 0.0010002106288672587]
	TIME [epoch: 49.5 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002843505144249436		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.002843505144249436 | validation: 0.00226660684720539]
	TIME [epoch: 49.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018848833963741585		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.0018848833963741585 | validation: 0.005312441400751024]
	TIME [epoch: 49.5 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002407917679090878		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.002407917679090878 | validation: 0.0020968596857034345]
	TIME [epoch: 49.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002997672112574917		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.002997672112574917 | validation: 0.0019333125279765166]
	TIME [epoch: 49.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011151058811580256		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.0011151058811580256 | validation: 0.0014229312999399792]
	TIME [epoch: 49.6 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0028971579371548243		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.0028971579371548243 | validation: 0.0025378681099661564]
	TIME [epoch: 49.5 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002793177911480413		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.002793177911480413 | validation: 0.0023824891269129383]
	TIME [epoch: 49.6 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017493978389230996		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.0017493978389230996 | validation: 0.0034744802210118775]
	TIME [epoch: 49.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018389452750380902		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.0018389452750380902 | validation: 0.0020990521582503322]
	TIME [epoch: 49.6 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029310089450050383		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.0029310089450050383 | validation: 0.00212307546976311]
	TIME [epoch: 49.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019429003099383831		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.0019429003099383831 | validation: 0.0012874781910661235]
	TIME [epoch: 49.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032256601676290218		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.0032256601676290218 | validation: 0.0024297083769430432]
	TIME [epoch: 49.4 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011617579597048434		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.0011617579597048434 | validation: 0.0023784063773706777]
	TIME [epoch: 49.5 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029668516256430347		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0029668516256430347 | validation: 0.0018779893746576626]
	TIME [epoch: 49.5 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018176899994926615		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.0018176899994926615 | validation: 0.00556190264032933]
	TIME [epoch: 49.4 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0043907813902929445		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.0043907813902929445 | validation: 0.002842969963854276]
	TIME [epoch: 49.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030882553287189464		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.0030882553287189464 | validation: 0.0023828943258688904]
	TIME [epoch: 49.6 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003012327645754949		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.003012327645754949 | validation: 0.0037370772602474574]
	TIME [epoch: 49.6 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002443785915109925		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.002443785915109925 | validation: 0.0038397458184586276]
	TIME [epoch: 49.6 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0032124772071944574		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.0032124772071944574 | validation: 0.0013888761231669261]
	TIME [epoch: 49.6 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013952209806143874		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.0013952209806143874 | validation: 0.0013403889810726809]
	TIME [epoch: 49.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002089223997486612		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.002089223997486612 | validation: 0.0013444423401833927]
	TIME [epoch: 49.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017486571703315785		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.0017486571703315785 | validation: 0.0012612119418589228]
	TIME [epoch: 49.6 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016407939955408427		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.0016407939955408427 | validation: 0.0014055078798899281]
	TIME [epoch: 49.5 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012962879904608003		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.0012962879904608003 | validation: 0.0019506081806469028]
	TIME [epoch: 49.6 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011071405276459369		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.0011071405276459369 | validation: 0.0015004350617278566]
	TIME [epoch: 49.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019177006473812008		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.0019177006473812008 | validation: 0.0025732610824199397]
	TIME [epoch: 49.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025094311755544676		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.0025094311755544676 | validation: 0.001671357658137711]
	TIME [epoch: 49.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002284763545027049		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.002284763545027049 | validation: 0.0012170094335284167]
	TIME [epoch: 49.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019363211829960666		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.0019363211829960666 | validation: 0.0019768127501732244]
	TIME [epoch: 49.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018313647750601955		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.0018313647750601955 | validation: 0.002139232000265032]
	TIME [epoch: 49.6 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019190521962825068		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.0019190521962825068 | validation: 0.006625130526440011]
	TIME [epoch: 49.6 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0056357680809672826		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.0056357680809672826 | validation: 0.0029266941071769224]
	TIME [epoch: 49.6 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020043915220203977		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.0020043915220203977 | validation: 0.0024293067239189465]
	TIME [epoch: 49.6 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026473516908024908		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.0026473516908024908 | validation: 0.0014786245583311452]
	TIME [epoch: 49.5 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001979044782558296		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.001979044782558296 | validation: 0.002735739433430762]
	TIME [epoch: 49.6 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014426955426662868		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.0014426955426662868 | validation: 0.0016742826416720038]
	TIME [epoch: 49.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018071705637072678		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.0018071705637072678 | validation: 0.0026248032093477217]
	TIME [epoch: 49.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023625601987027323		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.0023625601987027323 | validation: 0.0011946733650326001]
	TIME [epoch: 49.5 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017214170542537803		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.0017214170542537803 | validation: 0.000811173624521421]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_625.pth
	Model improved!!!
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012615778143873165		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.0012615778143873165 | validation: 0.0017478736553502025]
	TIME [epoch: 49.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015812038787798076		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.0015812038787798076 | validation: 0.0015932878405364769]
	TIME [epoch: 49.6 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015429120156317476		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.0015429120156317476 | validation: 0.0012959246173819472]
	TIME [epoch: 49.6 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0019945568101279194		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.0019945568101279194 | validation: 0.0024646465137260387]
	TIME [epoch: 49.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0047074109008487615		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.0047074109008487615 | validation: 0.002463607521370078]
	TIME [epoch: 49.6 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002093705692129408		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.002093705692129408 | validation: 0.001076371557132735]
	TIME [epoch: 49.6 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010391924470630662		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.0010391924470630662 | validation: 0.0011785345460410567]
	TIME [epoch: 49.6 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009690259520099879		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.0009690259520099879 | validation: 0.0017787275232702777]
	TIME [epoch: 49.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016879539057300867		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.0016879539057300867 | validation: 0.004417597767820067]
	TIME [epoch: 49.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018461674183504776		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.0018461674183504776 | validation: 0.0020357942798432133]
	TIME [epoch: 49.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025634754647661617		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.0025634754647661617 | validation: 0.015688180911830656]
	TIME [epoch: 49.6 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.008336083924771249		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.008336083924771249 | validation: 0.002472225141019326]
	TIME [epoch: 49.6 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016022143819903886		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.0016022143819903886 | validation: 0.002197794266951935]
	TIME [epoch: 49.6 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013146253273804895		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0013146253273804895 | validation: 0.002010409583698784]
	TIME [epoch: 49.6 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0036610914292870282		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.0036610914292870282 | validation: 0.003407200087321983]
	TIME [epoch: 49.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013246483656385113		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.0013246483656385113 | validation: 0.0019498592453123798]
	TIME [epoch: 49.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014946184216221114		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.0014946184216221114 | validation: 0.0013194145129119636]
	TIME [epoch: 49.5 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001452836979524028		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.001452836979524028 | validation: 0.0015137102224904125]
	TIME [epoch: 49.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008297256627175862		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.0008297256627175862 | validation: 0.002852882474471494]
	TIME [epoch: 49.6 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024317813640944725		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.0024317813640944725 | validation: 0.001173063663884419]
	TIME [epoch: 49.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010551838135012045		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.0010551838135012045 | validation: 0.0013465729615367104]
	TIME [epoch: 49.5 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044474112624716183		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.00044474112624716183 | validation: 0.0020334836000062053]
	TIME [epoch: 49.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001509154016694187		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.001509154016694187 | validation: 0.002283033105505561]
	TIME [epoch: 49.6 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015950755740730496		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.0015950755740730496 | validation: 0.0015521545455910374]
	TIME [epoch: 49.6 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016507884007766636		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.0016507884007766636 | validation: 0.0011288655796636044]
	TIME [epoch: 49.6 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001624234492751294		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.001624234492751294 | validation: 0.0012215073966638386]
	TIME [epoch: 49.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014484881073939019		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.0014484881073939019 | validation: 0.003674669212945995]
	TIME [epoch: 49.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015506497250521224		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.0015506497250521224 | validation: 0.0018409222890584799]
	TIME [epoch: 49.5 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015667278223920143		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.0015667278223920143 | validation: 0.0015136169788673248]
	TIME [epoch: 49.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014808729841863984		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0014808729841863984 | validation: 0.0019431249612789161]
	TIME [epoch: 49.6 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013962926988338518		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.0013962926988338518 | validation: 0.001335778919380505]
	TIME [epoch: 49.6 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002272310604245374		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.002272310604245374 | validation: 0.0010412404967931168]
	TIME [epoch: 49.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018996376192773469		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.0018996376192773469 | validation: 0.001649713609945052]
	TIME [epoch: 49.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002086520581094475		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.002086520581094475 | validation: 0.0027113259372791394]
	TIME [epoch: 49.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012371177724540446		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.0012371177724540446 | validation: 0.0004104872118758069]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_660.pth
	Model improved!!!
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002078560549926954		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.002078560549926954 | validation: 0.0018648113056207616]
	TIME [epoch: 49.6 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014479522454678452		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.0014479522454678452 | validation: 0.0017766998764065023]
	TIME [epoch: 49.5 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017730161803521825		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.0017730161803521825 | validation: 0.0012039948232074544]
	TIME [epoch: 49.6 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014250411655791508		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.0014250411655791508 | validation: 0.0010081287834830502]
	TIME [epoch: 49.6 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006471049365811548		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.0006471049365811548 | validation: 0.0012095753940394932]
	TIME [epoch: 49.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001934528522277522		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.001934528522277522 | validation: 0.002354166455612782]
	TIME [epoch: 49.6 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012253332652137085		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.0012253332652137085 | validation: 0.00113456294854887]
	TIME [epoch: 49.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000707026726944457		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.000707026726944457 | validation: 0.002531821339283074]
	TIME [epoch: 49.5 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0031291533170300237		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.0031291533170300237 | validation: 0.0002329518120242571]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008276472261193496		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.0008276472261193496 | validation: 0.0005039891053029253]
	TIME [epoch: 49.6 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007973343822458963		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.0007973343822458963 | validation: 0.0035941694888691846]
	TIME [epoch: 49.5 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016276963641883462		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.0016276963641883462 | validation: 0.004517472909239879]
	TIME [epoch: 49.6 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001979002052102449		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.001979002052102449 | validation: 0.0019919074074891113]
	TIME [epoch: 49.6 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014688014967231392		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.0014688014967231392 | validation: 0.0011163890058862088]
	TIME [epoch: 49.6 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001228277521971057		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.001228277521971057 | validation: 0.0024599753433875663]
	TIME [epoch: 49.6 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00117892360483864		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.00117892360483864 | validation: 0.0013944011750045044]
	TIME [epoch: 49.5 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010685166657605388		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.0010685166657605388 | validation: 0.0014914452848452254]
	TIME [epoch: 49.6 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0022454661123868344		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.0022454661123868344 | validation: 0.001915692124089945]
	TIME [epoch: 49.6 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001036813471436184		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.001036813471436184 | validation: 0.0006043510039406988]
	TIME [epoch: 49.6 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002086157539622903		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.002086157539622903 | validation: 0.0002250662982886795]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_680.pth
	Model improved!!!
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003017935610562866		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.003017935610562866 | validation: 0.0007965644515139187]
	TIME [epoch: 49.6 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010605518679425575		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.0010605518679425575 | validation: 0.0018166789937242639]
	TIME [epoch: 49.6 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002106045876090639		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.002106045876090639 | validation: 0.002335177187804895]
	TIME [epoch: 49.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006711791249273731		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.0006711791249273731 | validation: 0.0009278682038455379]
	TIME [epoch: 49.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012263815344650828		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.0012263815344650828 | validation: 0.0027079382016471183]
	TIME [epoch: 49.5 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012646329783139543		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.0012646329783139543 | validation: 0.0017789369422214838]
	TIME [epoch: 49.5 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001483122859841384		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.001483122859841384 | validation: 0.0011582466433771384]
	TIME [epoch: 49.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017818128283493624		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0017818128283493624 | validation: 0.0001814543318552766]
	TIME [epoch: 49.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017640819597326731		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.0017640819597326731 | validation: 0.0014783852254333404]
	TIME [epoch: 49.6 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001147236904675899		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.001147236904675899 | validation: 0.00082604020155634]
	TIME [epoch: 49.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005645712183141032		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.0005645712183141032 | validation: 0.0009314364863745187]
	TIME [epoch: 49.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012840617733909181		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.0012840617733909181 | validation: 0.0017991679292959292]
	TIME [epoch: 49.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014526761951489948		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.0014526761951489948 | validation: 0.001848877208210742]
	TIME [epoch: 49.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005980292575704467		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.0005980292575704467 | validation: 0.002266389923521725]
	TIME [epoch: 49.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0029205354278268553		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.0029205354278268553 | validation: 0.002448545522480742]
	TIME [epoch: 49.6 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007389162693107012		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.0007389162693107012 | validation: 0.0006941113828547291]
	TIME [epoch: 49.6 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016618179700220483		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.0016618179700220483 | validation: 0.002706559578879204]
	TIME [epoch: 49.6 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014059504572140526		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.0014059504572140526 | validation: 0.00030020466441946865]
	TIME [epoch: 49.6 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007628059480176436		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.0007628059480176436 | validation: 0.0005567056391149285]
	TIME [epoch: 49.6 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008062297359498865		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.0008062297359498865 | validation: 0.0018193344011020757]
	TIME [epoch: 49.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010564716638461755		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.0010564716638461755 | validation: 0.0010946420461883477]
	TIME [epoch: 49.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008805186379427102		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.0008805186379427102 | validation: 0.0013449410034150721]
	TIME [epoch: 49.6 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012011041223726317		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0012011041223726317 | validation: 0.001269204809057988]
	TIME [epoch: 49.6 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008321878417738913		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.0008321878417738913 | validation: 0.0022837671790115963]
	TIME [epoch: 49.6 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017135699486352917		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.0017135699486352917 | validation: 0.00046876063451604683]
	TIME [epoch: 49.6 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001012234560892472		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.001012234560892472 | validation: 0.0021369777796654537]
	TIME [epoch: 49.6 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004956804865239592		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.004956804865239592 | validation: 0.0026711998443816154]
	TIME [epoch: 49.7 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008076225317564622		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.0008076225317564622 | validation: 0.001224929504039098]
	TIME [epoch: 49.5 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009785290887158312		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.0009785290887158312 | validation: 0.001081159792577203]
	TIME [epoch: 49.6 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008095421182058629		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.0008095421182058629 | validation: 0.0008673149489016225]
	TIME [epoch: 49.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000565707802666051		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.000565707802666051 | validation: 0.0019567271021258287]
	TIME [epoch: 49.6 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010993944977760728		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.0010993944977760728 | validation: 0.0015040816816311352]
	TIME [epoch: 49.6 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010604453251006603		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0010604453251006603 | validation: 0.009239333288454814]
	TIME [epoch: 49.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00756253966160614		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.00756253966160614 | validation: 0.0019029105503544671]
	TIME [epoch: 49.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0017028508299816165		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.0017028508299816165 | validation: 0.0011984014754713593]
	TIME [epoch: 49.6 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015356468955106594		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0015356468955106594 | validation: 0.001290097405456617]
	TIME [epoch: 49.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005101094484161947		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.0005101094484161947 | validation: 0.0007704265658835641]
	TIME [epoch: 49.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008702030133374871		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.0008702030133374871 | validation: 0.0018667530502250323]
	TIME [epoch: 49.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006259279194159512		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.0006259279194159512 | validation: 0.0010333024105032575]
	TIME [epoch: 49.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001062823160353432		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.001062823160353432 | validation: 0.001191489084507225]
	TIME [epoch: 49.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0025453465964308834		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.0025453465964308834 | validation: 0.0010596051061681374]
	TIME [epoch: 49.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013348546479902694		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.0013348546479902694 | validation: 0.0006963096798267663]
	TIME [epoch: 49.6 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008102954801962438		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.0008102954801962438 | validation: 0.0020961194578263285]
	TIME [epoch: 49.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000846321129985706		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.000846321129985706 | validation: 0.0013208550733547098]
	TIME [epoch: 49.6 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007567042982296393		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.0007567042982296393 | validation: 0.0020658616841590827]
	TIME [epoch: 49.6 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005148022185581484		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.005148022185581484 | validation: 0.003193959115833267]
	TIME [epoch: 49.6 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0024069854180575703		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.0024069854180575703 | validation: 0.0015010268474313917]
	TIME [epoch: 49.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002383420386104558		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.002383420386104558 | validation: 0.0014017143601877584]
	TIME [epoch: 49.6 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012650072626539854		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.0012650072626539854 | validation: 0.0007159136993691253]
	TIME [epoch: 49.6 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016267539762988689		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.0016267539762988689 | validation: 0.010152123224598316]
	TIME [epoch: 49.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.005546693678109379		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.005546693678109379 | validation: 0.0009743836630727972]
	TIME [epoch: 49.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011941403174260071		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.0011941403174260071 | validation: 0.001096760446040812]
	TIME [epoch: 49.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010490224287098482		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.0010490224287098482 | validation: 0.0005410300768277066]
	TIME [epoch: 49.6 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009493672001419178		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.0009493672001419178 | validation: 0.004315693773082469]
	TIME [epoch: 49.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002180803121763194		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.002180803121763194 | validation: 0.0009236085197289623]
	TIME [epoch: 49.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012229767101149432		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.0012229767101149432 | validation: 0.002097634326868]
	TIME [epoch: 49.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009985145618731346		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.0009985145618731346 | validation: 0.0014778914278021059]
	TIME [epoch: 49.6 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008149837987148648		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.0008149837987148648 | validation: 0.0019561903828225692]
	TIME [epoch: 49.6 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005156395388731122		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.0005156395388731122 | validation: 0.0013213614084801716]
	TIME [epoch: 49.6 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0018049645510899342		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.0018049645510899342 | validation: 0.0011051702997364541]
	TIME [epoch: 49.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008480115379910873		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.0008480115379910873 | validation: 0.00036755130545200124]
	TIME [epoch: 49.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012990800638475759		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.0012990800638475759 | validation: 0.0022768034229867446]
	TIME [epoch: 49.6 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006148696212482299		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.0006148696212482299 | validation: 0.0016289410819268527]
	TIME [epoch: 49.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008966590324017985		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.0008966590324017985 | validation: 0.00039916140844504036]
	TIME [epoch: 49.6 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008665817865654145		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.0008665817865654145 | validation: 0.00048958090641261]
	TIME [epoch: 49.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007004986233122341		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.0007004986233122341 | validation: 0.0023824968743587525]
	TIME [epoch: 49.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001919040273431269		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.001919040273431269 | validation: 0.0016705714509155018]
	TIME [epoch: 49.6 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006753707904678062		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.0006753707904678062 | validation: 0.0010510020356514996]
	TIME [epoch: 49.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003543158465219534		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.003543158465219534 | validation: 0.001385446596107518]
	TIME [epoch: 49.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013282682802714077		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.0013282682802714077 | validation: 8.407976598526104e-06]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_750.pth
	Model improved!!!
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007797723393951221		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.0007797723393951221 | validation: 0.000871680153198585]
	TIME [epoch: 49.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001039432104350585		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.001039432104350585 | validation: 0.0012470609900081743]
	TIME [epoch: 49.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008042876010907622		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.0008042876010907622 | validation: -0.00026957666989004014]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_753.pth
	Model improved!!!
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009003316988193346		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.0009003316988193346 | validation: 0.0008082058168345006]
	TIME [epoch: 49.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007807393096796284		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0007807393096796284 | validation: 0.0018705542449257598]
	TIME [epoch: 49.6 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007077446442908475		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.0007077446442908475 | validation: 0.0004766806241558208]
	TIME [epoch: 49.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003867050769263431		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.0003867050769263431 | validation: 0.0010334197278530418]
	TIME [epoch: 49.6 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002422847309647991		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.002422847309647991 | validation: 0.0016940975951935946]
	TIME [epoch: 49.6 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010958954096134145		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.0010958954096134145 | validation: 0.0011230032383297206]
	TIME [epoch: 49.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4029116025759837e-06		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 3.4029116025759837e-06 | validation: 0.0012978337258099499]
	TIME [epoch: 49.6 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010978170023949513		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.0010978170023949513 | validation: 0.0013790065742736823]
	TIME [epoch: 49.6 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023616384336941393		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.0023616384336941393 | validation: 0.0015797329756019316]
	TIME [epoch: 49.6 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000902484163838981		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.000902484163838981 | validation: 0.0006465608266803527]
	TIME [epoch: 49.5 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009786004774017536		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0009786004774017536 | validation: 0.0011387090991992247]
	TIME [epoch: 49.6 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005198951164791093		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.0005198951164791093 | validation: 0.0015743722223183361]
	TIME [epoch: 49.6 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0015022325714538931		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.0015022325714538931 | validation: 0.0005312675401524269]
	TIME [epoch: 49.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003389490263388818		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.003389490263388818 | validation: 0.0020867237875110117]
	TIME [epoch: 49.5 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000597622277316366		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.000597622277316366 | validation: 7.528905484919336e-05]
	TIME [epoch: 49.6 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026022146697208994		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.00026022146697208994 | validation: 0.0009372203700666707]
	TIME [epoch: 49.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005003555798402473		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.0005003555798402473 | validation: 0.0015486981033504218]
	TIME [epoch: 49.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007635821896649698		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.0007635821896649698 | validation: 0.001590505102898052]
	TIME [epoch: 49.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012569642658825536		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.0012569642658825536 | validation: 0.0008240714370963907]
	TIME [epoch: 49.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008578636795581698		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.0008578636795581698 | validation: 0.0006552752441493422]
	TIME [epoch: 49.6 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006305010146715409		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.0006305010146715409 | validation: 0.0008213705522568109]
	TIME [epoch: 49.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0021313395475155055		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.0021313395475155055 | validation: 0.0028071726167764317]
	TIME [epoch: 49.5 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0023600931134755187		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.0023600931134755187 | validation: 0.0013292618253004532]
	TIME [epoch: 49.6 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007571551170792541		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.0007571551170792541 | validation: 0.0013090500797705872]
	TIME [epoch: 49.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0012384559332644964		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.0012384559332644964 | validation: 0.0016774871424867438]
	TIME [epoch: 49.6 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00042127331770954574		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.00042127331770954574 | validation: 0.0002200310255290496]
	TIME [epoch: 49.5 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006156539463199205		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.0006156539463199205 | validation: 0.0009163487915436828]
	TIME [epoch: 49.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00069588939206881		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.00069588939206881 | validation: 0.0009141180293191283]
	TIME [epoch: 49.5 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006252680953845791		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.0006252680953845791 | validation: 0.0006725313358397841]
	TIME [epoch: 49.6 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004043913144768634		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.0004043913144768634 | validation: 0.0012412982841026507]
	TIME [epoch: 49.6 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003890152781249397		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.0003890152781249397 | validation: 0.0023222789034282763]
	TIME [epoch: 49.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.002178463805395852		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.002178463805395852 | validation: 0.000894943251502506]
	TIME [epoch: 49.6 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006459714003240451		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.0006459714003240451 | validation: 0.0007932195631584014]
	TIME [epoch: 49.6 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043723620023606685		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.00043723620023606685 | validation: 0.0002833817061930413]
	TIME [epoch: 49.6 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008612750002369396		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.0008612750002369396 | validation: 0.0023686092369196313]
	TIME [epoch: 49.6 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004948120884966865		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.0004948120884966865 | validation: 0.001860277896543757]
	TIME [epoch: 49.6 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001056682237743511		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.001056682237743511 | validation: 0.0006686093671960634]
	TIME [epoch: 49.6 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006653016566845788		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.0006653016566845788 | validation: 0.00035828243096502405]
	TIME [epoch: 49.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2470520453684592e-05		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 1.2470520453684592e-05 | validation: 0.00035546799419984196]
	TIME [epoch: 49.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005860310088230869		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.0005860310088230869 | validation: 0.0010318009580767779]
	TIME [epoch: 49.5 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.198197285640617e-05		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 4.198197285640617e-05 | validation: 0.0008088748829197564]
	TIME [epoch: 49.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003842571911137214		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0003842571911137214 | validation: 0.00025938198227429596]
	TIME [epoch: 49.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043912655959640776		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.00043912655959640776 | validation: 0.0007108726781564472]
	TIME [epoch: 49.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001743385489236701		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.001743385489236701 | validation: 0.001325602612032188]
	TIME [epoch: 49.6 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014512613951057848		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.0014512613951057848 | validation: -0.00016739542406155516]
	TIME [epoch: 49.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011238717899776293		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.0011238717899776293 | validation: 0.0007944584399704972]
	TIME [epoch: 49.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005372904153182611		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.0005372904153182611 | validation: 0.0015121206860886469]
	TIME [epoch: 49.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007360091409147753		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.0007360091409147753 | validation: 0.000721336854914258]
	TIME [epoch: 49.6 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0011959671597104328		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0011959671597104328 | validation: 0.00041422237178591456]
	TIME [epoch: 49.6 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00043066535938998565		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.00043066535938998565 | validation: 0.0005609288535562369]
	TIME [epoch: 49.6 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003846687578014043		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.0003846687578014043 | validation: 0.001521841491657557]
	TIME [epoch: 49.6 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00023360330729816782		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.00023360330729816782 | validation: 0.0012125286003312175]
	TIME [epoch: 49.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008129439579441921		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.0008129439579441921 | validation: 0.0009255827822897409]
	TIME [epoch: 49.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013514910129013029		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0013514910129013029 | validation: 0.0007703518275467381]
	TIME [epoch: 49.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007485445219321052		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.0007485445219321052 | validation: 0.0008276750084131672]
	TIME [epoch: 49.6 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006463767753046598		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.0006463767753046598 | validation: 0.00022075748484442893]
	TIME [epoch: 49.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010788520790254424		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.0010788520790254424 | validation: 0.002185079682757978]
	TIME [epoch: 49.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010325719542707717		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0010325719542707717 | validation: 0.0002172155275548096]
	TIME [epoch: 49.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005231214339468829		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.0005231214339468829 | validation: 0.0010391385875291657]
	TIME [epoch: 49.6 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006814525426005913		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.0006814525426005913 | validation: 0.00042826544483183233]
	TIME [epoch: 49.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007239460405173028		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.0007239460405173028 | validation: 0.002619753721041334]
	TIME [epoch: 49.6 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016814676167167064		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0016814676167167064 | validation: 0.0023696364218351845]
	TIME [epoch: 49.6 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0020206914636324144		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.0020206914636324144 | validation: 0.00303273384806476]
	TIME [epoch: 49.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007679703491502739		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.0007679703491502739 | validation: 0.0022200903285362946]
	TIME [epoch: 49.6 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009486599391826628		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.0009486599391826628 | validation: 0.0005702492191126023]
	TIME [epoch: 49.6 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003428643442236747		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.0003428643442236747 | validation: 0.0007316687682296888]
	TIME [epoch: 49.6 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0001334249028184904		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.0001334249028184904 | validation: 0.00042013652238979927]
	TIME [epoch: 49.6 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003585818756179908		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.003585818756179908 | validation: 0.0014658432013475039]
	TIME [epoch: 49.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0016450975136278077		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.0016450975136278077 | validation: 0.001250679869285182]
	TIME [epoch: 49.6 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006589560428764159		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.0006589560428764159 | validation: 0.0004803664591696815]
	TIME [epoch: 49.6 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005476463903269846		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.0005476463903269846 | validation: 0.0008178142628921035]
	TIME [epoch: 49.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026107587568978283		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.00026107587568978283 | validation: 0.0013049028999133352]
	TIME [epoch: 49.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007158168697616498		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.0007158168697616498 | validation: 0.0004410712568680446]
	TIME [epoch: 49.5 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: -9.397899436293326e-06		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: -9.397899436293326e-06 | validation: 0.00022417427301367135]
	TIME [epoch: 49.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0013047291074416963		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.0013047291074416963 | validation: 0.0013576291744802705]
	TIME [epoch: 49.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004933494901060887		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0004933494901060887 | validation: 0.0007823184654681433]
	TIME [epoch: 49.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040062716263565123		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.00040062716263565123 | validation: 0.0010198201484083059]
	TIME [epoch: 49.6 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009692938560053664		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0009692938560053664 | validation: 0.0011977329399439902]
	TIME [epoch: 49.5 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008264812290138606		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.0008264812290138606 | validation: 0.0010118898330731833]
	TIME [epoch: 49.5 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006330410683750902		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.0006330410683750902 | validation: 0.0007818070610723052]
	TIME [epoch: 49.6 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0010848839327756853		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.0010848839327756853 | validation: 0.0012618464076526404]
	TIME [epoch: 49.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.0002278310055519033		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: -0.0002278310055519033 | validation: 0.00034609985867866034]
	TIME [epoch: 49.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00046854556995894875		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.00046854556995894875 | validation: 0.0008853910165468274]
	TIME [epoch: 49.6 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005823024764599709		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0005823024764599709 | validation: 0.00015085797098445127]
	TIME [epoch: 49.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006979705806882264		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.0006979705806882264 | validation: 0.0016506855861531415]
	TIME [epoch: 49.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0030235872043747457		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.0030235872043747457 | validation: 0.006944889325037883]
	TIME [epoch: 49.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0034499499803014697		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0034499499803014697 | validation: 0.0010776482986483771]
	TIME [epoch: 49.5 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0008136778271030958		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0008136778271030958 | validation: 0.0014628997978684754]
	TIME [epoch: 49.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003537654972942794		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.0003537654972942794 | validation: 0.0015668356218444166]
	TIME [epoch: 49.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0026942784781733347		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0026942784781733347 | validation: 0.0009090374218655656]
	TIME [epoch: 49.6 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00014271399190246271		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.00014271399190246271 | validation: 0.0010679052871358245]
	TIME [epoch: 49.5 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00026241447529896055		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.00026241447529896055 | validation: 0.0006233467395847185]
	TIME [epoch: 49.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00040965067595119395		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.00040965067595119395 | validation: -0.0003056793984043602]
	TIME [epoch: 49.6 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114555/states/model_phi2_1a_v_mmd1_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.004291361188332457		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.004291361188332457 | validation: 0.007581020781347456]
	TIME [epoch: 49.6 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.003730363778444592		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.003730363778444592 | validation: 0.0014263213342724543]
	TIME [epoch: 49.6 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005244371971327166		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.0005244371971327166 | validation: 0.0003856700767908894]
	TIME [epoch: 49.6 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002864889818982894		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.0002864889818982894 | validation: 0.0007678309902148231]
	TIME [epoch: 49.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00028304311075313195		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: -0.00028304311075313195 | validation: 0.0007135689606385505]
	TIME [epoch: 49.6 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019344229214746057		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.00019344229214746057 | validation: 0.0018320390675908697]
	TIME [epoch: 49.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00011731142256855742		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.00011731142256855742 | validation: 0.0014663984645035132]
	TIME [epoch: 49.6 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002153877357149865		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.0002153877357149865 | validation: 0.0009694561372325138]
	TIME [epoch: 49.6 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00019892324587038714		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.00019892324587038714 | validation: 0.0015229764953720198]
	TIME [epoch: 49.6 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004657004711038528		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.0004657004711038528 | validation: 0.0005825514876775877]
	TIME [epoch: 49.6 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005725472660773078		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.0005725472660773078 | validation: 0.0004992647231200556]
	TIME [epoch: 49.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.000734568472424066		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.000734568472424066 | validation: 0.0008888480870633507]
	TIME [epoch: 49.6 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0007580194920526302		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.0007580194920526302 | validation: 0.0007381295576260936]
	TIME [epoch: 49.6 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005816235389918394		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.0005816235389918394 | validation: 0.0013298693860733985]
	TIME [epoch: 49.6 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0003254949832385317		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.0003254949832385317 | validation: 0.0009871053416735643]
	TIME [epoch: 49.6 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0005499748245558885		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.0005499748245558885 | validation: 0.0008182063901000793]
	TIME [epoch: 49.6 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0009092051099577709		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.0009092051099577709 | validation: 0.0010688374733303484]
	TIME [epoch: 49.6 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0002809574497435143		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.0002809574497435143 | validation: 0.0007520751640829593]
	TIME [epoch: 49.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.285187244641712e-05		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 9.285187244641712e-05 | validation: 0.0013818757788941177]
	TIME [epoch: 49.6 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00026245585818355767		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: -0.00026245585818355767 | validation: -0.00011273614829019741]
	TIME [epoch: 49.6 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0006291968141012513		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.0006291968141012513 | validation: 0.0007616338621190342]
	TIME [epoch: 49.6 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0014535780765786795		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.0014535780765786795 | validation: 0.002469124082777205]
	TIME [epoch: 49.6 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.001982475604111236		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.001982475604111236 | validation: 0.0001272390075796701]
	TIME [epoch: 49.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00044724763965150354		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.00044724763965150354 | validation: 3.741353709701208e-05]
	TIME [epoch: 49.6 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0004458669392574408		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.0004458669392574408 | validation: 0.000542386746946478]
	TIME [epoch: 49.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00012611283833831877		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.00012611283833831877 | validation: 0.0006458200132615134]
	TIME [epoch: 49.6 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.873637992500846e-05		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 5.873637992500846e-05 | validation: 0.0003405982387522304]
	TIME [epoch: 49.6 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: -0.00021289459447337066		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: -0.00021289459447337066 | validation: 0.0002929259482745974]
	TIME [epoch: 49.6 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.00022388519164497086		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.00022388519164497086 | validation: 0.0006322340225746852]
	TIME [epoch: 49.6 sec]
EPOCH 876/2000:
	Training over batches...
