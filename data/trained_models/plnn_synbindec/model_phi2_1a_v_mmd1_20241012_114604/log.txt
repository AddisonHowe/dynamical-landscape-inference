Args:
Namespace(name='model_phi2_1a_v_mmd1', outdir='out/model_training/model_phi2_1a_v_mmd1', training_data='data/training_data/basic/data_phi2_1a/training', validation_data='data/training_data/basic/data_phi2_1a/validation', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, passes_per_epoch=1, batch_size=250, patience=100, min_epochs=500, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.1, nan_max_attempts=4, quadratic_a=1.0, quadratic_b=1.0, ndims=2, nparams=2, nsigs=2, ncells=200, ncells_sample=0, model_do_sample=True, dt=0.1, dt_schedule='stepped', dt_schedule_bounds=[200, 500, 1000], dt_schedule_scales=[0.5, 0.5, 0.5], signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.0], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.0], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='mmd', kernel='multiscale', bw_range=[0.2, 0.5, 0.9, 1.3], optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot_radius=4, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2009061570

Training model...

Saving initial model state to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5251752727866155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5251752727866155 | validation: 4.520931677783164]
	TIME [epoch: 112 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.458693927788076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.458693927788076 | validation: 3.0283156384307057]
	TIME [epoch: 13.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.273524676174674		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.273524676174674 | validation: 3.0339601214979997]
	TIME [epoch: 13.2 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.451307316907048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.451307316907048 | validation: 3.4364894426088832]
	TIME [epoch: 13.2 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4737475320652336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4737475320652336 | validation: 1.9286402864206333]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2157718917838745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2157718917838745 | validation: 2.008007655595015]
	TIME [epoch: 13.2 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8836253502835012		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8836253502835012 | validation: 1.7834202383391655]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6884886258585141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6884886258585141 | validation: 2.382804408117608]
	TIME [epoch: 13.2 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4897794416383356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4897794416383356 | validation: 1.2877318493877894]
	TIME [epoch: 13.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5167497247594504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5167497247594504 | validation: 2.105265709902792]
	TIME [epoch: 13.2 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5682210506042242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5682210506042242 | validation: 0.7835531526024908]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9880728432242296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9880728432242296 | validation: 0.6111361908621564]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9500809243405612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9500809243405612 | validation: 1.0826210969602306]
	TIME [epoch: 13.3 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8848008170240544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8848008170240544 | validation: 1.1538012412691145]
	TIME [epoch: 13.3 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8462766989232821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8462766989232821 | validation: 0.8683589021833196]
	TIME [epoch: 13.2 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744220083322522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.744220083322522 | validation: 0.8453646919718911]
	TIME [epoch: 13.3 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080915184975002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7080915184975002 | validation: 0.7050825714116373]
	TIME [epoch: 13.2 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644301572565912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7644301572565912 | validation: 0.7825327855540385]
	TIME [epoch: 13.2 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250127483559919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7250127483559919 | validation: 0.7382256779590631]
	TIME [epoch: 13.2 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6808915624166988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6808915624166988 | validation: 0.8410183544941178]
	TIME [epoch: 13.2 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6981776398703249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6981776398703249 | validation: 0.5616801741245181]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6532081702250505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6532081702250505 | validation: 0.9273808944116296]
	TIME [epoch: 13.2 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339053235356853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7339053235356853 | validation: 0.7616580393539312]
	TIME [epoch: 13.2 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6630820832270772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6630820832270772 | validation: 0.716772445854472]
	TIME [epoch: 13.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049429772933395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7049429772933395 | validation: 0.6555437005436247]
	TIME [epoch: 13.2 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6774964252275163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6774964252275163 | validation: 0.6611934210261629]
	TIME [epoch: 13.2 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6795059780779338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6795059780779338 | validation: 0.6800006992127399]
	TIME [epoch: 13.2 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473144298396607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6473144298396607 | validation: 0.6819571748596265]
	TIME [epoch: 13.2 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6940690261814805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6940690261814805 | validation: 0.5714074079893416]
	TIME [epoch: 13.2 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306884202361737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6306884202361737 | validation: 0.7466296882703611]
	TIME [epoch: 13.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806130567105471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5806130567105471 | validation: 0.828727767218587]
	TIME [epoch: 13.2 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730955768645105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7730955768645105 | validation: 0.5485116699623785]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621070694550135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.621070694550135 | validation: 0.6424155211401918]
	TIME [epoch: 13.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6452600789866498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6452600789866498 | validation: 0.47345831310959324]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5591963145824362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5591963145824362 | validation: 0.8047099566539498]
	TIME [epoch: 13.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736600981211768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6736600981211768 | validation: 0.6833951537277891]
	TIME [epoch: 13.2 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6389234416426055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6389234416426055 | validation: 0.6368475376281713]
	TIME [epoch: 13.2 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6116238030982961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6116238030982961 | validation: 0.5987544937958524]
	TIME [epoch: 13.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5867166935775442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5867166935775442 | validation: 0.6329743716665719]
	TIME [epoch: 13.2 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6096677359720708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6096677359720708 | validation: 0.5682228261511723]
	TIME [epoch: 13.2 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5606206682014775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5606206682014775 | validation: 0.6624203572685357]
	TIME [epoch: 13.2 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6145412679905473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6145412679905473 | validation: 0.5603926781876448]
	TIME [epoch: 13.2 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6659356412748257		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6659356412748257 | validation: 0.5791900097443149]
	TIME [epoch: 13.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5749409919768765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5749409919768765 | validation: 0.7004957109174326]
	TIME [epoch: 13.2 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950645740363472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5950645740363472 | validation: 0.44699310454337793]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.584791566293001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.584791566293001 | validation: 0.6442244292581198]
	TIME [epoch: 13.3 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801387171452199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5801387171452199 | validation: 0.5612743429943046]
	TIME [epoch: 13.2 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5573560526580033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5573560526580033 | validation: 0.590694722428639]
	TIME [epoch: 13.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578815927876658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.578815927876658 | validation: 0.5002725621173204]
	TIME [epoch: 13.2 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6192791234329451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6192791234329451 | validation: 0.6636788732226806]
	TIME [epoch: 13.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.598543972448521		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 0.598543972448521 | validation: 0.5075255652203075]
	TIME [epoch: 13.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049995384963797		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 0.5049995384963797 | validation: 0.6100902586982353]
	TIME [epoch: 13.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5750678779619411		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 0.5750678779619411 | validation: 0.4363575544203594]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5438164121191573		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 0.5438164121191573 | validation: 0.5445401539722952]
	TIME [epoch: 13.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612259897851717		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 0.5612259897851717 | validation: 0.4781044578523861]
	TIME [epoch: 13.2 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515863023009554		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 0.515863023009554 | validation: 0.5047009735936304]
	TIME [epoch: 13.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574345828503879		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 0.5574345828503879 | validation: 0.6829241577750467]
	TIME [epoch: 13.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924590476055792		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 0.5924590476055792 | validation: 0.4422294720643738]
	TIME [epoch: 13.2 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467026264758481		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 0.5467026264758481 | validation: 0.5269394469387043]
	TIME [epoch: 13.2 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5444032548693676		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 0.5444032548693676 | validation: 0.45173886566876365]
	TIME [epoch: 13.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508947674170277		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 0.5508947674170277 | validation: 0.49431435193910866]
	TIME [epoch: 13.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199083267979427		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 0.5199083267979427 | validation: 0.4453337855894392]
	TIME [epoch: 13.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5347208088330879		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 0.5347208088330879 | validation: 0.6909342747356262]
	TIME [epoch: 13.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445306171696412		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 0.5445306171696412 | validation: 0.5949238019749701]
	TIME [epoch: 13.2 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579851899291448		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 0.5579851899291448 | validation: 0.5117030635396008]
	TIME [epoch: 13.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5090979462159888		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 0.5090979462159888 | validation: 0.5007257003433974]
	TIME [epoch: 13.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977104725102723		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 0.4977104725102723 | validation: 0.5752179822251332]
	TIME [epoch: 13.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818377823124936		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 0.5818377823124936 | validation: 0.5208490039762294]
	TIME [epoch: 13.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47637272144582504		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 0.47637272144582504 | validation: 0.3512085414435423]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091312073557622		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 0.5091312073557622 | validation: 0.4468513875487008]
	TIME [epoch: 13.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217835569173772		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 0.5217835569173772 | validation: 0.4561241886390405]
	TIME [epoch: 13.2 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227242546638303		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 0.5227242546638303 | validation: 0.37474680769467106]
	TIME [epoch: 13.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567453639713787		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 0.5567453639713787 | validation: 0.3468437484500059]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497190673665775		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 0.4497190673665775 | validation: 0.6685366571223887]
	TIME [epoch: 13.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389463919469546		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 0.5389463919469546 | validation: 0.5234986617074467]
	TIME [epoch: 13.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164531720702575		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 0.5164531720702575 | validation: 0.4220667492272403]
	TIME [epoch: 13.2 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47703181878412526		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 0.47703181878412526 | validation: 0.5057184412617753]
	TIME [epoch: 13.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072272968965503		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 0.5072272968965503 | validation: 0.5026594970463719]
	TIME [epoch: 13.2 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4718917019370816		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 0.4718917019370816 | validation: 0.536260583015868]
	TIME [epoch: 13.2 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44405519706072727		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 0.44405519706072727 | validation: 0.3689513798032442]
	TIME [epoch: 13.2 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377865322827684		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 0.5377865322827684 | validation: 0.39179845151977977]
	TIME [epoch: 13.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44447060033579916		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 0.44447060033579916 | validation: 0.5689450248520778]
	TIME [epoch: 13.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48876854268665665		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 0.48876854268665665 | validation: 0.32373079394258375]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4402130076876808		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 0.4402130076876808 | validation: 0.6295179968841846]
	TIME [epoch: 13.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44334610860987844		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 0.44334610860987844 | validation: 0.3397608332334874]
	TIME [epoch: 13.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5143975105960028		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 0.5143975105960028 | validation: 0.4183994190633348]
	TIME [epoch: 13.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025262033306139		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 0.5025262033306139 | validation: 0.3797147159782919]
	TIME [epoch: 13.2 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418788323847983		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 0.418788323847983 | validation: 0.33845793718455686]
	TIME [epoch: 13.2 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4695241795206443		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 0.4695241795206443 | validation: 0.47131331882413946]
	TIME [epoch: 13.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46285051030536817		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 0.46285051030536817 | validation: 0.45314456536144593]
	TIME [epoch: 13.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4480214557237698		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 0.4480214557237698 | validation: 0.5301474275575021]
	TIME [epoch: 13.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4535795961349061		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 0.4535795961349061 | validation: 0.3796109402314386]
	TIME [epoch: 13.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4488613310978554		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 0.4488613310978554 | validation: 0.3549308575296623]
	TIME [epoch: 13.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232833832528709		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 0.4232833832528709 | validation: 0.37536439428808505]
	TIME [epoch: 13.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44008265252318235		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 0.44008265252318235 | validation: 0.505322919560542]
	TIME [epoch: 13.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4665222949089284		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 0.4665222949089284 | validation: 0.4142698142620378]
	TIME [epoch: 13.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39357989368532104		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 0.39357989368532104 | validation: 0.30391776358965256]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4697392269312255		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 0.4697392269312255 | validation: 0.4145063179973233]
	TIME [epoch: 13.2 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411865056222244		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 0.4411865056222244 | validation: 0.3874837668809379]
	TIME [epoch: 13.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43188523373244514		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 0.43188523373244514 | validation: 0.3231918146611119]
	TIME [epoch: 13.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43461102875745494		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 0.43461102875745494 | validation: 0.31924473706315326]
	TIME [epoch: 13.2 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43409791757618144		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 0.43409791757618144 | validation: 0.31067545666506013]
	TIME [epoch: 13.2 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41200260381595455		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 0.41200260381595455 | validation: 0.29860679654544453]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129458330041065		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 0.4129458330041065 | validation: 0.31968389802372243]
	TIME [epoch: 13.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43437225700033466		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 0.43437225700033466 | validation: 0.29354049713671365]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42184219673282525		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 0.42184219673282525 | validation: 0.29230035687485084]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.435562078174293		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 0.435562078174293 | validation: 0.30023436940661086]
	TIME [epoch: 13.2 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41788857190775264		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 0.41788857190775264 | validation: 0.32891337761600153]
	TIME [epoch: 13.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39858161612162146		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 0.39858161612162146 | validation: 0.2866300521233201]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43594120681879633		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 0.43594120681879633 | validation: 0.31686687093124843]
	TIME [epoch: 13.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38856417103487806		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 0.38856417103487806 | validation: 0.30220683318052716]
	TIME [epoch: 13.2 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4230508117372101		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 0.4230508117372101 | validation: 0.39063273892014627]
	TIME [epoch: 13.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983625946595526		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 0.3983625946595526 | validation: 0.36267517818970274]
	TIME [epoch: 13.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805315829046798		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 0.3805315829046798 | validation: 0.35576971006682534]
	TIME [epoch: 13.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43478099146744364		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 0.43478099146744364 | validation: 0.32308222179324314]
	TIME [epoch: 13.2 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37180184738355737		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.37180184738355737 | validation: 0.3316405379790426]
	TIME [epoch: 13.2 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4384939239279521		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 0.4384939239279521 | validation: 0.2749526217266622]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3580656073906711		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.3580656073906711 | validation: 0.40773152416658365]
	TIME [epoch: 13.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42439252727954396		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.42439252727954396 | validation: 0.3114092200719017]
	TIME [epoch: 13.2 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39823508334015867		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 0.39823508334015867 | validation: 0.2682021372762167]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3817428028167004		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 0.3817428028167004 | validation: 0.26654396201537023]
	TIME [epoch: 13.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3697898108095371		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.3697898108095371 | validation: 0.2982360409395345]
	TIME [epoch: 13.2 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3637497276325081		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.3637497276325081 | validation: 0.443133028480183]
	TIME [epoch: 13.2 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4211340611336133		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.4211340611336133 | validation: 0.310459840806673]
	TIME [epoch: 13.2 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37931998702951364		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.37931998702951364 | validation: 0.31326631526951726]
	TIME [epoch: 13.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793478180528125		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.3793478180528125 | validation: 0.3536593008145591]
	TIME [epoch: 13.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810362438831422		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.3810362438831422 | validation: 0.2661712706632884]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3709483787199378		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 0.3709483787199378 | validation: 0.42099482318607195]
	TIME [epoch: 13.2 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39536819321109984		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.39536819321109984 | validation: 0.42818306280464746]
	TIME [epoch: 13.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37928844040990534		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 0.37928844040990534 | validation: 0.2689762123575651]
	TIME [epoch: 13.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811425755661721		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.3811425755661721 | validation: 0.28594184084601687]
	TIME [epoch: 13.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33679384357929176		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.33679384357929176 | validation: 0.311896747219566]
	TIME [epoch: 13.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38123449269616566		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.38123449269616566 | validation: 0.2993159292642337]
	TIME [epoch: 13.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36535248902701745		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.36535248902701745 | validation: 0.31968494131555214]
	TIME [epoch: 13.2 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3528277877074318		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.3528277877074318 | validation: 0.37828394292192546]
	TIME [epoch: 13.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35895382944079957		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.35895382944079957 | validation: 0.25316879918363555]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.379044584817966		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.379044584817966 | validation: 0.287571223953657]
	TIME [epoch: 13.2 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33643333873272036		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.33643333873272036 | validation: 0.23963803923159704]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753182738763233		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.3753182738763233 | validation: 0.2488979061573724]
	TIME [epoch: 13.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3599394552770988		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.3599394552770988 | validation: 0.2835794690185526]
	TIME [epoch: 13.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3356735439179049		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.3356735439179049 | validation: 0.24946310274164138]
	TIME [epoch: 13.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3631264922589534		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.3631264922589534 | validation: 0.24106838360412822]
	TIME [epoch: 13.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573513924774139		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.3573513924774139 | validation: 0.2793040884654767]
	TIME [epoch: 13.2 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3442439255535602		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.3442439255535602 | validation: 0.39073171365648635]
	TIME [epoch: 13.2 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516339493933387		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.3516339493933387 | validation: 0.26956618232846974]
	TIME [epoch: 13.2 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3285631570543418		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.3285631570543418 | validation: 0.3130117040021302]
	TIME [epoch: 13.2 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3687556916776298		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.3687556916776298 | validation: 0.3143082748050302]
	TIME [epoch: 13.2 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35255031011794546		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.35255031011794546 | validation: 0.32975011748810246]
	TIME [epoch: 13.2 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3544228600722476		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.3544228600722476 | validation: 0.3109200835731514]
	TIME [epoch: 13.2 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32852134784721804		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.32852134784721804 | validation: 0.21377943370646824]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34753690999697906		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.34753690999697906 | validation: 0.22151755499585146]
	TIME [epoch: 13.2 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32860071144333136		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.32860071144333136 | validation: 0.27880170936805704]
	TIME [epoch: 13.2 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34405153777695824		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.34405153777695824 | validation: 0.21663570674399468]
	TIME [epoch: 13.2 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3163442020520536		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.3163442020520536 | validation: 0.2335139553628343]
	TIME [epoch: 13.2 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34085715170597547		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.34085715170597547 | validation: 0.21419954950523365]
	TIME [epoch: 13.2 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31869578802548093		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.31869578802548093 | validation: 0.2648256268419834]
	TIME [epoch: 13.2 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3279282674147388		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.3279282674147388 | validation: 0.23277158213620963]
	TIME [epoch: 13.2 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071784253225684		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.3071784253225684 | validation: 0.2336922477768793]
	TIME [epoch: 13.2 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3491664487272553		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.3491664487272553 | validation: 0.20125321168421811]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_159.pth
	Model improved!!!
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30618204161106743		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.30618204161106743 | validation: 0.2386693092479398]
	TIME [epoch: 13.2 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3280577896209266		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.3280577896209266 | validation: 0.22158329176905273]
	TIME [epoch: 13.2 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3233236497029694		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.3233236497029694 | validation: 0.21760301912593566]
	TIME [epoch: 13.2 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29984708516081726		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.29984708516081726 | validation: 0.2101964039418437]
	TIME [epoch: 13.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3086545163891562		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.3086545163891562 | validation: 0.2270586589884174]
	TIME [epoch: 13.2 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3166711344660254		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.3166711344660254 | validation: 0.22818048208823166]
	TIME [epoch: 13.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3340652757014972		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.3340652757014972 | validation: 0.2269755841231202]
	TIME [epoch: 13.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.299502385850941		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.299502385850941 | validation: 0.20735809817541154]
	TIME [epoch: 13.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3103275425342114		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.3103275425342114 | validation: 0.20670036508574705]
	TIME [epoch: 13.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3124299283987866		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.3124299283987866 | validation: 0.1898810588970294]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116179103514741		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.3116179103514741 | validation: 0.19198393598891517]
	TIME [epoch: 13.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189892434448326		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.3189892434448326 | validation: 0.20304803340333147]
	TIME [epoch: 13.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925444101450633		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.2925444101450633 | validation: 0.1881801718215755]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3152990210527978		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.3152990210527978 | validation: 0.1847880899932124]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2844677936019225		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.2844677936019225 | validation: 0.18856404349458747]
	TIME [epoch: 13.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950035396958038		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.2950035396958038 | validation: 0.24035662577587263]
	TIME [epoch: 13.2 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029769238961365		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.3029769238961365 | validation: 0.21766361760324476]
	TIME [epoch: 13.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093775555285545		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.3093775555285545 | validation: 0.19356393407837091]
	TIME [epoch: 13.2 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28518975484657416		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.28518975484657416 | validation: 0.19134250008631548]
	TIME [epoch: 13.2 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939569294236564		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.2939569294236564 | validation: 0.19069012056103243]
	TIME [epoch: 13.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29404652288591365		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.29404652288591365 | validation: 0.24281050972116225]
	TIME [epoch: 13.2 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28636003714937047		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.28636003714937047 | validation: 0.1669110546299306]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2896539964532204		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.2896539964532204 | validation: 0.20866681101533704]
	TIME [epoch: 13.2 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28490675761849843		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.28490675761849843 | validation: 0.1822585582527341]
	TIME [epoch: 13.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914783456804177		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.2914783456804177 | validation: 0.1813671885556803]
	TIME [epoch: 13.2 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279580504491726		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.279580504491726 | validation: 0.2421886804597128]
	TIME [epoch: 13.2 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3119201107475746		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.3119201107475746 | validation: 0.16976020320736643]
	TIME [epoch: 13.2 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27782295580469896		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.27782295580469896 | validation: 0.19910431451195262]
	TIME [epoch: 13.2 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29031029949217424		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.29031029949217424 | validation: 0.1757963989107392]
	TIME [epoch: 13.2 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856408319569176		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.2856408319569176 | validation: 0.16269579118131866]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_189.pth
	Model improved!!!
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28645048836619386		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.28645048836619386 | validation: 0.16590299181280402]
	TIME [epoch: 13.2 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27184479710690157		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.27184479710690157 | validation: 0.17580521886619538]
	TIME [epoch: 13.2 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28878910739843283		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.28878910739843283 | validation: 0.16987187688747402]
	TIME [epoch: 13.2 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28591130422033156		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.28591130422033156 | validation: 0.21058597192255657]
	TIME [epoch: 13.2 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2805318262255181		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.2805318262255181 | validation: 0.1737174582082761]
	TIME [epoch: 13.2 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28006087659583057		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.28006087659583057 | validation: 0.17579258369822093]
	TIME [epoch: 13.2 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28666081788348285		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.28666081788348285 | validation: 0.1703064381922001]
	TIME [epoch: 13.2 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28923539088262024		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.28923539088262024 | validation: 0.1615528404827834]
	TIME [epoch: 13.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28349826548614276		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.28349826548614276 | validation: 0.17614121850074807]
	TIME [epoch: 13.2 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2795751491055562		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.2795751491055562 | validation: 0.18134399527931366]
	TIME [epoch: 13.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848577710733272		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.2848577710733272 | validation: 0.18988240860642985]
	TIME [epoch: 13.2 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28623723707703835		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.28623723707703835 | validation: 0.16070805725472143]
	TIME [epoch: 122 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28789183668622587		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.28789183668622587 | validation: 0.1716116590712204]
	TIME [epoch: 25.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28297381070481314		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.28297381070481314 | validation: 0.17943140021462706]
	TIME [epoch: 25.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2777106694285989		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.2777106694285989 | validation: 0.16323095109045202]
	TIME [epoch: 25.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804431260898908		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.2804431260898908 | validation: 0.1771011989969143]
	TIME [epoch: 25.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29567140051578356		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.29567140051578356 | validation: 0.16147877947823688]
	TIME [epoch: 25.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.268249566814448		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.268249566814448 | validation: 0.1586664732948955]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26687321263000086		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.26687321263000086 | validation: 0.15859690539147842]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2907652131660301		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.2907652131660301 | validation: 0.16044977676633865]
	TIME [epoch: 25.4 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27518727421855227		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.27518727421855227 | validation: 0.16759588848638848]
	TIME [epoch: 25.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2760641816776227		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.2760641816776227 | validation: 0.18346741789924131]
	TIME [epoch: 25.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846446526352211		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.2846446526352211 | validation: 0.15666450628663386]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_212.pth
	Model improved!!!
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27465823003498746		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.27465823003498746 | validation: 0.1616260833995713]
	TIME [epoch: 25.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26929409276015914		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.26929409276015914 | validation: 0.16022224192299866]
	TIME [epoch: 25.4 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688354752214371		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.2688354752214371 | validation: 0.1823517642826841]
	TIME [epoch: 25.4 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28583648528507055		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.28583648528507055 | validation: 0.1812487139214307]
	TIME [epoch: 25.4 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27429585378452326		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.27429585378452326 | validation: 0.15599495721691095]
	TIME [epoch: 25.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_217.pth
	Model improved!!!
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26665973536938636		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.26665973536938636 | validation: 0.20897532330284393]
	TIME [epoch: 25.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27614066765044426		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.27614066765044426 | validation: 0.15473658763894033]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274425413205139		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.274425413205139 | validation: 0.17453775686352596]
	TIME [epoch: 25.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28593730024625147		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.28593730024625147 | validation: 0.15407548395366397]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27434615837676835		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.27434615837676835 | validation: 0.1728336429231064]
	TIME [epoch: 25.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694510865719481		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.2694510865719481 | validation: 0.16076867801420286]
	TIME [epoch: 25.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2703543083247323		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.2703543083247323 | validation: 0.1551648013690701]
	TIME [epoch: 25.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812108897638573		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.2812108897638573 | validation: 0.1755215909544412]
	TIME [epoch: 25.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2740125830714242		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.2740125830714242 | validation: 0.15350688371864327]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26851080939551114		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.26851080939551114 | validation: 0.16150608548572232]
	TIME [epoch: 25.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710807566223512		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.2710807566223512 | validation: 0.1703528649568795]
	TIME [epoch: 25.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27577489803618804		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.27577489803618804 | validation: 0.17142690838995292]
	TIME [epoch: 25.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2718918965631103		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.2718918965631103 | validation: 0.16143027584209818]
	TIME [epoch: 25.4 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2753147660678945		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.2753147660678945 | validation: 0.16185993971249785]
	TIME [epoch: 25.4 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26779279590713145		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.26779279590713145 | validation: 0.1555869754996388]
	TIME [epoch: 25.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27019174875725943		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.27019174875725943 | validation: 0.155426675484831]
	TIME [epoch: 25.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27493402926091737		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.27493402926091737 | validation: 0.17977460301055662]
	TIME [epoch: 25.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2797444061076908		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.2797444061076908 | validation: 0.15499326432121208]
	TIME [epoch: 25.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2698299438822034		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.2698299438822034 | validation: 0.1559278051084106]
	TIME [epoch: 25.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27161142618047635		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.27161142618047635 | validation: 0.1489042863530155]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632436017085178		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.2632436017085178 | validation: 0.16614822057880624]
	TIME [epoch: 25.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27069803413808174		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.27069803413808174 | validation: 0.1496841668985829]
	TIME [epoch: 25.4 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26287375105895444		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.26287375105895444 | validation: 0.1716994563651724]
	TIME [epoch: 25.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847027709903278		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.2847027709903278 | validation: 0.16608259447448898]
	TIME [epoch: 25.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2694350741358597		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.2694350741358597 | validation: 0.15609902222661715]
	TIME [epoch: 25.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26547129425991267		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.26547129425991267 | validation: 0.15886032301228506]
	TIME [epoch: 25.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699676726535472		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.2699676726535472 | validation: 0.15540498486347173]
	TIME [epoch: 25.4 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27646405669247365		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.27646405669247365 | validation: 0.1649179378709069]
	TIME [epoch: 25.4 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.269075821051989		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.269075821051989 | validation: 0.15019424020962774]
	TIME [epoch: 25.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677675227654799		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.2677675227654799 | validation: 0.1670888418111742]
	TIME [epoch: 25.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26654698208002514		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.26654698208002514 | validation: 0.15445777895122823]
	TIME [epoch: 25.4 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274493628810358		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.274493628810358 | validation: 0.14670730708898436]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26680564188186884		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.26680564188186884 | validation: 0.1507117322162345]
	TIME [epoch: 25.4 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26762945813014294		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.26762945813014294 | validation: 0.16172348753619298]
	TIME [epoch: 25.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27422945149958244		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.27422945149958244 | validation: 0.14728469235955177]
	TIME [epoch: 25.4 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26631409060179956		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.26631409060179956 | validation: 0.15725213605442764]
	TIME [epoch: 25.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671381581208288		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.2671381581208288 | validation: 0.15663992337696575]
	TIME [epoch: 25.4 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26572226184661557		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.26572226184661557 | validation: 0.1609854812705078]
	TIME [epoch: 25.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650166615188268		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.2650166615188268 | validation: 0.16066297036639127]
	TIME [epoch: 25.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2737738433868117		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.2737738433868117 | validation: 0.1845418856456072]
	TIME [epoch: 25.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2720043142854525		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.2720043142854525 | validation: 0.1515868561819503]
	TIME [epoch: 25.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624088017060359		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.2624088017060359 | validation: 0.14784189144561616]
	TIME [epoch: 25.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637847820223009		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.2637847820223009 | validation: 0.15516593017946056]
	TIME [epoch: 25.4 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727202151317763		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.2727202151317763 | validation: 0.152757217657964]
	TIME [epoch: 25.4 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624358492206247		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.2624358492206247 | validation: 0.15051872456914328]
	TIME [epoch: 25.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659708930292783		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.2659708930292783 | validation: 0.15412333646571694]
	TIME [epoch: 25.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2766944124075826		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.2766944124075826 | validation: 0.15541407984760613]
	TIME [epoch: 25.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26682164123512675		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.26682164123512675 | validation: 0.1521518796574948]
	TIME [epoch: 25.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26059118771704504		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.26059118771704504 | validation: 0.15752144569801318]
	TIME [epoch: 25.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744437941646012		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.2744437941646012 | validation: 0.14610884081759723]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_267.pth
	Model improved!!!
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26788363799239956		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.26788363799239956 | validation: 0.14618591788434881]
	TIME [epoch: 25.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26180586476132317		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.26180586476132317 | validation: 0.15872258725745225]
	TIME [epoch: 25.4 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692177860000069		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.2692177860000069 | validation: 0.14685383900993]
	TIME [epoch: 25.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666667784770974		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.2666667784770974 | validation: 0.14829101685786175]
	TIME [epoch: 25.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2684706586096077		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.2684706586096077 | validation: 0.15237949262980013]
	TIME [epoch: 25.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672302809721736		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.2672302809721736 | validation: 0.14871975772077867]
	TIME [epoch: 25.4 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26784133737846255		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.26784133737846255 | validation: 0.14604065951626638]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_274.pth
	Model improved!!!
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26182750866991517		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.26182750866991517 | validation: 0.1541930492691267]
	TIME [epoch: 25.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26842086767177714		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.26842086767177714 | validation: 0.1483022811489081]
	TIME [epoch: 25.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26384834908287635		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.26384834908287635 | validation: 0.15127907775252933]
	TIME [epoch: 25.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2713030296433632		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.2713030296433632 | validation: 0.15693340634970654]
	TIME [epoch: 25.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263854776421288		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.263854776421288 | validation: 0.14929640851276776]
	TIME [epoch: 25.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2671415207292232		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.2671415207292232 | validation: 0.14817886144094577]
	TIME [epoch: 25.3 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26735720159086473		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.26735720159086473 | validation: 0.15429616982151123]
	TIME [epoch: 25.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624018732671157		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.2624018732671157 | validation: 0.15163268293250787]
	TIME [epoch: 25.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26449801458993716		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.26449801458993716 | validation: 0.1670842391840539]
	TIME [epoch: 25.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26974828477070223		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.26974828477070223 | validation: 0.14626259585897453]
	TIME [epoch: 25.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2636278062364619		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.2636278062364619 | validation: 0.15074044935630293]
	TIME [epoch: 25.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263671086303201		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.263671086303201 | validation: 0.15072761906292342]
	TIME [epoch: 25.4 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26637020607149886		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.26637020607149886 | validation: 0.1643171697496843]
	TIME [epoch: 25.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26841553824856024		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.26841553824856024 | validation: 0.14628766642377608]
	TIME [epoch: 25.4 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.261250131701217		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.261250131701217 | validation: 0.14671608101650388]
	TIME [epoch: 25.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26462929666842133		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.26462929666842133 | validation: 0.148243910914038]
	TIME [epoch: 25.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651735938405318		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2651735938405318 | validation: 0.15135019164568328]
	TIME [epoch: 25.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26261501727039926		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.26261501727039926 | validation: 0.15668121558752113]
	TIME [epoch: 25.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.266111028916239		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.266111028916239 | validation: 0.14889543079751147]
	TIME [epoch: 25.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2692443100841323		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.2692443100841323 | validation: 0.14609349082359765]
	TIME [epoch: 25.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25736828413108287		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.25736828413108287 | validation: 0.15137858308982277]
	TIME [epoch: 25.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26339855068656903		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.26339855068656903 | validation: 0.149572573372805]
	TIME [epoch: 25.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599357654467758		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.2599357654467758 | validation: 0.1511879284301909]
	TIME [epoch: 25.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624981394442684		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.2624981394442684 | validation: 0.14719008451565907]
	TIME [epoch: 25.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2723286805426628		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.2723286805426628 | validation: 0.16287353884576966]
	TIME [epoch: 25.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26309694014678525		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.26309694014678525 | validation: 0.14694161091415633]
	TIME [epoch: 25.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26308440060795024		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.26308440060795024 | validation: 0.1458091195778789]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26686337169765667		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.26686337169765667 | validation: 0.14638942518182207]
	TIME [epoch: 25.4 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2592042044941619		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.2592042044941619 | validation: 0.14993489579266742]
	TIME [epoch: 25.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26137747533795147		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.26137747533795147 | validation: 0.15914204632747814]
	TIME [epoch: 25.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26712089419833024		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.26712089419833024 | validation: 0.14726576421915666]
	TIME [epoch: 25.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621830372773919		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.2621830372773919 | validation: 0.15292930125964527]
	TIME [epoch: 25.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652262207376028		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.2652262207376028 | validation: 0.15752688019443645]
	TIME [epoch: 25.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263441034054475		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.263441034054475 | validation: 0.1549095675505337]
	TIME [epoch: 25.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26289314043283935		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.26289314043283935 | validation: 0.14565651777269242]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_309.pth
	Model improved!!!
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2601091306907779		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.2601091306907779 | validation: 0.15259204268547974]
	TIME [epoch: 25.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677117599176431		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.2677117599176431 | validation: 0.1506017197819452]
	TIME [epoch: 25.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602021853342032		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.2602021853342032 | validation: 0.15130298930272798]
	TIME [epoch: 25.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26565897393701177		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.26565897393701177 | validation: 0.14514524137162063]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619525837137343		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.2619525837137343 | validation: 0.14932986397154108]
	TIME [epoch: 25.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26000360381938026		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.26000360381938026 | validation: 0.1451688602687104]
	TIME [epoch: 25.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2607280758097259		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2607280758097259 | validation: 0.16647430897412352]
	TIME [epoch: 25.4 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2637674403391035		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.2637674403391035 | validation: 0.14846065494479435]
	TIME [epoch: 25.4 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621427818272104		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.2621427818272104 | validation: 0.15462416747727362]
	TIME [epoch: 25.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29954476148642467		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.29954476148642467 | validation: 0.178262597855493]
	TIME [epoch: 25.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27227273991159945		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.27227273991159945 | validation: 0.14944842930215552]
	TIME [epoch: 25.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25798489040540373		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.25798489040540373 | validation: 0.14611546256820557]
	TIME [epoch: 25.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2610609582732204		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.2610609582732204 | validation: 0.14793458297527823]
	TIME [epoch: 25.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26209258588249534		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.26209258588249534 | validation: 0.1479038475330536]
	TIME [epoch: 25.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26284730144932256		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.26284730144932256 | validation: 0.1456580989223828]
	TIME [epoch: 25.4 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26000677451318294		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.26000677451318294 | validation: 0.15104034476042957]
	TIME [epoch: 25.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649931404076183		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.2649931404076183 | validation: 0.15736452319849314]
	TIME [epoch: 25.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25869957766305796		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.25869957766305796 | validation: 0.14197981687023212]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26411400177452743		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.26411400177452743 | validation: 0.15254175027487504]
	TIME [epoch: 25.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26309073755235995		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.26309073755235995 | validation: 0.150709257549402]
	TIME [epoch: 25.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26048468400593483		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.26048468400593483 | validation: 0.14342289244172035]
	TIME [epoch: 25.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572399359805968		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.2572399359805968 | validation: 0.15570444168760117]
	TIME [epoch: 25.4 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2691984821131319		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.2691984821131319 | validation: 0.14437809320141665]
	TIME [epoch: 25.4 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26396587711513053		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.26396587711513053 | validation: 0.14418170023600912]
	TIME [epoch: 25.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594760705166672		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.2594760705166672 | validation: 0.1444253341450503]
	TIME [epoch: 25.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605710389718122		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.2605710389718122 | validation: 0.16508146824123188]
	TIME [epoch: 25.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2609931662469114		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.2609931662469114 | validation: 0.14234566096972956]
	TIME [epoch: 25.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2576885459879488		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2576885459879488 | validation: 0.14594193021058108]
	TIME [epoch: 25.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26273307780249255		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.26273307780249255 | validation: 0.15162158479687854]
	TIME [epoch: 25.4 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590399851547974		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2590399851547974 | validation: 0.14955849086364786]
	TIME [epoch: 25.4 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624936016048116		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.2624936016048116 | validation: 0.14932231744100832]
	TIME [epoch: 25.4 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25856608911391454		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.25856608911391454 | validation: 0.14726951707211738]
	TIME [epoch: 25.4 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25819548837982553		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.25819548837982553 | validation: 0.14734257116948699]
	TIME [epoch: 25.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2680332002007426		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.2680332002007426 | validation: 0.14344277902425595]
	TIME [epoch: 25.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2575949706631705		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.2575949706631705 | validation: 0.1451569863600604]
	TIME [epoch: 25.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.263715593196311		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.263715593196311 | validation: 0.14326671687965203]
	TIME [epoch: 25.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25875129642548306		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.25875129642548306 | validation: 0.14229874880267343]
	TIME [epoch: 25.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2623873869226686		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2623873869226686 | validation: 0.1535345770089896]
	TIME [epoch: 25.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598231944620145		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.2598231944620145 | validation: 0.1439123287762186]
	TIME [epoch: 25.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2628240660593394		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.2628240660593394 | validation: 0.14625907885382636]
	TIME [epoch: 25.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588883563712151		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2588883563712151 | validation: 0.14514468254990082]
	TIME [epoch: 25.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25917702370466406		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.25917702370466406 | validation: 0.15125711208917922]
	TIME [epoch: 25.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259262407320246		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.259262407320246 | validation: 0.14460003844167113]
	TIME [epoch: 25.4 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618268630588571		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.2618268630588571 | validation: 0.14959108202315063]
	TIME [epoch: 25.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2634008443641418		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.2634008443641418 | validation: 0.14352128969454772]
	TIME [epoch: 25.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2553321522717628		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.2553321522717628 | validation: 0.14470822208167197]
	TIME [epoch: 25.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598513267490954		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.2598513267490954 | validation: 0.14481131656080176]
	TIME [epoch: 25.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632766005971776		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2632766005971776 | validation: 0.14696142928569547]
	TIME [epoch: 25.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25726617003226315		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.25726617003226315 | validation: 0.1427525074624311]
	TIME [epoch: 25.4 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2606344537951397		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2606344537951397 | validation: 0.14541639576861998]
	TIME [epoch: 25.4 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25552142866098787		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.25552142866098787 | validation: 0.14296805560008383]
	TIME [epoch: 25.3 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25914832926944464		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.25914832926944464 | validation: 0.1501255855576408]
	TIME [epoch: 25.4 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2653648453460672		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.2653648453460672 | validation: 0.14393369620994897]
	TIME [epoch: 25.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25653290873817897		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.25653290873817897 | validation: 0.1445765214457939]
	TIME [epoch: 25.4 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572168625070796		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2572168625070796 | validation: 0.14488885649531658]
	TIME [epoch: 25.4 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25681705421233186		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.25681705421233186 | validation: 0.1504926946306392]
	TIME [epoch: 25.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589827827215023		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2589827827215023 | validation: 0.14166845135882564]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_366.pth
	Model improved!!!
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26497309070112635		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.26497309070112635 | validation: 0.14694060013495333]
	TIME [epoch: 25.4 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26245675291509557		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.26245675291509557 | validation: 0.14449893517033066]
	TIME [epoch: 25.4 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25738697224182283		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.25738697224182283 | validation: 0.14616206687306774]
	TIME [epoch: 25.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2568704703853386		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.2568704703853386 | validation: 0.15300479249641574]
	TIME [epoch: 25.4 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.260657478570748		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.260657478570748 | validation: 0.14520199314740462]
	TIME [epoch: 25.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2545750969767825		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2545750969767825 | validation: 0.23818521406690749]
	TIME [epoch: 25.4 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1934017304768603		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.1934017304768603 | validation: 0.11629261931812387]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855452907560485		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.10855452907560485 | validation: 0.19740287683602403]
	TIME [epoch: 25.4 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12424701551583811		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.12424701551583811 | validation: 0.0865348184390173]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_375.pth
	Model improved!!!
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187727861414143		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.11187727861414143 | validation: 0.07966355251999868]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_376.pth
	Model improved!!!
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11579381688889423		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.11579381688889423 | validation: 0.0910573554858424]
	TIME [epoch: 25.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10014684491270807		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.10014684491270807 | validation: 0.0860383132165206]
	TIME [epoch: 25.4 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10832019167171292		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.10832019167171292 | validation: 0.0675266824723999]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406293579923095		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.10406293579923095 | validation: 0.07199355151804275]
	TIME [epoch: 25.4 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10973602430796381		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.10973602430796381 | validation: 0.08165515498170595]
	TIME [epoch: 25.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928392467509417		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.10928392467509417 | validation: 0.06310319259501773]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_382.pth
	Model improved!!!
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08006342035959291		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.08006342035959291 | validation: 0.06768655268482757]
	TIME [epoch: 25.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803559006116889		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.0803559006116889 | validation: 0.06377008000860292]
	TIME [epoch: 25.4 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12834399558320492		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.12834399558320492 | validation: 0.11512552620370226]
	TIME [epoch: 25.4 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10346898865153124		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.10346898865153124 | validation: 0.07915398452723185]
	TIME [epoch: 25.4 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08950600093307723		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.08950600093307723 | validation: 0.060175786222605214]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_387.pth
	Model improved!!!
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09036222405744704		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.09036222405744704 | validation: 0.08098348586455202]
	TIME [epoch: 25.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288968295974123		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.10288968295974123 | validation: 0.0813819544856356]
	TIME [epoch: 25.4 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09156460454795326		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.09156460454795326 | validation: 0.08718578272196353]
	TIME [epoch: 25.4 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753703297238382		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.09753703297238382 | validation: 0.07053961699451192]
	TIME [epoch: 25.4 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401457983382407		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.08401457983382407 | validation: 0.07291040787137988]
	TIME [epoch: 25.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0768916414476406		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.0768916414476406 | validation: 0.06549057307787604]
	TIME [epoch: 25.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10637799547090053		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.10637799547090053 | validation: 0.06239213075867382]
	TIME [epoch: 25.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09029115540483151		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.09029115540483151 | validation: 0.06309869080428988]
	TIME [epoch: 25.4 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09612858353755842		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.09612858353755842 | validation: 0.06776114814312655]
	TIME [epoch: 25.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08642907122532364		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.08642907122532364 | validation: 0.06401741941415845]
	TIME [epoch: 25.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1012634623285624		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.1012634623285624 | validation: 0.10501385415119695]
	TIME [epoch: 25.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09379747621545081		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.09379747621545081 | validation: 0.06624336505469194]
	TIME [epoch: 25.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08587868225064002		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.08587868225064002 | validation: 0.06402652212164404]
	TIME [epoch: 25.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08309406785117902		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.08309406785117902 | validation: 0.05752809888881704]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07572502445595766		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.07572502445595766 | validation: 0.05777988336713835]
	TIME [epoch: 25.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09714775456681311		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.09714775456681311 | validation: 0.05943494793299331]
	TIME [epoch: 25.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08867060590062374		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.08867060590062374 | validation: 0.06332961152714225]
	TIME [epoch: 25.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07791312575924894		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.07791312575924894 | validation: 0.08117448043550346]
	TIME [epoch: 25.4 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08869243425044271		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.08869243425044271 | validation: 0.08033513035501959]
	TIME [epoch: 25.4 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07944183061521645		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.07944183061521645 | validation: 0.16003900204048754]
	TIME [epoch: 25.4 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300553052493565		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.10300553052493565 | validation: 0.052614010474831344]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_408.pth
	Model improved!!!
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07171836420410954		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.07171836420410954 | validation: 0.05004850760365645]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09053291401764213		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.09053291401764213 | validation: 0.05654811565909507]
	TIME [epoch: 25.4 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516555931915257		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.08516555931915257 | validation: 0.05436898048290785]
	TIME [epoch: 25.4 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08623120191495938		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.08623120191495938 | validation: 0.05287881894916834]
	TIME [epoch: 25.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08864066670938439		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.08864066670938439 | validation: 0.056140919298289516]
	TIME [epoch: 25.4 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0725881845739733		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.0725881845739733 | validation: 0.05267467733084015]
	TIME [epoch: 25.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06710963059993828		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.06710963059993828 | validation: 0.2185681387716102]
	TIME [epoch: 25.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17592915854465394		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.17592915854465394 | validation: 0.08427408713492582]
	TIME [epoch: 25.4 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07642281008038217		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.07642281008038217 | validation: 0.0515749649597664]
	TIME [epoch: 25.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08238230130573056		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.08238230130573056 | validation: 0.06510936750161099]
	TIME [epoch: 25.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07085460043661003		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.07085460043661003 | validation: 0.061648077030873216]
	TIME [epoch: 25.4 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07831405773264699		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.07831405773264699 | validation: 0.05323687535915267]
	TIME [epoch: 25.4 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07140522023710716		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.07140522023710716 | validation: 0.05161530571713069]
	TIME [epoch: 25.4 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0797597134904195		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.0797597134904195 | validation: 0.061009903268543664]
	TIME [epoch: 25.4 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548271722924741		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.08548271722924741 | validation: 0.06316649993313285]
	TIME [epoch: 25.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07189989161855996		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.07189989161855996 | validation: 0.05686025072973076]
	TIME [epoch: 25.4 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07999925959698734		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.07999925959698734 | validation: 0.05359119763353805]
	TIME [epoch: 25.4 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08536369609481737		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.08536369609481737 | validation: 0.06441738416698765]
	TIME [epoch: 25.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06979391824794959		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.06979391824794959 | validation: 0.049306599783984176]
	TIME [epoch: 25.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07045039858397487		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.07045039858397487 | validation: 0.1537760855663207]
	TIME [epoch: 25.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09796752478104456		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.09796752478104456 | validation: 0.08795000333785032]
	TIME [epoch: 25.5 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785238030548828		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.0785238030548828 | validation: 0.054988100684545266]
	TIME [epoch: 25.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0728096380163959		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.0728096380163959 | validation: 0.05016315544199434]
	TIME [epoch: 25.4 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0753429218800307		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.0753429218800307 | validation: 0.0581533191248621]
	TIME [epoch: 25.4 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08348737510749138		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.08348737510749138 | validation: 0.0617905719802133]
	TIME [epoch: 25.4 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06858832248533447		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.06858832248533447 | validation: 0.051694319742288164]
	TIME [epoch: 25.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07647671340624325		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.07647671340624325 | validation: 0.05786876257038157]
	TIME [epoch: 25.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06814925283990671		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.06814925283990671 | validation: 0.05781512876781773]
	TIME [epoch: 25.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07308803414623183		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.07308803414623183 | validation: 0.04748378723441045]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_437.pth
	Model improved!!!
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.075585632343482		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.075585632343482 | validation: 0.045373556025811675]
	TIME [epoch: 25.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_438.pth
	Model improved!!!
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08650510216932138		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.08650510216932138 | validation: 0.05995090700059967]
	TIME [epoch: 25.4 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07374861346191294		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.07374861346191294 | validation: 0.13145446723861787]
	TIME [epoch: 25.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09990030705909554		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.09990030705909554 | validation: 0.06493733811069757]
	TIME [epoch: 25.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122889795815461		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.1122889795815461 | validation: 0.05508119242681089]
	TIME [epoch: 25.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07151796842985925		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.07151796842985925 | validation: 0.046522997823069165]
	TIME [epoch: 25.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07607222418725144		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.07607222418725144 | validation: 0.05270938316661441]
	TIME [epoch: 25.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859195452515313		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.06859195452515313 | validation: 0.05209669202968152]
	TIME [epoch: 25.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08069676121584472		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.08069676121584472 | validation: 0.053088900338138206]
	TIME [epoch: 25.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06991716468802048		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.06991716468802048 | validation: 0.0499554557177295]
	TIME [epoch: 25.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07086342102407257		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.07086342102407257 | validation: 0.053017526280285346]
	TIME [epoch: 25.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0671323943928365		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.0671323943928365 | validation: 0.05025748996341241]
	TIME [epoch: 25.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0769344667738597		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.0769344667738597 | validation: 0.0461396440021971]
	TIME [epoch: 25.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07397524160695641		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.07397524160695641 | validation: 0.050676864814049274]
	TIME [epoch: 25.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07391430330878732		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.07391430330878732 | validation: 0.05616526575153498]
	TIME [epoch: 25.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07734326333929707		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.07734326333929707 | validation: 0.05216640450316792]
	TIME [epoch: 25.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08039597606757765		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.08039597606757765 | validation: 0.06038672806300131]
	TIME [epoch: 25.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07236310403219093		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.07236310403219093 | validation: 0.05591299607938688]
	TIME [epoch: 25.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701497523657451		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.06701497523657451 | validation: 0.04568947922724874]
	TIME [epoch: 25.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821797337716978		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.06821797337716978 | validation: 0.052785376373044]
	TIME [epoch: 25.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07933015268613999		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.07933015268613999 | validation: 0.04692759231344662]
	TIME [epoch: 25.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07432330084921998		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.07432330084921998 | validation: 0.04971593168638884]
	TIME [epoch: 25.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07311082912716795		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.07311082912716795 | validation: 0.04969697480528848]
	TIME [epoch: 25.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06381642339073863		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.06381642339073863 | validation: 0.04449112236218756]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408447269676604		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.06408447269676604 | validation: 0.055072458994162674]
	TIME [epoch: 25.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06379830836476746		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.06379830836476746 | validation: 0.07365835817197178]
	TIME [epoch: 25.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06885041549405402		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.06885041549405402 | validation: 0.04086167920238737]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_464.pth
	Model improved!!!
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0807921594516563		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.0807921594516563 | validation: 0.09100251846552929]
	TIME [epoch: 25.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07481419354164841		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.07481419354164841 | validation: 0.051411185082592376]
	TIME [epoch: 25.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08285737664700277		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.08285737664700277 | validation: 0.07689298985338403]
	TIME [epoch: 25.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09700246852988177		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.09700246852988177 | validation: 0.05633501550492563]
	TIME [epoch: 25.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842626578687838		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.06842626578687838 | validation: 0.049821294193586343]
	TIME [epoch: 25.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061948874823754774		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.061948874823754774 | validation: 0.04337111043515112]
	TIME [epoch: 25.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648656673929418		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.0648656673929418 | validation: 0.04853758708158443]
	TIME [epoch: 25.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0726299314431724		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.0726299314431724 | validation: 0.04561590771653591]
	TIME [epoch: 25.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06824349108171625		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.06824349108171625 | validation: 0.04592841967812276]
	TIME [epoch: 25.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05742174311608144		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.05742174311608144 | validation: 0.04660499627151428]
	TIME [epoch: 25.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06571520076771614		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.06571520076771614 | validation: 0.04675537000437856]
	TIME [epoch: 25.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06970263290060426		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.06970263290060426 | validation: 0.04503995202529094]
	TIME [epoch: 25.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06855179264387805		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.06855179264387805 | validation: 0.05330625763342478]
	TIME [epoch: 25.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06833046257972449		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.06833046257972449 | validation: 0.0436267826509186]
	TIME [epoch: 25.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0623558367094011		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.0623558367094011 | validation: 0.0550699700661131]
	TIME [epoch: 25.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06109192760166959		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.06109192760166959 | validation: 0.04720163514551187]
	TIME [epoch: 25.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05912087890632485		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.05912087890632485 | validation: 0.04786424368428556]
	TIME [epoch: 25.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08652178122068707		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.08652178122068707 | validation: 0.06105837898173812]
	TIME [epoch: 25.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0849255334044513		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.0849255334044513 | validation: 0.05178621690249827]
	TIME [epoch: 25.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06822737384768413		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.06822737384768413 | validation: 0.04421388288061244]
	TIME [epoch: 25.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06031967856880245		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.06031967856880245 | validation: 0.07467155676963781]
	TIME [epoch: 25.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0646795376011995		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.0646795376011995 | validation: 0.041584815228887476]
	TIME [epoch: 25.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058415282415835094		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.058415282415835094 | validation: 0.046810788380683574]
	TIME [epoch: 25.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07060529623292991		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.07060529623292991 | validation: 0.049756549252122674]
	TIME [epoch: 25.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06373852976565521		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.06373852976565521 | validation: 0.04962253366814241]
	TIME [epoch: 25.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06211099931865384		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.06211099931865384 | validation: 0.04629915817286764]
	TIME [epoch: 25.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060542255951590324		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.060542255951590324 | validation: 0.04801264511285124]
	TIME [epoch: 25.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07143442221452913		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.07143442221452913 | validation: 0.04085241670793015]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_492.pth
	Model improved!!!
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057800823620084804		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.057800823620084804 | validation: 0.03774116704630841]
	TIME [epoch: 25.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0598892146596484		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.0598892146596484 | validation: 0.0565835840555278]
	TIME [epoch: 25.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058532501928929066		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.058532501928929066 | validation: 0.040815437670013]
	TIME [epoch: 25.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060295127654220834		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.060295127654220834 | validation: 0.04114273390781664]
	TIME [epoch: 25.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057162969880661045		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.057162969880661045 | validation: 0.053570808001575085]
	TIME [epoch: 25.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06758670116874058		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.06758670116874058 | validation: 0.03932041026787058]
	TIME [epoch: 25.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06419524234524783		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.06419524234524783 | validation: 0.04687213650408671]
	TIME [epoch: 25.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0642263673680878		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.0642263673680878 | validation: 0.04479294519047746]
	TIME [epoch: 25.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05589910107003266		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.05589910107003266 | validation: 0.04090919522692078]
	TIME [epoch: 146 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06587402388497651		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.06587402388497651 | validation: 0.03902440405504337]
	TIME [epoch: 50.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060869297007097256		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.060869297007097256 | validation: 0.040444296033976215]
	TIME [epoch: 50.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879732697826979		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.05879732697826979 | validation: 0.03906269946592001]
	TIME [epoch: 50.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05220793982708523		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.05220793982708523 | validation: 0.043259558866716404]
	TIME [epoch: 50.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07030697276527267		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.07030697276527267 | validation: 0.03832645397342936]
	TIME [epoch: 50.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05863613054523564		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.05863613054523564 | validation: 0.043151641837855546]
	TIME [epoch: 50.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05936757907895281		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.05936757907895281 | validation: 0.038044087842441884]
	TIME [epoch: 50.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06239899998214181		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.06239899998214181 | validation: 0.046465920573093414]
	TIME [epoch: 50.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05538613202673683		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.05538613202673683 | validation: 0.050266631836751126]
	TIME [epoch: 50.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06079002297690325		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.06079002297690325 | validation: 0.04189277003958215]
	TIME [epoch: 50.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059120267811805544		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.059120267811805544 | validation: 0.042551281301521374]
	TIME [epoch: 50.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05432812222177778		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.05432812222177778 | validation: 0.04548866274476171]
	TIME [epoch: 50.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0605563265340905		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.0605563265340905 | validation: 0.038729322376828114]
	TIME [epoch: 50.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054635497139633483		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.054635497139633483 | validation: 0.042907868217690034]
	TIME [epoch: 50.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055469950877098696		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.055469950877098696 | validation: 0.11623353505448088]
	TIME [epoch: 50.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09174301306248539		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.09174301306248539 | validation: 0.042723722878419745]
	TIME [epoch: 50.1 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05321027422928975		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.05321027422928975 | validation: 0.06394196241607501]
	TIME [epoch: 50.1 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05978878900847557		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.05978878900847557 | validation: 0.04057308861058363]
	TIME [epoch: 50.1 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04869403037794532		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.04869403037794532 | validation: 0.03650299225202723]
	TIME [epoch: 50.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_520.pth
	Model improved!!!
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056532433507333765		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.056532433507333765 | validation: 0.03957782842568798]
	TIME [epoch: 50.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056356971599965826		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.056356971599965826 | validation: 0.04140801668377744]
	TIME [epoch: 50.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06475985661244196		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.06475985661244196 | validation: 0.04968231740279642]
	TIME [epoch: 50.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06701928338039684		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.06701928338039684 | validation: 0.038089610604338436]
	TIME [epoch: 50.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054879797205153916		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.054879797205153916 | validation: 0.037640011454388785]
	TIME [epoch: 50.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122784638671755		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.05122784638671755 | validation: 0.03706872369824283]
	TIME [epoch: 50.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07101851829815156		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.07101851829815156 | validation: 0.03426372325416219]
	TIME [epoch: 50.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_527.pth
	Model improved!!!
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254008852099391		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.05254008852099391 | validation: 0.0354258338102175]
	TIME [epoch: 50.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053170069286248234		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.053170069286248234 | validation: 0.038677506451408286]
	TIME [epoch: 50.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06263301892662344		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.06263301892662344 | validation: 0.05083813385984148]
	TIME [epoch: 50.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05241398484215329		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.05241398484215329 | validation: 0.03948607603431857]
	TIME [epoch: 50.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051954587783427326		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.051954587783427326 | validation: 0.03495470619399826]
	TIME [epoch: 50.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05797305330857157		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.05797305330857157 | validation: 0.04540808128241271]
	TIME [epoch: 50.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05436397331605089		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.05436397331605089 | validation: 0.03816569130884308]
	TIME [epoch: 50.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053221115110533346		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.053221115110533346 | validation: 0.04370238626859603]
	TIME [epoch: 50.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05806442242112621		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.05806442242112621 | validation: 0.03796373287171588]
	TIME [epoch: 50.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0495948642659078		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.0495948642659078 | validation: 0.03350276809171528]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_537.pth
	Model improved!!!
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05303208278320906		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.05303208278320906 | validation: 0.047135839862599255]
	TIME [epoch: 50.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050701440879442505		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.050701440879442505 | validation: 0.03445815960998343]
	TIME [epoch: 50.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050380681586549896		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.050380681586549896 | validation: 0.036397489800296945]
	TIME [epoch: 50.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052721318320847636		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.052721318320847636 | validation: 0.03451450374225165]
	TIME [epoch: 50.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050572193171498823		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.050572193171498823 | validation: 0.032751516264025594]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050041271864546495		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.050041271864546495 | validation: 0.05388433878591309]
	TIME [epoch: 50.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05335839043108707		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.05335839043108707 | validation: 0.040663521503754504]
	TIME [epoch: 50.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980868367235135		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.04980868367235135 | validation: 0.033212562006684626]
	TIME [epoch: 50.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04626767593815309		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.04626767593815309 | validation: 0.03885961789299615]
	TIME [epoch: 50.4 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06313425935907435		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.06313425935907435 | validation: 0.03424474603689217]
	TIME [epoch: 50.4 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04878045989279266		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.04878045989279266 | validation: 0.03526090780181278]
	TIME [epoch: 50.4 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549219624533823		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.04549219624533823 | validation: 0.08445060172238913]
	TIME [epoch: 50.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06831063395796647		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.06831063395796647 | validation: 0.0369511305543119]
	TIME [epoch: 50.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588176344791619		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.04588176344791619 | validation: 0.03151859377690563]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_551.pth
	Model improved!!!
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04821706191423125		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.04821706191423125 | validation: 0.03522657558648892]
	TIME [epoch: 50.4 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473560478793166		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.04473560478793166 | validation: 0.032957294176645224]
	TIME [epoch: 50.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04369227938229514		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.04369227938229514 | validation: 0.04734555655120867]
	TIME [epoch: 50.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05571377523615054		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.05571377523615054 | validation: 0.044034213734979386]
	TIME [epoch: 50.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049856410151371953		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.049856410151371953 | validation: 0.0314218112214176]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04783921731449758		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.04783921731449758 | validation: 0.057669524489818984]
	TIME [epoch: 50.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055371484733920256		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.055371484733920256 | validation: 0.03440412121328039]
	TIME [epoch: 50.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04506704385705465		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.04506704385705465 | validation: 0.10344382553384183]
	TIME [epoch: 50.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08127936527571296		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.08127936527571296 | validation: 0.03670839668918234]
	TIME [epoch: 50.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590299436760841		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.04590299436760841 | validation: 0.03856223484799946]
	TIME [epoch: 50.4 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728974060088102		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.04728974060088102 | validation: 0.030610626930950645]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_562.pth
	Model improved!!!
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041981754787461106		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.041981754787461106 | validation: 0.028285179982846027]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_563.pth
	Model improved!!!
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050913161406304024		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.050913161406304024 | validation: 0.04196544807420642]
	TIME [epoch: 50.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631619598149067		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.04631619598149067 | validation: 0.02955780227062577]
	TIME [epoch: 50.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043437105778387		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.043437105778387 | validation: 0.04151845397231069]
	TIME [epoch: 50.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06383213251378247		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.06383213251378247 | validation: 0.032125436295740224]
	TIME [epoch: 50.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045712652184760005		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.045712652184760005 | validation: 0.031497065224440235]
	TIME [epoch: 50.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043788045823414515		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.043788045823414515 | validation: 0.031050009320687647]
	TIME [epoch: 50.4 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04402049804340779		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.04402049804340779 | validation: 0.02995472446260515]
	TIME [epoch: 50.4 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379641818376252		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.04379641818376252 | validation: 0.02924846936153528]
	TIME [epoch: 50.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183446867800285		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.04183446867800285 | validation: 0.04906269954048205]
	TIME [epoch: 50.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052966628193210276		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.052966628193210276 | validation: 0.03156837326248856]
	TIME [epoch: 50.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04355319476391114		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.04355319476391114 | validation: 0.028862923043425706]
	TIME [epoch: 50.4 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04714681222642956		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.04714681222642956 | validation: 0.03233097486477983]
	TIME [epoch: 50.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04200274607508113		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.04200274607508113 | validation: 0.033801534912800996]
	TIME [epoch: 50.4 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0471064142789218		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0471064142789218 | validation: 0.028170121820883944]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04181047109814873		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.04181047109814873 | validation: 0.029579777645401147]
	TIME [epoch: 50.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1347333142113281		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.1347333142113281 | validation: 0.03230125914750296]
	TIME [epoch: 50.4 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922332147074421		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.04922332147074421 | validation: 0.030596317489843324]
	TIME [epoch: 50.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05861364384956265		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.05861364384956265 | validation: 0.03653971360875262]
	TIME [epoch: 50.4 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04023799914309153		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.04023799914309153 | validation: 0.031460139645739765]
	TIME [epoch: 50.4 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04098458158872735		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.04098458158872735 | validation: 0.027378685841967343]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_583.pth
	Model improved!!!
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03997238488855565		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.03997238488855565 | validation: 0.0295966909064654]
	TIME [epoch: 50.4 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0391380535095575		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.0391380535095575 | validation: 0.02897168433737066]
	TIME [epoch: 50.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04063355486499268		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.04063355486499268 | validation: 0.04153743200978039]
	TIME [epoch: 50.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0479512319916391		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.0479512319916391 | validation: 0.03065520575140139]
	TIME [epoch: 50.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037295630180794945		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.037295630180794945 | validation: 0.03320044441884518]
	TIME [epoch: 50.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04194195245909103		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.04194195245909103 | validation: 0.03134093415330791]
	TIME [epoch: 50.4 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03649821987410415		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.03649821987410415 | validation: 0.025310424318847835]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_590.pth
	Model improved!!!
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03845970710315749		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.03845970710315749 | validation: 0.03437135909753158]
	TIME [epoch: 50.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460774182471014		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.04460774182471014 | validation: 0.03441953386094598]
	TIME [epoch: 50.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040694096057868744		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.040694096057868744 | validation: 0.02933148571145048]
	TIME [epoch: 50.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037440154540940226		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.037440154540940226 | validation: 0.025263645739297347]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036457598459449195		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.036457598459449195 | validation: 0.026851228502741888]
	TIME [epoch: 50.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392901673011662		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.0392901673011662 | validation: 0.023904276203994945]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043228925396603265		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.043228925396603265 | validation: 0.03284724312163063]
	TIME [epoch: 50.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03906610325829256		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.03906610325829256 | validation: 0.0366749604729117]
	TIME [epoch: 50.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0378688286715667		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.0378688286715667 | validation: 0.02844898697682231]
	TIME [epoch: 50.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039349252844957		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.039349252844957 | validation: 0.023676987678657037]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03571364743298277		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.03571364743298277 | validation: 0.02477489726367545]
	TIME [epoch: 50.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03807290609239079		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.03807290609239079 | validation: 0.02604750598592155]
	TIME [epoch: 50.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034407881312110006		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.034407881312110006 | validation: 0.023064286438539097]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_603.pth
	Model improved!!!
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231049765775237		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.04231049765775237 | validation: 0.025338834609331864]
	TIME [epoch: 50.4 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038978593063749414		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.038978593063749414 | validation: 0.02126273443611483]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_605.pth
	Model improved!!!
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03494158712914255		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.03494158712914255 | validation: 0.02380769552638424]
	TIME [epoch: 50.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03727302142747086		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.03727302142747086 | validation: 0.022792688092227585]
	TIME [epoch: 50.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0333066391720765		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.0333066391720765 | validation: 0.044190408585427304]
	TIME [epoch: 50.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040500699593086394		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.040500699593086394 | validation: 0.02181203840843092]
	TIME [epoch: 50.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03224612929112054		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.03224612929112054 | validation: 0.024607313404397986]
	TIME [epoch: 50.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582954340516693		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.04582954340516693 | validation: 0.024288183052135783]
	TIME [epoch: 50.4 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03621910915053682		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.03621910915053682 | validation: 0.023550576680334587]
	TIME [epoch: 50.4 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0343037415920629		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.0343037415920629 | validation: 0.020258003216264316]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_613.pth
	Model improved!!!
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328229613726813		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.0328229613726813 | validation: 0.019918688379085406]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_614.pth
	Model improved!!!
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033657190164209566		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.033657190164209566 | validation: 0.02215548848350108]
	TIME [epoch: 50.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031037197187360244		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.031037197187360244 | validation: 0.019728964694891972]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_616.pth
	Model improved!!!
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03779382640553763		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.03779382640553763 | validation: 0.022272580613307807]
	TIME [epoch: 50.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040370422886733565		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.040370422886733565 | validation: 0.021338311574461893]
	TIME [epoch: 50.4 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02942695197044639		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.02942695197044639 | validation: 0.02385477172971622]
	TIME [epoch: 50.4 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028955875429485033		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.028955875429485033 | validation: 0.019765084068656194]
	TIME [epoch: 50.4 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03160679698550026		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.03160679698550026 | validation: 0.03718150409544572]
	TIME [epoch: 50.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03732783003880195		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.03732783003880195 | validation: 0.027818442241775126]
	TIME [epoch: 50.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0321983768730314		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.0321983768730314 | validation: 0.021432313600774817]
	TIME [epoch: 50.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07070516576485267		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.07070516576485267 | validation: 0.022368111450422362]
	TIME [epoch: 50.4 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029802282550628438		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.029802282550628438 | validation: 0.022400817320703446]
	TIME [epoch: 50.4 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029619021665528843		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.029619021665528843 | validation: 0.0188276986356454]
	TIME [epoch: 50.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_626.pth
	Model improved!!!
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026496322061352953		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.026496322061352953 | validation: 0.02523892939404864]
	TIME [epoch: 50.4 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03346343271257962		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.03346343271257962 | validation: 0.018428102817411]
	TIME [epoch: 50.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04259125721757048		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.04259125721757048 | validation: 0.02494166384214762]
	TIME [epoch: 50.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0325699844470138		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.0325699844470138 | validation: 0.020577064743994445]
	TIME [epoch: 50.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028420384936339128		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.028420384936339128 | validation: 0.020149982355206583]
	TIME [epoch: 50.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03713156653677268		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.03713156653677268 | validation: 0.02465413743212825]
	TIME [epoch: 50.5 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029668044220546103		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.029668044220546103 | validation: 0.02054936493559552]
	TIME [epoch: 50.4 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027844217174781076		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.027844217174781076 | validation: 0.017442192942807935]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026868525716100454		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.026868525716100454 | validation: 0.020456726025544582]
	TIME [epoch: 50.5 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03270710575794507		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.03270710575794507 | validation: 0.020055284878735407]
	TIME [epoch: 50.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026390888874756057		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.026390888874756057 | validation: 0.022820212176652952]
	TIME [epoch: 50.4 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026879991498609566		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.026879991498609566 | validation: 0.017654185354089243]
	TIME [epoch: 50.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025707610094522024		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.025707610094522024 | validation: 0.016801733943333147]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_639.pth
	Model improved!!!
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030787473755510917		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.030787473755510917 | validation: 0.033503495424281195]
	TIME [epoch: 50.4 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03793299890343193		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.03793299890343193 | validation: 0.019802860705263]
	TIME [epoch: 50.4 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03599065965783711		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.03599065965783711 | validation: 0.01744349745715553]
	TIME [epoch: 50.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025983154825316573		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.025983154825316573 | validation: 0.019005904199375867]
	TIME [epoch: 50.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027894215714480475		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.027894215714480475 | validation: 0.017965561368998486]
	TIME [epoch: 50.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026138373177293974		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.026138373177293974 | validation: 0.021175824071260143]
	TIME [epoch: 50.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027812591077804816		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.027812591077804816 | validation: 0.02191901690350457]
	TIME [epoch: 50.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02562588081431709		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.02562588081431709 | validation: 0.0182859910245472]
	TIME [epoch: 50.4 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04801409647229427		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.04801409647229427 | validation: 0.025567154308136702]
	TIME [epoch: 50.4 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03232373663330604		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.03232373663330604 | validation: 0.01516969108847987]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_649.pth
	Model improved!!!
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024694706841343252		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.024694706841343252 | validation: 0.015716230443402562]
	TIME [epoch: 50.4 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027307676000176768		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.027307676000176768 | validation: 0.015777170786902425]
	TIME [epoch: 50.4 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022354802828616835		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.022354802828616835 | validation: 0.016551252757070055]
	TIME [epoch: 50.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023409632676658295		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.023409632676658295 | validation: 0.01636962976404051]
	TIME [epoch: 50.4 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02892016533447704		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.02892016533447704 | validation: 0.019273014279903276]
	TIME [epoch: 50.4 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0235388295190229		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.0235388295190229 | validation: 0.016485559737145376]
	TIME [epoch: 50.4 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02566167367057826		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.02566167367057826 | validation: 0.020602511609293717]
	TIME [epoch: 50.4 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023965089712112628		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.023965089712112628 | validation: 0.0161238992195611]
	TIME [epoch: 50.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024498576708617537		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.024498576708617537 | validation: 0.013831441844765317]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022113335615433296		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.022113335615433296 | validation: 0.017084244580956972]
	TIME [epoch: 50.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03029860685667729		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.03029860685667729 | validation: 0.02247693363220822]
	TIME [epoch: 50.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029928880450663286		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.029928880450663286 | validation: 0.019230124590892468]
	TIME [epoch: 50.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02786401904618508		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.02786401904618508 | validation: 0.015644340403040368]
	TIME [epoch: 50.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02315145401739715		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.02315145401739715 | validation: 0.014498654481514155]
	TIME [epoch: 50.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027059646889923735		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.027059646889923735 | validation: 0.02942404610183231]
	TIME [epoch: 50.2 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027389170978237256		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.027389170978237256 | validation: 0.0172546136042578]
	TIME [epoch: 50.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02823625670221488		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.02823625670221488 | validation: 0.01926009551323715]
	TIME [epoch: 50.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022538131577152544		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.022538131577152544 | validation: 0.021844166723151835]
	TIME [epoch: 50.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026810313029994676		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.026810313029994676 | validation: 0.015398757294784833]
	TIME [epoch: 50.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023070576986783504		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.023070576986783504 | validation: 0.01634990719966263]
	TIME [epoch: 50.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019623010235727014		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.019623010235727014 | validation: 0.013623216529613198]
	TIME [epoch: 50.2 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_670.pth
	Model improved!!!
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021111604022012478		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.021111604022012478 | validation: 0.014847388331898855]
	TIME [epoch: 50.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024800144600856864		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.024800144600856864 | validation: 0.016159052459988835]
	TIME [epoch: 50.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022578615899765363		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.022578615899765363 | validation: 0.014101810476063306]
	TIME [epoch: 50.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024063790172327293		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.024063790172327293 | validation: 0.015353396988030298]
	TIME [epoch: 50.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02065812516047928		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.02065812516047928 | validation: 0.015918842313269267]
	TIME [epoch: 50.1 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02304966001259836		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.02304966001259836 | validation: 0.01786300364559672]
	TIME [epoch: 50.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023122927781973224		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.023122927781973224 | validation: 0.015202256130791063]
	TIME [epoch: 50.1 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020198024444639903		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.020198024444639903 | validation: 0.015695088656499254]
	TIME [epoch: 50.1 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020652888983398014		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.020652888983398014 | validation: 0.015171973291201025]
	TIME [epoch: 50 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019902604616110632		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.019902604616110632 | validation: 0.014641178216943683]
	TIME [epoch: 50 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021158481960530152		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.021158481960530152 | validation: 0.014015295161047148]
	TIME [epoch: 50.1 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021205957626910077		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.021205957626910077 | validation: 0.0157489383813586]
	TIME [epoch: 50 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018655470686560673		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.018655470686560673 | validation: 0.017196326036654993]
	TIME [epoch: 50.1 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026620744449576145		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.026620744449576145 | validation: 0.014458896083209294]
	TIME [epoch: 50.1 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019340748821316492		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.019340748821316492 | validation: 0.013222547028984408]
	TIME [epoch: 50.1 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_685.pth
	Model improved!!!
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019421532057116837		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.019421532057116837 | validation: 0.035359836038082515]
	TIME [epoch: 50.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033430564821823903		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.033430564821823903 | validation: 0.016183974062500953]
	TIME [epoch: 50.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018799327451318598		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.018799327451318598 | validation: 0.012768799472395474]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_688.pth
	Model improved!!!
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018908222566950045		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.018908222566950045 | validation: 0.016606993588045384]
	TIME [epoch: 50.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01857821166231826		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.01857821166231826 | validation: 0.011596945723280166]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_690.pth
	Model improved!!!
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017588757915138684		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.017588757915138684 | validation: 0.014966235704701243]
	TIME [epoch: 50.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024859231552979495		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.024859231552979495 | validation: 0.012766969651234555]
	TIME [epoch: 50.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02075194906402842		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.02075194906402842 | validation: 0.014970608402931759]
	TIME [epoch: 50.4 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021083195079520143		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.021083195079520143 | validation: 0.014266311558801363]
	TIME [epoch: 50.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023046113087477147		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.023046113087477147 | validation: 0.015606956506715857]
	TIME [epoch: 50.4 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021588713928536313		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.021588713928536313 | validation: 0.022847042164902773]
	TIME [epoch: 50.4 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022191297228262807		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.022191297228262807 | validation: 0.015153684753072647]
	TIME [epoch: 50.4 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018507798239479803		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.018507798239479803 | validation: 0.01376793561424322]
	TIME [epoch: 50.4 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0177020339344939		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.0177020339344939 | validation: 0.01191602856880345]
	TIME [epoch: 50.4 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018995360412125215		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.018995360412125215 | validation: 0.017326767237989475]
	TIME [epoch: 50.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01844251391839341		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.01844251391839341 | validation: 0.023474323329351086]
	TIME [epoch: 50.4 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02388967678633659		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.02388967678633659 | validation: 0.011378511832516267]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_702.pth
	Model improved!!!
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020875940952079258		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.020875940952079258 | validation: 0.01280778438109866]
	TIME [epoch: 50.4 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028447438803912557		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.028447438803912557 | validation: 0.015104461293682639]
	TIME [epoch: 50.4 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01780629633614222		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.01780629633614222 | validation: 0.012216113920015068]
	TIME [epoch: 50.4 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017137383099835375		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.017137383099835375 | validation: 0.011405462012407656]
	TIME [epoch: 50.4 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02672503199566423		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.02672503199566423 | validation: 0.015207171866401085]
	TIME [epoch: 50.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016434240913238463		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.016434240913238463 | validation: 0.013686341774232866]
	TIME [epoch: 50.4 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01977733597031857		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.01977733597031857 | validation: 0.01719684581451071]
	TIME [epoch: 50.4 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022037535019543433		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.022037535019543433 | validation: 0.01467797831294438]
	TIME [epoch: 50.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018295224697954325		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.018295224697954325 | validation: 0.01640500302272981]
	TIME [epoch: 50.4 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015657031744929346		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.015657031744929346 | validation: 0.02108709233163814]
	TIME [epoch: 50.4 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021484829123440796		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.021484829123440796 | validation: 0.013167320784609882]
	TIME [epoch: 50.4 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0253217262858354		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.0253217262858354 | validation: 0.014614551986172154]
	TIME [epoch: 50.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018133751905936312		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.018133751905936312 | validation: 0.01261589964447188]
	TIME [epoch: 50.4 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0162823561226664		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.0162823561226664 | validation: 0.012146132805248596]
	TIME [epoch: 50.4 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016116043301819385		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.016116043301819385 | validation: 0.012240675410162941]
	TIME [epoch: 50.4 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017691746627651647		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.017691746627651647 | validation: 0.013031646523300522]
	TIME [epoch: 50.4 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019485626092091944		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.019485626092091944 | validation: 0.015410251582105097]
	TIME [epoch: 50.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025627422793519358		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.025627422793519358 | validation: 0.026555175674191137]
	TIME [epoch: 50.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021691174336546496		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.021691174336546496 | validation: 0.012319112853643547]
	TIME [epoch: 50.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015594833821554452		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.015594833821554452 | validation: 0.014205112139005613]
	TIME [epoch: 50.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016842459971151545		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.016842459971151545 | validation: 0.012204688462041296]
	TIME [epoch: 50.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015638741863966906		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.015638741863966906 | validation: 0.015512988976251665]
	TIME [epoch: 50.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018548625872041646		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.018548625872041646 | validation: 0.018354292131188776]
	TIME [epoch: 50.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02374130587661069		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.02374130587661069 | validation: 0.01608362935922751]
	TIME [epoch: 50.4 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018851826532418525		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.018851826532418525 | validation: 0.012571035601351171]
	TIME [epoch: 50.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0163488942549607		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.0163488942549607 | validation: 0.013557254866653778]
	TIME [epoch: 50.4 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01619010231319105		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.01619010231319105 | validation: 0.017167180916593396]
	TIME [epoch: 50.4 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02175370868326151		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.02175370868326151 | validation: 0.022717691018414272]
	TIME [epoch: 50.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0196803485397666		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.0196803485397666 | validation: 0.01140447881593642]
	TIME [epoch: 50.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014961066257447895		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.014961066257447895 | validation: 0.01204944937844273]
	TIME [epoch: 50.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015532522953144726		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.015532522953144726 | validation: 0.014267520658752326]
	TIME [epoch: 50.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017011097792315806		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.017011097792315806 | validation: 0.01954339611736202]
	TIME [epoch: 50.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017977426857492488		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.017977426857492488 | validation: 0.01411344359314132]
	TIME [epoch: 50.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01802328910349133		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.01802328910349133 | validation: 0.01177985468681503]
	TIME [epoch: 50.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016413602498602575		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.016413602498602575 | validation: 0.021545373039764674]
	TIME [epoch: 50.4 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01831683346766794		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.01831683346766794 | validation: 0.010760178575514562]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_738.pth
	Model improved!!!
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017423365223459764		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.017423365223459764 | validation: 0.00985124617719346]
	TIME [epoch: 50.3 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_739.pth
	Model improved!!!
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01459032969679209		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.01459032969679209 | validation: 0.023222332793247046]
	TIME [epoch: 50.4 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01830429028016619		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.01830429028016619 | validation: 0.011493970795738995]
	TIME [epoch: 50.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014859642515139087		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.014859642515139087 | validation: 0.01149377805406021]
	TIME [epoch: 50.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017975115986259935		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.017975115986259935 | validation: 0.013208640090683784]
	TIME [epoch: 50.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015769642050761958		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.015769642050761958 | validation: 0.00845356755451186]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_744.pth
	Model improved!!!
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014121928981713746		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.014121928981713746 | validation: 0.009473877803724893]
	TIME [epoch: 50.4 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01804323584288109		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.01804323584288109 | validation: 0.009585140931304519]
	TIME [epoch: 50.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015906233149712762		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.015906233149712762 | validation: 0.0146398880259868]
	TIME [epoch: 50.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.017789631698826403		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.017789631698826403 | validation: 0.011569830791010795]
	TIME [epoch: 50.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018377628523589127		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.018377628523589127 | validation: 0.01693543578516725]
	TIME [epoch: 50.4 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01884104184947438		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.01884104184947438 | validation: 0.013096853643095319]
	TIME [epoch: 50.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013813498101997355		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.013813498101997355 | validation: 0.009460229445217754]
	TIME [epoch: 50.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013932016815665204		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.013932016815665204 | validation: 0.010524859354252201]
	TIME [epoch: 50.4 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01868114559513395		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.01868114559513395 | validation: 0.009742578151985364]
	TIME [epoch: 50.4 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016220178600082794		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.016220178600082794 | validation: 0.010356600517201777]
	TIME [epoch: 50.4 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015257301136029303		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.015257301136029303 | validation: 0.01602390340021785]
	TIME [epoch: 50.4 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01508342890893714		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.01508342890893714 | validation: 0.011784745339924805]
	TIME [epoch: 50.5 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014494170460578337		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.014494170460578337 | validation: 0.010713273462979081]
	TIME [epoch: 50.4 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01586007562599382		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.01586007562599382 | validation: 0.01511418548555724]
	TIME [epoch: 50.4 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019291689797694304		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.019291689797694304 | validation: 0.013491136377926774]
	TIME [epoch: 50.4 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014752334227930935		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.014752334227930935 | validation: 0.012824214068134127]
	TIME [epoch: 50.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019623580791632768		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.019623580791632768 | validation: 0.011669038678906252]
	TIME [epoch: 50.4 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016814199573359234		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.016814199573359234 | validation: 0.01205636697724246]
	TIME [epoch: 50.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019168245110325853		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.019168245110325853 | validation: 0.011459400657227904]
	TIME [epoch: 50.4 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01350440769873533		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.01350440769873533 | validation: 0.011616426671681463]
	TIME [epoch: 50.4 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01427500600170975		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.01427500600170975 | validation: 0.010159327541234293]
	TIME [epoch: 50.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012803191973802709		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.012803191973802709 | validation: 0.009756272602276855]
	TIME [epoch: 50.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014993235673068171		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.014993235673068171 | validation: 0.013513073262828667]
	TIME [epoch: 50.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015218694530259673		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.015218694530259673 | validation: 0.011395670969014986]
	TIME [epoch: 50.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01348161586940119		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.01348161586940119 | validation: 0.01202768330147446]
	TIME [epoch: 50.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014810745478893243		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.014810745478893243 | validation: 0.014072499988909831]
	TIME [epoch: 50.4 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01609905663139233		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.01609905663139233 | validation: 0.0140892321783136]
	TIME [epoch: 50.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014836214098945394		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.014836214098945394 | validation: 0.00973875667702858]
	TIME [epoch: 50.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939347728706304		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.03939347728706304 | validation: 0.020717520675324903]
	TIME [epoch: 50.4 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01771566654938617		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.01771566654938617 | validation: 0.008944553187506497]
	TIME [epoch: 50.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027496290755416167		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.027496290755416167 | validation: 0.009876627805519962]
	TIME [epoch: 50.4 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01308879500695024		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.01308879500695024 | validation: 0.009351250020583913]
	TIME [epoch: 50.4 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012284389854203596		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.012284389854203596 | validation: 0.011091950351243308]
	TIME [epoch: 50.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014293335864713052		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.014293335864713052 | validation: 0.010818683525842508]
	TIME [epoch: 50.4 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012247250133113615		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.012247250133113615 | validation: 0.012965274384731313]
	TIME [epoch: 50.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014345379573390087		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.014345379573390087 | validation: 0.012388000199716817]
	TIME [epoch: 50.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013118649282861859		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.013118649282861859 | validation: 0.010859065001066683]
	TIME [epoch: 50.4 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013715425868306224		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.013715425868306224 | validation: 0.01146629702115007]
	TIME [epoch: 50.5 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01256946674506044		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.01256946674506044 | validation: 0.011580893932323338]
	TIME [epoch: 50.4 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015481967344995766		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.015481967344995766 | validation: 0.00987909980515784]
	TIME [epoch: 50.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013373625285895132		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.013373625285895132 | validation: 0.010011173765717247]
	TIME [epoch: 50.5 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013028045152945287		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.013028045152945287 | validation: 0.00937101262733963]
	TIME [epoch: 50.4 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01309235066459508		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.01309235066459508 | validation: 0.010254825763497122]
	TIME [epoch: 50.4 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014060898746678024		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.014060898746678024 | validation: 0.009948039546417885]
	TIME [epoch: 50.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011998600593122681		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.011998600593122681 | validation: 0.009787519686901695]
	TIME [epoch: 50.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013368727971471758		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.013368727971471758 | validation: 0.009914662143373892]
	TIME [epoch: 50.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013662019345600337		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.013662019345600337 | validation: 0.009571135480608955]
	TIME [epoch: 50.4 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015491111167058638		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.015491111167058638 | validation: 0.012538421582989762]
	TIME [epoch: 50.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014669582584309358		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.014669582584309358 | validation: 0.012610758793019587]
	TIME [epoch: 50.4 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013102068778413967		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.013102068778413967 | validation: 0.013159983601418634]
	TIME [epoch: 50.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013657195169353965		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.013657195169353965 | validation: 0.014085001805175293]
	TIME [epoch: 50.4 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014919755846836111		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.014919755846836111 | validation: 0.009803061098991843]
	TIME [epoch: 50.5 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012539334172359935		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.012539334172359935 | validation: 0.009205622141695007]
	TIME [epoch: 50.4 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011834733260951687		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.011834733260951687 | validation: 0.013238444930495873]
	TIME [epoch: 50.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013436613117548268		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.013436613117548268 | validation: 0.009400057494639721]
	TIME [epoch: 50.5 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014109957539706718		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.014109957539706718 | validation: 0.015448279744871604]
	TIME [epoch: 50.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020609610727271473		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.020609610727271473 | validation: 0.010038093131498145]
	TIME [epoch: 50.4 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015085369115018132		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.015085369115018132 | validation: 0.00989554442469075]
	TIME [epoch: 50.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011312603669289012		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.011312603669289012 | validation: 0.009961049108644971]
	TIME [epoch: 50.4 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011991575161521184		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.011991575161521184 | validation: 0.009130098537781565]
	TIME [epoch: 50.4 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012109063230741688		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.012109063230741688 | validation: 0.009938099744937152]
	TIME [epoch: 50.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014822208154677097		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.014822208154677097 | validation: 0.013389064272143225]
	TIME [epoch: 50.4 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012954843417977306		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.012954843417977306 | validation: 0.011424182871221353]
	TIME [epoch: 50.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012409694419942548		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.012409694419942548 | validation: 0.01184025638447378]
	TIME [epoch: 50.4 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014897271203286391		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.014897271203286391 | validation: 0.009293403949509883]
	TIME [epoch: 50.4 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01271406715373431		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.01271406715373431 | validation: 0.010571672519068579]
	TIME [epoch: 50.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01550182917166762		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.01550182917166762 | validation: 0.0107905707378417]
	TIME [epoch: 50.5 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011139476827511678		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.011139476827511678 | validation: 0.00896816340699918]
	TIME [epoch: 50.4 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011153737852191774		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.011153737852191774 | validation: 0.010964491034393134]
	TIME [epoch: 50.4 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011348321905593105		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.011348321905593105 | validation: 0.010856842535967082]
	TIME [epoch: 50.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01378964304856637		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.01378964304856637 | validation: 0.014151769409875748]
	TIME [epoch: 50.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014015591628822759		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.014015591628822759 | validation: 0.00823103088680761]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_816.pth
	Model improved!!!
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02600266998916195		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.02600266998916195 | validation: 0.016293882410623794]
	TIME [epoch: 50.4 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015163845731074054		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.015163845731074054 | validation: 0.008853790443877872]
	TIME [epoch: 50.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012413182960872552		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.012413182960872552 | validation: 0.00826116230739763]
	TIME [epoch: 50.4 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01172555688815646		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.01172555688815646 | validation: 0.009764096259480123]
	TIME [epoch: 50.4 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011618854040545808		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.011618854040545808 | validation: 0.008968353081809773]
	TIME [epoch: 50.4 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011683254872256889		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.011683254872256889 | validation: 0.008173757622627955]
	TIME [epoch: 50.5 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_822.pth
	Model improved!!!
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011674755031697147		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.011674755031697147 | validation: 0.01161184432732074]
	TIME [epoch: 50.2 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012714368190985322		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.012714368190985322 | validation: 0.009534681154850688]
	TIME [epoch: 50.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011222474633408072		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.011222474633408072 | validation: 0.01468953834637999]
	TIME [epoch: 50.2 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013732137863791858		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.013732137863791858 | validation: 0.008990408368843128]
	TIME [epoch: 50.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011709350225450482		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.011709350225450482 | validation: 0.009215862136374433]
	TIME [epoch: 50.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011645790743074216		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.011645790743074216 | validation: 0.009587020005986744]
	TIME [epoch: 50.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013709897841816119		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.013709897841816119 | validation: 0.009902462069104789]
	TIME [epoch: 50.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011543855048006276		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.011543855048006276 | validation: 0.010015419578677699]
	TIME [epoch: 50.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013668040638035804		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.013668040638035804 | validation: 0.0077601068914693325]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012001071724474717		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.012001071724474717 | validation: 0.009853848699715867]
	TIME [epoch: 50.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011914917873572343		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.011914917873572343 | validation: 0.00899119617621492]
	TIME [epoch: 50.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019012046179692495		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.019012046179692495 | validation: 0.009246547092113392]
	TIME [epoch: 50.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023915148008957866		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.023915148008957866 | validation: 0.01245224828678847]
	TIME [epoch: 50.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015453373167499288		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.015453373167499288 | validation: 0.010194782937709961]
	TIME [epoch: 50.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011070278787781001		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.011070278787781001 | validation: 0.00820147043179968]
	TIME [epoch: 50.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010983085501943348		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.010983085501943348 | validation: 0.01219470600754272]
	TIME [epoch: 50.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011670449962880372		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.011670449962880372 | validation: 0.00991173560395781]
	TIME [epoch: 50.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011080068496722575		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.011080068496722575 | validation: 0.008924037650261741]
	TIME [epoch: 50.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0138841697913588		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.0138841697913588 | validation: 0.008135202570232604]
	TIME [epoch: 50.4 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013525249882469132		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.013525249882469132 | validation: 0.010558351516785356]
	TIME [epoch: 50.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013024029792068516		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.013024029792068516 | validation: 0.009702638316522417]
	TIME [epoch: 50.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016937074272605185		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.016937074272605185 | validation: 0.013306516873656554]
	TIME [epoch: 50.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013334684472637942		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.013334684472637942 | validation: 0.00882261185903692]
	TIME [epoch: 50.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011648407941758726		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.011648407941758726 | validation: 0.009623126049750746]
	TIME [epoch: 50.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010258752220325653		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.010258752220325653 | validation: 0.00829846039582113]
	TIME [epoch: 50.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011481865620056646		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.011481865620056646 | validation: 0.00923229845762167]
	TIME [epoch: 50.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01629459485358211		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.01629459485358211 | validation: 0.008700642507128698]
	TIME [epoch: 50.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012854712232803772		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.012854712232803772 | validation: 0.008309544755409817]
	TIME [epoch: 50.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.013013751055640357		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.013013751055640357 | validation: 0.011018278508507515]
	TIME [epoch: 50.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012392100587099848		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.012392100587099848 | validation: 0.010990513903720725]
	TIME [epoch: 50.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.015493914484847566		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.015493914484847566 | validation: 0.010392519842397642]
	TIME [epoch: 50.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011983522174388066		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.011983522174388066 | validation: 0.008717328682287789]
	TIME [epoch: 50.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011357966784545107		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.011357966784545107 | validation: 0.007858964512341032]
	TIME [epoch: 50.4 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010902704868716414		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.010902704868716414 | validation: 0.009080548941337236]
	TIME [epoch: 50.4 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011941291467839347		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.011941291467839347 | validation: 0.009449229021984588]
	TIME [epoch: 50.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011934937021522379		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.011934937021522379 | validation: 0.010535210650051483]
	TIME [epoch: 50.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011394990958357963		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.011394990958357963 | validation: 0.009452036625578308]
	TIME [epoch: 50.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011213419125949229		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.011213419125949229 | validation: 0.009946298631794057]
	TIME [epoch: 50.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01076581818179162		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.01076581818179162 | validation: 0.009055105693449757]
	TIME [epoch: 50.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.014216191423009535		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.014216191423009535 | validation: 0.01035664747477788]
	TIME [epoch: 50.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012850443598266965		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.012850443598266965 | validation: 0.009175491503708522]
	TIME [epoch: 50.4 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.012284744143413105		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.012284744143413105 | validation: 0.009015448625096439]
	TIME [epoch: 50.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.011077889593511532		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.011077889593511532 | validation: 0.007734024087757863]
	TIME [epoch: 50.4 sec]
	Saving model to: out/model_training/model_phi2_1a_v_mmd1_20241012_114604/states/model_phi2_1a_v_mmd1_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.010239182252508174		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.010239182252508174 | validation: 0.008585038546785474]
	TIME [epoch: 50.4 sec]
EPOCH 867/2000:
	Training over batches...
